# LAT5150DRVMIL RAG System Dependencies
# Install with: pip install -r requirements.txt

# Core RAG dependencies (already installed)
numpy>=1.24.0
scikit-learn>=1.3.0

# Transformer upgrade (Phase 1: 75-88% accuracy)
sentence-transformers>=2.2.0
transformers>=4.30.0
torch>=2.0.0

# PEFT fine-tuning (Phase 2: 90-95%+ accuracy)
peft>=0.5.0
accelerate>=0.20.0
datasets>=2.14.0

# Reinforcement Learning optimization (Phase 3: 95%+ accuracy)
trl>=0.7.0  # Transformer Reinforcement Learning

# Inference optimization (Intel hardware accelerated)
optimum[onnxruntime]>=1.14.0
optimum-intel[openvino,nncf]>=1.14.0  # Intel CPU/NPU acceleration
optimum-quanto>=0.2.0                  # On-the-fly quantization (INT8/INT4/INT2)
intel-extension-for-pytorch>=2.0.0    # IPEX for better Intel CPU performance

# Vector database (optional but recommended)
chromadb>=0.4.0

# Document processing utilities
pypdf>=3.15.0
PyPDF2>=3.0.0              # PDF text extraction (fallback)
pdfplumber>=0.11.0         # Enhanced PDF extraction (tables, images, layout)
cffi>=2.0.0                # Required for pdfplumber cryptography
python-docx>=0.8.11
markdown>=3.4.0
pillow>=10.0.0             # Image processing for PDFs

# Optional: Donut OCR-free document understanding (vision transformer)
# Enables USE_DONUT_PDF=true mode for PDF processing
# Requires: transformers, torch, pdf2image, poppler-utils
# Install with: pip install transformers torch pdf2image
# System dependency: sudo apt-get install poppler-utils
# transformers>=4.30.0  # Already included above
# torch>=2.0.0          # Already included above
# pdf2image>=1.16.0     # Uncomment to enable Donut

# Fast & safe model serialization (zero-copy)
safetensors>=0.4.0

# Efficient data processing pipelines
datatrove>=0.2.0

# Telegram scraping for CVE monitoring
telethon>=1.34.0
python-dotenv>=1.0.0

# Jina AI Embeddings v3 and Reranker (Phase 4: 92-97%+ accuracy)
# High-dimensional embeddings (2084D), 8K token context, multilingual
# Install note: Requires trust_remote_code=True for full functionality
# Model download: ~2.2GB (570M parameters)
# Jina embeddings automatically installed via sentence-transformers
# Optional: requests for Jina Reranker API
requests>=2.31.0  # For Jina Reranker API integration

# Vector database with quantization support
qdrant-client>=1.7.0  # Multi-vector, scalar quantization, HNSW tuning

# Optional: GPU acceleration
# Install separately if you have CUDA:
# pip install torch --index-url https://download.pytorch.org/whl/cu118

# Optional: Jina Cloud API (alternative to local models)
# Sign up at: https://jina.ai
# Set environment variable: export JINA_API_KEY="your_key_here"
# API provides hosted embeddings and reranking (no local GPU needed)
