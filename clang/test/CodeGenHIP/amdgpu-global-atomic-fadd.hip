// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 6
// REQUIRES: amdgpu-registered-target
// RUN: %clang_cc1 -triple amdgcn-amd-amdhsa -target-cpu gfx942 -emit-llvm -fcuda-is-device %s -o - | FileCheck %s

#define __device__ __attribute__((device))

__device__ float global_float;
__device__ double global_double;

// CHECK-LABEL: define dso_local void @_Z33test_global_atomic_fadd_f32_validPff(
// CHECK-SAME: ptr noundef [[PTR:%.*]], float noundef [[VAL:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[VAL_ADDR:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[RESULT:%.*]] = alloca float, align 4, addrspace(5)
// CHECK-NEXT:    [[PTR_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[PTR_ADDR]] to ptr
// CHECK-NEXT:    [[VAL_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[VAL_ADDR]] to ptr
// CHECK-NEXT:    [[RESULT_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[RESULT]] to ptr
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store float [[VAL]], ptr [[VAL_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[TMP0]] to ptr addrspace(1)
// CHECK-NEXT:    [[TMP2:%.*]] = load float, ptr [[VAL_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw fadd ptr addrspace(1) [[TMP1]], float [[TMP2]] syncscope("agent") monotonic, align 4, !amdgpu.no.fine.grained.memory [[META4:![0-9]+]], !amdgpu.ignore.denormal.mode [[META4]]
// CHECK-NEXT:    store float [[TMP3]], ptr [[RESULT_ASCAST]], align 4
// CHECK-NEXT:    [[TMP4:%.*]] = load float, ptr [[VAL_ADDR_ASCAST]], align 4
// CHECK-NEXT:    [[TMP5:%.*]] = atomicrmw fadd ptr addrspace(1) @global_float, float [[TMP4]] syncscope("agent") monotonic, align 4, !amdgpu.no.fine.grained.memory [[META4]], !amdgpu.ignore.denormal.mode [[META4]]
// CHECK-NEXT:    store float [[TMP5]], ptr [[RESULT_ASCAST]], align 4
// CHECK-NEXT:    ret void
//
__device__ void test_global_atomic_fadd_f32_valid(float *ptr, float val) {
  float result;
  result = __builtin_amdgcn_global_atomic_fadd_f32(ptr, val);
  result = __builtin_amdgcn_global_atomic_fadd_f32(&global_float, val);
}

// CHECK-LABEL: define dso_local void @_Z33test_global_atomic_fadd_f64_validPdd(
// CHECK-SAME: ptr noundef [[PTR:%.*]], double noundef [[VAL:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[VAL_ADDR:%.*]] = alloca double, align 8, addrspace(5)
// CHECK-NEXT:    [[RESULT:%.*]] = alloca double, align 8, addrspace(5)
// CHECK-NEXT:    [[PTR_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[PTR_ADDR]] to ptr
// CHECK-NEXT:    [[VAL_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[VAL_ADDR]] to ptr
// CHECK-NEXT:    [[RESULT_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[RESULT]] to ptr
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    store double [[VAL]], ptr [[VAL_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[TMP0]] to ptr addrspace(1)
// CHECK-NEXT:    [[TMP2:%.*]] = load double, ptr [[VAL_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = atomicrmw fadd ptr addrspace(1) [[TMP1]], double [[TMP2]] syncscope("agent") monotonic, align 8, !amdgpu.no.fine.grained.memory [[META4]]
// CHECK-NEXT:    store double [[TMP3]], ptr [[RESULT_ASCAST]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load double, ptr [[VAL_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = atomicrmw fadd ptr addrspace(1) @global_double, double [[TMP4]] syncscope("agent") monotonic, align 8, !amdgpu.no.fine.grained.memory [[META4]]
// CHECK-NEXT:    store double [[TMP5]], ptr [[RESULT_ASCAST]], align 8
// CHECK-NEXT:    ret void
//
__device__ void test_global_atomic_fadd_f64_valid(double *ptr, double val) {
  double result;
  result = __builtin_amdgcn_global_atomic_fadd_f64(ptr, val);
  result = __builtin_amdgcn_global_atomic_fadd_f64(&global_double, val);
}
//.
// CHECK: [[META4]] = !{}
//.
