// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 2
// RUN: %clang_cc1 -std=c++23 -triple x86_64-unknown-linux-gnu -target-feature +fullbf16 -emit-llvm %s -o - | FileCheck %s

typedef decltype(0.0BF16) v8bfloat16 __attribute__((__vector_size__(16)));

// CHECK-LABEL: define dso_local void @_Z11test_vectorDv8_DF16bS_
// CHECK-SAME: (<8 x bfloat> noundef [[A:%.*]], <8 x bfloat> noundef [[B:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK:         [[A_ADDR:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    [[C:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    store <8 x bfloat> [[A]], ptr [[A_ADDR]], align 16
// CHECK-NEXT:    store <8 x bfloat> [[B]], ptr [[B_ADDR]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x bfloat>, ptr [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x bfloat>, ptr [[B_ADDR]], align 16
// CHECK-NEXT:    [[ADD:%.*]] = fadd <8 x bfloat> [[TMP0]], [[TMP1]]
// CHECK-NEXT:    store <8 x bfloat> [[ADD]], ptr [[C]], align 16
// CHECK-NEXT:    [[TMP2:%.*]] = load <8 x bfloat>, ptr [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP3:%.*]] = load <8 x bfloat>, ptr [[B_ADDR]], align 16
// CHECK-NEXT:    [[SUB:%.*]] = fsub <8 x bfloat> [[TMP2]], [[TMP3]]
// CHECK-NEXT:    store <8 x bfloat> [[SUB]], ptr [[C]], align 16
// CHECK-NEXT:    [[TMP4:%.*]] = load <8 x bfloat>, ptr [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP5:%.*]] = load <8 x bfloat>, ptr [[B_ADDR]], align 16
// CHECK-NEXT:    [[MUL:%.*]] = fmul <8 x bfloat> [[TMP4]], [[TMP5]]
// CHECK-NEXT:    store <8 x bfloat> [[MUL]], ptr [[C]], align 16
// CHECK-NEXT:    [[TMP6:%.*]] = load <8 x bfloat>, ptr [[A_ADDR]], align 16
// CHECK-NEXT:    [[TMP7:%.*]] = load <8 x bfloat>, ptr [[B_ADDR]], align 16
// CHECK-NEXT:    [[DIV:%.*]] = fdiv <8 x bfloat> [[TMP6]], [[TMP7]]
// CHECK-NEXT:    store <8 x bfloat> [[DIV]], ptr [[C]], align 16
// CHECK-NEXT:    ret void
//
void test_vector(v8bfloat16 a, v8bfloat16 b) {
    v8bfloat16 c;
    c = a + b;
    c = a - b;
    c = a * b;
    c = a / b;
}

// CHECK-LABEL: define dso_local void @_Z13test_vector_2v
// CHECK-SAME: () #[[ATTR1:[0-9]+]] {
// CHECK:         [[A:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    [[B:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL1:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    [[C:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    [[D:%.*]] = alloca <8 x bfloat>, align 16
// CHECK-NEXT:    store <8 x bfloat> zeroinitializer, ptr [[DOTCOMPOUNDLITERAL]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = load <8 x bfloat>, ptr [[DOTCOMPOUNDLITERAL]], align 16
// CHECK-NEXT:    store <8 x bfloat> [[TMP0]], ptr [[A]], align 16
// CHECK-NEXT:    store <8 x bfloat> <bfloat 0xR3F80, bfloat 0xR0000, bfloat 0xR0000, bfloat 0xR0000, bfloat 0xR0000, bfloat 0xR0000, bfloat 0xR0000, bfloat 0xR0000>, ptr [[DOTCOMPOUNDLITERAL1]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = load <8 x bfloat>, ptr [[DOTCOMPOUNDLITERAL1]], align 16
// CHECK-NEXT:    store <8 x bfloat> [[TMP1]], ptr [[B]], align 16
// CHECK-NEXT:    [[TMP2:%.*]] = load <8 x bfloat>, ptr [[A]], align 16
// CHECK-NEXT:    [[ELT_ABS:%.*]] = call <8 x bfloat> @llvm.fabs.v8bf16(<8 x bfloat> [[TMP2]])
// CHECK-NEXT:    store <8 x bfloat> [[ELT_ABS]], ptr [[C]], align 16
// CHECK-NEXT:    [[TMP3:%.*]] = load <8 x bfloat>, ptr [[C]], align 16
// CHECK-NEXT:    [[ELT_ABS2:%.*]] = call <8 x bfloat> @llvm.fabs.v8bf16(<8 x bfloat> [[TMP3]])
// CHECK-NEXT:    store <8 x bfloat> [[ELT_ABS2]], ptr [[D]], align 16
// CHECK-NEXT:    ret void
//
void test_vector_2() {
    v8bfloat16 a = (v8bfloat16){0.0bf16};
    v8bfloat16 b = (v8bfloat16){1.0bf16};
    v8bfloat16 c = __builtin_elementwise_abs(a);
    v8bfloat16 d = __builtin_elementwise_abs(c);
}

