// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// RUN: %clang_cc1 -disable-llvm-passes -O3 -triple x86_64 %s -emit-llvm -o - | FileCheck %s --check-prefix=CHECK
// RUN: %clang_cc1 -disable-llvm-passes -fno-fast-math -O3 -triple x86_64 %s -emit-llvm -o - | FileCheck %s --check-prefix=CHECK
//
// RUN: %clang_cc1 -disable-llvm-passes -fsigned-zeros -O3 -triple x86_64 %s -emit-llvm -o - | FileCheck %s --check-prefix=CHECK
// RUN: %clang_cc1 -disable-llvm-passes -menable-no-nans -O3 -triple x86_64 %s -emit-llvm -o - | FileCheck %s --check-prefix=CHECK-NO-NANS
// RUN: %clang_cc1 -disable-llvm-passes -menable-no-infs -O3 -triple x86_64 %s -emit-llvm -o - | FileCheck %s --check-prefix=CHECK-NO-INFS
/// FIXME: -ffinite-math-only
// RUN: %clang_cc1 -disable-llvm-passes -ffast-math -O3 -triple x86_64 %s -emit-llvm -o - | FileCheck %s --check-prefix=CHECK-FAST
//
// RUN: %clang_cc1 -disable-llvm-passes -O3 -ffp-exception-behavior=strict -DENSTRICT=1 -triple x86_64 %s -emit-llvm -o - | FileCheck %s --check-prefix=CHECK-STRICT

float fminf (float, float);
double fmin (double, double);
long double fminl (long double, long double);
float fmaxf (float, float);
double fmax (double, double);
long double fmaxl (long double, long double);

typedef float float4 __attribute__((ext_vector_type(4)));
typedef double double2 __attribute__((ext_vector_type(2)));

// CHECK-LABEL: define dso_local float @fmin32(
// CHECK-SAME: float noundef [[A:%.*]], float noundef [[B:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2:![0-9]+]]
// CHECK-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz float @llvm.minnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NEXT:    ret float [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) float @fmin32(
// CHECK-NO-NANS-SAME: float noundef nofpclass(nan) [[A:%.*]], float noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-NANS-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2:![0-9]+]]
// CHECK-NO-NANS-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz float @llvm.minnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NO-NANS-NEXT:    ret float [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) float @fmin32(
// CHECK-NO-INFS-SAME: float noundef nofpclass(inf) [[A:%.*]], float noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-INFS-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2:![0-9]+]]
// CHECK-NO-INFS-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz float @llvm.minnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NO-INFS-NEXT:    ret float [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) float @fmin32(
// CHECK-FAST-SAME: float noundef nofpclass(nan inf) [[A:%.*]], float noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-FAST-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2:![0-9]+]]
// CHECK-FAST-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn float @llvm.minnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-FAST-NEXT:    ret float [[TMP2]]
//
// CHECK-STRICT-LABEL: define dso_local float @fmin32(
// CHECK-STRICT-SAME: float noundef [[A:%.*]], float noundef [[B:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-STRICT-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2:![0-9]+]]
// CHECK-STRICT-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz float @llvm.experimental.constrained.minnum.f32(float [[TMP0]], float [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2:[0-9]+]]
// CHECK-STRICT-NEXT:    ret float [[TMP2]]
//
float fmin32(float a, float b) {
        return fminf(a, b);
}
// CHECK-LABEL: define dso_local float @fmin32b(
// CHECK-SAME: float noundef [[A:%.*]], float noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz float @llvm.minnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NEXT:    ret float [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) float @fmin32b(
// CHECK-NO-NANS-SAME: float noundef nofpclass(nan) [[A:%.*]], float noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-NANS-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz float @llvm.minnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NO-NANS-NEXT:    ret float [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) float @fmin32b(
// CHECK-NO-INFS-SAME: float noundef nofpclass(inf) [[A:%.*]], float noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-INFS-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz float @llvm.minnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NO-INFS-NEXT:    ret float [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) float @fmin32b(
// CHECK-FAST-SAME: float noundef nofpclass(nan inf) [[A:%.*]], float noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-FAST-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn float @llvm.minnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-FAST-NEXT:    ret float [[TMP2]]
//
// CHECK-STRICT-LABEL: define dso_local float @fmin32b(
// CHECK-STRICT-SAME: float noundef [[A:%.*]], float noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-STRICT-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz float @llvm.experimental.constrained.minnum.f32(float [[TMP0]], float [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret float [[TMP2]]
//
float fmin32b(float a, float b) {
        return __builtin_fminf(a, b);
}
#if !defined(ENSTRICT)
// CHECK-LABEL: define dso_local <4 x float> @pfmin32(
// CHECK-SAME: <4 x float> noundef [[A:%.*]], <4 x float> noundef [[B:%.*]], <4 x float> noundef [[C:%.*]]) #[[ATTR2:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[C_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    store <4 x float> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6:![0-9]+]]
// CHECK-NEXT:    store <4 x float> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    store <4 x float> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP0:%.*]] = load <4 x float>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[ELT_MIN:%.*]] = call nsz <4 x float> @llvm.minnum.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]])
// CHECK-NEXT:    store <4 x float> [[ELT_MIN]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP2:%.*]] = load <4 x float>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    ret <4 x float> [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) <4 x float> @pfmin32(
// CHECK-NO-NANS-SAME: <4 x float> noundef nofpclass(nan) [[A:%.*]], <4 x float> noundef nofpclass(nan) [[B:%.*]], <4 x float> noundef nofpclass(nan) [[C:%.*]]) #[[ATTR2:[0-9]+]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-NANS-NEXT:    [[C_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-NANS-NEXT:    store <4 x float> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6:![0-9]+]]
// CHECK-NO-NANS-NEXT:    store <4 x float> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    store <4 x float> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load <4 x float>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[ELT_MIN:%.*]] = call nnan nsz <4 x float> @llvm.minnum.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]])
// CHECK-NO-NANS-NEXT:    store <4 x float> [[ELT_MIN]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = load <4 x float>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    ret <4 x float> [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) <4 x float> @pfmin32(
// CHECK-NO-INFS-SAME: <4 x float> noundef nofpclass(inf) [[A:%.*]], <4 x float> noundef nofpclass(inf) [[B:%.*]], <4 x float> noundef nofpclass(inf) [[C:%.*]]) #[[ATTR2:[0-9]+]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-INFS-NEXT:    [[C_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-INFS-NEXT:    store <4 x float> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6:![0-9]+]]
// CHECK-NO-INFS-NEXT:    store <4 x float> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    store <4 x float> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load <4 x float>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[ELT_MIN:%.*]] = call ninf nsz <4 x float> @llvm.minnum.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]])
// CHECK-NO-INFS-NEXT:    store <4 x float> [[ELT_MIN]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = load <4 x float>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    ret <4 x float> [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) <4 x float> @pfmin32(
// CHECK-FAST-SAME: <4 x float> noundef nofpclass(nan inf) [[A:%.*]], <4 x float> noundef nofpclass(nan inf) [[B:%.*]], <4 x float> noundef nofpclass(nan inf) [[C:%.*]]) #[[ATTR2:[0-9]+]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-FAST-NEXT:    [[C_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-FAST-NEXT:    store <4 x float> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6:![0-9]+]]
// CHECK-FAST-NEXT:    store <4 x float> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    store <4 x float> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load <4 x float>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[ELT_MIN:%.*]] = call reassoc nnan ninf nsz arcp afn <4 x float> @llvm.minnum.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]])
// CHECK-FAST-NEXT:    store <4 x float> [[ELT_MIN]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = load <4 x float>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    ret <4 x float> [[TMP2]]
//
float4 pfmin32(float4 a, float4 b, float4 c) {
	c = __builtin_elementwise_min(a, b);
	return c;
}
#endif
// CHECK-LABEL: define dso_local float @fmin64(
// CHECK-SAME: double noundef [[A:%.*]], double noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7:![0-9]+]]
// CHECK-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz double @llvm.minnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[CONV:%.*]] = fptrunc double [[TMP2]] to float
// CHECK-NEXT:    ret float [[CONV]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) float @fmin64(
// CHECK-NO-NANS-SAME: double noundef nofpclass(nan) [[A:%.*]], double noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-NANS-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7:![0-9]+]]
// CHECK-NO-NANS-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz double @llvm.minnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NO-NANS-NEXT:    [[CONV:%.*]] = fptrunc nnan double [[TMP2]] to float
// CHECK-NO-NANS-NEXT:    ret float [[CONV]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) float @fmin64(
// CHECK-NO-INFS-SAME: double noundef nofpclass(inf) [[A:%.*]], double noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-INFS-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7:![0-9]+]]
// CHECK-NO-INFS-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz double @llvm.minnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NO-INFS-NEXT:    [[CONV:%.*]] = fptrunc ninf double [[TMP2]] to float
// CHECK-NO-INFS-NEXT:    ret float [[CONV]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) float @fmin64(
// CHECK-FAST-SAME: double noundef nofpclass(nan inf) [[A:%.*]], double noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-FAST-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7:![0-9]+]]
// CHECK-FAST-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn double @llvm.minnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-FAST-NEXT:    [[CONV:%.*]] = fptrunc reassoc nnan ninf nsz arcp afn double [[TMP2]] to float
// CHECK-FAST-NEXT:    ret float [[CONV]]
//
// CHECK-STRICT-LABEL: define dso_local float @fmin64(
// CHECK-STRICT-SAME: double noundef [[A:%.*]], double noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-STRICT-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA6:![0-9]+]]
// CHECK-STRICT-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz double @llvm.experimental.constrained.minnum.f64(double [[TMP0]], double [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    [[CONV:%.*]] = call float @llvm.experimental.constrained.fptrunc.f32.f64(double [[TMP2]], metadata !"round.tonearest", metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret float [[CONV]]
//
float fmin64(double a, double b) {
        return fmin(a, b);
}
// CHECK-LABEL: define dso_local float @fmin64b(
// CHECK-SAME: double noundef [[A:%.*]], double noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz double @llvm.minnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[CONV:%.*]] = fptrunc double [[TMP2]] to float
// CHECK-NEXT:    ret float [[CONV]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) float @fmin64b(
// CHECK-NO-NANS-SAME: double noundef nofpclass(nan) [[A:%.*]], double noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-NANS-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz double @llvm.minnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NO-NANS-NEXT:    [[CONV:%.*]] = fptrunc nnan double [[TMP2]] to float
// CHECK-NO-NANS-NEXT:    ret float [[CONV]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) float @fmin64b(
// CHECK-NO-INFS-SAME: double noundef nofpclass(inf) [[A:%.*]], double noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-INFS-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz double @llvm.minnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NO-INFS-NEXT:    [[CONV:%.*]] = fptrunc ninf double [[TMP2]] to float
// CHECK-NO-INFS-NEXT:    ret float [[CONV]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) float @fmin64b(
// CHECK-FAST-SAME: double noundef nofpclass(nan inf) [[A:%.*]], double noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-FAST-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn double @llvm.minnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-FAST-NEXT:    [[CONV:%.*]] = fptrunc reassoc nnan ninf nsz arcp afn double [[TMP2]] to float
// CHECK-FAST-NEXT:    ret float [[CONV]]
//
// CHECK-STRICT-LABEL: define dso_local float @fmin64b(
// CHECK-STRICT-SAME: double noundef [[A:%.*]], double noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-STRICT-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz double @llvm.experimental.constrained.minnum.f64(double [[TMP0]], double [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    [[CONV:%.*]] = call float @llvm.experimental.constrained.fptrunc.f32.f64(double [[TMP2]], metadata !"round.tonearest", metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret float [[CONV]]
//
float fmin64b(double a, double b) {
        return __builtin_fmin(a, b);
}
#if !defined(ENSTRICT)
// CHECK-LABEL: define dso_local <2 x double> @pfmin64(
// CHECK-SAME: <2 x double> noundef [[A:%.*]], <2 x double> noundef [[B:%.*]], <2 x double> noundef [[C:%.*]]) #[[ATTR2]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NEXT:    [[C_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NEXT:    store <2 x double> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    store <2 x double> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    store <2 x double> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP0:%.*]] = load <2 x double>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <2 x double>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[ELT_MIN:%.*]] = call nsz <2 x double> @llvm.minnum.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]])
// CHECK-NEXT:    store <2 x double> [[ELT_MIN]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP2:%.*]] = load <2 x double>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    ret <2 x double> [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) <2 x double> @pfmin64(
// CHECK-NO-NANS-SAME: <2 x double> noundef nofpclass(nan) [[A:%.*]], <2 x double> noundef nofpclass(nan) [[B:%.*]], <2 x double> noundef nofpclass(nan) [[C:%.*]]) #[[ATTR2]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-NANS-NEXT:    [[C_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-NANS-NEXT:    store <2 x double> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    store <2 x double> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    store <2 x double> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load <2 x double>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load <2 x double>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[ELT_MIN:%.*]] = call nnan nsz <2 x double> @llvm.minnum.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]])
// CHECK-NO-NANS-NEXT:    store <2 x double> [[ELT_MIN]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = load <2 x double>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    ret <2 x double> [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) <2 x double> @pfmin64(
// CHECK-NO-INFS-SAME: <2 x double> noundef nofpclass(inf) [[A:%.*]], <2 x double> noundef nofpclass(inf) [[B:%.*]], <2 x double> noundef nofpclass(inf) [[C:%.*]]) #[[ATTR2]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-INFS-NEXT:    [[C_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-INFS-NEXT:    store <2 x double> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    store <2 x double> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    store <2 x double> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load <2 x double>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load <2 x double>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[ELT_MIN:%.*]] = call ninf nsz <2 x double> @llvm.minnum.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]])
// CHECK-NO-INFS-NEXT:    store <2 x double> [[ELT_MIN]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = load <2 x double>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    ret <2 x double> [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) <2 x double> @pfmin64(
// CHECK-FAST-SAME: <2 x double> noundef nofpclass(nan inf) [[A:%.*]], <2 x double> noundef nofpclass(nan inf) [[B:%.*]], <2 x double> noundef nofpclass(nan inf) [[C:%.*]]) #[[ATTR2]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-FAST-NEXT:    [[C_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-FAST-NEXT:    store <2 x double> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    store <2 x double> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    store <2 x double> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load <2 x double>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load <2 x double>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[ELT_MIN:%.*]] = call reassoc nnan ninf nsz arcp afn <2 x double> @llvm.minnum.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]])
// CHECK-FAST-NEXT:    store <2 x double> [[ELT_MIN]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = load <2 x double>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    ret <2 x double> [[TMP2]]
//
double2 pfmin64(double2 a, double2 b, double2 c) {
	c = __builtin_elementwise_min(a, b);
	return c;
}
#endif
// CHECK-LABEL: define dso_local x86_fp80 @fmin80(
// CHECK-SAME: x86_fp80 noundef [[A:%.*]], x86_fp80 noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9:![0-9]+]]
// CHECK-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz x86_fp80 @llvm.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) x86_fp80 @fmin80(
// CHECK-NO-NANS-SAME: x86_fp80 noundef nofpclass(nan) [[A:%.*]], x86_fp80 noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-NANS-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9:![0-9]+]]
// CHECK-NO-NANS-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz x86_fp80 @llvm.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NO-NANS-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) x86_fp80 @fmin80(
// CHECK-NO-INFS-SAME: x86_fp80 noundef nofpclass(inf) [[A:%.*]], x86_fp80 noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-INFS-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9:![0-9]+]]
// CHECK-NO-INFS-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz x86_fp80 @llvm.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NO-INFS-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) x86_fp80 @fmin80(
// CHECK-FAST-SAME: x86_fp80 noundef nofpclass(nan inf) [[A:%.*]], x86_fp80 noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-FAST-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9:![0-9]+]]
// CHECK-FAST-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn x86_fp80 @llvm.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-FAST-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-STRICT-LABEL: define dso_local x86_fp80 @fmin80(
// CHECK-STRICT-SAME: x86_fp80 noundef [[A:%.*]], x86_fp80 noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-STRICT-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA8:![0-9]+]]
// CHECK-STRICT-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz x86_fp80 @llvm.experimental.constrained.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret x86_fp80 [[TMP2]]
//
long double fmin80(long double a, long double b) {
        return fminl(a, b);
}
// CHECK-LABEL: define dso_local x86_fp80 @fmin80b(
// CHECK-SAME: x86_fp80 noundef [[A:%.*]], x86_fp80 noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz x86_fp80 @llvm.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) x86_fp80 @fmin80b(
// CHECK-NO-NANS-SAME: x86_fp80 noundef nofpclass(nan) [[A:%.*]], x86_fp80 noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-NANS-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz x86_fp80 @llvm.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NO-NANS-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) x86_fp80 @fmin80b(
// CHECK-NO-INFS-SAME: x86_fp80 noundef nofpclass(inf) [[A:%.*]], x86_fp80 noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-INFS-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz x86_fp80 @llvm.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NO-INFS-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) x86_fp80 @fmin80b(
// CHECK-FAST-SAME: x86_fp80 noundef nofpclass(nan inf) [[A:%.*]], x86_fp80 noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-FAST-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn x86_fp80 @llvm.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-FAST-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-STRICT-LABEL: define dso_local x86_fp80 @fmin80b(
// CHECK-STRICT-SAME: x86_fp80 noundef [[A:%.*]], x86_fp80 noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-STRICT-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz x86_fp80 @llvm.experimental.constrained.minnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret x86_fp80 [[TMP2]]
//
long double fmin80b(long double a, long double b) {
        return __builtin_fminl(a, b);
}
// CHECK-LABEL: define dso_local float @fmax32(
// CHECK-SAME: float noundef [[A:%.*]], float noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz float @llvm.maxnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NEXT:    ret float [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) float @fmax32(
// CHECK-NO-NANS-SAME: float noundef nofpclass(nan) [[A:%.*]], float noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-NANS-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz float @llvm.maxnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NO-NANS-NEXT:    ret float [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) float @fmax32(
// CHECK-NO-INFS-SAME: float noundef nofpclass(inf) [[A:%.*]], float noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-INFS-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz float @llvm.maxnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NO-INFS-NEXT:    ret float [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) float @fmax32(
// CHECK-FAST-SAME: float noundef nofpclass(nan inf) [[A:%.*]], float noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-FAST-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn float @llvm.maxnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-FAST-NEXT:    ret float [[TMP2]]
//
// CHECK-STRICT-LABEL: define dso_local float @fmax32(
// CHECK-STRICT-SAME: float noundef [[A:%.*]], float noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-STRICT-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz float @llvm.experimental.constrained.maxnum.f32(float [[TMP0]], float [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret float [[TMP2]]
//
float fmax32(float a, float b) {
        return fmaxf(a, b);
}
// CHECK-LABEL: define dso_local float @fmax32b(
// CHECK-SAME: float noundef [[A:%.*]], float noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz float @llvm.maxnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NEXT:    ret float [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) float @fmax32b(
// CHECK-NO-NANS-SAME: float noundef nofpclass(nan) [[A:%.*]], float noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-NANS-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz float @llvm.maxnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NO-NANS-NEXT:    ret float [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) float @fmax32b(
// CHECK-NO-INFS-SAME: float noundef nofpclass(inf) [[A:%.*]], float noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-NO-INFS-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz float @llvm.maxnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-NO-INFS-NEXT:    ret float [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) float @fmax32b(
// CHECK-FAST-SAME: float noundef nofpclass(nan inf) [[A:%.*]], float noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-FAST-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn float @llvm.maxnum.f32(float [[TMP0]], float [[TMP1]])
// CHECK-FAST-NEXT:    ret float [[TMP2]]
//
// CHECK-STRICT-LABEL: define dso_local float @fmax32b(
// CHECK-STRICT-SAME: float noundef [[A:%.*]], float noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca float, align 4
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca float, align 4
// CHECK-STRICT-NEXT:    store float [[A]], ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    store float [[B]], ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load float, ptr [[A_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load float, ptr [[B_ADDR]], align 4, !tbaa [[TBAA2]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz float @llvm.experimental.constrained.maxnum.f32(float [[TMP0]], float [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret float [[TMP2]]
//
float fmax32b(float a, float b) {
        return __builtin_fmaxf(a, b);
}
#if !defined(ENSTRICT)
// CHECK-LABEL: define dso_local <4 x float> @pfmax32(
// CHECK-SAME: <4 x float> noundef [[A:%.*]], <4 x float> noundef [[B:%.*]], <4 x float> noundef [[C:%.*]]) #[[ATTR2]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[C_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    store <4 x float> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    store <4 x float> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    store <4 x float> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP0:%.*]] = load <4 x float>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[ELT_MAX:%.*]] = call nsz <4 x float> @llvm.maxnum.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]])
// CHECK-NEXT:    store <4 x float> [[ELT_MAX]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP2:%.*]] = load <4 x float>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    ret <4 x float> [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) <4 x float> @pfmax32(
// CHECK-NO-NANS-SAME: <4 x float> noundef nofpclass(nan) [[A:%.*]], <4 x float> noundef nofpclass(nan) [[B:%.*]], <4 x float> noundef nofpclass(nan) [[C:%.*]]) #[[ATTR2]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-NANS-NEXT:    [[C_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-NANS-NEXT:    store <4 x float> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    store <4 x float> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    store <4 x float> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load <4 x float>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[ELT_MAX:%.*]] = call nnan nsz <4 x float> @llvm.maxnum.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]])
// CHECK-NO-NANS-NEXT:    store <4 x float> [[ELT_MAX]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = load <4 x float>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    ret <4 x float> [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) <4 x float> @pfmax32(
// CHECK-NO-INFS-SAME: <4 x float> noundef nofpclass(inf) [[A:%.*]], <4 x float> noundef nofpclass(inf) [[B:%.*]], <4 x float> noundef nofpclass(inf) [[C:%.*]]) #[[ATTR2]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-INFS-NEXT:    [[C_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-NO-INFS-NEXT:    store <4 x float> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    store <4 x float> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    store <4 x float> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load <4 x float>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[ELT_MAX:%.*]] = call ninf nsz <4 x float> @llvm.maxnum.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]])
// CHECK-NO-INFS-NEXT:    store <4 x float> [[ELT_MAX]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = load <4 x float>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    ret <4 x float> [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) <4 x float> @pfmax32(
// CHECK-FAST-SAME: <4 x float> noundef nofpclass(nan inf) [[A:%.*]], <4 x float> noundef nofpclass(nan inf) [[B:%.*]], <4 x float> noundef nofpclass(nan inf) [[C:%.*]]) #[[ATTR2]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-FAST-NEXT:    [[C_ADDR:%.*]] = alloca <4 x float>, align 16
// CHECK-FAST-NEXT:    store <4 x float> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    store <4 x float> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    store <4 x float> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load <4 x float>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[ELT_MAX:%.*]] = call reassoc nnan ninf nsz arcp afn <4 x float> @llvm.maxnum.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]])
// CHECK-FAST-NEXT:    store <4 x float> [[ELT_MAX]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = load <4 x float>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    ret <4 x float> [[TMP2]]
//
float4 pfmax32(float4 a, float4 b, float4 c) {
	c = __builtin_elementwise_max(a, b);
	return c;
}
#endif
// CHECK-LABEL: define dso_local float @fmax64(
// CHECK-SAME: double noundef [[A:%.*]], double noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz double @llvm.maxnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[CONV:%.*]] = fptrunc double [[TMP2]] to float
// CHECK-NEXT:    ret float [[CONV]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) float @fmax64(
// CHECK-NO-NANS-SAME: double noundef nofpclass(nan) [[A:%.*]], double noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-NANS-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz double @llvm.maxnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NO-NANS-NEXT:    [[CONV:%.*]] = fptrunc nnan double [[TMP2]] to float
// CHECK-NO-NANS-NEXT:    ret float [[CONV]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) float @fmax64(
// CHECK-NO-INFS-SAME: double noundef nofpclass(inf) [[A:%.*]], double noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-INFS-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz double @llvm.maxnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NO-INFS-NEXT:    [[CONV:%.*]] = fptrunc ninf double [[TMP2]] to float
// CHECK-NO-INFS-NEXT:    ret float [[CONV]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) float @fmax64(
// CHECK-FAST-SAME: double noundef nofpclass(nan inf) [[A:%.*]], double noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-FAST-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn double @llvm.maxnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-FAST-NEXT:    [[CONV:%.*]] = fptrunc reassoc nnan ninf nsz arcp afn double [[TMP2]] to float
// CHECK-FAST-NEXT:    ret float [[CONV]]
//
// CHECK-STRICT-LABEL: define dso_local float @fmax64(
// CHECK-STRICT-SAME: double noundef [[A:%.*]], double noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-STRICT-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz double @llvm.experimental.constrained.maxnum.f64(double [[TMP0]], double [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    [[CONV:%.*]] = call float @llvm.experimental.constrained.fptrunc.f32.f64(double [[TMP2]], metadata !"round.tonearest", metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret float [[CONV]]
//
float fmax64(double a, double b) {
        return fmax(a, b);
}
// CHECK-LABEL: define dso_local float @fmax64b(
// CHECK-SAME: double noundef [[A:%.*]], double noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz double @llvm.maxnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[CONV:%.*]] = fptrunc double [[TMP2]] to float
// CHECK-NEXT:    ret float [[CONV]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) float @fmax64b(
// CHECK-NO-NANS-SAME: double noundef nofpclass(nan) [[A:%.*]], double noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-NANS-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz double @llvm.maxnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NO-NANS-NEXT:    [[CONV:%.*]] = fptrunc nnan double [[TMP2]] to float
// CHECK-NO-NANS-NEXT:    ret float [[CONV]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) float @fmax64b(
// CHECK-NO-INFS-SAME: double noundef nofpclass(inf) [[A:%.*]], double noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-NO-INFS-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz double @llvm.maxnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NO-INFS-NEXT:    [[CONV:%.*]] = fptrunc ninf double [[TMP2]] to float
// CHECK-NO-INFS-NEXT:    ret float [[CONV]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) float @fmax64b(
// CHECK-FAST-SAME: double noundef nofpclass(nan inf) [[A:%.*]], double noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-FAST-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA7]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn double @llvm.maxnum.f64(double [[TMP0]], double [[TMP1]])
// CHECK-FAST-NEXT:    [[CONV:%.*]] = fptrunc reassoc nnan ninf nsz arcp afn double [[TMP2]] to float
// CHECK-FAST-NEXT:    ret float [[CONV]]
//
// CHECK-STRICT-LABEL: define dso_local float @fmax64b(
// CHECK-STRICT-SAME: double noundef [[A:%.*]], double noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca double, align 8
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca double, align 8
// CHECK-STRICT-NEXT:    store double [[A]], ptr [[A_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    store double [[B]], ptr [[B_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load double, ptr [[A_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load double, ptr [[B_ADDR]], align 8, !tbaa [[TBAA6]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz double @llvm.experimental.constrained.maxnum.f64(double [[TMP0]], double [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    [[CONV:%.*]] = call float @llvm.experimental.constrained.fptrunc.f32.f64(double [[TMP2]], metadata !"round.tonearest", metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret float [[CONV]]
//
float fmax64b(double a, double b) {
        return __builtin_fmax(a, b);
}
#if !defined(ENSTRICT)
// CHECK-LABEL: define dso_local <2 x double> @pfmax64(
// CHECK-SAME: <2 x double> noundef [[A:%.*]], <2 x double> noundef [[B:%.*]], <2 x double> noundef [[C:%.*]]) #[[ATTR2]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NEXT:    [[C_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NEXT:    store <2 x double> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    store <2 x double> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    store <2 x double> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP0:%.*]] = load <2 x double>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <2 x double>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[ELT_MAX:%.*]] = call nsz <2 x double> @llvm.maxnum.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]])
// CHECK-NEXT:    store <2 x double> [[ELT_MAX]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    [[TMP2:%.*]] = load <2 x double>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NEXT:    ret <2 x double> [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) <2 x double> @pfmax64(
// CHECK-NO-NANS-SAME: <2 x double> noundef nofpclass(nan) [[A:%.*]], <2 x double> noundef nofpclass(nan) [[B:%.*]], <2 x double> noundef nofpclass(nan) [[C:%.*]]) #[[ATTR2]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-NANS-NEXT:    [[C_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-NANS-NEXT:    store <2 x double> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    store <2 x double> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    store <2 x double> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load <2 x double>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load <2 x double>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[ELT_MAX:%.*]] = call nnan nsz <2 x double> @llvm.maxnum.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]])
// CHECK-NO-NANS-NEXT:    store <2 x double> [[ELT_MAX]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = load <2 x double>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-NANS-NEXT:    ret <2 x double> [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) <2 x double> @pfmax64(
// CHECK-NO-INFS-SAME: <2 x double> noundef nofpclass(inf) [[A:%.*]], <2 x double> noundef nofpclass(inf) [[B:%.*]], <2 x double> noundef nofpclass(inf) [[C:%.*]]) #[[ATTR2]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-INFS-NEXT:    [[C_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-NO-INFS-NEXT:    store <2 x double> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    store <2 x double> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    store <2 x double> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load <2 x double>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load <2 x double>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[ELT_MAX:%.*]] = call ninf nsz <2 x double> @llvm.maxnum.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]])
// CHECK-NO-INFS-NEXT:    store <2 x double> [[ELT_MAX]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = load <2 x double>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-NO-INFS-NEXT:    ret <2 x double> [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) <2 x double> @pfmax64(
// CHECK-FAST-SAME: <2 x double> noundef nofpclass(nan inf) [[A:%.*]], <2 x double> noundef nofpclass(nan inf) [[B:%.*]], <2 x double> noundef nofpclass(nan inf) [[C:%.*]]) #[[ATTR2]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-FAST-NEXT:    [[C_ADDR:%.*]] = alloca <2 x double>, align 16
// CHECK-FAST-NEXT:    store <2 x double> [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    store <2 x double> [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    store <2 x double> [[C]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load <2 x double>, ptr [[A_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load <2 x double>, ptr [[B_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[ELT_MAX:%.*]] = call reassoc nnan ninf nsz arcp afn <2 x double> @llvm.maxnum.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]])
// CHECK-FAST-NEXT:    store <2 x double> [[ELT_MAX]], ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = load <2 x double>, ptr [[C_ADDR]], align 16, !tbaa [[TBAA6]]
// CHECK-FAST-NEXT:    ret <2 x double> [[TMP2]]
//
double2 pfmax64(double2 a, double2 b, double2 c) {
	c = __builtin_elementwise_max(a, b);
	return c;
}
#endif
// CHECK-LABEL: define dso_local x86_fp80 @fmax80(
// CHECK-SAME: x86_fp80 noundef [[A:%.*]], x86_fp80 noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz x86_fp80 @llvm.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) x86_fp80 @fmax80(
// CHECK-NO-NANS-SAME: x86_fp80 noundef nofpclass(nan) [[A:%.*]], x86_fp80 noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-NANS-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz x86_fp80 @llvm.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NO-NANS-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) x86_fp80 @fmax80(
// CHECK-NO-INFS-SAME: x86_fp80 noundef nofpclass(inf) [[A:%.*]], x86_fp80 noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-INFS-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz x86_fp80 @llvm.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NO-INFS-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) x86_fp80 @fmax80(
// CHECK-FAST-SAME: x86_fp80 noundef nofpclass(nan inf) [[A:%.*]], x86_fp80 noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-FAST-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn x86_fp80 @llvm.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-FAST-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-STRICT-LABEL: define dso_local x86_fp80 @fmax80(
// CHECK-STRICT-SAME: x86_fp80 noundef [[A:%.*]], x86_fp80 noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-STRICT-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz x86_fp80 @llvm.experimental.constrained.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret x86_fp80 [[TMP2]]
//
long double fmax80(long double a, long double b) {
        return fmaxl(a, b);
}
// CHECK-LABEL: define dso_local x86_fp80 @fmax80b(
// CHECK-SAME: x86_fp80 noundef [[A:%.*]], x86_fp80 noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NEXT:    [[TMP2:%.*]] = call nsz x86_fp80 @llvm.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-NO-NANS-LABEL: define dso_local nofpclass(nan) x86_fp80 @fmax80b(
// CHECK-NO-NANS-SAME: x86_fp80 noundef nofpclass(nan) [[A:%.*]], x86_fp80 noundef nofpclass(nan) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-NANS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-NANS-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-NANS-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-NANS-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-NANS-NEXT:    [[TMP2:%.*]] = call nnan nsz x86_fp80 @llvm.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NO-NANS-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-NO-INFS-LABEL: define dso_local nofpclass(inf) x86_fp80 @fmax80b(
// CHECK-NO-INFS-SAME: x86_fp80 noundef nofpclass(inf) [[A:%.*]], x86_fp80 noundef nofpclass(inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-NO-INFS-NEXT:  [[ENTRY:.*:]]
// CHECK-NO-INFS-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-INFS-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-NO-INFS-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-NO-INFS-NEXT:    [[TMP2:%.*]] = call ninf nsz x86_fp80 @llvm.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-NO-INFS-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-FAST-LABEL: define dso_local nofpclass(nan inf) x86_fp80 @fmax80b(
// CHECK-FAST-SAME: x86_fp80 noundef nofpclass(nan inf) [[A:%.*]], x86_fp80 noundef nofpclass(nan inf) [[B:%.*]]) #[[ATTR0]] {
// CHECK-FAST-NEXT:  [[ENTRY:.*:]]
// CHECK-FAST-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-FAST-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-FAST-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA9]]
// CHECK-FAST-NEXT:    [[TMP2:%.*]] = call reassoc nnan ninf nsz arcp afn x86_fp80 @llvm.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]])
// CHECK-FAST-NEXT:    ret x86_fp80 [[TMP2]]
//
// CHECK-STRICT-LABEL: define dso_local x86_fp80 @fmax80b(
// CHECK-STRICT-SAME: x86_fp80 noundef [[A:%.*]], x86_fp80 noundef [[B:%.*]]) #[[ATTR0]] {
// CHECK-STRICT-NEXT:  [[ENTRY:.*:]]
// CHECK-STRICT-NEXT:    [[A_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-STRICT-NEXT:    [[B_ADDR:%.*]] = alloca x86_fp80, align 16
// CHECK-STRICT-NEXT:    store x86_fp80 [[A]], ptr [[A_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    store x86_fp80 [[B]], ptr [[B_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP0:%.*]] = load x86_fp80, ptr [[A_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP1:%.*]] = load x86_fp80, ptr [[B_ADDR]], align 16, !tbaa [[TBAA8]]
// CHECK-STRICT-NEXT:    [[TMP2:%.*]] = call nsz x86_fp80 @llvm.experimental.constrained.maxnum.f80(x86_fp80 [[TMP0]], x86_fp80 [[TMP1]], metadata !"fpexcept.strict") #[[ATTR2]]
// CHECK-STRICT-NEXT:    ret x86_fp80 [[TMP2]]
//
long double fmax80b(long double a, long double b) {
        return __builtin_fmaxl(a, b);
}

//.
// CHECK: [[TBAA2]] = !{[[META3:![0-9]+]], [[META3]], i64 0}
// CHECK: [[META3]] = !{!"float", [[META4:![0-9]+]], i64 0}
// CHECK: [[META4]] = !{!"omnipotent char", [[META5:![0-9]+]], i64 0}
// CHECK: [[META5]] = !{!"Simple C/C++ TBAA"}
// CHECK: [[TBAA6]] = !{[[META4]], [[META4]], i64 0}
// CHECK: [[TBAA7]] = !{[[META8:![0-9]+]], [[META8]], i64 0}
// CHECK: [[META8]] = !{!"double", [[META4]], i64 0}
// CHECK: [[TBAA9]] = !{[[META10:![0-9]+]], [[META10]], i64 0}
// CHECK: [[META10]] = !{!"long double", [[META4]], i64 0}
//.
// CHECK-NO-NANS: [[TBAA2]] = !{[[META3:![0-9]+]], [[META3]], i64 0}
// CHECK-NO-NANS: [[META3]] = !{!"float", [[META4:![0-9]+]], i64 0}
// CHECK-NO-NANS: [[META4]] = !{!"omnipotent char", [[META5:![0-9]+]], i64 0}
// CHECK-NO-NANS: [[META5]] = !{!"Simple C/C++ TBAA"}
// CHECK-NO-NANS: [[TBAA6]] = !{[[META4]], [[META4]], i64 0}
// CHECK-NO-NANS: [[TBAA7]] = !{[[META8:![0-9]+]], [[META8]], i64 0}
// CHECK-NO-NANS: [[META8]] = !{!"double", [[META4]], i64 0}
// CHECK-NO-NANS: [[TBAA9]] = !{[[META10:![0-9]+]], [[META10]], i64 0}
// CHECK-NO-NANS: [[META10]] = !{!"long double", [[META4]], i64 0}
//.
// CHECK-NO-INFS: [[TBAA2]] = !{[[META3:![0-9]+]], [[META3]], i64 0}
// CHECK-NO-INFS: [[META3]] = !{!"float", [[META4:![0-9]+]], i64 0}
// CHECK-NO-INFS: [[META4]] = !{!"omnipotent char", [[META5:![0-9]+]], i64 0}
// CHECK-NO-INFS: [[META5]] = !{!"Simple C/C++ TBAA"}
// CHECK-NO-INFS: [[TBAA6]] = !{[[META4]], [[META4]], i64 0}
// CHECK-NO-INFS: [[TBAA7]] = !{[[META8:![0-9]+]], [[META8]], i64 0}
// CHECK-NO-INFS: [[META8]] = !{!"double", [[META4]], i64 0}
// CHECK-NO-INFS: [[TBAA9]] = !{[[META10:![0-9]+]], [[META10]], i64 0}
// CHECK-NO-INFS: [[META10]] = !{!"long double", [[META4]], i64 0}
//.
// CHECK-FAST: [[TBAA2]] = !{[[META3:![0-9]+]], [[META3]], i64 0}
// CHECK-FAST: [[META3]] = !{!"float", [[META4:![0-9]+]], i64 0}
// CHECK-FAST: [[META4]] = !{!"omnipotent char", [[META5:![0-9]+]], i64 0}
// CHECK-FAST: [[META5]] = !{!"Simple C/C++ TBAA"}
// CHECK-FAST: [[TBAA6]] = !{[[META4]], [[META4]], i64 0}
// CHECK-FAST: [[TBAA7]] = !{[[META8:![0-9]+]], [[META8]], i64 0}
// CHECK-FAST: [[META8]] = !{!"double", [[META4]], i64 0}
// CHECK-FAST: [[TBAA9]] = !{[[META10:![0-9]+]], [[META10]], i64 0}
// CHECK-FAST: [[META10]] = !{!"long double", [[META4]], i64 0}
//.
// CHECK-STRICT: [[TBAA2]] = !{[[META3:![0-9]+]], [[META3]], i64 0}
// CHECK-STRICT: [[META3]] = !{!"float", [[META4:![0-9]+]], i64 0}
// CHECK-STRICT: [[META4]] = !{!"omnipotent char", [[META5:![0-9]+]], i64 0}
// CHECK-STRICT: [[META5]] = !{!"Simple C/C++ TBAA"}
// CHECK-STRICT: [[TBAA6]] = !{[[META7:![0-9]+]], [[META7]], i64 0}
// CHECK-STRICT: [[META7]] = !{!"double", [[META4]], i64 0}
// CHECK-STRICT: [[TBAA8]] = !{[[META9:![0-9]+]], [[META9]], i64 0}
// CHECK-STRICT: [[META9]] = !{!"long double", [[META4]], i64 0}
//.
