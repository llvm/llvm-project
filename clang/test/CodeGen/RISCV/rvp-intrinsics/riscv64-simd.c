// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple riscv64 -target-feature +experimental-p -emit-llvm %s -o - \
// RUN:     -disable-O0-optnone | opt -S -passes=mem2reg \
// RUN:     | FileCheck %s  -check-prefix=RV64P

#include <riscv_simd.h>

// RV64P-LABEL: @pslli_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pslli.b.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pslli_b(uint64_t rs1, int64_t rs2) {
  return __riscv_pslli_b(rs1, 1);
}

// RV64P-LABEL: @pslli_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pslli.h.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pslli_h(uint64_t rs1, int64_t rs2) {
  return __riscv_pslli_h(rs1, 1);
}

// RV64P-LABEL: @pslli_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pslli.w.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pslli_w(uint64_t rs1, int64_t rs2) {
  return __riscv_pslli_w(rs1, 1);
}

// RV64P-LABEL: @psslai_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psslai.h.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psslai_h(uint64_t rs1, int64_t rs2) {
  return __riscv_psslai_h(rs1, 1);
}

// RV64P-LABEL: @psslai_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psslai.w.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psslai_w(uint64_t rs1, int64_t rs2) {
  return __riscv_psslai_w(rs1, 1);
}

// RV64P-LABEL: @psll_bs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psll.bs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psll_bs(uint64_t rs1, uint64_t rs2) {
  return __riscv_psll_bs(rs1, rs2);
}

// RV64P-LABEL: @psll_hs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psll.hs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psll_hs(uint64_t rs1, uint64_t rs2) {
  return __riscv_psll_hs(rs1, rs2);
}

// RV64P-LABEL: @psll_ws(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psll.ws.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psll_ws(uint64_t rs1, uint64_t rs2) {
  return __riscv_psll_ws(rs1, rs2);
}

// RV64P-LABEL: @padd_bs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.padd.bs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t padd_bs(uint64_t rs1, uint64_t rs2) {
  return __riscv_padd_bs(rs1, rs2);
}

// RV64P-LABEL: @padd_hs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.padd.hs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t padd_hs(uint64_t rs1, uint64_t rs2) {
  return __riscv_padd_hs(rs1, rs2);
}

// RV64P-LABEL: @padd_ws(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.padd.ws.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t padd_ws(uint64_t rs1, uint64_t rs2) {
  return __riscv_padd_ws(rs1, rs2);
}

// RV64P-LABEL: @pusati_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pusati.h.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pusati_h(uint64_t rs1, int64_t rs2) {
  return __riscv_pusati_h(rs1, 1);
}

// RV64P-LABEL: @pusati_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pusati.w.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pusati_w(uint64_t rs1, int64_t rs2) {
  return __riscv_pusati_w(rs1, 1);
}

// RV64P-LABEL: @usati(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.usati.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t usati(uint64_t rs1, int64_t rs2) {
  return __riscv_usati(rs1, 1);
}

// RV64P-LABEL: @psrai_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psrai.b.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psrai_b(uint64_t rs1, int64_t rs2) {
  return __riscv_psrai_b(rs1, 1);
}

// RV64P-LABEL: @psrai_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psrai.h.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psrai_h(uint64_t rs1, int64_t rs2) {
  return __riscv_psrai_h(rs1, 1);
}

// RV64P-LABEL: @psrai_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psrai.w.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psrai_w(uint64_t rs1, int64_t rs2) {
  return __riscv_psrai_w(rs1, 1);
}

// RV64P-LABEL: @psrari_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psrari.h.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psrari_h(uint64_t rs1, int64_t rs2) {
  return __riscv_psrari_h(rs1, 1);
}

// RV64P-LABEL: @psrari_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psrari.w.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psrari_w(uint64_t rs1, int64_t rs2) {
  return __riscv_psrari_w(rs1, 1);
}

// RV64P-LABEL: @srari(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.srari.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t srari(int64_t rs1, int64_t rs2) {
  return __riscv_srari(rs1, 1);
}

// RV64P-LABEL: @psati_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psati.h.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psati_h(uint64_t rs1, int64_t rs2) {
  return __riscv_psati_h(rs1, 1);
}

// RV64P-LABEL: @psati_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psati.w.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psati_w(uint64_t rs1, int64_t rs2) {
  return __riscv_psati_w(rs1, 1);
}

// RV64P-LABEL: @sati(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[CONV_I:%.*]] = sext i32 1 to i64
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.sati.i64.i64(i64 [[RS1:%.*]], i64 [[CONV_I]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t sati(int64_t rs1, int64_t rs2) {
  return __riscv_sati(rs1, 1);
}

// RV64P-LABEL: @psrl_bs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psrl.bs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psrl_bs(uint64_t rs1, uint64_t rs2) {
  return __riscv_psrl_bs(rs1, rs2);
}

// RV64P-LABEL: @psrl_hs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psrl.hs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psrl_hs(uint64_t rs1, uint64_t rs2) {
  return __riscv_psrl_hs(rs1, rs2);
}

// RV64P-LABEL: @psrl_ws(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psrl.ws.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psrl_ws(uint64_t rs1, uint64_t rs2) {
  return __riscv_psrl_ws(rs1, rs2);
}

// RV64P-LABEL: @predsum_bs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.predsum.bs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t predsum_bs(uint64_t rs1, uint64_t rs2) {
  return __riscv_predsum_bs(rs1, rs2);
}

// RV64P-LABEL: @predsum_hs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.predsum.hs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t predsum_hs(uint64_t rs1, uint64_t rs2) {
  return __riscv_predsum_hs(rs1, rs2);
}

// RV64P-LABEL: @predsum_ws(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.predsum.ws.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t predsum_ws(uint64_t rs1, uint64_t rs2) {
  return __riscv_predsum_ws(rs1, rs2);
}

// RV64P-LABEL: @predsumu_bs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.predsumu.bs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t predsumu_bs(uint64_t rs1, uint64_t rs2) {
  return __riscv_predsumu_bs(rs1, rs2);
}

// RV64P-LABEL: @predsumu_hs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.predsumu.hs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t predsumu_hs(uint64_t rs1, uint64_t rs2) {
  return __riscv_predsumu_hs(rs1, rs2);
}

// RV64P-LABEL: @predsumu_ws(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.predsumu.ws.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t predsumu_ws(uint64_t rs1, uint64_t rs2) {
  return __riscv_predsumu_ws(rs1, rs2);
}

// RV64P-LABEL: @psra_bs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psra.bs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psra_bs(uint64_t rs1, uint64_t rs2) {
  return __riscv_psra_bs(rs1, rs2);
}

// RV64P-LABEL: @psra_hs(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psra.hs.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psra_hs(uint64_t rs1, uint64_t rs2) {
  return __riscv_psra_hs(rs1, rs2);
}

// RV64P-LABEL: @psra_ws(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psra.ws.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psra_ws(uint64_t rs1, uint64_t rs2) {
  return __riscv_psra_ws(rs1, rs2);
}

// RV64P-LABEL: @padd_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.padd.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t padd_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_padd_b(rs1, rs2);
}

// RV64P-LABEL: @padd_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.padd.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t padd_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_padd_h(rs1, rs2);
}

// RV64P-LABEL: @padd_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.padd.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t padd_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_padd_w(rs1, rs2);
}

// RV64P-LABEL: @psadd_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psadd.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psadd_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_psadd_b(rs1, rs2);
}

// RV64P-LABEL: @psadd_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psadd.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psadd_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_psadd_h(rs1, rs2);
}

// RV64P-LABEL: @psadd_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psadd.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psadd_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_psadd_w(rs1, rs2);
}

// RV64P-LABEL: @paadd_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.paadd.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t paadd_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_paadd_b(rs1, rs2);
}

// RV64P-LABEL: @paadd_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.paadd.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t paadd_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_paadd_h(rs1, rs2);
}

// RV64P-LABEL: @paadd_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.paadd.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t paadd_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_paadd_w(rs1, rs2);
}

// RV64P-LABEL: @psaddu_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psaddu.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psaddu_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_psaddu_b(rs1, rs2);
}

// RV64P-LABEL: @psaddu_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psaddu.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psaddu_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_psaddu_h(rs1, rs2);
}

// RV64P-LABEL: @psaddu_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psaddu.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psaddu_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_psaddu_w(rs1, rs2);
}

// RV64P-LABEL: @paaddu_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.paaddu.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t paaddu_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_paaddu_b(rs1, rs2);
}

// RV64P-LABEL: @paaddu_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.paaddu.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t paaddu_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_paaddu_h(rs1, rs2);
}

// RV64P-LABEL: @paaddu_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.paaddu.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t paaddu_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_paaddu_w(rs1, rs2);
}

// RV64P-LABEL: @psub_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psub.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psub_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_psub_b(rs1, rs2);
}

// RV64P-LABEL: @psub_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psub.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psub_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_psub_h(rs1, rs2);
}

// RV64P-LABEL: @psub_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psub.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psub_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_psub_w(rs1, rs2);
}

// RV64P-LABEL: @pssub_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssub.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssub_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssub_b(rs1, rs2);
}

// RV64P-LABEL: @pssub_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssub.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssub_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssub_h(rs1, rs2);
}

// RV64P-LABEL: @pssub_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssub.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssub_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssub_w(rs1, rs2);
}

// RV64P-LABEL: @pasub_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pasub.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pasub_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pasub_b(rs1, rs2);
}

// RV64P-LABEL: @pasub_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pasub.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pasub_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pasub_h(rs1, rs2);
}

// RV64P-LABEL: @pasub_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pasub.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pasub_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pasub_w(rs1, rs2);
}

// RV64P-LABEL: @pssubu_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssubu.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssubu_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssubu_b(rs1, rs2);
}

// RV64P-LABEL: @pssubu_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssubu.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssubu_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssubu_h(rs1, rs2);
}

// RV64P-LABEL: @pssubu_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssubu.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssubu_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssubu_w(rs1, rs2);
}

// RV64P-LABEL: @pasubu_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pasubu.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pasubu_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pasubu_b(rs1, rs2);
}

// RV64P-LABEL: @pasubu_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pasubu.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pasubu_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pasubu_h(rs1, rs2);
}

// RV64P-LABEL: @pasubu_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pasubu.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pasubu_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pasubu_w(rs1, rs2);
}

// RV64P-LABEL: @pdif_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pdif.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pdif_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pdif_b(rs1, rs2);
}

// RV64P-LABEL: @pdif_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pdif.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pdif_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pdif_h(rs1, rs2);
}

// RV64P-LABEL: @pdifu_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pdifu.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pdifu_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pdifu_b(rs1, rs2);
}

// RV64P-LABEL: @pdifu_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pdifu.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pdifu_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pdifu_h(rs1, rs2);
}

// RV64P-LABEL: @pmul_h_b01(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmul.h.b01.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmul_h_b01(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmul_h_b01(rs1, rs2);
}

// RV64P-LABEL: @pmul_w_h01(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmul.w.h01.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmul_w_h01(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmul_w_h01(rs1, rs2);
}

// RV64P-LABEL: @pmulu_h_b01(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulu.h.b01.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulu_h_b01(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulu_h_b01(rs1, rs2);
}

// RV64P-LABEL: @pmulu_w_h01(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulu.w.h01.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulu_w_h01(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulu_w_h01(rs1, rs2);
}

// RV64P-LABEL: @mul_w01(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.mul.w01.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t mul_w01(uint64_t rs1, uint64_t rs2) {
  return __riscv_mul_w01(rs1, rs2);
}

// RV64P-LABEL: @mulu_w01(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.mulu.w01.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t mulu_w01(uint64_t rs1, uint64_t rs2) {
  return __riscv_mulu_w01(rs1, rs2);
}

// RV64P-LABEL: @slx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.slx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t slx(uint64_t rs1, uint64_t rs2) {
  return __riscv_slx(rs1, rs2);
}

// RV64P-LABEL: @psh1add_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psh1add.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psh1add_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_psh1add_h(rs1, rs2);
}

// RV64P-LABEL: @psh1add_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psh1add.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psh1add_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_psh1add_w(rs1, rs2);
}

// RV64P-LABEL: @pssh1sadd_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssh1sadd.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssh1sadd_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssh1sadd_h(rs1, rs2);
}

// RV64P-LABEL: @pssh1sadd_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssh1sadd.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssh1sadd_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssh1sadd_w(rs1, rs2);
}

// RV64P-LABEL: @unzip8p(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.unzip8p.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t unzip8p(int64_t rs1, int64_t rs2) {
  return __riscv_unzip8p(rs1, rs2);
}

// RV64P-LABEL: @unzip16p(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.unzip16p.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t unzip16p(int64_t rs1, int64_t rs2) {
  return __riscv_unzip16p(rs1, rs2);
}

// RV64P-LABEL: @unzip8hp(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.unzip8hp.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t unzip8hp(int64_t rs1, int64_t rs2) {
  return __riscv_unzip8hp(rs1, rs2);
}

// RV64P-LABEL: @unzip16hp(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.unzip16hp.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t unzip16hp(int64_t rs1, int64_t rs2) {
  return __riscv_unzip16hp(rs1, rs2);
}

// RV64P-LABEL: @zip8p(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.zip8p.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t zip8p(int64_t rs1, int64_t rs2) {
  return __riscv_zip8p(rs1, rs2);
}

// RV64P-LABEL: @zip16p(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.zip16p.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t zip16p(int64_t rs1, int64_t rs2) {
  return __riscv_zip16p(rs1, rs2);
}

// RV64P-LABEL: @zip8hp(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.zip8hp.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t zip8hp(int64_t rs1, int64_t rs2) {
  return __riscv_zip8hp(rs1, rs2);
}

// RV64P-LABEL: @zip16hp(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.zip16hp.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
int64_t zip16hp(int64_t rs1, int64_t rs2) {
  return __riscv_zip16hp(rs1, rs2);
}

// RV64P-LABEL: @pmul_h_b00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmul.h.b00.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmul_h_b00(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmul_h_b00(rs1, rs2);
}

// RV64P-LABEL: @pmul_w_h00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmul.w.h00.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmul_w_h00(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmul_w_h00(rs1, rs2);
}

// RV64P-LABEL: @pmul_h_b11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmul.h.b11.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmul_h_b11(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmul_h_b11(rs1, rs2);
}

// RV64P-LABEL: @pmul_w_h11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmul.w.h11.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmul_w_h11(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmul_w_h11(rs1, rs2);
}

// RV64P-LABEL: @pmulu_h_b00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulu.h.b00.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulu_h_b00(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulu_h_b00(rs1, rs2);
}

// RV64P-LABEL: @pmulu_w_h00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulu.w.h00.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulu_w_h00(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulu_w_h00(rs1, rs2);
}

// RV64P-LABEL: @pmulu_h_b11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulu.h.b11.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulu_h_b11(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulu_h_b11(rs1, rs2);
}

// RV64P-LABEL: @pmulu_w_h11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulu.w.h11.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulu_w_h11(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulu_w_h11(rs1, rs2);
}

// RV64P-LABEL: @pmulsu_h_b00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulsu.h.b00.i64.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulsu_h_b00(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulsu_h_b00(rs1, rs2);
}

// RV64P-LABEL: @pmulsu_w_h00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulsu.w.h00.i64.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulsu_w_h00(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulsu_w_h00(rs1, rs2);
}

// RV64P-LABEL: @pmulsu_h_b11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulsu.h.b11.i64.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulsu_h_b11(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulsu_h_b11(rs1, rs2);
}

// RV64P-LABEL: @pmulsu_w_h11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmulsu.w.h11.i64.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmulsu_w_h11(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmulsu_w_h11(rs1, rs2);
}

// RV64P-LABEL: @mul_w00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.mul.w00.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t mul_w00(uint64_t rs1, uint64_t rs2) {
  return __riscv_mul_w00(rs1, rs2);
}

// RV64P-LABEL: @mul_w11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.mul.w11.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t mul_w11(uint64_t rs1, uint64_t rs2) {
  return __riscv_mul_w11(rs1, rs2);
}

// RV64P-LABEL: @mulu_w00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.mulu.w00.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t mulu_w00(uint64_t rs1, uint64_t rs2) {
  return __riscv_mulu_w00(rs1, rs2);
}

// RV64P-LABEL: @mulu_w11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.mulu.w11.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t mulu_w11(uint64_t rs1, uint64_t rs2) {
  return __riscv_mulu_w11(rs1, rs2);
}

// RV64P-LABEL: @mulsu_w00(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.mulsu.w00.i64.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t mulsu_w00(uint64_t rs1, uint64_t rs2) {
  return __riscv_mulsu_w00(rs1, rs2);
}

// RV64P-LABEL: @mulsu_w11(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.mulsu.w11.i64.i64.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t mulsu_w11(uint64_t rs1, uint64_t rs2) {
  return __riscv_mulsu_w11(rs1, rs2);
}

// RV64P-LABEL: @ppack_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.ppack.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t ppack_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_ppack_h(rs1, rs2);
}

// RV64P-LABEL: @ppack_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.ppack.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t ppack_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_ppack_w(rs1, rs2);
}

// RV64P-LABEL: @ppackbt_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.ppackbt.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t ppackbt_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_ppackbt_h(rs1, rs2);
}

// RV64P-LABEL: @ppackbt_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.ppackbt.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t ppackbt_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_ppackbt_w(rs1, rs2);
}

// RV64P-LABEL: @packbt(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.packbt.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t packbt(uint64_t rs1, uint64_t rs2) {
  return __riscv_packbt(rs1, rs2);
}

// RV64P-LABEL: @ppacktb_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.ppacktb.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t ppacktb_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_ppacktb_h(rs1, rs2);
}

// RV64P-LABEL: @ppacktb_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.ppacktb.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t ppacktb_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_ppacktb_w(rs1, rs2);
}

// RV64P-LABEL: @packtb(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.packtb.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t packtb(uint64_t rs1, uint64_t rs2) {
  return __riscv_packtb(rs1, rs2);
}

// RV64P-LABEL: @ppackt_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.ppackt.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t ppackt_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_ppackt_h(rs1, rs2);
}

// RV64P-LABEL: @ppackt_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.ppackt.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t ppackt_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_ppackt_w(rs1, rs2);
}

// RV64P-LABEL: @packt(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.packt.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t packt(uint64_t rs1, uint64_t rs2) {
  return __riscv_packt(rs1, rs2);
}

// RV64P-LABEL: @pas_hx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pas.hx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pas_hx(uint64_t rs1, uint64_t rs2) {
  return __riscv_pas_hx(rs1, rs2);
}

// RV64P-LABEL: @pas_wx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pas.wx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pas_wx(uint64_t rs1, uint64_t rs2) {
  return __riscv_pas_wx(rs1, rs2);
}

// RV64P-LABEL: @psa_hx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psa.hx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psa_hx(uint64_t rs1, uint64_t rs2) {
  return __riscv_psa_hx(rs1, rs2);
}

// RV64P-LABEL: @psa_wx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psa.wx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psa_wx(uint64_t rs1, uint64_t rs2) {
  return __riscv_psa_wx(rs1, rs2);
}

// RV64P-LABEL: @psas_hx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psas.hx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psas_hx(uint64_t rs1, uint64_t rs2) {
  return __riscv_psas_hx(rs1, rs2);
}

// RV64P-LABEL: @psas_wx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.psas.wx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t psas_wx(uint64_t rs1, uint64_t rs2) {
  return __riscv_psas_wx(rs1, rs2);
}

// RV64P-LABEL: @pssa_hx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssa.hx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssa_hx(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssa_hx(rs1, rs2);
}

// RV64P-LABEL: @pssa_wx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pssa.wx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pssa_wx(uint64_t rs1, uint64_t rs2) {
  return __riscv_pssa_wx(rs1, rs2);
}

// RV64P-LABEL: @paas_hx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.paas.hx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t paas_hx(uint64_t rs1, uint64_t rs2) {
  return __riscv_paas_hx(rs1, rs2);
}

// RV64P-LABEL: @paas_wx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.paas.wx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t paas_wx(uint64_t rs1, uint64_t rs2) {
  return __riscv_paas_wx(rs1, rs2);
}

// RV64P-LABEL: @pasa_hx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pasa.hx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pasa_hx(uint64_t rs1, uint64_t rs2) {
  return __riscv_pasa_hx(rs1, rs2);
}

// RV64P-LABEL: @pasa_wx(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pasa.wx.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pasa_wx(uint64_t rs1, uint64_t rs2) {
  return __riscv_pasa_wx(rs1, rs2);
}

// RV64P-LABEL: @pmseq_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmseq.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmseq_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmseq_b(rs1, rs2);
}

// RV64P-LABEL: @pmseq_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmseq.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmseq_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmseq_h(rs1, rs2);
}

// RV64P-LABEL: @pmseq_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmseq.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmseq_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmseq_w(rs1, rs2);
}

// RV64P-LABEL: @pmslt_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmslt.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmslt_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmslt_b(rs1, rs2);
}

// RV64P-LABEL: @pmslt_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmslt.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmslt_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmslt_h(rs1, rs2);
}

// RV64P-LABEL: @pmslt_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmslt.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmslt_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmslt_w(rs1, rs2);
}

// RV64P-LABEL: @pmsltu_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmsltu.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmsltu_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmsltu_b(rs1, rs2);
}

// RV64P-LABEL: @pmsltu_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmsltu.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmsltu_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmsltu_h(rs1, rs2);
}

// RV64P-LABEL: @pmsltu_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmsltu.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmsltu_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmsltu_w(rs1, rs2);
}

// RV64P-LABEL: @pmin_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmin.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmin_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmin_b(rs1, rs2);
}

// RV64P-LABEL: @pmin_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmin.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmin_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmin_h(rs1, rs2);
}

// RV64P-LABEL: @pmin_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmin.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmin_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmin_w(rs1, rs2);
}

// RV64P-LABEL: @pminu_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pminu.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pminu_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pminu_b(rs1, rs2);
}

// RV64P-LABEL: @pminu_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pminu.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pminu_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pminu_h(rs1, rs2);
}

// RV64P-LABEL: @pminu_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pminu.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pminu_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pminu_w(rs1, rs2);
}

// RV64P-LABEL: @pmax_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmax.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmax_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmax_b(rs1, rs2);
}

// RV64P-LABEL: @pmax_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmax.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmax_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmax_h(rs1, rs2);
}

// RV64P-LABEL: @pmax_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmax.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmax_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmax_w(rs1, rs2);
}

// RV64P-LABEL: @pmaxu_b(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmaxu.b.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmaxu_b(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmaxu_b(rs1, rs2);
}

// RV64P-LABEL: @pmaxu_h(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmaxu.h.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmaxu_h(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmaxu_h(rs1, rs2);
}

// RV64P-LABEL: @pmaxu_w(
// RV64P-NEXT:  entry:
// RV64P-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.pmaxu.w.i64(i64 [[RS1:%.*]], i64 [[RS2:%.*]])
// RV64P-NEXT:    ret i64 [[TMP0]]
//
uint64_t pmaxu_w(uint64_t rs1, uint64_t rs2) {
  return __riscv_pmaxu_w(rs1, rs2);
}
