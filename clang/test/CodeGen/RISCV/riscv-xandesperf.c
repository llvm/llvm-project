// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple riscv32 -target-feature +xandesperf -emit-llvm %s -o - \
// RUN:     | FileCheck %s --check-prefix=CHECK-RV32
// RUN: %clang_cc1 -triple riscv64 -target-feature +xandesperf -emit-llvm %s -o - \
// RUN:     | FileCheck %s --check-prefix=CHECK-RV64

// CHECK-RV32-LABEL: @test_ffb(
// CHECK-RV32-NEXT:  entry:
// CHECK-RV32-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-RV32-NEXT:    [[B_ADDR:%.*]] = alloca i32, align 4
// CHECK-RV32-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-RV32-NEXT:    store i32 [[B:%.*]], ptr [[B_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP2:%.*]] = call i32 @llvm.riscv.nds.ffb.i32(i32 [[TMP0]], i32 [[TMP1]])
// CHECK-RV32-NEXT:    ret i32 [[TMP2]]
//
// CHECK-RV64-LABEL: @test_ffb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[A_ADDR:%.*]] = alloca i64, align 8
// CHECK-RV64-NEXT:    [[B_ADDR:%.*]] = alloca i64, align 8
// CHECK-RV64-NEXT:    store i64 [[A:%.*]], ptr [[A_ADDR]], align 8
// CHECK-RV64-NEXT:    store i64 [[B:%.*]], ptr [[B_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = load i64, ptr [[A_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[B_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP2:%.*]] = call i64 @llvm.riscv.nds.ffb.i64(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP2]]
//
long test_ffb(unsigned long a, unsigned long b) {
  return __builtin_riscv_nds_ffb(a, b);
}

// CHECK-RV32-LABEL: @test_ffzmism(
// CHECK-RV32-NEXT:  entry:
// CHECK-RV32-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-RV32-NEXT:    [[B_ADDR:%.*]] = alloca i32, align 4
// CHECK-RV32-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-RV32-NEXT:    store i32 [[B:%.*]], ptr [[B_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP2:%.*]] = call i32 @llvm.riscv.nds.ffzmism.i32(i32 [[TMP0]], i32 [[TMP1]])
// CHECK-RV32-NEXT:    ret i32 [[TMP2]]
//
// CHECK-RV64-LABEL: @test_ffzmism(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[A_ADDR:%.*]] = alloca i64, align 8
// CHECK-RV64-NEXT:    [[B_ADDR:%.*]] = alloca i64, align 8
// CHECK-RV64-NEXT:    store i64 [[A:%.*]], ptr [[A_ADDR]], align 8
// CHECK-RV64-NEXT:    store i64 [[B:%.*]], ptr [[B_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = load i64, ptr [[A_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[B_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP2:%.*]] = call i64 @llvm.riscv.nds.ffzmism.i64(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP2]]
//
long test_ffzmism(unsigned long a, unsigned long b) {
  return __builtin_riscv_nds_ffzmism(a, b);
}

// CHECK-RV32-LABEL: @test_ffmism(
// CHECK-RV32-NEXT:  entry:
// CHECK-RV32-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-RV32-NEXT:    [[B_ADDR:%.*]] = alloca i32, align 4
// CHECK-RV32-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-RV32-NEXT:    store i32 [[B:%.*]], ptr [[B_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP2:%.*]] = call i32 @llvm.riscv.nds.ffmism.i32(i32 [[TMP0]], i32 [[TMP1]])
// CHECK-RV32-NEXT:    ret i32 [[TMP2]]
//
// CHECK-RV64-LABEL: @test_ffmism(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[A_ADDR:%.*]] = alloca i64, align 8
// CHECK-RV64-NEXT:    [[B_ADDR:%.*]] = alloca i64, align 8
// CHECK-RV64-NEXT:    store i64 [[A:%.*]], ptr [[A_ADDR]], align 8
// CHECK-RV64-NEXT:    store i64 [[B:%.*]], ptr [[B_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = load i64, ptr [[A_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[B_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP2:%.*]] = call i64 @llvm.riscv.nds.ffmism.i64(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP2]]
//
long test_ffmism(unsigned long a, unsigned long b) {
  return __builtin_riscv_nds_ffmism(a, b);
}

// CHECK-RV32-LABEL: @test_flmism(
// CHECK-RV32-NEXT:  entry:
// CHECK-RV32-NEXT:    [[A_ADDR:%.*]] = alloca i32, align 4
// CHECK-RV32-NEXT:    [[B_ADDR:%.*]] = alloca i32, align 4
// CHECK-RV32-NEXT:    store i32 [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-RV32-NEXT:    store i32 [[B:%.*]], ptr [[B_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP0:%.*]] = load i32, ptr [[A_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B_ADDR]], align 4
// CHECK-RV32-NEXT:    [[TMP2:%.*]] = call i32 @llvm.riscv.nds.flmism.i32(i32 [[TMP0]], i32 [[TMP1]])
// CHECK-RV32-NEXT:    ret i32 [[TMP2]]
//
// CHECK-RV64-LABEL: @test_flmism(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[A_ADDR:%.*]] = alloca i64, align 8
// CHECK-RV64-NEXT:    [[B_ADDR:%.*]] = alloca i64, align 8
// CHECK-RV64-NEXT:    store i64 [[A:%.*]], ptr [[A_ADDR]], align 8
// CHECK-RV64-NEXT:    store i64 [[B:%.*]], ptr [[B_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = load i64, ptr [[A_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[B_ADDR]], align 8
// CHECK-RV64-NEXT:    [[TMP2:%.*]] = call i64 @llvm.riscv.nds.flmism.i64(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP2]]
//
long test_flmism(unsigned long a, unsigned long b) {
  return __builtin_riscv_nds_flmism(a, b);
}
