// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 4
// REQUIRES: riscv-registered-target
// RUN: %clang_cc1 -triple riscv64 -target-feature +xsfmmbase \
// RUN:   -target-feature +zvfhmin -target-feature +zvfbfmin \
// RUN:   -target-feature +zve64d \
// RUN:   -disable-O0-optnone -emit-llvm %s -o - | \
// RUN:   opt -S -passes=mem2reg | FileCheck --check-prefix=CHECK-RV64 %s

#include <sifive_vector.h>

// CHECK-RV64-LABEL: define dso_local <vscale x 32 x bfloat> @test_sf_vtmv_v_t_bf16m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 32 x bfloat> @llvm.riscv.sf.vtmv.v.t.nxv32bf16.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 32 x bfloat> [[TMP0]]
//
vbfloat16m8_t test_sf_vtmv_v_t_bf16m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_bf16m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 32 x half> @test_sf_vtmv_v_t_f16m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 32 x half> @llvm.riscv.sf.vtmv.v.t.nxv32f16.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 32 x half> [[TMP0]]
//
vfloat16m8_t test_sf_vtmv_v_t_f16m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_f16m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 16 x float> @test_sf_vtmv_v_t_f32m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 16 x float> @llvm.riscv.sf.vtmv.v.t.nxv16f32.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 16 x float> [[TMP0]]
//
vfloat32m8_t test_sf_vtmv_v_t_f32m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_f32m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 8 x double> @test_sf_vtmv_v_t_f64m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x double> @llvm.riscv.sf.vtmv.v.t.nxv8f64.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 8 x double> [[TMP0]]
//
vfloat64m8_t test_sf_vtmv_v_t_f64m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_f64m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 64 x i8> @test_sf_vtmv_v_t_i8m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 64 x i8> @llvm.riscv.sf.vtmv.v.t.nxv64i8.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 64 x i8> [[TMP0]]
//
vint8m8_t test_sf_vtmv_v_t_i8m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_i8m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 32 x i16> @test_sf_vtmv_v_t_i16m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 32 x i16> @llvm.riscv.sf.vtmv.v.t.nxv32i16.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
vint16m8_t test_sf_vtmv_v_t_i16m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_i16m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 16 x i32> @test_sf_vtmv_v_t_i32m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 16 x i32> @llvm.riscv.sf.vtmv.v.t.nxv16i32.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
vint32m8_t test_sf_vtmv_v_t_i32m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_i32m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 8 x i64> @test_sf_vtmv_v_t_i64m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x i64> @llvm.riscv.sf.vtmv.v.t.nxv8i64.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
vint64m8_t test_sf_vtmv_v_t_i64m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_i64m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 64 x i8> @test_sf_vtmv_v_t_u8m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 64 x i8> @llvm.riscv.sf.vtmv.v.t.nxv64i8.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 64 x i8> [[TMP0]]
//
vuint8m8_t test_sf_vtmv_v_t_u8m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_u8m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 32 x i16> @test_sf_vtmv_v_t_u16m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 32 x i16> @llvm.riscv.sf.vtmv.v.t.nxv32i16.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 32 x i16> [[TMP0]]
//
vuint16m8_t test_sf_vtmv_v_t_u16m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_u16m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 16 x i32> @test_sf_vtmv_v_t_u32m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 16 x i32> @llvm.riscv.sf.vtmv.v.t.nxv16i32.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 16 x i32> [[TMP0]]
//
vuint32m8_t test_sf_vtmv_v_t_u32m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_u32m8(tss, vl);
}

// CHECK-RV64-LABEL: define dso_local <vscale x 8 x i64> @test_sf_vtmv_v_t_u64m8(
// CHECK-RV64-SAME: i64 noundef [[TSS:%.*]], i64 noundef [[VL:%.*]]) #[[ATTR0]] {
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = call <vscale x 8 x i64> @llvm.riscv.sf.vtmv.v.t.nxv8i64.i64(i64 [[TSS]], i64 [[VL]])
// CHECK-RV64-NEXT:    ret <vscale x 8 x i64> [[TMP0]]
//
vuint64m8_t test_sf_vtmv_v_t_u64m8(size_t tss, size_t vl) {
  return __riscv_sf_vtmv_v_t_u64m8(tss, vl);
}

