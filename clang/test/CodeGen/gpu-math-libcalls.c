// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// RUN: %clang_cc1 -triple amdgcn-amd-amdhsa %s -emit-llvm -o - | FileCheck %s --check-prefix AMDGPU
// RUN: %clang_cc1 -triple nvptx64-nvidia-cuda %s -emit-llvm -o - | FileCheck %s --check-prefix NVPTX

double ceil(double);
float ceilf(float);
double copysign(double, double);
float copysignf(float, float);
double cos(double);
float cosf(float);
float coshf(float);
double exp(double);
double exp2(double);
float exp2f(float);
double exp10(double);
float exp10f(float);
float expf(float);
double fabs(double);
float fabsf(float);
double floor(double);
float floorf(float);
double fma(double, double, double);
float fmaf(float, float, float);
double fmax(double, double);
float fmaxf(float, float);
double fmin(double, double);
float fminf(float, float);
double fmod(double, double);
float fmodf(float, float);
double ldexp(double, int);
float ldexpf(float, int);
long long llround(double);
long long llroundf(float);
double log(double);
double log10(double);
float log10f(float);
double log2(double);
float log2f(float);
float logf(float);
long lrint(double);
long lrintf(float);
long lround(double);
long lroundf(float);
double nearbyint(double);
float nearbyintf(float);
double pow(double, double);
float powf(float, float);
double rint(double);
float rintf(float);
double round(double);
float roundf(float);
double roundeven(double);
float roundevenf(float);
double sin(double);
float sinf(float);
double sqrt(double);
float sqrtf(float);
double tan(double);
float tanf(float);
float tanhf(float);
double trunc(double);
float truncf(float);

// AMDGPU-LABEL: define dso_local void @ceil_test(
// AMDGPU-SAME: ) #[[ATTR0:[0-9]+]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @ceil(double noundef 0.000000e+00) #[[ATTR4:[0-9]+]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @ceilf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.ceil.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.ceil.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.ceil.f16(half 0xH0000)
// AMDGPU-NEXT:    [[TMP3:%.*]] = call double @llvm.ceil.f64(double 0.000000e+00)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @ceil_test(
// NVPTX-SAME: ) #[[ATTR0:[0-9]+]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @ceil(double noundef 0.000000e+00) #[[ATTR4:[0-9]+]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @ceilf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.ceil.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.ceil.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.ceil.f16(half 0xH0000)
// NVPTX-NEXT:    [[TMP3:%.*]] = call double @llvm.ceil.f64(double 0.000000e+00)
// NVPTX-NEXT:    ret void
//
void ceil_test(void) {
  (void)ceil(0.0);
  (void)ceilf(0.f);
  (void)__builtin_ceil(0.);
  (void)__builtin_ceilf(0.f);
  (void)__builtin_ceilf16((_Float16)0.);
  (void)__builtin_ceill(0.);
}

// AMDGPU-LABEL: define dso_local void @copysign_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @copysign(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @copysignf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call half @llvm.copysign.f16(half 0xH0000, half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @copysign_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @copysign(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @copysignf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call half @llvm.copysign.f16(half 0xH0000, half 0xH0000)
// NVPTX-NEXT:    ret void
//
void copysign_test(void) {
  (void)copysign(0., 0.);
  (void)copysignf(0.f, 0.f);
  (void)__builtin_copysign(0., 0.);
  (void)__builtin_copysignf(0.f, 0.f);
  (void)__builtin_copysignf16(0., 0.);
}

// AMDGPU-LABEL: define dso_local void @cos_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @cos(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @cosf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.cos.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.cos.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.cos.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @cos_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @cos(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @cosf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.cos.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.cos.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.cos.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void cos_test(void) {
  (void)cos(0.);
  (void)cosf(0.f);
  (void)__builtin_cos(0.);
  (void)__builtin_cosf(0.f);
  (void)__builtin_cosf16(0.);
}

// AMDGPU-LABEL: define dso_local void @exp_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @exp(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @expf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.exp.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.exp.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.exp.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @exp_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @exp(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @expf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.exp.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.exp.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.exp.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void exp_test(void) {
  (void)exp(0.);
  (void)expf(0.f);
  (void)__builtin_exp(0.);
  (void)__builtin_expf(0.f);
  (void)__builtin_expf16(0.);
}

// AMDGPU-LABEL: define dso_local void @exp2_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @exp2(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @exp2f(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.exp2.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.exp2.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.exp2.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @exp2_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @exp2(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @exp2f(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.exp2.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.exp2.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.exp2.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void exp2_test(void) {
  (void)exp2(0.);
  (void)exp2f(0.f);
  (void)__builtin_exp2(0.);
  (void)__builtin_exp2f(0.f);
  (void)__builtin_exp2f16(0.);
}

// AMDGPU-LABEL: define dso_local void @exp10_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @exp10(double noundef 0.000000e+00)
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @exp10f(float noundef 0.000000e+00)
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.exp10.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.exp10.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.exp10.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @exp10_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @exp10(double noundef 0.000000e+00)
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @exp10f(float noundef 0.000000e+00)
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.exp10.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.exp10.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.exp10.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void exp10_test(void) {
  (void)exp10(0.);
  (void)exp10f(0.f);
  (void)__builtin_exp10(0.);
  (void)__builtin_exp10f(0.f);
  (void)__builtin_exp10f16(0.);
}

// AMDGPU-LABEL: define dso_local void @fabs_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @fabs(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @fabsf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call half @llvm.fabs.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @fabs_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @fabs(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @fabsf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call half @llvm.fabs.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void fabs_test(void) {
  (void)fabs(0.);
  (void)fabsf(0.f);
  (void)__builtin_fabs(0.);
  (void)__builtin_fabsf(0.f);
  (void)__builtin_fabsf16(0.);
}

// AMDGPU-LABEL: define dso_local void @floor_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @floor(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @floorf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.floor.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.floor.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.floor.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @floor_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @floor(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @floorf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.floor.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.floor.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.floor.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void floor_test(void) {
  (void)floor(0.);
  (void)floorf(0.f);
  (void)__builtin_floor(0.);
  (void)__builtin_floorf(0.f);
  (void)__builtin_floorf16(0.);
}

// AMDGPU-LABEL: define dso_local void @fma_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @fma(double noundef 0.000000e+00, double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @fmaf(float noundef 0.000000e+00, float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.fma.f64(double 0.000000e+00, double 0.000000e+00, double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.fma.f32(float 0.000000e+00, float 0.000000e+00, float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.fma.f16(half 0xH0000, half 0xH0000, half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @fma_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @fma(double noundef 0.000000e+00, double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @fmaf(float noundef 0.000000e+00, float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.fma.f64(double 0.000000e+00, double 0.000000e+00, double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.fma.f32(float 0.000000e+00, float 0.000000e+00, float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.fma.f16(half 0xH0000, half 0xH0000, half 0xH0000)
// NVPTX-NEXT:    ret void
//
void fma_test(void) {
  (void)fma(0., 0., 0.);
  (void)fmaf(0.f, 0.f, 0.f);
  (void)__builtin_fma(0., 0., 0.);
  (void)__builtin_fmaf(0.f, 0.f, 0.f);
  (void)__builtin_fmaf16(0., 0., 0.);
}

// AMDGPU-LABEL: define dso_local void @fmax_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @fmax(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @fmaxf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @fmax_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @fmax(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @fmaxf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    ret void
//
void fmax_test(void) {
  (void)fmax(0., 0.);
  (void)fmaxf(0.f, 0.f);
  (void)__builtin_fmax(0., 0.);
  (void)__builtin_fmaxf(0.f, 0.f);
  (void)__builtin_fmaxf16(0., 0.);
}

// AMDGPU-LABEL: define dso_local void @fmin_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @fmin(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @fminf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @fmin_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @fmin(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @fminf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    ret void
//
void fmin_test(void) {
  (void)fmin(0., 0.);
  (void)fminf(0.f, 0.f);
  (void)__builtin_fmin(0., 0.);
  (void)__builtin_fminf(0.f, 0.f);
  (void)__builtin_fminf16(0., 0.);
}

// AMDGPU-LABEL: define dso_local void @fmod_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @fmod(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @fmodf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @fmod_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @fmod(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @fmodf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    ret void
//
void fmod_test(void) {
  (void)fmod(0., 0.);
  (void)fmodf(0.f, 0.f);
  (void)__builtin_fmod(0., 0.);
  (void)__builtin_fmodf(0.f, 0.f);
  (void)__builtin_fmodf16(0., 0.);
}

// AMDGPU-LABEL: define dso_local void @log_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @log(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @logf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.log.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.log.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.log.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @log_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @log(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @logf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.log.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.log.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.log.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void log_test(void) {
  (void)log(0.);
  (void)logf(0.f);
  (void)__builtin_log(0.);
  (void)__builtin_logf(0.f);
  (void)__builtin_logf16(0.);
}

// AMDGPU-LABEL: define dso_local void @log10_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @log10(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @log10f(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.log10.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.log10.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.log10.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @log10_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @log10(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @log10f(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.log10.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.log10.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.log10.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void log10_test(void) {
  (void)log10(0.);
  (void)log10f(0.f);
  (void)__builtin_log10(0.);
  (void)__builtin_log10f(0.f);
  (void)__builtin_log10f16(0.);
}

// AMDGPU-LABEL: define dso_local void @log2_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @log2(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @log2f(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.log2.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.log2.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.log2.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @log2_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @log2(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @log2f(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.log2.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.log2.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.log2.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void log2_test(void) {
  (void)log2(0.);
  (void)log2f(0.f);
  (void)__builtin_log2(0.);
  (void)__builtin_log2f(0.f);
  (void)__builtin_log2f16(0.);
}

// AMDGPU-LABEL: define dso_local void @nearbyint_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @nearbyint(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @nearbyintf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.nearbyint.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.nearbyint.f32(float 0.000000e+00)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @nearbyint_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @nearbyint(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @nearbyintf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.nearbyint.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.nearbyint.f32(float 0.000000e+00)
// NVPTX-NEXT:    ret void
//
void nearbyint_test(void) {
  (void)nearbyint(0.);
  (void)nearbyintf(0.f);
  (void)__builtin_nearbyint(0.);
  (void)__builtin_nearbyintf(0.f);
}

// AMDGPU-LABEL: define dso_local void @pow_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @pow(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @powf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.pow.f64(double 0.000000e+00, double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.pow.f32(float 0.000000e+00, float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.pow.f16(half 0xH0000, half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @pow_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @pow(double noundef 0.000000e+00, double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @powf(float noundef 0.000000e+00, float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.pow.f64(double 0.000000e+00, double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.pow.f32(float 0.000000e+00, float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.pow.f16(half 0xH0000, half 0xH0000)
// NVPTX-NEXT:    ret void
//
void pow_test(void) {
  (void)pow(0., 0.);
  (void)powf(0.f, 0.f);
  (void)__builtin_pow(0., 0.);
  (void)__builtin_powf(0.f, 0.f);
  (void)__builtin_powf16(0., 0.);
}

// AMDGPU-LABEL: define dso_local void @rint_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @rint(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @rintf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.rint.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.rint.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.rint.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @rint_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @rint(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @rintf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.rint.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.rint.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.rint.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void rint_test(void) {
  (void)rint(0.);
  (void)rintf(0.f);
  (void)__builtin_rint(0.);
  (void)__builtin_rintf(0.f);
  (void)__builtin_rintf16(0.);
}

// AMDGPU-LABEL: define dso_local void @round_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @round(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @roundf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.round.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.round.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.round.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @round_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @round(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @roundf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.round.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.round.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.round.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void round_test(void) {
  (void)round(0.);
  (void)roundf(0.f);
  (void)__builtin_round(0.);
  (void)__builtin_roundf(0.f);
  (void)__builtin_roundf16(0.);
}

// AMDGPU-LABEL: define dso_local void @roundeven_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @roundeven(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @roundevenf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.roundeven.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.roundeven.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.roundeven.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @roundeven_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @roundeven(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @roundevenf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.roundeven.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.roundeven.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.roundeven.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void roundeven_test(void) {
  (void)roundeven(0.);
  (void)roundevenf(0.f);
  (void)__builtin_roundeven(0.);
  (void)__builtin_roundevenf(0.f);
  (void)__builtin_roundevenf16(0.);
}

// AMDGPU-LABEL: define dso_local void @sin_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @sin(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @sinf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.sin.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.sin.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.sin.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @sin_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @sin(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @sinf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.sin.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.sin.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.sin.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void sin_test(void) {
  (void)sin(0.);
  (void)sinf(0.f);
  (void)__builtin_sin(0.);
  (void)__builtin_sinf(0.f);
  (void)__builtin_sinf16(0.);
}

// AMDGPU-LABEL: define dso_local void @sqrt_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @sqrt(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @sqrtf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.sqrt.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.sqrt.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.sqrt.f16(half 0xH0000)
// AMDGPU-NEXT:    [[TMP3:%.*]] = call double @llvm.sqrt.f64(double 0.000000e+00)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @sqrt_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @sqrt(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @sqrtf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.sqrt.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.sqrt.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.sqrt.f16(half 0xH0000)
// NVPTX-NEXT:    [[TMP3:%.*]] = call double @llvm.sqrt.f64(double 0.000000e+00)
// NVPTX-NEXT:    ret void
//
void sqrt_test(void) {
  (void)sqrt(0.);
  (void)sqrtf(0.f);
  (void)__builtin_sqrt(0.);
  (void)__builtin_sqrtf(0.f);
  (void)__builtin_sqrtf16(0.);
  (void)__builtin_elementwise_sqrt(0.);
}

// AMDGPU-LABEL: define dso_local void @tan_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @tan(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @tanf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.tan.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.tan.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.tan.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @tan_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @tan(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @tanf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.tan.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.tan.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.tan.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void tan_test(void) {
  (void)tan(0.);
  (void)tanf(0.f);
  (void)__builtin_tan(0.);
  (void)__builtin_tanf(0.f);
  (void)__builtin_tanf16(0.);
}

// AMDGPU-LABEL: define dso_local void @trunc_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @trunc(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @truncf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.trunc.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.trunc.f32(float 0.000000e+00)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.trunc.f16(half 0xH0000)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @trunc_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @trunc(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @truncf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.trunc.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.trunc.f32(float 0.000000e+00)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.trunc.f16(half 0xH0000)
// NVPTX-NEXT:    ret void
//
void trunc_test(void) {
  (void)trunc(0.);
  (void)truncf(0.f);
  (void)__builtin_trunc(0.);
  (void)__builtin_truncf(0.f);
  (void)__builtin_truncf16(0.);
}

// AMDGPU-LABEL: define dso_local void @lround_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call i64 @lround(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call i64 @lroundf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call i64 @llvm.lround.i64.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call i64 @llvm.lround.i64.f32(float 0.000000e+00)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @lround_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call i64 @lround(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call i64 @lroundf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call i64 @llvm.lround.i64.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call i64 @llvm.lround.i64.f32(float 0.000000e+00)
// NVPTX-NEXT:    ret void
//
void lround_test(void) {
  (void)lround(0.);
  (void)lroundf(0.f);
  (void)__builtin_lround(0.);
  (void)__builtin_lroundf(0.f);
}

// AMDGPU-LABEL: define dso_local void @llround_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call i64 @llround(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call i64 @llroundf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call i64 @llvm.llround.i64.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call i64 @llvm.llround.i64.f32(float 0.000000e+00)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @llround_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call i64 @llround(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call i64 @llroundf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call i64 @llvm.llround.i64.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call i64 @llvm.llround.i64.f32(float 0.000000e+00)
// NVPTX-NEXT:    ret void
//
void llround_test(void) {
  (void)llround(0.);
  (void)llroundf(0.f);
  (void)__builtin_llround(0.);
  (void)__builtin_llroundf(0.f);
}

// AMDGPU-LABEL: define dso_local void @lrint_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call i64 @lrint(double noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call i64 @lrintf(float noundef 0.000000e+00) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call i64 @llvm.lrint.i64.f64(double 0.000000e+00)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call i64 @llvm.lrint.i64.f32(float 0.000000e+00)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @lrint_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call i64 @lrint(double noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call i64 @lrintf(float noundef 0.000000e+00) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call i64 @llvm.lrint.i64.f64(double 0.000000e+00)
// NVPTX-NEXT:    [[TMP1:%.*]] = call i64 @llvm.lrint.i64.f32(float 0.000000e+00)
// NVPTX-NEXT:    ret void
//
void lrint_test(void) {
  (void)lrint(0.);
  (void)lrintf(0.f);
  (void)__builtin_lrint(0.);
  (void)__builtin_lrintf(0.f);
}

// AMDGPU-LABEL: define dso_local void @__builtin_ldexp_test(
// AMDGPU-SAME: ) #[[ATTR0]] {
// AMDGPU-NEXT:  [[ENTRY:.*:]]
// AMDGPU-NEXT:    [[CALL:%.*]] = call double @ldexp(double noundef 0.000000e+00, i32 noundef 0) #[[ATTR4]]
// AMDGPU-NEXT:    [[CALL1:%.*]] = call float @ldexpf(float noundef 0.000000e+00, i32 noundef 0) #[[ATTR4]]
// AMDGPU-NEXT:    [[TMP0:%.*]] = call double @llvm.ldexp.f64.i32(double 0.000000e+00, i32 0)
// AMDGPU-NEXT:    [[TMP1:%.*]] = call float @llvm.ldexp.f32.i32(float 0.000000e+00, i32 0)
// AMDGPU-NEXT:    [[TMP2:%.*]] = call half @llvm.ldexp.f16.i32(half 0xH0000, i32 0)
// AMDGPU-NEXT:    ret void
//
// NVPTX-LABEL: define dso_local void @__builtin_ldexp_test(
// NVPTX-SAME: ) #[[ATTR0]] {
// NVPTX-NEXT:  [[ENTRY:.*:]]
// NVPTX-NEXT:    [[CALL:%.*]] = call double @ldexp(double noundef 0.000000e+00, i32 noundef 0) #[[ATTR4]]
// NVPTX-NEXT:    [[CALL1:%.*]] = call float @ldexpf(float noundef 0.000000e+00, i32 noundef 0) #[[ATTR4]]
// NVPTX-NEXT:    [[TMP0:%.*]] = call double @llvm.ldexp.f64.i32(double 0.000000e+00, i32 0)
// NVPTX-NEXT:    [[TMP1:%.*]] = call float @llvm.ldexp.f32.i32(float 0.000000e+00, i32 0)
// NVPTX-NEXT:    [[TMP2:%.*]] = call half @llvm.ldexp.f16.i32(half 0xH0000, i32 0)
// NVPTX-NEXT:    ret void
//
void __builtin_ldexp_test(void) {
  (void)ldexp(0., 0);
  (void)ldexpf(0.f, 0);
  (void)__builtin_ldexp(0., 0);
  (void)__builtin_ldexpf(0.f, 0);
  (void)__builtin_ldexpf16(0., 0);
}
