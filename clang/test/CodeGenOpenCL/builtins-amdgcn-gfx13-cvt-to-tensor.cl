// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// REQUIRES: amdgpu-registered-target
// RUN: %clang_cc1 -triple amdgcn-unknown-unknown -target-cpu gfx1300 -target-feature +wavefrontsize32 -emit-llvm -o - %s | FileCheck %s --check-prefix=CHECK-GFX1300

typedef float  v4f   __attribute__((ext_vector_type(4)));
typedef half   v2h   __attribute__((ext_vector_type(2)));
typedef half   v4h   __attribute__((ext_vector_type(4)));
typedef half   v8h   __attribute__((ext_vector_type(8)));
typedef __bf16 v2bf16 __attribute__((ext_vector_type(2)));
typedef __bf16 v4bf16 __attribute__((ext_vector_type(4)));
typedef __bf16 v8bf16 __attribute__((ext_vector_type(8)));

typedef int    v2i   __attribute__((ext_vector_type(2)));

#define PIXEL_SHAPE_8X4X8      (0 << 0)
#define PIXEL_SHAPE_4X4X8      (1 << 0)
#define PIXEL_SHAPE_4X4X16     (2 << 0)
#define PIXEL_SHAPE_4X2X16     (3 << 0)




// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_f32_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i4.f32.v4f32(<4 x float> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4:![0-9]+]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_f32_4x2x16(global int* out, v4f acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_f32_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_f16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.i4.f16.double.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8:![0-9]+]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_f16_8x4x8(global v2i* out, v8h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_f16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_f16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i4.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_f16_4x4x8(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_f16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i4.f16.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_f16_4x4x16(global int* out, v8h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_f16_4x4x16(acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_f16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i4.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_f16_4x2x16(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_bf16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.i4.bf16.double.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_bf16_8x4x8(global v2i* out, v8bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_bf16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_bf16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i4.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_bf16_4x4x8(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_bf16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i4.bf16.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_bf16_4x4x16(global int* out, v8bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_bf16_4x4x16(acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i4_bf16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i4.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i4_bf16_4x2x16(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i4_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_f32_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u4.f32.v4f32(<4 x float> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_f32_4x2x16(global int* out, v4f acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_f32_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_f16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.u4.f16.double.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_f16_8x4x8(global v2i* out, v8h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_f16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_f16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u4.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_f16_4x4x8(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_f16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u4.f16.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_f16_4x4x16(global int* out, v8h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_f16_4x4x16(acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_f16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u4.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_f16_4x2x16(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_bf16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.u4.bf16.double.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_bf16_8x4x8(global v2i* out, v8bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_bf16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_bf16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u4.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_bf16_4x4x8(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_bf16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u4.bf16.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_bf16_4x4x16(global int* out, v8bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_bf16_4x4x16(acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u4_bf16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u4.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u4_bf16_4x2x16(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u4_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_f32_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i8.f32.v4f32(<4 x float> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_f32_4x2x16(global int* out, v4f acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i8_f32_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_f16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.i8.f16.double.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_f16_8x4x8(global v2i* out, v8h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i8_f16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_f16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i8.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_f16_4x4x8(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i8_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_f16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i8.f16.scatter2.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { i32, i32 } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store i32 [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i32 } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store i32 [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_f16_4x4x16(global int* out0, global int* out1, v8h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_i8_f16_4x4x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_f16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i8.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_f16_4x2x16(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i8_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_bf16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.i8.bf16.double.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_bf16_8x4x8(global v2i* out, v8bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i8_bf16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_bf16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i8.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_bf16_4x4x8(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i8_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_bf16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i8.bf16.scatter2.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { i32, i32 } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store i32 [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i32 } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store i32 [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_bf16_4x4x16(global int* out0, global int* out1, v8bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_i8_bf16_4x4x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_i8_bf16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.i8.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_i8_bf16_4x2x16(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_i8_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_f32_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u8.f32.v4f32(<4 x float> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_f32_4x2x16(global int* out, v4f acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u8_f32_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_f16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.i8.bf16.double.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_f16_8x4x8(global v2i* out, v8h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u8_f16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_f16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u8.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_f16_4x4x8(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u8_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_f16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u8.f16.scatter2.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { i32, i32 } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store i32 [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i32 } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store i32 [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_f16_4x4x16(global int* out0, global int* out1, v8h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_u8_f16_4x4x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_f16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u8.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_f16_4x2x16(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u8_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_bf16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.u8.bf16.double.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_bf16_8x4x8(global v2i* out, v8bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u8_bf16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_bf16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u8.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_bf16_4x4x8(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u8_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_bf16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u8.bf16.scatter2.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { i32, i32 } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store i32 [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i32 } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store i32 [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_bf16_4x4x16(global int* out0, global int* out1, v8bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_u8_bf16_4x4x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_u8_bf16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.u8.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_u8_bf16_4x2x16(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_u8_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_f32_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.fp8.f32.v4f32(<4 x float> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_f32_4x2x16(global int* out, v4f acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_fp8_f32_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_f16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.fp8.f16.double.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_f16_8x4x8(global v2i* out, v8h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_fp8_f16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_f16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.fp8.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_f16_4x4x8(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_fp8_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_f16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.fp8.f16.scatter2.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { i32, i32 } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store i32 [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i32 } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store i32 [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_f16_4x4x16(global int* out0, global int* out1, v8h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_fp8_f16_4x4x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_f16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.fp8.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_f16_4x2x16(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_fp8_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_bf16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.fp8.bf16.double.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_bf16_8x4x8(global v2i* out, v8bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_fp8_bf16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_bf16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.fp8.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_bf16_4x4x8(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_fp8_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_bf16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.fp8.bf16.scatter2.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { i32, i32 } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store i32 [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i32 } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store i32 [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_bf16_4x4x16(global int* out0, global int* out1, v8bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_fp8_bf16_4x4x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_fp8_bf16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.fp8.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_fp8_bf16_4x2x16(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_fp8_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_f32_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.bf8.f32.v4f32(<4 x float> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_f32_4x2x16(global int* out, v4f acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_bf8_f32_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_f16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.bf8.f16.double.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_f16_8x4x8(global v2i* out, v8h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_bf8_f16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_f16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.bf8.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_f16_4x4x8(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_bf8_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_f16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.bf8.f16.scatter2.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { i32, i32 } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store i32 [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i32 } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store i32 [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_f16_4x4x16(global int* out0, global int* out1, v8h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf8_f16_4x4x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_f16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.bf8.f16.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_f16_4x2x16(global int* out, v4h acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_bf8_f16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_bf16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.amdgcn.cvt.to.tensor.bf8.bf16.double.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    store <2 x i32> [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 8, !tbaa [[TBAA8]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_bf16_8x4x8(global v2i* out, v8bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_bf8_bf16_8x4x8(acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_bf16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.bf8.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_bf16_4x4x8(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_bf8_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_bf16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.bf8.bf16.scatter2.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { i32, i32 } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store i32 [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { i32, i32 } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store i32 [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_bf16_4x4x16(global int* out0, global int* out1, v8bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf8_bf16_4x4x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf8_bf16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.amdgcn.cvt.to.tensor.bf8.bf16.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    store i32 [[TMP0]], ptr addrspace(1) [[OUT:%.*]], align 4, !tbaa [[TBAA4]]
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf8_bf16_4x2x16(global int* out, v4bf16 acc_in, char scale) {
  *out = __builtin_amdgcn_cvt_to_tensor_bf8_bf16_4x4x8_4x2x16(acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}



// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_f32_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.f16.f32.scatter2.v4f32(<4 x float> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_f32_4x2x16(global v2h* out0, global v2h* out1, v4f acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_f32_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_f16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <4 x half>, <4 x half> } @llvm.amdgcn.cvt.to.tensor.f16.f16.scatter2.double.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <4 x half>, <4 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <4 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 8
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <4 x half>, <4 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <4 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 8
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_f16_8x4x8(global v4h* out0, global v4h* out1, v8h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_f16_8x4x8(out0, out1, acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_f16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.f16.f16.scatter2.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_f16_4x4x8(global v2h* out0, global v2h* out1, v4h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_f16_4x4x8_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_f16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x half>, <2 x half>, <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.f16.f16.scatter4.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP3:%.*]] = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } [[TMP0]], 2
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP3]], ptr addrspace(1) [[OUT2:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP4:%.*]] = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } [[TMP0]], 3
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP4]], ptr addrspace(1) [[OUT3:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_f16_4x4x16(global v2h* out0, global v2h* out1, global v2h* out2, global v2h* out3, v8h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_f16_4x4x16(out0, out1, out2, out3, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_f16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.f16.f16.scatter2.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_f16_4x2x16(global v2h* out0, global v2h* out1, v4h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_f16_4x4x8_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_bf16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <4 x half>, <4 x half> } @llvm.amdgcn.cvt.to.tensor.f16.bf16.scatter2.double.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <4 x half>, <4 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <4 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 8
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <4 x half>, <4 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <4 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 8
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_bf16_8x4x8(global v4h* out0, global v4h* out1, v8bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_bf16_8x4x8(out0, out1, acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_bf16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.f16.bf16.scatter2.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_bf16_4x4x8(global v2h* out0, global v2h* out1, v4bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_bf16_4x4x8_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_bf16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x half>, <2 x half>, <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.f16.bf16.scatter4.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP3:%.*]] = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } [[TMP0]], 2
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP3]], ptr addrspace(1) [[OUT2:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP4:%.*]] = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } [[TMP0]], 3
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP4]], ptr addrspace(1) [[OUT3:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_bf16_4x4x16(global v2h* out0, global v2h* out1, global v2h* out2, global v2h* out3, v8bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_bf16_4x4x16(out0, out1, out2, out3, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_f16_bf16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.f16.bf16.scatter2.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x half>, <2 x half> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x half> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_f16_bf16_4x2x16(global v2h* out0, global v2h* out1, v4bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_f16_bf16_4x4x8_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_f32_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.f32.scatter2.v4f32(<4 x float> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_f32_4x2x16(global v2bf16* out0, global v2bf16* out1, v4f acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_f32_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_f16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <4 x bfloat>, <4 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.f16.scatter2.double.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <4 x bfloat>, <4 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <4 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 8
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <4 x bfloat>, <4 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <4 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 8
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_f16_8x4x8(global v4bf16* out0, global v4bf16* out1, v8h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_f16_8x4x8(out0, out1, acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_f16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.f16.scatter2.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_f16_4x4x8(global v2bf16* out0, global v2bf16* out1, v4h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_f16_4x4x8_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_f16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.f16.scatter4.v8f16(<8 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP3:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } [[TMP0]], 2
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP3]], ptr addrspace(1) [[OUT2:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP4:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } [[TMP0]], 3
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP4]], ptr addrspace(1) [[OUT3:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_f16_4x4x16(global v2bf16* out0, global v2bf16* out1, global v2bf16* out2, global v2bf16* out3, v8h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_f16_4x4x16(out0, out1, out2, out3, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_f16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.f16.scatter2.v4f16(<4 x half> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_f16_4x2x16(global v2bf16* out0, global v2bf16* out1, v4h acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_f16_4x4x8_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_bf16_8x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <4 x bfloat>, <4 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.bf16.scatter2.double.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 0, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <4 x bfloat>, <4 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <4 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 8
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <4 x bfloat>, <4 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <4 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 8
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_bf16_8x4x8(global v4bf16* out0, global v4bf16* out1, v8bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_bf16_8x4x8(out0, out1, acc_in, scale, PIXEL_SHAPE_8X4X8, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_bf16_4x4x8(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.bf16.scatter2.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 1, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_bf16_4x4x8(global v2bf16* out0, global v2bf16* out1, v4bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_bf16_4x4x8_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X4X8, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_bf16_4x4x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.bf16.scatter4.v8bf16(<8 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 2, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP3:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } [[TMP0]], 2
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP3]], ptr addrspace(1) [[OUT2:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP4:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } [[TMP0]], 3
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP4]], ptr addrspace(1) [[OUT3:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_bf16_4x4x16(global v2bf16* out0, global v2bf16* out1, global v2bf16* out2, global v2bf16* out3, v8bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_bf16_4x4x16(out0, out1, out2, out3, acc_in, scale, PIXEL_SHAPE_4X4X16, 1);
}


// CHECK-GFX1300-LABEL: @test_amdgcn_cvt_to_tensor_bf16_bf16_4x2x16(
// CHECK-GFX1300-NEXT:  entry:
// CHECK-GFX1300-NEXT:    [[TMP0:%.*]] = tail call { <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.bf16.scatter2.v4bf16(<4 x bfloat> [[ACC_IN:%.*]], i8 [[SCALE:%.*]], i32 3, i1 true)
// CHECK-GFX1300-NEXT:    [[TMP1:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 0
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP1]], ptr addrspace(1) [[OUT0:%.*]], align 4
// CHECK-GFX1300-NEXT:    [[TMP2:%.*]] = extractvalue { <2 x bfloat>, <2 x bfloat> } [[TMP0]], 1
// CHECK-GFX1300-NEXT:    store <2 x bfloat> [[TMP2]], ptr addrspace(1) [[OUT1:%.*]], align 4
// CHECK-GFX1300-NEXT:    ret void
//
void test_amdgcn_cvt_to_tensor_bf16_bf16_4x2x16(global v2bf16* out0, global v2bf16* out1, v4bf16 acc_in, char scale) {
  __builtin_amdgcn_cvt_to_tensor_bf16_bf16_4x4x8_4x2x16(out0, out1, acc_in, scale, PIXEL_SHAPE_4X2X16, 1);
}

