// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --replace-value-regex "!annotation ![0-9]+" "!tbaa ![0-9]+" "!llvm.loop ![0-9]+" "#[0-9]+" --prefix-filecheck-ir-name TMP_

// REQUIRES: x86-registered-target

// RUN: %clang_cc1 -O2 -triple x86_64 -fbounds-safety -fno-bounds-safety-bringup-missing-checks=all -fno-split-cold-code -emit-llvm %s -o - | FileCheck --check-prefix=CHECK %s
// RUN: %clang_cc1 -O2 -triple x86_64 -fbounds-safety -fno-bounds-safety-bringup-missing-checks=all -fno-split-cold-code -x objective-c -fexperimental-bounds-safety-objc -emit-llvm %s -o - | FileCheck --check-prefix=CHECK %s

#include <ptrcheck.h>

// All accesses in the loop at in bounds and can be eliminated.
// CHECK-LABEL: @loop_all_accesses_in_bounds(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP5_NOT:%.*]] = icmp eq i32 [[N:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP5_NOT]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_PREHEADER:%.*]]
// CHECK:       for.body.preheader:
// CHECK-NEXT:    [[TMP0:%.*]] = zext i32 [[N]] to i64
// CHECK-NEXT:    [[TMP1:%.*]] = shl nuw nsw i64 [[TMP0]], 2
// CHECK-NEXT:    tail call void @llvm.memset.p0.i64(ptr align 4 [[DST:%.*]], i8 0, i64 [[TMP1]], i1 false), {{!tbaa ![0-9]+}}
// CHECK-NEXT:    br label [[FOR_COND_CLEANUP]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
//
void loop_all_accesses_in_bounds(int* __counted_by(n) dst, unsigned n) {
  for (int i = 0; i < n; i += 1)
    dst[i] = 0;
}

// CHECK-LABEL: @loop_access_by_dereference(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[N:%.*]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, ptr [[A:%.*]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[CMP6:%.*]] = icmp sgt i32 [[N]], 0
// CHECK-NEXT:    br i1 [[CMP6]], label [[FOR_BODY:%.*]], label [[FOR_COND_CLEANUP:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    [[R_0_LCSSA:%.*]] = phi i32 [ 0, [[ENTRY:%.*]] ], [ [[ADD:%.*]], [[CONT1:%.*]] ]
// CHECK-NEXT:    ret i32 [[R_0_LCSSA]]
// CHECK:       for.body:
// CHECK-NEXT:    [[B_SROA_0_09:%.*]] = phi ptr [ [[BOUND_PTR_ARITH:%.*]], [[CONT1]] ], [ [[A]], [[ENTRY]] ]
// CHECK-NEXT:    [[R_08:%.*]] = phi i32 [ [[ADD]], [[CONT1]] ], [ 0, [[ENTRY]] ]
// CHECK-NEXT:    [[I_07:%.*]] = phi i32 [ [[INC:%.*]], [[CONT1]] ], [ 0, [[ENTRY]] ]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[B_SROA_0_09]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[B_SROA_0_09]], [[A]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP0]], [[TMP1]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT1]], label [[TRAP:%.*]], !prof [[PROF10:![0-9]+]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    [[BOUND_PTR_ARITH]] = getelementptr i8, ptr [[B_SROA_0_09]], i64 4
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[B_SROA_0_09]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ADD]] = add nsw i32 [[TMP2]], [[R_08]]
// CHECK-NEXT:    [[INC]] = add nuw nsw i32 [[I_07]], 1
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i32 [[INC]], [[N]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
int loop_access_by_dereference(int *__counted_by(n) a, int n) {
	int *b = a;
	int r = 0;
	for (int i = 0; i < n; ++i) {
		r += *b++;
	}
	return r;
}

// CHECK-LABEL: @loop_all_accesses_in_bounds_variable_start_1(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP5:%.*]] = icmp ult i32 [[START:%.*]], [[N:%.*]]
// CHECK-NEXT:    br i1 [[CMP5]], label [[FOR_BODY_PREHEADER:%.*]], label [[FOR_COND_CLEANUP:%.*]]
// CHECK:       for.body.preheader:
// CHECK-NEXT:    [[TMP0:%.*]] = zext i32 [[START]] to i64
// CHECK-NEXT:    [[TMP1:%.*]] = shl nuw nsw i64 [[TMP0]], 2
// CHECK-NEXT:    [[SCEVGEP:%.*]] = getelementptr i8, ptr [[DST:%.*]], i64 [[TMP1]]
// CHECK-NEXT:    [[TMP2:%.*]] = xor i32 [[START]], -1
// CHECK-NEXT:    [[TMP3:%.*]] = add i32 [[N]], [[TMP2]]
// CHECK-NEXT:    [[TMP4:%.*]] = zext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[TMP5:%.*]] = shl nuw nsw i64 [[TMP4]], 2
// CHECK-NEXT:    [[TMP6:%.*]] = add nuw nsw i64 [[TMP5]], 4
// CHECK-NEXT:    tail call void @llvm.memset.p0.i64(ptr noundef nonnull align 4 dereferenceable(1) [[SCEVGEP]], i8 0, i64 [[TMP6]], i1 false), {{!tbaa ![0-9]+}}
// CHECK-NEXT:    br label [[FOR_COND_CLEANUP]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
//
void loop_all_accesses_in_bounds_variable_start_1(int* __counted_by(n) dst,
                                                  unsigned n, unsigned start) {
  for (unsigned i = start; i < n; i += 1)
    dst[i] = 0;
}

// CHECK-LABEL: @loop_all_accesses_in_bounds_variable_start_2_add(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[ADD:%.*]] = add i32 [[START:%.*]], 10
// CHECK-NEXT:    [[CMP7:%.*]] = icmp ult i32 [[ADD]], [[N:%.*]]
// CHECK-NEXT:    br i1 [[CMP7]], label [[FOR_BODY_PREHEADER:%.*]], label [[FOR_COND_CLEANUP:%.*]]
// CHECK:       for.body.preheader:
// CHECK-NEXT:    [[TMP0:%.*]] = zext i32 [[ADD]] to i64
// CHECK-NEXT:    [[TMP1:%.*]] = shl nuw nsw i64 [[TMP0]], 2
// CHECK-NEXT:    [[SCEVGEP:%.*]] = getelementptr i8, ptr [[DST:%.*]], i64 [[TMP1]]
// CHECK-NEXT:    [[TMP2:%.*]] = add i32 [[N]], -11
// CHECK-NEXT:    [[TMP3:%.*]] = sub i32 [[TMP2]], [[START]]
// CHECK-NEXT:    [[TMP4:%.*]] = zext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[TMP5:%.*]] = shl nuw nsw i64 [[TMP4]], 2
// CHECK-NEXT:    [[TMP6:%.*]] = add nuw nsw i64 [[TMP5]], 4
// CHECK-NEXT:    tail call void @llvm.memset.p0.i64(ptr noundef nonnull align 4 dereferenceable(1) [[SCEVGEP]], i8 0, i64 [[TMP6]], i1 false), {{!tbaa ![0-9]+}}
// CHECK-NEXT:    br label [[FOR_COND_CLEANUP]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
//
void loop_all_accesses_in_bounds_variable_start_2_add(int* __counted_by(n) dst,
                                                      unsigned n, unsigned start) {
  start = start + 10;
  for (unsigned i = start; i < n; i += 1)
    dst[i] = 0;
}

// CHECK-LABEL: @loop_all_accesses_in_bounds_variable_start_3_modulo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = zext i32 [[N:%.*]] to i64
// CHECK-NEXT:    [[TMP1:%.*]] = urem i32 [[START:%.*]], [[N]]
// CHECK-NEXT:    [[TMP2:%.*]] = zext i32 [[TMP1]] to i64
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[TMP2]], [[ENTRY:%.*]] ], [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ]
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i32, ptr [[DST:%.*]], i64 [[INDVARS_IV]]
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
// CHECK-NEXT:    [[CMP:%.*]] = icmp samesign ult i64 [[INDVARS_IV_NEXT]], [[TMP0]]
// CHECK-NEXT:    br i1 [[CMP]], label [[FOR_BODY]], label [[FOR_COND_CLEANUP:%.*]], {{!llvm.loop ![0-9]+}}
//
void loop_all_accesses_in_bounds_variable_start_3_modulo(int* __counted_by(n) dst,
                                                         unsigned n, unsigned start) {
  start = start % n;
  for (unsigned i = start; i < n; i += 1)
    dst[i] = 0;
}

// CHECK-LABEL: @loop_all_accesses_in_bounds_variable_start_4_div(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DIV:%.*]] = udiv i32 [[START2:%.*]], 10
// CHECK-NEXT:    [[ADD:%.*]] = add i32 [[DIV]], [[START1:%.*]]
// CHECK-NEXT:    [[CMP7:%.*]] = icmp ult i32 [[ADD]], [[N:%.*]]
// CHECK-NEXT:    br i1 [[CMP7]], label [[FOR_BODY_PREHEADER:%.*]], label [[FOR_COND_CLEANUP:%.*]]
// CHECK:       for.body.preheader:
// CHECK-NEXT:    [[TMP0:%.*]] = zext i32 [[ADD]] to i64
// CHECK-NEXT:    [[TMP1:%.*]] = shl nuw nsw i64 [[TMP0]], 2
// CHECK-NEXT:    [[SCEVGEP:%.*]] = getelementptr i8, ptr [[DST:%.*]], i64 [[TMP1]]
// CHECK-NEXT:    [[TMP2:%.*]] = xor i32 [[START1]], -1
// CHECK-NEXT:    [[TMP3:%.*]] = add i32 [[N]], [[TMP2]]
// CHECK-NEXT:    [[TMP4:%.*]] = sub i32 [[TMP3]], [[DIV]]
// CHECK-NEXT:    [[TMP5:%.*]] = zext i32 [[TMP4]] to i64
// CHECK-NEXT:    [[TMP6:%.*]] = shl nuw nsw i64 [[TMP5]], 2
// CHECK-NEXT:    [[TMP7:%.*]] = add nuw nsw i64 [[TMP6]], 4
// CHECK-NEXT:    tail call void @llvm.memset.p0.i64(ptr noundef nonnull align 4 dereferenceable(1) [[SCEVGEP]], i8 0, i64 [[TMP7]], i1 false), {{!tbaa ![0-9]+}}
// CHECK-NEXT:    br label [[FOR_COND_CLEANUP]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
//
void loop_all_accesses_in_bounds_variable_start_4_div(int* __counted_by(n) dst,
                                                      unsigned n, unsigned start1,
                                                      unsigned start2) {
  start1 += (start2 / 10);
  for (unsigned i = start1; i < n; i += 1)
    dst[i] = 0;
}

// CHECK-LABEL: @loop_all_accesses_in_bounds_len_signed(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP5:%.*]] = icmp sgt i32 [[LEN:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP5]], label [[FOR_BODY_PREHEADER:%.*]], label [[FOR_COND_CLEANUP:%.*]]
// CHECK:       for.body.preheader:
// CHECK-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext nneg i32 [[LEN]] to i64
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, [[FOR_BODY_PREHEADER]] ], [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ]
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i32, ptr [[BUF:%.*]], i64 [[INDVARS_IV]]
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP0]], 1
// CHECK-NEXT:    store i32 [[ADD]], ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[WIDE_TRIP_COUNT]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_all_accesses_in_bounds_len_signed(int* __counted_by(len) buf, int len) {
  for (int i = 0; i < len; ++i)
    buf[i] += 1;
}

// CHECK-LABEL: @loop_all_accesses_in_bounds_length_ull(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP6_NOT:%.*]] = icmp eq i64 [[LEN:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP6_NOT]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_LR_PH:%.*]]
// CHECK:       for.body.lr.ph:
// CHECK-NEXT:    [[CMP1:%.*]] = icmp sgt i64 [[LEN]], -1
// CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP1]])
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[I_07:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[INC:%.*]], [[FOR_BODY]] ]
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i32, ptr [[BUF:%.*]], i64 [[I_07]]
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP0]], 1
// CHECK-NEXT:    store i32 [[ADD]], ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[INC]] = add nuw i64 [[I_07]], 1
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INC]], [[LEN]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_all_accesses_in_bounds_length_ull(int* __counted_by(len) buf, unsigned long long len) {
  for (unsigned long long i = 0; i < len; ++i)
    buf[i] += 1;
}

// The lower bound checks can be eliminated, because we know that:
//   1. computing dst + n does not wrap
//   2. i + 1 <= n from loop bound.
//
// 1. and 2. together imply that dst + i + 1 does not wrap, hence dst + i + 1 >= dst is true.

// CHECK-LABEL: @loop_accesses_out_of_bounds_eliminate_lower_check(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP6_NOT:%.*]] = icmp eq i32 [[N:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP6_NOT]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_LR_PH:%.*]]
// CHECK:       for.body.lr.ph:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext i32 [[N]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[DST:%.*]], i64 [[IDX_EXT]]
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[INDVARS_IV_NEXT:%.*]], [[CONT1:%.*]] ]
// CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i32, ptr [[DST]], i64 [[INDVARS_IV_NEXT]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[ARRAYIDX]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP0]], label [[CONT1]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[IDX_EXT]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_accesses_out_of_bounds_eliminate_lower_check(int* __counted_by(n) dst, unsigned n) {
  for (int i = 0; i < n; i += 1)
    dst[i+1] = 0;
}

// CHECK-LABEL: @loop_accesses_out_of_bounds_eliminate_lower_check_len_signed(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP5:%.*]] = icmp sgt i32 [[LEN:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP5]], label [[FOR_BODY_LR_PH:%.*]], label [[FOR_COND_CLEANUP:%.*]]
// CHECK:       for.body.lr.ph:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext nneg i32 [[LEN]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[BUF:%.*]], i64 [[IDX_EXT]]
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[INDVARS_IV_NEXT:%.*]], [[CONT1:%.*]] ]
// CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i32, ptr [[BUF]], i64 [[INDVARS_IV_NEXT]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[ARRAYIDX]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP0]], label [[CONT1]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[IDX_EXT]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_accesses_out_of_bounds_eliminate_lower_check_len_signed(int* __counted_by(len) buf, int len) {
  for (int i = 0; i < len; ++i)
    buf[i+1] = 0;
}

// CHECK-LABEL: @loop_accesses_out_of_bounds_eliminate_lower_check_len_ull(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP6_NOT:%.*]] = icmp eq i64 [[LEN:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP6_NOT]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_LR_PH:%.*]]
// CHECK:       for.body.lr.ph:
// CHECK-NEXT:    [[CMP1:%.*]] = icmp sgt i64 [[LEN]], -1
// CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP1]])
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[BUF:%.*]], i64 [[LEN]]
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[I_07:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[ADD:%.*]], [[CONT2:%.*]] ]
// CHECK-NEXT:    [[ADD]] = add nuw i64 [[I_07]], 1
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i32, ptr [[BUF]], i64 [[ADD]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[ARRAYIDX]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[ARRAYIDX]], [[BUF]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP0]], [[TMP1]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT2]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont2:
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD]], [[LEN]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_accesses_out_of_bounds_eliminate_lower_check_len_ull(int* __counted_by(len) buf, unsigned long long len) {
  for (unsigned long long i = 0; i < len; ++i)
    buf[i+1] = 0;
}

// No checks can be eliminated, as dst + i + 2 may wrap and is out of bounds.
// CHECK-LABEL: @loop_accesses_out_of_bounds_cannot_eliminate_wrap_check(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[INVARIANT_GEP:%.*]] = getelementptr i8, ptr [[DST:%.*]], i64 8
// CHECK-NEXT:    [[CMP6_NOT:%.*]] = icmp eq i32 [[N:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP6_NOT]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_LR_PH:%.*]]
// CHECK:       for.body.lr.ph:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext i32 [[N]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[DST]], i64 [[IDX_EXT]]
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[INDVARS_IV_NEXT:%.*]], [[CONT1:%.*]] ]
// CHECK-NEXT:    [[GEP:%.*]] = getelementptr i32, ptr [[INVARIANT_GEP]], i64 [[INDVARS_IV]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[GEP]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[GEP]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP0]], [[TMP1]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT1]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    store i32 0, ptr [[GEP]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[IDX_EXT]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_accesses_out_of_bounds_cannot_eliminate_wrap_check(int* __counted_by(n) dst, unsigned n) {
  for (int i = 0; i < n; i += 1)
    dst[i+2] = 0;
}

// CHECK-LABEL: @loop_accesses_out_of_bounds_cannot_eliminate_wrap_check_signed_len(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[INVARIANT_GEP:%.*]] = getelementptr i8, ptr [[DST:%.*]], i64 8
// CHECK-NEXT:    [[CMP6:%.*]] = icmp sgt i32 [[N:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP6]], label [[FOR_BODY_LR_PH:%.*]], label [[FOR_COND_CLEANUP:%.*]]
// CHECK:       for.body.lr.ph:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext nneg i32 [[N]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[DST]], i64 [[IDX_EXT]]
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[INDVARS_IV_NEXT:%.*]], [[CONT1:%.*]] ]
// CHECK-NEXT:    [[GEP:%.*]] = getelementptr i32, ptr [[INVARIANT_GEP]], i64 [[INDVARS_IV]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[GEP]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[GEP]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP0]], [[TMP1]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT1]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    store i32 0, ptr [[GEP]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[IDX_EXT]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_accesses_out_of_bounds_cannot_eliminate_wrap_check_signed_len(int* __counted_by(n) dst, int n) {
  for (int i = 0; i < n; i += 1)
    dst[i+2] = 0;
}

// CHECK-LABEL: @loop_accesses_out_of_bounds_cannot_eliminate_wrap_check_ull_len(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[INVARIANT_GEP:%.*]] = getelementptr i8, ptr [[DST:%.*]], i64 8
// CHECK-NEXT:    [[CMP7_NOT:%.*]] = icmp eq i64 [[N:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP7_NOT]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_LR_PH:%.*]]
// CHECK:       for.body.lr.ph:
// CHECK-NEXT:    [[CMP1:%.*]] = icmp sgt i64 [[N]], -1
// CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP1]])
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[DST]], i64 [[N]]
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[I_08:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[ADD3:%.*]], [[CONT2:%.*]] ]
// CHECK-NEXT:    [[GEP:%.*]] = getelementptr i32, ptr [[INVARIANT_GEP]], i64 [[I_08]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[GEP]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[GEP]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP0]], [[TMP1]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT2]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont2:
// CHECK-NEXT:    store i32 0, ptr [[GEP]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ADD3]] = add nuw i64 [[I_08]], 1
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD3]], [[N]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_accesses_out_of_bounds_cannot_eliminate_wrap_check_ull_len(int* __counted_by(n) dst, unsigned long long n) {
  for (unsigned long long i = 0; i < n; i += 1)
    dst[i+2] = 0;
}

// Both lower checks can be eliminated.
// dst + i + 1  >= dst can be eliminated because i + 1 <= n and dst + n does not wrap.
//
// dst + i + 2 >= dst can be eliminated because from the check for dst[i+1] we know:
//   1. dst + n does not wrap.
//   2. dst + i + 1 < dst + n
//
// 1. and 2. together imply dst + i + 1 does not wrap, and dst + i + 2 also
// does not (note the < in 2.). Hence dst + i + 2 >= dst is true.
//
// FIXME: Regressed at the moment, rdar://120485098.
// CHECK-LABEL: @loop_accesses_eliminate_second_lower_check(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[INVARIANT_GEP:%.*]] = getelementptr i8, ptr [[DST:%.*]], i64 8
// CHECK-NEXT:    [[CMP24_NOT:%.*]] = icmp eq i32 [[N:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP24_NOT]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_LR_PH:%.*]]
// CHECK:       for.body.lr.ph:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext i32 [[N]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[DST]], i64 [[IDX_EXT]]
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, [[FOR_BODY_LR_PH]] ], [ [[INDVARS_IV_NEXT:%.*]], [[CONT15:%.*]] ]
// CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i32, ptr [[DST]], i64 [[INDVARS_IV_NEXT]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[ARRAYIDX]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP0]], label [[CONT1:%.*]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[GEP:%.*]] = getelementptr i32, ptr [[INVARIANT_GEP]], i64 [[INDVARS_IV]]
// CHECK-NEXT:    [[TMP1:%.*]] = icmp ult ptr [[GEP]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP2:%.*]] = icmp uge ptr [[GEP]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND17:%.*]] = and i1 [[TMP1]], [[TMP2]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND17]], label [[CONT15]], label [[TRAP]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       cont15:
// CHECK-NEXT:    store i32 0, ptr [[GEP]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[IDX_EXT]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_accesses_eliminate_second_lower_check(int* __counted_by(n) dst, unsigned n) {
  for (int i = 0; i < n; i += 1) {
    dst[i+1] = 0;
    dst[i+2] = 0;
  }
}

// We can eliminate the checks for dst[i+1], because the earlier checks for
// dst[i+2] make them redundant.
// CHECK-LABEL: @loop_accesses_eliminate_later_checks(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext i32 [[N:%.*]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[DST:%.*]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[INVARIANT_GEP:%.*]] = getelementptr i8, ptr [[DST]], i64 8
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond.cleanup:
// CHECK-NEXT:    ret void
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[INDVARS_IV_NEXT:%.*]], [[CONT15:%.*]] ]
// CHECK-NEXT:    [[GEP:%.*]] = getelementptr i32, ptr [[INVARIANT_GEP]], i64 [[INDVARS_IV]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[GEP]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[GEP]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP0]], [[TMP1]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT1:%.*]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    store i32 0, ptr [[GEP]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
// CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr i32, ptr [[DST]], i64 [[INDVARS_IV_NEXT]]
// CHECK-NEXT:    [[TMP2:%.*]] = icmp ult ptr [[ARRAYIDX9]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP3:%.*]] = icmp uge ptr [[ARRAYIDX9]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND17:%.*]] = and i1 [[TMP2]], [[TMP3]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND17]], label [[CONT15]], label [[TRAP]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       cont15:
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX9]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 2000
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
//
void loop_accesses_eliminate_later_checks(int* __counted_by(n) dst, unsigned n) {
  for (int i = 0; i < 2000; i += 1) {
    dst[i+2] = 0;
    dst[i+1] = 0;
  }
}

// The checks for dst[4], dst[3] and dst[2] should be removed, because they are
// redundant after checking dst[5].
// CHECK-LABEL: @elim_consecutive_writes(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext i32 [[N:%.*]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[DST:%.*]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i8, ptr [[DST]], i64 4
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[ARRAYIDX]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[ARRAYIDX]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP1]], [[TMP0]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT1:%.*]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr i8, ptr [[DST]], i64 20
// CHECK-NEXT:    [[TMP2:%.*]] = icmp ult ptr [[ARRAYIDX7]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP3:%.*]] = icmp uge ptr [[ARRAYIDX7]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND50:%.*]] = and i1 [[TMP3]], [[TMP2]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND50]], label [[CONT49:%.*]], label [[TRAP]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       cont49:
// CHECK-NEXT:    [[ARRAYIDX43:%.*]] = getelementptr i8, ptr [[DST]], i64 8
// CHECK-NEXT:    tail call void @llvm.memset.p0.i64(ptr noundef nonnull align 4 dereferenceable(16) [[ARRAYIDX43]], i8 0, i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void elim_consecutive_writes(int* __counted_by(n) dst, unsigned n) {
    dst[1] = 0; // Need to check for wrap and against upper bound.
    dst[5] = 0; // Need to check for wrap and against upper bound.
    dst[4] = 0; // No checks needed.
    dst[3] = 0; // No checks needed.
    dst[2] = 0; // No checks needed.
}

// CHECK-LABEL: @elim_consecutive_writes2(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp ugt i32 [[IDX:%.*]], 3
// CHECK-NEXT:    br i1 [[CMP]], label [[IF_THEN:%.*]], label [[IF_END:%.*]]
// CHECK:       if.then:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext i32 [[N:%.*]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i32, ptr [[DST:%.*]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[IDXPROM:%.*]] = zext i32 [[IDX]] to i64
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr i32, ptr [[DST]], i64 [[IDXPROM]]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[ARRAYIDX]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[ARRAYIDX]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP0]], [[TMP1]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT37:%.*]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont37:
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr i8, ptr [[DST]], i64 16
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX7]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ARRAYIDX19:%.*]] = getelementptr i8, ptr [[DST]], i64 12
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX19]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ARRAYIDX31:%.*]] = getelementptr i8, ptr [[DST]], i64 8
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX31]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ARRAYIDX43:%.*]] = getelementptr i8, ptr [[DST]], i64 20
// CHECK-NEXT:    [[TMP2:%.*]] = icmp ult ptr [[ARRAYIDX43]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP3:%.*]] = icmp uge ptr [[ARRAYIDX43]], [[DST]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND53:%.*]] = and i1 [[TMP3]], [[TMP2]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND53]], label [[CONT49:%.*]], label [[TRAP]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       cont49:
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX43]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    br label [[IF_END]]
// CHECK:       if.end:
// CHECK-NEXT:    ret void
//
void elim_consecutive_writes2(int* __counted_by(n) dst, unsigned n, unsigned idx) {
    if (idx >= 4) {
        dst[idx] = 0; // Need to check for wrap and against upper bound.
        dst[4] = 0; // No checks needed.
        dst[3] = 0; // No checks needed.
        dst[2] = 0; // No checks needed.
        dst[5] = 0; // Need to check against upper bound.
    }
}

// TODO
// CHECK-LABEL: @count_ptr_relations(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[N:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP]], label [[RETURN:%.*]], label [[LAND_RHS:%.*]]
// CHECK:       land.rhs:
// CHECK-NEXT:    [[SUB:%.*]] = add i32 [[N]], -1, {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr i8, ptr [[ARG:%.*]], i64 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext i32 [[N]] to i64
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[SUB]] to i64, {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP0:%.*]] = add nuw nsw i64 [[IDX_EXT]], 4611686018427387903
// CHECK-NEXT:    [[SUB_PTR_DIV:%.*]] = and i64 [[TMP0]], 4611686018427387903
// CHECK-NEXT:    [[CMP27_NOT:%.*]] = icmp samesign ult i64 [[SUB_PTR_DIV]], [[CONV]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[CMP27_NOT]], label [[TRAP:%.*]], label [[CONT59:%.*]], !prof [[PROF29:![0-9]+]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont59:
// CHECK-NEXT:    store i32 0, ptr [[ARG]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[ARRAYIDX53:%.*]] = getelementptr i32, ptr [[ARG]], i64 [[CONV]]
// CHECK-NEXT:    store i32 0, ptr [[ARRAYIDX53]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[DOTNOT:%.*]] = icmp eq i32 [[SUB]], 0, {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[DOTNOT]], label [[TRAP]], label [[CONT85:%.*]], !prof [[PROF31:![0-9]+]], {{!annotation ![0-9]+}}
// CHECK:       cont85:
// CHECK-NEXT:    store i32 1, ptr [[BOUND_PTR_ARITH]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[SUB77:%.*]] = add i32 [[N]], -2
// CHECK-NEXT:    [[IDXPROM78:%.*]] = zext i32 [[SUB77]] to i64
// CHECK-NEXT:    [[ARRAYIDX79:%.*]] = getelementptr i32, ptr [[BOUND_PTR_ARITH]], i64 [[IDXPROM78]]
// CHECK-NEXT:    store i32 1, ptr [[ARRAYIDX79]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    br label [[RETURN]]
// CHECK:       return:
// CHECK-NEXT:    ret void
//
void count_ptr_relations(int *__counted_by(n) arg, unsigned n) {
    if (n == 0)
        return;
   unsigned m = n-1;
   int *__counted_by(m) ptr = arg + 1;
   arg[0] = 0;
   arg[n-1] = 0;
   ptr[0] = 1; // eliminate checks?
   ptr[m-1] = 1; // eliminate checks?
}

// CHECK-LABEL: @ptrinc0(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP5_NOT:%.*]] = icmp eq i32 [[INLEN:%.*]], 0
// CHECK-NEXT:    br i1 [[CMP5_NOT]], label [[WHILE_END:%.*]], label [[WHILE_BODY_PREHEADER:%.*]]
// CHECK:       while.body.preheader:
// CHECK-NEXT:    [[TMP0:%.*]] = zext i32 [[INLEN]] to i64
// CHECK-NEXT:    tail call void @llvm.memset.p0.i64(ptr align 1 [[BUF:%.*]], i8 0, i64 [[TMP0]], i1 false), {{!tbaa ![0-9]+}}
// CHECK-NEXT:    br label [[WHILE_END]]
// CHECK:       while.end:
// CHECK-NEXT:    ret void
//
void ptrinc0(char *__counted_by(inLen) buf,
             unsigned inLen) {
  unsigned inc = 0;
  char *currentBuf = buf;
  while (inc < inLen) {
    *currentBuf = 0;
    inc++;
    currentBuf++;
  }
}

// TODO rdar://75687730
// CHECK-LABEL: @ptrinc1(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[IDX_EXT:%.*]] = zext i32 [[INLEN:%.*]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds nuw i8, ptr [[BUF:%.*]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[CMP_NOT4:%.*]] = icmp eq i32 [[INLEN]], 0
// CHECK-NEXT:    br i1 [[CMP_NOT4]], label [[WHILE_END:%.*]], label [[WHILE_BODY:%.*]]
// CHECK:       while.body:
// CHECK-NEXT:    [[CURRENTLEN_06:%.*]] = phi i32 [ [[DEC:%.*]], [[CONT1:%.*]] ], [ [[INLEN]], [[ENTRY:%.*]] ]
// CHECK-NEXT:    [[CURRENTBUF_SROA_0_05:%.*]] = phi ptr [ [[BOUND_PTR_ARITH:%.*]], [[CONT1]] ], [ [[BUF]], [[ENTRY]] ]
// CHECK-NEXT:    [[TMP0:%.*]] = icmp ult ptr [[CURRENTBUF_SROA_0_05]], [[ADD_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[TMP1:%.*]] = icmp uge ptr [[CURRENTBUF_SROA_0_05]], [[BUF]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[TMP0]], [[TMP1]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[OR_COND]], label [[CONT1]], label [[TRAP:%.*]], !prof [[PROF10]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont1:
// CHECK-NEXT:    store i8 0, ptr [[CURRENTBUF_SROA_0_05]], align 1, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[DEC]] = add i32 [[CURRENTLEN_06]], -1
// CHECK-NEXT:    [[BOUND_PTR_ARITH]] = getelementptr i8, ptr [[CURRENTBUF_SROA_0_05]], i64 1
// CHECK-NEXT:    [[CMP_NOT:%.*]] = icmp eq i32 [[DEC]], 0
// CHECK-NEXT:    br i1 [[CMP_NOT]], label [[WHILE_END]], label [[WHILE_BODY]], {{!llvm.loop ![0-9]+}}
// CHECK:       while.end:
// CHECK-NEXT:    ret void
//
void ptrinc1(char *__counted_by(inLen) buf,
             unsigned inLen) {
  unsigned currentLen = inLen;
  char *currentBuf = buf;
  while (currentLen != 0) {
    *currentBuf = 0;
    currentLen--;
    currentBuf++;
  }
}

// TODO: rdar://99414486 - All BoundsSafety checks should be removed.
// CHECK-LABEL: @test_reforge_indexable(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CMP_NOT:%.*]] = icmp ult i32 [[IDX:%.*]], [[TABLE_SIZE:%.*]]
// CHECK-NEXT:    [[CMP1_NOT37:%.*]] = icmp ne i32 [[IDX]], 0
// CHECK-NEXT:    [[OR_COND:%.*]] = and i1 [[CMP_NOT]], [[CMP1_NOT37]]
// CHECK-NEXT:    br i1 [[OR_COND]], label [[FOR_BODY_PREHEADER:%.*]], label [[RETURN:%.*]]
// CHECK:       for.body.preheader:
// CHECK-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext i32 [[IDX]] to i64
// CHECK-NEXT:    br label [[FOR_BODY:%.*]]
// CHECK:       for.cond:
// CHECK-NEXT:    [[INDVARS_IV_NEXT:%.*]] = add nuw nsw i64 [[INDVARS_IV:%.*]], 1
// CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[WIDE_TRIP_COUNT]]
// CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[RETURN]], label [[FOR_BODY]], {{!llvm.loop ![0-9]+}}
// CHECK:       for.body:
// CHECK-NEXT:    [[INDVARS_IV]] = phi i64 [ 0, [[FOR_BODY_PREHEADER]] ], [ [[INDVARS_IV_NEXT]], [[FOR_COND:%.*]] ]
// CHECK-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr i32, ptr [[TABLE:%.*]], i64 [[INDVARS_IV]]
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[BOUND_PTR_ARITH]], align 4, {{!tbaa ![0-9]+}}
// CHECK-NEXT:    [[CMP3_NOT:%.*]] = icmp eq i32 [[TMP0]], [[VALUE:%.*]]
// CHECK-NEXT:    br i1 [[CMP3_NOT]], label [[IF_THEN4:%.*]], label [[FOR_COND]]
// CHECK:       trap:
// CHECK-NEXT:    tail call void @llvm.ubsantrap(i8 25) {{#[0-9]+}}, {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       if.then4:
// CHECK-NEXT:    [[BOUND_PTR_ARITH_LE:%.*]] = getelementptr i32, ptr [[TABLE]], i64 [[INDVARS_IV]]
// CHECK-NEXT:    [[IDX_EXT_LE:%.*]] = zext i32 [[TABLE_SIZE]] to i64
// CHECK-NEXT:    [[ADD_PTR_LE:%.*]] = getelementptr inbounds nuw i32, ptr [[TABLE]], i64 [[IDX_EXT_LE]]
// CHECK-NEXT:    [[DOTNOT31:%.*]] = icmp ult ptr [[BOUND_PTR_ARITH_LE]], [[TABLE]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[DOTNOT31]], label [[TRAP:%.*]], label [[RETURN]], !prof [[PROF29]], {{!annotation ![0-9]+}}
// CHECK:       return:
// CHECK-NEXT:    [[RETVAL_SROA_4_3:%.*]] = phi ptr [ null, [[ENTRY:%.*]] ], [ [[ADD_PTR_LE]], [[IF_THEN4]] ], [ null, [[FOR_COND]] ]
// CHECK-NEXT:    [[RETVAL_SROA_0_3:%.*]] = phi ptr [ null, [[ENTRY]] ], [ [[BOUND_PTR_ARITH_LE]], [[IF_THEN4]] ], [ null, [[FOR_COND]] ]
// CHECK-NEXT:    [[DOTFCA_0_INSERT:%.*]] = insertvalue { ptr, ptr } poison, ptr [[RETVAL_SROA_0_3]], 0
// CHECK-NEXT:    [[DOTFCA_1_INSERT:%.*]] = insertvalue { ptr, ptr } [[DOTFCA_0_INSERT]], ptr [[RETVAL_SROA_4_3]], 1
// CHECK-NEXT:    ret { ptr, ptr } [[DOTFCA_1_INSERT]]
//
int *__indexable test_reforge_indexable(unsigned idx, int*__counted_by(table_size) table,
                      unsigned table_size, int value) {
  if (idx >= table_size)
      return 0;

  for (unsigned i = 0; i < idx; i++) {
    int *__single value_entry = &table[i];
    if (*value_entry == value)
        return &table[i];
  }
  return 0;
}
