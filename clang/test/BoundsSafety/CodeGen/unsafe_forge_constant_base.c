// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --check-globals --prefix-filecheck-ir-name TMP_ --version 3


// RUN: %clang_cc1 -triple x86_64 -fbounds-safety -emit-llvm %s -o - | FileCheck %s --check-prefix=X86_64
#include <ptrcheck.h>

void f1(void *__sized_by(size) ptr, unsigned size);

//.
// X86_64: @static_single.p_compile_time_constant_single = internal constant ptr inttoptr (i64 123400004321 to ptr), align 8
// X86_64: @static_bidi.p_compile_time_constant_bidi = internal constant %"__bounds_safety::wide_ptr.bidi_indexable.1" { ptr inttoptr (i64 12300321 to ptr), ptr inttoptr (i64 12300333 to ptr), ptr inttoptr (i64 12300321 to ptr) }, align 8
//.
// X86_64-LABEL: define dso_local void @f2(
// X86_64-SAME: ) #[[ATTR0:[0-9]+]] {
// X86_64-NEXT:  entry:
// X86_64-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// X86_64-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// X86_64-NEXT:    [[AGG_TEMP2:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// X86_64-NEXT:    [[AGG_TEMP11:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// X86_64-NEXT:    [[AGG_TEMP12:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// X86_64-NEXT:    [[AGG_TEMP25:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// X86_64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// X86_64-NEXT:    store ptr inttoptr (i32 4096 to ptr), ptr [[TMP0]], align 8
// X86_64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// X86_64-NEXT:    store ptr getelementptr (i8, ptr inttoptr (i32 4096 to ptr), i64 10), ptr [[TMP1]], align 8
// X86_64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// X86_64-NEXT:    store ptr inttoptr (i32 4096 to ptr), ptr [[TMP2]], align 8
// X86_64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP2]], ptr align 8 [[AGG_TEMP]], i64 24, i1 false), !annotation [[META2:![0-9]+]]
// X86_64-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP2]], i32 0, i32 1, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP2]], i32 0, i32 0, !annotation [[META2]]
// X86_64-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP3]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP2]], i32 0, i32 0, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB_ADDR3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP2]], i32 0, i32 1, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB4:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR3]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP2]], i32 0, i32 2, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP1]], i32 0, i32 0, !annotation [[META2]]
// X86_64-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP4]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP1]], i32 0, i32 1, !annotation [[META2]]
// X86_64-NEXT:    store ptr [[WIDE_PTR_UB4]], ptr [[TMP5]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP1]], i32 0, i32 2, !annotation [[META2]]
// X86_64-NEXT:    store ptr [[WIDE_PTR_LB]], ptr [[TMP6]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_PTR_ADDR5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP1]], i32 0, i32 0, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_PTR6:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR5]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB_ADDR7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP1]], i32 0, i32 1, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB8:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR7]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_LB_ADDR9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP1]], i32 0, i32 2, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_LB10:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR9]], align 8, !annotation [[META2]]
// X86_64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP12]], ptr align 8 [[AGG_TEMP]], i64 24, i1 false), !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_PTR_ADDR13:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP12]], i32 0, i32 0, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_PTR14:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR13]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB_ADDR15:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP12]], i32 0, i32 1, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB16:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR15]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_LB_ADDR17:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP12]], i32 0, i32 2, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_LB18:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR17]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP11]], i32 0, i32 0, !annotation [[META2]]
// X86_64-NEXT:    store ptr [[WIDE_PTR_PTR14]], ptr [[TMP7]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP11]], i32 0, i32 1, !annotation [[META2]]
// X86_64-NEXT:    store ptr [[WIDE_PTR_UB16]], ptr [[TMP8]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP11]], i32 0, i32 2, !annotation [[META2]]
// X86_64-NEXT:    store ptr [[WIDE_PTR_LB18]], ptr [[TMP9]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_PTR_ADDR19:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP11]], i32 0, i32 0, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_PTR20:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR19]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB_ADDR21:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP11]], i32 0, i32 1, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_UB22:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR21]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_LB_ADDR23:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP11]], i32 0, i32 2, !annotation [[META2]]
// X86_64-NEXT:    [[WIDE_PTR_LB24:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR23]], align 8, !annotation [[META2]]
// X86_64-NEXT:    [[SUB_PTR_LHS_CAST:%.*]] = ptrtoint ptr [[WIDE_PTR_PTR6]] to i64, !annotation [[META2]]
// X86_64-NEXT:    [[SUB_PTR_RHS_CAST:%.*]] = ptrtoint ptr [[WIDE_PTR_PTR20]] to i64, !annotation [[META2]]
// X86_64-NEXT:    [[SUB_PTR_SUB:%.*]] = sub i64 [[SUB_PTR_LHS_CAST]], [[SUB_PTR_RHS_CAST]], !annotation [[META2]]
// X86_64-NEXT:    [[CMP:%.*]] = icmp ule i64 10, [[SUB_PTR_SUB]], !annotation [[META2]]
// X86_64-NEXT:    br i1 [[CMP]], label [[CONT:%.*]], label [[TRAP:%.*]], !annotation [[META2]]
// X86_64:       trap:
// X86_64-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4:[0-9]+]], !annotation [[META2]]
// X86_64-NEXT:    unreachable, !annotation [[META2]]
// X86_64:       cont:
// X86_64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP25]], ptr align 8 [[AGG_TEMP]], i64 24, i1 false)
// X86_64-NEXT:    [[WIDE_PTR_PTR_ADDR26:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP25]], i32 0, i32 0
// X86_64-NEXT:    [[WIDE_PTR_PTR27:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR26]], align 8
// X86_64-NEXT:    [[WIDE_PTR_UB_ADDR28:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP25]], i32 0, i32 1
// X86_64-NEXT:    [[WIDE_PTR_UB29:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR28]], align 8
// X86_64-NEXT:    [[WIDE_PTR_LB_ADDR30:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP25]], i32 0, i32 2
// X86_64-NEXT:    [[WIDE_PTR_LB31:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR30]], align 8
// X86_64-NEXT:    call void @f1(ptr noundef [[WIDE_PTR_PTR27]], i32 noundef 10)
// X86_64-NEXT:    ret void
//
void f2(void) {
  f1(__unsafe_forge_bidi_indexable(void *, 0x1000, 10), 10);
}

// X86_64-LABEL: define dso_local ptr @static_single(
// X86_64-SAME: ) #[[ATTR0]] {
// X86_64-NEXT:  entry:
// X86_64-NEXT:    ret ptr inttoptr (i64 123400004321 to ptr)
//
unsigned int *  __single static_single() {
    static unsigned int * __single const p_compile_time_constant_single = __unsafe_forge_single(unsigned int*, 123400004321);
    return p_compile_time_constant_single;
}
// X86_64-LABEL: define dso_local void @static_bidi(
// X86_64-SAME: ptr dead_on_unwind noalias writable sret(%"__bounds_safety::wide_ptr.bidi_indexable.1") align 8 [[AGG_RESULT:%.*]]) #[[ATTR0]] {
// X86_64-NEXT:  entry:
// X86_64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_RESULT]], ptr align 8 @static_bidi.p_compile_time_constant_bidi, i64 24, i1 false)
// X86_64-NEXT:    ret void
//
unsigned int *  __bidi_indexable static_bidi() {
    static unsigned int * __bidi_indexable const p_compile_time_constant_bidi = __unsafe_forge_bidi_indexable(unsigned int*, 12300321, 12);
    return p_compile_time_constant_bidi;
}

// X86_64-LABEL: define dso_local ptr @nonstatic_single(
// X86_64-SAME: ) #[[ATTR0]] {
// X86_64-NEXT:  entry:
// X86_64-NEXT:    [[P:%.*]] = alloca ptr, align 8
// X86_64-NEXT:    store ptr inttoptr (i64 123400004321 to ptr), ptr [[P]], align 8
// X86_64-NEXT:    ret ptr inttoptr (i64 123400004321 to ptr)
//
unsigned int *  __single nonstatic_single() {
    unsigned int * __single const p = __unsafe_forge_single(unsigned int*, 123400004321);
    return p;
}
// X86_64-LABEL: define dso_local void @nonstatic_bidi(
// X86_64-SAME: ptr dead_on_unwind noalias writable sret(%"__bounds_safety::wide_ptr.bidi_indexable.1") align 8 [[AGG_RESULT:%.*]]) #[[ATTR0]] {
// X86_64-NEXT:  entry:
// X86_64-NEXT:    [[P:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.1", align 8
// X86_64-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// X86_64-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// X86_64-NEXT:    store ptr inttoptr (i32 12300321 to ptr), ptr [[TMP0]], align 8
// X86_64-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// X86_64-NEXT:    store ptr getelementptr (i8, ptr inttoptr (i32 12300321 to ptr), i64 12), ptr [[TMP1]], align 8
// X86_64-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// X86_64-NEXT:    store ptr inttoptr (i32 12300321 to ptr), ptr [[TMP2]], align 8
// X86_64-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// X86_64-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// X86_64-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// X86_64-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// X86_64-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// X86_64-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// X86_64-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[P]], i32 0, i32 0
// X86_64-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP3]], align 8
// X86_64-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[P]], i32 0, i32 1
// X86_64-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP4]], align 8
// X86_64-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[P]], i32 0, i32 2
// X86_64-NEXT:    store ptr [[WIDE_PTR_LB]], ptr [[TMP5]], align 8
// X86_64-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_RESULT]], ptr align 8 [[P]], i64 24, i1 false)
// X86_64-NEXT:    ret void
//
unsigned int *  __bidi_indexable nonstatic_bidi() {
    unsigned int * __bidi_indexable const p = __unsafe_forge_bidi_indexable(unsigned int*, 12300321, 12);
    return p;
}
//.
// X86_64: attributes #[[ATTR0]] = { noinline nounwind optnone "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-features"="+cx8,+mmx,+sse,+sse2,+x87" }
// X86_64: attributes #[[ATTR1:[0-9]+]] = { nocallback nofree nounwind willreturn memory(argmem: readwrite) }
// X86_64: attributes #[[ATTR2:[0-9]+]] = { cold noreturn nounwind }
// X86_64: attributes #[[ATTR3:[0-9]+]] = { "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-features"="+cx8,+mmx,+sse,+sse2,+x87" }
// X86_64: attributes #[[ATTR4]] = { nomerge noreturn nounwind }
//.
// X86_64: [[META0:![0-9]+]] = !{i32 1, !"wchar_size", i32 4}
// X86_64: [[META1:![0-9]+]] = !{!"{{.*}}clang version {{.*}}"}
// X86_64: [[META2]] = !{!"bounds-safety-generic"}
//.
