// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// REQUIRES: system-darwin

// Note: Specifying the triple seems to be necessary for `update_cc_test_checks.py` to work
// RUN: %clang_cc1 -O0 -triple arm64-apple-iphoneos -emit-llvm -fbounds-safety -fno-bounds-safety-bringup-missing-checks=compound_literal_init -Wno-bounds-attributes-init-list-side-effect -o - %s | FileCheck %s
// RUN: %clang_cc1 -O0 -triple arm64-apple-iphoneos -emit-llvm -x objective-c -fexperimental-bounds-safety-objc -fbounds-safety -fno-bounds-safety-bringup-missing-checks=compound_literal_init -Wno-bounds-attributes-init-list-side-effect %s -o - | FileCheck %s

#include <ptrcheck.h>

struct sb {
  int count;
  char* __sized_by(count) buf;
};
void consume_sb(struct sb);
void consume_sb_arr(struct sb (*arr)[]);

struct nested_sb {
  struct sb nested;
  int other;
};

struct nested_and_outer_sb {
  struct sb nested;
  int other;
  int count;
  char* __sized_by(count) buf;
};


int get_int(void);

struct sb_with_other_data {
  int count;
  char* __sized_by(count) buf;
  int other;
};
struct no_attr_with_other_data {
  int count;
  char* buf;
  int other;
};
_Static_assert(sizeof(struct sb_with_other_data) ==
               sizeof(struct no_attr_with_other_data), "size mismatch");
void consume_sb_with_other_data_arr(struct sb_with_other_data (*arr)[]);

union TransparentUnion {
  struct sb_with_other_data sb;
  struct no_attr_with_other_data no_sb;
} __attribute__((__transparent_union__));

void receive_transparent_union(union TransparentUnion);

// NOTE: We currently don't test globals because those don't generate bounds
// checks. We currently rely on Sema checks to prevent all invalid externally
// counted pointers. This only works because global initializers must be
// constant evaluable.

// =============================================================================
// Tests with __bidi_indexable source ptr
//
// These are more readable due to the lack of BoundsSafetyPromotionExpr
// =============================================================================

// CHECK-LABEL: define dso_local void @assign_via_ptr(
// CHECK-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr(struct sb* ptr, int new_count,
                    char* __bidi_indexable new_ptr) {
  *ptr = (struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}

// CHECK-LABEL: define dso_local void @assign_operator(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NEW]], i32 0, i32 0
// CHECK-NEXT:    store i32 0, ptr [[COUNT]], align 8, !annotation [[META2:![0-9]+]]
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NEW]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[BUF]], align 8, !annotation [[META2]]
// CHECK-NEXT:    [[COUNT1:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT1]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF2:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF2]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[NEW]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_operator(int new_count, char* __bidi_indexable new_ptr) {
  struct sb new;
  new = (struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}


// CHECK-LABEL: define dso_local void @local_var_init(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NEW]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[NEW]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NEW]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    ret void
//
void local_var_init(int new_count, char* __bidi_indexable new_ptr) {
  struct sb new = (struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}

// CHECK-LABEL: define dso_local void @call_arg(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load [2 x i64], ptr [[DOTCOMPOUNDLITERAL]], align 8
// CHECK-NEXT:    call void @consume_sb([2 x i64] [[TMP2]])
// CHECK-NEXT:    ret void
//
void call_arg(int new_count, char* __bidi_indexable new_ptr) {
  consume_sb((struct sb) {
    .count = new_count,
    .buf = new_ptr
  });
}

// CHECK-LABEL: define dso_local [2 x i64] @return_sb(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[RETVAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load [2 x i64], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [2 x i64] [[TMP2]]
//
struct sb return_sb(int new_count, char* __bidi_indexable new_ptr) {
  return (struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}

// CHECK-LABEL: define dso_local void @construct_not_used(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TMP_ENSURED:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[AGG_TMP_ENSURED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[AGG_TMP_ENSURED]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[AGG_TMP_ENSURED]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    ret void
//
void construct_not_used(int new_count, char* __bidi_indexable new_ptr) {
  (void)(struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nullptr(
// CHECK-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[BUF]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nullptr(struct sb* ptr, int new_count) {
  *ptr = (struct sb) {
    .count = new_count,
    .buf = 0x0
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[NESTED]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP3]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested(struct nested_sb* ptr,
                           char* __bidi_indexable new_ptr,
                           int new_count) {
  *ptr = (struct nested_sb) {
    .nested = {.buf = new_ptr, .count = new_count },
    .other = 0x0
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested_v2(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[NESTED]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP3]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested_v2(struct nested_sb* ptr,
                              char* __bidi_indexable new_ptr,
                              int new_count) {
  *ptr = (struct nested_sb) {
    .nested = (struct sb){.buf = new_ptr, .count = new_count },
    .other = 0x0
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested_v3(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_AND_OUTER_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP3:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_AND_OUTER_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[NESTED]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_AND_OUTER_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[COUNT1:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_AND_OUTER_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP3]], ptr [[COUNT1]], align 4
// CHECK-NEXT:    [[BUF2:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_AND_OUTER_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 3
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP3]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR5:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB7:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB9:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR8]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR5]], ptr [[BUF2]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 32, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested_v3(struct nested_and_outer_sb* ptr,
                              char* __bidi_indexable new_ptr,
                              int new_count) {
  *ptr = (struct nested_and_outer_sb) {
    .nested = (struct sb){.buf = new_ptr, .count = new_count },
    .other = 0x0,
    .buf = new_ptr,
    .count = new_count
  };
}

// CHECK-LABEL: define dso_local void @array_of_struct_init(
// CHECK-SAME: ptr noundef [[NEW_PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ARR:%.*]] = alloca [2 x %struct.sb], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP3:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// CHECK-NEXT:    [[AGG_TEMP4:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.1", align 8
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB:%.*]], ptr [[ARR]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[ARR]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[ARR]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds [[STRUCT_SB]], ptr [[ARR]], i64 1
// CHECK-NEXT:    [[COUNT1:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[ARRAYINIT_ELEMENT]], i32 0, i32 0
// CHECK-NEXT:    store i32 0, ptr [[COUNT1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[ARRAYINIT_ELEMENT]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF2:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[ARRAYINIT_ELEMENT]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[BUF2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr [2 x %struct.sb], ptr [[ARR]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[ARR]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[ARR]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR6:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB8:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB10:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR9]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR6]], ptr [[TMP7]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[WIDE_PTR_UB8]], ptr [[TMP8]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[WIDE_PTR_LB10]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR12:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR13:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB14:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR13]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR15:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB16:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR15]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = icmp ne ptr [[WIDE_PTR_PTR12]], null, !annotation [[META3:![0-9]+]]
// CHECK-NEXT:    br i1 [[TMP10]], label %[[BOUNDSCHECK_NOTNULL:.*]], label %[[CONT18:.*]], !annotation [[META3]]
// CHECK:       [[BOUNDSCHECK_NOTNULL]]:
// CHECK-NEXT:    [[TMP11:%.*]] = icmp ult ptr [[WIDE_PTR_PTR12]], [[WIDE_PTR_UB14]], !annotation [[META4:![0-9]+]]
// CHECK-NEXT:    br i1 [[TMP11]], label %[[CONT:.*]], label %[[TRAP:.*]], !prof [[PROF5:![0-9]+]], !annotation [[META4]]
// CHECK:       [[TRAP]]:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR5:[0-9]+]], !annotation [[META4]]
// CHECK-NEXT:    unreachable, !annotation [[META4]]
// CHECK:       [[CONT]]:
// CHECK-NEXT:    [[TMP12:%.*]] = icmp uge ptr [[WIDE_PTR_PTR12]], [[WIDE_PTR_LB16]], !annotation [[META6:![0-9]+]]
// CHECK-NEXT:    br i1 [[TMP12]], label %[[CONT18]], label %[[TRAP17:.*]], !prof [[PROF5]], !annotation [[META6]]
// CHECK:       [[TRAP17]]:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR5]], !annotation [[META6]]
// CHECK-NEXT:    unreachable, !annotation [[META6]]
// CHECK:       [[CONT18]]:
// CHECK-NEXT:    call void @consume_sb_arr(ptr noundef [[WIDE_PTR_PTR12]])
// CHECK-NEXT:    ret void
//
void array_of_struct_init(char* __bidi_indexable new_ptr,
                          int new_count) {
  struct sb arr[] = (struct sb[]) {
    {.count = new_count, .buf = new_ptr},
    {.count = 0x0, .buf = 0x0}
  };
  consume_sb_arr(&arr);
}


// CHECK-LABEL: define dso_local void @assign_via_ptr_other_data_side_effect(
// CHECK-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB_WITH_OTHER_DATA:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[CALL:%.*]] = call i32 @get_int()
// CHECK-NEXT:    store i32 [[CALL]], ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP3]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_other_data_side_effect(struct sb_with_other_data* ptr,
                                           int new_count,
                                           char* __bidi_indexable new_ptr) {
  *ptr = (struct sb_with_other_data) {
    .count = new_count,
    .buf = new_ptr,
    // Side effect. Generates a warning but it is suppressed for this test
    .other = get_int()
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_other_data_side_effect_zero_ptr(
// CHECK-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB_WITH_OTHER_DATA:%.*]], align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[CALL:%.*]] = call i32 @get_int()
// CHECK-NEXT:    store i32 [[CALL]], ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP3]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_other_data_side_effect_zero_ptr(struct sb_with_other_data* ptr,
                                           int new_count,
                                           char* __bidi_indexable new_ptr) {
  *ptr = (struct sb_with_other_data) {
    .count = new_count,
    .buf = 0x0,
    // Side effect. Generates a warning but it is suppressed for this test
    .other = get_int()
  };
}

// CHECK-LABEL: define dso_local void @call_arg_transparent_union(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TMP:%.*]] = alloca [[UNION_TRANSPARENTUNION:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA:%.*]], ptr [[AGG_TMP]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[AGG_TMP]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[AGG_TMP]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[AGG_TMP]], i32 0, i32 2
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[AGG_TMP]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @receive_transparent_union(ptr noundef [[AGG_TMP]])
// CHECK-NEXT:    ret void
//
void call_arg_transparent_union(int new_count,
                                char* __bidi_indexable new_ptr) {
  receive_transparent_union(
    (struct sb_with_other_data) {
      .count = new_count,
      .buf = new_ptr,
      .other = 0x0
    }
  );
}

// CHECK-LABEL: define dso_local void @call_arg_transparent_union_untransparently(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[UNION_TRANSPARENTUNION:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[BYVAL_TEMP:%.*]] = alloca [[UNION_TRANSPARENTUNION]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA:%.*]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[BYVAL_TEMP]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    call void @receive_transparent_union(ptr noundef [[BYVAL_TEMP]])
// CHECK-NEXT:    ret void
//
void call_arg_transparent_union_untransparently(int new_count,
                                char* __bidi_indexable new_ptr) {
  receive_transparent_union(
    (union TransparentUnion) {
      .sb = {
        .count = new_count,
        .buf = new_ptr,
        .other = 0x0
      }
    }
  );
}

// =============================================================================
// Tests with __sized_by source ptr
//
// These are less readable due to the BoundsSafetyPromotionExpr
// =============================================================================
// CHECK-LABEL: define dso_local void @assign_via_ptr_from_ptr(
// CHECK-SAME: ptr noundef [[PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT1:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[COUNT1]], align 8
// CHECK-NEXT:    store i32 [[TMP2]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP3]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT2:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[TMP4]], i32 0, i32 0
// CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[COUNT2]], align 8
// CHECK-NEXT:    [[BUF3:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[TMP4]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[BUF3]], align 8
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP5]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP6]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP7]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP8]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_from_ptr(struct sb* ptr) {
  *ptr = (struct sb) {
    .count = ptr->count,
    .buf = ptr->buf
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_from_sb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP4]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP3]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_from_sb(struct sb* ptr, int new_count,
                            char* __sized_by(new_count) new_ptr) {
  *ptr = (struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}

// CHECK-LABEL: define dso_local void @assign_operator_from_sb(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NEW]], i32 0, i32 0
// CHECK-NEXT:    store i32 0, ptr [[COUNT]], align 8, !annotation [[META2]]
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NEW]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[BUF]], align 8, !annotation [[META2]]
// CHECK-NEXT:    [[COUNT1:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT1]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF2:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP2]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF2]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[NEW]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_operator_from_sb(int new_count,
                             char* __sized_by(new_count) new_ptr) {
  struct sb new;
  new = (struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}


// CHECK-LABEL: define dso_local void @local_var_init_from_sb(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NEW]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[NEW]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NEW]], i32 0, i32 1
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP2]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    ret void
//
void local_var_init_from_sb(int new_count,
                            char* __sized_by(new_count) new_ptr) {
  struct sb new = (struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}

// CHECK-LABEL: define dso_local void @call_arg_from_sb(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP2]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load [2 x i64], ptr [[DOTCOMPOUNDLITERAL]], align 8
// CHECK-NEXT:    call void @consume_sb([2 x i64] [[TMP7]])
// CHECK-NEXT:    ret void
//
void call_arg_from_sb(int new_count,
                      char* __sized_by(new_count) new_ptr) {
  consume_sb((struct sb) {
    .count = new_count,
    .buf = new_ptr
  });
}

// CHECK-LABEL: define dso_local [2 x i64] @return_sb_from_sb(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[RETVAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP2]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load [2 x i64], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [2 x i64] [[TMP7]]
//
struct sb return_sb_from_sb(int new_count,
                            char* __sized_by(new_count) new_ptr) {
  return (struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}

// CHECK-LABEL: define dso_local void @construct_not_used_from_sb(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TMP_ENSURED:%.*]] = alloca [[STRUCT_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[AGG_TMP_ENSURED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[AGG_TMP_ENSURED]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[AGG_TMP_ENSURED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP2]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    ret void
//
void construct_not_used_from_sb(int new_count,
                                char* __sized_by(new_count) new_ptr) {
  (void)(struct sb) {
    .count = new_count,
    .buf = new_ptr
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested_from_sb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[NESTED]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP4]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP3]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP8]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested_from_sb(struct nested_sb* ptr,
                                   char* __sized_by(new_count) new_ptr,
                                   int new_count) {
  *ptr = (struct nested_sb) {
    .nested = {.buf = new_ptr, .count = new_count },
    .other = 0x0
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested_v2_from_sb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_SB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[NESTED]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP4]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP3]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_SB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP8]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested_v2_from_sb(struct nested_sb* ptr,
                                      char* __sized_by(new_count)new_ptr,
                                      int new_count) {
  *ptr = (struct nested_sb) {
    .nested = (struct sb){.buf = new_ptr, .count = new_count },
    .other = 0x0
  };
}

// CHECK-LABEL: define dso_local void @array_of_struct_init_from_sb(
// CHECK-SAME: ptr noundef [[NEW_PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ARR:%.*]] = alloca [2 x %struct.sb], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP3:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// CHECK-NEXT:    [[AGG_TEMP4:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.1", align 8
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB:%.*]], ptr [[ARR]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[ARR]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[ARR]], i32 0, i32 1
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP2]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds [[STRUCT_SB]], ptr [[ARR]], i64 1
// CHECK-NEXT:    [[COUNT1:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[ARRAYINIT_ELEMENT]], i32 0, i32 0
// CHECK-NEXT:    store i32 0, ptr [[COUNT1]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[ARRAYINIT_ELEMENT]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP7]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF2:%.*]] = getelementptr inbounds nuw [[STRUCT_SB]], ptr [[ARRAYINIT_ELEMENT]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[BUF2]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = getelementptr [2 x %struct.sb], ptr [[ARR]], i64 1
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[ARR]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[ARR]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR6:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB8:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB10:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR9]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR6]], ptr [[TMP12]], align 8
// CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[WIDE_PTR_UB8]], ptr [[TMP13]], align 8
// CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[WIDE_PTR_LB10]], ptr [[TMP14]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR12:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR13:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB14:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR13]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR15:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB16:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR15]], align 8
// CHECK-NEXT:    [[TMP15:%.*]] = icmp ne ptr [[WIDE_PTR_PTR12]], null, !annotation [[META3]]
// CHECK-NEXT:    br i1 [[TMP15]], label %[[BOUNDSCHECK_NOTNULL:.*]], label %[[CONT18:.*]], !annotation [[META3]]
// CHECK:       [[BOUNDSCHECK_NOTNULL]]:
// CHECK-NEXT:    [[TMP16:%.*]] = icmp ult ptr [[WIDE_PTR_PTR12]], [[WIDE_PTR_UB14]], !annotation [[META4]]
// CHECK-NEXT:    br i1 [[TMP16]], label %[[CONT:.*]], label %[[TRAP:.*]], !prof [[PROF5]], !annotation [[META4]]
// CHECK:       [[TRAP]]:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR5]], !annotation [[META4]]
// CHECK-NEXT:    unreachable, !annotation [[META4]]
// CHECK:       [[CONT]]:
// CHECK-NEXT:    [[TMP17:%.*]] = icmp uge ptr [[WIDE_PTR_PTR12]], [[WIDE_PTR_LB16]], !annotation [[META6]]
// CHECK-NEXT:    br i1 [[TMP17]], label %[[CONT18]], label %[[TRAP17:.*]], !prof [[PROF5]], !annotation [[META6]]
// CHECK:       [[TRAP17]]:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR5]], !annotation [[META6]]
// CHECK-NEXT:    unreachable, !annotation [[META6]]
// CHECK:       [[CONT18]]:
// CHECK-NEXT:    call void @consume_sb_arr(ptr noundef [[WIDE_PTR_PTR12]])
// CHECK-NEXT:    ret void
//
void array_of_struct_init_from_sb(char* __sized_by(new_count) new_ptr,
                                  int new_count) {
  struct sb arr[] = (struct sb[]) {
    {.count = new_count, .buf = new_ptr},
    {.count = 0x0, .buf = 0x0}
  };
  consume_sb_arr(&arr);
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_other_data_side_effect_from_sb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB_WITH_OTHER_DATA:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP4]] to i64
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP3]], i64 [[IDX_EXT]]
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[CALL:%.*]] = call i32 @get_int()
// CHECK-NEXT:    store i32 [[CALL]], ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP8]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_other_data_side_effect_from_sb(struct sb_with_other_data* ptr,
                                                   int new_count,
                                                   char* __sized_by(new_count) new_ptr) {
  *ptr = (struct sb_with_other_data) {
    .count = new_count,
    .buf = new_ptr,
    // Side effect. Generates a warning but it is suppressed for this test
    .other = get_int()
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_other_data_side_effect_zero_ptr_from_sb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_SB_WITH_OTHER_DATA:%.*]], align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP1]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[CALL:%.*]] = call i32 @get_int()
// CHECK-NEXT:    store i32 [[CALL]], ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP3]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_other_data_side_effect_zero_ptr_from_sb(struct sb_with_other_data* ptr,
                                           int new_count,
                                           char* __sized_by(new_count) new_ptr) {
  *ptr = (struct sb_with_other_data) {
    .count = new_count,
    .buf = 0x0,
    // Side effect. Generates a warning but it is suppressed for this test
    .other = get_int()
  };
}

// CHECK-LABEL: define dso_local void @call_arg_transparent_union_from_sb(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TMP:%.*]] = alloca [[UNION_TRANSPARENTUNION:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA:%.*]], ptr [[AGG_TMP]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[AGG_TMP]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[AGG_TMP]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[AGG_TMP]], i32 0, i32 2
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[AGG_TMP]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @receive_transparent_union(ptr noundef [[AGG_TMP]])
// CHECK-NEXT:    ret void
//
void call_arg_transparent_union_from_sb(int new_count,
                                        char* __bidi_indexable new_ptr) {
  receive_transparent_union(
    (struct sb_with_other_data) {
      .count = new_count,
      .buf = new_ptr,
      .other = 0x0
    }
  );
}


// CHECK-LABEL: define dso_local void @call_arg_transparent_union_untransparently_from_sb(
// CHECK-SAME: i32 noundef [[NEW_COUNT:%.*]], ptr noundef [[NEW_PTR:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_COUNT_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[NEW_PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[UNION_TRANSPARENTUNION:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[BYVAL_TEMP:%.*]] = alloca [[UNION_TRANSPARENTUNION]], align 8
// CHECK-NEXT:    store i32 [[NEW_COUNT]], ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store ptr [[NEW_PTR]], ptr [[NEW_PTR_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    [[COUNT:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA:%.*]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[NEW_COUNT_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[COUNT]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 4
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[BUF:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_PTR]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[BUF]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_SB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[BYVAL_TEMP]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    call void @receive_transparent_union(ptr noundef [[BYVAL_TEMP]])
// CHECK-NEXT:    ret void
//
void call_arg_transparent_union_untransparently_from_sb(int new_count,
                                char* __bidi_indexable new_ptr) {
  receive_transparent_union(
    (union TransparentUnion) {
      .sb = {
        .count = new_count,
        .buf = new_ptr,
        .other = 0x0
      }
    }
  );
}
//.
// CHECK: [[META2]] = !{!"bounds-safety-zero-init"}
// CHECK: [[META3]] = !{!"bounds-safety-check-ptr-neq-null"}
// CHECK: [[META4]] = !{!"bounds-safety-check-ptr-lt-upper-bound"}
// CHECK: [[PROF5]] = !{!"branch_weights", i32 1048575, i32 1}
// CHECK: [[META6]] = !{!"bounds-safety-check-ptr-ge-lower-bound"}
//.
