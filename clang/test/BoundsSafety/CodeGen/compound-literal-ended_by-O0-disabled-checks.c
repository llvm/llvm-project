// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// REQUIRES: system-darwin

// Note: Specifying the triple seems to be necessary for `update_cc_test_checks.py` to work
// RUN: %clang_cc1 -O0 -triple arm64-apple-iphoneos -emit-llvm -fbounds-safety -fno-bounds-safety-bringup-missing-checks=compound_literal_init -Wno-bounds-attributes-init-list-side-effect -Wno-bounds-safety-init-list-partial-null -o - %s | FileCheck %s
// RUN: %clang_cc1 -O0 -triple arm64-apple-iphoneos -emit-llvm -x objective-c -fexperimental-bounds-safety-objc -fbounds-safety -fno-bounds-safety-bringup-missing-checks=compound_literal_init -Wno-bounds-attributes-init-list-side-effect -Wno-bounds-safety-init-list-partial-null %s -o - | FileCheck %s

#include <ptrcheck.h>

struct eb {
  char* __ended_by(end) start;
  char* end;
};
void consume_eb(struct eb);
void consume_eb_arr(struct eb (*arr)[]);

struct nested_eb {
  struct eb nested;
  int other;
};

struct nested_and_outer_eb {
  struct eb nested;
  int other;
  char* __ended_by(end) start;
  char* end;
};

int get_int(void);

struct eb_with_other_data {
  char* __ended_by(end) start;
  char* end;
  int other;
};
struct no_attr_with_other_data {
  int count;
  char* buf;
  int other;
};
_Static_assert(sizeof(struct eb_with_other_data) ==
               sizeof(struct no_attr_with_other_data), "size mismatch");
void consume_eb_with_other_data_arr(struct eb_with_other_data (*arr)[]);

union TransparentUnion {
  struct eb_with_other_data eb;
  struct no_attr_with_other_data no_eb;
} __attribute__((__transparent_union__));

void receive_transparent_union(union TransparentUnion);

// NOTE: We currently don't test globals because those don't generate bounds
// checks. We currently rely on Sema checks to prevent all invalid externally
// counted pointers. This only works because global initializers must be
// constant evaluable.

// =============================================================================
// Tests with __bidi_indexable source ptr
// =============================================================================

// CHECK-LABEL: define dso_local void @assign_via_ptr(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr(struct eb* ptr,
                    char* __bidi_indexable new_start, char* new_end) {
  *ptr = (struct eb) {
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @assign_operator(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NEW]], i32 0, i32 0
// CHECK-NEXT:    store ptr null, ptr [[START]], align 8, !annotation [[META2:![0-9]+]]
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NEW]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[END]], align 8, !annotation [[META2]]
// CHECK-NEXT:    [[START1:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START1]], align 8
// CHECK-NEXT:    [[END2:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[END2]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[NEW]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_operator(char* __bidi_indexable new_start, char* new_end) {
  struct eb new;
  new = (struct eb) {
    .start = new_start,
    .end = new_end
  };
}


// CHECK-LABEL: define dso_local void @local_var_init(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NEW]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NEW]], i32 0, i32 1
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[END]], align 8
// CHECK-NEXT:    ret void
//
void local_var_init(char* __bidi_indexable new_start, char* new_end) {
  struct eb new = (struct eb) {
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @call_arg(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[END]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load [2 x i64], ptr [[DOTCOMPOUNDLITERAL]], align 8
// CHECK-NEXT:    call void @consume_eb([2 x i64] [[TMP1]])
// CHECK-NEXT:    ret void
//
void call_arg(char* __bidi_indexable new_start, char* new_end) {
  consume_eb((struct eb) {
    .start = new_start,
    .end = new_end
  });
}

// CHECK-LABEL: define dso_local [2 x i64] @return_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[END]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load [2 x i64], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [2 x i64] [[TMP1]]
//
struct eb return_eb(char* __bidi_indexable new_start, char* new_end) {
  return (struct eb) {
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @construct_not_used(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TMP_ENSURED:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[AGG_TMP_ENSURED]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[AGG_TMP_ENSURED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[END]], align 8
// CHECK-NEXT:    ret void
//
void construct_not_used(char* __bidi_indexable new_start, char* new_end) {
  (void)(struct eb) {
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nullptr(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr null, ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nullptr(struct eb* ptr, char* new_end) {
  *ptr = (struct eb) {
    // Diagnostic emitted here but suppressed for this test case
    .start = 0x0,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested(struct nested_eb* ptr,
                           char* __bidi_indexable new_start,
                           char* new_end) {
  *ptr = (struct nested_eb) {
    .nested = {.start = new_start, .end = new_end },
    .other = 0x0
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested_v2(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested_v2(struct nested_eb* ptr,
                              char* __bidi_indexable new_start,
                              char* new_end) {
  *ptr = (struct nested_eb) {
    .nested = (struct eb){.start = new_start, .end = new_end },
    .other = 0x0
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested_v3(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_AND_OUTER_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP2:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_AND_OUTER_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_AND_OUTER_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    [[START1:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_AND_OUTER_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP2]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP2]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR4:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR3]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP2]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB6:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP2]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB8:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR7]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR4]], ptr [[START1]], align 8
// CHECK-NEXT:    [[END9:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_AND_OUTER_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 3
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[END9]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 40, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested_v3(struct nested_and_outer_eb* ptr,
                              char* __bidi_indexable new_start,
                              char* new_end) {
  *ptr = (struct nested_and_outer_eb) {
    .nested = (struct eb){.start = new_start, .end = new_end },
    .other = 0x0,
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @array_of_struct_init(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[ARR:%.*]] = alloca [2 x %struct.eb], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP3:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// CHECK-NEXT:    [[AGG_TEMP4:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.1", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB:%.*]], ptr [[ARR]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[ARR]], i32 0, i32 1
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[END]], align 8
// CHECK-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds [[STRUCT_EB]], ptr [[ARR]], i64 1
// CHECK-NEXT:    [[START1:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[ARRAYINIT_ELEMENT]], i32 0, i32 0
// CHECK-NEXT:    store ptr null, ptr [[START1]], align 8
// CHECK-NEXT:    [[END2:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[ARRAYINIT_ELEMENT]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[END2]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr [2 x %struct.eb], ptr [[ARR]], i64 1
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[ARR]], ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[ARR]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR6:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB8:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP4]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB10:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR9]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR6]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[WIDE_PTR_UB8]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[WIDE_PTR_LB10]], ptr [[TMP7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR12:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR13:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB14:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR13]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR15:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB16:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR15]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = icmp ne ptr [[WIDE_PTR_PTR12]], null, !annotation [[META3:![0-9]+]]
// CHECK-NEXT:    br i1 [[TMP8]], label %[[BOUNDSCHECK_NOTNULL:.*]], label %[[CONT18:.*]], !annotation [[META3]]
// CHECK:       [[BOUNDSCHECK_NOTNULL]]:
// CHECK-NEXT:    [[TMP9:%.*]] = icmp ult ptr [[WIDE_PTR_PTR12]], [[WIDE_PTR_UB14]], !annotation [[META4:![0-9]+]]
// CHECK-NEXT:    br i1 [[TMP9]], label %[[CONT:.*]], label %[[TRAP:.*]], !prof [[PROF5:![0-9]+]], !annotation [[META4]]
// CHECK:       [[TRAP]]:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR5:[0-9]+]], !annotation [[META4]]
// CHECK-NEXT:    unreachable, !annotation [[META4]]
// CHECK:       [[CONT]]:
// CHECK-NEXT:    [[TMP10:%.*]] = icmp uge ptr [[WIDE_PTR_PTR12]], [[WIDE_PTR_LB16]], !annotation [[META6:![0-9]+]]
// CHECK-NEXT:    br i1 [[TMP10]], label %[[CONT18]], label %[[TRAP17:.*]], !prof [[PROF5]], !annotation [[META6]]
// CHECK:       [[TRAP17]]:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR5]], !annotation [[META6]]
// CHECK-NEXT:    unreachable, !annotation [[META6]]
// CHECK:       [[CONT18]]:
// CHECK-NEXT:    call void @consume_eb_arr(ptr noundef [[WIDE_PTR_PTR12]])
// CHECK-NEXT:    ret void
//
void array_of_struct_init(char* __bidi_indexable new_start, char* new_end) {
  struct eb arr[] = (struct eb[]) {
    {.start = new_start, .end = new_end},
    {.start = 0x0, .end = 0x0}
  };
  consume_eb_arr(&arr);
}


// CHECK-LABEL: define dso_local void @assign_via_ptr_other_data_side_effect(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB_WITH_OTHER_DATA:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[CALL:%.*]] = call i32 @get_int()
// CHECK-NEXT:    store i32 [[CALL]], ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_other_data_side_effect(struct eb_with_other_data* ptr,
                                           char* __bidi_indexable new_start,
                                           char* new_end) {
  *ptr = (struct eb_with_other_data) {
    .start = new_start,
    .end = new_end,
    // Side effect. Generates a warning but it is suppressed for this test
    .other = get_int()
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_other_data_side_effect_zero_ptr(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB_WITH_OTHER_DATA:%.*]], align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr null, ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[CALL:%.*]] = call i32 @get_int()
// CHECK-NEXT:    store i32 [[CALL]], ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_other_data_side_effect_zero_ptr(struct eb_with_other_data* ptr,
                                                    char* new_end) {
  *ptr = (struct eb_with_other_data) {
    .start = 0x0,
    .end = new_end, // Generates a warning but it's suppressed in this test
    // Side effect. Generates a warning but it is suppressed for this test
    .other = get_int()
  };
}

// CHECK-LABEL: define dso_local void @call_arg_transparent_union(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TMP:%.*]] = alloca [[UNION_TRANSPARENTUNION:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA:%.*]], ptr [[AGG_TMP]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[AGG_TMP]], i32 0, i32 1
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[AGG_TMP]], i32 0, i32 2
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[AGG_TMP]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @receive_transparent_union(ptr noundef [[AGG_TMP]])
// CHECK-NEXT:    ret void
//
void call_arg_transparent_union(char* __bidi_indexable new_start,
                                char* new_end) {
  receive_transparent_union(
    (struct eb_with_other_data) {
      .start = new_start,
      .end = new_end,
      .other = 0x0
    }
  );
}

// CHECK-LABEL: define dso_local void @call_arg_transparent_union_untransparently(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[UNION_TRANSPARENTUNION:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[BYVAL_TEMP:%.*]] = alloca [[UNION_TRANSPARENTUNION]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA:%.*]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[NEW_START]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[BYVAL_TEMP]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    call void @receive_transparent_union(ptr noundef [[BYVAL_TEMP]])
// CHECK-NEXT:    ret void
//
void call_arg_transparent_union_untransparently(
  char* __bidi_indexable new_start,
  char* new_end) {
  receive_transparent_union(
    (union TransparentUnion) {
      .eb = {
        .start = new_start,
        .end = new_end,
        .other = 0x0
      }
    }
  );
}

// =============================================================================
// Tests with __ended_by source ptr
// =============================================================================

// CHECK-LABEL: define dso_local void @assign_via_ptr_from_eb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP9]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP12]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_from_eb(struct eb* ptr,
                    char* __ended_by(new_end) new_start, char* new_end) {
  *ptr = (struct eb) {
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @assign_operator_from_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP3:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NEW]], i32 0, i32 0
// CHECK-NEXT:    store ptr null, ptr [[START]], align 8, !annotation [[META2]]
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NEW]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[END]], align 8, !annotation [[META2]]
// CHECK-NEXT:    [[START1:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START1]], align 8
// CHECK-NEXT:    [[END2:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR5:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB7:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB9:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR8]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR5]], ptr [[END2]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[NEW]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_operator_from_eb(char* __ended_by(new_end) new_start, char* new_end) {
  struct eb new;
  new = (struct eb) {
    .start = new_start,
    .end = new_end
  };
}


// CHECK-LABEL: define dso_local void @local_var_init_from_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NEW]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NEW]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    ret void
//
void local_var_init_from_eb(char* __ended_by(new_end) new_start, char* new_end) {
  struct eb new = (struct eb) {
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @call_arg_from_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = load [2 x i64], ptr [[DOTCOMPOUNDLITERAL]], align 8
// CHECK-NEXT:    call void @consume_eb([2 x i64] [[TMP12]])
// CHECK-NEXT:    ret void
//
void call_arg_from_eb(char* __ended_by(new_end) new_start, char* new_end) {
  consume_eb((struct eb) {
    .start = new_start,
    .end = new_end
  });
}

// CHECK-LABEL: define dso_local [2 x i64] @return_eb_from_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[RETVAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[RETVAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = load [2 x i64], ptr [[RETVAL]], align 8
// CHECK-NEXT:    ret [2 x i64] [[TMP12]]
//
struct eb return_eb_from_eb(char* __ended_by(new_end) new_start, char* new_end) {
  return (struct eb) {
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @construct_not_used_from_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TMP_ENSURED:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[AGG_TMP_ENSURED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[AGG_TMP_ENSURED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    ret void
//
void construct_not_used_from_eb(char* __ended_by(new_end) new_start, char* new_end) {
  (void)(struct eb) {
    .start = new_start,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nullptr_from_eb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB:%.*]], align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr null, ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nullptr_from_eb(struct eb* ptr, char* new_end) {
  *ptr = (struct eb) {
    // Diagnostic emitted here but suppressed for this test case
    .start = 0x0,
    .end = new_end
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested_from_eb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP9]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP12]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP13]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested_from_eb(struct nested_eb* ptr,
                           char* __ended_by(new_end) new_start,
                           char* new_end) {
  *ptr = (struct nested_eb) {
    .nested = {.start = new_start, .end = new_end },
    .other = 0x0
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_nested_v2_from_eb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_NESTED_EB:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[NESTED:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB:%.*]], ptr [[NESTED]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[NESTED]], i32 0, i32 1
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP9]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP12]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTED_EB]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP13]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_nested_v2_from_eb(struct nested_eb* ptr,
                              char* __ended_by(new_end) new_start,
                              char* new_end) {
  *ptr = (struct nested_eb) {
    .nested = (struct eb){.start = new_start, .end = new_end },
    .other = 0x0
  };
}

// CHECK-LABEL: define dso_local void @array_of_struct_init_from_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[ARR:%.*]] = alloca [2 x %struct.eb], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP10:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// CHECK-NEXT:    [[AGG_TEMP11:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.1", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB:%.*]], ptr [[ARR]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[ARR]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    [[ARRAYINIT_ELEMENT:%.*]] = getelementptr inbounds [[STRUCT_EB]], ptr [[ARR]], i64 1
// CHECK-NEXT:    [[START8:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[ARRAYINIT_ELEMENT]], i32 0, i32 0
// CHECK-NEXT:    store ptr null, ptr [[START8]], align 8
// CHECK-NEXT:    [[END9:%.*]] = getelementptr inbounds nuw [[STRUCT_EB]], ptr [[ARRAYINIT_ELEMENT]], i32 0, i32 1
// CHECK-NEXT:    store ptr null, ptr [[END9]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr [2 x %struct.eb], ptr [[ARR]], i64 1
// CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP11]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[ARR]], ptr [[TMP13]], align 8
// CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP11]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP12]], ptr [[TMP14]], align 8
// CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP11]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[ARR]], ptr [[TMP15]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR12:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP11]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR13:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR12]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR14:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP11]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB15:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR14]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR16:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP11]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB17:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR16]], align 8
// CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP10]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR13]], ptr [[TMP16]], align 8
// CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP10]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[WIDE_PTR_UB15]], ptr [[TMP17]], align 8
// CHECK-NEXT:    [[TMP18:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP10]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[WIDE_PTR_LB17]], ptr [[TMP18]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR18:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP10]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR19:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR18]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR20:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP10]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB21:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR20]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR22:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP10]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB23:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR22]], align 8
// CHECK-NEXT:    [[TMP19:%.*]] = icmp ne ptr [[WIDE_PTR_PTR19]], null, !annotation [[META3]]
// CHECK-NEXT:    br i1 [[TMP19]], label %[[BOUNDSCHECK_NOTNULL:.*]], label %[[CONT25:.*]], !annotation [[META3]]
// CHECK:       [[BOUNDSCHECK_NOTNULL]]:
// CHECK-NEXT:    [[TMP20:%.*]] = icmp ult ptr [[WIDE_PTR_PTR19]], [[WIDE_PTR_UB21]], !annotation [[META4]]
// CHECK-NEXT:    br i1 [[TMP20]], label %[[CONT:.*]], label %[[TRAP:.*]], !prof [[PROF5]], !annotation [[META4]]
// CHECK:       [[TRAP]]:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR5]], !annotation [[META4]]
// CHECK-NEXT:    unreachable, !annotation [[META4]]
// CHECK:       [[CONT]]:
// CHECK-NEXT:    [[TMP21:%.*]] = icmp uge ptr [[WIDE_PTR_PTR19]], [[WIDE_PTR_LB23]], !annotation [[META6]]
// CHECK-NEXT:    br i1 [[TMP21]], label %[[CONT25]], label %[[TRAP24:.*]], !prof [[PROF5]], !annotation [[META6]]
// CHECK:       [[TRAP24]]:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR5]], !annotation [[META6]]
// CHECK-NEXT:    unreachable, !annotation [[META6]]
// CHECK:       [[CONT25]]:
// CHECK-NEXT:    call void @consume_eb_arr(ptr noundef [[WIDE_PTR_PTR19]])
// CHECK-NEXT:    ret void
//
void array_of_struct_init_from_eb(char* __ended_by(new_end) new_start, char* new_end) {
  struct eb arr[] = (struct eb[]) {
    {.start = new_start, .end = new_end},
    {.start = 0x0, .end = 0x0}
  };
  consume_eb_arr(&arr);
}


// CHECK-LABEL: define dso_local void @assign_via_ptr_other_data_side_effect_from_eb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB_WITH_OTHER_DATA:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP9]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP12]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[CALL:%.*]] = call i32 @get_int()
// CHECK-NEXT:    store i32 [[CALL]], ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP13]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_other_data_side_effect_from_eb(struct eb_with_other_data* ptr,
                                           char* __ended_by(new_end) new_start,
                                           char* new_end) {
  *ptr = (struct eb_with_other_data) {
    .start = new_start,
    .end = new_end,
    // Side effect. Generates a warning but it is suppressed for this test
    .other = get_int()
  };
}

// CHECK-LABEL: define dso_local void @assign_via_ptr_other_data_side_effect_zero_ptr_from_eb(
// CHECK-SAME: ptr noundef [[PTR:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[STRUCT_EB_WITH_OTHER_DATA:%.*]], align 8
// CHECK-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    store ptr null, ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    [[CALL:%.*]] = call i32 @get_int()
// CHECK-NEXT:    store i32 [[CALL]], ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP2]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP0]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void assign_via_ptr_other_data_side_effect_zero_ptr_from_eb(struct eb_with_other_data* ptr,
                                                    char* new_end) {
  *ptr = (struct eb_with_other_data) {
    .start = 0x0,
    .end = new_end, // Generates a warning but it's suppressed in this test
    // Side effect. Generates a warning but it is suppressed for this test
    .other = get_int()
  };
}

// CHECK-LABEL: define dso_local void @call_arg_transparent_union_from_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TMP:%.*]] = alloca [[UNION_TRANSPARENTUNION:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA:%.*]], ptr [[AGG_TMP]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[AGG_TMP]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[AGG_TMP]], i32 0, i32 2
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[AGG_TMP]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP12]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @receive_transparent_union(ptr noundef [[AGG_TMP]])
// CHECK-NEXT:    ret void
//
void call_arg_transparent_union_from_eb(char* __ended_by(new_end) new_start,
                                char* new_end) {
  receive_transparent_union(
    (struct eb_with_other_data) {
      .start = new_start,
      .end = new_end,
      .other = 0x0
    }
  );
}

// CHECK-LABEL: define dso_local void @call_arg_transparent_union_untransparently_from_eb(
// CHECK-SAME: ptr noundef [[NEW_START:%.*]], ptr noundef [[NEW_END:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  [[ENTRY:.*:]]
// CHECK-NEXT:    [[NEW_START_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[NEW_END_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTCOMPOUNDLITERAL:%.*]] = alloca [[UNION_TRANSPARENTUNION:%.*]], align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[BYVAL_TEMP:%.*]] = alloca [[UNION_TRANSPARENTUNION]], align 8
// CHECK-NEXT:    store ptr [[NEW_START]], ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    store ptr [[NEW_END]], ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA:%.*]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[START]], align 8
// CHECK-NEXT:    [[END:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 1
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[NEW_START_ADDR]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[NEW_END_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP6]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP1]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB7:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR6]], align 8
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR3]], ptr [[END]], align 8
// CHECK-NEXT:    [[OTHER:%.*]] = getelementptr inbounds nuw [[STRUCT_EB_WITH_OTHER_DATA]], ptr [[DOTCOMPOUNDLITERAL]], i32 0, i32 2
// CHECK-NEXT:    store i32 0, ptr [[OTHER]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[DOTCOMPOUNDLITERAL]], i64 20
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP12]], i8 0, i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[BYVAL_TEMP]], ptr align 8 [[DOTCOMPOUNDLITERAL]], i64 24, i1 false)
// CHECK-NEXT:    call void @receive_transparent_union(ptr noundef [[BYVAL_TEMP]])
// CHECK-NEXT:    ret void
//
void call_arg_transparent_union_untransparently_from_eb(
  char* __ended_by(new_end) new_start,
  char* new_end) {
  receive_transparent_union(
    (union TransparentUnion) {
      .eb = {
        .start = new_start,
        .end = new_end,
        .other = 0x0
      }
    }
  );
}
//.
// CHECK: [[META2]] = !{!"bounds-safety-zero-init"}
// CHECK: [[META3]] = !{!"bounds-safety-check-ptr-neq-null"}
// CHECK: [[META4]] = !{!"bounds-safety-check-ptr-lt-upper-bound"}
// CHECK: [[PROF5]] = !{!"branch_weights", i32 1048575, i32 1}
// CHECK: [[META6]] = !{!"bounds-safety-check-ptr-ge-lower-bound"}
//.
