// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 5
// REQUIRES: system-darwin
// Include the `access_size` because this effects the checks that are emitted.
// RUN: %clang_cc1 -O0 -fbounds-safety -fbounds-safety-bringup-missing-checks=access_size,array_subscript_agg -triple arm64-apple-iphoneos -emit-llvm %s -o - | FileCheck --check-prefixes=NEW %s
// RUN: %clang_cc1 -O0 -fbounds-safety -fno-bounds-safety-bringup-missing-checks=access_size,array_subscript_agg -triple arm64-apple-iphoneos -emit-llvm %s -o - | FileCheck --check-prefixes=LEGACY %s
#include <ptrcheck.h>
#include <stdint.h>

struct Foo {
  int x;
  int y;
};

// NEW-LABEL: define dso_local i64 @access_Foo_bi(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0:[0-9]+]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2:![0-9]+]]
// NEW-NEXT:    [[TMP2:%.*]] = icmp ule ptr [[TMP1]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP2]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3:[0-9]+]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP3:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP1]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP3]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP4:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3:![0-9]+]]
// NEW-NEXT:    br i1 [[TMP4]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP5:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP5]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_bi(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0:[0-9]+]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP1:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP1]]
//
struct Foo access_Foo_bi(struct Foo* __bidi_indexable ptr, int idx) {
  return ptr[idx];
}

// NEW-LABEL: define dso_local i64 @access_Foo_idx(
// NEW-SAME: [2 x i64] noundef [[PTR_COERCE:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// NEW-NEXT:    store [2 x i64] [[PTR_COERCE]], ptr [[PTR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[PTR]], i64 16, i1 false)
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP0]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP1]], align 8
// NEW-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP2]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP3]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR3]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP5:%.*]] = icmp ule ptr [[TMP4]], [[WIDE_PTR_UB5]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP5]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP6:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP4]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP6]], label %[[CONT7:.*]], label %[[TRAP6:.*]], !annotation [[META2]]
// NEW:       [[TRAP6]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT7]]:
// NEW-NEXT:    [[TMP7:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP7]], label %[[CONT9:.*]], label %[[TRAP8:.*]], !annotation [[META3]]
// NEW:       [[TRAP8]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT9]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP8:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP8]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_idx(
// LEGACY-SAME: [2 x i64] noundef [[PTR_COERCE:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// LEGACY-NEXT:    store [2 x i64] [[PTR_COERCE]], ptr [[PTR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[PTR]], i64 16, i1 false)
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP0]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP1]], align 8
// LEGACY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP2]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP3]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR3]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP4:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP4]]
//
struct Foo access_Foo_idx(struct Foo* __indexable ptr, int idx) {
  return ptr[idx];
}

// NEW-LABEL: define dso_local i64 @access_Foo_cb(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// NEW-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[TMP0]], i64 [[IDX_EXT]]
// NEW-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP2]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP4]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP5]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP7:%.*]] = icmp ule ptr [[TMP6]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP7]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP8:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP6]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP8]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP9:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP9]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP10]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_cb(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// LEGACY-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[TMP0]], i64 [[IDX_EXT]]
// LEGACY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP2]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP5:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP5]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP6:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP6]]
//
struct Foo access_Foo_cb(struct Foo* __counted_by(count) ptr, int idx, int count) {
  return ptr[idx];
}

// NEW-LABEL: define dso_local i64 @access_Foo_cbon(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[TMP2:%.*]] = icmp ne ptr [[TMP0]], null, !annotation [[META4:![0-9]+]]
// NEW-NEXT:    br i1 [[TMP2]], label %[[BOUNDSCHECK_NOTNULL:.*]], label %[[BOUNDSCHECK_NULL:.*]], !annotation [[META4]]
// NEW:       [[BOUNDSCHECK_NOTNULL]]:
// NEW-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// NEW-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[TMP0]], i64 [[IDX_EXT]]
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP4]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP5]], align 8
// NEW-NEXT:    br label %[[BOUNDSCHECK_CONT:.*]]
// NEW:       [[BOUNDSCHECK_NULL]]:
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr null, ptr [[TMP6]], align 8
// NEW-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr null, ptr [[TMP7]], align 8
// NEW-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr null, ptr [[TMP8]], align 8
// NEW-NEXT:    br label %[[BOUNDSCHECK_CONT]]
// NEW:       [[BOUNDSCHECK_CONT]]:
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP9:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP9]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP10:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP11:%.*]] = icmp ule ptr [[TMP10]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP11]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP12:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP10]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP12]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP13:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP13]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP14:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP14]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_cbon(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[TMP2:%.*]] = icmp ne ptr [[TMP0]], null, !annotation [[META2:![0-9]+]]
// LEGACY-NEXT:    br i1 [[TMP2]], label %[[BOUNDSCHECK_NOTNULL:.*]], label %[[BOUNDSCHECK_NULL:.*]], !annotation [[META2]]
// LEGACY:       [[BOUNDSCHECK_NOTNULL]]:
// LEGACY-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// LEGACY-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[TMP0]], i64 [[IDX_EXT]]
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP5]], align 8
// LEGACY-NEXT:    br label %[[BOUNDSCHECK_CONT:.*]]
// LEGACY:       [[BOUNDSCHECK_NULL]]:
// LEGACY-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr null, ptr [[TMP6]], align 8
// LEGACY-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr null, ptr [[TMP7]], align 8
// LEGACY-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr null, ptr [[TMP8]], align 8
// LEGACY-NEXT:    br label %[[BOUNDSCHECK_CONT]]
// LEGACY:       [[BOUNDSCHECK_CONT]]:
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP9:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP9]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP10:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP10]]
//
struct Foo access_Foo_cbon(struct Foo* __counted_by_or_null(count) ptr, int idx, int count) {
  return ptr[idx];
}

// NEW-LABEL: define dso_local i64 @access_Foo_sb(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// NEW-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i64 [[IDX_EXT]]
// NEW-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP2]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP4]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP5]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP7:%.*]] = icmp ule ptr [[TMP6]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP7]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP8:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP6]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP8]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP9:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP9]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP10]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_sb(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// LEGACY-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i64 [[IDX_EXT]]
// LEGACY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP2]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP5:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP5]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP6:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP6]]
//
struct Foo access_Foo_sb(struct Foo* __sized_by(count) ptr, int idx, int count) {
  return ptr[idx];
}

// NEW-LABEL: define dso_local i64 @access_Foo_sbon(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[TMP2:%.*]] = icmp ne ptr [[TMP0]], null, !annotation [[META4]]
// NEW-NEXT:    br i1 [[TMP2]], label %[[BOUNDSCHECK_NOTNULL:.*]], label %[[BOUNDSCHECK_NULL:.*]], !annotation [[META4]]
// NEW:       [[BOUNDSCHECK_NOTNULL]]:
// NEW-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// NEW-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i64 [[IDX_EXT]]
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP4]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP5]], align 8
// NEW-NEXT:    br label %[[BOUNDSCHECK_CONT:.*]]
// NEW:       [[BOUNDSCHECK_NULL]]:
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr null, ptr [[TMP6]], align 8
// NEW-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr null, ptr [[TMP7]], align 8
// NEW-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr null, ptr [[TMP8]], align 8
// NEW-NEXT:    br label %[[BOUNDSCHECK_CONT]]
// NEW:       [[BOUNDSCHECK_CONT]]:
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP9:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP9]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP10:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP11:%.*]] = icmp ule ptr [[TMP10]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP11]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP12:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP10]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP12]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP13:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP13]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP14:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP14]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_sbon(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[TMP2:%.*]] = icmp ne ptr [[TMP0]], null, !annotation [[META2]]
// LEGACY-NEXT:    br i1 [[TMP2]], label %[[BOUNDSCHECK_NOTNULL:.*]], label %[[BOUNDSCHECK_NULL:.*]], !annotation [[META2]]
// LEGACY:       [[BOUNDSCHECK_NOTNULL]]:
// LEGACY-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// LEGACY-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i64 [[IDX_EXT]]
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP5]], align 8
// LEGACY-NEXT:    br label %[[BOUNDSCHECK_CONT:.*]]
// LEGACY:       [[BOUNDSCHECK_NULL]]:
// LEGACY-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr null, ptr [[TMP6]], align 8
// LEGACY-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr null, ptr [[TMP7]], align 8
// LEGACY-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr null, ptr [[TMP8]], align 8
// LEGACY-NEXT:    br label %[[BOUNDSCHECK_CONT]]
// LEGACY:       [[BOUNDSCHECK_CONT]]:
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP9:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP9]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP10:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP10]]
//
struct Foo access_Foo_sbon(struct Foo* __sized_by_or_null(count) ptr, int idx, int count) {
  return ptr[idx];
}

// NEW-LABEL: define dso_local i64 @access_Foo_var_array_size(
// NEW-SAME: i32 noundef [[COUNT:%.*]], ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[TMP1:%.*]] = zext i32 [[TMP0]] to i64
// NEW-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP3]] to i64
// NEW-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[TMP2]], i64 [[IDX_EXT]]
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP5]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP7:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP7]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP8:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP9:%.*]] = icmp ule ptr [[TMP8]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP9]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP10:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP8]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP10]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP11:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP11]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP12:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP12]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_var_array_size(
// LEGACY-SAME: i32 noundef [[COUNT:%.*]], ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[TMP1:%.*]] = zext i32 [[TMP0]] to i64
// LEGACY-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP3]] to i64
// LEGACY-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[TMP2]], i64 [[IDX_EXT]]
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP5]], align 8
// LEGACY-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP2]], ptr [[TMP6]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP7:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP7]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP8:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP8]]
//
struct Foo access_Foo_var_array_size(int count, struct Foo ptr[count], int idx) {
  return ptr[idx];
}

// NEW-LABEL: define dso_local i64 @access_Foo_const_array_size(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[TMP0]], i64 5
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP1]], align 8
// NEW-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP2]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP4]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP6:%.*]] = icmp ule ptr [[TMP5]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP6]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP7:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP5]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP7]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP8:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP8]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP9:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP9]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_const_array_size(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[TMP0]], i64 5
// LEGACY-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP1]], align 8
// LEGACY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP2]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP4]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP5:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP5]]
//
struct Foo access_Foo_const_array_size(struct Foo ptr[5], int idx) {
  return ptr[idx];
}

struct NestedArrayOfStructs {
  struct Foo arr[5];
};

// NEW-LABEL: define dso_local i64 @access_Foo_from_struct_arr(
// NEW-SAME: ptr noundef [[NAOS:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[NAOS_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    store ptr [[NAOS]], ptr [[NAOS_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NAOS_ADDR]], align 8
// NEW-NEXT:    [[ARR:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTEDARRAYOFSTRUCTS:%.*]], ptr [[TMP0]], i32 0, i32 0
// NEW-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [5 x %struct.Foo], ptr [[ARR]], i64 0, i64 0
// NEW-NEXT:    [[UPPER:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[ARRAYDECAY]], i64 5
// NEW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP1]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYDECAY]], i64 [[IDXPROM]]
// NEW-NEXT:    [[TMP2:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP3:%.*]] = icmp ule ptr [[TMP2]], [[UPPER]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP3]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP4:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP2]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP4]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP5:%.*]] = icmp uge ptr [[ARRAYIDX]], [[ARRAYDECAY]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP5]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP6:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP6]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_from_struct_arr(
// LEGACY-SAME: ptr noundef [[NAOS:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[NAOS_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    store ptr [[NAOS]], ptr [[NAOS_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[NAOS_ADDR]], align 8
// LEGACY-NEXT:    [[ARR:%.*]] = getelementptr inbounds nuw [[STRUCT_NESTEDARRAYOFSTRUCTS:%.*]], ptr [[TMP0]], i32 0, i32 0
// LEGACY-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [5 x %struct.Foo], ptr [[ARR]], i64 0, i64 0
// LEGACY-NEXT:    [[UPPER:%.*]] = getelementptr inbounds [[STRUCT_FOO]], ptr [[ARRAYDECAY]], i64 5
// LEGACY-NEXT:    [[TMP1:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP1]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYDECAY]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP2:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP2]]
//
struct Foo access_Foo_from_struct_arr(struct NestedArrayOfStructs* naos, int idx) {
  return naos->arr[idx];
}

struct HasFAM {
  int count;
  struct Foo fam[__counted_by(count)];
};

// FIXME: The `__counted_by` attribute isn't used for the bounds check on the
// ArraySubscriptExpr (rdar://145253815).

// NEW-LABEL: define dso_local i64 @access_Foo_from_HasFAM(
// NEW-SAME: ptr noundef [[HAS_FAM:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[HAS_FAM_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// NEW-NEXT:    [[AGG_TEMP2:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// NEW-NEXT:    [[AGG_TEMP5:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// NEW-NEXT:    store ptr [[HAS_FAM]], ptr [[HAS_FAM_INDIRECT_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[HAS_FAM]], i64 24, i1 false)
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP2]], ptr align 8 [[AGG_TEMP1]], i64 24, i1 false)
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP2]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP2]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP2]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP0:%.*]] = getelementptr [[STRUCT_HASFAM:%.*]], ptr [[WIDE_PTR_PTR]], i64 1
// NEW-NEXT:    [[TMP1:%.*]] = icmp ule ptr [[TMP0]], [[WIDE_PTR_UB]], !annotation [[META5:![0-9]+]]
// NEW-NEXT:    br i1 [[TMP1]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META5]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META5]]
// NEW-NEXT:    unreachable, !annotation [[META5]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP2:%.*]] = icmp ule ptr [[WIDE_PTR_LB]], [[WIDE_PTR_PTR]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP2]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    [[FAM:%.*]] = getelementptr inbounds nuw [[STRUCT_HASFAM]], ptr [[WIDE_PTR_PTR]], i32 0, i32 1
// NEW-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [0 x %struct.Foo], ptr [[FAM]], i64 0, i64 0
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP5]], ptr align 8 [[AGG_TEMP1]], i64 24, i1 false)
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP5]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB7:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR6]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP5]], i32 0, i32 0
// NEW-NEXT:    store ptr [[WIDE_PTR_UB7]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP5]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR9:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR8]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP4]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR9]], ptr [[TMP5]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP6]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR11:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR10]], align 8
// NEW-NEXT:    [[TMP7:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP7]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR11]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR12:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB13:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR12]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR14:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB15:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR14]], align 8
// NEW-NEXT:    [[TMP8:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP9:%.*]] = icmp ule ptr [[TMP8]], [[WIDE_PTR_UB13]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP9]], label %[[CONT17:.*]], label %[[TRAP16:.*]], !annotation [[META2]]
// NEW:       [[TRAP16]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT17]]:
// NEW-NEXT:    [[TMP10:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP8]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP10]], label %[[CONT19:.*]], label %[[TRAP18:.*]], !annotation [[META2]]
// NEW:       [[TRAP18]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT19]]:
// NEW-NEXT:    [[TMP11:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB15]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP11]], label %[[CONT21:.*]], label %[[TRAP20:.*]], !annotation [[META3]]
// NEW:       [[TRAP20]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT21]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP12:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP12]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_from_HasFAM(
// LEGACY-SAME: ptr noundef [[HAS_FAM:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[HAS_FAM_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// LEGACY-NEXT:    [[AGG_TEMP2:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// LEGACY-NEXT:    [[AGG_TEMP5:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.0", align 8
// LEGACY-NEXT:    store ptr [[HAS_FAM]], ptr [[HAS_FAM_INDIRECT_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[HAS_FAM]], i64 24, i1 false)
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP2]], ptr align 8 [[AGG_TEMP1]], i64 24, i1 false)
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP2]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP2]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP2]], i32 0, i32 2
// LEGACY-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP0:%.*]] = getelementptr [[STRUCT_HASFAM:%.*]], ptr [[WIDE_PTR_PTR]], i64 1
// LEGACY-NEXT:    [[TMP1:%.*]] = icmp ule ptr [[TMP0]], [[WIDE_PTR_UB]], !annotation [[META3:![0-9]+]]
// LEGACY-NEXT:    br i1 [[TMP1]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META3]]
// LEGACY:       [[TRAP]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3:[0-9]+]], !annotation [[META3]]
// LEGACY-NEXT:    unreachable, !annotation [[META3]]
// LEGACY:       [[CONT]]:
// LEGACY-NEXT:    [[TMP2:%.*]] = icmp ule ptr [[WIDE_PTR_LB]], [[WIDE_PTR_PTR]], !annotation [[META4:![0-9]+]]
// LEGACY-NEXT:    br i1 [[TMP2]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META4]]
// LEGACY:       [[TRAP3]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META4]]
// LEGACY-NEXT:    unreachable, !annotation [[META4]]
// LEGACY:       [[CONT4]]:
// LEGACY-NEXT:    [[FAM:%.*]] = getelementptr inbounds nuw [[STRUCT_HASFAM]], ptr [[WIDE_PTR_PTR]], i32 0, i32 1
// LEGACY-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [0 x %struct.Foo], ptr [[FAM]], i64 0, i64 0
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP5]], ptr align 8 [[AGG_TEMP1]], i64 24, i1 false)
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP5]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB7:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR6]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP5]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[WIDE_PTR_UB7]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR8:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.0", ptr [[AGG_TEMP5]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR9:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR8]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR9]], ptr [[TMP5]], align 8
// LEGACY-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[ARRAYDECAY]], ptr [[TMP6]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR10:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR11:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR10]], align 8
// LEGACY-NEXT:    [[TMP7:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP7]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR11]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP8:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP8]]
//
struct Foo access_Foo_from_HasFAM(struct HasFAM* __bidi_indexable has_fam, int idx) {
  return has_fam->fam[idx];
}

// Access with a MemberExpr has identical codegen

// NEW-LABEL: define dso_local i64 @access_Foo_eb(
// NEW-SAME: ptr noundef [[START:%.*]], i32 noundef [[IDX:%.*]], ptr noundef [[END:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[START_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[END_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[START]], ptr [[START_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    store ptr [[END]], ptr [[END_ADDR]], align 8
// NEW-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[START_ADDR]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[START_ADDR]], align 8
// NEW-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[END_ADDR]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP6]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP7:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP8:%.*]] = icmp ule ptr [[TMP7]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP8]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP9:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP7]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP9]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP10:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP10]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// NEW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP11]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_eb(
// LEGACY-SAME: ptr noundef [[START:%.*]], i32 noundef [[IDX:%.*]], ptr noundef [[END:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[START_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[END_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[START]], ptr [[START_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    store ptr [[END]], ptr [[END_ADDR]], align 8
// LEGACY-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[START_ADDR]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[START_ADDR]], align 8
// LEGACY-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[END_ADDR]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[TMP2]], ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP1]], ptr [[TMP5]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP6:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP6]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[ARRAYIDX]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP7:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP7]]
//
struct Foo access_Foo_eb(struct Foo* __ended_by(end) start, int idx, struct Foo* end) {
  return start[idx];
}

// NEW-LABEL: define dso_local i32 @access_Foo_member_bi(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO:%.*]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP2:%.*]] = icmp ule ptr [[TMP1]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP2]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP3:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP1]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP3]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP4:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP4]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    [[X:%.*]] = getelementptr inbounds nuw [[STRUCT_FOO]], ptr [[ARRAYIDX]], i32 0, i32 0
// NEW-NEXT:    [[TMP5:%.*]] = load i32, ptr [[X]], align 4
// NEW-NEXT:    ret i32 [[TMP5]]
//
// LEGACY-LABEL: define dso_local i32 @access_Foo_member_bi(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO:%.*]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = icmp ult ptr [[ARRAYIDX]], [[WIDE_PTR_UB]], !annotation [[META3]]
// LEGACY-NEXT:    br i1 [[TMP1]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META3]]
// LEGACY:       [[TRAP]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// LEGACY-NEXT:    unreachable, !annotation [[META3]]
// LEGACY:       [[CONT]]:
// LEGACY-NEXT:    [[TMP2:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META4]]
// LEGACY-NEXT:    br i1 [[TMP2]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META4]]
// LEGACY:       [[TRAP1]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META4]]
// LEGACY-NEXT:    unreachable, !annotation [[META4]]
// LEGACY:       [[CONT2]]:
// LEGACY-NEXT:    [[X:%.*]] = getelementptr inbounds nuw [[STRUCT_FOO]], ptr [[ARRAYIDX]], i32 0, i32 0
// LEGACY-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 4
// LEGACY-NEXT:    ret i32 [[TMP3]]
//
int access_Foo_member_bi(struct Foo* __bidi_indexable ptr, int idx) {
  return ptr[idx].x;
}

// NEW-LABEL: define dso_local i32 @access_Foo_member_idx(
// NEW-SAME: [2 x i64] noundef [[PTR_COERCE:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[PTR:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// NEW-NEXT:    store [2 x i64] [[PTR_COERCE]], ptr [[PTR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[PTR]], i64 16, i1 false)
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP0]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP1]], align 8
// NEW-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP2]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP3]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO:%.*]], ptr [[WIDE_PTR_PTR3]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP5:%.*]] = icmp ule ptr [[TMP4]], [[WIDE_PTR_UB5]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP5]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP6:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP4]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP6]], label %[[CONT7:.*]], label %[[TRAP6:.*]], !annotation [[META2]]
// NEW:       [[TRAP6]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT7]]:
// NEW-NEXT:    [[TMP7:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP7]], label %[[CONT9:.*]], label %[[TRAP8:.*]], !annotation [[META3]]
// NEW:       [[TRAP8]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT9]]:
// NEW-NEXT:    [[X:%.*]] = getelementptr inbounds nuw [[STRUCT_FOO]], ptr [[ARRAYIDX]], i32 0, i32 0
// NEW-NEXT:    [[TMP8:%.*]] = load i32, ptr [[X]], align 4
// NEW-NEXT:    ret i32 [[TMP8]]
//
// LEGACY-LABEL: define dso_local i32 @access_Foo_member_idx(
// LEGACY-SAME: [2 x i64] noundef [[PTR_COERCE:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[PTR:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// LEGACY-NEXT:    store [2 x i64] [[PTR_COERCE]], ptr [[PTR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[PTR]], i64 16, i1 false)
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP0]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP1]], align 8
// LEGACY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP2]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP3]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO:%.*]], ptr [[WIDE_PTR_PTR3]], i64 [[IDXPROM]]
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = icmp ult ptr [[ARRAYIDX]], [[WIDE_PTR_UB5]], !annotation [[META3]]
// LEGACY-NEXT:    br i1 [[TMP4]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META3]]
// LEGACY:       [[TRAP]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// LEGACY-NEXT:    unreachable, !annotation [[META3]]
// LEGACY:       [[CONT]]:
// LEGACY-NEXT:    [[TMP5:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META4]]
// LEGACY-NEXT:    br i1 [[TMP5]], label %[[CONT7:.*]], label %[[TRAP6:.*]], !annotation [[META4]]
// LEGACY:       [[TRAP6]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META4]]
// LEGACY-NEXT:    unreachable, !annotation [[META4]]
// LEGACY:       [[CONT7]]:
// LEGACY-NEXT:    [[X:%.*]] = getelementptr inbounds nuw [[STRUCT_FOO]], ptr [[ARRAYIDX]], i32 0, i32 0
// LEGACY-NEXT:    [[TMP6:%.*]] = load i32, ptr [[X]], align 4
// LEGACY-NEXT:    ret i32 [[TMP6]]
//
int access_Foo_member_idx(struct Foo* __indexable ptr, int idx) {
  return ptr[idx].x;
}

// NEW-LABEL: define dso_local i32 @access_Foo_member_cb(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// NEW-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// NEW-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO:%.*]], ptr [[TMP0]], i64 [[IDX_EXT]]
// NEW-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP2]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP0]], ptr [[TMP4]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[TMP5:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP5]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP7:%.*]] = icmp ule ptr [[TMP6]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP7]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP8:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP6]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP8]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP9:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP9]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    [[X:%.*]] = getelementptr inbounds nuw [[STRUCT_FOO]], ptr [[ARRAYIDX]], i32 0, i32 0
// NEW-NEXT:    [[TMP10:%.*]] = load i32, ptr [[X]], align 4
// NEW-NEXT:    ret i32 [[TMP10]]
//
// LEGACY-LABEL: define dso_local i32 @access_Foo_member_cb(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]], i32 noundef [[COUNT:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[COUNT_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    store i32 [[COUNT]], ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = load i32, ptr [[COUNT_ADDR]], align 4
// LEGACY-NEXT:    [[IDX_EXT:%.*]] = sext i32 [[TMP1]] to i64
// LEGACY-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[STRUCT_FOO:%.*]], ptr [[TMP0]], i64 [[IDX_EXT]]
// LEGACY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP2]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP0]], ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[TMP5:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP5]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 [[IDXPROM]]
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP6:%.*]] = icmp ult ptr [[ARRAYIDX]], [[WIDE_PTR_UB]], !annotation [[META3]]
// LEGACY-NEXT:    br i1 [[TMP6]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META3]]
// LEGACY:       [[TRAP]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// LEGACY-NEXT:    unreachable, !annotation [[META3]]
// LEGACY:       [[CONT]]:
// LEGACY-NEXT:    [[TMP7:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META4]]
// LEGACY-NEXT:    br i1 [[TMP7]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META4]]
// LEGACY:       [[TRAP1]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META4]]
// LEGACY-NEXT:    unreachable, !annotation [[META4]]
// LEGACY:       [[CONT2]]:
// LEGACY-NEXT:    [[X:%.*]] = getelementptr inbounds nuw [[STRUCT_FOO]], ptr [[ARRAYIDX]], i32 0, i32 0
// LEGACY-NEXT:    [[TMP8:%.*]] = load i32, ptr [[X]], align 4
// LEGACY-NEXT:    ret i32 [[TMP8]]
//
int access_Foo_member_cb(struct Foo* __counted_by(count) ptr, int idx, int count) {
  return ptr[idx].x;
}

// Member access is also an aggregate
struct MemberIsAgg {
  struct Foo agg;
};
// NEW-LABEL: define dso_local i64 @access_MemberIsAgg_member_bidi(
// NEW-SAME: [2 x i64] noundef [[PTR_COERCE:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable.1", align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.2", align 8
// NEW-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable.1", align 8
// NEW-NEXT:    store [2 x i64] [[PTR_COERCE]], ptr [[PTR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[PTR]], i64 16, i1 false)
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable.1", ptr [[AGG_TEMP1]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable.1", ptr [[AGG_TEMP1]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP0]], align 8
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP1]], align 8
// NEW-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP2]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// NEW-NEXT:    [[TMP3:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP3]] to i64
// NEW-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_MEMBERISAGG:%.*]], ptr [[WIDE_PTR_PTR3]], i64 [[IDXPROM]]
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr [[STRUCT_MEMBERISAGG]], ptr [[ARRAYIDX]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP5:%.*]] = icmp ule ptr [[TMP4]], [[WIDE_PTR_UB5]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP5]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP6:%.*]] = icmp ule ptr [[ARRAYIDX]], [[TMP4]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP6]], label %[[CONT7:.*]], label %[[TRAP6:.*]], !annotation [[META2]]
// NEW:       [[TRAP6]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT7]]:
// NEW-NEXT:    [[TMP7:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP7]], label %[[CONT9:.*]], label %[[TRAP8:.*]], !annotation [[META3]]
// NEW:       [[TRAP8]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT9]]:
// NEW-NEXT:    [[AGG:%.*]] = getelementptr inbounds nuw [[STRUCT_MEMBERISAGG]], ptr [[ARRAYIDX]], i32 0, i32 0
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[AGG]], i64 8, i1 false)
// NEW-NEXT:    [[TMP8:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP8]]
//
// LEGACY-LABEL: define dso_local i64 @access_MemberIsAgg_member_bidi(
// LEGACY-SAME: [2 x i64] noundef [[PTR_COERCE:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable.1", align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.2", align 8
// LEGACY-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable.1", align 8
// LEGACY-NEXT:    store [2 x i64] [[PTR_COERCE]], ptr [[PTR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[PTR]], i64 16, i1 false)
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable.1", ptr [[AGG_TEMP1]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.indexable.1", ptr [[AGG_TEMP1]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP0]], align 8
// LEGACY-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP1]], align 8
// LEGACY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP2]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// LEGACY-NEXT:    [[TMP3:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP3]] to i64
// LEGACY-NEXT:    [[ARRAYIDX:%.*]] = getelementptr [[STRUCT_MEMBERISAGG:%.*]], ptr [[WIDE_PTR_PTR3]], i64 [[IDXPROM]]
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable.2", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = icmp ult ptr [[ARRAYIDX]], [[WIDE_PTR_UB5]], !annotation [[META3]]
// LEGACY-NEXT:    br i1 [[TMP4]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META3]]
// LEGACY:       [[TRAP]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// LEGACY-NEXT:    unreachable, !annotation [[META3]]
// LEGACY:       [[CONT]]:
// LEGACY-NEXT:    [[TMP5:%.*]] = icmp uge ptr [[ARRAYIDX]], [[WIDE_PTR_LB]], !annotation [[META4]]
// LEGACY-NEXT:    br i1 [[TMP5]], label %[[CONT7:.*]], label %[[TRAP6:.*]], !annotation [[META4]]
// LEGACY:       [[TRAP6]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META4]]
// LEGACY-NEXT:    unreachable, !annotation [[META4]]
// LEGACY:       [[CONT7]]:
// LEGACY-NEXT:    [[AGG:%.*]] = getelementptr inbounds nuw [[STRUCT_MEMBERISAGG]], ptr [[ARRAYIDX]], i32 0, i32 0
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[AGG]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP6:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP6]]
//
struct Foo access_MemberIsAgg_member_bidi(struct MemberIsAgg* __indexable ptr, int idx) {
  return ptr[idx].agg;
}

// Access using ptr arithmetic has identical codegen

// NEW-LABEL: define dso_local i64 @access_Foo_bi_ptr_arith(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// NEW-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// NEW-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[TMP1]], align 8
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// NEW-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[TMP2]], i64 [[IDXPROM]]
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// NEW-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[TMP4]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[TMP5]], ptr [[TMP6]], align 8
// NEW-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// NEW-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[TMP7]], align 8
// NEW-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP8]], ptr [[TMP9]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP10:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP11:%.*]] = icmp ule ptr [[TMP10]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP11]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP12:%.*]] = icmp ule ptr [[WIDE_PTR_PTR]], [[TMP10]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP12]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP13:%.*]] = icmp uge ptr [[WIDE_PTR_PTR]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP13]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[WIDE_PTR_PTR]], i64 8, i1 false)
// NEW-NEXT:    [[TMP14:%.*]] = load i64, ptr [[RETVAL]], align 4
// NEW-NEXT:    ret i64 [[TMP14]]
//
// LEGACY-LABEL: define dso_local i64 @access_Foo_bi_ptr_arith(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[RETVAL:%.*]] = alloca [[STRUCT_FOO:%.*]], align 4
// LEGACY-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// LEGACY-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// LEGACY-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[TMP1]], align 8
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// LEGACY-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[TMP2]], i64 [[IDXPROM]]
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// LEGACY-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[TMP5]], ptr [[TMP6]], align 8
// LEGACY-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// LEGACY-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[TMP7]], align 8
// LEGACY-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP8]], ptr [[TMP9]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP10:%.*]] = icmp ult ptr [[WIDE_PTR_PTR]], [[WIDE_PTR_UB]], !annotation [[META3]]
// LEGACY-NEXT:    br i1 [[TMP10]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META3]]
// LEGACY:       [[TRAP]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// LEGACY-NEXT:    unreachable, !annotation [[META3]]
// LEGACY:       [[CONT]]:
// LEGACY-NEXT:    [[TMP11:%.*]] = icmp uge ptr [[WIDE_PTR_PTR]], [[WIDE_PTR_LB]], !annotation [[META4]]
// LEGACY-NEXT:    br i1 [[TMP11]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META4]]
// LEGACY:       [[TRAP1]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META4]]
// LEGACY-NEXT:    unreachable, !annotation [[META4]]
// LEGACY:       [[CONT2]]:
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[RETVAL]], ptr align 4 [[WIDE_PTR_PTR]], i64 8, i1 false)
// LEGACY-NEXT:    [[TMP12:%.*]] = load i64, ptr [[RETVAL]], align 4
// LEGACY-NEXT:    ret i64 [[TMP12]]
//
struct Foo access_Foo_bi_ptr_arith(struct Foo* __bidi_indexable ptr, int idx) {
  return *(ptr + idx);
}

// NEW-LABEL: define dso_local void @compute_addr_with_subscript_Foo_bi(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[F:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// NEW-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[TMP1]], align 8
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// NEW-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr [[STRUCT_FOO:%.*]], ptr [[TMP2]], i64 [[IDXPROM]]
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 0
// NEW-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// NEW-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[TMP4]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 1
// NEW-NEXT:    store ptr [[TMP5]], ptr [[TMP6]], align 8
// NEW-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// NEW-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[TMP7]], align 8
// NEW-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP8]], ptr [[TMP9]], align 8
// NEW-NEXT:    ret void
//
// LEGACY-LABEL: define dso_local void @compute_addr_with_subscript_Foo_bi(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[F:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// LEGACY-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// LEGACY-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[TMP1]], align 8
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// LEGACY-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr [[STRUCT_FOO:%.*]], ptr [[TMP2]], i64 [[IDXPROM]]
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// LEGACY-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[TMP5]], ptr [[TMP6]], align 8
// LEGACY-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// LEGACY-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[TMP7]], align 8
// LEGACY-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP8]], ptr [[TMP9]], align 8
// LEGACY-NEXT:    ret void
//
void compute_addr_with_subscript_Foo_bi(struct Foo* __bidi_indexable ptr, int idx) {
  struct Foo* f = &ptr[idx];
}

// NEW-LABEL: define dso_local void @compute_addr_with_ptr_arith_Foo_bi(
// NEW-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// NEW-NEXT:  [[ENTRY:.*:]]
// NEW-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// NEW-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// NEW-NEXT:    [[F:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// NEW-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// NEW-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// NEW-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// NEW-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// NEW-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[TMP1]], align 8
// NEW-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// NEW-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr [[STRUCT_FOO:%.*]], ptr [[TMP2]], i64 [[IDXPROM]]
// NEW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP3]], align 8
// NEW-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// NEW-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[TMP4]], align 8
// NEW-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    store ptr [[TMP5]], ptr [[TMP6]], align 8
// NEW-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// NEW-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[TMP7]], align 8
// NEW-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    store ptr [[TMP8]], ptr [[TMP9]], align 8
// NEW-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// NEW-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// NEW-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// NEW-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// NEW-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// NEW-NEXT:    [[TMP10:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 1, !annotation [[META2]]
// NEW-NEXT:    [[TMP11:%.*]] = icmp ule ptr [[TMP10]], [[WIDE_PTR_UB]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP11]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META2]]
// NEW:       [[TRAP]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT]]:
// NEW-NEXT:    [[TMP12:%.*]] = icmp ule ptr [[WIDE_PTR_PTR]], [[TMP10]], !annotation [[META2]]
// NEW-NEXT:    br i1 [[TMP12]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META2]]
// NEW:       [[TRAP1]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META2]]
// NEW-NEXT:    unreachable, !annotation [[META2]]
// NEW:       [[CONT2]]:
// NEW-NEXT:    [[TMP13:%.*]] = icmp uge ptr [[WIDE_PTR_PTR]], [[WIDE_PTR_LB]], !annotation [[META3]]
// NEW-NEXT:    br i1 [[TMP13]], label %[[CONT4:.*]], label %[[TRAP3:.*]], !annotation [[META3]]
// NEW:       [[TRAP3]]:
// NEW-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// NEW-NEXT:    unreachable, !annotation [[META3]]
// NEW:       [[CONT4]]:
// NEW-NEXT:    [[TMP14:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 1
// NEW-NEXT:    [[TMP15:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 0
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP15]], align 8
// NEW-NEXT:    [[TMP16:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 1
// NEW-NEXT:    store ptr [[TMP14]], ptr [[TMP16]], align 8
// NEW-NEXT:    [[TMP17:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 2
// NEW-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP17]], align 8
// NEW-NEXT:    ret void
//
// LEGACY-LABEL: define dso_local void @compute_addr_with_ptr_arith_Foo_bi(
// LEGACY-SAME: ptr noundef [[PTR:%.*]], i32 noundef [[IDX:%.*]]) #[[ATTR0]] {
// LEGACY-NEXT:  [[ENTRY:.*:]]
// LEGACY-NEXT:    [[PTR_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// LEGACY-NEXT:    [[IDX_ADDR:%.*]] = alloca i32, align 4
// LEGACY-NEXT:    [[F:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// LEGACY-NEXT:    store ptr [[PTR]], ptr [[PTR_INDIRECT_ADDR]], align 8
// LEGACY-NEXT:    store i32 [[IDX]], ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    [[TMP0:%.*]] = load i32, ptr [[IDX_ADDR]], align 4
// LEGACY-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[TMP]], ptr align 8 [[PTR]], i64 24, i1 false)
// LEGACY-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// LEGACY-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[TMP1]], align 8
// LEGACY-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// LEGACY-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr [[STRUCT_FOO:%.*]], ptr [[TMP2]], i64 [[IDXPROM]]
// LEGACY-NEXT:    [[TMP3:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP3]], align 8
// LEGACY-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// LEGACY-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[TMP4]], align 8
// LEGACY-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[TMP5]], ptr [[TMP6]], align 8
// LEGACY-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// LEGACY-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[TMP7]], align 8
// LEGACY-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[TMP8]], ptr [[TMP9]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// LEGACY-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// LEGACY-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// LEGACY-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// LEGACY-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// LEGACY-NEXT:    [[TMP10:%.*]] = icmp ult ptr [[WIDE_PTR_PTR]], [[WIDE_PTR_UB]], !annotation [[META3]]
// LEGACY-NEXT:    br i1 [[TMP10]], label %[[CONT:.*]], label %[[TRAP:.*]], !annotation [[META3]]
// LEGACY:       [[TRAP]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META3]]
// LEGACY-NEXT:    unreachable, !annotation [[META3]]
// LEGACY:       [[CONT]]:
// LEGACY-NEXT:    [[TMP11:%.*]] = icmp uge ptr [[WIDE_PTR_PTR]], [[WIDE_PTR_LB]], !annotation [[META4]]
// LEGACY-NEXT:    br i1 [[TMP11]], label %[[CONT2:.*]], label %[[TRAP1:.*]], !annotation [[META4]]
// LEGACY:       [[TRAP1]]:
// LEGACY-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR3]], !annotation [[META4]]
// LEGACY-NEXT:    unreachable, !annotation [[META4]]
// LEGACY:       [[CONT2]]:
// LEGACY-NEXT:    [[TMP12:%.*]] = getelementptr [[STRUCT_FOO]], ptr [[WIDE_PTR_PTR]], i64 1
// LEGACY-NEXT:    [[TMP13:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 0
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP13]], align 8
// LEGACY-NEXT:    [[TMP14:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 1
// LEGACY-NEXT:    store ptr [[TMP12]], ptr [[TMP14]], align 8
// LEGACY-NEXT:    [[TMP15:%.*]] = getelementptr inbounds nuw %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[F]], i32 0, i32 2
// LEGACY-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP15]], align 8
// LEGACY-NEXT:    ret void
//
void compute_addr_with_ptr_arith_Foo_bi(struct Foo* __bidi_indexable ptr, int idx) {
  struct Foo* f = &*(ptr + idx);
}


//.
// NEW: [[META2]] = !{!"bounds-safety-check-ptr-le-upper-bound"}
// NEW: [[META3]] = !{!"bounds-safety-check-ptr-ge-lower-bound"}
// NEW: [[META4]] = !{!"bounds-safety-check-ptr-neq-null"}
// NEW: [[META5]] = !{!"bounds-safety-check-ptr-lt-upper-bound"}
//.
// LEGACY: [[META2]] = !{!"bounds-safety-check-ptr-neq-null"}
// LEGACY: [[META3]] = !{!"bounds-safety-check-ptr-lt-upper-bound"}
// LEGACY: [[META4]] = !{!"bounds-safety-check-ptr-ge-lower-bound"}
//.
