==========
KernelInfo
==========

.. contents::
   :local:

Introduction
============

This LLVM IR pass reports various statistics for codes compiled for GPUs.  The
goal of these statistics is to help identify bad code patterns and ways to
mitigate them.  The pass operates at the LLVM IR level so that it can, in
theory, support any LLVM-based compiler for programming languages supporting
GPUs.

By default, the pass runs at the end of LTO, and options like
``-Rpass=kernel-info`` enable its remarks.  Example ``opt`` and ``clang``
command lines appear in the next section.

Remarks include summary statistics (e.g., total size of static allocas) and
individual occurrences (e.g., source location of each alloca).  Examples of the
output appear in tests in `llvm/test/Analysis/KernelInfo`.

Example Command Lines
=====================

To analyze a C program as it appears to an LLVM GPU backend at the end of LTO:

.. code-block:: shell

  $ clang -O2 -g -fopenmp --offload-arch=native test.c -foffload-lto \
      -Rpass=kernel-info

To analyze specified LLVM IR, perhaps previously generated by something like
``clang -save-temps -g -fopenmp --offload-arch=native test.c``:

.. code-block:: shell

  $ opt -disable-output test-openmp-nvptx64-nvidia-cuda-sm_70.bc \
      -pass-remarks=kernel-info -passes=kernel-info

When specifying an LLVM pass pipeline on the command line, ``kernel-info`` still
runs at the end of LTO by default.  ``-no-kernel-info-end-lto`` disables that
behavior so you can position ``kernel-info`` explicitly:

.. code-block:: shell

  $ clang -O2 -g -fopenmp --offload-arch=native test.c -foffload-lto \
      -Rpass=kernel-info \
      -Xoffload-linker --lto-newpm-passes='lto<O2>'

  $ clang -O2 -g -fopenmp --offload-arch=native test.c -foffload-lto \
      -Rpass=kernel-info -mllvm -no-kernel-info-end-lto \
      -Xoffload-linker --lto-newpm-passes='module(kernel-info),lto<O2>'

  $ opt -disable-output test-openmp-nvptx64-nvidia-cuda-sm_70.bc \
      -pass-remarks=kernel-info \
      -passes='lto<O2>'

  $ opt -disable-output test-openmp-nvptx64-nvidia-cuda-sm_70.bc \
      -pass-remarks=kernel-info -no-kernel-info-end-lto \
      -passes='module(kernel-info),lto<O2>'

PGO
===

Using LLVM's PGO implementation for GPUs, profile data can augment the info
reported by kernel-info.  In particular, kernel-info can estimate the number of
floating point operations executed.

For example, the following computes 2\ :sup:`4`\ , so we expect 4 fmul
instructions to execute at run time:

.. code-block:: shell

  $ cat test.c
  #include <stdio.h>
  #include <stdlib.h>
  __attribute__((noinline))
  double test(double x, int n) {
    double res = 1;
    for (int i = 0; i < n; ++i)
      res *= x;
    return res;
  }
  int main(int argc, char *argv[]) {
    double x = atof(argv[1]);
    unsigned n = atoi(argv[2]);
    #pragma omp target map(tofrom:x)
    x = test(x, n);
    printf("%f\n", x);
    return 0;
  }

  $ clang -O1 -g -fopenmp --offload-arch=native test.c -o test \
        -fprofile-generate -Xarch_device -fprofile-update=atomic

  $ LLVM_PROFILE_FILE=test.profraw ./test 2 4
  16.000000

  $ llvm-profdata merge -output=test.profdata *.profraw

  $ clang -O1 -g -fopenmp --offload-arch=native test.c -foffload-lto \
        -Rpass=kernel-info -fprofile-use=test.profdata | \
      grep "test.c:.*Floating\|double"
  test.c:13:0: in artificial function '__omp_offloading_34_1bc8484_main_l13', FloatingPointOpProfileCount = 0
  test.c:7:9: in function 'test', double 'fmul' ('%9') executed 4 times
  test.c:4:0: in function 'test', FloatingPointOpProfileCount = 4

While ``-Xarch_device -fprofile-update=atomic`` is not required for the simple
example above, it can be critical while profiling parallel code.
