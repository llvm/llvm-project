//===- AMDGPUNextUseAnalysis.h ----------------------------------------*- C++-
//*-===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//

#ifndef LLVM_LIB_TARGET_AMDGPU_NEXT_USE_ANALYSIS_H
#define LLVM_LIB_TARGET_AMDGPU_NEXT_USE_ANALYSIS_H

#include "llvm/ADT/DenseMap.h"
#include "llvm/CodeGen/MachineLoopInfo.h"
#include "llvm/CodeGen/SlotIndexes.h"

#include "AMDGPUSSARAUtils.h"
#include "GCNSubtarget.h"
#include "SIRegisterInfo.h"
#include "VRegMaskPair.h"

#include <algorithm>
#include <limits>
#include <set>

using namespace llvm;

// namespace {

// Helper function for rebasing successor distances into current block frame
static inline int64_t rebaseFromSucc(int64_t SuccStored, unsigned SuccEntryOff,
                                     int64_t EdgeWeight /*0 or LoopTag*/) {
  // Move succ-relative value into "current block end" frame.
  return (int64_t)SuccStored + (int64_t)SuccEntryOff + (int64_t)EdgeWeight;
}

class NextUseResult {
  friend class AMDGPUNextUseAnalysisWrapper;
  SlotIndexes *Indexes;
  const MachineRegisterInfo *MRI;
  const SIRegisterInfo *TRI;
  MachineLoopInfo *LI;

  class VRegDistances {

    using Record = std::pair<LaneBitmask, int64_t>;
    struct CompareByDist {
      bool operator()(const Record &LHS, const Record &RHS) const {
        if (LHS.second != RHS.second)     // Different distances
          return LHS.second < RHS.second; // Closest first
        return LHS.first.getAsInteger() <
               RHS.first.getAsInteger(); // Tiebreaker
      }
    };

  public:
    using SortedRecords = std::set<Record, CompareByDist>;

  private:
    DenseMap<unsigned, SortedRecords> NextUseMap;

  public:
    auto begin() { return NextUseMap.begin(); }
    auto end() { return NextUseMap.end(); }

    auto begin() const { return NextUseMap.begin(); }
    auto end() const { return NextUseMap.end(); }

    size_t size() const { return NextUseMap.size(); }
    std::pair<bool, SortedRecords> get(unsigned Key) const {
      if (NextUseMap.contains(Key))
        return {true, NextUseMap.find(Key)->second};
      return {false, SortedRecords()};
    }

    SortedRecords &operator[](unsigned Key) { return NextUseMap[Key]; }

    SmallVector<unsigned> keys() {
      SmallVector<unsigned> Keys;
      for (auto P : NextUseMap)
        Keys.push_back(P.first);
      return Keys;
    }

    bool contains(unsigned Key) { return NextUseMap.contains(Key); }

    bool insert(VRegMaskPair VMP, int64_t Dist) {
      Record R(VMP.getLaneMask(), Dist);
      if (NextUseMap.contains(VMP.getVReg())) {
        SortedRecords &Dists = NextUseMap[VMP.getVReg()];

        if (Dists.find(R) == Dists.end()) {
          SmallVector<SortedRecords::iterator, 4> ToErase;

          for (auto It = Dists.begin(); It != Dists.end(); ++It) {
            const Record &D = *It;

            // Check if existing use covers the new use
            if ((R.first & D.first) == R.first) {
              // Existing use covers new use
              if (D.second <= R.second) {
                // Existing use is closer or equal → reject new use
                return false;
              }
              // Existing use is further → continue (might replace it)
            }

            // Check if new use covers existing use
            if ((D.first & R.first) == D.first) {
              // New use covers existing use
              if (R.second <= D.second) {
                // New use is closer → mark existing for removal
                ToErase.push_back(It);
              } else {
                // New use is further → reject it
                return false;
              }
            }
          }

          // Remove all records that the new use supersedes
          for (auto It : ToErase) {
            Dists.erase(It);
          }

          // Add new record
          return Dists.insert(R).second;
        }
        // Record already exists!
        return false;
      }
      return NextUseMap[VMP.getVReg()].insert(R).second;
    }

    void clear(VRegMaskPair VMP) {
      if (NextUseMap.contains(VMP.getVReg())) {
        auto &Dists = NextUseMap[VMP.getVReg()];
        for (auto It = Dists.begin(); It != Dists.end(); ) {
          LaneBitmask Masked = It->first & ~VMP.getLaneMask();
          if (Masked.none()) {
            It = Dists.erase(It);
          } else {
            ++It;
          }
        }
        if (Dists.empty())
          NextUseMap.erase(VMP.getVReg());
      }
    }

    bool operator==(const VRegDistances Other) const {

      if (Other.size() != size())
        return false;

      for (auto P : NextUseMap) {

        std::pair<bool, SortedRecords> OtherDists = Other.get(P.getFirst());
        if (!OtherDists.first)
          return false;
        SortedRecords &Dists = P.getSecond();

        if (Dists.size() != OtherDists.second.size())
          return false;

        for (auto R : OtherDists.second) {
          SortedRecords::iterator I = Dists.find(R);
          if (I == Dists.end())
            return false;
          if (R.second != I->second)
            return false;
        }
      }

      return true;
    }

    bool operator!=(const VRegDistances &Other) const {
      return !operator==(Other);
    }

    // Adjust 'Other' (which is in successor's frame) into *this* frame,
    // then take pointwise min by LaneBitmask.
    void merge(const VRegDistances &Other, unsigned SuccEntryOff,
               int64_t EdgeWeight = 0) {
      for (const auto &P : Other) {
        unsigned Key = P.getFirst();
        const auto &OtherDists = P.getSecond();
        auto &MineDists = NextUseMap[Key]; // creates empty if not present

        for (const auto &D : OtherDists) {
          // D.second is the successor's STORED value (signed, relative to succ)
          int64_t Rebased = rebaseFromSucc(D.second, SuccEntryOff, EdgeWeight);

          // Try to find existing record with the same LaneBitmask
          auto It =
              std::find_if(MineDists.begin(), MineDists.end(),
                           [&](const Record &R) { return R.first == D.first; });

          if (It == MineDists.end()) {
            // No record → insert
            MineDists.insert({D.first, Rebased});
          } else if (It->second > Rebased) { // take MIN in the current frame
            // Furthest wins (adjusted is more distant) → replace
            MineDists.erase(It);
            MineDists.insert({D.first, Rebased});
          }
        }
      }
    }
  };
  class NextUseInfo {
    // FIXME: need to elaborate proper class interface!
  public:
    VRegDistances Bottom;
    DenseMap<const MachineInstr *, VRegDistances> InstrDist;
    DenseMap<const MachineInstr *, unsigned>
        InstrOffset; // offset at that MI snapshot
  };

  DenseMap<unsigned, NextUseInfo> NextUseMap;
  // Map MBB number to the maximal offset in given by the bottm-up walk
  DenseMap<unsigned, unsigned> EntryOff;

public:
private:
  DenseMap<unsigned, SetVector<VRegMaskPair>> UsedInBlock;
  DenseMap<int, int> LoopExits;
  // Signed tag used to mark "outside current loop" in stored values.
  // Must be >> any finite distance you can accumulate in one function.
  static constexpr int64_t LoopTag = (int64_t)1 << 40; // ~1e12 headroom
  static constexpr int64_t DeadTag = (int64_t)1 << 60; // ~1e18, >> LoopTag

  // Unsigned Infinity for external API/DAG users who want a sentinel.
  static constexpr unsigned PrintedInfinity = std::numeric_limits<unsigned>::max();

  const uint16_t Infinity = std::numeric_limits<unsigned short>::max();
  void init(const MachineFunction &MF);
  void analyze(const MachineFunction &MF);

  // Core materialization: convert stored relative value + snapshot offset
  // to full materialized distance with bounds checking.
  int64_t materialize(int64_t Stored, unsigned SnapshotOffset) const {
    int64_t Mat64 = Stored + static_cast<int64_t>(SnapshotOffset);
    return (Mat64 <= 0) ? 0 : Mat64;
  }

  // Structure for enhanced distance ranking and printing
  struct PrintDist {
    bool IsInfinity;
    bool IsDead;
    int64_t LoopMultiplier;  // How many LoopTags are in the distance
    int64_t Rema;            // remainder after extracting LoopTags
    
    PrintDist(int64_t Mat64) {
      if (Mat64 >= DeadTag) {
        IsInfinity = false;
        IsDead = true;
        LoopMultiplier = 0;
        Rema = Mat64 - DeadTag;
      } else if (Mat64 >= LoopTag) {
        IsInfinity = true;
        IsDead = false;
        // Extract LoopTag multiples and remainder
        LoopMultiplier = Mat64 / LoopTag;
        Rema = Mat64 % LoopTag;
      } else {
        IsInfinity = false;
        IsDead = false;
        LoopMultiplier = 0;
        Rema = Mat64;
      }
    }
  };

  // Materializer for spiller use: applies three-tier ranking system
  unsigned materializeForRank(int64_t Stored, unsigned SnapshotOffset) const;

  // Materializer for printing: returns PrintDist structure
  PrintDist materializeForPrint(int64_t Stored, unsigned SnapshotOffset) const {
    return PrintDist(materialize(Stored, SnapshotOffset));
  }

  // Print each (VReg, LaneMask) entry with materialized distances.
  // Returns true if at least one record was printed.
  LLVM_DUMP_METHOD
  bool printSortedRecords(const VRegDistances::SortedRecords &Records,
                          unsigned VReg, unsigned SnapshotOffset,
                          int64_t EdgeWeigth = 0, raw_ostream &O = dbgs(),
                          StringRef Indent = "      ") const {
    bool Any = false;
    O << "\n";
    for (const auto &X : Records) {
      const LaneBitmask UseMask = X.first;
      const int64_t Stored = X.second; // stored relative (may be negative)

      // Use enhanced materialization for display that shows three-tier
      // structure
      PrintDist PDist =
          materializeForPrint(Stored + EdgeWeigth, SnapshotOffset);

      O << Indent << "Vreg: ";
      const LaneBitmask FullMask = MRI->getMaxLaneMaskForVReg(VReg);
      if (UseMask != FullMask) {
        const unsigned SubRegIdx = getSubRegIndexForLaneMask(UseMask, TRI);
        O << printReg(VReg, TRI, SubRegIdx, MRI);
      } else {
        O << printReg(VReg, TRI);
      }

      if (PDist.IsDead)
        O << "[ DEAD ]\n";
      else if (PDist.IsInfinity)
        if (PDist.LoopMultiplier == 1)
          O << "[ LoopTag+" << PDist.Rema << " ]\n";
        else if (PDist.LoopMultiplier > 1)
          O << "[ LoopTag*" << PDist.LoopMultiplier << "+" << PDist.Rema << " ]\n";
        else
          O << "[ INF+" << PDist.Rema << " ]\n";
      else
        O << "[ " << PDist.Rema << " ]\n";

      Any = true;
    }
    return Any;
  }

  // Iterate VRegs and delegate to printSortedRecords.
  // Returns true if anything was printed.
  LLVM_DUMP_METHOD
  bool printVregDistances(const VRegDistances &D, unsigned SnapshotOffset,
                          int64_t EdgeWeight = 0, raw_ostream &O = dbgs(),
                          StringRef Indent = "      ") const {
    bool Any = false;
    for (const auto &P : D) {
      Any |= printSortedRecords(P.second, P.first, SnapshotOffset, EdgeWeight,
                                O, Indent);
    }
    return Any;
  }

  // Backward-compat shim for block-end printing (offset = 0, default indent).
  LLVM_DUMP_METHOD
  bool printVregDistances(const VRegDistances &D,
                          raw_ostream &O = dbgs()) const {
    return printVregDistances(D, /*SnapshotOffset=*/0, /*EdgeWeight*/ 0, O);
  }

  void clear() {
    NextUseMap.clear();
    LoopExits.clear();
  }

public:
  NextUseResult() = default;
  NextUseResult(const MachineFunction &MF, SlotIndexes &SI, MachineLoopInfo &LI)
      : Indexes(&SI), MRI(&MF.getRegInfo()), LI(&LI) {
    init(MF);
    analyze(MF);
  }
  ~NextUseResult() { clear(); }

  // void print(raw_ostream &O) const { dump(O); }

  unsigned getNextUseDistance(const MachineBasicBlock &MBB,
                              const VRegMaskPair VMP);
  unsigned getNextUseDistance(const MachineBasicBlock::iterator I,
                              const VRegMaskPair VMP);
  void getFromSortedRecords(const VRegDistances::SortedRecords &Dists,
                            LaneBitmask Mask, unsigned SnapshotOffset,
                            unsigned &D);

  SmallVector<VRegMaskPair>
  getSortedSubregUses(const MachineBasicBlock::iterator I,
                      const VRegMaskPair VMP);

  SmallVector<VRegMaskPair> getSortedSubregUses(const MachineBasicBlock &MBB,
                                                const VRegMaskPair VMP);

  bool isDead(MachineBasicBlock &MBB, MachineBasicBlock::iterator I,
              const VRegMaskPair VMP) {
    if (!VMP.getVReg().isVirtual())
      report_fatal_error("Only virtual registers allowed!\n", true);
    // FIXME: We use the same Infinity value to indicate both invalid distance
    // and too long for out of block values. It is okay if the use out of block
    // is at least one instruction further then the end of loop exit. In this
    // case we have a distance Infinity + 1 and hence register is not considered
    // dead. What if the register is defined by the last instruction in the loop
    // exit block and out of loop use is in PHI? By design the dist of all PHIs
    // from the beginning of block are ZERO and hence the distance of
    // out-of-the-loop use will be exactly Infinity So, the register will be
    // mistakenly considered DEAD! On another hand, any predecessor of the block
    // containing PHI must have a branch as the last instruction. In this case
    // the current design works.
    return I == MBB.end() ? getNextUseDistance(MBB, VMP) == Infinity
                          : getNextUseDistance(I, VMP) == Infinity;
  }

  SetVector<VRegMaskPair> &usedInBlock(MachineBasicBlock &MBB) {
    return UsedInBlock[MBB.getNumber()];
  }

  LLVM_DUMP_METHOD void dumpUsedInBlock();

  /// Dump complete next-use analysis results for testing
  LLVM_DUMP_METHOD void dumpAllNextUseDistances(const MachineFunction &MF);
};

class AMDGPUNextUseAnalysis : public AnalysisInfoMixin<AMDGPUNextUseAnalysis> {
  friend AnalysisInfoMixin<AMDGPUNextUseAnalysis>;
  static AnalysisKey Key;

public:
  using Result = NextUseResult;
  Result run(MachineFunction &MF, MachineFunctionAnalysisManager &MFAM);
};

class AMDGPUNextUseAnalysisWrapper : public MachineFunctionPass {
  NextUseResult NU;

public:
  static char ID;

  AMDGPUNextUseAnalysisWrapper();

  void getAnalysisUsage(AnalysisUsage &AU) const override;

  /// Pass entry point; Calculates LiveIntervals.
  bool runOnMachineFunction(MachineFunction &) override;
  void releaseMemory() override { NU.clear(); }

  // /// Implement the dump method.
  // void print(raw_ostream &O, const Module * = nullptr) const override {
  //   NU.print(O);
  // }

  NextUseResult &getNU() { return NU; }
};

//}

#endif // LLVM_LIB_TARGET_AMDGPU_NEXT_USE_ANALYSIS_H
