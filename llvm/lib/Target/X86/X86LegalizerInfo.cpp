//===- X86LegalizerInfo.cpp --------------------------------------*- C++ -*-==//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//
/// \file
/// This file implements the targeting of the Machinelegalizer class for X86.
/// \todo This should be generated by TableGen.
//===----------------------------------------------------------------------===//

#include "X86LegalizerInfo.h"
#include "X86Subtarget.h"
#include "X86TargetMachine.h"
#include "llvm/CodeGen/GlobalISel/LegalizerHelper.h"
#include "llvm/CodeGen/TargetOpcodes.h"
#include "llvm/CodeGen/ValueTypes.h"
#include "llvm/IR/DerivedTypes.h"
#include "llvm/IR/Type.h"

using namespace llvm;
using namespace TargetOpcode;
using namespace LegalizeActions;
using namespace LegalityPredicates;

/// FIXME: The following static functions are SizeChangeStrategy functions
/// that are meant to temporarily mimic the behaviour of the old legalization
/// based on doubling/halving non-legal types as closely as possible. This is
/// not entirly possible as only legalizing the types that are exactly a power
/// of 2 times the size of the legal types would require specifying all those
/// sizes explicitly.
/// In practice, not specifying those isn't a problem, and the below functions
/// should disappear quickly as we add support for legalizing non-power-of-2
/// sized types further.
static void addAndInterleaveWithUnsupported(
    LegacyLegalizerInfo::SizeAndActionsVec &result,
    const LegacyLegalizerInfo::SizeAndActionsVec &v) {
  for (unsigned i = 0; i < v.size(); ++i) {
    result.push_back(v[i]);
    if (i + 1 < v[i].first && i + 1 < v.size() &&
        v[i + 1].first != v[i].first + 1)
      result.push_back({v[i].first + 1, LegacyLegalizeActions::Unsupported});
  }
}

static LegacyLegalizerInfo::SizeAndActionsVec
widen_1(const LegacyLegalizerInfo::SizeAndActionsVec &v) {
  assert(v.size() >= 1);
  assert(v[0].first > 1);
  LegacyLegalizerInfo::SizeAndActionsVec result = {
      {1, LegacyLegalizeActions::WidenScalar},
      {2, LegacyLegalizeActions::Unsupported}};
  addAndInterleaveWithUnsupported(result, v);
  auto Largest = result.back().first;
  result.push_back({Largest + 1, LegacyLegalizeActions::Unsupported});
  return result;
}

X86LegalizerInfo::X86LegalizerInfo(const X86Subtarget &STI,
                                   const X86TargetMachine &TM)
    : Subtarget(STI), TM(TM) {

  bool Is64Bit = Subtarget.is64Bit();
  bool HasSSE1 = Subtarget.hasSSE1();
  bool HasSSE2 = Subtarget.hasSSE2();
  bool HasSSE41 = Subtarget.hasSSE41();
  bool HasAVX = Subtarget.hasAVX();
  bool HasAVX2 = Subtarget.hasAVX2();
  bool HasAVX512 = Subtarget.hasAVX512();
  bool HasVLX = Subtarget.hasVLX();
  bool HasDQI = Subtarget.hasAVX512() && Subtarget.hasDQI();
  bool HasBWI = Subtarget.hasAVX512() && Subtarget.hasBWI();

  const LLT p0 = LLT::pointer(0, TM.getPointerSizeInBits(0));
  const LLT s1 = LLT::scalar(1);
  const LLT s8 = LLT::scalar(8);
  const LLT s16 = LLT::scalar(16);
  const LLT s32 = LLT::scalar(32);
  const LLT s64 = LLT::scalar(64);
  const LLT s128 = LLT::scalar(128);
  const LLT sMaxScalar = Subtarget.is64Bit() ? s64 : s32;

  const LLT v16s8 = LLT::fixed_vector(16, 8);
  const LLT v8s16 = LLT::fixed_vector(8, 16);
  const LLT v4s32 = LLT::fixed_vector(4, 32);
  const LLT v2s64 = LLT::fixed_vector(2, 64);

  const LLT v32s8 = LLT::fixed_vector(32, 8);
  const LLT v16s16 = LLT::fixed_vector(16, 16);
  const LLT v8s32 = LLT::fixed_vector(8, 32);
  const LLT v4s64 = LLT::fixed_vector(4, 64);

  const LLT v64s8 = LLT::fixed_vector(64, 8);
  const LLT v32s16 = LLT::fixed_vector(32, 16);
  const LLT v16s32 = LLT::fixed_vector(16, 32);
  const LLT v8s64 = LLT::fixed_vector(8, 64);

  // implicit/constants
  getActionDefinitionsBuilder(G_IMPLICIT_DEF)
      .legalIf([=](const LegalityQuery &Query) -> bool {
        // 32/64-bits needs support for s64/s128 to handle cases:
        // s64 = EXTEND (G_IMPLICIT_DEF s32) -> s64 = G_IMPLICIT_DEF
        // s128 = EXTEND (G_IMPLICIT_DEF s32/s64) -> s128 = G_IMPLICIT_DEF
        return typeInSet(0, {p0, s1, s8, s16, s32, s64})(Query) ||
               (Is64Bit && typeInSet(0, {s128})(Query));
      });

  getActionDefinitionsBuilder(G_CONSTANT)
      .legalIf([=](const LegalityQuery &Query) -> bool {
        return typeInSet(0, {p0, s8, s16, s32})(Query) ||
               (Is64Bit && typeInSet(0, {s64})(Query));
      })
      .widenScalarToNextPow2(0, /*Min=*/8)
      .clampScalar(0, s8, sMaxScalar);

  // integer addition/subtraction
  getActionDefinitionsBuilder({G_ADD, G_SUB})
      .legalIf([=](const LegalityQuery &Query) -> bool {
        if (typeInSet(0, {s8, s16, s32})(Query))
          return true;
        if (Is64Bit && typeInSet(0, {s64})(Query))
          return true;
        if (HasSSE2 && typeInSet(0, {v16s8, v8s16, v4s32, v2s64})(Query))
          return true;
        if (HasAVX2 && typeInSet(0, {v32s8, v16s16, v8s32, v4s64})(Query))
          return true;
        if (HasAVX512 && typeInSet(0, {v16s32, v8s64})(Query))
          return true;
        if (HasBWI && typeInSet(0, {v64s8, v32s16})(Query))
          return true;
        return false;
      })
      .clampMinNumElements(0, s8, 16)
      .clampMinNumElements(0, s16, 8)
      .clampMinNumElements(0, s32, 4)
      .clampMinNumElements(0, s64, 2)
      .clampMaxNumElements(0, s8, HasBWI ? 64 : (HasAVX2 ? 32 : 16))
      .clampMaxNumElements(0, s16, HasBWI ? 32 : (HasAVX2 ? 16 : 8))
      .clampMaxNumElements(0, s32, HasAVX512 ? 16 : (HasAVX2 ? 8 : 4))
      .clampMaxNumElements(0, s64, HasAVX512 ? 8 : (HasAVX2 ? 4 : 2))
      .widenScalarToNextPow2(0, /*Min=*/32)
      .clampScalar(0, s8, sMaxScalar)
      .scalarize(0);

  // integer multiply
  getActionDefinitionsBuilder(G_MUL)
      .legalIf([=](const LegalityQuery &Query) -> bool {
        if (typeInSet(0, {s8, s16, s32})(Query))
          return true;
        if (Is64Bit && typeInSet(0, {s64})(Query))
          return true;
        if (HasSSE2 && typeInSet(0, {v8s16})(Query))
          return true;
        if (HasSSE41 && typeInSet(0, {v4s32})(Query))
          return true;
        if (HasAVX2 && typeInSet(0, {v16s16, v8s32})(Query))
          return true;
        if (HasAVX512 && typeInSet(0, {v16s32})(Query))
          return true;
        if (HasDQI && typeInSet(0, {v8s64})(Query))
          return true;
        if (HasDQI && HasVLX && typeInSet(0, {v2s64, v4s64})(Query))
          return true;
        if (HasBWI && typeInSet(0, {v32s16})(Query))
          return true;
        return false;
      })
      .clampMinNumElements(0, s16, 8)
      .clampMinNumElements(0, s32, 4)
      .clampMinNumElements(0, s64, HasVLX ? 2 : 8)
      .clampMaxNumElements(0, s16, HasBWI ? 32 : (HasAVX2 ? 16 : 8))
      .clampMaxNumElements(0, s32, HasAVX512 ? 16 : (HasAVX2 ? 8 : 4))
      .clampMaxNumElements(0, s64, 8)
      .widenScalarToNextPow2(0, /*Min=*/32)
      .clampScalar(0, s8, sMaxScalar)
      .scalarize(0);

  // integer divisions
  getActionDefinitionsBuilder({G_SDIV, G_SREM, G_UDIV, G_UREM})
      .legalIf([=](const LegalityQuery &Query) -> bool {
        return typeInSet(0, {s8, s16, s32})(Query) ||
               (Is64Bit && typeInSet(0, {s64})(Query));
      })
      .clampScalar(0, s8, sMaxScalar);

  // integer shifts
  getActionDefinitionsBuilder({G_SHL, G_LSHR, G_ASHR})
      .legalIf([=](const LegalityQuery &Query) -> bool {
        return typePairInSet(0, 1, {{s8, s8}, {s16, s8}, {s32, s8}})(Query) ||
               (Is64Bit && typePairInSet(0, 1, {{s64, s8}})(Query));
      })
      .clampScalar(0, s8, sMaxScalar)
      .clampScalar(1, s8, s8);

  // integer logic
  getActionDefinitionsBuilder({G_AND, G_OR, G_XOR})
      .legalIf([=](const LegalityQuery &Query) -> bool {
        if (typeInSet(0, {s8, s16, s32})(Query))
          return true;
        if (Is64Bit && typeInSet(0, {s64})(Query))
          return true;
        if (HasSSE2 && typeInSet(0, {v16s8, v8s16, v4s32, v2s64})(Query))
          return true;
        if (HasAVX && typeInSet(0, {v32s8, v16s16, v8s32, v4s64})(Query))
          return true;
        if (HasAVX512 && typeInSet(0, {v64s8, v32s16, v16s32, v8s64})(Query))
          return true;
        return false;
      })
      .clampMinNumElements(0, s8, 16)
      .clampMinNumElements(0, s16, 8)
      .clampMinNumElements(0, s32, 4)
      .clampMinNumElements(0, s64, 2)
      .clampMaxNumElements(0, s8, HasAVX512 ? 64 : (HasAVX ? 32 : 16))
      .clampMaxNumElements(0, s16, HasAVX512 ? 32 : (HasAVX ? 16 : 8))
      .clampMaxNumElements(0, s32, HasAVX512 ? 16 : (HasAVX ? 8 : 4))
      .clampMaxNumElements(0, s64, HasAVX512 ? 8 : (HasAVX ? 4 : 2))
      .widenScalarToNextPow2(0, /*Min=*/32)
      .clampScalar(0, s8, sMaxScalar)
      .scalarize(0);

  // integer comparison
  const std::initializer_list<LLT> IntTypes32 = {s8, s16, s32, p0};
  const std::initializer_list<LLT> IntTypes64 = {s8, s16, s32, s64, p0};

  getActionDefinitionsBuilder(G_ICMP)
      .legalForCartesianProduct({s8}, Is64Bit ? IntTypes64 : IntTypes32)
      .clampScalar(0, s8, s8);

  // bswap
  getActionDefinitionsBuilder(G_BSWAP)
      .legalIf([=](const LegalityQuery &Query) {
        return Query.Types[0] == s32 ||
               (Subtarget.is64Bit() && Query.Types[0] == s64);
      })
      .widenScalarToNextPow2(0, /*Min=*/32)
      .clampScalar(0, s32, sMaxScalar);

  // popcount
  getActionDefinitionsBuilder(G_CTPOP)
      .legalIf([=](const LegalityQuery &Query) -> bool {
        return Subtarget.hasPOPCNT() &&
               (typePairInSet(0, 1, {{s16, s16}, {s32, s32}})(Query) ||
                (Is64Bit && typePairInSet(0, 1, {{s64, s64}})(Query)));
      })
      .widenScalarToNextPow2(1, /*Min=*/16)
      .clampScalar(1, s16, sMaxScalar);

  // count leading zeros (LZCNT)
  getActionDefinitionsBuilder(G_CTLZ)
      .legalIf([=](const LegalityQuery &Query) -> bool {
        return Subtarget.hasLZCNT() &&
               (typePairInSet(0, 1, {{s16, s16}, {s32, s32}})(Query) ||
                (Is64Bit && typePairInSet(0, 1, {{s64, s64}})(Query)));
      })
      .widenScalarToNextPow2(1, /*Min=*/16)
      .clampScalar(1, s16, sMaxScalar);

  // count trailing zeros
  getActionDefinitionsBuilder({G_CTTZ_ZERO_UNDEF, G_CTTZ})
      .legalIf([=](const LegalityQuery &Query) -> bool {
        return (Query.Opcode == G_CTTZ_ZERO_UNDEF || Subtarget.hasBMI()) &&
               (typePairInSet(0, 1, {{s16, s16}, {s32, s32}})(Query) ||
                (Is64Bit && typePairInSet(0, 1, {{s64, s64}})(Query)));
      })
      .widenScalarToNextPow2(1, /*Min=*/16)
      .clampScalar(1, s16, sMaxScalar);

  // pointer handling
  const std::initializer_list<LLT> PtrTypes32 = {s1, s8, s16, s32};
  const std::initializer_list<LLT> PtrTypes64 = {s1, s8, s16, s32, s64};

  getActionDefinitionsBuilder(G_PTRTOINT)
      .legalForCartesianProduct(Is64Bit ? PtrTypes64 : PtrTypes32, {p0})
      .maxScalar(0, sMaxScalar)
      .widenScalarToNextPow2(0, /*Min*/ 8);

  getActionDefinitionsBuilder(G_INTTOPTR).legalFor({{p0, sMaxScalar}});

  // sext, zext, and anyext
  getActionDefinitionsBuilder({G_SEXT, G_ZEXT, G_ANYEXT})
      .legalIf([=](const LegalityQuery &Query) {
        return typeInSet(0, {s8, s16, s32})(Query) ||
          (Query.Opcode == G_ANYEXT && Query.Types[0] == s128) ||
          (Is64Bit && Query.Types[0] == s64);
      })
    .widenScalarToNextPow2(0, /*Min=*/8)
    .clampScalar(0, s8, sMaxScalar)
    .widenScalarToNextPow2(1, /*Min=*/8)
    .clampScalar(1, s8, sMaxScalar);

  // fp constants
  getActionDefinitionsBuilder(G_FCONSTANT)
      .legalIf([=](const LegalityQuery &Query) -> bool {
        return (HasSSE1 && typeInSet(0, {s32})(Query)) ||
               (HasSSE2 && typeInSet(0, {s64})(Query));
      });

  // fp arithmetic
  getActionDefinitionsBuilder({G_FADD, G_FSUB, G_FMUL, G_FDIV})
      .legalIf([=](const LegalityQuery &Query) {
        return (HasSSE1 && typeInSet(0, {s32, v4s32})(Query)) ||
               (HasSSE2 && typeInSet(0, {s64, v2s64})(Query)) ||
               (HasAVX && typeInSet(0, {v8s32, v4s64})(Query)) ||
               (HasAVX512 && typeInSet(0, {v16s32, v8s64})(Query));
      });

  setLegalizerInfo32bit();
  setLegalizerInfo64bit();
  setLegalizerInfoSSE1();
  setLegalizerInfoSSE2();
  setLegalizerInfoAVX();
  setLegalizerInfoAVX2();
  setLegalizerInfoAVX512();

  getActionDefinitionsBuilder(G_INTRINSIC_ROUNDEVEN)
    .scalarize(0)
    .minScalar(0, LLT::scalar(32))
    .libcall();

  auto &LegacyInfo = getLegacyLegalizerInfo();
  LegacyInfo.setLegalizeScalarToDifferentSizeStrategy(G_PHI, 0, widen_1);
  for (unsigned MemOp : {G_LOAD, G_STORE})
    LegacyInfo.setLegalizeScalarToDifferentSizeStrategy(
        MemOp, 0, LegacyLegalizerInfo::narrowToSmallerAndWidenToSmallest);
  LegacyInfo.setLegalizeScalarToDifferentSizeStrategy(
      G_PTR_ADD, 1,
      LegacyLegalizerInfo::widenToLargerTypesUnsupportedOtherwise);

  getActionDefinitionsBuilder({G_MEMCPY, G_MEMMOVE, G_MEMSET}).libcall();

  LegacyInfo.computeTables();
  verify(*STI.getInstrInfo());
}

bool X86LegalizerInfo::legalizeIntrinsic(LegalizerHelper &Helper,
                                         MachineInstr &MI) const {
  return true;
}

void X86LegalizerInfo::setLegalizerInfo32bit() {

  const LLT p0 = LLT::pointer(0, TM.getPointerSizeInBits(0));
  const LLT s1 = LLT::scalar(1);
  const LLT s8 = LLT::scalar(8);
  const LLT s16 = LLT::scalar(16);
  const LLT s32 = LLT::scalar(32);
  const LLT s64 = LLT::scalar(64);

  auto &LegacyInfo = getLegacyLegalizerInfo();

  for (auto Ty : {s8, s16, s32, p0})
    LegacyInfo.setAction({G_PHI, Ty}, LegacyLegalizeActions::Legal);

  for (unsigned Op : {G_UADDE}) {
    LegacyInfo.setAction({Op, s32}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({Op, 1, s1}, LegacyLegalizeActions::Legal);
  }

  for (unsigned MemOp : {G_LOAD, G_STORE}) {
    for (auto Ty : {s8, s16, s32, p0})
      LegacyInfo.setAction({MemOp, Ty}, LegacyLegalizeActions::Legal);

    // And everything's fine in addrspace 0.
    LegacyInfo.setAction({MemOp, 1, p0}, LegacyLegalizeActions::Legal);
  }

  // Pointer-handling
  LegacyInfo.setAction({G_FRAME_INDEX, p0}, LegacyLegalizeActions::Legal);
  LegacyInfo.setAction({G_GLOBAL_VALUE, p0}, LegacyLegalizeActions::Legal);

  LegacyInfo.setAction({G_PTR_ADD, p0}, LegacyLegalizeActions::Legal);
  LegacyInfo.setAction({G_PTR_ADD, 1, s32}, LegacyLegalizeActions::Legal);

  // Control-flow
  LegacyInfo.setAction({G_BRCOND, s1}, LegacyLegalizeActions::Legal);

  getActionDefinitionsBuilder(G_SEXT_INREG).lower();

  // Merge/Unmerge
  for (const auto &Ty : {s16, s32, s64}) {
    LegacyInfo.setAction({G_MERGE_VALUES, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, 1, Ty},
                         LegacyLegalizeActions::Legal);
  }
  for (const auto &Ty : {s8, s16, s32}) {
    LegacyInfo.setAction({G_MERGE_VALUES, 1, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, Ty}, LegacyLegalizeActions::Legal);
  }
}

void X86LegalizerInfo::setLegalizerInfo64bit() {

  if (!Subtarget.is64Bit())
    return;

  const LLT s8 = LLT::scalar(8);
  const LLT s32 = LLT::scalar(32);
  const LLT s64 = LLT::scalar(64);
  const LLT s128 = LLT::scalar(128);

  auto &LegacyInfo = getLegacyLegalizerInfo();

  LegacyInfo.setAction({G_PHI, s64}, LegacyLegalizeActions::Legal);

  for (unsigned MemOp : {G_LOAD, G_STORE})
    LegacyInfo.setAction({MemOp, s64}, LegacyLegalizeActions::Legal);

  // Pointer-handling
  LegacyInfo.setAction({G_PTR_ADD, 1, s64}, LegacyLegalizeActions::Legal);

  getActionDefinitionsBuilder(G_SITOFP)
    .legalForCartesianProduct({s32, s64})
      .clampScalar(1, s32, s64)
      .widenScalarToNextPow2(1)
      .clampScalar(0, s32, s64)
      .widenScalarToNextPow2(0);

  getActionDefinitionsBuilder(G_FPTOSI)
      .legalForCartesianProduct({s32, s64})
      .clampScalar(1, s32, s64)
      .widenScalarToNextPow2(0)
      .clampScalar(0, s32, s64)
      .widenScalarToNextPow2(1);

  getActionDefinitionsBuilder(G_FCMP)
      .legalForCartesianProduct({s8}, {s32, s64})
      .clampScalar(0, s8, s8)
      .clampScalar(1, s32, s64)
      .widenScalarToNextPow2(1);

  // Merge/Unmerge
  LegacyInfo.setAction({G_MERGE_VALUES, s128}, LegacyLegalizeActions::Legal);
  LegacyInfo.setAction({G_UNMERGE_VALUES, 1, s128},
                       LegacyLegalizeActions::Legal);
  LegacyInfo.setAction({G_MERGE_VALUES, 1, s128}, LegacyLegalizeActions::Legal);
  LegacyInfo.setAction({G_UNMERGE_VALUES, s128}, LegacyLegalizeActions::Legal);
}

void X86LegalizerInfo::setLegalizerInfoSSE1() {
  if (!Subtarget.hasSSE1())
    return;

  const LLT s32 = LLT::scalar(32);
  const LLT s64 = LLT::scalar(64);
  const LLT v4s32 = LLT::fixed_vector(4, 32);
  const LLT v2s64 = LLT::fixed_vector(2, 64);

  auto &LegacyInfo = getLegacyLegalizerInfo();

  for (unsigned MemOp : {G_LOAD, G_STORE})
    for (auto Ty : {v4s32, v2s64})
      LegacyInfo.setAction({MemOp, Ty}, LegacyLegalizeActions::Legal);

  // Merge/Unmerge
  for (const auto &Ty : {v4s32, v2s64}) {
    LegacyInfo.setAction({G_CONCAT_VECTORS, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, 1, Ty},
                         LegacyLegalizeActions::Legal);
  }
  LegacyInfo.setAction({G_MERGE_VALUES, 1, s64}, LegacyLegalizeActions::Legal);
  LegacyInfo.setAction({G_UNMERGE_VALUES, s64}, LegacyLegalizeActions::Legal);
}

void X86LegalizerInfo::setLegalizerInfoSSE2() {
  if (!Subtarget.hasSSE2())
    return;

  const LLT s32 = LLT::scalar(32);
  const LLT s64 = LLT::scalar(64);
  const LLT v16s8 = LLT::fixed_vector(16, 8);
  const LLT v8s16 = LLT::fixed_vector(8, 16);
  const LLT v4s32 = LLT::fixed_vector(4, 32);
  const LLT v2s64 = LLT::fixed_vector(2, 64);

  const LLT v32s8 = LLT::fixed_vector(32, 8);
  const LLT v16s16 = LLT::fixed_vector(16, 16);
  const LLT v8s32 = LLT::fixed_vector(8, 32);
  const LLT v4s64 = LLT::fixed_vector(4, 64);

  auto &LegacyInfo = getLegacyLegalizerInfo();

  LegacyInfo.setAction({G_FPEXT, s64}, LegacyLegalizeActions::Legal);
  LegacyInfo.setAction({G_FPEXT, 1, s32}, LegacyLegalizeActions::Legal);

  LegacyInfo.setAction({G_FPTRUNC, s32}, LegacyLegalizeActions::Legal);
  LegacyInfo.setAction({G_FPTRUNC, 1, s64}, LegacyLegalizeActions::Legal);

  // Merge/Unmerge
  for (const auto &Ty :
       {v16s8, v32s8, v8s16, v16s16, v4s32, v8s32, v2s64, v4s64}) {
    LegacyInfo.setAction({G_CONCAT_VECTORS, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, 1, Ty},
                         LegacyLegalizeActions::Legal);
  }
  for (const auto &Ty : {v16s8, v8s16, v4s32, v2s64}) {
    LegacyInfo.setAction({G_CONCAT_VECTORS, 1, Ty},
                         LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, Ty}, LegacyLegalizeActions::Legal);
  }
}

void X86LegalizerInfo::setLegalizerInfoAVX() {
  if (!Subtarget.hasAVX())
    return;

  const LLT v16s8 = LLT::fixed_vector(16, 8);
  const LLT v8s16 = LLT::fixed_vector(8, 16);
  const LLT v4s32 = LLT::fixed_vector(4, 32);
  const LLT v2s64 = LLT::fixed_vector(2, 64);

  const LLT v32s8 = LLT::fixed_vector(32, 8);
  const LLT v64s8 = LLT::fixed_vector(64, 8);
  const LLT v16s16 = LLT::fixed_vector(16, 16);
  const LLT v32s16 = LLT::fixed_vector(32, 16);
  const LLT v8s32 = LLT::fixed_vector(8, 32);
  const LLT v16s32 = LLT::fixed_vector(16, 32);
  const LLT v4s64 = LLT::fixed_vector(4, 64);
  const LLT v8s64 = LLT::fixed_vector(8, 64);

  auto &LegacyInfo = getLegacyLegalizerInfo();

  for (unsigned MemOp : {G_LOAD, G_STORE})
    for (auto Ty : {v8s32, v4s64})
      LegacyInfo.setAction({MemOp, Ty}, LegacyLegalizeActions::Legal);

  for (auto Ty : {v32s8, v16s16, v8s32, v4s64}) {
    LegacyInfo.setAction({G_INSERT, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_EXTRACT, 1, Ty}, LegacyLegalizeActions::Legal);
  }
  for (auto Ty : {v16s8, v8s16, v4s32, v2s64}) {
    LegacyInfo.setAction({G_INSERT, 1, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_EXTRACT, Ty}, LegacyLegalizeActions::Legal);
  }
  // Merge/Unmerge
  for (const auto &Ty :
       {v32s8, v64s8, v16s16, v32s16, v8s32, v16s32, v4s64, v8s64}) {
    LegacyInfo.setAction({G_CONCAT_VECTORS, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, 1, Ty},
                         LegacyLegalizeActions::Legal);
  }
  for (const auto &Ty :
       {v16s8, v32s8, v8s16, v16s16, v4s32, v8s32, v2s64, v4s64}) {
    LegacyInfo.setAction({G_CONCAT_VECTORS, 1, Ty},
                         LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, Ty}, LegacyLegalizeActions::Legal);
  }
}

void X86LegalizerInfo::setLegalizerInfoAVX2() {
  if (!Subtarget.hasAVX2())
    return;

  const LLT v32s8 = LLT::fixed_vector(32, 8);
  const LLT v16s16 = LLT::fixed_vector(16, 16);
  const LLT v8s32 = LLT::fixed_vector(8, 32);
  const LLT v4s64 = LLT::fixed_vector(4, 64);

  const LLT v64s8 = LLT::fixed_vector(64, 8);
  const LLT v32s16 = LLT::fixed_vector(32, 16);
  const LLT v16s32 = LLT::fixed_vector(16, 32);
  const LLT v8s64 = LLT::fixed_vector(8, 64);

  auto &LegacyInfo = getLegacyLegalizerInfo();

  // Merge/Unmerge
  for (const auto &Ty : {v64s8, v32s16, v16s32, v8s64}) {
    LegacyInfo.setAction({G_CONCAT_VECTORS, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, 1, Ty},
                         LegacyLegalizeActions::Legal);
  }
  for (const auto &Ty : {v32s8, v16s16, v8s32, v4s64}) {
    LegacyInfo.setAction({G_CONCAT_VECTORS, 1, Ty},
                         LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_UNMERGE_VALUES, Ty}, LegacyLegalizeActions::Legal);
  }
}

void X86LegalizerInfo::setLegalizerInfoAVX512() {
  if (!Subtarget.hasAVX512())
    return;

  const LLT v16s8 = LLT::fixed_vector(16, 8);
  const LLT v8s16 = LLT::fixed_vector(8, 16);
  const LLT v4s32 = LLT::fixed_vector(4, 32);
  const LLT v2s64 = LLT::fixed_vector(2, 64);

  const LLT v32s8 = LLT::fixed_vector(32, 8);
  const LLT v16s16 = LLT::fixed_vector(16, 16);
  const LLT v8s32 = LLT::fixed_vector(8, 32);
  const LLT v4s64 = LLT::fixed_vector(4, 64);

  const LLT v64s8 = LLT::fixed_vector(64, 8);
  const LLT v32s16 = LLT::fixed_vector(32, 16);
  const LLT v16s32 = LLT::fixed_vector(16, 32);
  const LLT v8s64 = LLT::fixed_vector(8, 64);

  auto &LegacyInfo = getLegacyLegalizerInfo();

  for (unsigned MemOp : {G_LOAD, G_STORE})
    for (auto Ty : {v16s32, v8s64})
      LegacyInfo.setAction({MemOp, Ty}, LegacyLegalizeActions::Legal);

  for (auto Ty : {v64s8, v32s16, v16s32, v8s64}) {
    LegacyInfo.setAction({G_INSERT, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_EXTRACT, 1, Ty}, LegacyLegalizeActions::Legal);
  }
  for (auto Ty : {v32s8, v16s16, v8s32, v4s64, v16s8, v8s16, v4s32, v2s64}) {
    LegacyInfo.setAction({G_INSERT, 1, Ty}, LegacyLegalizeActions::Legal);
    LegacyInfo.setAction({G_EXTRACT, Ty}, LegacyLegalizeActions::Legal);
  }
}
