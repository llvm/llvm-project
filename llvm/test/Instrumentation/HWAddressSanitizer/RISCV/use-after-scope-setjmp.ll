; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; RUN: opt -passes=hwasan -hwasan-use-stack-safety=0 -hwasan-use-after-scope -hwasan-inline-fast-path-checks=0 -S < %s | FileCheck %s
target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
target triple = "riscv64-unknown-linux"

@stackbuf = dso_local local_unnamed_addr global ptr null, align 8
@jbuf = dso_local global [32 x i64] zeroinitializer, align 8

declare void @may_jump()

define dso_local noundef i1 @_Z6targetv() sanitize_hwaddress {
; CHECK-LABEL: define dso_local noundef i1 @_Z6targetv
; CHECK-SAME: () #[[ATTR0:[0-9]+]] personality ptr @__hwasan_personality_thunk {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, ptr @__hwasan_tls, align 8
; CHECK-NEXT:    [[TMP1:%.*]] = shl i64 [[TMP0]], 8
; CHECK-NEXT:    [[TMP2:%.*]] = ashr i64 [[TMP1]], 8
; CHECK-NEXT:    [[TMP3:%.*]] = ashr i64 [[TMP0]], 3
; CHECK-NEXT:    [[TMP4:%.*]] = call ptr @llvm.frameaddress.p0(i32 0)
; CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint ptr [[TMP4]] to i64
; CHECK-NEXT:    [[TMP6:%.*]] = shl i64 [[TMP5]], 44
; CHECK-NEXT:    [[TMP7:%.*]] = or i64 ptrtoint (ptr @_Z6targetv to i64), [[TMP6]]
; CHECK-NEXT:    [[TMP8:%.*]] = inttoptr i64 [[TMP2]] to ptr
; CHECK-NEXT:    store i64 [[TMP7]], ptr [[TMP8]], align 8
; CHECK-NEXT:    [[TMP9:%.*]] = ashr i64 [[TMP0]], 56
; CHECK-NEXT:    [[TMP10:%.*]] = shl nuw nsw i64 [[TMP9]], 12
; CHECK-NEXT:    [[TMP11:%.*]] = xor i64 [[TMP10]], -1
; CHECK-NEXT:    [[TMP12:%.*]] = add i64 [[TMP0]], 8
; CHECK-NEXT:    [[TMP13:%.*]] = and i64 [[TMP12]], [[TMP11]]
; CHECK-NEXT:    store i64 [[TMP13]], ptr @__hwasan_tls, align 8
; CHECK-NEXT:    [[TMP14:%.*]] = or i64 [[TMP2]], 4294967295
; CHECK-NEXT:    [[HWASAN_SHADOW:%.*]] = add i64 [[TMP14]], 1
; CHECK-NEXT:    [[TMP15:%.*]] = inttoptr i64 [[HWASAN_SHADOW]] to ptr
; CHECK-NEXT:    [[HWASAN_UAR_TAG:%.*]] = lshr i64 [[TMP5]], 56
; CHECK-NEXT:    [[BUF:%.*]] = alloca [4096 x i8], align 16
; CHECK-NEXT:    [[TMP16:%.*]] = xor i64 [[TMP3]], 0
; CHECK-NEXT:    [[TMP17:%.*]] = ptrtoint ptr [[BUF]] to i64
; CHECK-NEXT:    [[TMP18:%.*]] = shl i64 [[TMP17]], 8
; CHECK-NEXT:    [[TMP19:%.*]] = ashr i64 [[TMP18]], 8
; CHECK-NEXT:    [[TMP20:%.*]] = shl i64 [[TMP16]], 56
; CHECK-NEXT:    [[TMP21:%.*]] = or i64 [[TMP19]], [[TMP20]]
; CHECK-NEXT:    [[BUF_HWASAN:%.*]] = inttoptr i64 [[TMP21]] to ptr
; CHECK-NEXT:    [[TMP22:%.*]] = trunc i64 [[TMP16]] to i8
; CHECK-NEXT:    [[TMP23:%.*]] = ptrtoint ptr [[BUF]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = shl i64 [[TMP23]], 8
; CHECK-NEXT:    [[TMP25:%.*]] = ashr i64 [[TMP24]], 8
; CHECK-NEXT:    [[TMP26:%.*]] = ashr i64 [[TMP25]], 4
; CHECK-NEXT:    [[TMP27:%.*]] = getelementptr i8, ptr [[TMP15]], i64 [[TMP26]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 1 [[TMP27]], i8 [[TMP22]], i64 256, i1 false)
; CHECK-NEXT:    [[CALL:%.*]] = call i32 @setjmp(ptr noundef @jbuf)
; CHECK-NEXT:    switch i32 [[CALL]], label [[WHILE_BODY:%.*]] [
; CHECK-NEXT:      i32 1, label [[RETURN:%.*]]
; CHECK-NEXT:      i32 2, label [[SW_BB1:%.*]]
; CHECK-NEXT:    ]
; CHECK:       sw.bb1:
; CHECK-NEXT:    br label [[RETURN]]
; CHECK:       while.body:
; CHECK-NEXT:    call void @llvm.hwasan.check.memaccess.shortgranules(ptr [[TMP15]], ptr @stackbuf, i32 19)
; CHECK-NEXT:    store ptr [[BUF_HWASAN]], ptr @stackbuf, align 8
; CHECK-NEXT:    call void @may_jump()
; CHECK-NEXT:    br label [[RETURN]]
; CHECK:       return:
; CHECK-NEXT:    [[RETVAL_0:%.*]] = phi i1 [ true, [[WHILE_BODY]] ], [ true, [[SW_BB1]] ], [ false, [[ENTRY:%.*]] ]
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[HWASAN_UAR_TAG]] to i8
; CHECK-NEXT:    [[TMP29:%.*]] = ptrtoint ptr [[BUF]] to i64
; CHECK-NEXT:    [[TMP30:%.*]] = shl i64 [[TMP29]], 8
; CHECK-NEXT:    [[TMP31:%.*]] = ashr i64 [[TMP30]], 8
; CHECK-NEXT:    [[TMP32:%.*]] = ashr i64 [[TMP31]], 4
; CHECK-NEXT:    [[TMP33:%.*]] = getelementptr i8, ptr [[TMP15]], i64 [[TMP32]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 1 [[TMP33]], i8 [[TMP28]], i64 256, i1 false)
; CHECK-NEXT:    ret i1 [[RETVAL_0]]
;
entry:
  %buf = alloca [4096 x i8], align 1
  %call = call i32 @setjmp(ptr noundef @jbuf)
  switch i32 %call, label %while.body [
  i32 1, label %return
  i32 2, label %sw.bb1
  ]

sw.bb1:                                           ; preds = %entry
  br label %return

while.body:                                       ; preds = %entry
  call void @llvm.lifetime.start.p0(i64 4096, ptr nonnull %buf) #10
  store ptr %buf, ptr @stackbuf, align 8
  ; may_jump may call longjmp, going back to the switch (and then the return),
  ; bypassing the lifetime.end. This is why we need to untag on the return,
  ; rather than the lifetime.end.
  call void @may_jump()
  call void @llvm.lifetime.end.p0(i64 4096, ptr nonnull %buf) #10
  br label %return

return:                                           ; preds = %entry, %while.body, %sw.bb1
  %retval.0 = phi i1 [ true, %while.body ], [ true, %sw.bb1 ], [ false, %entry ]
  ret i1 %retval.0
}

declare i32 @setjmp(ptr noundef) returns_twice

declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture)
