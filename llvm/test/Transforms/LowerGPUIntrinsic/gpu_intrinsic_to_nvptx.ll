; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-attributes
; RUN: opt -S -mtriple=nvptx64-- -passes=lower-gpu-intrinsic < %s | FileCheck %s --check-prefix=NVPTX

define i32 @num_blocks_x() {
; NVPTX-LABEL: @num_blocks_x(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.nctaid.x()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.num.blocks.x()
  ret i32 %1
}

declare i32 @llvm.gpu.num.blocks.x()

define i32 @num_blocks_y() {
; NVPTX-LABEL: @num_blocks_y(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.nctaid.y()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.num.blocks.y()
  ret i32 %1
}

declare i32 @llvm.gpu.num.blocks.y()

define i32 @num_blocks_z() {
; NVPTX-LABEL: @num_blocks_z(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.nctaid.z()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.num.blocks.z()
  ret i32 %1
}

declare i32 @llvm.gpu.num.blocks.z()

define i32 @block_id_x() {
; NVPTX-LABEL: @block_id_x(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.block.id.x()
  ret i32 %1
}

declare i32 @llvm.gpu.block.id.x()

define i32 @block_id_y() {
; NVPTX-LABEL: @block_id_y(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.block.id.y()
  ret i32 %1
}

declare i32 @llvm.gpu.block.id.y()

define i32 @block_id_z() {
; NVPTX-LABEL: @block_id_z(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.z()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.block.id.z()
  ret i32 %1
}

declare i32 @llvm.gpu.block.id.z()

define i32 @num_threads_x() {
; NVPTX-LABEL: @num_threads_x(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.num.threads.x()
  ret i32 %1
}

declare i32 @llvm.gpu.num.threads.x()

define i32 @num_threads_y() {
; NVPTX-LABEL: @num_threads_y(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.num.threads.y()
  ret i32 %1
}

declare i32 @llvm.gpu.num.threads.y()

define i32 @num_threads_z() {
; NVPTX-LABEL: @num_threads_z(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ntid.z()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.num.threads.z()
  ret i32 %1
}

declare i32 @llvm.gpu.num.threads.z()

define i32 @thread_id_x() {
; NVPTX-LABEL: @thread_id_x(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.thread.id.x()
  ret i32 %1
}

declare i32 @llvm.gpu.thread.id.x()

define i32 @thread_id_y() {
; NVPTX-LABEL: @thread_id_y(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.y()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.thread.id.y()
  ret i32 %1
}

declare i32 @llvm.gpu.thread.id.y()

define i32 @thread_id_z() {
; NVPTX-LABEL: @thread_id_z(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.z()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.thread.id.z()
  ret i32 %1
}

declare i32 @llvm.gpu.thread.id.z()

define i32 @num_lanes() {
; NVPTX-LABEL: @num_lanes(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.warpsize()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.num.lanes()
  ret i32 %1
}

declare i32 @llvm.gpu.num.lanes()

define i32 @lane_id() {
; NVPTX-LABEL: @lane_id(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.read.ptx.sreg.laneid()
; NVPTX-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.lane.id()
  ret i32 %1
}

declare i32 @llvm.gpu.lane.id()

define i64 @lane_mask() {
; NVPTX-LABEL: @lane_mask(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.activemask()
; NVPTX-NEXT:    [[CONV:%.*]] = zext i32 [[TMP1]] to i64
; NVPTX-NEXT:    ret i64 [[CONV]]
;
  %1 = call i64 @llvm.gpu.lane.mask()
  ret i64 %1
}

declare i64 @llvm.gpu.lane.mask()

define i32 @read_first_lane_u32(i64 %lane_mask, i32 %x)  {
; NVPTX-LABEL: @read_first_lane_u32(
; NVPTX-NEXT:    [[CONV:%.*]] = trunc i64 [[LANE_MASK:%.*]] to i32
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.cttz.i32(i32 [[CONV]], i1 true)
; NVPTX-NEXT:    [[ISZERO:%.*]] = icmp eq i32 [[CONV]], 0
; NVPTX-NEXT:    [[SUB:%.*]] = select i1 [[ISZERO]], i32 -1, i32 [[TMP1]]
; NVPTX-NEXT:    [[TMP2:%.*]] = call i32 @llvm.nvvm.shfl.sync.idx.i32(i32 [[CONV]], i32 [[X:%.*]], i32 [[SUB]], i32 31)
; NVPTX-NEXT:    ret i32 [[TMP2]]
;
  %1 = call i32 @llvm.gpu.read.first.lane.u32(i64 %lane_mask, i32 %x)
  ret i32 %1
}

declare i32 @llvm.gpu.read.first.lane.u32(i64, i32)

define i64 @ballot(i64 %lane_mask, i1 zeroext %x)  {
; NVPTX-LABEL: @ballot(
; NVPTX-NEXT:    [[CONV:%.*]] = trunc i64 [[LANE_MASK:%.*]] to i32
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.vote.ballot.sync(i32 [[CONV]], i1 [[X:%.*]])
; NVPTX-NEXT:    [[CONV1:%.*]] = zext i32 [[TMP1]] to i64
; NVPTX-NEXT:    ret i64 [[CONV1]]
;
  %1 = call i64 @llvm.gpu.ballot(i64 %lane_mask, i1 %x)
  ret i64 %1
}

declare i64 @llvm.gpu.ballot(i64, i1)

define void @sync_threads() {
; NVPTX-LABEL: @sync_threads(
; NVPTX-NEXT:    call void @llvm.nvvm.barrier0()
; NVPTX-NEXT:    ret void
;
  call void @llvm.gpu.sync.threads()
  ret void
}

declare void @llvm.gpu.sync.threads()

define void @sync_lane(i64 %lane_mask) {
; NVPTX-LABEL: @sync_lane(
; NVPTX-NEXT:    [[TMP1:%.*]] = trunc i64 [[LANE_MASK:%.*]] to i32
; NVPTX-NEXT:    call void @llvm.nvvm.bar.warp.sync(i32 [[TMP1]])
; NVPTX-NEXT:    ret void
;
  call void @llvm.gpu.sync.lane(i64 %lane_mask)
  ret void
}

declare void @llvm.gpu.sync.lane(i64)

define i32 @shuffle_idx_u32(i64 %lane_mask, i32 %idx, i32 %x, i32 %width)  {
; NVPTX-LABEL: @shuffle_idx_u32(
; NVPTX-NEXT:    [[CONV:%.*]] = trunc i64 [[LANE_MASK:%.*]] to i32
; NVPTX-NEXT:    [[SH_PROM:%.*]] = zext i32 [[IDX:%.*]] to i64
; NVPTX-NEXT:    [[TMP1:%.*]] = shl i32 [[WIDTH:%.*]], 8
; NVPTX-NEXT:    [[OR:%.*]] = sub i32 8223, [[TMP1]]
; NVPTX-NEXT:    [[TMP2:%.*]] = call i32 @llvm.nvvm.shfl.sync.idx.i32(i32 [[CONV]], i32 [[X:%.*]], i32 [[IDX]], i32 [[OR]])
; NVPTX-NEXT:    [[TMP3:%.*]] = shl i64 1, [[SH_PROM]]
; NVPTX-NEXT:    [[TMP4:%.*]] = and i64 [[TMP3]], [[LANE_MASK]]
; NVPTX-NEXT:    [[TMP5:%.*]] = icmp eq i64 [[TMP4]], 0
; NVPTX-NEXT:    [[AND4:%.*]] = select i1 [[TMP5]], i32 0, i32 [[TMP2]]
; NVPTX-NEXT:    ret i32 [[AND4]]
;
  %1 = call i32 @llvm.gpu.shuffle.idx.u32(i64 %lane_mask, i32 %idx, i32 %x, i32 %width)
  ret i32 %1
}

declare i32 @llvm.gpu.shuffle.idx.u32(i64, i32, i32, i32)

define void @gpu_exit() {
; NVPTX-LABEL: @gpu_exit(
; NVPTX-NEXT:    call void @llvm.nvvm.exit()
; NVPTX-NEXT:    ret void
;
  call void @llvm.gpu.exit()
  ret void
}

declare void @llvm.gpu.exit()

define void @thread_suspend() {
; NVPTX-LABEL: @thread_suspend(
; NVPTX-NEXT:    [[TMP1:%.*]] = call i32 @llvm.nvvm.reflect(ptr @[[GLOB0:[0-9]+]])
; NVPTX-NEXT:    [[TMP2:%.*]] = icmp ugt i32 [[TMP1]], 699
; NVPTX-NEXT:    br i1 [[TMP2]], label [[TMP3:%.*]], label [[TMP4:%.*]]
; NVPTX:       3:
; NVPTX-NEXT:    call void @llvm.nvvm.nanosleep(i32 64)
; NVPTX-NEXT:    br label [[TMP4]]
; NVPTX:       4:
; NVPTX-NEXT:    ret void
;
  call void @llvm.gpu.thread.suspend()
  ret void
}

declare void @llvm.gpu.thread.suspend()
