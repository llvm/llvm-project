; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-attributes
; RUN: opt -S -mtriple=amdgcn-- -passes=lower-gpu-intrinsic < %s | FileCheck %s --check-prefix=AMDGCN

@__oclc_ABI_version = weak_odr hidden addrspace(4) constant i32 500

define i32 @num_blocks_x() {
; AMDGCN-LABEL: @num_blocks_x(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP1]], i32 12
; AMDGCN-NEXT:    [[TMP3:%.*]] = load i32, ptr addrspace(4) [[TMP2]], align 4, !range [[RNG0:![0-9]+]], !invariant.load [[META1:![0-9]+]]
; AMDGCN-NEXT:    [[TMP4:%.*]] = load i32, ptr addrspace(4) @__oclc_ABI_version, align 4
; AMDGCN-NEXT:    [[TMP5:%.*]] = icmp sge i32 [[TMP4]], 500
; AMDGCN-NEXT:    [[TMP6:%.*]] = call align 8 dereferenceable(256) ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr()
; AMDGCN-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP6]], i32 12
; AMDGCN-NEXT:    [[TMP8:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP8]], i32 4
; AMDGCN-NEXT:    [[TMP10:%.*]] = select i1 [[TMP5]], ptr addrspace(4) [[TMP7]], ptr addrspace(4) [[TMP9]]
; AMDGCN-NEXT:    [[TMP11:%.*]] = load i16, ptr addrspace(4) [[TMP10]], align 2, !invariant.load [[META1]], !noundef [[META1]]
; AMDGCN-NEXT:    [[TMP12:%.*]] = zext i16 [[TMP11]] to i32
; AMDGCN-NEXT:    [[TMP13:%.*]] = udiv i32 [[TMP3]], [[TMP12]]
; AMDGCN-NEXT:    ret i32 [[TMP13]]
;
  %1 = call i32 @llvm.gpu.num.blocks.x()
  ret i32 %1
}

declare i32 @llvm.gpu.num.blocks.x()

define i32 @num_blocks_y() {
; AMDGCN-LABEL: @num_blocks_y(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP1]], i32 16
; AMDGCN-NEXT:    [[TMP3:%.*]] = load i32, ptr addrspace(4) [[TMP2]], align 4, !range [[RNG0]], !invariant.load [[META1]]
; AMDGCN-NEXT:    [[TMP4:%.*]] = load i32, ptr addrspace(4) @__oclc_ABI_version, align 4
; AMDGCN-NEXT:    [[TMP5:%.*]] = icmp sge i32 [[TMP4]], 500
; AMDGCN-NEXT:    [[TMP6:%.*]] = call align 8 dereferenceable(256) ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr()
; AMDGCN-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP6]], i32 14
; AMDGCN-NEXT:    [[TMP8:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP8]], i32 6
; AMDGCN-NEXT:    [[TMP10:%.*]] = select i1 [[TMP5]], ptr addrspace(4) [[TMP7]], ptr addrspace(4) [[TMP9]]
; AMDGCN-NEXT:    [[TMP11:%.*]] = load i16, ptr addrspace(4) [[TMP10]], align 2, !invariant.load [[META1]], !noundef [[META1]]
; AMDGCN-NEXT:    [[TMP12:%.*]] = zext i16 [[TMP11]] to i32
; AMDGCN-NEXT:    [[TMP13:%.*]] = udiv i32 [[TMP3]], [[TMP12]]
; AMDGCN-NEXT:    ret i32 [[TMP13]]
;
  %1 = call i32 @llvm.gpu.num.blocks.y()
  ret i32 %1
}

declare i32 @llvm.gpu.num.blocks.y()

define i32 @num_blocks_z() {
; AMDGCN-LABEL: @num_blocks_z(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP2:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP1]], i32 20
; AMDGCN-NEXT:    [[TMP3:%.*]] = load i32, ptr addrspace(4) [[TMP2]], align 4, !range [[RNG0]], !invariant.load [[META1]]
; AMDGCN-NEXT:    [[TMP4:%.*]] = load i32, ptr addrspace(4) @__oclc_ABI_version, align 4
; AMDGCN-NEXT:    [[TMP5:%.*]] = icmp sge i32 [[TMP4]], 500
; AMDGCN-NEXT:    [[TMP6:%.*]] = call align 8 dereferenceable(256) ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr()
; AMDGCN-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP6]], i32 16
; AMDGCN-NEXT:    [[TMP8:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP8]], i32 8
; AMDGCN-NEXT:    [[TMP10:%.*]] = select i1 [[TMP5]], ptr addrspace(4) [[TMP7]], ptr addrspace(4) [[TMP9]]
; AMDGCN-NEXT:    [[TMP11:%.*]] = load i16, ptr addrspace(4) [[TMP10]], align 2, !invariant.load [[META1]], !noundef [[META1]]
; AMDGCN-NEXT:    [[TMP12:%.*]] = zext i16 [[TMP11]] to i32
; AMDGCN-NEXT:    [[TMP13:%.*]] = udiv i32 [[TMP3]], [[TMP12]]
; AMDGCN-NEXT:    ret i32 [[TMP13]]
;
  %1 = call i32 @llvm.gpu.num.blocks.z()
  ret i32 %1
}

declare i32 @llvm.gpu.num.blocks.z()

define i32 @block_id_x() {
; AMDGCN-LABEL: @block_id_x(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.workgroup.id.x()
; AMDGCN-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.block.id.x()
  ret i32 %1
}

declare i32 @llvm.gpu.block.id.x()

define i32 @block_id_y() {
; AMDGCN-LABEL: @block_id_y(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.workgroup.id.y()
; AMDGCN-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.block.id.y()
  ret i32 %1
}

declare i32 @llvm.gpu.block.id.y()

define i32 @block_id_z() {
; AMDGCN-LABEL: @block_id_z(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.workgroup.id.z()
; AMDGCN-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.block.id.z()
  ret i32 %1
}

declare i32 @llvm.gpu.block.id.z()

define i32 @num_threads_x() {
; AMDGCN-LABEL: @num_threads_x(
; AMDGCN-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) @__oclc_ABI_version, align 4
; AMDGCN-NEXT:    [[TMP2:%.*]] = icmp sge i32 [[TMP1]], 500
; AMDGCN-NEXT:    [[TMP3:%.*]] = call align 8 dereferenceable(256) ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr()
; AMDGCN-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP3]], i32 12
; AMDGCN-NEXT:    [[TMP5:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP5]], i32 4
; AMDGCN-NEXT:    [[TMP7:%.*]] = select i1 [[TMP2]], ptr addrspace(4) [[TMP4]], ptr addrspace(4) [[TMP6]]
; AMDGCN-NEXT:    [[TMP8:%.*]] = load i16, ptr addrspace(4) [[TMP7]], align 2, !invariant.load [[META1]], !noundef [[META1]]
; AMDGCN-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP8]] to i32
; AMDGCN-NEXT:    ret i32 [[TMP9]]
;
  %1 = call i32 @llvm.gpu.num.threads.x()
  ret i32 %1
}

declare i32 @llvm.gpu.num.threads.x()

define i32 @num_threads_y() {
; AMDGCN-LABEL: @num_threads_y(
; AMDGCN-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) @__oclc_ABI_version, align 4
; AMDGCN-NEXT:    [[TMP2:%.*]] = icmp sge i32 [[TMP1]], 500
; AMDGCN-NEXT:    [[TMP3:%.*]] = call align 8 dereferenceable(256) ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr()
; AMDGCN-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP3]], i32 14
; AMDGCN-NEXT:    [[TMP5:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP5]], i32 6
; AMDGCN-NEXT:    [[TMP7:%.*]] = select i1 [[TMP2]], ptr addrspace(4) [[TMP4]], ptr addrspace(4) [[TMP6]]
; AMDGCN-NEXT:    [[TMP8:%.*]] = load i16, ptr addrspace(4) [[TMP7]], align 2, !invariant.load [[META1]], !noundef [[META1]]
; AMDGCN-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP8]] to i32
; AMDGCN-NEXT:    ret i32 [[TMP9]]
;
  %1 = call i32 @llvm.gpu.num.threads.y()
  ret i32 %1
}

declare i32 @llvm.gpu.num.threads.y()

define i32 @num_threads_z() {
; AMDGCN-LABEL: @num_threads_z(
; AMDGCN-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) @__oclc_ABI_version, align 4
; AMDGCN-NEXT:    [[TMP2:%.*]] = icmp sge i32 [[TMP1]], 500
; AMDGCN-NEXT:    [[TMP3:%.*]] = call align 8 dereferenceable(256) ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr()
; AMDGCN-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP3]], i32 16
; AMDGCN-NEXT:    [[TMP5:%.*]] = call align 4 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.dispatch.ptr()
; AMDGCN-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP5]], i32 8
; AMDGCN-NEXT:    [[TMP7:%.*]] = select i1 [[TMP2]], ptr addrspace(4) [[TMP4]], ptr addrspace(4) [[TMP6]]
; AMDGCN-NEXT:    [[TMP8:%.*]] = load i16, ptr addrspace(4) [[TMP7]], align 2, !invariant.load [[META1]], !noundef [[META1]]
; AMDGCN-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP8]] to i32
; AMDGCN-NEXT:    ret i32 [[TMP9]]
;
  %1 = call i32 @llvm.gpu.num.threads.z()
  ret i32 %1
}

declare i32 @llvm.gpu.num.threads.z()

define i32 @thread_id_x() {
; AMDGCN-LABEL: @thread_id_x(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.workitem.id.x()
; AMDGCN-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.thread.id.x()
  ret i32 %1
}

declare i32 @llvm.gpu.thread.id.x()

define i32 @thread_id_y() {
; AMDGCN-LABEL: @thread_id_y(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.workitem.id.y()
; AMDGCN-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.thread.id.y()
  ret i32 %1
}

declare i32 @llvm.gpu.thread.id.y()

define i32 @thread_id_z() {
; AMDGCN-LABEL: @thread_id_z(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.workitem.id.z()
; AMDGCN-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.thread.id.z()
  ret i32 %1
}

declare i32 @llvm.gpu.thread.id.z()

define i32 @num_lanes() {
; AMDGCN-LABEL: @num_lanes(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.wavefrontsize()
; AMDGCN-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.num.lanes()
  ret i32 %1
}

declare i32 @llvm.gpu.num.lanes()

define i32 @lane_id() {
; AMDGCN-LABEL: @lane_id(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.mbcnt.lo(i32 -1, i32 0)
; AMDGCN-NEXT:    [[TMP2:%.*]] = call i32 @llvm.amdgcn.mbcnt.hi(i32 -1, i32 [[TMP1]])
; AMDGCN-NEXT:    ret i32 [[TMP2]]
;
  %1 = call i32 @llvm.gpu.lane.id()
  ret i32 %1
}

declare i32 @llvm.gpu.lane.id()

define i64 @lane_mask() {
; AMDGCN-LABEL: @lane_mask(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i64 @llvm.amdgcn.ballot.i64(i1 true)
; AMDGCN-NEXT:    ret i64 [[TMP1]]
;
  %1 = call i64 @llvm.gpu.lane.mask()
  ret i64 %1
}

declare i64 @llvm.gpu.lane.mask()

define i32 @read_first_lane_u32(i64 %lane_mask, i32 %x)  {
; AMDGCN-LABEL: @read_first_lane_u32(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.readfirstlane.i32(i32 [[X:%.*]])
; AMDGCN-NEXT:    ret i32 [[TMP1]]
;
  %1 = call i32 @llvm.gpu.read.first.lane.u32(i64 %lane_mask, i32 %x)
  ret i32 %1
}

declare i32 @llvm.gpu.read.first.lane.u32(i64, i32)

define i64 @ballot(i64 %lane_mask, i1 zeroext %x)  {
; AMDGCN-LABEL: @ballot(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i64 @llvm.amdgcn.ballot.i64(i1 [[X:%.*]])
; AMDGCN-NEXT:    [[TMP2:%.*]] = and i64 [[TMP1]], [[LANE_MASK:%.*]]
; AMDGCN-NEXT:    ret i64 [[TMP2]]
;
  %1 = call i64 @llvm.gpu.ballot(i64 %lane_mask, i1 %x)
  ret i64 %1
}

declare i64 @llvm.gpu.ballot(i64, i1)

define void @sync_threads() {
; AMDGCN-LABEL: @sync_threads(
; AMDGCN-NEXT:    call void @llvm.amdgcn.s.barrier()
; AMDGCN-NEXT:    fence syncscope("workgroup") seq_cst
; AMDGCN-NEXT:    ret void
;
  call void @llvm.gpu.sync.threads()
  ret void
}

declare void @llvm.gpu.sync.threads()

define void @sync_lane(i64 %lane_mask) {
; AMDGCN-LABEL: @sync_lane(
; AMDGCN-NEXT:    call void @llvm.amdgcn.wave.barrier()
; AMDGCN-NEXT:    ret void
;
  call void @llvm.gpu.sync.lane(i64 %lane_mask)
  ret void
}

declare void @llvm.gpu.sync.lane(i64)

define i32 @shuffle_idx_u32(i64 %lane_mask, i32 %idx, i32 %x, i32 %width)  {
; AMDGCN-LABEL: @shuffle_idx_u32(
; AMDGCN-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.mbcnt.lo(i32 -1, i32 0)
; AMDGCN-NEXT:    [[TMP2:%.*]] = call i32 @llvm.amdgcn.mbcnt.hi(i32 -1, i32 [[TMP1]])
; AMDGCN-NEXT:    [[NOT:%.*]] = sub i32 0, [[WIDTH:%.*]]
; AMDGCN-NEXT:    [[AND:%.*]] = and i32 [[TMP2]], [[NOT]]
; AMDGCN-NEXT:    [[ADD:%.*]] = add i32 [[AND]], [[IDX:%.*]]
; AMDGCN-NEXT:    [[SHL:%.*]] = shl i32 [[ADD]], 2
; AMDGCN-NEXT:    [[TMP3:%.*]] = call i32 @llvm.amdgcn.ds.bpermute(i32 [[SHL]], i32 [[X:%.*]])
; AMDGCN-NEXT:    ret i32 [[TMP3]]
;
  %1 = call i32 @llvm.gpu.shuffle.idx.u32(i64 %lane_mask, i32 %idx, i32 %x, i32 %width)
  ret i32 %1
}

declare i32 @llvm.gpu.shuffle.idx.u32(i64, i32, i32, i32)

define void @gpu_exit() {
; AMDGCN-LABEL: @gpu_exit(
; AMDGCN-NEXT:    call void @llvm.amdgcn.endpgm()
; AMDGCN-NEXT:    ret void
;
  call void @llvm.gpu.exit()
  ret void
}

declare void @llvm.gpu.exit()

define void @thread_suspend() {
; AMDGCN-LABEL: @thread_suspend(
; AMDGCN-NEXT:    call void @llvm.amdgcn.s.sleep(i32 2)
; AMDGCN-NEXT:    ret void
;
  call void @llvm.gpu.thread.suspend()
  ret void
}

declare void @llvm.gpu.thread.suspend()
