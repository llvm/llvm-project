; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -passes=objc-arc -S < %s | FileCheck %s

%struct.__objcFastEnumerationState = type { i64, ptr, ptr, [5 x i64] }

@"\01L_OBJC_METH_VAR_NAME_" = internal global [43 x i8] c"countByEnumeratingWithState:objects:count:\00", section "__TEXT,__objc_methname,cstring_literals", align 1
@"\01L_OBJC_SELECTOR_REFERENCES_" = internal global ptr @"\01L_OBJC_METH_VAR_NAME_", section "__DATA, __objc_selrefs, literal_pointers, no_dead_strip"
@g = common global ptr null, align 8
@"\01L_OBJC_IMAGE_INFO" = internal constant [2 x i32] [i32 0, i32 16], section "__DATA, __objc_imageinfo, regular, no_dead_strip"

declare void @callee()
declare ptr @returner()
declare ptr @llvm.objc.retainAutoreleasedReturnValue(ptr)
declare ptr @llvm.objc.retain(ptr)
declare void @llvm.objc.enumerationMutation(ptr)
declare void @llvm.memset.p0.i64(ptr nocapture, i8, i64, i1) nounwind
declare ptr @objc_msgSend(ptr, ptr, ...) nonlazybind
declare void @use(ptr)
declare void @llvm.objc.release(ptr)
declare ptr @def()
declare void @__crasher_block_invoke(ptr nocapture)
declare ptr @llvm.objc.retainBlock(ptr)
declare void @__crasher_block_invoke1(ptr nocapture)

!0 = !{}

; Delete a nested retain+release pair.

define void @test0(ptr %a) nounwind {
; CHECK-LABEL: define void @test0(
; CHECK-SAME: ptr [[A:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retain(ptr [[A]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL:%.*]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP2]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    [[STATEITEMS_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL6:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP7:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP7]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ], [ [[TMP3:%.*]], %[[FORCOLL_NOTMUTATED:.*]] ]
; CHECK-NEXT:    [[MUTATIONSPTR3:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR3]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP1]], label %[[FORCOLL_NOTMUTATED]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP0]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[STATEITEMS:%.*]] = load ptr, ptr [[STATEITEMS_PTR]], align 8
; CHECK-NEXT:    [[CURRENTITEM_PTR:%.*]] = getelementptr ptr, ptr [[STATEITEMS]], i64 [[FORCOLL_INDEX]]
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[CURRENTITEM_PTR]], align 8
; CHECK-NEXT:    call void @use(ptr [[TMP2]])
; CHECK-NEXT:    [[TMP3]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[TMP3]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP5:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL6]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP5]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL6]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0:![0-9]+]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %0 = call ptr @llvm.objc.retain(ptr %a) nounwind
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %1 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp2 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call = call i64 @objc_msgSend(ptr %1, ptr %tmp2, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  %stateitems.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 1
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call, %forcoll.loopinit ], [ %call6, %forcoll.refetch ]
  %tmp7 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp7, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ 0, %forcoll.loopbody.outer ], [ %4, %forcoll.notmutated ]
  %mutationsptr3 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr3, align 8
  %2 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %2, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %1)
  br label %forcoll.notmutated

forcoll.notmutated:
  %stateitems = load ptr, ptr %stateitems.ptr, align 8
  %currentitem.ptr = getelementptr ptr, ptr %stateitems, i64 %forcoll.index
  %3 = load ptr, ptr %currentitem.ptr, align 8
  call void @use(ptr %3)
  %4 = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %4, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp5 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call6 = call i64 @objc_msgSend(ptr %1, ptr %tmp5, ptr %state.ptr, ptr %items.ptr, i64 16)
  %5 = icmp eq i64 %call6, 0
  br i1 %5, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %1) nounwind
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; Delete a nested retain+release pair.

define void @test2() nounwind {
; CHECK-LABEL: define void @test2(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL3:%.*]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP2]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL3]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    [[STATEITEMS_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL3]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP8]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ], [ [[TMP3:%.*]], %[[FORCOLL_NOTMUTATED:.*]] ]
; CHECK-NEXT:    [[MUTATIONSPTR4:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR4]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP1]], label %[[FORCOLL_NOTMUTATED]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP0]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[STATEITEMS:%.*]] = load ptr, ptr [[STATEITEMS_PTR]], align 8
; CHECK-NEXT:    [[CURRENTITEM_PTR:%.*]] = getelementptr ptr, ptr [[STATEITEMS]], i64 [[FORCOLL_INDEX]]
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[CURRENTITEM_PTR]], align 8
; CHECK-NEXT:    call void @use(ptr [[TMP2]])
; CHECK-NEXT:    [[TMP3]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[TMP3]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %1 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp2 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call3 = call i64 @objc_msgSend(ptr %1, ptr %tmp2, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call3, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  %stateitems.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 1
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call3, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp8 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp8, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ 0, %forcoll.loopbody.outer ], [ %4, %forcoll.notmutated ]
  %mutationsptr4 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr4, align 8
  %2 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %2, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %1)
  br label %forcoll.notmutated

forcoll.notmutated:
  %stateitems = load ptr, ptr %stateitems.ptr, align 8
  %currentitem.ptr = getelementptr ptr, ptr %stateitems, i64 %forcoll.index
  %3 = load ptr, ptr %currentitem.ptr, align 8
  call void @use(ptr %3)
  %4 = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %4, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %1, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %5 = icmp eq i64 %call7, 0
  br i1 %5, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %1) nounwind
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; Delete a nested retain+release pair.

define void @test4() nounwind {
; CHECK-LABEL: define void @test4(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[TMP:%.*]] = load ptr, ptr @g, align 8
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retain(ptr [[TMP]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL:%.*]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP4]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    [[STATEITEMS_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL8:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP9]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ], [ [[TMP3:%.*]], %[[FORCOLL_NOTMUTATED:.*]] ]
; CHECK-NEXT:    [[MUTATIONSPTR5:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR5]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP1]], label %[[FORCOLL_NOTMUTATED]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP0]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[STATEITEMS:%.*]] = load ptr, ptr [[STATEITEMS_PTR]], align 8
; CHECK-NEXT:    [[CURRENTITEM_PTR:%.*]] = getelementptr ptr, ptr [[STATEITEMS]], i64 [[FORCOLL_INDEX]]
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[CURRENTITEM_PTR]], align 8
; CHECK-NEXT:    call void @use(ptr [[TMP2]])
; CHECK-NEXT:    [[TMP3]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[TMP3]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL8]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP7]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL8]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %tmp = load ptr, ptr @g, align 8
  %0 = call ptr @llvm.objc.retain(ptr %tmp) nounwind
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %1 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp4 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call = call i64 @objc_msgSend(ptr %1, ptr %tmp4, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  %stateitems.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 1
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call, %forcoll.loopinit ], [ %call8, %forcoll.refetch ]
  %tmp9 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp9, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ 0, %forcoll.loopbody.outer ], [ %4, %forcoll.notmutated ]
  %mutationsptr5 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr5, align 8
  %2 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %2, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %1)
  br label %forcoll.notmutated

forcoll.notmutated:
  %stateitems = load ptr, ptr %stateitems.ptr, align 8
  %currentitem.ptr = getelementptr ptr, ptr %stateitems, i64 %forcoll.index
  %3 = load ptr, ptr %currentitem.ptr, align 8
  call void @use(ptr %3)
  %4 = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %4, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp7 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call8 = call i64 @objc_msgSend(ptr %1, ptr %tmp7, ptr %state.ptr, ptr %items.ptr, i64 16)
  %5 = icmp eq i64 %call8, 0
  br i1 %5, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %1) nounwind
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; Delete a nested retain+release pair.

define void @test5() nounwind {
; CHECK-LABEL: define void @test5(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL3:%.*]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP2]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL3]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    [[STATEITEMS_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL3]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP8]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ], [ [[TMP3:%.*]], %[[FORCOLL_NOTMUTATED:.*]] ]
; CHECK-NEXT:    [[MUTATIONSPTR4:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR4]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP1]], label %[[FORCOLL_NOTMUTATED]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP0]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[STATEITEMS:%.*]] = load ptr, ptr [[STATEITEMS_PTR]], align 8
; CHECK-NEXT:    [[CURRENTITEM_PTR:%.*]] = getelementptr ptr, ptr [[STATEITEMS]], i64 [[FORCOLL_INDEX]]
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[CURRENTITEM_PTR]], align 8
; CHECK-NEXT:    call void @use(ptr [[TMP2]])
; CHECK-NEXT:    [[TMP3]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[TMP3]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %1 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp2 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call3 = call i64 @objc_msgSend(ptr %1, ptr %tmp2, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call3, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  %stateitems.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 1
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call3, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp8 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp8, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ 0, %forcoll.loopbody.outer ], [ %4, %forcoll.notmutated ]
  %mutationsptr4 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr4, align 8
  %2 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %2, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %1)
  br label %forcoll.notmutated

forcoll.notmutated:
  %stateitems = load ptr, ptr %stateitems.ptr, align 8
  %currentitem.ptr = getelementptr ptr, ptr %stateitems, i64 %forcoll.index
  %3 = load ptr, ptr %currentitem.ptr, align 8
  call void @use(ptr %3)
  %4 = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %4, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %1, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %5 = icmp eq i64 %call7, 0
  br i1 %5, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %1) nounwind
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; We handle this now due to the fact that a release just needs a post dominating
; use.
;
define void @test6() nounwind {
; CHECK-LABEL: define void @test6(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL3:%.*]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP2]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL3]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    [[STATEITEMS_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL3]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP8]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ], [ [[TMP3:%.*]], %[[FORCOLL_NOTMUTATED:.*]] ]
; CHECK-NEXT:    [[MUTATIONSPTR4:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR4]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP1]], label %[[FORCOLL_NOTMUTATED]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP0]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[STATEITEMS:%.*]] = load ptr, ptr [[STATEITEMS_PTR]], align 8
; CHECK-NEXT:    [[CURRENTITEM_PTR:%.*]] = getelementptr ptr, ptr [[STATEITEMS]], i64 [[FORCOLL_INDEX]]
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[CURRENTITEM_PTR]], align 8
; CHECK-NEXT:    call void @use(ptr [[TMP2]])
; CHECK-NEXT:    [[TMP3]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[TMP3]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @callee()
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %1 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp2 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call3 = call i64 @objc_msgSend(ptr %1, ptr %tmp2, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call3, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  %stateitems.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 1
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call3, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp8 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp8, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ 0, %forcoll.loopbody.outer ], [ %4, %forcoll.notmutated ]
  %mutationsptr4 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr4, align 8
  %2 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %2, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %1)
  br label %forcoll.notmutated

forcoll.notmutated:
  %stateitems = load ptr, ptr %stateitems.ptr, align 8
  %currentitem.ptr = getelementptr ptr, ptr %stateitems, i64 %forcoll.index
  %3 = load ptr, ptr %currentitem.ptr, align 8
  call void @use(ptr %3)
  %4 = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %4, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %1, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %5 = icmp eq i64 %call7, 0
  br i1 %5, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %1) nounwind
  call void @callee()
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; TODO: Delete a nested retain+release pair.
; The optimizer currently can't do this, because isn't isn't sophisticated enough in
; reasnoning about nesting.

define void @test7() nounwind {
; CHECK-LABEL: define void @test7(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    call void @callee()
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP1:%.*]] = tail call ptr @llvm.objc.retain(ptr [[TMP0]]) #[[ATTR0]]
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL3:%.*]] = call i64 @objc_msgSend(ptr [[TMP1]], ptr [[TMP2]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL3]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    [[STATEITEMS_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL3]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP8]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ], [ [[TMP4:%.*]], %[[FORCOLL_NOTMUTATED:.*]] ]
; CHECK-NEXT:    [[MUTATIONSPTR4:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR4]], align 8
; CHECK-NEXT:    [[TMP2:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP2]], label %[[FORCOLL_NOTMUTATED]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP1]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[STATEITEMS:%.*]] = load ptr, ptr [[STATEITEMS_PTR]], align 8
; CHECK-NEXT:    [[CURRENTITEM_PTR:%.*]] = getelementptr ptr, ptr [[STATEITEMS]], i64 [[FORCOLL_INDEX]]
; CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[CURRENTITEM_PTR]], align 8
; CHECK-NEXT:    call void @use(ptr [[TMP3]])
; CHECK-NEXT:    [[TMP4]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[TMP4]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP1]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP5:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP5]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP1]]) #[[ATTR0]]
; CHECK-NEXT:    call void @callee()
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  call void @callee()
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %1 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp2 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call3 = call i64 @objc_msgSend(ptr %1, ptr %tmp2, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call3, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  %stateitems.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 1
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call3, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp8 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp8, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ 0, %forcoll.loopbody.outer ], [ %4, %forcoll.notmutated ]
  %mutationsptr4 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr4, align 8
  %2 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %2, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %1)
  br label %forcoll.notmutated

forcoll.notmutated:
  %stateitems = load ptr, ptr %stateitems.ptr, align 8
  %currentitem.ptr = getelementptr ptr, ptr %stateitems, i64 %forcoll.index
  %3 = load ptr, ptr %currentitem.ptr, align 8
  call void @use(ptr %3)
  %4 = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %4, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %1, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %5 = icmp eq i64 %call7, 0
  br i1 %5, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %1) nounwind
  call void @callee()
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; Delete a nested retain+release pair.

define void @test8() nounwind {
; CHECK-LABEL: define void @test8(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL3:%.*]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP2]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL3]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    [[STATEITEMS_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL3]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP8]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ], [ [[TMP3:%.*]], %[[FORCOLL_NEXT:.*]] ]
; CHECK-NEXT:    [[MUTATIONSPTR4:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR4]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP1]], label %[[FORCOLL_NOTMUTATED:.*]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP0]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[STATEITEMS:%.*]] = load ptr, ptr [[STATEITEMS_PTR]], align 8
; CHECK-NEXT:    [[CURRENTITEM_PTR:%.*]] = getelementptr ptr, ptr [[STATEITEMS]], i64 [[FORCOLL_INDEX]]
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[CURRENTITEM_PTR]], align 8
; CHECK-NEXT:    [[TOBOOL:%.*]] = icmp eq ptr [[TMP2]], null
; CHECK-NEXT:    br i1 [[TOBOOL]], label %[[FORCOLL_NEXT]], label %[[IF_THEN:.*]]
; CHECK:       [[IF_THEN]]:
; CHECK-NEXT:    call void @callee()
; CHECK-NEXT:    br label %[[FORCOLL_NEXT]]
; CHECK:       [[FORCOLL_NEXT]]:
; CHECK-NEXT:    [[TMP3]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[TMP3]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP0]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %1 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp2 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call3 = call i64 @objc_msgSend(ptr %1, ptr %tmp2, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call3, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  %stateitems.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 1
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call3, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp8 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp8, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ 0, %forcoll.loopbody.outer ], [ %4, %forcoll.next ]
  %mutationsptr4 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr4, align 8
  %2 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %2, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %1)
  br label %forcoll.notmutated

forcoll.notmutated:
  %stateitems = load ptr, ptr %stateitems.ptr, align 8
  %currentitem.ptr = getelementptr ptr, ptr %stateitems, i64 %forcoll.index
  %3 = load ptr, ptr %currentitem.ptr, align 8
  %tobool = icmp eq ptr %3, null
  br i1 %tobool, label %forcoll.next, label %if.then

if.then:
  call void @callee()
  br label %forcoll.next

forcoll.next:
  %4 = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %4, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %1, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %5 = icmp eq i64 %call7, 0
  br i1 %5, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %1) nounwind
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; TODO: Delete a nested retain+release pair.
; The optimizer currently can't do this, because of a split loop backedge.
; See test9b for the same testcase without a split backedge.

define void @test9() nounwind {
; CHECK-LABEL: define void @test9(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    [[CALL1:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP1:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL1]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = tail call ptr @llvm.objc.retain(ptr [[TMP0]]) #[[ATTR0]]
; CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL4:%.*]] = call i64 @objc_msgSend(ptr [[TMP2]], ptr [[TMP3]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL4]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL4]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP9]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ [[PHITMP:%.*]], %[[FORCOLL_NOTMUTATED_FORCOLL_LOOPBODY_CRIT_EDGE:.*]] ], [ 1, %[[FORCOLL_LOOPBODY_OUTER]] ]
; CHECK-NEXT:    [[MUTATIONSPTR5:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR5]], align 8
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP3]], label %[[FORCOLL_NOTMUTATED:.*]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP2]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[FORCOLL_INDEX]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_NOTMUTATED_FORCOLL_LOOPBODY_CRIT_EDGE]]
; CHECK:       [[FORCOLL_NOTMUTATED_FORCOLL_LOOPBODY_CRIT_EDGE]]:
; CHECK-NEXT:    [[PHITMP]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP2]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP2]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP1]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  %call1 = call ptr @returner()
  %1 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call1) nounwind
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %2 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp3 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call4 = call i64 @objc_msgSend(ptr %2, ptr %tmp3, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call4, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call4, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp9 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp9, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ %phitmp, %forcoll.notmutated.forcoll.loopbody_crit_edge ], [ 1, %forcoll.loopbody.outer ]
  %mutationsptr5 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr5, align 8
  %3 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %3, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %2)
  br label %forcoll.notmutated

forcoll.notmutated:
  %exitcond = icmp eq i64 %forcoll.index, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.notmutated.forcoll.loopbody_crit_edge

forcoll.notmutated.forcoll.loopbody_crit_edge:
  %phitmp = add i64 %forcoll.index, 1
  br label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %2, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %4 = icmp eq i64 %call7, 0
  br i1 %4, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %2) nounwind
  call void @llvm.objc.release(ptr %1) nounwind, !clang.imprecise_release !0
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; Like test9, but without a split backedge. TODO: optimize this.

define void @test9b() nounwind {
; CHECK-LABEL: define void @test9b(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    [[CALL1:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP1:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL1]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = tail call ptr @llvm.objc.retain(ptr [[TMP0]]) #[[ATTR0]]
; CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL4:%.*]] = call i64 @objc_msgSend(ptr [[TMP2]], ptr [[TMP3]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL4]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL4]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP9]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ [[PHITMP:%.*]], %[[FORCOLL_NOTMUTATED:.*]] ], [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ]
; CHECK-NEXT:    [[MUTATIONSPTR5:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR5]], align 8
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP3]], label %[[FORCOLL_NOTMUTATED]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP2]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[PHITMP]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[PHITMP]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP2]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP2]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP1]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  %call1 = call ptr @returner()
  %1 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call1) nounwind
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %2 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp3 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call4 = call i64 @objc_msgSend(ptr %2, ptr %tmp3, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call4, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call4, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp9 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp9, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ %phitmp, %forcoll.notmutated ], [ 0, %forcoll.loopbody.outer ]
  %mutationsptr5 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr5, align 8
  %3 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %3, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %2)
  br label %forcoll.notmutated

forcoll.notmutated:
  %phitmp = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %phitmp, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %2, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %4 = icmp eq i64 %call7, 0
  br i1 %4, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %2) nounwind
  call void @llvm.objc.release(ptr %1) nounwind, !clang.imprecise_release !0
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; TODO: Delete a nested retain+release pair.
; The optimizer currently can't do this, because of a split loop backedge.
; See test10b for the same testcase without a split backedge.

define void @test10() nounwind {
; CHECK-LABEL: define void @test10(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    [[CALL1:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP1:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL1]]) #[[ATTR0]]
; CHECK-NEXT:    call void @callee()
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = tail call ptr @llvm.objc.retain(ptr [[TMP0]]) #[[ATTR0]]
; CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL4:%.*]] = call i64 @objc_msgSend(ptr [[TMP2]], ptr [[TMP3]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL4]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL4]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP9]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ [[PHITMP:%.*]], %[[FORCOLL_NOTMUTATED_FORCOLL_LOOPBODY_CRIT_EDGE:.*]] ], [ 1, %[[FORCOLL_LOOPBODY_OUTER]] ]
; CHECK-NEXT:    [[MUTATIONSPTR5:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR5]], align 8
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP3]], label %[[FORCOLL_NOTMUTATED:.*]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP2]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[FORCOLL_INDEX]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_NOTMUTATED_FORCOLL_LOOPBODY_CRIT_EDGE]]
; CHECK:       [[FORCOLL_NOTMUTATED_FORCOLL_LOOPBODY_CRIT_EDGE]]:
; CHECK-NEXT:    [[PHITMP]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP2]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP2]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP1]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  %call1 = call ptr @returner()
  %1 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call1) nounwind
  call void @callee()
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %2 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp3 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call4 = call i64 @objc_msgSend(ptr %2, ptr %tmp3, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call4, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call4, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp9 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp9, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ %phitmp, %forcoll.notmutated.forcoll.loopbody_crit_edge ], [ 1, %forcoll.loopbody.outer ]
  %mutationsptr5 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr5, align 8
  %3 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %3, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %2)
  br label %forcoll.notmutated

forcoll.notmutated:
  %exitcond = icmp eq i64 %forcoll.index, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.notmutated.forcoll.loopbody_crit_edge

forcoll.notmutated.forcoll.loopbody_crit_edge:
  %phitmp = add i64 %forcoll.index, 1
  br label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %2, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %4 = icmp eq i64 %call7, 0
  br i1 %4, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %2) nounwind
  call void @llvm.objc.release(ptr %1) nounwind, !clang.imprecise_release !0
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; Like test10, but without a split backedge. TODO: optimize this.

define void @test10b() nounwind {
; CHECK-LABEL: define void @test10b(
; CHECK-SAME: ) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[STATE_PTR:%.*]] = alloca [[STRUCT___OBJCFASTENUMERATIONSTATE:%.*]], align 8
; CHECK-NEXT:    [[ITEMS_PTR:%.*]] = alloca [16 x ptr], align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    [[CALL1:%.*]] = call ptr @returner()
; CHECK-NEXT:    [[TMP1:%.*]] = tail call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr [[CALL1]]) #[[ATTR0]]
; CHECK-NEXT:    call void @callee()
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[STATE_PTR]], i8 0, i64 64, i1 false)
; CHECK-NEXT:    [[TMP2:%.*]] = tail call ptr @llvm.objc.retain(ptr [[TMP0]]) #[[ATTR0]]
; CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL4:%.*]] = call i64 @objc_msgSend(ptr [[TMP2]], ptr [[TMP3]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[ISZERO:%.*]] = icmp eq i64 [[CALL4]], 0
; CHECK-NEXT:    br i1 [[ISZERO]], label %[[FORCOLL_EMPTY:.*]], label %[[FORCOLL_LOOPINIT:.*]]
; CHECK:       [[FORCOLL_LOOPINIT]]:
; CHECK-NEXT:    [[MUTATIONSPTR_PTR:%.*]] = getelementptr inbounds [[STRUCT___OBJCFASTENUMERATIONSTATE]], ptr [[STATE_PTR]], i64 0, i32 2
; CHECK-NEXT:    [[MUTATIONSPTR:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[FORCOLL_INITIAL_MUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR]], align 8
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY_OUTER:.*]]
; CHECK:       [[FORCOLL_LOOPBODY_OUTER]]:
; CHECK-NEXT:    [[FORCOLL_COUNT_PH:%.*]] = phi i64 [ [[CALL4]], %[[FORCOLL_LOOPINIT]] ], [ [[CALL7:%.*]], %[[FORCOLL_REFETCH:.*]] ]
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ugt i64 [[FORCOLL_COUNT_PH]], 1
; CHECK-NEXT:    [[UMAX:%.*]] = select i1 [[TMP9]], i64 [[FORCOLL_COUNT_PH]], i64 1
; CHECK-NEXT:    br label %[[FORCOLL_LOOPBODY:.*]]
; CHECK:       [[FORCOLL_LOOPBODY]]:
; CHECK-NEXT:    [[FORCOLL_INDEX:%.*]] = phi i64 [ [[PHITMP:%.*]], %[[FORCOLL_NOTMUTATED:.*]] ], [ 0, %[[FORCOLL_LOOPBODY_OUTER]] ]
; CHECK-NEXT:    [[MUTATIONSPTR5:%.*]] = load ptr, ptr [[MUTATIONSPTR_PTR]], align 8
; CHECK-NEXT:    [[STATEMUTATIONS:%.*]] = load i64, ptr [[MUTATIONSPTR5]], align 8
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i64 [[STATEMUTATIONS]], [[FORCOLL_INITIAL_MUTATIONS]]
; CHECK-NEXT:    br i1 [[TMP3]], label %[[FORCOLL_NOTMUTATED]], label %[[FORCOLL_MUTATED:.*]]
; CHECK:       [[FORCOLL_MUTATED]]:
; CHECK-NEXT:    call void @llvm.objc.enumerationMutation(ptr [[TMP2]])
; CHECK-NEXT:    br label %[[FORCOLL_NOTMUTATED]]
; CHECK:       [[FORCOLL_NOTMUTATED]]:
; CHECK-NEXT:    [[PHITMP]] = add i64 [[FORCOLL_INDEX]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[PHITMP]], [[UMAX]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[FORCOLL_REFETCH]], label %[[FORCOLL_LOOPBODY]]
; CHECK:       [[FORCOLL_REFETCH]]:
; CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
; CHECK-NEXT:    [[CALL7]] = call i64 @objc_msgSend(ptr [[TMP2]], ptr [[TMP6]], ptr [[STATE_PTR]], ptr [[ITEMS_PTR]], i64 16)
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[CALL7]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label %[[FORCOLL_EMPTY]], label %[[FORCOLL_LOOPBODY_OUTER]]
; CHECK:       [[FORCOLL_EMPTY]]:
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP2]]) #[[ATTR0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP1]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[TMP0]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    ret void
;
entry:
  %state.ptr = alloca %struct.__objcFastEnumerationState, align 8
  %items.ptr = alloca [16 x ptr], align 8
  %call = call ptr @returner()
  %0 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call) nounwind
  %call1 = call ptr @returner()
  %1 = call ptr @llvm.objc.retainAutoreleasedReturnValue(ptr %call1) nounwind
  call void @callee()
  call void @llvm.memset.p0.i64(ptr align 8 %state.ptr, i8 0, i64 64, i1 false)
  %2 = call ptr @llvm.objc.retain(ptr %0) nounwind
  %tmp3 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call4 = call i64 @objc_msgSend(ptr %2, ptr %tmp3, ptr %state.ptr, ptr %items.ptr, i64 16)
  %iszero = icmp eq i64 %call4, 0
  br i1 %iszero, label %forcoll.empty, label %forcoll.loopinit

forcoll.loopinit:
  %mutationsptr.ptr = getelementptr inbounds %struct.__objcFastEnumerationState, ptr %state.ptr, i64 0, i32 2
  %mutationsptr = load ptr, ptr %mutationsptr.ptr, align 8
  %forcoll.initial-mutations = load i64, ptr %mutationsptr, align 8
  br label %forcoll.loopbody.outer

forcoll.loopbody.outer:
  %forcoll.count.ph = phi i64 [ %call4, %forcoll.loopinit ], [ %call7, %forcoll.refetch ]
  %tmp9 = icmp ugt i64 %forcoll.count.ph, 1
  %umax = select i1 %tmp9, i64 %forcoll.count.ph, i64 1
  br label %forcoll.loopbody

forcoll.loopbody:
  %forcoll.index = phi i64 [ %phitmp, %forcoll.notmutated ], [ 0, %forcoll.loopbody.outer ]
  %mutationsptr5 = load ptr, ptr %mutationsptr.ptr, align 8
  %statemutations = load i64, ptr %mutationsptr5, align 8
  %3 = icmp eq i64 %statemutations, %forcoll.initial-mutations
  br i1 %3, label %forcoll.notmutated, label %forcoll.mutated

forcoll.mutated:
  call void @llvm.objc.enumerationMutation(ptr %2)
  br label %forcoll.notmutated

forcoll.notmutated:
  %phitmp = add i64 %forcoll.index, 1
  %exitcond = icmp eq i64 %phitmp, %umax
  br i1 %exitcond, label %forcoll.refetch, label %forcoll.loopbody

forcoll.refetch:
  %tmp6 = load ptr, ptr @"\01L_OBJC_SELECTOR_REFERENCES_", align 8
  %call7 = call i64 @objc_msgSend(ptr %2, ptr %tmp6, ptr %state.ptr, ptr %items.ptr, i64 16)
  %4 = icmp eq i64 %call7, 0
  br i1 %4, label %forcoll.empty, label %forcoll.loopbody.outer

forcoll.empty:
  call void @llvm.objc.release(ptr %2) nounwind
  call void @llvm.objc.release(ptr %1) nounwind, !clang.imprecise_release !0
  call void @llvm.objc.release(ptr %0) nounwind, !clang.imprecise_release !0
  ret void
}

; Pointers to strong pointers can obscure provenance relationships. Be conservative
; in the face of escaping pointers. rdar://12150909.

%struct.__block_d = type { i64, i64 }

@_NSConcreteStackBlock = external global ptr
@__block_d_tmp = external hidden constant { i64, i64, ptr, ptr, ptr, ptr }
@__block_d_tmp5 = external hidden constant { i64, i64, ptr, ptr, ptr, ptr }

define void @test11() {
; CHECK-LABEL: define void @test11() {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[BLOCK:%.*]] = alloca <{ ptr, i32, i32, ptr, ptr, ptr }>, align 8
; CHECK-NEXT:    [[BLOCK9:%.*]] = alloca <{ ptr, i32, i32, ptr, ptr, ptr }>, align 8
; CHECK-NEXT:    [[CALL:%.*]] = call ptr @def(), !clang.arc.no_objc_arc_exceptions [[META0]]
; CHECK-NEXT:    [[FOO:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK]], i64 0, i32 5
; CHECK-NEXT:    [[BLOCK_ISA:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK]], i64 0, i32 0
; CHECK-NEXT:    store ptr @_NSConcreteStackBlock, ptr [[BLOCK_ISA]], align 8
; CHECK-NEXT:    [[BLOCK_FLAGS:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK]], i64 0, i32 1
; CHECK-NEXT:    store i32 1107296256, ptr [[BLOCK_FLAGS]], align 8
; CHECK-NEXT:    [[BLOCK_RESERVED:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK]], i64 0, i32 2
; CHECK-NEXT:    store i32 0, ptr [[BLOCK_RESERVED]], align 4
; CHECK-NEXT:    [[BLOCK_INVOKE:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK]], i64 0, i32 3
; CHECK-NEXT:    store ptr @__crasher_block_invoke, ptr [[BLOCK_INVOKE]], align 8
; CHECK-NEXT:    [[BLOCK_D:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK]], i64 0, i32 4
; CHECK-NEXT:    store ptr @__block_d_tmp, ptr [[BLOCK_D]], align 8
; CHECK-NEXT:    [[FOO2:%.*]] = tail call ptr @llvm.objc.retain(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    store ptr [[FOO2]], ptr [[FOO]], align 8
; CHECK-NEXT:    [[FOO5:%.*]] = call ptr @llvm.objc.retainBlock(ptr [[BLOCK]]) #[[ATTR0]]
; CHECK-NEXT:    call void @use(ptr [[FOO5]]), !clang.arc.no_objc_arc_exceptions [[META0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[FOO5]]) #[[ATTR0]]
; CHECK-NEXT:    [[STRONGDESTROY:%.*]] = load ptr, ptr [[FOO]], align 8
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[STRONGDESTROY]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    [[FOO10:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK9]], i64 0, i32 5
; CHECK-NEXT:    [[BLOCK_ISA11:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK9]], i64 0, i32 0
; CHECK-NEXT:    store ptr @_NSConcreteStackBlock, ptr [[BLOCK_ISA11]], align 8
; CHECK-NEXT:    [[BLOCK_FLAGS12:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK9]], i64 0, i32 1
; CHECK-NEXT:    store i32 1107296256, ptr [[BLOCK_FLAGS12]], align 8
; CHECK-NEXT:    [[BLOCK_RESERVED13:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK9]], i64 0, i32 2
; CHECK-NEXT:    store i32 0, ptr [[BLOCK_RESERVED13]], align 4
; CHECK-NEXT:    [[BLOCK_INVOKE14:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK9]], i64 0, i32 3
; CHECK-NEXT:    store ptr @__crasher_block_invoke1, ptr [[BLOCK_INVOKE14]], align 8
; CHECK-NEXT:    [[BLOCK_D15:%.*]] = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr [[BLOCK9]], i64 0, i32 4
; CHECK-NEXT:    store ptr @__block_d_tmp5, ptr [[BLOCK_D15]], align 8
; CHECK-NEXT:    store ptr [[CALL]], ptr [[FOO10]], align 8
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[CALL]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    [[FOO21:%.*]] = call ptr @llvm.objc.retainBlock(ptr [[BLOCK9]]) #[[ATTR0]]
; CHECK-NEXT:    call void @use(ptr [[FOO21]]), !clang.arc.no_objc_arc_exceptions [[META0]]
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[FOO21]]) #[[ATTR0]]
; CHECK-NEXT:    [[STRONGDESTROY25:%.*]] = load ptr, ptr [[FOO10]], align 8
; CHECK-NEXT:    call void @llvm.objc.release(ptr [[STRONGDESTROY25]]) #[[ATTR0]], !clang.imprecise_release [[META0]]
; CHECK-NEXT:    [[TMP0:%.*]] = tail call ptr @llvm.objc.retain(ptr [[CALL]]) #[[ATTR0]]
; CHECK-NEXT:    ret void
;
entry:
  %block = alloca <{ ptr, i32, i32, ptr, ptr, ptr }>, align 8
  %block9 = alloca <{ ptr, i32, i32, ptr, ptr, ptr }>, align 8
  %call = call ptr @def(), !clang.arc.no_objc_arc_exceptions !0
  %foo = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block, i64 0, i32 5
  %block.isa = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block, i64 0, i32 0
  store ptr @_NSConcreteStackBlock, ptr %block.isa, align 8
  %block.flags = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block, i64 0, i32 1
  store i32 1107296256, ptr %block.flags, align 8
  %block.reserved = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block, i64 0, i32 2
  store i32 0, ptr %block.reserved, align 4
  %block.invoke = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block, i64 0, i32 3
  store ptr @__crasher_block_invoke, ptr %block.invoke, align 8
  %block.d = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block, i64 0, i32 4
  store ptr @__block_d_tmp, ptr %block.d, align 8
  %foo2 = tail call ptr @llvm.objc.retain(ptr %call) nounwind
  store ptr %foo2, ptr %foo, align 8
  %foo5 = call ptr @llvm.objc.retainBlock(ptr %block) nounwind
  call void @use(ptr %foo5), !clang.arc.no_objc_arc_exceptions !0
  call void @llvm.objc.release(ptr %foo5) nounwind
  %strongdestroy = load ptr, ptr %foo, align 8
  call void @llvm.objc.release(ptr %strongdestroy) nounwind, !clang.imprecise_release !0
  %foo10 = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block9, i64 0, i32 5
  %block.isa11 = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block9, i64 0, i32 0
  store ptr @_NSConcreteStackBlock, ptr %block.isa11, align 8
  %block.flags12 = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block9, i64 0, i32 1
  store i32 1107296256, ptr %block.flags12, align 8
  %block.reserved13 = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block9, i64 0, i32 2
  store i32 0, ptr %block.reserved13, align 4
  %block.invoke14 = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block9, i64 0, i32 3
  store ptr @__crasher_block_invoke1, ptr %block.invoke14, align 8
  %block.d15 = getelementptr inbounds <{ ptr, i32, i32, ptr, ptr, ptr }>, ptr %block9, i64 0, i32 4
  store ptr @__block_d_tmp5, ptr %block.d15, align 8
  %foo18 = call ptr @llvm.objc.retain(ptr %call) nounwind
  store ptr %call, ptr %foo10, align 8
  %foo21 = call ptr @llvm.objc.retainBlock(ptr %block9) nounwind
  call void @use(ptr %foo21), !clang.arc.no_objc_arc_exceptions !0
  call void @llvm.objc.release(ptr %foo21) nounwind
  %strongdestroy25 = load ptr, ptr %foo10, align 8
  call void @llvm.objc.release(ptr %strongdestroy25) nounwind, !clang.imprecise_release !0
  call void @llvm.objc.release(ptr %call) nounwind, !clang.imprecise_release !0
  ret void
}


;.
; CHECK: [[META0]] = !{}
;.
