; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: %if x86-registered-target %{ opt -passes=slp-vectorizer -S -mtriple=x86_64-unknown-linux-gnu < %s | FileCheck %s --check-prefix=X86 %}
; RUN: %if aarch64-registered-target %{ opt -passes=slp-vectorizer -S -mtriple=aarch64-unknown-linux-gnu < %s | FileCheck %s --check-prefix=AARCH64 %}

define void @foo(ptr %c, ptr %d) {
; X86-LABEL: @foo(
; X86-NEXT:  entry:
; X86-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds i8, ptr [[C:%.*]], i64 4
; X86-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds i8, ptr [[C]], i64 1
; X86-NEXT:    [[ARRAYIDX12:%.*]] = getelementptr inbounds i8, ptr [[C]], i64 2
; X86-NEXT:    [[ADD_PTR53:%.*]] = getelementptr inbounds float, ptr [[D:%.*]], i64 -4
; X86-NEXT:    [[TMP0:%.*]] = load i8, ptr [[ARRAYIDX4]], align 1
; X86-NEXT:    [[TMP1:%.*]] = load i8, ptr [[ARRAYIDX1]], align 1
; X86-NEXT:    [[CONV5:%.*]] = zext i8 [[TMP0]] to i32
; X86-NEXT:    [[CONV2:%.*]] = zext i8 [[TMP1]] to i32
; X86-NEXT:    [[SHL6:%.*]] = shl nuw nsw i32 [[CONV5]], 2
; X86-NEXT:    [[AND:%.*]] = and i32 [[CONV2]], 3
; X86-NEXT:    [[TMP2:%.*]] = load <2 x i8>, ptr [[ARRAYIDX12]], align 1
; X86-NEXT:    [[TMP3:%.*]] = zext <2 x i8> [[TMP2]] to <2 x i16>
; X86-NEXT:    [[TMP4:%.*]] = shl <2 x i16> [[TMP3]], splat (i16 2)
; X86-NEXT:    [[TMP5:%.*]] = insertelement <4 x i32> poison, i32 [[SHL6]], i32 0
; X86-NEXT:    [[TMP6:%.*]] = zext <2 x i16> [[TMP4]] to <2 x i32>
; X86-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> poison, <4 x i32> <i32 0, i32 1, i32 poison, i32 poison>
; X86-NEXT:    [[TMP8:%.*]] = shufflevector <4 x i32> [[TMP5]], <4 x i32> [[TMP7]], <4 x i32> <i32 0, i32 4, i32 5, i32 poison>
; X86-NEXT:    [[TMP9:%.*]] = insertelement <4 x i32> [[TMP8]], i32 [[AND]], i32 3
; X86-NEXT:    [[TMP10:%.*]] = add nsw <4 x i32> undef, [[TMP9]]
; X86-NEXT:    [[TMP11:%.*]] = sitofp <4 x i32> [[TMP10]] to <4 x float>
; X86-NEXT:    [[TMP12:%.*]] = fdiv <4 x float> [[TMP11]], undef
; X86-NEXT:    [[TMP13:%.*]] = shufflevector <4 x float> [[TMP12]], <4 x float> poison, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
; X86-NEXT:    store <4 x float> [[TMP13]], ptr [[ADD_PTR53]], align 4
; X86-NEXT:    ret void
;
; AARCH64-LABEL: @foo(
; AARCH64-NEXT:  entry:
; AARCH64-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds i8, ptr [[C:%.*]], i64 1
; AARCH64-NEXT:    [[ADD_PTR53:%.*]] = getelementptr inbounds float, ptr [[D:%.*]], i64 -4
; AARCH64-NEXT:    [[TMP0:%.*]] = load <4 x i8>, ptr [[ARRAYIDX4]], align 1
; AARCH64-NEXT:    [[TMP1:%.*]] = zext <4 x i8> [[TMP0]] to <4 x i32>
; AARCH64-NEXT:    [[TMP2:%.*]] = shl nuw nsw <4 x i32> [[TMP1]], <i32 2, i32 2, i32 2, i32 3>
; AARCH64-NEXT:    [[TMP3:%.*]] = and <4 x i32> [[TMP1]], <i32 2, i32 2, i32 2, i32 3>
; AARCH64-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[TMP2]], <4 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 7>
; AARCH64-NEXT:    [[TMP5:%.*]] = add nsw <4 x i32> undef, [[TMP4]]
; AARCH64-NEXT:    [[TMP6:%.*]] = sitofp <4 x i32> [[TMP5]] to <4 x float>
; AARCH64-NEXT:    [[TMP7:%.*]] = fdiv <4 x float> [[TMP6]], undef
; AARCH64-NEXT:    [[TMP8:%.*]] = shufflevector <4 x float> [[TMP7]], <4 x float> poison, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
; AARCH64-NEXT:    store <4 x float> [[TMP8]], ptr [[ADD_PTR53]], align 4
; AARCH64-NEXT:    ret void
;
entry:
  %arrayidx1 = getelementptr inbounds i8, ptr %c, i64 4
  %0 = load i8, ptr %arrayidx1, align 1
  %conv2 = zext i8 %0 to i32
  %and = and i32 %conv2, 3
  %arrayidx4 = getelementptr inbounds i8, ptr %c, i64 1
  %1 = load i8, ptr %arrayidx4, align 1
  %conv5 = zext i8 %1 to i32
  %shl6 = shl nuw nsw i32 %conv5, 2
  %arrayidx12 = getelementptr inbounds i8, ptr %c, i64 2
  %2 = load i8, ptr %arrayidx12, align 1
  %conv13 = zext i8 %2 to i32
  %shl14 = shl nuw nsw i32 %conv13, 2
  %arrayidx17 = getelementptr inbounds i8, ptr %c, i64 3
  %3 = load i8, ptr %arrayidx17, align 1
  %conv18 = zext i8 %3 to i32
  %shl19 = shl nuw nsw i32 %conv18, 2
  %sub = add nsw i32 undef, %shl6
  %conv27 = sitofp i32 %sub to float
  %div = fdiv float %conv27, undef
  %add.ptr = getelementptr inbounds float, ptr %d, i64 -1
  store float %div, ptr %add.ptr, align 4
  %sub32 = add nsw i32 undef, %and
  %conv33 = sitofp i32 %sub32 to float
  %div36 = fdiv float %conv33, undef
  %add.ptr37 = getelementptr inbounds float, ptr %d, i64 -2
  store float %div36, ptr %add.ptr37, align 4
  %sub40 = add nsw i32 undef, %shl19
  %conv41 = sitofp i32 %sub40 to float
  %div44 = fdiv float %conv41, undef
  %add.ptr45 = getelementptr inbounds float, ptr %d, i64 -3
  store float %div44, ptr %add.ptr45, align 4
  %sub48 = add nsw i32 undef, %shl14
  %conv49 = sitofp i32 %sub48 to float
  %div52 = fdiv float %conv49, undef
  %add.ptr53 = getelementptr inbounds float, ptr %d, i64 -4
  store float %div52, ptr %add.ptr53, align 4
  ret void
}
