; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S -mtriple=amdgcn-amd-amdhsa -mcpu=gfx900 -passes=slp-vectorizer < %s | FileCheck %s
;

define void @complex_mul_fma(ptr %result, float %a, float %b, float %c, float %d) {
; CHECK-LABEL: @complex_mul_fma(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[MUL_AC:%.*]] = fmul contract float [[A:%.*]], [[C:%.*]]
; CHECK-NEXT:    [[MUL_BD:%.*]] = fmul contract float [[B:%.*]], [[D:%.*]]
; CHECK-NEXT:    [[REAL:%.*]] = fsub contract float [[MUL_AC]], [[MUL_BD]]
; CHECK-NEXT:    [[MUL_AD:%.*]] = fmul contract float [[A]], [[D]]
; CHECK-NEXT:    [[MUL_BC:%.*]] = fmul contract float [[B]], [[C]]
; CHECK-NEXT:    [[IMAG:%.*]] = fadd contract float [[MUL_AD]], [[MUL_BC]]
; CHECK-NEXT:    store float [[REAL]], ptr [[RESULT:%.*]], align 4
; CHECK-NEXT:    [[RESULT_IMAG:%.*]] = getelementptr inbounds float, ptr [[RESULT]], i64 1
; CHECK-NEXT:    store float [[IMAG]], ptr [[RESULT_IMAG]], align 4
; CHECK-NEXT:    ret void
;
entry:
  ; Real part: a*c - b*d
  %mul.ac = fmul contract float %a, %c
  %mul.bd = fmul contract float %b, %d
  %real = fsub contract float %mul.ac, %mul.bd

  ; Imaginary part: a*d + b*c
  %mul.ad = fmul contract float %a, %d
  %mul.bc = fmul contract float %b, %c
  %imag = fadd contract float %mul.ad, %mul.bc

  ; Store results
  store float %real, ptr %result, align 4
  %result.imag = getelementptr inbounds float, ptr %result, i64 1
  store float %imag, ptr %result.imag, align 4

  ret void
}

define void @fmul_fadd_prefer_fma(ptr %dst, ptr %src1, ptr %src2, ptr %src3) {
; CHECK-LABEL: @fmul_fadd_prefer_fma(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[A0:%.*]] = load float, ptr [[SRC1:%.*]], align 4
; CHECK-NEXT:    [[B0:%.*]] = load float, ptr [[SRC2:%.*]], align 4
; CHECK-NEXT:    [[C0:%.*]] = load float, ptr [[SRC3:%.*]], align 4
; CHECK-NEXT:    [[MUL0:%.*]] = fmul contract float [[A0]], [[B0]]
; CHECK-NEXT:    [[ADD0:%.*]] = fadd contract float [[MUL0]], [[C0]]
; CHECK-NEXT:    store float [[ADD0]], ptr [[DST:%.*]], align 4
; CHECK-NEXT:    [[SRC1_1:%.*]] = getelementptr inbounds float, ptr [[SRC1]], i64 1
; CHECK-NEXT:    [[A1:%.*]] = load float, ptr [[SRC1_1]], align 4
; CHECK-NEXT:    [[SRC2_1:%.*]] = getelementptr inbounds float, ptr [[SRC2]], i64 1
; CHECK-NEXT:    [[B1:%.*]] = load float, ptr [[SRC2_1]], align 4
; CHECK-NEXT:    [[SRC3_1:%.*]] = getelementptr inbounds float, ptr [[SRC3]], i64 1
; CHECK-NEXT:    [[C1:%.*]] = load float, ptr [[SRC3_1]], align 4
; CHECK-NEXT:    [[MUL1:%.*]] = fmul contract float [[A1]], [[B1]]
; CHECK-NEXT:    [[ADD1:%.*]] = fadd contract float [[MUL1]], [[C1]]
; CHECK-NEXT:    [[DST_1:%.*]] = getelementptr inbounds float, ptr [[DST]], i64 1
; CHECK-NEXT:    store float [[ADD1]], ptr [[DST_1]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %a0 = load float, ptr %src1, align 4
  %b0 = load float, ptr %src2, align 4
  %c0 = load float, ptr %src3, align 4
  %mul0 = fmul contract float %a0, %b0
  %add0 = fadd contract float %mul0, %c0
  store float %add0, ptr %dst, align 4

  %src1.1 = getelementptr inbounds float, ptr %src1, i64 1
  %a1 = load float, ptr %src1.1, align 4
  %src2.1 = getelementptr inbounds float, ptr %src2, i64 1
  %b1 = load float, ptr %src2.1, align 4
  %src3.1 = getelementptr inbounds float, ptr %src3, i64 1
  %c1 = load float, ptr %src3.1, align 4
  %mul1 = fmul contract float %a1, %b1
  %add1 = fadd contract float %mul1, %c1
  %dst.1 = getelementptr inbounds float, ptr %dst, i64 1
  store float %add1, ptr %dst.1, align 4

  ret void
}

define void @fmul_no_fma_can_vectorize(ptr addrspace(3) %a, ptr addrspace(3) %b, ptr addrspace(3) %c) {
; CHECK-LABEL: @fmul_no_fma_can_vectorize(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = load <2 x half>, ptr addrspace(3) [[A:%.*]], align 2
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x half>, ptr addrspace(3) [[B:%.*]], align 2
; CHECK-NEXT:    [[TMP2:%.*]] = fmul <2 x half> [[TMP0]], [[TMP1]]
; CHECK-NEXT:    store <2 x half> [[TMP2]], ptr addrspace(3) [[C:%.*]], align 2
; CHECK-NEXT:    ret void
;
entry:
  %i0 = load half, ptr addrspace(3) %a, align 2
  %i1 = load half, ptr addrspace(3) %b, align 2
  %mul = fmul half %i0, %i1
  %arrayidx3 = getelementptr inbounds half, ptr addrspace(3) %a, i64 1
  %i3 = load half, ptr addrspace(3) %arrayidx3, align 2
  %arrayidx4 = getelementptr inbounds half, ptr addrspace(3) %b, i64 1
  %i4 = load half, ptr addrspace(3) %arrayidx4, align 2
  %mul5 = fmul half %i3, %i4
  store half %mul, ptr addrspace(3) %c, align 2
  %arrayidx5 = getelementptr inbounds half, ptr addrspace(3) %c, i64 1
  store half %mul5, ptr addrspace(3) %arrayidx5, align 2
  ret void
}
