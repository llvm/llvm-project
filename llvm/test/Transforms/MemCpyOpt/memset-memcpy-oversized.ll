; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -passes=memcpyopt -S %s -verify-memoryssa | FileCheck %s

; memset -> memcpy forwarding, if memcpy is larger than memset, but trailing
; bytes are known to be undef.


%T = type { i64, i32, i32 }

define void @test_alloca(ptr %result) {
; CHECK-LABEL: @test_alloca(
; CHECK-NEXT:    [[A:%.*]] = alloca [[T:%.*]], align 8
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[RESULT:%.*]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca %T, align 8
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 12, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 false)
  ret void
}

define void @test_alloca_with_lifetimes(ptr %result) {
; CHECK-LABEL: @test_alloca_with_lifetimes(
; CHECK-NEXT:    [[A:%.*]] = alloca [[T:%.*]], align 8
; CHECK-NEXT:    call void @llvm.lifetime.start.p0(ptr [[A]])
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[RESULT:%.*]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    call void @llvm.lifetime.end.p0(ptr [[A]])
; CHECK-NEXT:    ret void
;
  %a = alloca %T, align 8
  call void @llvm.lifetime.start.p0(ptr %a)
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 12, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 false)
  call void @llvm.lifetime.end.p0(ptr %a)
  ret void
}

; The trailing bytes are not known to be undef, we can't ignore them.
define void @test_not_undef_memory(ptr %result, ptr %input) {
; CHECK-LABEL: @test_not_undef_memory(
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[INPUT:%.*]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[RESULT:%.*]], ptr align 8 [[INPUT]], i64 16, i1 false)
; CHECK-NEXT:    ret void
;
  call void @llvm.memset.p0.i64(ptr align 8 %input, i8 0, i64 12, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %input, i64 16, i1 false)
  ret void
}

; Memset is volatile, memcpy is not. Can be optimized.
define void @test_volatile_memset(ptr %result) {
; CHECK-LABEL: @test_volatile_memset(
; CHECK-NEXT:    [[A:%.*]] = alloca [[T:%.*]], align 8
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 12, i1 true)
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[RESULT:%.*]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca %T, align 8
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 12, i1 true)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 false)
  ret void
}

; Memcpy is volatile, memset is not. Cannot be optimized.
define void @test_volatile_memcpy(ptr %result) {
; CHECK-LABEL: @test_volatile_memcpy(
; CHECK-NEXT:    [[A:%.*]] = alloca [[T:%.*]], align 8
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[RESULT:%.*]], ptr align 8 [[A]], i64 16, i1 true)
; CHECK-NEXT:    ret void
;
  %a = alloca %T, align 8
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 12, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 true)
  ret void
}

; Write between memset and memcpy, can't optimize.
define void @test_write_between(ptr %result) {
; CHECK-LABEL: @test_write_between(
; CHECK-NEXT:    [[A:%.*]] = alloca [[T:%.*]], align 8
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    store i8 -1, ptr [[A]], align 1
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[RESULT:%.*]], ptr align 8 [[A]], i64 16, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca %T, align 8
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 12, i1 false)
  store i8 -1, ptr %a
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 false)
  ret void
}

; A write prior to the memset, which is part of the memset region.
; We could optimize this, but currently don't, because the used memory location is imprecise.
define void @test_write_before_memset_in_memset_region(ptr %result) {
; CHECK-LABEL: @test_write_before_memset_in_memset_region(
; CHECK-NEXT:    [[A:%.*]] = alloca [[T:%.*]], align 8
; CHECK-NEXT:    store i8 -1, ptr [[A]], align 1
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 8, i1 false)
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[RESULT:%.*]], ptr align 8 [[A]], i64 16, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca %T, align 8
  store i8 -1, ptr %a
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 8, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 false)
  ret void
}

; A write prior to the memset, which is part of the memcpy (but not memset) region.
; This cannot be optimized.
define void @test_write_before_memset_in_memcpy_region(ptr %result) {
; CHECK-LABEL: @test_write_before_memset_in_memcpy_region(
; CHECK-NEXT:    [[A:%.*]] = alloca [[T:%.*]], align 8
; CHECK-NEXT:    [[C:%.*]] = getelementptr inbounds [[T]], ptr [[A]], i64 0, i32 2
; CHECK-NEXT:    store i32 -1, ptr [[C]], align 4
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 8, i1 false)
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[RESULT:%.*]], ptr align 8 [[A]], i64 16, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca %T, align 8
  %c = getelementptr inbounds %T, ptr %a, i64 0, i32 2
  store i32 -1, ptr %c
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 8, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 false)
  ret void
}

; A write prior to the memset, which is part of both the memset and memcpy regions.
; This cannot be optimized.
define void @test_write_before_memset_in_both_regions(ptr %result) {
; CHECK-LABEL: @test_write_before_memset_in_both_regions(
; CHECK-NEXT:    [[A:%.*]] = alloca [[T:%.*]], align 8
; CHECK-NEXT:    [[C:%.*]] = getelementptr inbounds [[T]], ptr [[A]], i64 0, i32 1
; CHECK-NEXT:    store i32 -1, ptr [[C]], align 4
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 10, i1 false)
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[RESULT:%.*]], ptr align 8 [[A]], i64 16, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca %T, align 8
  %c = getelementptr inbounds %T, ptr %a, i64 0, i32 1
  store i32 -1, ptr %c
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 10, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 false)
  ret void
}

define void @test_negative_offset_memset(ptr %result) {
; CHECK-LABEL: @test_negative_offset_memset(
; CHECK-NEXT:    [[A1:%.*]] = alloca [16 x i8], align 8
; CHECK-NEXT:    [[A:%.*]] = getelementptr i8, ptr [[A1]], i32 4
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[A]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[RESULT:%.*]], i64 4
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[TMP1]], i8 0, i64 8, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca [ 16 x i8 ], align 8
  %b = getelementptr i8, ptr %a, i32 4
  call void @llvm.memset.p0.i64(ptr align 4 %b, i8 0, i64 12, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 12, i1 false)
  ret void
}

define void @test_offset_memsetcpy(ptr %result) {
; CHECK-LABEL: @test_offset_memsetcpy(
; CHECK-NEXT:    [[A1:%.*]] = alloca [16 x i8], align 8
; CHECK-NEXT:    [[A:%.*]] = getelementptr i8, ptr [[A1]], i32 4
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A1]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[RESULT:%.*]], i8 0, i64 8, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca [ 16 x i8 ], align 8
  %b = getelementptr i8, ptr %a, i32 4
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 12, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 4 %b, i64 12, i1 false)
  ret void
}

define void @test_two_memset(ptr %result) {
; CHECK-LABEL: @test_two_memset(
; CHECK-NEXT:    [[A:%.*]] = alloca [16 x i8], align 8
; CHECK-NEXT:    [[B:%.*]] = getelementptr i8, ptr [[A]], i32 12
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[A]], i8 0, i64 12, i1 false)
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[B]], i8 1, i64 4, i1 false)
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[RESULT:%.*]], ptr align 8 [[A]], i64 16, i1 false)
; CHECK-NEXT:    ret void
;
  %a = alloca [ 16 x i8 ], align 8
  %b = getelementptr i8, ptr %a, i32 12
  call void @llvm.memset.p0.i64(ptr align 8 %a, i8 0, i64 12, i1 false)
  call void @llvm.memset.p0.i64(ptr align 4 %b, i8 1, i64 4, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %result, ptr align 8 %a, i64 16, i1 false)
  ret void
}

; Allocate 26 bytes, memset 24 bytes starting from offset 2, memcpy out the whole area.
define void @test_negative_offset_memset_2(ptr %out) {
; CHECK-LABEL: @test_negative_offset_memset_2(
; CHECK-NEXT:    [[ALLOCA:%.*]] = alloca <{ [2 x i8], i64, i64, i64 }>, align 8
; CHECK-NEXT:    [[OFFSET:%.*]] = getelementptr i8, ptr [[ALLOCA]], i64 2
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[OFFSET]], i8 0, i64 24, i1 false)
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[OUT:%.*]], i64 2
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[TMP1]], i8 0, i64 24, i1 false)
; CHECK-NEXT:    ret void
;
  %alloca = alloca <{ [2 x i8], i64, i64, i64 }>
  %offset = getelementptr i8, ptr %alloca, i64 2
  call void @llvm.memset.p0.i64(ptr %offset, i8 0, i64 24, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %out, ptr %alloca, i64 26, i1 false)
  ret void
}

; Allocate 20 bytes, memset the last 10 bytes, memcpy out the first 15 bytes,
; meaning that only the last 5 bytes of the source are zeroed out.
define void @test_negative_offset_memset_3(ptr %out) {
; CHECK-LABEL: @test_negative_offset_memset_3(
; CHECK-NEXT:    [[ALLOCA:%.*]] = alloca [20 x i8], align 1
; CHECK-NEXT:    [[OFFSET:%.*]] = getelementptr i8, ptr [[ALLOCA]], i64 10
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[OFFSET]], i8 0, i64 10, i1 false)
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[OUT:%.*]], i64 10
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[TMP1]], i8 0, i64 5, i1 false)
; CHECK-NEXT:    ret void
;
  %alloca = alloca [20 x i8]
  %offset = getelementptr i8, ptr %alloca, i64 10
  call void @llvm.memset.p0.i64(ptr %offset, i8 0, i64 10, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %out, ptr %alloca, i64 15, i1 false)
  ret void
}

; Source/dest buffers have different alignment. Recompute it.
define void @test_negative_offset_memset_different_alignment(ptr %out) {
; CHECK-LABEL: @test_negative_offset_memset_different_alignment(
; CHECK-NEXT:    [[ALLOCA:%.*]] = alloca [20 x i8], align 1
; CHECK-NEXT:    [[OFFSET:%.*]] = getelementptr i8, ptr [[ALLOCA]], i64 4
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 1 [[OFFSET]], i8 0, i64 16, i1 false)
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[OUT:%.*]], i64 4
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 4 [[TMP1]], i8 0, i64 16, i1 false)
; CHECK-NEXT:    ret void
;
  %alloca = alloca [20 x i8], align 1
  %offset = getelementptr i8, ptr %alloca, i64 4
  call void @llvm.memset.p0.i64(ptr align 1 %offset, i8 0, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %out, ptr align 1 %alloca, i64 20, i1 false)
  ret void
}

; Allocate 20 bytes, memset the last 10 bytes, memcpy out the first 15 bytes
; to %out - 10, meaning that only the first 5 bytes of %out will be zeroed out.
define void @test_negative_offset_memset_and_negative_offset_memcpy_dest(ptr %out) {
; CHECK-LABEL: @test_negative_offset_memset_and_negative_offset_memcpy_dest(
; CHECK-NEXT:    [[ALLOCA:%.*]] = alloca [20 x i8], align 1
; CHECK-NEXT:    [[OFFSET:%.*]] = getelementptr i8, ptr [[ALLOCA]], i64 10
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[OFFSET]], i8 0, i64 10, i1 false)
; CHECK-NEXT:    [[OFFSET_OUT:%.*]] = getelementptr i8, ptr [[OUT:%.*]], i64 -10
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[OFFSET_OUT]], i64 10
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[TMP1]], i8 0, i64 5, i1 false)
; CHECK-NEXT:    ret void
;
  %alloca = alloca [20 x i8]
  %offset = getelementptr i8, ptr %alloca, i64 10
  call void @llvm.memset.p0.i64(ptr %offset, i8 0, i64 10, i1 false)
  %offset_out = getelementptr i8, ptr %out, i64 -10
  call void @llvm.memcpy.p0.p0.i64(ptr %offset_out, ptr %alloca, i64 15, i1 false)
  ret void
}

; Negative tests.
define void @test_negative_offset_memset_store_between(ptr %out) {
; CHECK-LABEL: @test_negative_offset_memset_store_between(
; CHECK-NEXT:    [[ALLOCA:%.*]] = alloca <{ [2 x i8], i64, i64, i64 }>, align 8
; CHECK-NEXT:    [[IDX_1:%.*]] = getelementptr inbounds nuw i8, ptr [[ALLOCA]], i64 1
; CHECK-NEXT:    store i8 1, ptr [[IDX_1]], align 1
; CHECK-NEXT:    [[OFFSET:%.*]] = getelementptr i8, ptr [[ALLOCA]], i64 2
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[OFFSET]], i8 0, i64 24, i1 false)
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[OUT:%.*]], ptr [[ALLOCA]], i64 26, i1 false)
; CHECK-NEXT:    ret void
;
  %alloca = alloca <{ [2 x i8], i64, i64, i64 }>
  %idx_1 = getelementptr inbounds nuw i8, ptr %alloca, i64 1
  store i8 1, ptr %idx_1
  %offset = getelementptr i8, ptr %alloca, i64 2
  call void @llvm.memset.p0.i64(ptr %offset, i8 0, i64 24, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %out, ptr %alloca, i64 26, i1 false)
  ret void
}

define void @test_negative_offset_memset_variable_sized(ptr %out, i64 %sz1, i64 %sz2) {
; CHECK-LABEL: @test_negative_offset_memset_variable_sized(
; CHECK-NEXT:    [[ALLOCA:%.*]] = alloca <{ [2 x i8], i64, i64, i64 }>, align 8
; CHECK-NEXT:    [[OFFSET:%.*]] = getelementptr i8, ptr [[ALLOCA]], i64 2
; CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr [[OFFSET]], i8 0, i64 [[SZ1:%.*]], i1 false)
; CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr [[OUT:%.*]], ptr [[ALLOCA]], i64 [[SZ2:%.*]], i1 false)
; CHECK-NEXT:    ret void
;
  %alloca = alloca <{ [2 x i8], i64, i64, i64 }>
  %offset = getelementptr i8, ptr %alloca, i64 2
  call void @llvm.memset.p0.i64(ptr %offset, i8 0, i64 %sz1, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr %out, ptr %alloca, i64 %sz2, i1 false)
  ret void
}

declare ptr @malloc(i64)
declare void @free(ptr)

declare void @llvm.memset.p0.i64(ptr nocapture, i8, i64, i1)
declare void @llvm.memcpy.p0.p0.i64(ptr nocapture, ptr nocapture readonly, i64, i1)

declare void @llvm.lifetime.start.p0(ptr nocapture)
declare void @llvm.lifetime.end.p0(ptr nocapture)
