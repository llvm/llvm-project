; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 6
; RUN: opt -passes=vector-combine -S -mtriple=x86_64-unknown-linux-gnu < %s | FileCheck %s

define i1 @or_zext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @or_zext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.or.v4i16(<4 x i16> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %zext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @or_zext_i3(<4 x i3> %x) {
; CHECK-LABEL: define i1 @or_zext_i3(
; CHECK-SAME: <4 x i3> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i3 @llvm.vector.reduce.or.v4i3(<4 x i3> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i3 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i3> %x to <4 x i32>
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %zext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; negative: costly for X86
define i1 @or_zext_v3_costly(<3 x i8> %x) {
; CHECK-LABEL: define i1 @or_zext_v3_costly(
; CHECK-SAME: <3 x i8> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <3 x i8> [[X]] to <3 x i32>
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.or.v3i32(<3 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <3 x i8> %x to <3 x i32>
  %red = call i32 @llvm.vector.reduce.or.v3i32(<3 x i32> %zext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @or_sext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @or_sext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.or.v4i16(<4 x i16> [[X]])
; CHECK-NEXT:    [[RED:%.*]] = sext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %sext = sext <4 x i16> %x to <4 x i32>
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %sext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @or_neg(<4 x i32> %x) {
; CHECK-LABEL: define i1 @or_neg(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %neg = sub <4 x i32> zeroinitializer, %x
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %neg)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @or_mul(<4 x i32> %x) {
; CHECK-LABEL: define i1 @or_mul(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %mul = mul nuw <4 x i32> %x, splat (i32 7)
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @or_shl(<4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @or_shl(
; CHECK-SAME: <4 x i32> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shl = shl nuw <4 x i32> %x, %y
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umin_zext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @umin_zext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.umin.v4i16(<4 x i16> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %zext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umin_sext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @umin_sext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.umin.v4i16(<4 x i16> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %sext = sext <4 x i16> %x to <4 x i32>
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %sext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umin_neg(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umin_neg(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %neg = sub <4 x i32> zeroinitializer, %x
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %neg)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umin_mul(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umin_mul(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %mul = mul nuw <4 x i32> %x, splat (i32 7)
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umin_shl(<4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @umin_shl(
; CHECK-SAME: <4 x i32> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shl = shl nuw <4 x i32> %x, %y
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umax_zext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @umax_zext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.or.v4i16(<4 x i16> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %zext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umax_sext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @umax_sext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.or.v4i16(<4 x i16> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %sext = sext <4 x i16> %x to <4 x i32>
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %sext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umax_neg(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umax_neg(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %neg = sub <4 x i32> zeroinitializer, %x
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %neg)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umax_mul(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umax_mul(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %mul = mul nuw <4 x i32> %x, splat (i32 7)
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umax_shl(<4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @umax_shl(
; CHECK-SAME: <4 x i32> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shl = shl nuw <4 x i32> %x, %y
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @smin_zext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @smin_zext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[AND:%.*]] = and <4 x i16> [[X]], splat (i16 32767)
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.smin.v4i16(<4 x i16> [[AND]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %and = and <4 x i16> %x, splat (i16 32767)
  %zext = zext <4 x i16> %and to <4 x i32>
  %red = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %zext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @smin_sext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @smin_sext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[AND:%.*]] = and <4 x i16> [[X]], splat (i16 32767)
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.smin.v4i16(<4 x i16> [[AND]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %and = and <4 x i16> %x, splat (i16 32767)
  %sext = sext <4 x i16> %and to <4 x i32>
  %red = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %sext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; neg is incompatible with smin constraints, expected not to combine
define i1 @smin_neg(<4 x i16> %x) {
; CHECK-LABEL: define i1 @smin_neg(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[NEG:%.*]] = sub nsw <4 x i32> zeroinitializer, [[ZEXT]]
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> [[NEG]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %neg = sub nsw <4 x i32> zeroinitializer, %zext
  %red = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %neg)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @smin_mul(<4 x i16> %x) {
; CHECK-LABEL: define i1 @smin_mul(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %mul = mul nuw nsw <4 x i32> %zext, splat (i32 7)
  %red = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @smin_shl(<4 x i16> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @smin_shl(
; CHECK-SAME: <4 x i16> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %ymasked = and <4 x i32> %y, splat (i32 7)
  %shl = shl nuw nsw <4 x i32> %zext, %ymasked
  %red = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @smax_zext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @smax_zext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[AND:%.*]] = and <4 x i16> [[X]], splat (i16 32767)
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.smax.v4i16(<4 x i16> [[AND]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %and = and <4 x i16> %x, splat (i16 32767)
  %zext = zext <4 x i16> %and to <4 x i32>
  %red = call i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %zext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @smax_sext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @smax_sext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[AND:%.*]] = and <4 x i16> [[X]], splat (i16 32767)
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.smax.v4i16(<4 x i16> [[AND]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %and = and <4 x i16> %x, splat (i16 32767)
  %sext = sext <4 x i16> %and to <4 x i32>
  %red = call i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %sext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; neg is incompatible with smax constraints, expected not to combine
define i1 @smax_neg(<4 x i16> %x) {
; CHECK-LABEL: define i1 @smax_neg(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[NEG:%.*]] = sub nsw <4 x i32> zeroinitializer, [[ZEXT]]
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> [[NEG]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %neg = sub nsw <4 x i32> zeroinitializer, %zext
  %red = call i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %neg)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @smax_mul(<4 x i16> %x) {
; CHECK-LABEL: define i1 @smax_mul(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %mul = mul nuw nsw <4 x i32> %zext, splat (i32 7)
  %red = call i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @smax_shl(<4 x i16> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @smax_shl(
; CHECK-SAME: <4 x i16> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %ymasked = and <4 x i32> %y, splat (i32 7)
  %shl = shl nuw nsw <4 x i32> %zext, %ymasked
  %red = call i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @add_zext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @add_zext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[AND:%.*]] = and <4 x i16> [[X]], splat (i16 8191)
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.add.v4i16(<4 x i16> [[AND]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %and = and <4 x i16> %x, splat (i16 8191)
  %zext = zext <4 x i16> %and to <4 x i32>
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %zext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @add_sext(<4 x i16> %x) {
; CHECK-LABEL: define i1 @add_sext(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[AND:%.*]] = and <4 x i16> [[X]], splat (i16 8191)
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.add.v4i16(<4 x i16> [[AND]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %and = and <4 x i16> %x, splat (i16 8191)
  %sext = sext <4 x i16> %and to <4 x i32>
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %sext)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; neg is incompatible with add constraints, expected not to combine
define i1 @add_neg(<4 x i16> %x) {
; CHECK-LABEL: define i1 @add_neg(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[NEG:%.*]] = sub nsw <4 x i32> zeroinitializer, [[ZEXT]]
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[NEG]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %neg = sub nsw <4 x i32> zeroinitializer, %zext
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %neg)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @add_mul(<4 x i16> %x) {
; CHECK-LABEL: define i1 @add_mul(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %mul = mul nuw <4 x i32> %zext, splat (i32 7)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @add_shl(<4 x i16> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @add_shl(
; CHECK-SAME: <4 x i16> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %ymasked = and <4 x i32> %y, splat (i32 7)
  %shl = shl nuw <4 x i32> %zext, %ymasked
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @add_shl_ne(<4 x i16> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @add_shl_ne(
; CHECK-SAME: <4 x i16> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp ne i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %ymasked = and <4 x i32> %y, splat (i32 7)
  %shl = shl nuw <4 x i32> %zext, %ymasked
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shl)
  %cmp = icmp ne i32 %red, 0
  ret i1 %cmp
}

; x may be negative, expected not to combine
define i1 @add_shl_negative(<4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @add_shl_negative(
; CHECK-SAME: <4 x i32> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[YMASKED:%.*]] = and <4 x i32> [[Y]], splat (i32 7)
; CHECK-NEXT:    [[SHL:%.*]] = shl nsw <4 x i32> [[X]], [[YMASKED]]
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHL]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %ymasked = and <4 x i32> %y, splat (i32 7)
  %shl = shl nsw <4 x i32> %x, %ymasked
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; comparison with non-zero, expected not to combine
define i1 @add_shl_nonzero_cmp(<4 x i16> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @add_shl_nonzero_cmp(
; CHECK-SAME: <4 x i16> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[YMASKED:%.*]] = and <4 x i32> [[Y]], splat (i32 7)
; CHECK-NEXT:    [[SHL:%.*]] = shl nsw <4 x i32> [[ZEXT]], [[YMASKED]]
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHL]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 42
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %ymasked = and <4 x i32> %y, splat (i32 7)
  %shl = shl nsw <4 x i32> %zext, %ymasked
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 42
  ret i1 %cmp
}

; shl has multiple uses, expected not to combine
define i1 @add_shl_multiuse(<4 x i16> %x, <4 x i32> %y, ptr %p) {
; CHECK-LABEL: define i1 @add_shl_multiuse(
; CHECK-SAME: <4 x i16> [[X:%.*]], <4 x i32> [[Y:%.*]], ptr [[P:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[YMASKED:%.*]] = and <4 x i32> [[Y]], splat (i32 7)
; CHECK-NEXT:    [[SHL:%.*]] = shl nsw <4 x i32> [[ZEXT]], [[YMASKED]]
; CHECK-NEXT:    store <4 x i32> [[SHL]], ptr [[P]], align 16
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHL]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %ymasked = and <4 x i32> %y, splat (i32 7)
  %shl = shl nsw <4 x i32> %zext, %ymasked
  store <4 x i32> %shl, ptr %p
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; shift amount unbounded, expected not to combine
define i1 @add_shl_unbounded(<4 x i16> %x, <4 x i32> %y) {
; CHECK-LABEL: define i1 @add_shl_unbounded(
; CHECK-SAME: <4 x i16> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[SHL:%.*]] = shl nsw <4 x i32> [[ZEXT]], [[Y]]
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHL]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %shl = shl nsw <4 x i32> %zext, %y
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shl)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @add_mul_nonsplat(<4 x i16> %x) {
; CHECK-LABEL: define i1 @add_mul_nonsplat(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %mul = mul nuw <4 x i32> %zext, <i32 1, i32 2, i32 3, i32 4>
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @add_mul_poison(<4 x i16> %x) {
; CHECK-LABEL: define i1 @add_mul_poison(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[ZEXT]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %mul = mul nuw <4 x i32> %zext, <i32 1, i32 poison, i32 3, i32 4>
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; constant has zero lane, expected not to combine
define i1 @add_mul_zero_lane(<4 x i16> %x) {
; CHECK-LABEL: define i1 @add_mul_zero_lane(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[MUL:%.*]] = mul nuw <4 x i32> [[ZEXT]], <i32 1, i32 0, i32 3, i32 4>
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[MUL]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %mul = mul nuw <4 x i32> %zext, <i32 1, i32 0, i32 3, i32 4>
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; constant has negative lane, expected not to combine
define i1 @add_mul_neg_const(<4 x i16> %x) {
; CHECK-LABEL: define i1 @add_mul_neg_const(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[ZEXT:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[MUL:%.*]] = mul nuw <4 x i32> [[ZEXT]], <i32 3, i32 -1, i32 2, i32 5>
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[MUL]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %zext = zext <4 x i16> %x to <4 x i32>
  %mul = mul nuw <4 x i32> %zext, <i32 3, i32 -1, i32 2, i32 5>
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %mul)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

declare void @foo(<4 x i32>)

define void @or_zext_two_blocks(<4 x i16> %x) {
; CHECK-LABEL: define void @or_zext_two_blocks(
; CHECK-SAME: <4 x i16> [[X:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[A:%.*]] = zext <4 x i16> [[X]] to <4 x i32>
; CHECK-NEXT:    [[TMP0:%.*]] = call i16 @llvm.vector.reduce.or.v4i16(<4 x i16> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i16 [[TMP0]], 0
; CHECK-NEXT:    br i1 [[CMP]], label %[[THEN:.*]], label %[[EXIT:.*]]
; CHECK:       [[THEN]]:
; CHECK-NEXT:    call void @foo(<4 x i32> [[A]])
; CHECK-NEXT:    br label %[[EXIT]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;
entry:
  %a = zext <4 x i16> %x to <4 x i32>
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a)
  %cmp = icmp eq i32 %red, 0
  br i1 %cmp, label %then, label %exit

then:
  call void @foo(<4 x i32> %a)
  br label %exit

exit:
  ret void
}

define void @or_shl_two_blocks(<4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: define void @or_shl_two_blocks(
; CHECK-SAME: <4 x i32> [[X:%.*]], <4 x i32> [[Y:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[A:%.*]] = shl nuw <4 x i32> [[X]], [[Y]]
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    br i1 [[CMP]], label %[[THEN:.*]], label %[[EXIT:.*]]
; CHECK:       [[THEN]]:
; CHECK-NEXT:    call void @foo(<4 x i32> [[A]])
; CHECK-NEXT:    br label %[[EXIT]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;
entry:
  %a = shl nuw <4 x i32> %x, %y
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a)
  %cmp = icmp eq i32 %red, 0
  br i1 %cmp, label %then, label %exit

then:
  call void @foo(<4 x i32> %a)
  br label %exit

exit:
  ret void
}
