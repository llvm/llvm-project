; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -S -passes=vector-combine -mtriple=aarch64 < %s | FileCheck %s

define i1 @or_eq_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @or_eq_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @or_ne_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @or_ne_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 0
  ret i1 %cmp
}

define i1 @or_eq_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @or_eq_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 1
  ret i1 %cmp
}

define i1 @or_ne_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @or_ne_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 1
  ret i1 %cmp
}

define i1 @umax_eq_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umax_eq_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umax_ne_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umax_ne_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 0
  ret i1 %cmp
}

define i1 @umax_eq_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umax_eq_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 1
  ret i1 %cmp
}

define i1 @umax_ne_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umax_ne_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 1
  ret i1 %cmp
}

define i1 @and_eq_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @and_eq_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @and_ne_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @and_ne_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 0
  ret i1 %cmp
}

define i1 @and_eq_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @and_eq_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 1
  ret i1 %cmp
}

define i1 @and_ne_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @and_ne_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 1
  ret i1 %cmp
}

define i1 @umin_eq_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umin_eq_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @umin_ne_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umin_ne_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 0
  ret i1 %cmp
}

define i1 @umin_eq_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umin_eq_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 1
  ret i1 %cmp
}

define i1 @umin_ne_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @umin_ne_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 1
  ret i1 %cmp
}

define i1 @add_eq_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @add_eq_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @add_ne_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @add_ne_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 0
  ret i1 %cmp
}

define i1 @add_eq_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @add_eq_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 4
  ret i1 %cmp
}

define i1 @add_ne_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @add_ne_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp ne i32 %red, 4
  ret i1 %cmp
}

define i1 @add_ult_max(<4 x i32> %x) {
; CHECK-LABEL: define i1 @add_ult_max(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp ult i32 %red, 4
  ret i1 %cmp
}

define i1 @add_ugt_max_minus_1(<4 x i32> %x) {
; CHECK-LABEL: define i1 @add_ugt_max_minus_1(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp ugt i32 %red, 3
  ret i1 %cmp
}

define i1 @ashr_add_eq_0(<4 x i32> %x) {
; CHECK-LABEL: define i1 @ashr_add_eq_0(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = ashr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

define i1 @or_eq_0_v8i16(<8 x i16> %x) {
; CHECK-LABEL: define i1 @or_eq_0_v8i16(
; CHECK-SAME: <8 x i16> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i16 @llvm.vector.reduce.umax.v8i16(<8 x i16> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i16 [[TMP1]], -1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <8 x i16> %x, splat (i16 15)
  %red = call i16 @llvm.vector.reduce.or.v8i16(<8 x i16> %shr)
  %cmp = icmp eq i16 %red, 0
  ret i1 %cmp
}

define i1 @and_eq_max_v2i64(<2 x i64> %x) {
; CHECK-LABEL: define i1 @and_eq_max_v2i64(
; CHECK-SAME: <2 x i64> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP1:%.*]] = call i64 @llvm.vector.reduce.umin.v2i64(<2 x i64> [[X]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i64 [[TMP1]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <2 x i64> %x, splat (i64 63)
  %red = call i64 @llvm.vector.reduce.and.v2i64(<2 x i64> %shr)
  %cmp = icmp eq i64 %red, 1
  ret i1 %cmp
}

; negative: shift amount is not bitwidth-1
define i1 @negative_wrong_shift(<4 x i32> %x) {
; CHECK-LABEL: define i1 @negative_wrong_shift(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[SHR:%.*]] = lshr <4 x i32> [[X]], splat (i32 30)
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHR]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 30)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; negative: comparison constant is neither 0 nor max
define i1 @negative_wrong_cmp_const(<4 x i32> %x) {
; CHECK-LABEL: define i1 @negative_wrong_cmp_const(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[SHR:%.*]] = lshr <4 x i32> [[X]], splat (i32 31)
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHR]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 2
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 2
  ret i1 %cmp
}

; negative: shift has multiple uses
define i1 @negative_multi_use_shift(<4 x i32> %x, ptr %p) {
; CHECK-LABEL: define i1 @negative_multi_use_shift(
; CHECK-SAME: <4 x i32> [[X:%.*]], ptr [[P:%.*]]) {
; CHECK-NEXT:    [[SHR:%.*]] = lshr <4 x i32> [[X]], splat (i32 31)
; CHECK-NEXT:    store <4 x i32> [[SHR]], ptr [[P]], align 16
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHR]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  store <4 x i32> %shr, ptr %p
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp eq i32 %red, 0
  ret i1 %cmp
}

; negative: sgt with wrong constant (not 0 or max-1)
define i1 @negative_sgt_wrong_const(<4 x i32> %x) {
; CHECK-LABEL: define i1 @negative_sgt_wrong_const(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[SHR:%.*]] = lshr <4 x i32> [[X]], splat (i32 31)
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHR]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[RED]], 1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp sgt i32 %red, 1
  ret i1 %cmp
}

; negative: slt with wrong constant (not 1 or max)
define i1 @negative_slt_wrong_const(<4 x i32> %x) {
; CHECK-LABEL: define i1 @negative_slt_wrong_const(
; CHECK-SAME: <4 x i32> [[X:%.*]]) {
; CHECK-NEXT:    [[SHR:%.*]] = lshr <4 x i32> [[X]], splat (i32 31)
; CHECK-NEXT:    [[RED:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[SHR]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[RED]], 2
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <4 x i32> %x, splat (i32 31)
  %red = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %shr)
  %cmp = icmp slt i32 %red, 2
  ret i1 %cmp
}

; negative: if reduce.add can wrap, transformation is incorrect
define i1 @negative_add_numelts_overflow(<8 x i2> %x) {
; CHECK-LABEL: define i1 @negative_add_numelts_overflow(
; CHECK-SAME: <8 x i2> [[X:%.*]]) {
; CHECK-NEXT:    [[SHR:%.*]] = lshr <8 x i2> [[X]], splat (i2 1)
; CHECK-NEXT:    [[RED:%.*]] = call i2 @llvm.vector.reduce.add.v8i2(<8 x i2> [[SHR]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i2 [[RED]], 0
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %shr = lshr <8 x i2> %x, splat (i2 1)
  %red = call i2 @llvm.vector.reduce.add.v8i2(<8 x i2> %shr)
  %cmp = icmp eq i2 %red, 0
  ret i1 %cmp
}
