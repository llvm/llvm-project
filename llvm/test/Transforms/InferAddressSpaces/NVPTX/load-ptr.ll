; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -S -passes=infer-address-spaces %s | FileCheck %s

target triple = "nvptx64-nvidia-cuda"

define ptx_kernel void @globalmem_flat_ptr_with_global(ptr %a, ptr %b){
; CHECK-LABEL: define ptx_kernel void @globalmem_flat_ptr_with_global(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = addrspacecast ptr [[A]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[B]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr addrspace(1) [[TMP0]], align 8
; CHECK-NEXT:    [[DOTGLOBAL:%.*]] = addrspacecast ptr [[TMP2]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
; CHECK-NEXT:    [[IDXPROM:%.*]] = zext nneg i32 [[TMP3]] to i64
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[DOTGLOBAL]], i64 [[IDXPROM]]
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr addrspace(1) [[ARRAYIDX]], align 4
; CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[TMP1]], i64 [[IDXPROM]]
; CHECK-NEXT:    store i32 [[TMP4]], ptr addrspace(1) [[ARRAYIDX3]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %0 = load ptr, ptr %a, align 8
  %1 = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %idxprom = zext nneg i32 %1 to i64
  %arrayidx = getelementptr inbounds nuw i32, ptr %0, i64 %idxprom
  %2 = load i32, ptr %arrayidx, align 4
  %arrayidx3 = getelementptr inbounds nuw i32, ptr %b, i64 %idxprom
  store i32 %2, ptr %arrayidx3, align 4
  ret void
}

@shared_ptrs = internal unnamed_addr addrspace(3) global [32 x ptr] poison, align 8

define ptx_kernel void @sharedmem_flat_ptr_with_global(ptr %a, ptr %b) {
; CHECK-LABEL: define ptx_kernel void @sharedmem_flat_ptr_with_global(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = addrspacecast ptr [[A]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP2:%.*]] = addrspacecast ptr [[B]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
; CHECK-NEXT:    [[IDXPROM:%.*]] = zext nneg i32 [[TMP3]] to i64
; CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[TMP0]], i64 [[IDXPROM]]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = addrspacecast ptr addrspace(1) [[ARRAYIDX1]] to ptr
; CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds ptr, ptr addrspace(3) @shared_ptrs, i64 [[IDXPROM]]
; CHECK-NEXT:    store ptr [[ARRAYIDX]], ptr addrspace(3) [[ARRAYIDX3]], align 8
; CHECK-NEXT:    tail call void @llvm.nvvm.bar.warp.sync(i32 -1)
; CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr addrspace(3) [[ARRAYIDX3]], align 8
; CHECK-NEXT:    [[DOTGLOBAL:%.*]] = addrspacecast ptr [[TMP4]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr addrspace(1) [[DOTGLOBAL]], align 4
; CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[TMP2]], i64 [[IDXPROM]]
; CHECK-NEXT:    store i32 [[TMP5]], ptr addrspace(1) [[ARRAYIDX9]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %0 = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %idxprom = zext nneg i32 %0 to i64
  %arrayidx = getelementptr inbounds nuw i32, ptr %a, i64 %idxprom
  %arrayidx3 = getelementptr inbounds nuw ptr, ptr addrspacecast (ptr addrspace(3) @shared_ptrs to ptr), i64 %idxprom
  store ptr %arrayidx, ptr %arrayidx3, align 8
  tail call void @llvm.nvvm.bar.warp.sync(i32 -1)
  %1 = load ptr, ptr %arrayidx3, align 8
  %2 = load i32, ptr %1, align 4
  %arrayidx9 = getelementptr inbounds nuw i32, ptr %b, i64 %idxprom
  store i32 %2, ptr %arrayidx9, align 4
  ret void
}

@a = dso_local addrspace(1) externally_initialized global ptr null, align 8
@llvm.compiler.used = appending global [1 x ptr] [ptr addrspacecast (ptr addrspace(1) @a to ptr)], section "llvm.metadata"

define dso_local ptx_kernel void @device_var_with_global(ptr %b) {
; CHECK-LABEL: define dso_local ptx_kernel void @device_var_with_global(
; CHECK-SAME: ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = addrspacecast ptr [[B]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr addrspace(1) @a, align 8
; CHECK-NEXT:    [[DOTGLOBAL1:%.*]] = addrspacecast ptr [[TMP1]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr addrspace(1) [[DOTGLOBAL1]], align 8
; CHECK-NEXT:    [[DOTGLOBAL:%.*]] = addrspacecast ptr [[TMP2]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP3:%.*]] = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
; CHECK-NEXT:    [[IDXPROM:%.*]] = zext nneg i32 [[TMP3]] to i64
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[DOTGLOBAL]], i64 [[IDXPROM]]
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr addrspace(1) [[ARRAYIDX]], align 4
; CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[TMP0]], i64 [[IDXPROM]]
; CHECK-NEXT:    store i32 [[TMP4]], ptr addrspace(1) [[ARRAYIDX3]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %0 = load ptr, ptr addrspacecast (ptr addrspace(1) @a to ptr), align 8
  %1 = load ptr, ptr %0, align 8
  %2 = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %idxprom = zext nneg i32 %2 to i64
  %arrayidx = getelementptr inbounds nuw i32, ptr %1, i64 %idxprom
  %3 = load i32, ptr %arrayidx, align 4
  %arrayidx3 = getelementptr inbounds nuw i32, ptr %b, i64 %idxprom
  store i32 %3, ptr %arrayidx3, align 4
  ret void
}


define ptx_kernel void @globalmem_flat_ptr_with_global_clobber(ptr %a, ptr %b) {
; CHECK-LABEL: define ptx_kernel void @globalmem_flat_ptr_with_global_clobber(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = addrspacecast ptr [[A]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[B]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr addrspace(1) [[TMP0]], align 8
; CHECK-NEXT:    [[DOTGLOBAL:%.*]] = addrspacecast ptr [[TMP2]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP3:%.*]] = addrspacecast ptr addrspace(1) [[DOTGLOBAL]] to ptr
; CHECK-NEXT:    [[TMP4:%.*]] = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
; CHECK-NEXT:    [[IDXPROM:%.*]] = zext nneg i32 [[TMP4]] to i64
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds ptr, ptr addrspace(1) [[TMP1]], i64 [[IDXPROM]]
; CHECK-NEXT:    store ptr [[TMP3]], ptr addrspace(1) [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr addrspace(1) [[DOTGLOBAL]], align 4
; CHECK-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds i8, ptr addrspace(1) [[DOTGLOBAL]], i64 4
; CHECK-NEXT:    store i32 [[TMP5]], ptr addrspace(1) [[ARRAYIDX4]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %0 = load ptr, ptr %a, align 8
  %1 = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %idxprom = zext nneg i32 %1 to i64
  %arrayidx = getelementptr inbounds nuw ptr, ptr %b, i64 %idxprom
  ; 1 = MemoryDef(liveOnEntry)
  store ptr %0, ptr %arrayidx, align 8
  ; MemoryUse(1)
  %2 = load i32, ptr %0, align 4
  %arrayidx4 = getelementptr inbounds nuw i8, ptr %0, i64 4
  ; 2 = MemoryDef(1)
  store i32 %2, ptr %arrayidx4, align 4
  ret void
}


@s_int2 = internal addrspace(3) global [2 x i32] poison, align 4

; Function Attrs: convergent mustprogress noinline norecurse nounwind
define dso_local ptx_kernel void @phi_clobber_with_diff_as(ptr %a, ptr %b) {
; CHECK-LABEL: define dso_local ptx_kernel void @phi_clobber_with_diff_as(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = addrspacecast ptr [[A]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[B]] to ptr addrspace(1)
; CHECK-NEXT:    store i32 0, ptr addrspace(3) @s_int2, align 4
; CHECK-NEXT:    store i32 0, ptr addrspace(3) getelementptr inbounds nuw (i8, ptr addrspace(3) @s_int2, i64 4), align 4
; CHECK-NEXT:    tail call void @llvm.nvvm.bar.warp.sync(i32 -1)
; CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
; CHECK-NEXT:    [[CMP:%.*]] = icmp samesign ugt i32 [[TMP2]], 15
; CHECK-NEXT:    [[IDXPROM:%.*]] = zext nneg i32 [[TMP2]] to i64
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds ptr, ptr addrspace(1) [[TMP0]], i64 [[IDXPROM]]
; CHECK-NEXT:    br i1 [[CMP]], label %[[IF_THEN:.*]], label %[[ENTRY_IF_END_CRIT_EDGE:.*]]
; CHECK:       [[ENTRY_IF_END_CRIT_EDGE]]:
; CHECK-NEXT:    [[DOTPRE:%.*]] = load ptr, ptr addrspace(1) [[ARRAYIDX]], align 8
; CHECK-NEXT:    br label %[[IF_END:.*]]
; CHECK:       [[IF_THEN]]:
; CHECK-NEXT:    store ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), ptr addrspace(1) [[ARRAYIDX]], align 8
; CHECK-NEXT:    br label %[[IF_END]]
; CHECK:       [[IF_END]]:
; CHECK-NEXT:    [[TMP3:%.*]] = phi ptr [ [[DOTPRE]], %[[ENTRY_IF_END_CRIT_EDGE]] ], [ addrspacecast (ptr addrspace(3) @s_int2 to ptr), %[[IF_THEN]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[TMP1]], i64 [[IDXPROM]]
; CHECK-NEXT:    store i32 [[TMP4]], ptr addrspace(1) [[ARRAYIDX7]], align 4
; CHECK-NEXT:    ret void
;
entry:
  store i32 0, ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), align 4
  store i32 0, ptr getelementptr inbounds nuw (i8, ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), i64 4), align 4
  tail call void @llvm.nvvm.bar.warp.sync(i32 -1)
  %0 = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %cmp = icmp samesign ugt i32 %0, 15
  %idxprom = zext nneg i32 %0 to i64
  %arrayidx = getelementptr inbounds nuw ptr, ptr %a, i64 %idxprom
  br i1 %cmp, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  %.pre = load ptr, ptr %arrayidx, align 8
  br label %if.end

if.then:                                          ; preds = %entry
  store ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), ptr %arrayidx, align 8
  br label %if.end

if.end:                                           ; preds = %entry.if.end_crit_edge, %if.then
  %1 = phi ptr [ %.pre, %entry.if.end_crit_edge ], [ addrspacecast (ptr addrspace(3) @s_int2 to ptr), %if.then ]
  %2 = load i32, ptr %1, align 4
  %arrayidx7 = getelementptr inbounds nuw i32, ptr %b, i64 %idxprom
  store i32 %2, ptr %arrayidx7, align 4
  ret void
}

define ptx_kernel void @phi_clobber_with_same_as(ptr %a, ptr %b) {
; CHECK-LABEL: define ptx_kernel void @phi_clobber_with_same_as(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = addrspacecast ptr [[A]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[B]] to ptr addrspace(1)
; CHECK-NEXT:    store i32 0, ptr addrspace(3) @s_int2, align 4
; CHECK-NEXT:    store i32 0, ptr addrspace(3) getelementptr inbounds nuw (i8, ptr addrspace(3) @s_int2, i64 4), align 4
; CHECK-NEXT:    tail call void @llvm.nvvm.bar.warp.sync(i32 -1)
; CHECK-NEXT:    [[TMP2:%.*]] = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
; CHECK-NEXT:    [[CMP:%.*]] = icmp samesign ugt i32 [[TMP2]], 15
; CHECK-NEXT:    [[IDXPROM:%.*]] = zext nneg i32 [[TMP2]] to i64
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds ptr, ptr addrspace(1) [[TMP0]], i64 [[IDXPROM]]
; CHECK-NEXT:    br i1 [[CMP]], label %[[IF_THEN:.*]], label %[[ENTRY_IF_END_CRIT_EDGE:.*]]
; CHECK:       [[ENTRY_IF_END_CRIT_EDGE]]:
; CHECK-NEXT:    store ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), ptr addrspace(1) [[ARRAYIDX]], align 8
; CHECK-NEXT:    br label %[[IF_END:.*]]
; CHECK:       [[IF_THEN]]:
; CHECK-NEXT:    store ptr addrspacecast (ptr addrspace(3) getelementptr inbounds nuw (i8, ptr addrspace(3) @s_int2, i64 4) to ptr), ptr addrspace(1) [[ARRAYIDX]], align 8
; CHECK-NEXT:    br label %[[IF_END]]
; CHECK:       [[IF_END]]:
; CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr addrspace(1) [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[DOTGLOBAL:%.*]] = addrspacecast ptr [[TMP3]] to ptr addrspace(3)
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr addrspace(3) [[DOTGLOBAL]], align 4
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[TMP1]], i64 [[IDXPROM]]
; CHECK-NEXT:    store i32 [[TMP4]], ptr addrspace(1) [[ARRAYIDX7]], align 4
; CHECK-NEXT:    ret void
;
entry:
  store i32 0, ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), align 4
  store i32 0, ptr getelementptr inbounds nuw (i8, ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), i64 4), align 4
  tail call void @llvm.nvvm.bar.warp.sync(i32 -1)
  %0 = tail call noundef i32 @llvm.nvvm.read.ptx.sreg.tid.x()
  %cmp = icmp samesign ugt i32 %0, 15
  %idxprom = zext nneg i32 %0 to i64
  %arrayidx = getelementptr inbounds nuw ptr, ptr %a, i64 %idxprom
  br i1 %cmp, label %if.then, label %entry.if.end_crit_edge

entry.if.end_crit_edge:                           ; preds = %entry
  store ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), ptr %arrayidx, align 8
  br label %if.end

if.then:                                          ; preds = %entry
  store ptr getelementptr inbounds nuw (i8, ptr addrspacecast (ptr addrspace(3) @s_int2 to ptr), i64 4), ptr %arrayidx, align 8
  br label %if.end

if.end:                                           ; preds = %entry.if.end_crit_edge, %if.then
  %1 = load ptr, ptr %arrayidx, align 8
  %2 = load i32, ptr %1, align 4
  %arrayidx7 = getelementptr inbounds nuw i32, ptr %b, i64 %idxprom
  store i32 %2, ptr %arrayidx7, align 4
  ret void
}

declare i32 @llvm.nvvm.read.ptx.sreg.tid.x()
declare void @llvm.nvvm.bar.warp.sync(i32)
