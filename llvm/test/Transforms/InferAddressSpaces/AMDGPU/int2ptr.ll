; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 6
; RUN: opt -S -mtriple=amdgcn-amd-amdhsa -passes=infer-address-spaces %s | FileCheck %s

; Test that address space inference works correctly for inttoptr/ptrtoint
; patterns when the pointer manipulation is within the preserved mask.
; AMDGPU uses 2^32-aligned apertures for local memory, so modifications
; to the lower 32 bits are safe.

; Local (shared) memory tests - addrspace(3)

define void @test_xor_local(ptr addrspace(3) %sp) {
; CHECK-LABEL: define void @test_xor_local(
; CHECK-SAME: ptr addrspace(3) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(3) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = xor i64 [[A]], 4095
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[GP2]] to ptr addrspace(3)
; CHECK-NEXT:    store i16 0, ptr addrspace(3) [[TMP1]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(3) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  %b = xor i64 %a, 4095
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

define void @test_xor_local_max32bit(ptr addrspace(3) %sp) {
; CHECK-LABEL: define void @test_xor_local_max32bit(
; CHECK-SAME: ptr addrspace(3) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(3) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = xor i64 [[A]], 4294967295
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[GP2]] to ptr addrspace(3)
; CHECK-NEXT:    store i16 0, ptr addrspace(3) [[TMP1]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(3) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  ; 0xFFFFFFFF - maximum 32-bit value, should still be optimized
  %b = xor i64 %a, 4294967295
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

define void @test_xor_local_fail_bit33(ptr addrspace(3) %sp) {
; CHECK-LABEL: define void @test_xor_local_fail_bit33(
; CHECK-SAME: ptr addrspace(3) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(3) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = xor i64 [[A]], 4294967296
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    store i16 0, ptr [[GP2]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(3) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  ; 0x100000000 - bit 32 set, should NOT be optimized
  %b = xor i64 %a, 4294967296
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

define void @test_or_local(ptr addrspace(3) %sp) {
; CHECK-LABEL: define void @test_or_local(
; CHECK-SAME: ptr addrspace(3) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(3) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = or i64 [[A]], 255
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[GP2]] to ptr addrspace(3)
; CHECK-NEXT:    store i16 0, ptr addrspace(3) [[TMP1]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(3) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  %b = or i64 %a, 255
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

define void @test_and_local(ptr addrspace(3) %sp) {
; CHECK-LABEL: define void @test_and_local(
; CHECK-SAME: ptr addrspace(3) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(3) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = and i64 [[A]], -4096
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[GP2]] to ptr addrspace(3)
; CHECK-NEXT:    store i16 0, ptr addrspace(3) [[TMP1]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(3) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  ; -4096 = 0xFFFFFFFFFFFFF000 - clears low 12 bits, should be optimized
  %b = and i64 %a, -4096
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

define void @test_and_local_fail(ptr addrspace(3) %sp) {
; CHECK-LABEL: define void @test_and_local_fail(
; CHECK-SAME: ptr addrspace(3) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(3) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = and i64 [[A]], -4294967297
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    store i16 0, ptr [[GP2]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(3) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  ; -4294967297 = 0xFFFFFFFEFFFFFFFF - clears bit 32, should NOT be optimized
  %b = and i64 %a, -4294967297
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

; Global memory tests - addrspace(1)

define void @test_xor_global(ptr addrspace(1) %sp) {
; CHECK-LABEL: define void @test_xor_global(
; CHECK-SAME: ptr addrspace(1) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(1) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = xor i64 [[A]], 7
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[GP2]] to ptr addrspace(1)
; CHECK-NEXT:    store i16 0, ptr addrspace(1) [[TMP1]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(1) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  %b = xor i64 %a, 7
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

define void @test_xor_global_max32bit(ptr addrspace(1) %sp) {
; CHECK-LABEL: define void @test_xor_global_max32bit(
; CHECK-SAME: ptr addrspace(1) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(1) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = xor i64 [[A]], 4294967295
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[GP2]] to ptr addrspace(1)
; CHECK-NEXT:    store i16 0, ptr addrspace(1) [[TMP1]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(1) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  ; 0xFFFFFFFF - maximum 32-bit value, should still be optimized
  %b = xor i64 %a, 4294967295
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

define void @test_xor_global_fail_bit33(ptr addrspace(1) %sp) {
; CHECK-LABEL: define void @test_xor_global_fail_bit33(
; CHECK-SAME: ptr addrspace(1) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(1) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = xor i64 [[A]], 4294967296
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    store i16 0, ptr [[GP2]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(1) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  ; 0x100000000 - bit 32 set, should NOT be optimized
  %b = xor i64 %a, 4294967296
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

; Private memory tests - addrspace(5)
; Private address space is NOT handled, so these should NOT be optimized

define void @test_xor_private(ptr addrspace(5) %sp) {
; CHECK-LABEL: define void @test_xor_private(
; CHECK-SAME: ptr addrspace(5) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(5) [[SP]] to ptr
; CHECK-NEXT:    [[A:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[B:%.*]] = xor i64 [[A]], 7
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[B]] to ptr
; CHECK-NEXT:    store i16 0, ptr [[GP2]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(5) %sp to ptr
  %a = ptrtoint ptr %gp to i64
  %b = xor i64 %a, 7
  %gp2 = inttoptr i64 %b to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}

; Complex swizzling pattern - similar to NVPTX test3

define void @test_swizzle_local(ptr addrspace(3) %sp) {
; CHECK-LABEL: define void @test_swizzle_local(
; CHECK-SAME: ptr addrspace(3) [[SP:%.*]]) {
; CHECK-NEXT:    [[GP:%.*]] = addrspacecast ptr addrspace(3) [[SP]] to ptr
; CHECK-NEXT:    [[T1:%.*]] = ptrtoint ptr [[GP]] to i64
; CHECK-NEXT:    [[AND:%.*]] = lshr i64 [[T1]], 8
; CHECK-NEXT:    [[SHR:%.*]] = and i64 [[AND]], 8
; CHECK-NEXT:    [[AND1:%.*]] = lshr i64 [[T1]], 10
; CHECK-NEXT:    [[SHR2:%.*]] = and i64 [[AND1]], 4
; CHECK-NEXT:    [[OR:%.*]] = or i64 [[SHR]], [[SHR2]]
; CHECK-NEXT:    [[AND3:%.*]] = lshr i64 [[T1]], 4
; CHECK-NEXT:    [[SHR4:%.*]] = and i64 [[AND3]], 112
; CHECK-NEXT:    [[OR5:%.*]] = or i64 [[OR]], [[SHR4]]
; CHECK-NEXT:    [[XOR:%.*]] = xor i64 [[OR5]], [[T1]]
; CHECK-NEXT:    [[GP2:%.*]] = inttoptr i64 [[XOR]] to ptr
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[GP2]] to ptr addrspace(3)
; CHECK-NEXT:    store i16 0, ptr addrspace(3) [[TMP1]], align 2
; CHECK-NEXT:    ret void
;
  %gp = addrspacecast ptr addrspace(3) %sp to ptr
  %t1 = ptrtoint ptr %gp to i64
  %and = lshr i64 %t1, 8
  %shr = and i64 %and, 8
  %and1 = lshr i64 %t1, 10
  %shr2 = and i64 %and1, 4
  %or = or i64 %shr, %shr2
  %and3 = lshr i64 %t1, 4
  %shr4 = and i64 %and3, 112
  %or5 = or i64 %or, %shr4
  %xor = xor i64 %or5, %t1
  %gp2 = inttoptr i64 %xor to ptr
  store i16 0, ptr %gp2, align 2
  ret void
}
