; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; RUN: opt -S -O3 < %s | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128-Fn32"
target triple = "aarch64"

; This function (a more complex reduction of (a[i] - b[i]) * itself) should be vectorized successfully.

define dso_local noundef nofpclass(nan inf) float @_Z4testPKfS0_ii(ptr noundef %0, ptr noundef %1, i32 noundef %2, i32 noundef %3) {
; CHECK-LABEL: define dso_local noundef nofpclass(nan inf) float @_Z4testPKfS0_ii
; CHECK-SAME: (ptr noundef readonly captures(none) [[TMP0:%.*]], ptr noundef readonly captures(none) [[TMP1:%.*]], i32 noundef [[TMP2:%.*]], i32 noundef [[TMP3:%.*]]) local_unnamed_addr #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  .preheader.i:
; CHECK-NEXT:    [[TMP4:%.*]] = sext i32 [[TMP3]] to i64
; CHECK-NEXT:    [[TMP5:%.*]] = shl nsw i64 [[TMP4]], 2
; CHECK-NEXT:    [[TMP6:%.*]] = sext i32 [[TMP2]] to i64
; CHECK-NEXT:    [[TMP7:%.*]] = shl nsw i64 [[TMP6]], 2
; CHECK-NEXT:    [[TMP8:%.*]] = load <20 x float>, ptr [[TMP0]], align 4, !tbaa [[TBAA4:![0-9]+]]
; CHECK-NEXT:    [[TMP9:%.*]] = load <20 x float>, ptr [[TMP1]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP10:%.*]] = fsub fast <20 x float> [[TMP8]], [[TMP9]]
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast <20 x float> [[TMP10]], [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP0]], i64 80
; CHECK-NEXT:    [[TMP13:%.*]] = load float, ptr [[TMP12]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP1]], i64 80
; CHECK-NEXT:    [[TMP15:%.*]] = load float, ptr [[TMP14]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP16:%.*]] = fsub fast float [[TMP13]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = fmul fast float [[TMP16]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr inbounds i8, ptr [[TMP1]], i64 [[TMP5]]
; CHECK-NEXT:    [[OP_RDX:%.*]] = tail call fast float @llvm.vector.reduce.fadd.v20f32(float [[TMP17]], <20 x float> [[TMP11]])
; CHECK-NEXT:    [[TMP20:%.*]] = load <20 x float>, ptr [[TMP18]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP21:%.*]] = load <20 x float>, ptr [[TMP19]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP22:%.*]] = fsub fast <20 x float> [[TMP20]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = fmul fast <20 x float> [[TMP22]], [[TMP22]]
; CHECK-NEXT:    [[TMP24:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP18]], i64 80
; CHECK-NEXT:    [[TMP25:%.*]] = load float, ptr [[TMP24]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP19]], i64 80
; CHECK-NEXT:    [[TMP27:%.*]] = load float, ptr [[TMP26]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP28:%.*]] = fsub fast float [[TMP25]], [[TMP27]]
; CHECK-NEXT:    [[TMP29:%.*]] = fmul fast float [[TMP28]], [[TMP28]]
; CHECK-NEXT:    [[TMP30:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP31:%.*]] = getelementptr inbounds i8, ptr [[TMP19]], i64 [[TMP5]]
; CHECK-NEXT:    [[OP_RDX_1:%.*]] = tail call fast float @llvm.vector.reduce.fadd.v20f32(float [[TMP29]], <20 x float> [[TMP23]])
; CHECK-NEXT:    [[OP_RDX3_1:%.*]] = fadd fast float [[OP_RDX_1]], [[OP_RDX]]
; CHECK-NEXT:    [[TMP32:%.*]] = load <20 x float>, ptr [[TMP30]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP33:%.*]] = load <20 x float>, ptr [[TMP31]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP34:%.*]] = fsub fast <20 x float> [[TMP32]], [[TMP33]]
; CHECK-NEXT:    [[TMP35:%.*]] = fmul fast <20 x float> [[TMP34]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP30]], i64 80
; CHECK-NEXT:    [[TMP37:%.*]] = load float, ptr [[TMP36]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP38:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP31]], i64 80
; CHECK-NEXT:    [[TMP39:%.*]] = load float, ptr [[TMP38]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP40:%.*]] = fsub fast float [[TMP37]], [[TMP39]]
; CHECK-NEXT:    [[TMP41:%.*]] = fmul fast float [[TMP40]], [[TMP40]]
; CHECK-NEXT:    [[TMP42:%.*]] = getelementptr inbounds i8, ptr [[TMP30]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP43:%.*]] = getelementptr inbounds i8, ptr [[TMP31]], i64 [[TMP5]]
; CHECK-NEXT:    [[OP_RDX_2:%.*]] = tail call fast float @llvm.vector.reduce.fadd.v20f32(float [[TMP41]], <20 x float> [[TMP35]])
; CHECK-NEXT:    [[OP_RDX3_2:%.*]] = fadd fast float [[OP_RDX_2]], [[OP_RDX3_1]]
; CHECK-NEXT:    [[TMP44:%.*]] = load <20 x float>, ptr [[TMP42]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP45:%.*]] = load <20 x float>, ptr [[TMP43]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP46:%.*]] = fsub fast <20 x float> [[TMP44]], [[TMP45]]
; CHECK-NEXT:    [[TMP47:%.*]] = fmul fast <20 x float> [[TMP46]], [[TMP46]]
; CHECK-NEXT:    [[TMP48:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP42]], i64 80
; CHECK-NEXT:    [[TMP49:%.*]] = load float, ptr [[TMP48]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP50:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP43]], i64 80
; CHECK-NEXT:    [[TMP51:%.*]] = load float, ptr [[TMP50]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP52:%.*]] = fsub fast float [[TMP49]], [[TMP51]]
; CHECK-NEXT:    [[TMP53:%.*]] = fmul fast float [[TMP52]], [[TMP52]]
; CHECK-NEXT:    [[TMP54:%.*]] = getelementptr inbounds i8, ptr [[TMP42]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP55:%.*]] = getelementptr inbounds i8, ptr [[TMP43]], i64 [[TMP5]]
; CHECK-NEXT:    [[OP_RDX_3:%.*]] = tail call fast float @llvm.vector.reduce.fadd.v20f32(float [[TMP53]], <20 x float> [[TMP47]])
; CHECK-NEXT:    [[OP_RDX3_3:%.*]] = fadd fast float [[OP_RDX_3]], [[OP_RDX3_2]]
; CHECK-NEXT:    [[TMP56:%.*]] = load <20 x float>, ptr [[TMP54]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP57:%.*]] = load <20 x float>, ptr [[TMP55]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP58:%.*]] = fsub fast <20 x float> [[TMP56]], [[TMP57]]
; CHECK-NEXT:    [[TMP59:%.*]] = fmul fast <20 x float> [[TMP58]], [[TMP58]]
; CHECK-NEXT:    [[TMP60:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP54]], i64 80
; CHECK-NEXT:    [[TMP61:%.*]] = load float, ptr [[TMP60]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP62:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP55]], i64 80
; CHECK-NEXT:    [[TMP63:%.*]] = load float, ptr [[TMP62]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP64:%.*]] = fsub fast float [[TMP61]], [[TMP63]]
; CHECK-NEXT:    [[TMP65:%.*]] = fmul fast float [[TMP64]], [[TMP64]]
; CHECK-NEXT:    [[TMP66:%.*]] = getelementptr inbounds i8, ptr [[TMP54]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP67:%.*]] = getelementptr inbounds i8, ptr [[TMP55]], i64 [[TMP5]]
; CHECK-NEXT:    [[OP_RDX_4:%.*]] = tail call fast float @llvm.vector.reduce.fadd.v20f32(float [[TMP65]], <20 x float> [[TMP59]])
; CHECK-NEXT:    [[OP_RDX3_4:%.*]] = fadd fast float [[OP_RDX_4]], [[OP_RDX3_3]]
; CHECK-NEXT:    [[TMP68:%.*]] = load <20 x float>, ptr [[TMP66]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP69:%.*]] = load <20 x float>, ptr [[TMP67]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP70:%.*]] = fsub fast <20 x float> [[TMP68]], [[TMP69]]
; CHECK-NEXT:    [[TMP71:%.*]] = fmul fast <20 x float> [[TMP70]], [[TMP70]]
; CHECK-NEXT:    [[TMP72:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP66]], i64 80
; CHECK-NEXT:    [[TMP73:%.*]] = load float, ptr [[TMP72]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP74:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP67]], i64 80
; CHECK-NEXT:    [[TMP75:%.*]] = load float, ptr [[TMP74]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP76:%.*]] = fsub fast float [[TMP73]], [[TMP75]]
; CHECK-NEXT:    [[TMP77:%.*]] = fmul fast float [[TMP76]], [[TMP76]]
; CHECK-NEXT:    [[TMP78:%.*]] = getelementptr inbounds i8, ptr [[TMP66]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP79:%.*]] = getelementptr inbounds i8, ptr [[TMP67]], i64 [[TMP5]]
; CHECK-NEXT:    [[OP_RDX_5:%.*]] = tail call fast float @llvm.vector.reduce.fadd.v20f32(float [[TMP77]], <20 x float> [[TMP71]])
; CHECK-NEXT:    [[OP_RDX3_5:%.*]] = fadd fast float [[OP_RDX_5]], [[OP_RDX3_4]]
; CHECK-NEXT:    [[TMP80:%.*]] = load <20 x float>, ptr [[TMP78]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP81:%.*]] = load <20 x float>, ptr [[TMP79]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP82:%.*]] = fsub fast <20 x float> [[TMP80]], [[TMP81]]
; CHECK-NEXT:    [[TMP83:%.*]] = fmul fast <20 x float> [[TMP82]], [[TMP82]]
; CHECK-NEXT:    [[TMP84:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP78]], i64 80
; CHECK-NEXT:    [[TMP85:%.*]] = load float, ptr [[TMP84]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP86:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP79]], i64 80
; CHECK-NEXT:    [[TMP87:%.*]] = load float, ptr [[TMP86]], align 4, !tbaa [[TBAA4]]
; CHECK-NEXT:    [[TMP88:%.*]] = fsub fast float [[TMP85]], [[TMP87]]
; CHECK-NEXT:    [[TMP89:%.*]] = fmul fast float [[TMP88]], [[TMP88]]
; CHECK-NEXT:    [[OP_RDX_6:%.*]] = tail call fast float @llvm.vector.reduce.fadd.v20f32(float [[TMP89]], <20 x float> [[TMP83]])
; CHECK-NEXT:    [[OP_RDX3_6:%.*]] = fadd fast float [[OP_RDX_6]], [[OP_RDX3_5]]
; CHECK-NEXT:    ret float [[OP_RDX3_6]]
;
  %5 = alloca ptr, align 8
  %6 = alloca ptr, align 8
  %7 = alloca i32, align 4
  %8 = alloca i32, align 4
  store ptr %0, ptr %5, align 8, !tbaa !4
  store ptr %1, ptr %6, align 8, !tbaa !4
  store i32 %2, ptr %7, align 4, !tbaa !9
  store i32 %3, ptr %8, align 4, !tbaa !9
  %9 = load ptr, ptr %5, align 8, !tbaa !4
  %10 = load ptr, ptr %6, align 8, !tbaa !4
  %11 = load i32, ptr %7, align 4, !tbaa !9
  %12 = load i32, ptr %8, align 4, !tbaa !9
  %13 = call fast noundef nofpclass(nan inf) float @_ZL6reduceILi7EEfPKfS1_ii(ptr noundef %9, ptr noundef %10, i32 noundef %11, i32 noundef %12)
  ret float %13
}

define internal noundef nofpclass(nan inf) float @_ZL6reduceILi7EEfPKfS1_ii(ptr noundef %0, ptr noundef %1, i32 noundef %2, i32 noundef %3) {
  %5 = alloca ptr, align 8
  %6 = alloca ptr, align 8
  %7 = alloca i32, align 4
  %8 = alloca i32, align 4
  %9 = alloca i32, align 4
  %10 = alloca i32, align 4
  %11 = alloca i32, align 4
  %12 = alloca float, align 4
  %13 = alloca i32, align 4
  %14 = alloca i32, align 4
  %15 = alloca float, align 4
  %16 = alloca i32, align 4
  %17 = alloca float, align 4
  store ptr %0, ptr %5, align 8, !tbaa !4
  store ptr %1, ptr %6, align 8, !tbaa !4
  store i32 %2, ptr %7, align 4, !tbaa !9
  store i32 %3, ptr %8, align 4, !tbaa !9
  call void @llvm.lifetime.start.p0(ptr %9)
  store i32 3, ptr %9, align 4, !tbaa !9
  call void @llvm.lifetime.start.p0(ptr %10)
  store i32 3, ptr %10, align 4, !tbaa !9
  call void @llvm.lifetime.start.p0(ptr %11)
  store i32 7, ptr %11, align 4, !tbaa !9
  call void @llvm.lifetime.start.p0(ptr %12)
  store float 0.000000e+00, ptr %12, align 4, !tbaa !11
  call void @llvm.lifetime.start.p0(ptr %13)
  store i32 0, ptr %13, align 4, !tbaa !9
  br label %18

18:                                               ; preds = %59, %4
  %19 = load i32, ptr %13, align 4, !tbaa !9
  %20 = icmp slt i32 %19, 7
  br i1 %20, label %22, label %21

21:                                               ; preds = %18
  store i32 2, ptr %14, align 4
  call void @llvm.lifetime.end.p0(ptr %13)
  br label %62

22:                                               ; preds = %18
  call void @llvm.lifetime.start.p0(ptr %15)
  store float 0.000000e+00, ptr %15, align 4, !tbaa !11
  call void @llvm.lifetime.start.p0(ptr %16)
  store i32 0, ptr %16, align 4, !tbaa !9
  br label %23

23:                                               ; preds = %44, %22
  %24 = load i32, ptr %16, align 4, !tbaa !9
  %25 = icmp slt i32 %24, 21
  br i1 %25, label %27, label %26

26:                                               ; preds = %23
  store i32 5, ptr %14, align 4
  call void @llvm.lifetime.end.p0(ptr %16)
  br label %47

27:                                               ; preds = %23
  call void @llvm.lifetime.start.p0(ptr %17)
  %28 = load ptr, ptr %5, align 8, !tbaa !4
  %29 = load i32, ptr %16, align 4, !tbaa !9
  %30 = sext i32 %29 to i64
  %31 = getelementptr inbounds float, ptr %28, i64 %30
  %32 = load float, ptr %31, align 4, !tbaa !11
  %33 = load ptr, ptr %6, align 8, !tbaa !4
  %34 = load i32, ptr %16, align 4, !tbaa !9
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds float, ptr %33, i64 %35
  %37 = load float, ptr %36, align 4, !tbaa !11
  %38 = fsub fast float %32, %37
  store float %38, ptr %17, align 4, !tbaa !11
  %39 = load float, ptr %17, align 4, !tbaa !11
  %40 = load float, ptr %17, align 4, !tbaa !11
  %41 = fmul fast float %39, %40
  %42 = load float, ptr %15, align 4, !tbaa !11
  %43 = fadd fast float %42, %41
  store float %43, ptr %15, align 4, !tbaa !11
  call void @llvm.lifetime.end.p0(ptr %17)
  br label %44

44:                                               ; preds = %27
  %45 = load i32, ptr %16, align 4, !tbaa !9
  %46 = add nsw i32 %45, 1
  store i32 %46, ptr %16, align 4, !tbaa !9
  br label %23, !llvm.loop !13

47:                                               ; preds = %26
  %48 = load i32, ptr %7, align 4, !tbaa !9
  %49 = load ptr, ptr %5, align 8, !tbaa !4
  %50 = sext i32 %48 to i64
  %51 = getelementptr inbounds float, ptr %49, i64 %50
  store ptr %51, ptr %5, align 8, !tbaa !4
  %52 = load i32, ptr %8, align 4, !tbaa !9
  %53 = load ptr, ptr %6, align 8, !tbaa !4
  %54 = sext i32 %52 to i64
  %55 = getelementptr inbounds float, ptr %53, i64 %54
  store ptr %55, ptr %6, align 8, !tbaa !4
  %56 = load float, ptr %15, align 4, !tbaa !11
  %57 = load float, ptr %12, align 4, !tbaa !11
  %58 = fadd fast float %57, %56
  store float %58, ptr %12, align 4, !tbaa !11
  call void @llvm.lifetime.end.p0(ptr %15)
  br label %59

59:                                               ; preds = %47
  %60 = load i32, ptr %13, align 4, !tbaa !9
  %61 = add nsw i32 %60, 1
  store i32 %61, ptr %13, align 4, !tbaa !9
  br label %18, !llvm.loop !15

62:                                               ; preds = %21
  %63 = load float, ptr %12, align 4, !tbaa !11
  store i32 1, ptr %14, align 4
  call void @llvm.lifetime.end.p0(ptr %12)
  call void @llvm.lifetime.end.p0(ptr %11)
  call void @llvm.lifetime.end.p0(ptr %10)
  call void @llvm.lifetime.end.p0(ptr %9)
  ret float %63
}

declare void @llvm.lifetime.start.p0(ptr captures(none))
declare void @llvm.lifetime.end.p0(ptr captures(none))

!llvm.module.flags = !{!0, !1, !2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"uwtable", i32 2}
!2 = !{i32 7, !"frame-pointer", i32 1}
!3 = !{!"clang version 22.0.0git"}
!4 = !{!5, !5, i64 0}
!5 = !{!"p1 float", !6, i64 0}
!6 = !{!"any pointer", !7, i64 0}
!7 = !{!"omnipotent char", !8, i64 0}
!8 = !{!"Simple C++ TBAA"}
!9 = !{!10, !10, i64 0}
!10 = !{!"int", !7, i64 0}
!11 = !{!12, !12, i64 0}
!12 = !{!"float", !7, i64 0}
!13 = distinct !{!13, !14}
!14 = !{!"llvm.loop.mustprogress"}
!15 = distinct !{!15, !14}
