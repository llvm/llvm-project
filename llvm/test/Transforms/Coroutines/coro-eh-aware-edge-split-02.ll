; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 6
; Check that we can handle edge splits leading into a landingpad
; RUN: opt < %s -passes='cgscc(coro-split),simplifycfg,early-cse' -S | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @h(i1 %cond, i32 %x, i32 %y) presplitcoroutine personality i32 0 {
; CHECK-LABEL: define void @h(
; CHECK-SAME: i1 [[COND:%.*]], i32 [[X:%.*]], i32 [[Y:%.*]]) personality i32 0 {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[ID:%.*]] = call token @llvm.coro.id(i32 16, ptr null, ptr null, ptr @h.resumers)
; CHECK-NEXT:    [[ALLOC:%.*]] = call ptr @malloc(i64 32)
; CHECK-NEXT:    [[HDL:%.*]] = call noalias nonnull ptr @llvm.coro.begin(token [[ID]], ptr [[ALLOC]])
; CHECK-NEXT:    store ptr @h.resume, ptr [[HDL]], align 8
; CHECK-NEXT:    [[DESTROY_ADDR:%.*]] = getelementptr inbounds nuw [[H_FRAME:%.*]], ptr [[HDL]], i32 0, i32 1
; CHECK-NEXT:    store ptr @h.destroy, ptr [[DESTROY_ADDR]], align 8
; CHECK-NEXT:    [[Y_SPILL_ADDR:%.*]] = getelementptr inbounds [[H_FRAME]], ptr [[HDL]], i32 0, i32 3
; CHECK-NEXT:    store i32 [[Y]], ptr [[Y_SPILL_ADDR]], align 4
; CHECK-NEXT:    [[X_SPILL_ADDR:%.*]] = getelementptr inbounds [[H_FRAME]], ptr [[HDL]], i32 0, i32 2
; CHECK-NEXT:    store i32 [[X]], ptr [[X_SPILL_ADDR]], align 4
; CHECK-NEXT:    [[COND_SPILL_ADDR:%.*]] = getelementptr inbounds [[H_FRAME]], ptr [[HDL]], i32 0, i32 5
; CHECK-NEXT:    store i1 [[COND]], ptr [[COND_SPILL_ADDR]], align 1
; CHECK-NEXT:    [[INDEX_ADDR1:%.*]] = getelementptr inbounds nuw [[H_FRAME]], ptr [[HDL]], i32 0, i32 4
; CHECK-NEXT:    store i1 false, ptr [[INDEX_ADDR1]], align 1
; CHECK-NEXT:    ret void
;
entry:
  %id = call token @llvm.coro.id(i32 16, ptr null, ptr null, ptr null)
  %size = tail call i64 @llvm.coro.size.i64()
  %alloc = call ptr @malloc(i64 %size)
  %hdl = call ptr @llvm.coro.begin(token %id, ptr %alloc)
  %sp = call i8 @llvm.coro.suspend(token none, i1 false)
  switch i8 %sp, label %coro.ret [
  i8 0, label %resume
  i8 1, label %cleanup
  ]

resume:
  br i1 %cond, label %invoke1, label %invoke2

invoke1:
  invoke void @may_throw1()
  to label %coro.ret unwind label %pad.with.phi
invoke2:
  invoke void @may_throw2()
  to label %coro.ret unwind label %pad.with.phi

; Verify that we created cleanuppads on every edge and inserted a reload of the spilled value



pad.with.phi:
  %val = phi i32 [ %x, %invoke1 ], [ %y, %invoke2 ]
  %switch = catchswitch within none [label %catch] unwind to caller

catch:                                            ; preds = %catch.dispatch
  %pad = catchpad within %switch [ptr null, i32 64, ptr null]
  call void @use_val(i32 %val)
  catchret from %pad to label %coro.ret

cleanup:                                        ; preds = %invoke.cont15, %if.else, %if.then, %ehcleanup21, %init.suspend
  %mem = call ptr @llvm.coro.free(token %id, ptr %hdl)
  call void @free(ptr %mem)
  br label %coro.ret

coro.ret:
  call void @llvm.coro.end(ptr null, i1 false, token none)
  ret void
}

; Function Attrs: argmemonly nounwind readonly
declare token @llvm.coro.id(i32, ptr readnone, ptr nocapture readonly, ptr)
declare noalias ptr @malloc(i64)
declare i64 @llvm.coro.size.i64()
declare ptr @llvm.coro.begin(token, ptr writeonly)

; Function Attrs: nounwind
declare token @llvm.coro.save(ptr)
declare i8 @llvm.coro.suspend(token, i1)

; Function Attrs: argmemonly nounwind
declare void @may_throw1()
declare void @may_throw2()

declare ptr @__cxa_begin_catch(ptr)

declare void @use_val(i32)
declare void @__cxa_end_catch()

; Function Attrs: nounwind
declare void @llvm.coro.end(ptr, i1, token)
declare void @free(ptr)
declare ptr @llvm.coro.free(token, ptr nocapture readonly)
