; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -S -passes=instcombine < %s | FileCheck %s

define <2 x i64> @tricky(<2 x i64> noundef %a, <2 x i64> noundef %b, <2 x i64> noundef %c, <2 x i64> noundef %src) {
; CHECK-LABEL: define <2 x i64> @tricky(
; CHECK-SAME: <2 x i64> noundef [[A:%.*]], <2 x i64> noundef [[B:%.*]], <2 x i64> noundef [[C:%.*]], <2 x i64> noundef [[SRC:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast <2 x i64> [[A]] to <4 x i32>
; CHECK-NEXT:    [[CMP_I:%.*]] = icmp sgt <4 x i32> [[TMP0]], zeroinitializer
; CHECK-NEXT:    [[SEXT_I:%.*]] = sext <4 x i1> [[CMP_I]] to <4 x i32>
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast <4 x i32> [[SEXT_I]] to <2 x i64>
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast <2 x i64> [[B]] to <4 x i32>
; CHECK-NEXT:    [[CMP_I21:%.*]] = icmp sgt <4 x i32> [[TMP2]], zeroinitializer
; CHECK-NEXT:    [[SEXT_I22:%.*]] = sext <4 x i1> [[CMP_I21]] to <4 x i32>
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast <4 x i32> [[SEXT_I22]] to <2 x i64>
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <2 x i64> [[C]] to <4 x i32>
; CHECK-NEXT:    [[CMP_I23:%.*]] = icmp sgt <4 x i32> [[TMP4]], zeroinitializer
; CHECK-NEXT:    [[SEXT_I24:%.*]] = sext <4 x i1> [[CMP_I23]] to <4 x i32>
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <4 x i32> [[SEXT_I24]] to <2 x i64>
; CHECK-NEXT:    [[AND_I:%.*]] = and <2 x i64> [[TMP3]], [[TMP1]]
; CHECK-NEXT:    [[XOR_I:%.*]] = xor <2 x i64> [[AND_I]], [[TMP5]]
; CHECK-NEXT:    [[AND_I25:%.*]] = and <2 x i64> [[XOR_I]], [[TMP1]]
; CHECK-NEXT:    [[AND_I26:%.*]] = and <2 x i64> [[XOR_I]], [[TMP3]]
; CHECK-NEXT:    [[AND_I27:%.*]] = and <2 x i64> [[AND_I]], [[SRC]]
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <2 x i64> [[AND_I27]] to <16 x i8>
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i64> [[A]] to <16 x i8>
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <2 x i64> [[AND_I25]] to <16 x i8>
; CHECK-NEXT:    [[TMP9:%.*]] = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> [[TMP6]], <16 x i8> [[TMP7]], <16 x i8> [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast <2 x i64> [[B]] to <16 x i8>
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <2 x i64> [[AND_I26]] to <16 x i8>
; CHECK-NEXT:    [[TMP12:%.*]] = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> [[TMP9]], <16 x i8> [[TMP10]], <16 x i8> [[TMP11]])
; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <16 x i8> [[TMP12]] to <2 x i64>
; CHECK-NEXT:    ret <2 x i64> [[TMP13]]
;
entry:
  %0 = bitcast <2 x i64> %a to <4 x i32>
  %cmp.i = icmp sgt <4 x i32> %0, zeroinitializer
  %sext.i = sext <4 x i1> %cmp.i to <4 x i32>
  %1 = bitcast <4 x i32> %sext.i to <2 x i64>
  %2 = bitcast <2 x i64> %b to <4 x i32>
  %cmp.i21 = icmp sgt <4 x i32> %2, zeroinitializer
  %sext.i22 = sext <4 x i1> %cmp.i21 to <4 x i32>
  %3 = bitcast <4 x i32> %sext.i22 to <2 x i64>
  %4 = bitcast <2 x i64> %c to <4 x i32>
  %cmp.i23 = icmp sgt <4 x i32> %4, zeroinitializer
  %sext.i24 = sext <4 x i1> %cmp.i23 to <4 x i32>
  %5 = bitcast <4 x i32> %sext.i24 to <2 x i64>
  %and.i = and <2 x i64> %3, %1
  %xor.i = xor <2 x i64> %and.i, %5
  %and.i25 = and <2 x i64> %xor.i, %1
  %and.i26 = and <2 x i64> %xor.i, %3
  %and.i27 = and <2 x i64> %and.i, %src
  %6 = bitcast <2 x i64> %and.i27 to <16 x i8>
  %7 = bitcast <2 x i64> %a to <16 x i8>
  %8 = bitcast <2 x i64> %and.i25 to <16 x i8>
  %9 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %6, <16 x i8> %7, <16 x i8> %8)
  %10 = bitcast <2 x i64> %b to <16 x i8>
  %11 = bitcast <2 x i64> %and.i26 to <16 x i8>
  %12 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %9, <16 x i8> %10, <16 x i8> %11)
  %13 = bitcast <16 x i8> %12 to <2 x i64>
  ret <2 x i64> %13
}
declare <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8>, <16 x i8>, <16 x i8>)
