; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -passes=instcombine -S %s | FileCheck %s
target datalayout = "p:32:32"


define i1 @alloca_argument_compare(i64* %arg) {
; CHECK-LABEL: @alloca_argument_compare(
; CHECK-NEXT:    ret i1 false
;
  %alloc = alloca i64
  %cmp = icmp eq i64* %arg, %alloc
  ret i1 %cmp
}

define i1 @alloca_argument_compare_swapped(i64* %arg) {
; CHECK-LABEL: @alloca_argument_compare_swapped(
; CHECK-NEXT:    ret i1 false
;
  %alloc = alloca i64
  %cmp = icmp eq i64* %alloc, %arg
  ret i1 %cmp
}

define i1 @alloca_argument_compare_ne(i64* %arg) {
; CHECK-LABEL: @alloca_argument_compare_ne(
; CHECK-NEXT:    ret i1 true
;
  %alloc = alloca i64
  %cmp = icmp ne i64* %arg, %alloc
  ret i1 %cmp
}

define i1 @alloca_argument_compare_derived_ptrs(i64* %arg, i64 %x) {
; CHECK-LABEL: @alloca_argument_compare_derived_ptrs(
; CHECK-NEXT:    ret i1 false
;
  %alloc = alloca i64, i64 8
  %p = getelementptr i64, i64* %arg, i64 %x
  %q = getelementptr i64, i64* %alloc, i64 3
  %cmp = icmp eq i64* %p, %q
  ret i1 %cmp
}

declare void @escape(i64*)
define i1 @alloca_argument_compare_escaped_alloca(i64* %arg) {
; CHECK-LABEL: @alloca_argument_compare_escaped_alloca(
; CHECK-NEXT:    [[ALLOC:%.*]] = alloca i64, align 8
; CHECK-NEXT:    call void @escape(i64* nonnull [[ALLOC]])
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i64* [[ALLOC]], [[ARG:%.*]]
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %alloc = alloca i64
  call void @escape(i64* %alloc)
  %cmp = icmp eq i64* %alloc, %arg
  ret i1 %cmp
}

declare void @check_compares(i1, i1)
define void @alloca_argument_compare_two_compares(i64* %p) {
; CHECK-LABEL: @alloca_argument_compare_two_compares(
; CHECK-NEXT:    [[Q1:%.*]] = alloca [8 x i64], align 8
; CHECK-NEXT:    [[Q1_SUB:%.*]] = getelementptr inbounds [8 x i64], [8 x i64]* [[Q1]], i32 0, i32 0
; CHECK-NEXT:    [[R:%.*]] = getelementptr i64, i64* [[P:%.*]], i32 1
; CHECK-NEXT:    [[S:%.*]] = getelementptr inbounds [8 x i64], [8 x i64]* [[Q1]], i32 0, i32 2
; CHECK-NEXT:    [[CMP1:%.*]] = icmp eq i64* [[Q1_SUB]], [[P]]
; CHECK-NEXT:    [[CMP2:%.*]] = icmp eq i64* [[R]], [[S]]
; CHECK-NEXT:    call void @check_compares(i1 [[CMP1]], i1 [[CMP2]])
; CHECK-NEXT:    ret void
;
  %q = alloca i64, i64 8
  %r = getelementptr i64, i64* %p, i64 1
  %s = getelementptr i64, i64* %q, i64 2
  %cmp1 = icmp eq i64* %p, %q
  %cmp2 = icmp eq i64* %r, %s
  call void @check_compares(i1 %cmp1, i1 %cmp2)
  ret void
  ; We will only fold if there is a single cmp.
}

define i1 @alloca_argument_compare_escaped_through_store(i64* %arg, i64** %ptr) {
; CHECK-LABEL: @alloca_argument_compare_escaped_through_store(
; CHECK-NEXT:    [[ALLOC:%.*]] = alloca i64, align 8
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i64* [[ALLOC]], [[ARG:%.*]]
; CHECK-NEXT:    [[P:%.*]] = getelementptr inbounds i64, i64* [[ALLOC]], i32 1
; CHECK-NEXT:    store i64* [[P]], i64** [[PTR:%.*]], align 4
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %alloc = alloca i64
  %cmp = icmp eq i64* %alloc, %arg
  %p = getelementptr i64, i64* %alloc, i64 1
  store i64* %p, i64** %ptr
  ret i1 %cmp
}

declare void @llvm.lifetime.start.p0i8(i64, i8* nocapture)
declare void @llvm.lifetime.end.p0i8(i64, i8* nocapture)
define i1 @alloca_argument_compare_benign_instrs(i8* %arg) {
; CHECK-LABEL: @alloca_argument_compare_benign_instrs(
; CHECK-NEXT:    ret i1 false
;
  %alloc = alloca i8
  call void @llvm.lifetime.start.p0i8(i64 1, i8* %alloc)
  %cmp = icmp eq i8* %arg, %alloc
  %x = load i8, i8* %arg
  store i8 %x, i8* %alloc
  call void @llvm.lifetime.end.p0i8(i64 1, i8* %alloc)
  ret i1 %cmp
}

declare i64* @allocator()
define i1 @alloca_call_compare() {
; CHECK-LABEL: @alloca_call_compare(
; CHECK-NEXT:    [[Q:%.*]] = call i64* @allocator()
; CHECK-NEXT:    ret i1 false
;
  %p = alloca i64
  %q = call i64* @allocator()
  %cmp = icmp eq i64* %p, %q
  ret i1 %cmp
}
