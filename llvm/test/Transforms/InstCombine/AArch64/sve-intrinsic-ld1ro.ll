; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S -mattr=+sve,+f64mm -passes=instcombine < %s | FileCheck %s

target triple = "aarch64-unknown-linux-gnu"

; The instuction ld1ro load a 256-bit (octaword) vector, so half of vscale=4 can match this limitation.
define <vscale x 2 x double> @combine_ld1ro_double(ptr %addr) vscale_range(4,4) {
; CHECK-LABEL: @combine_ld1ro_double(
; CHECK-NEXT:    [[PRED:%.*]] = call <vscale x 2 x i1> @llvm.aarch64.sve.whilelt.nxv2i1.i64(i64 0, i64 4)
; CHECK-NEXT:    [[RES:%.*]] = call <vscale x 2 x double> @llvm.aarch64.sve.ld1ro.nxv2f64(<vscale x 2 x i1> [[PRED]], ptr [[ADDR:%.*]])
; CHECK-NEXT:    ret <vscale x 2 x double> [[RES]]
;
  %pred = call <vscale x 2 x i1> @llvm.aarch64.sve.whilelt.nxv2i1.i64(i64 0, i64 4)   ; half = 512/bits(type double)/2 = 4
  %a = call <vscale x 2 x double> @llvm.masked.load.nxv2f64(ptr %addr, i32 8, <vscale x 2 x i1> %pred, <vscale x 2 x double> zeroinitializer)
  %res = call <vscale x 2 x double> @llvm.aarch64.sve.splice.nxv2f64(<vscale x 2 x i1> %pred, <vscale x 2 x double> %a, <vscale x 2 x double> %a)
  ret <vscale x 2 x double> %res
}

; Negative test: More than 2 uses
define <vscale x 2 x double> @combine_ld1ro_double_3uses(ptr %addr) vscale_range(4,4) {
; CHECK-LABEL: @combine_ld1ro_double_3uses(
; CHECK-NEXT:    [[PRED:%.*]] = call <vscale x 2 x i1> @llvm.aarch64.sve.whilelt.nxv2i1.i64(i64 0, i64 4)
; CHECK-NEXT:    [[A:%.*]] = call <vscale x 2 x double> @llvm.masked.load.nxv2f64.p0(ptr [[ADDR:%.*]], i32 8, <vscale x 2 x i1> [[PRED]], <vscale x 2 x double> zeroinitializer)
; CHECK-NEXT:    call void @use_double(<vscale x 2 x double> [[A]])
; CHECK-NEXT:    [[RES:%.*]] = call <vscale x 2 x double> @llvm.aarch64.sve.splice.nxv2f64(<vscale x 2 x i1> [[PRED]], <vscale x 2 x double> [[A]], <vscale x 2 x double> [[A]])
; CHECK-NEXT:    ret <vscale x 2 x double> [[RES]]
;
  %pred = call <vscale x 2 x i1> @llvm.aarch64.sve.whilelt.nxv2i1.i64(i64 0, i64 4)   ; half = 512/bits(type double)/2 = 4
  %a = call <vscale x 2 x double> @llvm.masked.load.nxv2f64(ptr %addr, i32 8, <vscale x 2 x i1> %pred, <vscale x 2 x double> zeroinitializer)
  call void @use_double(<vscale x 2 x double> %a)
  %res = call <vscale x 2 x double> @llvm.aarch64.sve.splice.nxv2f64(<vscale x 2 x i1> %pred, <vscale x 2 x double> %a, <vscale x 2 x double> %a)
  ret <vscale x 2 x double> %res
}

declare void @use_double(<vscale x 2 x double>)
declare <vscale x 2 x double> @llvm.masked.load.nxv2f64(<vscale x 2 x double>*, i32, <vscale x 2 x i1>, <vscale x 2 x double>)
declare <vscale x 2 x double> @llvm.aarch64.sve.splice.nxv2f64(<vscale x 2 x i1>, <vscale x 2 x double>, <vscale x 2 x double>)
declare <vscale x 2 x i1> @llvm.aarch64.sve.whilelt.nxv2i1.i64(i64, i64)
