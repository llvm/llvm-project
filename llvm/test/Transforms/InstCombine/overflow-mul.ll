; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S -passes=instcombine < %s | FileCheck %s

; The last test needs this weird datalayout.
target datalayout = "i32:8:8"
; Without it, InstCombine will align the pointed on 4 Bytes
; The KnownBitsZero that result from the alignment allows to
; turn:
;    and i32 %mul, 255
; to:
;    and i32 %mul, 252
; The mask is no longer in the form 2^n-1  and this prevents the transformation.

declare void @use.i64(i64)
declare void @use.i32(i32)

; return mul(zext x, zext y) > MAX
define i32 @pr4917_1(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4917_1(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[OVERFLOW:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ugt i64 %mul64, 4294967295
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

; return mul(zext x, zext y) >= MAX+1
define i32 @pr4917_1a(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4917_1a(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[OVERFLOW:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp uge i64 %mul64, 4294967296
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

; mul(zext x, zext y) > MAX
; mul(x, y) is used
define i32 @pr4917_2(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4917_2(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[UMUL_VALUE:%.*]] = extractvalue { i32, i1 } [[UMUL]], 0
; CHECK-NEXT:    [[OVERFLOW:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[RETVAL:%.*]] = select i1 [[OVERFLOW]], i32 [[UMUL_VALUE]], i32 111
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ugt i64 %mul64, 4294967295
  %mul32 = trunc i64 %mul64 to i32
  %retval = select i1 %overflow, i32 %mul32, i32 111
  ret i32 %retval
}

; return mul(zext x, zext y) > MAX
; mul is used in non-truncate
define i64 @pr4917_3(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4917_3(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[L:%.*]] = zext i32 [[X:%.*]] to i64
; CHECK-NEXT:    [[R:%.*]] = zext i32 [[Y:%.*]] to i64
; CHECK-NEXT:    [[MUL64:%.*]] = mul nuw i64 [[L]], [[R]]
; CHECK-NEXT:    [[OVERFLOW:%.*]] = icmp ugt i64 [[MUL64]], 4294967295
; CHECK-NEXT:    [[RETVAL:%.*]] = select i1 [[OVERFLOW]], i64 [[MUL64]], i64 111
; CHECK-NEXT:    ret i64 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ugt i64 %mul64, 4294967295
  %retval = select i1 %overflow, i64 %mul64, i64 111
  ret i64 %retval
}

; return mul(zext x, zext y) <= MAX
define i32 @pr4917_4(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4917_4(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[TMP0:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[OVERFLOW:%.*]] = xor i1 [[TMP0]], true
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ule i64 %mul64, 4294967295
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

; return mul(zext x, zext y) < MAX+1
define i32 @pr4917_4a(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4917_4a(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[TMP0:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[OVERFLOW:%.*]] = xor i1 [[TMP0]], true
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ult i64 %mul64, 4294967296
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

; operands of mul are of different size
define i32 @pr4917_5(i32 %x, i8 %y) nounwind {
; CHECK-LABEL: @pr4917_5(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = zext i8 [[Y:%.*]] to i32
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[TMP0]])
; CHECK-NEXT:    [[UMUL_VALUE:%.*]] = extractvalue { i32, i1 } [[UMUL]], 0
; CHECK-NEXT:    [[OVERFLOW:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[RETVAL:%.*]] = select i1 [[OVERFLOW]], i32 [[UMUL_VALUE]], i32 111
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i8 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ugt i64 %mul64, 4294967295
  %mul32 = trunc i64 %mul64 to i32
  %retval = select i1 %overflow, i32 %mul32, i32 111
  ret i32 %retval
}

; mul(zext x, zext y) != zext trunc mul
define i32 @pr4918_1(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4918_1(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[OVERFLOW:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %part32 = trunc i64 %mul64 to i32
  %part64 = zext i32 %part32 to i64
  %overflow = icmp ne i64 %mul64, %part64
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

; mul(zext x, zext y) == zext trunc mul
define i32 @pr4918_2(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4918_2(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[TMP0:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[OVERFLOW:%.*]] = xor i1 [[TMP0]], true
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %part32 = trunc i64 %mul64 to i32
  %part64 = zext i32 %part32 to i64
  %overflow = icmp eq i64 %mul64, %part64
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

; zext trunc mul != mul(zext x, zext y)
define i32 @pr4918_3(i32 %x, i32 %y) nounwind {
; CHECK-LABEL: @pr4918_3(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[OVERFLOW:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %part32 = trunc i64 %mul64 to i32
  %part64 = zext i32 %part32 to i64
  %overflow = icmp ne i64 %part64, %mul64
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

define <4 x i32> @pr20113(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: @pr20113(
; CHECK-NEXT:    [[VMOVL_I_I726:%.*]] = zext <4 x i16> [[A:%.*]] to <4 x i32>
; CHECK-NEXT:    [[VMOVL_I_I712:%.*]] = zext <4 x i16> [[B:%.*]] to <4 x i32>
; CHECK-NEXT:    [[MUL_I703:%.*]] = mul nuw <4 x i32> [[VMOVL_I_I712]], [[VMOVL_I_I726]]
; CHECK-NEXT:    [[TMP:%.*]] = icmp sgt <4 x i32> [[MUL_I703]], splat (i32 -1)
; CHECK-NEXT:    [[VCGEZ_I:%.*]] = sext <4 x i1> [[TMP]] to <4 x i32>
; CHECK-NEXT:    ret <4 x i32> [[VCGEZ_I]]
;
  %vmovl.i.i726 = zext <4 x i16> %a to <4 x i32>
  %vmovl.i.i712 = zext <4 x i16> %b to <4 x i32>
  %mul.i703 = mul <4 x i32> %vmovl.i.i712, %vmovl.i.i726
  %tmp = icmp sge <4 x i32> %mul.i703, zeroinitializer
  %vcgez.i = sext <4 x i1> %tmp to <4 x i32>
  ret <4 x i32> %vcgez.i
}


@pr21445_data = external global i32
define i1 @pr21445(i8 %a) {
; CHECK-LABEL: @pr21445(
; CHECK-NEXT:    [[UMUL:%.*]] = call { i8, i1 } @llvm.umul.with.overflow.i8(i8 [[A:%.*]], i8 ptrtoint (ptr @pr21445_data to i8))
; CHECK-NEXT:    [[CMP:%.*]] = extractvalue { i8, i1 } [[UMUL]], 1
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %ext = zext i8 %a to i32
  %ext2 = zext i8 ptrtoint (ptr @pr21445_data to i8) to i32
  %mul = mul i32 %ext, %ext2
  %and = and i32 %mul, 255
  %cmp = icmp ne i32 %mul, %and
  ret i1 %cmp
}

; Negative test: mul(zext x, zext y) may overflow.
define i32 @mul_may_overflow(i32 %x, i32 %y) {
; CHECK-LABEL: @mul_may_overflow(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[L:%.*]] = zext i32 [[X:%.*]] to i34
; CHECK-NEXT:    [[R:%.*]] = zext i32 [[Y:%.*]] to i34
; CHECK-NEXT:    [[MUL34:%.*]] = mul i34 [[L]], [[R]]
; CHECK-NEXT:    [[OVERFLOW:%.*]] = icmp ult i34 [[MUL34]], 4294967296
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i34
  %r = zext i32 %y to i34
  %mul34 = mul i34 %l, %r
  %overflow = icmp ule i34 %mul34, 4294967295
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

define i32 @mul_known_nuw(i32 %x, i32 %y) {
; CHECK-LABEL: @mul_known_nuw(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[TMP0:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    [[OVERFLOW:%.*]] = xor i1 [[TMP0]], true
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
entry:
  %l = zext i32 %x to i34
  %r = zext i32 %y to i34
  %mul34 = mul nuw i34 %l, %r
  %overflow = icmp ule i34 %mul34, 4294967295
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

define i32 @extra_and_use(i32 %x, i32 %y) {
; CHECK-LABEL: @extra_and_use(
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[UMUL_VALUE:%.*]] = extractvalue { i32, i1 } [[UMUL]], 0
; CHECK-NEXT:    [[AND:%.*]] = zext i32 [[UMUL_VALUE]] to i64
; CHECK-NEXT:    [[OVERFLOW:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    call void @use.i64(i64 [[AND]])
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ugt i64 %mul64, 4294967295
  %and = and i64 %mul64, u0xffffffff
  call void @use.i64(i64 %and)
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

define i32 @extra_and_use_small_mask(i32 %x, i32 %y) {
; CHECK-LABEL: @extra_and_use_small_mask(
; CHECK-NEXT:    [[UMUL:%.*]] = call { i32, i1 } @llvm.umul.with.overflow.i32(i32 [[X:%.*]], i32 [[Y:%.*]])
; CHECK-NEXT:    [[UMUL_VALUE:%.*]] = extractvalue { i32, i1 } [[UMUL]], 0
; CHECK-NEXT:    [[TMP1:%.*]] = and i32 [[UMUL_VALUE]], 268435455
; CHECK-NEXT:    [[AND:%.*]] = zext nneg i32 [[TMP1]] to i64
; CHECK-NEXT:    [[OVERFLOW:%.*]] = extractvalue { i32, i1 } [[UMUL]], 1
; CHECK-NEXT:    call void @use.i64(i64 [[AND]])
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ugt i64 %mul64, 4294967295
  %and = and i64 %mul64, u0xfffffff
  call void @use.i64(i64 %and)
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

define i32 @extra_and_use_mask_too_large(i32 %x, i32 %y) {
; CHECK-LABEL: @extra_and_use_mask_too_large(
; CHECK-NEXT:    [[L:%.*]] = zext i32 [[X:%.*]] to i64
; CHECK-NEXT:    [[R:%.*]] = zext i32 [[Y:%.*]] to i64
; CHECK-NEXT:    [[MUL64:%.*]] = mul nuw i64 [[L]], [[R]]
; CHECK-NEXT:    [[OVERFLOW:%.*]] = icmp ugt i64 [[MUL64]], 4294967295
; CHECK-NEXT:    [[AND:%.*]] = and i64 [[MUL64]], 68719476735
; CHECK-NEXT:    call void @use.i64(i64 [[AND]])
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[OVERFLOW]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %l = zext i32 %x to i64
  %r = zext i32 %y to i64
  %mul64 = mul i64 %l, %r
  %overflow = icmp ugt i64 %mul64, 4294967295
  %and = and i64 %mul64, u0xfffffffff
  call void @use.i64(i64 %and)
  %retval = zext i1 %overflow to i32
  ret i32 %retval
}

define i32 @smul(i32 %a, i32 %b) {
; CHECK-LABEL: @smul(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add nsw i64 [[MUL]], -2147483648
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP1]], -4294967296
; CHECK-NEXT:    [[CONV3:%.*]] = zext i1 [[TMP2]] to i32
; CHECK-NEXT:    ret i32 [[CONV3]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %1 = add nsw i64 %mul, -2147483648
  %2 = icmp ult i64 %1, -4294967296
  %conv3 = zext i1 %2 to i32
  ret i32 %conv3
}

define i32 @smul2(i32 %a, i32 %b) {
; CHECK-LABEL: @smul2(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add i64 [[MUL]], 2147483647
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP1]], 4294967295
; CHECK-NEXT:    [[CONV3:%.*]] = zext i1 [[TMP2]] to i32
; CHECK-NEXT:    ret i32 [[CONV3]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %cmp = icmp sle i64 %mul, 2147483647
  %cmp2 = icmp sgt i64 %mul, -2147483648
  %1 = select i1 %cmp, i1 %cmp2, i1 false
  %conv3 = zext i1 %1 to i32
  ret i32 %conv3
}

define i1 @smul_sext_add_pattern(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_pattern(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i8 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i8 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[MUL]], 128
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i32 [[ADD]], 256
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %add = add i32 %mul, 128
  %cmp = icmp ult i32 %add, 256
  ret i1 %cmp
}

define i1 @smul_sext_add_wrong_constants(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_wrong_constants(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i8 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i8 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[MUL]], 58
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %add = add i32 %mul, 42
  %cmp = icmp slt i32 %add, 100 
  ret i1 %cmp
}

define i1 @smul_sext_add_eq_predicate(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_eq_predicate(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i8 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i8 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[MUL]], 128
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %add = add i32 %mul, 128
  %cmp = icmp eq i32 %add, 256
  ret i1 %cmp
}

define i1 @smul_sext_add_different_widths(i4 %a, i16 %b) {
; CHECK-LABEL: @smul_sext_add_different_widths(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i4 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i16 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[MUL]], 128
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i32 [[ADD]], 256
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i4 %a to i32
  %b.ext = sext i16 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %add = add i32 %mul, 128
  %cmp = icmp ult i32 %add, 256
  ret i1 %cmp
}

define i1 @smul_sext_add_no_nsw(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_no_nsw(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i8 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i8 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[MUL]], 128
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i32 [[ADD]], 256
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul i32 %a.ext, %b.ext  ; No nsw flag
  %add = add i32 %mul, 128
  %cmp = icmp ult i32 %add, 256
  ret i1 %cmp
}

define <2 x i1> @smul_sext_add_vector(<2 x i8> %a, <2 x i8> %b) {
; CHECK-LABEL: @smul_sext_add_vector(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext <2 x i8> [[A:%.*]] to <2 x i32>
; CHECK-NEXT:    [[B_EXT:%.*]] = sext <2 x i8> [[B:%.*]] to <2 x i32>
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw <2 x i32> [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[ADD:%.*]] = add nsw <2 x i32> [[MUL]], splat (i32 128)
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult <2 x i32> [[ADD]], splat (i32 256)
; CHECK-NEXT:    ret <2 x i1> [[CMP]]
;
  %a.ext = sext <2 x i8> %a to <2 x i32>
  %b.ext = sext <2 x i8> %b to <2 x i32>
  %mul = mul nsw <2 x i32> %a.ext, %b.ext
  %add = add <2 x i32> %mul, <i32 128, i32 128>
  %cmp = icmp ult <2 x i32> %add, <i32 256, i32 256>
  ret <2 x i1> %cmp
}

define i1 @smul_sext_add_negative2(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_negative2(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i8 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i8 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i32 [[MUL]], 128
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %cmp = icmp ult i32 %mul, 128
  %add = add i32 %mul, 128
  ret i1 %cmp
}

define i1 @smul_sext_add_multiple_uses(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_multiple_uses(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i8 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i8 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[MUL]], 128
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i32 [[ADD]], 256
; CHECK-NEXT:    call void @use.i32(i32 [[MUL]])
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %add = add i32 %mul, 128
  %cmp = icmp ult i32 %add, 256
  call void @use.i32(i32 %mul)
  ret i1 %cmp
}

define i1 @smul_sext_add_extreme_constants(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_extreme_constants(
; CHECK-NEXT:    ret i1 false
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %add = add i32 %mul, 2147483647  ; INT_MAX
  %cmp = icmp slt i32 %add, -2147483648  ; INT_MIN
  ret i1 %cmp
}

define i1 @smul_sext_add_nsw(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_nsw(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i8 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i8 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[MUL]], 128
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i32 [[ADD]], 256
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %add = add nsw i32 %mul, 128 
  %cmp = icmp ult i32 %add, 256
  ret i1 %cmp
}

define i1 @smul_sext_add_nuw_negative(i8 %a, i8 %b) {
; CHECK-LABEL: @smul_sext_add_nuw_negative(
; CHECK-NEXT:    [[A_EXT:%.*]] = sext i8 [[A:%.*]] to i32
; CHECK-NEXT:    [[B_EXT:%.*]] = sext i8 [[B:%.*]] to i32
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[A_EXT]], [[B_EXT]]
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i32 [[MUL]], 128
; CHECK-NEXT:    ret i1 [[CMP]]
;
  %a.ext = sext i8 %a to i32
  %b.ext = sext i8 %b to i32
  %mul = mul nsw i32 %a.ext, %b.ext
  %add = add nuw i32 %mul, 128
  %cmp = icmp ult i32 %add, 256
  ret i1 %cmp
}

define i32 @smul_extra_and_use(i32 %a, i32 %b) {
; CHECK-LABEL: @smul_extra_and_use(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add nsw i64 [[MUL]], -2147483648
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP1]], -4294967296
; CHECK-NEXT:    [[AND:%.*]] = and i64 [[MUL]], 4294967295
; CHECK-NEXT:    call void @use.i64(i64 [[AND]])
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[TMP2]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %1 = add nsw i64 %mul, -2147483648
  %2 = icmp ult i64 %1, -4294967296
  %and = and i64 %mul, 4294967295
  call void @use.i64(i64 %and)
  %retval = zext i1 %2 to i32
  ret i32 %retval
}

define i32 @smul_extra_trunc_use(i32 %a, i32 %b) {
; CHECK-LABEL: @smul_extra_trunc_use(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add nsw i64 [[MUL]], -2147483648
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP1]], -4294967296
; CHECK-NEXT:    [[TRUNC:%.*]] = trunc i64 [[MUL]] to i32
; CHECK-NEXT:    call void @use.i32(i32 [[TRUNC]])
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[TMP2]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %1 = add nsw i64 %mul, -2147483648
  %2 = icmp ult i64 %1, -4294967296
  %trunc = trunc i64 %mul to i32
  call void @use.i32(i32 %trunc)
  %retval = zext i1 %2 to i32
  ret i32 %retval
}

define i32 @smul_extra_and_use_small_mask(i32 %a, i32 %b) {
; CHECK-LABEL: @smul_extra_and_use_small_mask(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add nsw i64 [[MUL]], -2147483648
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP1]], -4294967296
; CHECK-NEXT:    [[AND:%.*]] = and i64 [[MUL]], 268435455
; CHECK-NEXT:    call void @use.i64(i64 [[AND]])
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[TMP2]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %1 = add nsw i64 %mul, -2147483648
  %2 = icmp ult i64 %1, -4294967296
  %and = and i64 %mul, u0xfffffff
  call void @use.i64(i64 %and)
  %retval = zext i1 %2 to i32
  ret i32 %retval
}

define i32 @smul_multiple_uses(i32 %a, i32 %b) {
; CHECK-LABEL: @smul_multiple_uses(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add nsw i64 [[MUL]], -2147483648
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP1]], -4294967296
; CHECK-NEXT:    [[AND:%.*]] = and i64 [[MUL]], 4294967295
; CHECK-NEXT:    [[TRUNC:%.*]] = trunc i64 [[MUL]] to i32
; CHECK-NEXT:    call void @use.i64(i64 [[AND]])
; CHECK-NEXT:    call void @use.i32(i32 [[TRUNC]])
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[TMP2]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %1 = add nsw i64 %mul, -2147483648
  %2 = icmp ult i64 %1, -4294967296
  %and = and i64 %mul, 4294967295
  %trunc = trunc i64 %mul to i32
  call void @use.i64(i64 %and)
  call void @use.i32(i32 %trunc)
  %retval = zext i1 %2 to i32
  ret i32 %retval
}

define i32 @smul_extra_and_use_mask_too_large(i32 %a, i32 %b) {
; CHECK-LABEL: @smul_extra_and_use_mask_too_large(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add nsw i64 [[MUL]], -2147483648
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP1]], -4294967296
; CHECK-NEXT:    [[AND:%.*]] = and i64 [[MUL]], 68719476735
; CHECK-NEXT:    call void @use.i64(i64 [[AND]])
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[TMP2]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %1 = add nsw i64 %mul, -2147483648
  %2 = icmp ult i64 %1, -4294967296
  %and = and i64 %mul, u0xfffffffff
  call void @use.i64(i64 %and)
  %retval = zext i1 %2 to i32
  ret i32 %retval
}

define i32 @smul_different_sizes(i32 %a, i8 %b) {
; CHECK-LABEL: @smul_different_sizes(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i8 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add nsw i64 [[MUL]], -2147483648
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult i64 [[TMP1]], -4294967296
; CHECK-NEXT:    [[TRUNC:%.*]] = trunc i64 [[MUL]] to i32
; CHECK-NEXT:    [[RETVAL:%.*]] = select i1 [[TMP2]], i32 [[TRUNC]], i32 111
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i8 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %1 = add nsw i64 %mul, -2147483648
  %2 = icmp ult i64 %1, -4294967296
  %trunc = trunc i64 %mul to i32
  %retval = select i1 %2, i32 %trunc, i32 111
  ret i32 %retval
}

define i32 @smul_inverse_pattern(i32 %a, i32 %b) {
; CHECK-LABEL: @smul_inverse_pattern(
; CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
; CHECK-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[ADD:%.*]] = add i64 [[MUL]], 2147483647
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i64 [[ADD]], 4294967295
; CHECK-NEXT:    [[RETVAL:%.*]] = zext i1 [[CMP]] to i32
; CHECK-NEXT:    ret i32 [[RETVAL]]
;
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %mul = mul nsw i64 %conv1, %conv
  %add = add i64 %mul, 2147483647
  %cmp = icmp ult i64 %add, 4294967295
  %retval = zext i1 %cmp to i32
  ret i32 %retval
}

define <2 x i32> @smul_vector_operations(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: @smul_vector_operations(
; CHECK-NEXT:    [[CONV:%.*]] = sext <2 x i32> [[A:%.*]] to <2 x i64>
; CHECK-NEXT:    [[CONV1:%.*]] = sext <2 x i32> [[B:%.*]] to <2 x i64>
; CHECK-NEXT:    [[MUL:%.*]] = mul nsw <2 x i64> [[CONV1]], [[CONV]]
; CHECK-NEXT:    [[TMP1:%.*]] = add nsw <2 x i64> [[MUL]], splat (i64 -2147483648)
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ult <2 x i64> [[TMP1]], splat (i64 -4294967296)
; CHECK-NEXT:    [[V:%.*]] = zext <2 x i1> [[TMP2]] to <2 x i32>
; CHECK-NEXT:    ret <2 x i32> [[V]]
;
  %conv = sext <2 x i32> %a to <2 x i64>
  %conv1 = sext <2 x i32> %b to <2 x i64>
  %mul = mul nsw <2 x i64> %conv1, %conv
  %1 = add nsw <2 x i64> %mul, <i64 -2147483648, i64 -2147483648>
  %2 = icmp ult <2 x i64> %1, <i64 -4294967296, i64 -4294967296>
  %v = select <2 x i1> %2, <2 x i32> <i32 1, i32 1>, <2 x i32> <i32 0, i32 0>
  ret <2 x i32> %v
}
