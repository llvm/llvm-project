; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -passes=instcombine -S < %s | FileCheck %s

define void @test_masked_store_success(<8 x i32> %x, ptr %ptr, <8 x i1> %cmp) {
; CHECK-LABEL: define void @test_masked_store_success(
; CHECK-SAME: <8 x i32> [[X:%.*]], ptr [[PTR:%.*]], <8 x i1> [[CMP:%.*]]) {
; CHECK-NEXT:    call void @llvm.masked.store.v8i32.p0(<8 x i32> [[X]], ptr [[PTR]], i32 32, <8 x i1> [[CMP]])
; CHECK-NEXT:    ret void
;
  %load = load <8 x i32>, ptr %ptr, align 32
  %sel = select <8 x i1> %cmp, <8 x i32> %x, <8 x i32> %load
  store <8 x i32> %sel, ptr %ptr, align 32
  ret void
}

define void @test_masked_store_volatile_load(<8 x i32> %x, ptr %ptr, <8 x i1> %cmp) {
; CHECK-LABEL: define void @test_masked_store_volatile_load(
; CHECK-SAME: <8 x i32> [[X:%.*]], ptr [[PTR:%.*]], <8 x i1> [[CMP:%.*]]) {
; CHECK-NEXT:    [[LOAD:%.*]] = load volatile <8 x i32>, ptr [[PTR]], align 32
; CHECK-NEXT:    [[SEL:%.*]] = select <8 x i1> [[CMP]], <8 x i32> [[X]], <8 x i32> [[LOAD]]
; CHECK-NEXT:    store <8 x i32> [[SEL]], ptr [[PTR]], align 32
; CHECK-NEXT:    ret void
;
  %load = load volatile <8 x i32>, ptr %ptr, align 32
  %sel = select <8 x i1> %cmp, <8 x i32> %x, <8 x i32> %load
  store <8 x i32> %sel, ptr %ptr, align 32
  ret void
}

define void @test_masked_store_volatile_store(<8 x i32> %x, ptr %ptr, <8 x i1> %cmp) {
; CHECK-LABEL: define void @test_masked_store_volatile_store(
; CHECK-SAME: <8 x i32> [[X:%.*]], ptr [[PTR:%.*]], <8 x i1> [[CMP:%.*]]) {
; CHECK-NEXT:    [[LOAD:%.*]] = load <8 x i32>, ptr [[PTR]], align 32
; CHECK-NEXT:    [[SEL:%.*]] = select <8 x i1> [[CMP]], <8 x i32> [[X]], <8 x i32> [[LOAD]]
; CHECK-NEXT:    store volatile <8 x i32> [[SEL]], ptr [[PTR]], align 32
; CHECK-NEXT:    ret void
;
  %load = load <8 x i32>, ptr %ptr, align 32
  %sel = select <8 x i1> %cmp, <8 x i32> %x, <8 x i32> %load
  store volatile <8 x i32> %sel, ptr %ptr, align 32
  ret void
}

declare void @use_vec(<8 x i32>)

define void @test_masked_store_intervening(<8 x i32> %x, ptr %ptr, <8 x i1> %cmp) {
; CHECK-LABEL: define void @test_masked_store_intervening(
; CHECK-SAME: <8 x i32> [[X:%.*]], ptr [[PTR:%.*]], <8 x i1> [[CMP:%.*]]) {
; CHECK-NEXT:    [[LOAD:%.*]] = load <8 x i32>, ptr [[PTR]], align 32
; CHECK-NEXT:    store <8 x i32> zeroinitializer, ptr [[PTR]], align 32
; CHECK-NEXT:    call void @use_vec(<8 x i32> zeroinitializer)
; CHECK-NEXT:    [[SEL:%.*]] = select <8 x i1> [[CMP]], <8 x i32> [[X]], <8 x i32> [[LOAD]]
; CHECK-NEXT:    store <8 x i32> [[SEL]], ptr [[PTR]], align 32
; CHECK-NEXT:    ret void
;
  %load = load <8 x i32>, ptr %ptr, align 32
  store <8 x i32> zeroinitializer, ptr %ptr, align 32
  %tmp = load <8 x i32>, ptr %ptr
  call void @use_vec(<8 x i32> %tmp)
  %sel = select <8 x i1> %cmp, <8 x i32> %x, <8 x i32> %load
  store <8 x i32> %sel, ptr %ptr, align 32
  ret void
}
