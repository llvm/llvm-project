; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-globals none --filter-out-after "^scalar.ph" --version 6
; RUN: opt -p loop-vectorize -force-vector-width=16 -force-target-supports-scalable-vectors=true -scalable-vectorization=preferred -S %s | FileCheck %s

define void @legalize_multiple_ptr_inductions(ptr %p, ptr noalias %q) {
; CHECK-LABEL: define void @legalize_multiple_ptr_inductions(
; CHECK-SAME: ptr [[P:%.*]], ptr noalias [[Q:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    [[TMP0:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP1:%.*]] = shl nuw i64 [[TMP0]], 4
; CHECK-NEXT:    br label %[[PH:.*]]
; CHECK:       [[PH]]:
; CHECK-NEXT:    [[REC_Q_INIT:%.*]] = phi ptr [ [[GEP_Q_LCSSA:%.*]], %[[LOOP_EXIT:.*]] ], [ [[Q]], %[[ENTRY]] ]
; CHECK-NEXT:    [[REC_P_INIT:%.*]] = phi ptr [ [[GEP_P_LCSSA:%.*]], %[[LOOP_EXIT]] ], [ [[P]], %[[ENTRY]] ]
; CHECK-NEXT:    [[REC_P_INIT1:%.*]] = ptrtoint ptr [[REC_P_INIT]] to i64
; CHECK-NEXT:    [[REC_Q_INIT2:%.*]] = ptrtoint ptr [[REC_Q_INIT]] to i64
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 1024, [[TMP1]]
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_MEMCHECK:.*]]
; CHECK:       [[VECTOR_MEMCHECK]]:
; CHECK-NEXT:    [[TMP2:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP3:%.*]] = mul nuw i64 [[TMP2]], 16
; CHECK-NEXT:    [[TMP4:%.*]] = sub i64 [[REC_P_INIT1]], [[REC_Q_INIT2]]
; CHECK-NEXT:    [[DIFF_CHECK:%.*]] = icmp ult i64 [[TMP4]], [[TMP3]]
; CHECK-NEXT:    br i1 [[DIFF_CHECK]], label %[[SCALAR_PH]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[TMP5:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP6:%.*]] = mul nuw i64 [[TMP5]], 16
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 1024, [[TMP6]]
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 1024, [[N_MOD_VF]]
; CHECK-NEXT:    [[TMP7:%.*]] = trunc i64 [[N_VEC]] to i32
; CHECK-NEXT:    [[TMP8:%.*]] = mul i64 [[N_VEC]], -1
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[REC_Q_INIT]], i64 [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = mul i64 [[N_VEC]], -1
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr [[REC_P_INIT]], i64 [[TMP10]]
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <vscale x 16 x i32> [ zeroinitializer, %[[VECTOR_PH]] ], [ [[TMP28:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[OFFSET_IDX:%.*]] = sub i64 0, [[INDEX]]
; CHECK-NEXT:    [[NEXT_GEP:%.*]] = getelementptr i8, ptr [[REC_Q_INIT]], i64 [[OFFSET_IDX]]
; CHECK-NEXT:    [[OFFSET_IDX3:%.*]] = sub i64 0, [[INDEX]]
; CHECK-NEXT:    [[NEXT_GEP4:%.*]] = getelementptr i8, ptr [[REC_P_INIT]], i64 [[OFFSET_IDX3]]
; CHECK-NEXT:    [[TMP18:%.*]] = getelementptr i8, ptr [[NEXT_GEP4]], i64 -1
; CHECK-NEXT:    [[TMP15:%.*]] = mul i64 0, [[TMP6]]
; CHECK-NEXT:    [[TMP16:%.*]] = sub i64 [[TMP6]], 1
; CHECK-NEXT:    [[TMP17:%.*]] = mul i64 -1, [[TMP16]]
; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr i8, ptr [[TMP18]], i64 [[TMP15]]
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr [[TMP19]], i64 [[TMP17]]
; CHECK-NEXT:    [[REVERSE:%.*]] = call <vscale x 16 x i8> @llvm.vector.reverse.nxv16i8(<vscale x 16 x i8> zeroinitializer)
; CHECK-NEXT:    store <vscale x 16 x i8> [[REVERSE]], ptr [[TMP20]], align 1
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr i8, ptr [[NEXT_GEP]], i64 -1
; CHECK-NEXT:    [[TMP22:%.*]] = mul i64 0, [[TMP6]]
; CHECK-NEXT:    [[TMP23:%.*]] = sub i64 [[TMP6]], 1
; CHECK-NEXT:    [[TMP24:%.*]] = mul i64 -1, [[TMP23]]
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr [[TMP25]], i64 [[TMP22]]
; CHECK-NEXT:    [[TMP27:%.*]] = getelementptr i8, ptr [[TMP26]], i64 [[TMP24]]
; CHECK-NEXT:    [[REVERSE5:%.*]] = call <vscale x 16 x i8> @llvm.vector.reverse.nxv16i8(<vscale x 16 x i8> zeroinitializer)
; CHECK-NEXT:    store <vscale x 16 x i8> [[REVERSE5]], ptr [[TMP27]], align 1
; CHECK-NEXT:    [[TMP28]] = or <vscale x 16 x i32> [[VEC_PHI]], splat (i32 1)
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], [[TMP6]]
; CHECK-NEXT:    [[TMP30:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP30]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[TMP31:%.*]] = call i32 @llvm.vector.reduce.or.nxv16i32(<vscale x 16 x i32> [[TMP28]])
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 1024, [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], label %[[LOOP_EXIT]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
;
entry:
  br label %ph

ph:
  %rec.q.init = phi ptr [ %gep.q, %loop.exit ], [ %q, %entry ]
  %rec.p.init = phi ptr [ %gep.p, %loop.exit ], [ %p, %entry ]
  br label %loop

loop:
  %iv = phi i32 [ 0, %ph ], [ %iv.next, %loop ]
  %rec.q = phi ptr [ %rec.q.init, %ph ], [ %gep.q, %loop ]
  %rec.p = phi ptr [ %rec.p.init, %ph ], [ %gep.p, %loop ]
  %rec.add = phi i32 [ 0, %ph ], [ %add.next, %loop ]
  %gep.p = getelementptr i8, ptr %rec.p, i64 -1
  store i8 0, ptr %gep.p
  %gep.q = getelementptr i8, ptr %rec.q, i64 -1
  store i8 0, ptr %gep.q
  %add.next = or i32 %rec.add, 1
  %iv.next = add i32 %iv, 1
  %ec = icmp eq i32 %iv.next, 1024
  br i1 %ec, label %loop.exit, label %loop

loop.exit:
  %ec.exit = icmp eq i32 %add.next, 512
  br i1 %ec.exit, label %exit, label %ph

exit:
  ret void
}
