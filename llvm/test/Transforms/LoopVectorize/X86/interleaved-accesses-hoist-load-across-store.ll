; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; RUN: opt -passes=loop-vectorize -force-vector-width=4 -force-vector-interleave=1 -S %s | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128-ni:1-p2:32:8:8:32-ni:2"
target triple = "x86_64-apple-macos"

; Both %l3 and the earlier store to %gep.iv.2 access the same location. %l1
; cannot be added safely to the same interleave group as %l2 and %l3, because
; that would mean %l2 and %l3 would need to be hoisted across the store.
define void @pr63602_1(ptr %arr) {
; CHECK-LABEL: define void @pr63602_1
; CHECK-SAME: (ptr [[ARR:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = mul i64 [[INDEX]], 3
; CHECK-NEXT:    [[OFFSET_IDX:%.*]] = add i64 1, [[TMP0]]
; CHECK-NEXT:    [[TMP1:%.*]] = add i64 [[OFFSET_IDX]], 0
; CHECK-NEXT:    [[TMP2:%.*]] = add i64 [[OFFSET_IDX]], 3
; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[OFFSET_IDX]], 6
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[OFFSET_IDX]], 9
; CHECK-NEXT:    [[TMP5:%.*]] = mul i64 [[INDEX]], 3
; CHECK-NEXT:    [[OFFSET_IDX1:%.*]] = add i64 4, [[TMP5]]
; CHECK-NEXT:    [[TMP6:%.*]] = add i64 [[OFFSET_IDX1]], 0
; CHECK-NEXT:    [[TMP7:%.*]] = add i64 [[OFFSET_IDX1]], 3
; CHECK-NEXT:    [[TMP8:%.*]] = add i64 [[OFFSET_IDX1]], 6
; CHECK-NEXT:    [[TMP9:%.*]] = add i64 [[OFFSET_IDX1]], 9
; CHECK-NEXT:    [[TMP10:%.*]] = add nuw nsw i64 [[TMP1]], 4
; CHECK-NEXT:    [[TMP11:%.*]] = add nuw nsw i64 [[TMP2]], 4
; CHECK-NEXT:    [[TMP12:%.*]] = add nuw nsw i64 [[TMP3]], 4
; CHECK-NEXT:    [[TMP13:%.*]] = add nuw nsw i64 [[TMP4]], 4
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP10]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP11]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP12]]
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP13]]
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = load i32, ptr [[TMP15]], align 4
; CHECK-NEXT:    [[TMP20:%.*]] = load i32, ptr [[TMP16]], align 4
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[TMP17]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP6]]
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP24:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP8]]
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP9]]
; CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP22]], align 4
; CHECK-NEXT:    store i32 [[TMP19]], ptr [[TMP23]], align 4
; CHECK-NEXT:    store i32 [[TMP20]], ptr [[TMP24]], align 4
; CHECK-NEXT:    store i32 [[TMP21]], ptr [[TMP25]], align 4
; CHECK-NEXT:    [[TMP26:%.*]] = add nuw nsw i64 [[TMP1]], 2
; CHECK-NEXT:    [[TMP27:%.*]] = add nuw nsw i64 [[TMP2]], 2
; CHECK-NEXT:    [[TMP28:%.*]] = add nuw nsw i64 [[TMP3]], 2
; CHECK-NEXT:    [[TMP29:%.*]] = add nuw nsw i64 [[TMP4]], 2
; CHECK-NEXT:    [[TMP30:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP26]]
; CHECK-NEXT:    [[TMP31:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP27]]
; CHECK-NEXT:    [[TMP32:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP28]]
; CHECK-NEXT:    [[TMP33:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP29]]
; CHECK-NEXT:    [[TMP34:%.*]] = load i32, ptr [[TMP30]], align 4
; CHECK-NEXT:    [[TMP35:%.*]] = load i32, ptr [[TMP31]], align 4
; CHECK-NEXT:    [[TMP36:%.*]] = load i32, ptr [[TMP32]], align 4
; CHECK-NEXT:    [[TMP37:%.*]] = load i32, ptr [[TMP33]], align 4
; CHECK-NEXT:    [[TMP38:%.*]] = insertelement <4 x i32> poison, i32 [[TMP34]], i32 0
; CHECK-NEXT:    [[TMP39:%.*]] = insertelement <4 x i32> [[TMP38]], i32 [[TMP35]], i32 1
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <4 x i32> [[TMP39]], i32 [[TMP36]], i32 2
; CHECK-NEXT:    [[TMP41:%.*]] = insertelement <4 x i32> [[TMP40]], i32 [[TMP37]], i32 3
; CHECK-NEXT:    [[TMP42:%.*]] = load i32, ptr [[TMP22]], align 4
; CHECK-NEXT:    [[TMP43:%.*]] = load i32, ptr [[TMP23]], align 4
; CHECK-NEXT:    [[TMP44:%.*]] = load i32, ptr [[TMP24]], align 4
; CHECK-NEXT:    [[TMP45:%.*]] = load i32, ptr [[TMP25]], align 4
; CHECK-NEXT:    [[TMP46:%.*]] = insertelement <4 x i32> poison, i32 [[TMP42]], i32 0
; CHECK-NEXT:    [[TMP47:%.*]] = insertelement <4 x i32> [[TMP46]], i32 [[TMP43]], i32 1
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <4 x i32> [[TMP47]], i32 [[TMP44]], i32 2
; CHECK-NEXT:    [[TMP49:%.*]] = insertelement <4 x i32> [[TMP48]], i32 [[TMP45]], i32 3
; CHECK-NEXT:    [[TMP50:%.*]] = add <4 x i32> [[TMP49]], [[TMP41]]
; CHECK-NEXT:    [[TMP51:%.*]] = extractelement <4 x i32> [[TMP50]], i32 0
; CHECK-NEXT:    [[TMP52:%.*]] = extractelement <4 x i32> [[TMP50]], i32 1
; CHECK-NEXT:    [[TMP53:%.*]] = extractelement <4 x i32> [[TMP50]], i32 2
; CHECK-NEXT:    [[TMP54:%.*]] = extractelement <4 x i32> [[TMP50]], i32 3
; CHECK-NEXT:    store i32 [[TMP51]], ptr [[TMP22]], align 4
; CHECK-NEXT:    store i32 [[TMP52]], ptr [[TMP23]], align 4
; CHECK-NEXT:    store i32 [[TMP53]], ptr [[TMP24]], align 4
; CHECK-NEXT:    store i32 [[TMP54]], ptr [[TMP25]], align 4
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
; CHECK-NEXT:    [[TMP55:%.*]] = icmp eq i64 [[INDEX_NEXT]], 16
; CHECK-NEXT:    br i1 [[TMP55]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br label [[SCALAR_PH:%.*]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    br label [[LOOP:%.*]]
; CHECK:       loop:
; CHECK-NEXT:    [[IV_1:%.*]] = phi i64 [ 49, [[SCALAR_PH]] ], [ [[IV_1_NEXT:%.*]], [[LOOP]] ]
; CHECK-NEXT:    [[IV_2:%.*]] = phi i64 [ 52, [[SCALAR_PH]] ], [ [[IV_2_NEXT:%.*]], [[LOOP]] ]
; CHECK-NEXT:    [[IV_1_NEXT]] = add nuw nsw i64 [[IV_1]], 3
; CHECK-NEXT:    [[IV_1_PLUS_4:%.*]] = add nuw nsw i64 [[IV_1]], 4
; CHECK-NEXT:    [[GEP_IV_1_PLUS_4:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[IV_1_PLUS_4]]
; CHECK-NEXT:    [[L1:%.*]] = load i32, ptr [[GEP_IV_1_PLUS_4]], align 4
; CHECK-NEXT:    [[GEP_IV_2:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[IV_2]]
; CHECK-NEXT:    store i32 [[L1]], ptr [[GEP_IV_2]], align 4
; CHECK-NEXT:    [[IV_1_PLUS_2:%.*]] = add nuw nsw i64 [[IV_1]], 2
; CHECK-NEXT:    [[GEP_IV_1_PLUS_2:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[IV_1_PLUS_2]]
; CHECK-NEXT:    [[L2:%.*]] = load i32, ptr [[GEP_IV_1_PLUS_2]], align 4
; CHECK-NEXT:    [[L3:%.*]] = load i32, ptr [[GEP_IV_2]], align 4
; CHECK-NEXT:    [[ADD:%.*]] = add i32 [[L3]], [[L2]]
; CHECK-NEXT:    store i32 [[ADD]], ptr [[GEP_IV_2]], align 4
; CHECK-NEXT:    [[IV_2_NEXT]] = add nuw nsw i64 [[IV_2]], 3
; CHECK-NEXT:    [[ICMP:%.*]] = icmp ugt i64 [[IV_2]], 50
; CHECK-NEXT:    br i1 [[ICMP]], label [[EXIT:%.*]], label [[LOOP]], !llvm.loop [[LOOP3:![0-9]+]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %iv.1 = phi i64 [ 1, %entry ], [ %iv.1.next, %loop ]
  %iv.2 = phi i64 [ 4, %entry ], [ %iv.2.next, %loop ]
  %iv.1.next = add nuw nsw i64 %iv.1, 3
  %iv.1.plus.4 = add nuw nsw i64 %iv.1, 4
  %gep.iv.1.plus.4 = getelementptr inbounds i32, ptr %arr, i64 %iv.1.plus.4
  %l1 = load i32, ptr %gep.iv.1.plus.4
  %gep.iv.2 = getelementptr inbounds i32, ptr %arr, i64 %iv.2
  store i32 %l1, ptr %gep.iv.2
  %iv.1.plus.2 = add nuw nsw i64 %iv.1, 2
  %gep.iv.1.plus.2= getelementptr inbounds i32, ptr %arr, i64 %iv.1.plus.2
  %l2 = load i32, ptr %gep.iv.1.plus.2
  %l3 = load i32, ptr %gep.iv.2
  %add = add i32 %l3 , %l2
  store i32 %add, ptr %gep.iv.2
  %iv.2.next = add nuw nsw i64 %iv.2, 3
  %icmp = icmp ugt i64 %iv.2, 50
  br i1 %icmp, label %exit, label %loop

exit:
  ret void
}

; %l3 and the preceeding store access the same memory location. So, we cannot
; have the loads %l1, %l2 and %l3 in the same interleave group since it would
; mean hoisting the load %l2 and %l3 across the store.

; Unlike the above case, since we go through the last load in program order and
; compare against the obstructing stores (%l2 versus the store) there is no
; dependency. However, the other load in %l2's interleave group (%l3) does
; obstruct with the store.
define void @pr63602_2(ptr %arr) {
; CHECK-LABEL: define void @pr63602_2
; CHECK-SAME: (ptr [[ARR:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = mul i64 [[INDEX]], 3
; CHECK-NEXT:    [[OFFSET_IDX:%.*]] = add i64 1, [[TMP0]]
; CHECK-NEXT:    [[TMP1:%.*]] = add i64 [[OFFSET_IDX]], 0
; CHECK-NEXT:    [[TMP2:%.*]] = add i64 [[OFFSET_IDX]], 3
; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[OFFSET_IDX]], 6
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[OFFSET_IDX]], 9
; CHECK-NEXT:    [[TMP5:%.*]] = mul i64 [[INDEX]], 3
; CHECK-NEXT:    [[OFFSET_IDX1:%.*]] = add i64 4, [[TMP5]]
; CHECK-NEXT:    [[TMP6:%.*]] = add i64 [[OFFSET_IDX1]], 0
; CHECK-NEXT:    [[TMP7:%.*]] = add i64 [[OFFSET_IDX1]], 3
; CHECK-NEXT:    [[TMP8:%.*]] = add i64 [[OFFSET_IDX1]], 6
; CHECK-NEXT:    [[TMP9:%.*]] = add i64 [[OFFSET_IDX1]], 9
; CHECK-NEXT:    [[TMP10:%.*]] = add nuw nsw i64 [[TMP1]], 4
; CHECK-NEXT:    [[TMP11:%.*]] = add nuw nsw i64 [[TMP2]], 4
; CHECK-NEXT:    [[TMP12:%.*]] = add nuw nsw i64 [[TMP3]], 4
; CHECK-NEXT:    [[TMP13:%.*]] = add nuw nsw i64 [[TMP4]], 4
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP10]]
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP11]]
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP12]]
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP13]]
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = load i32, ptr [[TMP15]], align 4
; CHECK-NEXT:    [[TMP20:%.*]] = load i32, ptr [[TMP16]], align 4
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[TMP17]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP6]]
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP24:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP8]]
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP9]]
; CHECK-NEXT:    store i32 [[TMP18]], ptr [[TMP22]], align 4
; CHECK-NEXT:    store i32 [[TMP19]], ptr [[TMP23]], align 4
; CHECK-NEXT:    store i32 [[TMP20]], ptr [[TMP24]], align 4
; CHECK-NEXT:    store i32 [[TMP21]], ptr [[TMP25]], align 4
; CHECK-NEXT:    [[TMP26:%.*]] = add nuw nsw i64 [[TMP1]], 2
; CHECK-NEXT:    [[TMP27:%.*]] = add nuw nsw i64 [[TMP2]], 2
; CHECK-NEXT:    [[TMP28:%.*]] = add nuw nsw i64 [[TMP3]], 2
; CHECK-NEXT:    [[TMP29:%.*]] = add nuw nsw i64 [[TMP4]], 2
; CHECK-NEXT:    [[TMP30:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP26]]
; CHECK-NEXT:    [[TMP31:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP27]]
; CHECK-NEXT:    [[TMP32:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP28]]
; CHECK-NEXT:    [[TMP33:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[TMP29]]
; CHECK-NEXT:    [[TMP34:%.*]] = load i32, ptr [[TMP22]], align 4
; CHECK-NEXT:    [[TMP35:%.*]] = load i32, ptr [[TMP23]], align 4
; CHECK-NEXT:    [[TMP36:%.*]] = load i32, ptr [[TMP24]], align 4
; CHECK-NEXT:    [[TMP37:%.*]] = load i32, ptr [[TMP25]], align 4
; CHECK-NEXT:    [[TMP38:%.*]] = insertelement <4 x i32> poison, i32 [[TMP34]], i32 0
; CHECK-NEXT:    [[TMP39:%.*]] = insertelement <4 x i32> [[TMP38]], i32 [[TMP35]], i32 1
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <4 x i32> [[TMP39]], i32 [[TMP36]], i32 2
; CHECK-NEXT:    [[TMP41:%.*]] = insertelement <4 x i32> [[TMP40]], i32 [[TMP37]], i32 3
; CHECK-NEXT:    [[TMP42:%.*]] = load i32, ptr [[TMP30]], align 4
; CHECK-NEXT:    [[TMP43:%.*]] = load i32, ptr [[TMP31]], align 4
; CHECK-NEXT:    [[TMP44:%.*]] = load i32, ptr [[TMP32]], align 4
; CHECK-NEXT:    [[TMP45:%.*]] = load i32, ptr [[TMP33]], align 4
; CHECK-NEXT:    [[TMP46:%.*]] = insertelement <4 x i32> poison, i32 [[TMP42]], i32 0
; CHECK-NEXT:    [[TMP47:%.*]] = insertelement <4 x i32> [[TMP46]], i32 [[TMP43]], i32 1
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <4 x i32> [[TMP47]], i32 [[TMP44]], i32 2
; CHECK-NEXT:    [[TMP49:%.*]] = insertelement <4 x i32> [[TMP48]], i32 [[TMP45]], i32 3
; CHECK-NEXT:    [[TMP50:%.*]] = add <4 x i32> [[TMP41]], [[TMP49]]
; CHECK-NEXT:    [[TMP51:%.*]] = extractelement <4 x i32> [[TMP50]], i32 0
; CHECK-NEXT:    [[TMP52:%.*]] = extractelement <4 x i32> [[TMP50]], i32 1
; CHECK-NEXT:    [[TMP53:%.*]] = extractelement <4 x i32> [[TMP50]], i32 2
; CHECK-NEXT:    [[TMP54:%.*]] = extractelement <4 x i32> [[TMP50]], i32 3
; CHECK-NEXT:    store i32 [[TMP51]], ptr [[TMP22]], align 4
; CHECK-NEXT:    store i32 [[TMP52]], ptr [[TMP23]], align 4
; CHECK-NEXT:    store i32 [[TMP53]], ptr [[TMP24]], align 4
; CHECK-NEXT:    store i32 [[TMP54]], ptr [[TMP25]], align 4
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
; CHECK-NEXT:    [[TMP55:%.*]] = icmp eq i64 [[INDEX_NEXT]], 16
; CHECK-NEXT:    br i1 [[TMP55]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br label [[SCALAR_PH:%.*]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    br label [[LOOP:%.*]]
; CHECK:       loop:
; CHECK-NEXT:    [[IV_1:%.*]] = phi i64 [ 49, [[SCALAR_PH]] ], [ [[IV_1_NEXT:%.*]], [[LOOP]] ]
; CHECK-NEXT:    [[IV_2:%.*]] = phi i64 [ 52, [[SCALAR_PH]] ], [ [[IV_2_NEXT:%.*]], [[LOOP]] ]
; CHECK-NEXT:    [[IV_1_NEXT]] = add nuw nsw i64 [[IV_1]], 3
; CHECK-NEXT:    [[IV_1_PLUS_4:%.*]] = add nuw nsw i64 [[IV_1]], 4
; CHECK-NEXT:    [[GEP_IV_1_PLUS_4:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[IV_1_PLUS_4]]
; CHECK-NEXT:    [[L1:%.*]] = load i32, ptr [[GEP_IV_1_PLUS_4]], align 4
; CHECK-NEXT:    [[GEP_IV_2:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[IV_2]]
; CHECK-NEXT:    store i32 [[L1]], ptr [[GEP_IV_2]], align 4
; CHECK-NEXT:    [[IV_1_PLUS_2:%.*]] = add nuw nsw i64 [[IV_1]], 2
; CHECK-NEXT:    [[GEP_IV_1_PLUS_2:%.*]] = getelementptr inbounds i32, ptr [[ARR]], i64 [[IV_1_PLUS_2]]
; CHECK-NEXT:    [[L3:%.*]] = load i32, ptr [[GEP_IV_2]], align 4
; CHECK-NEXT:    [[L2:%.*]] = load i32, ptr [[GEP_IV_1_PLUS_2]], align 4
; CHECK-NEXT:    [[ADD:%.*]] = add i32 [[L3]], [[L2]]
; CHECK-NEXT:    store i32 [[ADD]], ptr [[GEP_IV_2]], align 4
; CHECK-NEXT:    [[IV_2_NEXT]] = add nuw nsw i64 [[IV_2]], 3
; CHECK-NEXT:    [[ICMP:%.*]] = icmp ugt i64 [[IV_2]], 50
; CHECK-NEXT:    br i1 [[ICMP]], label [[EXIT:%.*]], label [[LOOP]], !llvm.loop [[LOOP5:![0-9]+]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %iv.1 = phi i64 [ 1, %entry ], [ %iv.1.next, %loop ]
  %iv.2 = phi i64 [ 4, %entry ], [ %iv.2.next, %loop ]
  %iv.1.next = add nuw nsw i64 %iv.1, 3
  %iv.1.plus.4 = add nuw nsw i64 %iv.1, 4
  %gep.iv.1.plus.4 = getelementptr inbounds i32, ptr %arr, i64 %iv.1.plus.4
  %l1 = load i32, ptr %gep.iv.1.plus.4
  %gep.iv.2 = getelementptr inbounds i32, ptr %arr, i64 %iv.2
  store i32 %l1, ptr %gep.iv.2
  %iv.1.plus.2 = add nuw nsw i64 %iv.1, 2
  %gep.iv.1.plus.2= getelementptr inbounds i32, ptr %arr, i64 %iv.1.plus.2
  %l3 = load i32, ptr %gep.iv.2
  %l2 = load i32, ptr %gep.iv.1.plus.2
  %add = add i32 %l3 , %l2
  store i32 %add, ptr %gep.iv.2
  %iv.2.next = add nuw nsw i64 %iv.2, 3
  %icmp = icmp ugt i64 %iv.2, 50
  br i1 %icmp, label %exit, label %loop

exit:
  ret void
}
