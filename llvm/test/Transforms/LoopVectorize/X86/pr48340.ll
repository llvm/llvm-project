; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -loop-vectorize --force-vector-width=4 --force-vector-interleave=0 -S -o - < %s | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%0 = type { i32 }
%1 = type { i64 }

define void @foo(i64* %p, i64* %p.last) unnamed_addr #0 {
; CHECK-LABEL: @foo(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[P4:%.*]] = ptrtoint i64* [[P:%.*]] to i64
; CHECK-NEXT:    [[P_LAST1:%.*]] = ptrtoint i64* [[P_LAST:%.*]] to i64
; CHECK-NEXT:    [[TMP0:%.*]] = add i64 [[P_LAST1]], -1024
; CHECK-NEXT:    [[TMP1:%.*]] = sub i64 [[TMP0]], [[P4]]
; CHECK-NEXT:    [[TMP2:%.*]] = lshr i64 [[TMP1]], 10
; CHECK-NEXT:    [[TMP3:%.*]] = add nuw nsw i64 [[TMP2]], 1
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[TMP3]], 16
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[TMP3]], 16
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[TMP3]], [[N_MOD_VF]]
; CHECK-NEXT:    [[TMP4:%.*]] = mul i64 [[N_VEC]], 128
; CHECK-NEXT:    [[IND_END:%.*]] = getelementptr i64, i64* [[P]], i64 [[TMP4]]
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[POINTER_PHI:%.*]] = phi i64* [ [[P]], [[VECTOR_PH]] ], [ [[PTR_IND:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i64, i64* [[POINTER_PHI]], <4 x i64> <i64 0, i64 128, i64 256, i64 384>
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i64, i64* [[POINTER_PHI]], <4 x i64> <i64 512, i64 640, i64 768, i64 896>
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i64, i64* [[POINTER_PHI]], <4 x i64> <i64 1024, i64 1152, i64 1280, i64 1408>
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i64, i64* [[POINTER_PHI]], <4 x i64> <i64 1536, i64 1664, i64 1792, i64 1920>
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <4 x i64*> [[TMP5]] to <4 x %0**>
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast <4 x i64*> [[TMP6]] to <4 x %0**>
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <4 x i64*> [[TMP7]] to <4 x %0**>
; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <4 x i64*> [[TMP8]] to <4 x %0**>
; CHECK-NEXT:    [[WIDE_MASKED_GATHER:%.*]] = call <4 x %0*> @llvm.masked.gather.v4p0s_s.v4p0p0s_s.0(<4 x %0**> [[TMP9]], i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x %0*> undef)
; CHECK-NEXT:    [[WIDE_MASKED_GATHER5:%.*]] = call <4 x %0*> @llvm.masked.gather.v4p0s_s.v4p0p0s_s.0(<4 x %0**> [[TMP10]], i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x %0*> undef)
; CHECK-NEXT:    [[WIDE_MASKED_GATHER6:%.*]] = call <4 x %0*> @llvm.masked.gather.v4p0s_s.v4p0p0s_s.0(<4 x %0**> [[TMP11]], i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x %0*> undef)
; CHECK-NEXT:    [[WIDE_MASKED_GATHER7:%.*]] = call <4 x %0*> @llvm.masked.gather.v4p0s_s.v4p0p0s_s.0(<4 x %0**> [[TMP12]], i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x %0*> undef)
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
; CHECK-NEXT:    [[PTR_IND]] = getelementptr i64, i64* [[POINTER_PHI]], i64 2048
; CHECK-NEXT:    [[TMP13:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP13]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[TMP3]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], label [[EXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64* [ [[IND_END]], [[MIDDLE_BLOCK]] ], [ [[P]], [[ENTRY:%.*]] ]
; CHECK-NEXT:    br label [[LOOP:%.*]]
; CHECK:       loop:
; CHECK-NEXT:    [[P2:%.*]] = phi i64* [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ], [ [[P_INC:%.*]], [[LOOP]] ]
; CHECK-NEXT:    [[P_INC]] = getelementptr inbounds i64, i64* [[P2]], i64 128
; CHECK-NEXT:    [[P3:%.*]] = bitcast i64* [[P2]] to %0**
; CHECK-NEXT:    [[V:%.*]] = load %0*, %0** [[P3]], align 8
; CHECK-NEXT:    [[B:%.*]] = icmp eq i64* [[P_INC]], [[P_LAST]]
; CHECK-NEXT:    br i1 [[B]], label [[EXIT]], label [[LOOP]], !llvm.loop [[LOOP2:![0-9]+]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %p2 = phi i64* [ %p, %entry ], [ %p.inc, %loop ]
  %p.inc = getelementptr inbounds i64, i64* %p2, i64 128
  %p3 = bitcast i64* %p2 to %0**
  %v = load %0*, %0** %p3, align 8
  %b = icmp eq i64* %p.inc, %p.last
  br i1 %b, label %exit, label %loop

exit:
  ret void
}

define void @bar(i64* %p, i64* %p.last) unnamed_addr #0 {
; CHECK-LABEL: @bar(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[P4:%.*]] = ptrtoint i64* [[P:%.*]] to i64
; CHECK-NEXT:    [[P_LAST1:%.*]] = ptrtoint i64* [[P_LAST:%.*]] to i64
; CHECK-NEXT:    [[TMP0:%.*]] = add i64 [[P_LAST1]], -1024
; CHECK-NEXT:    [[TMP1:%.*]] = sub i64 [[TMP0]], [[P4]]
; CHECK-NEXT:    [[TMP2:%.*]] = lshr i64 [[TMP1]], 10
; CHECK-NEXT:    [[TMP3:%.*]] = add nuw nsw i64 [[TMP2]], 1
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[TMP3]], 16
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[TMP3]], 16
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[TMP3]], [[N_MOD_VF]]
; CHECK-NEXT:    [[TMP4:%.*]] = mul i64 [[N_VEC]], 128
; CHECK-NEXT:    [[IND_END:%.*]] = getelementptr i64, i64* [[P]], i64 [[TMP4]]
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[POINTER_PHI:%.*]] = phi i64* [ [[P]], [[VECTOR_PH]] ], [ [[PTR_IND:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i64, i64* [[POINTER_PHI]], <4 x i64> <i64 0, i64 128, i64 256, i64 384>
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i64, i64* [[POINTER_PHI]], <4 x i64> <i64 512, i64 640, i64 768, i64 896>
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i64, i64* [[POINTER_PHI]], <4 x i64> <i64 1024, i64 1152, i64 1280, i64 1408>
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i64, i64* [[POINTER_PHI]], <4 x i64> <i64 1536, i64 1664, i64 1792, i64 1920>
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <4 x i64*> [[TMP5]] to <4 x %1**>
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast <4 x i64*> [[TMP6]] to <4 x %1**>
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <4 x i64*> [[TMP7]] to <4 x %1**>
; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <4 x i64*> [[TMP8]] to <4 x %1**>
; CHECK-NEXT:    [[WIDE_MASKED_GATHER:%.*]] = call <4 x %1*> @llvm.masked.gather.v4p0s_s.v4p0p0s_s.1(<4 x %1**> [[TMP9]], i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x %1*> undef)
; CHECK-NEXT:    [[WIDE_MASKED_GATHER5:%.*]] = call <4 x %1*> @llvm.masked.gather.v4p0s_s.v4p0p0s_s.1(<4 x %1**> [[TMP10]], i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x %1*> undef)
; CHECK-NEXT:    [[WIDE_MASKED_GATHER6:%.*]] = call <4 x %1*> @llvm.masked.gather.v4p0s_s.v4p0p0s_s.1(<4 x %1**> [[TMP11]], i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x %1*> undef)
; CHECK-NEXT:    [[WIDE_MASKED_GATHER7:%.*]] = call <4 x %1*> @llvm.masked.gather.v4p0s_s.v4p0p0s_s.1(<4 x %1**> [[TMP12]], i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x %1*> undef)
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
; CHECK-NEXT:    [[PTR_IND]] = getelementptr i64, i64* [[POINTER_PHI]], i64 2048
; CHECK-NEXT:    [[TMP13:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP13]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[TMP3]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], label [[EXIT:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64* [ [[IND_END]], [[MIDDLE_BLOCK]] ], [ [[P]], [[ENTRY:%.*]] ]
; CHECK-NEXT:    br label [[LOOP:%.*]]
; CHECK:       loop:
; CHECK-NEXT:    [[P2:%.*]] = phi i64* [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ], [ [[P_INC:%.*]], [[LOOP]] ]
; CHECK-NEXT:    [[P_INC]] = getelementptr inbounds i64, i64* [[P2]], i64 128
; CHECK-NEXT:    [[P3:%.*]] = bitcast i64* [[P2]] to %1**
; CHECK-NEXT:    [[V:%.*]] = load %1*, %1** [[P3]], align 8
; CHECK-NEXT:    [[B:%.*]] = icmp eq i64* [[P_INC]], [[P_LAST]]
; CHECK-NEXT:    br i1 [[B]], label [[EXIT]], label [[LOOP]], !llvm.loop [[LOOP5:![0-9]+]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %p2 = phi i64* [ %p, %entry ], [ %p.inc, %loop ]
  %p.inc = getelementptr inbounds i64, i64* %p2, i64 128
  %p3 = bitcast i64* %p2 to %1**
  %v = load %1*, %1** %p3, align 8
  %b = icmp eq i64* %p.inc, %p.last
  br i1 %b, label %exit, label %loop

exit:
  ret void
}

attributes #0 = { "target-cpu"="skylake" }

