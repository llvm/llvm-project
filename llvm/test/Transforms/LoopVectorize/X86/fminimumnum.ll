; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; FIXME: fmaximumnum/fminimumnum have no vectorizing support yet.
; RUN: opt --passes=loop-vectorize --mtriple=x86_64 -S < %s | FileCheck %s --check-prefix=X64

@input1_f32 = global [4096 x float] zeroinitializer, align 4
@input2_f32 = global [4096 x float] zeroinitializer, align 4
@output_f32 = global [4096 x float] zeroinitializer, align 4
@input1_f64 = global [4096 x double] zeroinitializer, align 8
@input2_f64 = global [4096 x double] zeroinitializer, align 8
@output_f64 = global [4096 x double] zeroinitializer, align 8
@input1_f16 = global [4096 x half] zeroinitializer, align 2
@input2_f16 = global [4096 x half] zeroinitializer, align 2
@output_f16 = global [4096 x half] zeroinitializer, align 2

define void @f32min()  {
; X64-LABEL: define void @f32min() {
; X64-NEXT:  [[ENTRY:.*]]:
; X64-NEXT:    br label %[[FOR_BODY:.*]]
; X64:       [[FOR_COND_CLEANUP:.*]]:
; X64-NEXT:    ret void
; X64:       [[FOR_BODY]]:
; X64-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, %[[ENTRY]] ], [ [[INDVARS_IV_NEXT:%.*]], %[[FOR_BODY]] ]
; X64-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds nuw [4096 x float], ptr @input1_f32, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP12:%.*]] = load float, ptr [[ARRAYIDX]], align 4
; X64-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds nuw [4096 x float], ptr @input2_f32, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP13:%.*]] = load float, ptr [[ARRAYIDX2]], align 4
; X64-NEXT:    [[TMP14:%.*]] = tail call float @llvm.minimumnum.f32(float [[TMP12]], float [[TMP13]])
; X64-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds nuw [4096 x float], ptr @output_f32, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    store float [[TMP14]], ptr [[ARRAYIDX4]], align 4
; X64-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; X64-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 4096
; X64-NEXT:    br i1 [[EXITCOND_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY]]
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  ret void

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds nuw [4096 x float], ptr @input1_f32, i64 0, i64 %indvars.iv
  %input1 = load float, ptr %arrayidx, align 4
  %arrayidx2 = getelementptr inbounds nuw [4096 x float], ptr @input2_f32, i64 0, i64 %indvars.iv
  %input2 = load float, ptr %arrayidx2, align 4
  %output = tail call float @llvm.minimumnum.f32(float %input1, float %input2)
  %arrayidx4 = getelementptr inbounds nuw [4096 x float], ptr @output_f32, i64 0, i64 %indvars.iv
  store float %output, ptr %arrayidx4, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 4096
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
}

declare float @llvm.minimumnum.f32(float, float)

define void @f32max()  {
; X64-LABEL: define void @f32max() {
; X64-NEXT:  [[ENTRY:.*]]:
; X64-NEXT:    br label %[[FOR_BODY:.*]]
; X64:       [[FOR_COND_CLEANUP:.*]]:
; X64-NEXT:    ret void
; X64:       [[FOR_BODY]]:
; X64-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, %[[ENTRY]] ], [ [[INDVARS_IV_NEXT:%.*]], %[[FOR_BODY]] ]
; X64-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds nuw [4096 x float], ptr @input1_f32, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP12:%.*]] = load float, ptr [[ARRAYIDX]], align 4
; X64-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds nuw [4096 x float], ptr @input2_f32, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP13:%.*]] = load float, ptr [[ARRAYIDX2]], align 4
; X64-NEXT:    [[TMP14:%.*]] = tail call float @llvm.maximumnum.f32(float [[TMP12]], float [[TMP13]])
; X64-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds nuw [4096 x float], ptr @output_f32, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    store float [[TMP14]], ptr [[ARRAYIDX4]], align 4
; X64-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; X64-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 4096
; X64-NEXT:    br i1 [[EXITCOND_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY]]
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  ret void

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds nuw [4096 x float], ptr @input1_f32, i64 0, i64 %indvars.iv
  %input1 = load float, ptr %arrayidx, align 4
  %arrayidx2 = getelementptr inbounds nuw [4096 x float], ptr @input2_f32, i64 0, i64 %indvars.iv
  %input2 = load float, ptr %arrayidx2, align 4
  %output = tail call float @llvm.maximumnum.f32(float %input1, float %input2)
  %arrayidx4 = getelementptr inbounds nuw [4096 x float], ptr @output_f32, i64 0, i64 %indvars.iv
  store float %output, ptr %arrayidx4, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 4096
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
}

declare float @llvm.maximumnum.f32(float, float)

define void @f64min()  {
; X64-LABEL: define void @f64min() {
; X64-NEXT:  [[ENTRY:.*]]:
; X64-NEXT:    br label %[[FOR_BODY:.*]]
; X64:       [[FOR_COND_CLEANUP:.*]]:
; X64-NEXT:    ret void
; X64:       [[FOR_BODY]]:
; X64-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, %[[ENTRY]] ], [ [[INDVARS_IV_NEXT:%.*]], %[[FOR_BODY]] ]
; X64-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds nuw [4096 x double], ptr @input1_f64, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP12:%.*]] = load double, ptr [[ARRAYIDX]], align 8
; X64-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds nuw [4096 x double], ptr @input2_f64, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP13:%.*]] = load double, ptr [[ARRAYIDX2]], align 8
; X64-NEXT:    [[TMP14:%.*]] = tail call double @llvm.minimumnum.f64(double [[TMP12]], double [[TMP13]])
; X64-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds nuw [4096 x double], ptr @output_f64, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    store double [[TMP14]], ptr [[ARRAYIDX4]], align 8
; X64-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; X64-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 4096
; X64-NEXT:    br i1 [[EXITCOND_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY]]
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  ret void

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds nuw [4096 x double], ptr @input1_f64, i64 0, i64 %indvars.iv
  %input1 = load double, ptr %arrayidx, align 8
  %arrayidx2 = getelementptr inbounds nuw [4096 x double], ptr @input2_f64, i64 0, i64 %indvars.iv
  %input2 = load double, ptr %arrayidx2, align 8
  %output = tail call double @llvm.minimumnum.f64(double %input1, double %input2)
  %arrayidx4 = getelementptr inbounds nuw [4096 x double], ptr @output_f64, i64 0, i64 %indvars.iv
  store double %output, ptr %arrayidx4, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 4096
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
}

declare double @llvm.minimumnum.f64(double, double)

define void @f64max()  {
; X64-LABEL: define void @f64max() {
; X64-NEXT:  [[ENTRY:.*]]:
; X64-NEXT:    br label %[[FOR_BODY:.*]]
; X64:       [[FOR_COND_CLEANUP:.*]]:
; X64-NEXT:    ret void
; X64:       [[FOR_BODY]]:
; X64-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, %[[ENTRY]] ], [ [[INDVARS_IV_NEXT:%.*]], %[[FOR_BODY]] ]
; X64-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds nuw [4096 x double], ptr @input1_f64, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP12:%.*]] = load double, ptr [[ARRAYIDX]], align 8
; X64-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds nuw [4096 x double], ptr @input2_f64, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP13:%.*]] = load double, ptr [[ARRAYIDX2]], align 8
; X64-NEXT:    [[TMP14:%.*]] = tail call double @llvm.maximumnum.f64(double [[TMP12]], double [[TMP13]])
; X64-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds nuw [4096 x double], ptr @output_f64, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    store double [[TMP14]], ptr [[ARRAYIDX4]], align 8
; X64-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; X64-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 4096
; X64-NEXT:    br i1 [[EXITCOND_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY]]
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  ret void

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds nuw [4096 x double], ptr @input1_f64, i64 0, i64 %indvars.iv
  %input1 = load double, ptr %arrayidx, align 8
  %arrayidx2 = getelementptr inbounds nuw [4096 x double], ptr @input2_f64, i64 0, i64 %indvars.iv
  %input2 = load double, ptr %arrayidx2, align 8
  %output = tail call double @llvm.maximumnum.f64(double %input1, double %input2)
  %arrayidx4 = getelementptr inbounds nuw [4096 x double], ptr @output_f64, i64 0, i64 %indvars.iv
  store double %output, ptr %arrayidx4, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 4096
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
}

declare double @llvm.maximumnum.f64(double, double)

define void @f16min()  {
; X64-LABEL: define void @f16min() {
; X64-NEXT:  [[ENTRY:.*]]:
; X64-NEXT:    br label %[[FOR_BODY:.*]]
; X64:       [[FOR_COND_CLEANUP:.*]]:
; X64-NEXT:    ret void
; X64:       [[FOR_BODY]]:
; X64-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, %[[ENTRY]] ], [ [[INDVARS_IV_NEXT:%.*]], %[[FOR_BODY]] ]
; X64-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds nuw [4096 x half], ptr @input1_f16, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP8:%.*]] = load half, ptr [[ARRAYIDX]], align 2
; X64-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds nuw [4096 x half], ptr @input2_f16, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP9:%.*]] = load half, ptr [[ARRAYIDX2]], align 2
; X64-NEXT:    [[TMP10:%.*]] = tail call half @llvm.minimumnum.f16(half [[TMP8]], half [[TMP9]])
; X64-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds nuw [4096 x half], ptr @output_f16, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    store half [[TMP10]], ptr [[ARRAYIDX4]], align 2
; X64-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; X64-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 4096
; X64-NEXT:    br i1 [[EXITCOND_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY]]
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  ret void

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds nuw [4096 x half], ptr @input1_f16, i64 0, i64 %indvars.iv
  %input1 = load half, ptr %arrayidx, align 2
  %arrayidx2 = getelementptr inbounds nuw [4096 x half], ptr @input2_f16, i64 0, i64 %indvars.iv
  %input2 = load half, ptr %arrayidx2, align 2
  %output = tail call half @llvm.minimumnum.f16(half %input1, half %input2)
  %arrayidx4 = getelementptr inbounds nuw [4096 x half], ptr @output_f16, i64 0, i64 %indvars.iv
  store half %output, ptr %arrayidx4, align 2
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 4096
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
}

declare half @llvm.minimumnum.f16(half, half)

define void @f16max()  {
; X64-LABEL: define void @f16max() {
; X64-NEXT:  [[ENTRY:.*]]:
; X64-NEXT:    br label %[[FOR_BODY:.*]]
; X64:       [[FOR_COND_CLEANUP:.*]]:
; X64-NEXT:    ret void
; X64:       [[FOR_BODY]]:
; X64-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ 0, %[[ENTRY]] ], [ [[INDVARS_IV_NEXT:%.*]], %[[FOR_BODY]] ]
; X64-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds nuw [4096 x half], ptr @input1_f16, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP8:%.*]] = load half, ptr [[ARRAYIDX]], align 2
; X64-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds nuw [4096 x half], ptr @input2_f16, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    [[TMP9:%.*]] = load half, ptr [[ARRAYIDX2]], align 2
; X64-NEXT:    [[TMP10:%.*]] = tail call half @llvm.maximumnum.f16(half [[TMP8]], half [[TMP9]])
; X64-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds nuw [4096 x half], ptr @output_f16, i64 0, i64 [[INDVARS_IV]]
; X64-NEXT:    store half [[TMP10]], ptr [[ARRAYIDX4]], align 2
; X64-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; X64-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 4096
; X64-NEXT:    br i1 [[EXITCOND_NOT]], label %[[FOR_COND_CLEANUP]], label %[[FOR_BODY]]
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  ret void

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds nuw [4096 x half], ptr @input1_f16, i64 0, i64 %indvars.iv
  %input1 = load half, ptr %arrayidx, align 2
  %arrayidx2 = getelementptr inbounds nuw [4096 x half], ptr @input2_f16, i64 0, i64 %indvars.iv
  %input2 = load half, ptr %arrayidx2, align 2
  %output = tail call half @llvm.maximumnum.f16(half %input1, half %input2)
  %arrayidx4 = getelementptr inbounds nuw [4096 x half], ptr @output_f16, i64 0, i64 %indvars.iv
  store half %output, ptr %arrayidx4, align 2
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 4096
  br i1 %exitcond.not, label %for.cond.cleanup, label %for.body
}

declare half @llvm.maximumnum.f16(half, half)
