; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; REQUIRES: asserts
; RUN: opt < %s -S -debug -loop-vectorize -mcpu=slm 2>&1 | FileCheck %s --check-prefix=SLM

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define i8 @mul_i8(i8* %dataA, i8* %dataB, i32 %N) {
; SLM-LABEL: @mul_i8(
; SLM-NEXT:  entry:
; SLM-NEXT:    [[CMP12:%.*]] = icmp eq i32 [[N:%.*]], 0
; SLM-NEXT:    br i1 [[CMP12]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_PREHEADER:%.*]]
; SLM:       for.body.preheader:
; SLM-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext i32 [[N]] to i64
; SLM-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[WIDE_TRIP_COUNT]], 8
; SLM-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; SLM:       vector.ph:
; SLM-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[WIDE_TRIP_COUNT]], 8
; SLM-NEXT:    [[N_VEC:%.*]] = sub i64 [[WIDE_TRIP_COUNT]], [[N_MOD_VF]]
; SLM-NEXT:    br label [[VECTOR_BODY:%.*]]
; SLM:       vector.body:
; SLM-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; SLM-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i32> [ zeroinitializer, [[VECTOR_PH]] ], [ [[TMP50:%.*]], [[VECTOR_BODY]] ]
; SLM-NEXT:    [[VEC_PHI1:%.*]] = phi <4 x i32> [ zeroinitializer, [[VECTOR_PH]] ], [ [[TMP51:%.*]], [[VECTOR_BODY]] ]
; SLM-NEXT:    [[TMP0:%.*]] = add i64 [[INDEX]], 0
; SLM-NEXT:    [[TMP1:%.*]] = add i64 [[INDEX]], 4
; SLM-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, i8* [[DATAA:%.*]], i64 [[TMP0]]
; SLM-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, i8* [[DATAA]], i64 [[TMP1]]
; SLM-NEXT:    [[TMP4:%.*]] = getelementptr inbounds i8, i8* [[TMP2]], i32 0
; SLM-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP4]] to <4 x i8>*
; SLM-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, <4 x i8>* [[TMP5]], align 1
; SLM-NEXT:    [[TMP6:%.*]] = getelementptr inbounds i8, i8* [[TMP2]], i32 4
; SLM-NEXT:    [[TMP7:%.*]] = bitcast i8* [[TMP6]] to <4 x i8>*
; SLM-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, <4 x i8>* [[TMP7]], align 1
; SLM-NEXT:    [[TMP8:%.*]] = sext <4 x i8> [[WIDE_LOAD]] to <4 x i32>
; SLM-NEXT:    [[TMP9:%.*]] = sext <4 x i8> [[WIDE_LOAD2]] to <4 x i32>
; SLM-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i8, i8* [[DATAB:%.*]], i64 [[TMP0]]
; SLM-NEXT:    [[TMP11:%.*]] = getelementptr inbounds i8, i8* [[DATAB]], i64 [[TMP1]]
; SLM-NEXT:    [[TMP12:%.*]] = getelementptr inbounds i8, i8* [[TMP10]], i32 0
; SLM-NEXT:    [[TMP13:%.*]] = bitcast i8* [[TMP12]] to <4 x i8>*
; SLM-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, <4 x i8>* [[TMP13]], align 1
; SLM-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i8, i8* [[TMP10]], i32 4
; SLM-NEXT:    [[TMP15:%.*]] = bitcast i8* [[TMP14]] to <4 x i8>*
; SLM-NEXT:    [[WIDE_LOAD4:%.*]] = load <4 x i8>, <4 x i8>* [[TMP15]], align 1
; SLM-NEXT:    [[TMP16:%.*]] = sext <4 x i8> [[WIDE_LOAD3]] to <4 x i32>
; SLM-NEXT:    [[TMP17:%.*]] = sext <4 x i8> [[WIDE_LOAD4]] to <4 x i32>
; SLM-NEXT:    [[TMP18:%.*]] = mul nsw <4 x i32> [[TMP16]], [[TMP8]]
; SLM-NEXT:    [[TMP19:%.*]] = mul nsw <4 x i32> [[TMP17]], [[TMP9]]
; SLM-NEXT:    [[TMP20:%.*]] = zext <4 x i8> [[WIDE_LOAD3]] to <4 x i32>
; SLM-NEXT:    [[TMP21:%.*]] = zext <4 x i8> [[WIDE_LOAD4]] to <4 x i32>
; SLM-NEXT:    [[TMP22:%.*]] = mul nsw <4 x i32> [[TMP20]], [[TMP8]]
; SLM-NEXT:    [[TMP23:%.*]] = mul nsw <4 x i32> [[TMP21]], [[TMP9]]
; SLM-NEXT:    [[TMP24:%.*]] = add <4 x i32> [[TMP18]], [[TMP22]]
; SLM-NEXT:    [[TMP25:%.*]] = add <4 x i32> [[TMP19]], [[TMP23]]
; SLM-NEXT:    [[TMP26:%.*]] = zext <4 x i8> [[WIDE_LOAD]] to <4 x i32>
; SLM-NEXT:    [[TMP27:%.*]] = zext <4 x i8> [[WIDE_LOAD2]] to <4 x i32>
; SLM-NEXT:    [[TMP28:%.*]] = mul nsw <4 x i32> [[TMP26]], [[TMP20]]
; SLM-NEXT:    [[TMP29:%.*]] = mul nsw <4 x i32> [[TMP27]], [[TMP21]]
; SLM-NEXT:    [[TMP30:%.*]] = add <4 x i32> [[TMP24]], [[TMP28]]
; SLM-NEXT:    [[TMP31:%.*]] = add <4 x i32> [[TMP25]], [[TMP29]]
; SLM-NEXT:    [[TMP32:%.*]] = mul nsw <4 x i32> <i32 -120, i32 -120, i32 -120, i32 -120>, [[TMP16]]
; SLM-NEXT:    [[TMP33:%.*]] = mul nsw <4 x i32> <i32 -120, i32 -120, i32 -120, i32 -120>, [[TMP17]]
; SLM-NEXT:    [[TMP34:%.*]] = add <4 x i32> [[TMP30]], [[TMP32]]
; SLM-NEXT:    [[TMP35:%.*]] = add <4 x i32> [[TMP31]], [[TMP33]]
; SLM-NEXT:    [[TMP36:%.*]] = mul nsw <4 x i32> <i32 250, i32 250, i32 250, i32 250>, [[TMP16]]
; SLM-NEXT:    [[TMP37:%.*]] = mul nsw <4 x i32> <i32 250, i32 250, i32 250, i32 250>, [[TMP17]]
; SLM-NEXT:    [[TMP38:%.*]] = add <4 x i32> [[TMP34]], [[TMP36]]
; SLM-NEXT:    [[TMP39:%.*]] = add <4 x i32> [[TMP35]], [[TMP37]]
; SLM-NEXT:    [[TMP40:%.*]] = mul nsw <4 x i32> <i32 -120, i32 -120, i32 -120, i32 -120>, [[TMP20]]
; SLM-NEXT:    [[TMP41:%.*]] = mul nsw <4 x i32> <i32 -120, i32 -120, i32 -120, i32 -120>, [[TMP21]]
; SLM-NEXT:    [[TMP42:%.*]] = add <4 x i32> [[TMP38]], [[TMP40]]
; SLM-NEXT:    [[TMP43:%.*]] = add <4 x i32> [[TMP39]], [[TMP41]]
; SLM-NEXT:    [[TMP44:%.*]] = mul nsw <4 x i32> <i32 250, i32 250, i32 250, i32 250>, [[TMP20]]
; SLM-NEXT:    [[TMP45:%.*]] = mul nsw <4 x i32> <i32 250, i32 250, i32 250, i32 250>, [[TMP21]]
; SLM-NEXT:    [[TMP46:%.*]] = add <4 x i32> [[TMP42]], [[TMP44]]
; SLM-NEXT:    [[TMP47:%.*]] = add <4 x i32> [[TMP43]], [[TMP45]]
; SLM-NEXT:    [[TMP48:%.*]] = add <4 x i32> [[VEC_PHI]], <i32 5, i32 5, i32 5, i32 5>
; SLM-NEXT:    [[TMP49:%.*]] = add <4 x i32> [[VEC_PHI1]], <i32 5, i32 5, i32 5, i32 5>
; SLM-NEXT:    [[TMP50]] = add <4 x i32> [[TMP48]], [[TMP46]]
; SLM-NEXT:    [[TMP51]] = add <4 x i32> [[TMP49]], [[TMP47]]
; SLM-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 8
; SLM-NEXT:    [[TMP52:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; SLM-NEXT:    br i1 [[TMP52]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; SLM:       middle.block:
; SLM-NEXT:    [[BIN_RDX:%.*]] = add <4 x i32> [[TMP51]], [[TMP50]]
; SLM-NEXT:    [[TMP53:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[BIN_RDX]])
; SLM-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[WIDE_TRIP_COUNT]], [[N_VEC]]
; SLM-NEXT:    br i1 [[CMP_N]], label [[FOR_COND_CLEANUP_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; SLM:       scalar.ph:
; SLM-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N_VEC]], [[MIDDLE_BLOCK]] ], [ 0, [[FOR_BODY_PREHEADER]] ]
; SLM-NEXT:    [[BC_MERGE_RDX:%.*]] = phi i32 [ 0, [[FOR_BODY_PREHEADER]] ], [ [[TMP53]], [[MIDDLE_BLOCK]] ]
; SLM-NEXT:    br label [[FOR_BODY:%.*]]
; SLM:       for.cond.cleanup.loopexit:
; SLM-NEXT:    [[ADD4_LCSSA:%.*]] = phi i32 [ [[ADD4:%.*]], [[FOR_BODY]] ], [ [[TMP53]], [[MIDDLE_BLOCK]] ]
; SLM-NEXT:    [[PHITMP:%.*]] = trunc i32 [[ADD4_LCSSA]] to i8
; SLM-NEXT:    br label [[FOR_COND_CLEANUP]]
; SLM:       for.cond.cleanup:
; SLM-NEXT:    [[ACC_0_LCSSA:%.*]] = phi i8 [ 0, [[ENTRY:%.*]] ], [ [[PHITMP]], [[FOR_COND_CLEANUP_LOOPEXIT]] ]
; SLM-NEXT:    ret i8 [[ACC_0_LCSSA]]
; SLM:       for.body:
; SLM-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; SLM-NEXT:    [[ACC_013:%.*]] = phi i32 [ [[ADD4]], [[FOR_BODY]] ], [ [[BC_MERGE_RDX]], [[SCALAR_PH]] ]
; SLM-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i8, i8* [[DATAA]], i64 [[INDVARS_IV]]
; SLM-NEXT:    [[TMP54:%.*]] = load i8, i8* [[ARRAYIDX]], align 1
; SLM-NEXT:    [[CONV:%.*]] = sext i8 [[TMP54]] to i32
; SLM-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds i8, i8* [[DATAB]], i64 [[INDVARS_IV]]
; SLM-NEXT:    [[TMP55:%.*]] = load i8, i8* [[ARRAYIDX2]], align 1
; SLM-NEXT:    [[CONV3:%.*]] = sext i8 [[TMP55]] to i32
; SLM-NEXT:    [[MUL:%.*]] = mul nsw i32 [[CONV3]], [[CONV]]
; SLM-NEXT:    [[CONV4:%.*]] = zext i8 [[TMP55]] to i32
; SLM-NEXT:    [[MUL2:%.*]] = mul nsw i32 [[CONV4]], [[CONV]]
; SLM-NEXT:    [[SUM0:%.*]] = add i32 [[MUL]], [[MUL2]]
; SLM-NEXT:    [[CONV5:%.*]] = zext i8 [[TMP54]] to i32
; SLM-NEXT:    [[MUL3:%.*]] = mul nsw i32 [[CONV5]], [[CONV4]]
; SLM-NEXT:    [[SUM1:%.*]] = add i32 [[SUM0]], [[MUL3]]
; SLM-NEXT:    [[MUL4:%.*]] = mul nsw i32 -120, [[CONV3]]
; SLM-NEXT:    [[SUM2:%.*]] = add i32 [[SUM1]], [[MUL4]]
; SLM-NEXT:    [[MUL5:%.*]] = mul nsw i32 250, [[CONV3]]
; SLM-NEXT:    [[SUM3:%.*]] = add i32 [[SUM2]], [[MUL5]]
; SLM-NEXT:    [[MUL6:%.*]] = mul nsw i32 -120, [[CONV4]]
; SLM-NEXT:    [[SUM4:%.*]] = add i32 [[SUM3]], [[MUL6]]
; SLM-NEXT:    [[MUL7:%.*]] = mul nsw i32 250, [[CONV4]]
; SLM-NEXT:    [[SUM5:%.*]] = add i32 [[SUM4]], [[MUL7]]
; SLM-NEXT:    [[ADD:%.*]] = add i32 [[ACC_013]], 5
; SLM-NEXT:    [[ADD4]] = add i32 [[ADD]], [[SUM5]]
; SLM-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; SLM-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[WIDE_TRIP_COUNT]]
; SLM-NEXT:    br i1 [[EXITCOND]], label [[FOR_COND_CLEANUP_LOOPEXIT]], label [[FOR_BODY]], !llvm.loop [[LOOP2:![0-9]+]]
;
entry:
  %cmp12 = icmp eq i32 %N, 0
  br i1 %cmp12, label %for.cond.cleanup, label %for.body.preheader

for.body.preheader:                               ; preds = %entry
  %wide.trip.count = zext i32 %N to i64
  br label %for.body

for.cond.cleanup.loopexit:                        ; preds = %for.body
  %phitmp = trunc i32 %add4 to i8
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit, %entry
  %acc.0.lcssa = phi i8 [ 0, %entry ], [ %phitmp, %for.cond.cleanup.loopexit ]
  ret i8 %acc.0.lcssa

for.body:                                         ; preds = %for.body.preheader, %for.body
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 0, %for.body.preheader ]
  %acc.013 = phi i32 [ %add4, %for.body ], [ 0, %for.body.preheader ]
  %arrayidx = getelementptr inbounds i8, i8* %dataA, i64 %indvars.iv
  %0 = load i8, i8* %arrayidx, align 1
  %conv = sext i8 %0 to i32
  %arrayidx2 = getelementptr inbounds i8, i8* %dataB, i64 %indvars.iv
  %1 = load i8, i8* %arrayidx2, align 1
  %conv3 = sext i8 %1 to i32
; sources of the mul is sext\sext from i8
; use pmullw\sext seq.
  %mul = mul nsw i32 %conv3, %conv
; sources of the mul is zext\sext from i8
; use pmulhw\pmullw\pshuf
  %conv4 = zext i8 %1 to i32
  %mul2 = mul nsw i32 %conv4, %conv
  %sum0 = add i32 %mul, %mul2
; sources of the mul is zext\zext from i8
; use pmullw\zext
  %conv5 = zext i8 %0 to i32
  %mul3 = mul nsw i32 %conv5, %conv4
  %sum1 = add i32 %sum0, %mul3
; sources of the mul is sext\-120
; use pmullw\sext
  %mul4 = mul nsw i32 -120, %conv3
  %sum2 = add i32 %sum1, %mul4
; sources of the mul is sext\250
; use pmulhw\pmullw\pshuf
  %mul5 = mul nsw i32 250, %conv3
  %sum3 = add i32 %sum2, %mul5
; sources of the mul is zext\-120
; use pmulhw\pmullw\pshuf
  %mul6 = mul nsw i32 -120, %conv4
  %sum4 = add i32 %sum3, %mul6
; sources of the mul is zext\250
; use pmullw\zext
  %mul7 = mul nsw i32 250, %conv4
  %sum5 = add i32 %sum4, %mul7
  %add = add i32 %acc.013, 5
  %add4 = add i32 %add, %sum5
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond, label %for.cond.cleanup.loopexit, label %for.body
}

define i16 @mul_i16(i16* %dataA, i16* %dataB, i32 %N) {
; SLM-LABEL: @mul_i16(
; SLM-NEXT:  entry:
; SLM-NEXT:    [[CMP12:%.*]] = icmp eq i32 [[N:%.*]], 0
; SLM-NEXT:    br i1 [[CMP12]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_PREHEADER:%.*]]
; SLM:       for.body.preheader:
; SLM-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext i32 [[N]] to i64
; SLM-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[WIDE_TRIP_COUNT]], 8
; SLM-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; SLM:       vector.ph:
; SLM-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[WIDE_TRIP_COUNT]], 8
; SLM-NEXT:    [[N_VEC:%.*]] = sub i64 [[WIDE_TRIP_COUNT]], [[N_MOD_VF]]
; SLM-NEXT:    br label [[VECTOR_BODY:%.*]]
; SLM:       vector.body:
; SLM-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; SLM-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i32> [ zeroinitializer, [[VECTOR_PH]] ], [ [[TMP50:%.*]], [[VECTOR_BODY]] ]
; SLM-NEXT:    [[VEC_PHI1:%.*]] = phi <4 x i32> [ zeroinitializer, [[VECTOR_PH]] ], [ [[TMP51:%.*]], [[VECTOR_BODY]] ]
; SLM-NEXT:    [[TMP0:%.*]] = add i64 [[INDEX]], 0
; SLM-NEXT:    [[TMP1:%.*]] = add i64 [[INDEX]], 4
; SLM-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i16, i16* [[DATAA:%.*]], i64 [[TMP0]]
; SLM-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i16, i16* [[DATAA]], i64 [[TMP1]]
; SLM-NEXT:    [[TMP4:%.*]] = getelementptr inbounds i16, i16* [[TMP2]], i32 0
; SLM-NEXT:    [[TMP5:%.*]] = bitcast i16* [[TMP4]] to <4 x i16>*
; SLM-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i16>, <4 x i16>* [[TMP5]], align 1
; SLM-NEXT:    [[TMP6:%.*]] = getelementptr inbounds i16, i16* [[TMP2]], i32 4
; SLM-NEXT:    [[TMP7:%.*]] = bitcast i16* [[TMP6]] to <4 x i16>*
; SLM-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i16>, <4 x i16>* [[TMP7]], align 1
; SLM-NEXT:    [[TMP8:%.*]] = sext <4 x i16> [[WIDE_LOAD]] to <4 x i32>
; SLM-NEXT:    [[TMP9:%.*]] = sext <4 x i16> [[WIDE_LOAD2]] to <4 x i32>
; SLM-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i16, i16* [[DATAB:%.*]], i64 [[TMP0]]
; SLM-NEXT:    [[TMP11:%.*]] = getelementptr inbounds i16, i16* [[DATAB]], i64 [[TMP1]]
; SLM-NEXT:    [[TMP12:%.*]] = getelementptr inbounds i16, i16* [[TMP10]], i32 0
; SLM-NEXT:    [[TMP13:%.*]] = bitcast i16* [[TMP12]] to <4 x i16>*
; SLM-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i16>, <4 x i16>* [[TMP13]], align 1
; SLM-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i16, i16* [[TMP10]], i32 4
; SLM-NEXT:    [[TMP15:%.*]] = bitcast i16* [[TMP14]] to <4 x i16>*
; SLM-NEXT:    [[WIDE_LOAD4:%.*]] = load <4 x i16>, <4 x i16>* [[TMP15]], align 1
; SLM-NEXT:    [[TMP16:%.*]] = sext <4 x i16> [[WIDE_LOAD3]] to <4 x i32>
; SLM-NEXT:    [[TMP17:%.*]] = sext <4 x i16> [[WIDE_LOAD4]] to <4 x i32>
; SLM-NEXT:    [[TMP18:%.*]] = mul nsw <4 x i32> [[TMP16]], [[TMP8]]
; SLM-NEXT:    [[TMP19:%.*]] = mul nsw <4 x i32> [[TMP17]], [[TMP9]]
; SLM-NEXT:    [[TMP20:%.*]] = zext <4 x i16> [[WIDE_LOAD3]] to <4 x i32>
; SLM-NEXT:    [[TMP21:%.*]] = zext <4 x i16> [[WIDE_LOAD4]] to <4 x i32>
; SLM-NEXT:    [[TMP22:%.*]] = mul nsw <4 x i32> [[TMP20]], [[TMP8]]
; SLM-NEXT:    [[TMP23:%.*]] = mul nsw <4 x i32> [[TMP21]], [[TMP9]]
; SLM-NEXT:    [[TMP24:%.*]] = add <4 x i32> [[TMP18]], [[TMP22]]
; SLM-NEXT:    [[TMP25:%.*]] = add <4 x i32> [[TMP19]], [[TMP23]]
; SLM-NEXT:    [[TMP26:%.*]] = zext <4 x i16> [[WIDE_LOAD]] to <4 x i32>
; SLM-NEXT:    [[TMP27:%.*]] = zext <4 x i16> [[WIDE_LOAD2]] to <4 x i32>
; SLM-NEXT:    [[TMP28:%.*]] = mul nsw <4 x i32> [[TMP26]], [[TMP20]]
; SLM-NEXT:    [[TMP29:%.*]] = mul nsw <4 x i32> [[TMP27]], [[TMP21]]
; SLM-NEXT:    [[TMP30:%.*]] = add <4 x i32> [[TMP24]], [[TMP28]]
; SLM-NEXT:    [[TMP31:%.*]] = add <4 x i32> [[TMP25]], [[TMP29]]
; SLM-NEXT:    [[TMP32:%.*]] = mul nsw <4 x i32> <i32 -32000, i32 -32000, i32 -32000, i32 -32000>, [[TMP16]]
; SLM-NEXT:    [[TMP33:%.*]] = mul nsw <4 x i32> <i32 -32000, i32 -32000, i32 -32000, i32 -32000>, [[TMP17]]
; SLM-NEXT:    [[TMP34:%.*]] = add <4 x i32> [[TMP30]], [[TMP32]]
; SLM-NEXT:    [[TMP35:%.*]] = add <4 x i32> [[TMP31]], [[TMP33]]
; SLM-NEXT:    [[TMP36:%.*]] = mul nsw <4 x i32> <i32 64000, i32 64000, i32 64000, i32 64000>, [[TMP16]]
; SLM-NEXT:    [[TMP37:%.*]] = mul nsw <4 x i32> <i32 64000, i32 64000, i32 64000, i32 64000>, [[TMP17]]
; SLM-NEXT:    [[TMP38:%.*]] = add <4 x i32> [[TMP34]], [[TMP36]]
; SLM-NEXT:    [[TMP39:%.*]] = add <4 x i32> [[TMP35]], [[TMP37]]
; SLM-NEXT:    [[TMP40:%.*]] = mul nsw <4 x i32> <i32 -32000, i32 -32000, i32 -32000, i32 -32000>, [[TMP20]]
; SLM-NEXT:    [[TMP41:%.*]] = mul nsw <4 x i32> <i32 -32000, i32 -32000, i32 -32000, i32 -32000>, [[TMP21]]
; SLM-NEXT:    [[TMP42:%.*]] = add <4 x i32> [[TMP38]], [[TMP40]]
; SLM-NEXT:    [[TMP43:%.*]] = add <4 x i32> [[TMP39]], [[TMP41]]
; SLM-NEXT:    [[TMP44:%.*]] = mul nsw <4 x i32> <i32 250, i32 250, i32 250, i32 250>, [[TMP20]]
; SLM-NEXT:    [[TMP45:%.*]] = mul nsw <4 x i32> <i32 250, i32 250, i32 250, i32 250>, [[TMP21]]
; SLM-NEXT:    [[TMP46:%.*]] = add <4 x i32> [[TMP42]], [[TMP44]]
; SLM-NEXT:    [[TMP47:%.*]] = add <4 x i32> [[TMP43]], [[TMP45]]
; SLM-NEXT:    [[TMP48:%.*]] = add <4 x i32> [[VEC_PHI]], <i32 5, i32 5, i32 5, i32 5>
; SLM-NEXT:    [[TMP49:%.*]] = add <4 x i32> [[VEC_PHI1]], <i32 5, i32 5, i32 5, i32 5>
; SLM-NEXT:    [[TMP50]] = add <4 x i32> [[TMP48]], [[TMP46]]
; SLM-NEXT:    [[TMP51]] = add <4 x i32> [[TMP49]], [[TMP47]]
; SLM-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 8
; SLM-NEXT:    [[TMP52:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; SLM-NEXT:    br i1 [[TMP52]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; SLM:       middle.block:
; SLM-NEXT:    [[BIN_RDX:%.*]] = add <4 x i32> [[TMP51]], [[TMP50]]
; SLM-NEXT:    [[TMP53:%.*]] = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> [[BIN_RDX]])
; SLM-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[WIDE_TRIP_COUNT]], [[N_VEC]]
; SLM-NEXT:    br i1 [[CMP_N]], label [[FOR_COND_CLEANUP_LOOPEXIT:%.*]], label [[SCALAR_PH]]
; SLM:       scalar.ph:
; SLM-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N_VEC]], [[MIDDLE_BLOCK]] ], [ 0, [[FOR_BODY_PREHEADER]] ]
; SLM-NEXT:    [[BC_MERGE_RDX:%.*]] = phi i32 [ 0, [[FOR_BODY_PREHEADER]] ], [ [[TMP53]], [[MIDDLE_BLOCK]] ]
; SLM-NEXT:    br label [[FOR_BODY:%.*]]
; SLM:       for.cond.cleanup.loopexit:
; SLM-NEXT:    [[ADD4_LCSSA:%.*]] = phi i32 [ [[ADD4:%.*]], [[FOR_BODY]] ], [ [[TMP53]], [[MIDDLE_BLOCK]] ]
; SLM-NEXT:    [[PHITMP:%.*]] = trunc i32 [[ADD4_LCSSA]] to i16
; SLM-NEXT:    br label [[FOR_COND_CLEANUP]]
; SLM:       for.cond.cleanup:
; SLM-NEXT:    [[ACC_0_LCSSA:%.*]] = phi i16 [ 0, [[ENTRY:%.*]] ], [ [[PHITMP]], [[FOR_COND_CLEANUP_LOOPEXIT]] ]
; SLM-NEXT:    ret i16 [[ACC_0_LCSSA]]
; SLM:       for.body:
; SLM-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
; SLM-NEXT:    [[ACC_013:%.*]] = phi i32 [ [[ADD4]], [[FOR_BODY]] ], [ [[BC_MERGE_RDX]], [[SCALAR_PH]] ]
; SLM-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i16, i16* [[DATAA]], i64 [[INDVARS_IV]]
; SLM-NEXT:    [[TMP54:%.*]] = load i16, i16* [[ARRAYIDX]], align 1
; SLM-NEXT:    [[CONV:%.*]] = sext i16 [[TMP54]] to i32
; SLM-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds i16, i16* [[DATAB]], i64 [[INDVARS_IV]]
; SLM-NEXT:    [[TMP55:%.*]] = load i16, i16* [[ARRAYIDX2]], align 1
; SLM-NEXT:    [[CONV3:%.*]] = sext i16 [[TMP55]] to i32
; SLM-NEXT:    [[MUL:%.*]] = mul nsw i32 [[CONV3]], [[CONV]]
; SLM-NEXT:    [[CONV4:%.*]] = zext i16 [[TMP55]] to i32
; SLM-NEXT:    [[MUL2:%.*]] = mul nsw i32 [[CONV4]], [[CONV]]
; SLM-NEXT:    [[SUM0:%.*]] = add i32 [[MUL]], [[MUL2]]
; SLM-NEXT:    [[CONV5:%.*]] = zext i16 [[TMP54]] to i32
; SLM-NEXT:    [[MUL3:%.*]] = mul nsw i32 [[CONV5]], [[CONV4]]
; SLM-NEXT:    [[SUM1:%.*]] = add i32 [[SUM0]], [[MUL3]]
; SLM-NEXT:    [[MUL4:%.*]] = mul nsw i32 -32000, [[CONV3]]
; SLM-NEXT:    [[SUM2:%.*]] = add i32 [[SUM1]], [[MUL4]]
; SLM-NEXT:    [[MUL5:%.*]] = mul nsw i32 64000, [[CONV3]]
; SLM-NEXT:    [[SUM3:%.*]] = add i32 [[SUM2]], [[MUL5]]
; SLM-NEXT:    [[MUL6:%.*]] = mul nsw i32 -32000, [[CONV4]]
; SLM-NEXT:    [[SUM4:%.*]] = add i32 [[SUM3]], [[MUL6]]
; SLM-NEXT:    [[MUL7:%.*]] = mul nsw i32 250, [[CONV4]]
; SLM-NEXT:    [[SUM5:%.*]] = add i32 [[SUM4]], [[MUL7]]
; SLM-NEXT:    [[ADD:%.*]] = add i32 [[ACC_013]], 5
; SLM-NEXT:    [[ADD4]] = add i32 [[ADD]], [[SUM5]]
; SLM-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; SLM-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[WIDE_TRIP_COUNT]]
; SLM-NEXT:    br i1 [[EXITCOND]], label [[FOR_COND_CLEANUP_LOOPEXIT]], label [[FOR_BODY]], !llvm.loop [[LOOP5:![0-9]+]]
;
entry:
  %cmp12 = icmp eq i32 %N, 0
  br i1 %cmp12, label %for.cond.cleanup, label %for.body.preheader

for.body.preheader:                               ; preds = %entry
  %wide.trip.count = zext i32 %N to i64
  br label %for.body

for.cond.cleanup.loopexit:                        ; preds = %for.body
  %phitmp = trunc i32 %add4 to i16
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit, %entry
  %acc.0.lcssa = phi i16 [ 0, %entry ], [ %phitmp, %for.cond.cleanup.loopexit ]
  ret i16 %acc.0.lcssa

for.body:                                         ; preds = %for.body.preheader, %for.body
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 0, %for.body.preheader ]
  %acc.013 = phi i32 [ %add4, %for.body ], [ 0, %for.body.preheader ]
  %arrayidx = getelementptr inbounds i16, i16* %dataA, i64 %indvars.iv
  %0 = load i16, i16* %arrayidx, align 1
  %conv = sext i16 %0 to i32
  %arrayidx2 = getelementptr inbounds i16, i16* %dataB, i64 %indvars.iv
  %1 = load i16, i16* %arrayidx2, align 1
  %conv3 = sext i16 %1 to i32
; sources of the mul is sext\sext from i16
; use pmulhw\pmullw\pshuf seq.
  %mul = mul nsw i32 %conv3, %conv
; sources of the mul is zext\sext from i16
; use pmulld
  %conv4 = zext i16 %1 to i32
  %mul2 = mul nsw i32 %conv4, %conv
  %sum0 = add i32 %mul, %mul2
; sources of the mul is zext\zext from i16
; use pmulhw\pmullw\zext
  %conv5 = zext i16 %0 to i32
  %mul3 = mul nsw i32 %conv5, %conv4
  %sum1 = add i32 %sum0, %mul3
; sources of the mul is sext\-32000
; use pmulhw\pmullw\sext
  %mul4 = mul nsw i32 -32000, %conv3
  %sum2 = add i32 %sum1, %mul4
; sources of the mul is sext\64000
; use pmulld
  %mul5 = mul nsw i32 64000, %conv3
  %sum3 = add i32 %sum2, %mul5
; sources of the mul is zext\-32000
; use pmulld
  %mul6 = mul nsw i32 -32000, %conv4
  %sum4 = add i32 %sum3, %mul6
; sources of the mul is zext\64000
; use pmulhw\pmullw\zext
  %mul7 = mul nsw i32 250, %conv4
  %sum5 = add i32 %sum4, %mul7
  %add = add i32 %acc.013, 5
  %add4 = add i32 %add, %sum5
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond, label %for.cond.cleanup.loopexit, label %for.body
}


