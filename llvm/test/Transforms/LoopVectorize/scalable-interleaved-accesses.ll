; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-globals none --version 5
; RUN: opt -S -passes=loop-vectorize,instcombine -force-vector-width=1 -force-vector-interleave=1 -enable-interleaved-mem-accesses=true -scalable-vectorization=on -force-target-instruction-cost=1 -force-target-supports-scalable-vectors -max-interleave-group-factor=16 < %s | FileCheck %s

define void @factor8(ptr noalias %p, ptr noalias %q) {
; CHECK-LABEL: define void @factor8(
; CHECK-SAME: ptr noalias [[P:%.*]], ptr noalias [[Q:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    [[TMP36:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ugt i32 [[TMP36]], 1024
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[TMP38:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i32 1024, [[TMP38]]
; CHECK-NEXT:    [[N_VEC:%.*]] = sub nuw nsw i32 1024, [[N_MOD_VF]]
; CHECK-NEXT:    [[TMP40:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i32 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = sext i32 [[INDEX]] to i64
; CHECK-NEXT:    [[GEPP0:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP0]], i64 0
; CHECK-NEXT:    [[WIDE_VEC:%.*]] = load <vscale x 8 x i32>, ptr [[GEPP0]], align 4
; CHECK-NEXT:    [[STRIDED_VEC:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave8.nxv8i32(<vscale x 8 x i32> [[WIDE_VEC]])
; CHECK-NEXT:    [[TMP31:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC]], 0
; CHECK-NEXT:    [[TMP32:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC]], 1
; CHECK-NEXT:    [[TMP33:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC]], 2
; CHECK-NEXT:    [[TMP37:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC]], 3
; CHECK-NEXT:    [[TMP39:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC]], 4
; CHECK-NEXT:    [[TMP41:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC]], 5
; CHECK-NEXT:    [[TMP42:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC]], 6
; CHECK-NEXT:    [[TMP43:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC]], 7
; CHECK-NEXT:    [[TMP16:%.*]] = sext i32 [[INDEX]] to i64
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP16]], i64 0
; CHECK-NEXT:    [[WIDE_VEC1:%.*]] = load <vscale x 8 x i32>, ptr [[TMP17]], align 4
; CHECK-NEXT:    [[STRIDED_VEC2:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave8.nxv8i32(<vscale x 8 x i32> [[WIDE_VEC1]])
; CHECK-NEXT:    [[TMP44:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC2]], 0
; CHECK-NEXT:    [[TMP45:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC2]], 1
; CHECK-NEXT:    [[TMP46:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC2]], 2
; CHECK-NEXT:    [[TMP18:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC2]], 3
; CHECK-NEXT:    [[TMP19:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC2]], 4
; CHECK-NEXT:    [[TMP20:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC2]], 5
; CHECK-NEXT:    [[TMP21:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC2]], 6
; CHECK-NEXT:    [[TMP22:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC2]], 7
; CHECK-NEXT:    [[TMP23:%.*]] = add <vscale x 1 x i32> [[TMP31]], [[TMP44]]
; CHECK-NEXT:    [[TMP24:%.*]] = add <vscale x 1 x i32> [[TMP32]], [[TMP45]]
; CHECK-NEXT:    [[TMP25:%.*]] = add <vscale x 1 x i32> [[TMP33]], [[TMP46]]
; CHECK-NEXT:    [[TMP26:%.*]] = add <vscale x 1 x i32> [[TMP37]], [[TMP18]]
; CHECK-NEXT:    [[TMP27:%.*]] = add <vscale x 1 x i32> [[TMP39]], [[TMP19]]
; CHECK-NEXT:    [[TMP28:%.*]] = add <vscale x 1 x i32> [[TMP41]], [[TMP20]]
; CHECK-NEXT:    [[TMP29:%.*]] = add <vscale x 1 x i32> [[TMP42]], [[TMP21]]
; CHECK-NEXT:    [[TMP30:%.*]] = add <vscale x 1 x i32> [[TMP43]], [[TMP22]]
; CHECK-NEXT:    [[INTERLEAVED_VEC:%.*]] = call <vscale x 8 x i32> @llvm.vector.interleave8.nxv8i32(<vscale x 1 x i32> [[TMP23]], <vscale x 1 x i32> [[TMP24]], <vscale x 1 x i32> [[TMP25]], <vscale x 1 x i32> [[TMP26]], <vscale x 1 x i32> [[TMP27]], <vscale x 1 x i32> [[TMP28]], <vscale x 1 x i32> [[TMP29]], <vscale x 1 x i32> [[TMP30]])
; CHECK-NEXT:    store <vscale x 8 x i32> [[INTERLEAVED_VEC]], ptr [[GEPP0]], align 4
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i32 [[INDEX]], [[TMP40]]
; CHECK-NEXT:    [[TMP34:%.*]] = icmp eq i32 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP34]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i32 [[N_MOD_VF]], 0
; CHECK-NEXT:    br i1 [[CMP_N]], label %[[EXIT:.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i32 [ [[N_VEC]], %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ]
; CHECK-NEXT:    br label %[[LOOP:.*]]
; CHECK:       [[LOOP]]:
; CHECK-NEXT:    [[IV:%.*]] = phi i32 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP]] ]
; CHECK-NEXT:    [[TMP35:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP8:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP35]], i64 0
; CHECK-NEXT:    [[P0:%.*]] = load i32, ptr [[GEPP8]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ0:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP1]], i64 0
; CHECK-NEXT:    [[Q0:%.*]] = load i32, ptr [[GEPQ0]], align 4
; CHECK-NEXT:    [[Z0:%.*]] = add i32 [[P0]], [[Q0]]
; CHECK-NEXT:    store i32 [[Z0]], ptr [[GEPP8]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP1:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP2]], i64 1
; CHECK-NEXT:    [[P1:%.*]] = load i32, ptr [[GEPP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ1:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP3]], i64 1
; CHECK-NEXT:    [[Q1:%.*]] = load i32, ptr [[GEPQ1]], align 4
; CHECK-NEXT:    [[Z1:%.*]] = add i32 [[P1]], [[Q1]]
; CHECK-NEXT:    store i32 [[Z1]], ptr [[GEPP1]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP2:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP4]], i64 2
; CHECK-NEXT:    [[P2:%.*]] = load i32, ptr [[GEPP2]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ2:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP5]], i64 2
; CHECK-NEXT:    [[Q2:%.*]] = load i32, ptr [[GEPQ2]], align 4
; CHECK-NEXT:    [[Z2:%.*]] = add i32 [[P2]], [[Q2]]
; CHECK-NEXT:    store i32 [[Z2]], ptr [[GEPP2]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP3:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP6]], i64 3
; CHECK-NEXT:    [[P3:%.*]] = load i32, ptr [[GEPP3]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ3:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP7]], i64 3
; CHECK-NEXT:    [[Q3:%.*]] = load i32, ptr [[GEPQ3]], align 4
; CHECK-NEXT:    [[Z3:%.*]] = add i32 [[P3]], [[Q3]]
; CHECK-NEXT:    store i32 [[Z3]], ptr [[GEPP3]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP4:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP8]], i64 4
; CHECK-NEXT:    [[P4:%.*]] = load i32, ptr [[GEPP4]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ4:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP9]], i64 4
; CHECK-NEXT:    [[Q4:%.*]] = load i32, ptr [[GEPQ4]], align 4
; CHECK-NEXT:    [[Z4:%.*]] = add i32 [[P4]], [[Q4]]
; CHECK-NEXT:    store i32 [[Z4]], ptr [[GEPP4]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP5:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP10]], i64 5
; CHECK-NEXT:    [[P5:%.*]] = load i32, ptr [[GEPP5]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ5:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP11]], i64 5
; CHECK-NEXT:    [[Q5:%.*]] = load i32, ptr [[GEPQ5]], align 4
; CHECK-NEXT:    [[Z5:%.*]] = add i32 [[P5]], [[Q5]]
; CHECK-NEXT:    store i32 [[Z5]], ptr [[GEPP5]], align 4
; CHECK-NEXT:    [[TMP12:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP6:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP12]], i64 6
; CHECK-NEXT:    [[P6:%.*]] = load i32, ptr [[GEPP6]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ6:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP13]], i64 6
; CHECK-NEXT:    [[Q6:%.*]] = load i32, ptr [[GEPQ6]], align 4
; CHECK-NEXT:    [[Z6:%.*]] = add i32 [[P6]], [[Q6]]
; CHECK-NEXT:    store i32 [[Z6]], ptr [[GEPP6]], align 4
; CHECK-NEXT:    [[TMP14:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP7:%.*]] = getelementptr [8 x i32], ptr [[P]], i64 [[TMP14]], i64 7
; CHECK-NEXT:    [[P15:%.*]] = load i32, ptr [[GEPP7]], align 4
; CHECK-NEXT:    [[TMP15:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ7:%.*]] = getelementptr [8 x i32], ptr [[Q]], i64 [[TMP15]], i64 7
; CHECK-NEXT:    [[Q15:%.*]] = load i32, ptr [[GEPQ7]], align 4
; CHECK-NEXT:    [[Z15:%.*]] = add i32 [[P15]], [[Q15]]
; CHECK-NEXT:    store i32 [[Z15]], ptr [[GEPP7]], align 4
; CHECK-NEXT:    [[IV_NEXT]] = add i32 [[IV]], 1
; CHECK-NEXT:    [[DONE:%.*]] = icmp eq i32 [[IV_NEXT]], 1024
; CHECK-NEXT:    br i1 [[DONE]], label %[[EXIT]], label %[[LOOP]], !llvm.loop [[LOOP3:![0-9]+]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %iv = phi i32 [ 0, %entry ], [ %iv.next, %loop ]

  %gepp0 = getelementptr [8 x i32], ptr %p, i32 %iv, i32 0
  %p0 = load i32, ptr %gepp0
  %gepq0 = getelementptr [8 x i32], ptr %q, i32 %iv, i32 0
  %q0 = load i32, ptr %gepq0
  %z0 = add i32 %p0, %q0
  store i32 %z0, ptr %gepp0

  %gepp1 = getelementptr [8 x i32], ptr %p, i32 %iv, i32 1
  %p1 = load i32, ptr %gepp1
  %gepq1 = getelementptr [8 x i32], ptr %q, i32 %iv, i32 1
  %q1 = load i32, ptr %gepq1
  %z1 = add i32 %p1, %q1
  store i32 %z1, ptr %gepp1

  %gepp2 = getelementptr [8 x i32], ptr %p, i32 %iv, i32 2
  %p2 = load i32, ptr %gepp2
  %gepq2 = getelementptr [8 x i32], ptr %q, i32 %iv, i32 2
  %q2 = load i32, ptr %gepq2
  %z2 = add i32 %p2, %q2
  store i32 %z2, ptr %gepp2

  %gepp3 = getelementptr [8 x i32], ptr %p, i32 %iv, i32 3
  %p3 = load i32, ptr %gepp3
  %gepq3 = getelementptr [8 x i32], ptr %q, i32 %iv, i32 3
  %q3 = load i32, ptr %gepq3
  %z3 = add i32 %p3, %q3
  store i32 %z3, ptr %gepp3

  %gepp4 = getelementptr [8 x i32], ptr %p, i32 %iv, i32 4
  %p4 = load i32, ptr %gepp4
  %gepq4 = getelementptr [8 x i32], ptr %q, i32 %iv, i32 4
  %q4 = load i32, ptr %gepq4
  %z4 = add i32 %p4, %q4
  store i32 %z4, ptr %gepp4

  %gepp5 = getelementptr [8 x i32], ptr %p, i32 %iv, i32 5
  %p5 = load i32, ptr %gepp5
  %gepq5 = getelementptr [8 x i32], ptr %q, i32 %iv, i32 5
  %q5 = load i32, ptr %gepq5
  %z5 = add i32 %p5, %q5
  store i32 %z5, ptr %gepp5

  %gepp6 = getelementptr [8 x i32], ptr %p, i32 %iv, i32 6
  %p6 = load i32, ptr %gepp6
  %gepq6 = getelementptr [8 x i32], ptr %q, i32 %iv, i32 6
  %q6 = load i32, ptr %gepq6
  %z6 = add i32 %p6, %q6
  store i32 %z6, ptr %gepp6

  %gepp7 = getelementptr [8 x i32], ptr %p, i32 %iv, i32 7
  %p7 = load i32, ptr %gepp7
  %gepq7 = getelementptr [8 x i32], ptr %q, i32 %iv, i32 7
  %q7 = load i32, ptr %gepq7
  %z7 = add i32 %p7, %q7
  store i32 %z7, ptr %gepp7

  %iv.next = add i32 %iv, 1
  %done = icmp eq i32 %iv.next, 1024
  br i1 %done, label %exit, label %loop

exit:
  ret void
}

define void @factor16(ptr noalias %p, ptr noalias %q) {
; CHECK-LABEL: define void @factor16(
; CHECK-SAME: ptr noalias [[P:%.*]], ptr noalias [[Q:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    [[TMP35:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ugt i32 [[TMP35]], 1024
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[TMP36:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i32 1024, [[TMP36]]
; CHECK-NEXT:    [[N_VEC:%.*]] = sub nuw nsw i32 1024, [[N_MOD_VF]]
; CHECK-NEXT:    [[TMP86:%.*]] = call i32 @llvm.vscale.i32()
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i32 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = sext i32 [[INDEX]] to i64
; CHECK-NEXT:    [[GEPP0:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP0]], i64 0
; CHECK-NEXT:    [[WIDE_VEC:%.*]] = load <vscale x 16 x i32>, ptr [[GEPP0]], align 4
; CHECK-NEXT:    [[STRIDED_VEC:%.*]] = call { <vscale x 8 x i32>, <vscale x 8 x i32> } @llvm.vector.deinterleave2.nxv16i32(<vscale x 16 x i32> [[WIDE_VEC]])
; CHECK-NEXT:    [[TMP87:%.*]] = extractvalue { <vscale x 8 x i32>, <vscale x 8 x i32> } [[STRIDED_VEC]], 0
; CHECK-NEXT:    [[TMP88:%.*]] = extractvalue { <vscale x 8 x i32>, <vscale x 8 x i32> } [[STRIDED_VEC]], 1
; CHECK-NEXT:    [[STRIDED_VEC1:%.*]] = call { <vscale x 4 x i32>, <vscale x 4 x i32> } @llvm.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> [[TMP87]])
; CHECK-NEXT:    [[STRIDED_VEC2:%.*]] = call { <vscale x 4 x i32>, <vscale x 4 x i32> } @llvm.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> [[TMP88]])
; CHECK-NEXT:    [[TMP89:%.*]] = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } [[STRIDED_VEC1]], 0
; CHECK-NEXT:    [[TMP90:%.*]] = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } [[STRIDED_VEC2]], 0
; CHECK-NEXT:    [[TMP91:%.*]] = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } [[STRIDED_VEC1]], 1
; CHECK-NEXT:    [[TMP92:%.*]] = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } [[STRIDED_VEC2]], 1
; CHECK-NEXT:    [[STRIDED_VEC3:%.*]] = call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.vector.deinterleave2.nxv4i32(<vscale x 4 x i32> [[TMP89]])
; CHECK-NEXT:    [[STRIDED_VEC4:%.*]] = call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.vector.deinterleave2.nxv4i32(<vscale x 4 x i32> [[TMP90]])
; CHECK-NEXT:    [[STRIDED_VEC5:%.*]] = call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.vector.deinterleave2.nxv4i32(<vscale x 4 x i32> [[TMP91]])
; CHECK-NEXT:    [[STRIDED_VEC6:%.*]] = call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.vector.deinterleave2.nxv4i32(<vscale x 4 x i32> [[TMP92]])
; CHECK-NEXT:    [[TMP93:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC3]], 0
; CHECK-NEXT:    [[TMP94:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC4]], 0
; CHECK-NEXT:    [[TMP95:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC5]], 0
; CHECK-NEXT:    [[TMP96:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC6]], 0
; CHECK-NEXT:    [[TMP97:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC3]], 1
; CHECK-NEXT:    [[TMP98:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC4]], 1
; CHECK-NEXT:    [[TMP99:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC5]], 1
; CHECK-NEXT:    [[TMP100:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC6]], 1
; CHECK-NEXT:    [[STRIDED_VEC7:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP93]])
; CHECK-NEXT:    [[STRIDED_VEC8:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP94]])
; CHECK-NEXT:    [[STRIDED_VEC9:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP95]])
; CHECK-NEXT:    [[STRIDED_VEC10:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP96]])
; CHECK-NEXT:    [[STRIDED_VEC11:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP97]])
; CHECK-NEXT:    [[STRIDED_VEC12:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP98]])
; CHECK-NEXT:    [[STRIDED_VEC13:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP99]])
; CHECK-NEXT:    [[STRIDED_VEC14:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP100]])
; CHECK-NEXT:    [[TMP101:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC7]], 0
; CHECK-NEXT:    [[TMP102:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC8]], 0
; CHECK-NEXT:    [[TMP103:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC9]], 0
; CHECK-NEXT:    [[TMP104:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC10]], 0
; CHECK-NEXT:    [[TMP105:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC11]], 0
; CHECK-NEXT:    [[TMP106:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC12]], 0
; CHECK-NEXT:    [[TMP107:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC13]], 0
; CHECK-NEXT:    [[TMP108:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC14]], 0
; CHECK-NEXT:    [[TMP109:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC7]], 1
; CHECK-NEXT:    [[TMP110:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC8]], 1
; CHECK-NEXT:    [[TMP111:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC9]], 1
; CHECK-NEXT:    [[TMP112:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC10]], 1
; CHECK-NEXT:    [[TMP113:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC11]], 1
; CHECK-NEXT:    [[TMP32:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC12]], 1
; CHECK-NEXT:    [[TMP33:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC13]], 1
; CHECK-NEXT:    [[TMP34:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC14]], 1
; CHECK-NEXT:    [[TMP1:%.*]] = sext i32 [[INDEX]] to i64
; CHECK-NEXT:    [[GEPQ0:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP1]], i64 0
; CHECK-NEXT:    [[WIDE_VEC15:%.*]] = load <vscale x 16 x i32>, ptr [[GEPQ0]], align 4
; CHECK-NEXT:    [[STRIDED_VEC16:%.*]] = call { <vscale x 8 x i32>, <vscale x 8 x i32> } @llvm.vector.deinterleave2.nxv16i32(<vscale x 16 x i32> [[WIDE_VEC15]])
; CHECK-NEXT:    [[TMP37:%.*]] = extractvalue { <vscale x 8 x i32>, <vscale x 8 x i32> } [[STRIDED_VEC16]], 0
; CHECK-NEXT:    [[TMP38:%.*]] = extractvalue { <vscale x 8 x i32>, <vscale x 8 x i32> } [[STRIDED_VEC16]], 1
; CHECK-NEXT:    [[STRIDED_VEC17:%.*]] = call { <vscale x 4 x i32>, <vscale x 4 x i32> } @llvm.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> [[TMP37]])
; CHECK-NEXT:    [[STRIDED_VEC18:%.*]] = call { <vscale x 4 x i32>, <vscale x 4 x i32> } @llvm.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> [[TMP38]])
; CHECK-NEXT:    [[TMP39:%.*]] = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } [[STRIDED_VEC17]], 0
; CHECK-NEXT:    [[TMP40:%.*]] = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } [[STRIDED_VEC18]], 0
; CHECK-NEXT:    [[TMP41:%.*]] = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } [[STRIDED_VEC17]], 1
; CHECK-NEXT:    [[TMP42:%.*]] = extractvalue { <vscale x 4 x i32>, <vscale x 4 x i32> } [[STRIDED_VEC18]], 1
; CHECK-NEXT:    [[STRIDED_VEC19:%.*]] = call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.vector.deinterleave2.nxv4i32(<vscale x 4 x i32> [[TMP39]])
; CHECK-NEXT:    [[STRIDED_VEC20:%.*]] = call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.vector.deinterleave2.nxv4i32(<vscale x 4 x i32> [[TMP40]])
; CHECK-NEXT:    [[STRIDED_VEC21:%.*]] = call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.vector.deinterleave2.nxv4i32(<vscale x 4 x i32> [[TMP41]])
; CHECK-NEXT:    [[STRIDED_VEC22:%.*]] = call { <vscale x 2 x i32>, <vscale x 2 x i32> } @llvm.vector.deinterleave2.nxv4i32(<vscale x 4 x i32> [[TMP42]])
; CHECK-NEXT:    [[TMP43:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC19]], 0
; CHECK-NEXT:    [[TMP44:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC20]], 0
; CHECK-NEXT:    [[TMP45:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC21]], 0
; CHECK-NEXT:    [[TMP46:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC22]], 0
; CHECK-NEXT:    [[TMP47:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC19]], 1
; CHECK-NEXT:    [[TMP48:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC20]], 1
; CHECK-NEXT:    [[TMP49:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC21]], 1
; CHECK-NEXT:    [[TMP50:%.*]] = extractvalue { <vscale x 2 x i32>, <vscale x 2 x i32> } [[STRIDED_VEC22]], 1
; CHECK-NEXT:    [[STRIDED_VEC23:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP43]])
; CHECK-NEXT:    [[STRIDED_VEC24:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP44]])
; CHECK-NEXT:    [[STRIDED_VEC25:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP45]])
; CHECK-NEXT:    [[STRIDED_VEC26:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP46]])
; CHECK-NEXT:    [[STRIDED_VEC27:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP47]])
; CHECK-NEXT:    [[STRIDED_VEC28:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP48]])
; CHECK-NEXT:    [[STRIDED_VEC29:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP49]])
; CHECK-NEXT:    [[STRIDED_VEC30:%.*]] = call { <vscale x 1 x i32>, <vscale x 1 x i32> } @llvm.vector.deinterleave2.nxv2i32(<vscale x 2 x i32> [[TMP50]])
; CHECK-NEXT:    [[TMP51:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC23]], 0
; CHECK-NEXT:    [[TMP52:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC24]], 0
; CHECK-NEXT:    [[TMP53:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC25]], 0
; CHECK-NEXT:    [[TMP54:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC26]], 0
; CHECK-NEXT:    [[TMP55:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC27]], 0
; CHECK-NEXT:    [[TMP56:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC28]], 0
; CHECK-NEXT:    [[TMP57:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC29]], 0
; CHECK-NEXT:    [[TMP58:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC30]], 0
; CHECK-NEXT:    [[TMP59:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC23]], 1
; CHECK-NEXT:    [[TMP60:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC24]], 1
; CHECK-NEXT:    [[TMP61:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC25]], 1
; CHECK-NEXT:    [[TMP62:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC26]], 1
; CHECK-NEXT:    [[TMP63:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC27]], 1
; CHECK-NEXT:    [[TMP64:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC28]], 1
; CHECK-NEXT:    [[TMP65:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC29]], 1
; CHECK-NEXT:    [[TMP66:%.*]] = extractvalue { <vscale x 1 x i32>, <vscale x 1 x i32> } [[STRIDED_VEC30]], 1
; CHECK-NEXT:    [[TMP67:%.*]] = add <vscale x 1 x i32> [[TMP101]], [[TMP51]]
; CHECK-NEXT:    [[TMP68:%.*]] = add <vscale x 1 x i32> [[TMP102]], [[TMP52]]
; CHECK-NEXT:    [[TMP69:%.*]] = add <vscale x 1 x i32> [[TMP103]], [[TMP53]]
; CHECK-NEXT:    [[TMP70:%.*]] = add <vscale x 1 x i32> [[TMP104]], [[TMP54]]
; CHECK-NEXT:    [[TMP71:%.*]] = add <vscale x 1 x i32> [[TMP105]], [[TMP55]]
; CHECK-NEXT:    [[TMP72:%.*]] = add <vscale x 1 x i32> [[TMP106]], [[TMP56]]
; CHECK-NEXT:    [[TMP73:%.*]] = add <vscale x 1 x i32> [[TMP107]], [[TMP57]]
; CHECK-NEXT:    [[TMP74:%.*]] = add <vscale x 1 x i32> [[TMP108]], [[TMP58]]
; CHECK-NEXT:    [[TMP75:%.*]] = add <vscale x 1 x i32> [[TMP109]], [[TMP59]]
; CHECK-NEXT:    [[TMP76:%.*]] = add <vscale x 1 x i32> [[TMP110]], [[TMP60]]
; CHECK-NEXT:    [[TMP77:%.*]] = add <vscale x 1 x i32> [[TMP111]], [[TMP61]]
; CHECK-NEXT:    [[TMP78:%.*]] = add <vscale x 1 x i32> [[TMP112]], [[TMP62]]
; CHECK-NEXT:    [[TMP79:%.*]] = add <vscale x 1 x i32> [[TMP113]], [[TMP63]]
; CHECK-NEXT:    [[TMP80:%.*]] = add <vscale x 1 x i32> [[TMP32]], [[TMP64]]
; CHECK-NEXT:    [[TMP81:%.*]] = add <vscale x 1 x i32> [[TMP33]], [[TMP65]]
; CHECK-NEXT:    [[TMP82:%.*]] = add <vscale x 1 x i32> [[TMP34]], [[TMP66]]
; CHECK-NEXT:    [[INTERLEAVED_VEC:%.*]] = call <vscale x 2 x i32> @llvm.vector.interleave2.nxv2i32(<vscale x 1 x i32> [[TMP67]], <vscale x 1 x i32> [[TMP75]])
; CHECK-NEXT:    [[INTERLEAVED_VEC31:%.*]] = call <vscale x 2 x i32> @llvm.vector.interleave2.nxv2i32(<vscale x 1 x i32> [[TMP68]], <vscale x 1 x i32> [[TMP76]])
; CHECK-NEXT:    [[INTERLEAVED_VEC32:%.*]] = call <vscale x 2 x i32> @llvm.vector.interleave2.nxv2i32(<vscale x 1 x i32> [[TMP69]], <vscale x 1 x i32> [[TMP77]])
; CHECK-NEXT:    [[INTERLEAVED_VEC33:%.*]] = call <vscale x 2 x i32> @llvm.vector.interleave2.nxv2i32(<vscale x 1 x i32> [[TMP70]], <vscale x 1 x i32> [[TMP78]])
; CHECK-NEXT:    [[INTERLEAVED_VEC34:%.*]] = call <vscale x 2 x i32> @llvm.vector.interleave2.nxv2i32(<vscale x 1 x i32> [[TMP71]], <vscale x 1 x i32> [[TMP79]])
; CHECK-NEXT:    [[INTERLEAVED_VEC35:%.*]] = call <vscale x 2 x i32> @llvm.vector.interleave2.nxv2i32(<vscale x 1 x i32> [[TMP72]], <vscale x 1 x i32> [[TMP80]])
; CHECK-NEXT:    [[INTERLEAVED_VEC36:%.*]] = call <vscale x 2 x i32> @llvm.vector.interleave2.nxv2i32(<vscale x 1 x i32> [[TMP73]], <vscale x 1 x i32> [[TMP81]])
; CHECK-NEXT:    [[INTERLEAVED_VEC37:%.*]] = call <vscale x 2 x i32> @llvm.vector.interleave2.nxv2i32(<vscale x 1 x i32> [[TMP74]], <vscale x 1 x i32> [[TMP82]])
; CHECK-NEXT:    [[INTERLEAVED_VEC38:%.*]] = call <vscale x 4 x i32> @llvm.vector.interleave2.nxv4i32(<vscale x 2 x i32> [[INTERLEAVED_VEC]], <vscale x 2 x i32> [[INTERLEAVED_VEC34]])
; CHECK-NEXT:    [[INTERLEAVED_VEC39:%.*]] = call <vscale x 4 x i32> @llvm.vector.interleave2.nxv4i32(<vscale x 2 x i32> [[INTERLEAVED_VEC31]], <vscale x 2 x i32> [[INTERLEAVED_VEC35]])
; CHECK-NEXT:    [[INTERLEAVED_VEC40:%.*]] = call <vscale x 4 x i32> @llvm.vector.interleave2.nxv4i32(<vscale x 2 x i32> [[INTERLEAVED_VEC32]], <vscale x 2 x i32> [[INTERLEAVED_VEC36]])
; CHECK-NEXT:    [[INTERLEAVED_VEC41:%.*]] = call <vscale x 4 x i32> @llvm.vector.interleave2.nxv4i32(<vscale x 2 x i32> [[INTERLEAVED_VEC33]], <vscale x 2 x i32> [[INTERLEAVED_VEC37]])
; CHECK-NEXT:    [[INTERLEAVED_VEC42:%.*]] = call <vscale x 8 x i32> @llvm.vector.interleave2.nxv8i32(<vscale x 4 x i32> [[INTERLEAVED_VEC38]], <vscale x 4 x i32> [[INTERLEAVED_VEC40]])
; CHECK-NEXT:    [[INTERLEAVED_VEC43:%.*]] = call <vscale x 8 x i32> @llvm.vector.interleave2.nxv8i32(<vscale x 4 x i32> [[INTERLEAVED_VEC39]], <vscale x 4 x i32> [[INTERLEAVED_VEC41]])
; CHECK-NEXT:    [[INTERLEAVED_VEC44:%.*]] = call <vscale x 16 x i32> @llvm.vector.interleave2.nxv16i32(<vscale x 8 x i32> [[INTERLEAVED_VEC42]], <vscale x 8 x i32> [[INTERLEAVED_VEC43]])
; CHECK-NEXT:    store <vscale x 16 x i32> [[INTERLEAVED_VEC44]], ptr [[GEPP0]], align 4
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i32 [[INDEX]], [[TMP86]]
; CHECK-NEXT:    [[TMP83:%.*]] = icmp eq i32 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP83]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i32 [[N_MOD_VF]], 0
; CHECK-NEXT:    br i1 [[CMP_N]], label %[[EXIT:.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i32 [ [[N_VEC]], %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ]
; CHECK-NEXT:    br label %[[LOOP:.*]]
; CHECK:       [[LOOP]]:
; CHECK-NEXT:    [[IV:%.*]] = phi i32 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP]] ]
; CHECK-NEXT:    [[TMP84:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP16:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP84]], i64 0
; CHECK-NEXT:    [[P0:%.*]] = load i32, ptr [[GEPP16]], align 4
; CHECK-NEXT:    [[TMP85:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ16:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP85]], i64 0
; CHECK-NEXT:    [[Q0:%.*]] = load i32, ptr [[GEPQ16]], align 4
; CHECK-NEXT:    [[Z0:%.*]] = add i32 [[P0]], [[Q0]]
; CHECK-NEXT:    store i32 [[Z0]], ptr [[GEPP16]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP1:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP2]], i64 1
; CHECK-NEXT:    [[P1:%.*]] = load i32, ptr [[GEPP1]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ1:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP3]], i64 1
; CHECK-NEXT:    [[Q1:%.*]] = load i32, ptr [[GEPQ1]], align 4
; CHECK-NEXT:    [[Z1:%.*]] = add i32 [[P1]], [[Q1]]
; CHECK-NEXT:    store i32 [[Z1]], ptr [[GEPP1]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP2:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP4]], i64 2
; CHECK-NEXT:    [[P2:%.*]] = load i32, ptr [[GEPP2]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ2:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP5]], i64 2
; CHECK-NEXT:    [[Q2:%.*]] = load i32, ptr [[GEPQ2]], align 4
; CHECK-NEXT:    [[Z2:%.*]] = add i32 [[P2]], [[Q2]]
; CHECK-NEXT:    store i32 [[Z2]], ptr [[GEPP2]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP3:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP6]], i64 3
; CHECK-NEXT:    [[P3:%.*]] = load i32, ptr [[GEPP3]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ3:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP7]], i64 3
; CHECK-NEXT:    [[Q3:%.*]] = load i32, ptr [[GEPQ3]], align 4
; CHECK-NEXT:    [[Z3:%.*]] = add i32 [[P3]], [[Q3]]
; CHECK-NEXT:    store i32 [[Z3]], ptr [[GEPP3]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP4:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP8]], i64 4
; CHECK-NEXT:    [[P4:%.*]] = load i32, ptr [[GEPP4]], align 4
; CHECK-NEXT:    [[TMP9:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ4:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP9]], i64 4
; CHECK-NEXT:    [[Q4:%.*]] = load i32, ptr [[GEPQ4]], align 4
; CHECK-NEXT:    [[Z4:%.*]] = add i32 [[P4]], [[Q4]]
; CHECK-NEXT:    store i32 [[Z4]], ptr [[GEPP4]], align 4
; CHECK-NEXT:    [[TMP10:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP5:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP10]], i64 5
; CHECK-NEXT:    [[P5:%.*]] = load i32, ptr [[GEPP5]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ5:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP11]], i64 5
; CHECK-NEXT:    [[Q5:%.*]] = load i32, ptr [[GEPQ5]], align 4
; CHECK-NEXT:    [[Z5:%.*]] = add i32 [[P5]], [[Q5]]
; CHECK-NEXT:    store i32 [[Z5]], ptr [[GEPP5]], align 4
; CHECK-NEXT:    [[TMP12:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP6:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP12]], i64 6
; CHECK-NEXT:    [[P6:%.*]] = load i32, ptr [[GEPP6]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ6:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP13]], i64 6
; CHECK-NEXT:    [[Q6:%.*]] = load i32, ptr [[GEPQ6]], align 4
; CHECK-NEXT:    [[Z6:%.*]] = add i32 [[P6]], [[Q6]]
; CHECK-NEXT:    store i32 [[Z6]], ptr [[GEPP6]], align 4
; CHECK-NEXT:    [[TMP14:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP7:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP14]], i64 7
; CHECK-NEXT:    [[P7:%.*]] = load i32, ptr [[GEPP7]], align 4
; CHECK-NEXT:    [[TMP15:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ7:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP15]], i64 7
; CHECK-NEXT:    [[Q7:%.*]] = load i32, ptr [[GEPQ7]], align 4
; CHECK-NEXT:    [[Z7:%.*]] = add i32 [[P7]], [[Q7]]
; CHECK-NEXT:    store i32 [[Z7]], ptr [[GEPP7]], align 4
; CHECK-NEXT:    [[TMP16:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP8:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP16]], i64 8
; CHECK-NEXT:    [[P8:%.*]] = load i32, ptr [[GEPP8]], align 4
; CHECK-NEXT:    [[TMP17:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ8:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP17]], i64 8
; CHECK-NEXT:    [[Q8:%.*]] = load i32, ptr [[GEPQ8]], align 4
; CHECK-NEXT:    [[Z8:%.*]] = add i32 [[P8]], [[Q8]]
; CHECK-NEXT:    store i32 [[Z8]], ptr [[GEPP8]], align 4
; CHECK-NEXT:    [[TMP18:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP9:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP18]], i64 9
; CHECK-NEXT:    [[P9:%.*]] = load i32, ptr [[GEPP9]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ9:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP19]], i64 9
; CHECK-NEXT:    [[Q9:%.*]] = load i32, ptr [[GEPQ9]], align 4
; CHECK-NEXT:    [[Z9:%.*]] = add i32 [[P9]], [[Q9]]
; CHECK-NEXT:    store i32 [[Z9]], ptr [[GEPP9]], align 4
; CHECK-NEXT:    [[TMP20:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP10:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP20]], i64 10
; CHECK-NEXT:    [[P10:%.*]] = load i32, ptr [[GEPP10]], align 4
; CHECK-NEXT:    [[TMP21:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ10:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP21]], i64 10
; CHECK-NEXT:    [[Q10:%.*]] = load i32, ptr [[GEPQ10]], align 4
; CHECK-NEXT:    [[Z10:%.*]] = add i32 [[P10]], [[Q10]]
; CHECK-NEXT:    store i32 [[Z10]], ptr [[GEPP10]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP11:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP22]], i64 11
; CHECK-NEXT:    [[P11:%.*]] = load i32, ptr [[GEPP11]], align 4
; CHECK-NEXT:    [[TMP23:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ11:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP23]], i64 11
; CHECK-NEXT:    [[Q11:%.*]] = load i32, ptr [[GEPQ11]], align 4
; CHECK-NEXT:    [[Z11:%.*]] = add i32 [[P11]], [[Q11]]
; CHECK-NEXT:    store i32 [[Z11]], ptr [[GEPP11]], align 4
; CHECK-NEXT:    [[TMP24:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP12:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP24]], i64 12
; CHECK-NEXT:    [[P12:%.*]] = load i32, ptr [[GEPP12]], align 4
; CHECK-NEXT:    [[TMP25:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ12:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP25]], i64 12
; CHECK-NEXT:    [[Q12:%.*]] = load i32, ptr [[GEPQ12]], align 4
; CHECK-NEXT:    [[Z12:%.*]] = add i32 [[P12]], [[Q12]]
; CHECK-NEXT:    store i32 [[Z12]], ptr [[GEPP12]], align 4
; CHECK-NEXT:    [[TMP26:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP13:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP26]], i64 13
; CHECK-NEXT:    [[P13:%.*]] = load i32, ptr [[GEPP13]], align 4
; CHECK-NEXT:    [[TMP27:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ13:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP27]], i64 13
; CHECK-NEXT:    [[Q13:%.*]] = load i32, ptr [[GEPQ13]], align 4
; CHECK-NEXT:    [[Z13:%.*]] = add i32 [[P13]], [[Q13]]
; CHECK-NEXT:    store i32 [[Z13]], ptr [[GEPP13]], align 4
; CHECK-NEXT:    [[TMP28:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP14:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP28]], i64 14
; CHECK-NEXT:    [[P14:%.*]] = load i32, ptr [[GEPP14]], align 4
; CHECK-NEXT:    [[TMP29:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ14:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP29]], i64 14
; CHECK-NEXT:    [[Q14:%.*]] = load i32, ptr [[GEPQ14]], align 4
; CHECK-NEXT:    [[Z14:%.*]] = add i32 [[P14]], [[Q14]]
; CHECK-NEXT:    store i32 [[Z14]], ptr [[GEPP14]], align 4
; CHECK-NEXT:    [[TMP30:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPP15:%.*]] = getelementptr [16 x i32], ptr [[P]], i64 [[TMP30]], i64 15
; CHECK-NEXT:    [[P15:%.*]] = load i32, ptr [[GEPP15]], align 4
; CHECK-NEXT:    [[TMP31:%.*]] = sext i32 [[IV]] to i64
; CHECK-NEXT:    [[GEPQ15:%.*]] = getelementptr [16 x i32], ptr [[Q]], i64 [[TMP31]], i64 15
; CHECK-NEXT:    [[Q15:%.*]] = load i32, ptr [[GEPQ15]], align 4
; CHECK-NEXT:    [[Z15:%.*]] = add i32 [[P15]], [[Q15]]
; CHECK-NEXT:    store i32 [[Z15]], ptr [[GEPP15]], align 4
; CHECK-NEXT:    [[IV_NEXT]] = add i32 [[IV]], 1
; CHECK-NEXT:    [[DONE:%.*]] = icmp eq i32 [[IV_NEXT]], 1024
; CHECK-NEXT:    br i1 [[DONE]], label %[[EXIT]], label %[[LOOP]], !llvm.loop [[LOOP5:![0-9]+]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %iv = phi i32 [ 0, %entry ], [ %iv.next, %loop ]

  %gepp0 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 0
  %p0 = load i32, ptr %gepp0
  %gepq0 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 0
  %q0 = load i32, ptr %gepq0
  %z0 = add i32 %p0, %q0
  store i32 %z0, ptr %gepp0

  %gepp1 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 1
  %p1 = load i32, ptr %gepp1
  %gepq1 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 1
  %q1 = load i32, ptr %gepq1
  %z1 = add i32 %p1, %q1
  store i32 %z1, ptr %gepp1

  %gepp2 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 2
  %p2 = load i32, ptr %gepp2
  %gepq2 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 2
  %q2 = load i32, ptr %gepq2
  %z2 = add i32 %p2, %q2
  store i32 %z2, ptr %gepp2

  %gepp3 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 3
  %p3 = load i32, ptr %gepp3
  %gepq3 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 3
  %q3 = load i32, ptr %gepq3
  %z3 = add i32 %p3, %q3
  store i32 %z3, ptr %gepp3

  %gepp4 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 4
  %p4 = load i32, ptr %gepp4
  %gepq4 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 4
  %q4 = load i32, ptr %gepq4
  %z4 = add i32 %p4, %q4
  store i32 %z4, ptr %gepp4

  %gepp5 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 5
  %p5 = load i32, ptr %gepp5
  %gepq5 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 5
  %q5 = load i32, ptr %gepq5
  %z5 = add i32 %p5, %q5
  store i32 %z5, ptr %gepp5

  %gepp6 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 6
  %p6 = load i32, ptr %gepp6
  %gepq6 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 6
  %q6 = load i32, ptr %gepq6
  %z6 = add i32 %p6, %q6
  store i32 %z6, ptr %gepp6

  %gepp7 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 7
  %p7 = load i32, ptr %gepp7
  %gepq7 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 7
  %q7 = load i32, ptr %gepq7
  %z7 = add i32 %p7, %q7
  store i32 %z7, ptr %gepp7

  %gepp8 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 8
  %p8 = load i32, ptr %gepp8
  %gepq8 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 8
  %q8 = load i32, ptr %gepq8
  %z8 = add i32 %p8, %q8
  store i32 %z8, ptr %gepp8

  %gepp9 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 9
  %p9 = load i32, ptr %gepp9
  %gepq9 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 9
  %q9 = load i32, ptr %gepq9
  %z9 = add i32 %p9, %q9
  store i32 %z9, ptr %gepp9

  %gepp10 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 10
  %p10 = load i32, ptr %gepp10
  %gepq10 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 10
  %q10 = load i32, ptr %gepq10
  %z10 = add i32 %p10, %q10
  store i32 %z10, ptr %gepp10

  %gepp11 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 11
  %p11 = load i32, ptr %gepp11
  %gepq11 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 11
  %q11 = load i32, ptr %gepq11
  %z11 = add i32 %p11, %q11
  store i32 %z11, ptr %gepp11

  %gepp12 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 12
  %p12 = load i32, ptr %gepp12
  %gepq12 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 12
  %q12 = load i32, ptr %gepq12
  %z12 = add i32 %p12, %q12
  store i32 %z12, ptr %gepp12

  %gepp13 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 13
  %p13 = load i32, ptr %gepp13
  %gepq13 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 13
  %q13 = load i32, ptr %gepq13
  %z13 = add i32 %p13, %q13
  store i32 %z13, ptr %gepp13

  %gepp14 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 14
  %p14 = load i32, ptr %gepp14
  %gepq14 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 14
  %q14 = load i32, ptr %gepq14
  %z14 = add i32 %p14, %q14
  store i32 %z14, ptr %gepp14

  %gepp15 = getelementptr [16 x i32], ptr %p, i32 %iv, i32 15
  %p15 = load i32, ptr %gepp15
  %gepq15 = getelementptr [16 x i32], ptr %q, i32 %iv, i32 15
  %q15 = load i32, ptr %gepq15
  %z15 = add i32 %p15, %q15
  store i32 %z15, ptr %gepp15

  %iv.next = add i32 %iv, 1
  %done = icmp eq i32 %iv.next, 1024
  br i1 %done, label %exit, label %loop

exit:
  ret void
}
