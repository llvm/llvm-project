; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt < %s -debug-only=loop-vectorize -passes='function(loop-vectorize),default<O2>' -vectorizer-maximize-bandwidth -mtriple=powerpc64-unknown-linux -S -mcpu=pwr8 2>&1 | FileCheck %s --check-prefixes=CHECK,CHECK-PWR8
; RUN: opt < %s -debug-only=loop-vectorize -passes='function(loop-vectorize),default<O2>' -vectorizer-maximize-bandwidth -mtriple=powerpc64le-unknown-linux -S -mcpu=pwr9 2>&1 | FileCheck %s --check-prefixes=CHECK,CHECK-PWR9
; REQUIRES: asserts

@a = global [1024 x i8] zeroinitializer, align 16
@b = global [1024 x i8] zeroinitializer, align 16

define i32 @foo() {
; CHECK-PWR8-LABEL: @foo(
; CHECK-PWR8-NEXT:  iter.check:
; CHECK-PWR8-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK-PWR8:       vector.body:
; CHECK-PWR8-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[ITER_CHECK:%.*]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI:%.*]] = phi <16 x i32> [ zeroinitializer, [[ITER_CHECK]] ], [ [[TMP32:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI1:%.*]] = phi <16 x i32> [ zeroinitializer, [[ITER_CHECK]] ], [ [[TMP33:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI2:%.*]] = phi <16 x i32> [ zeroinitializer, [[ITER_CHECK]] ], [ [[TMP34:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI3:%.*]] = phi <16 x i32> [ zeroinitializer, [[ITER_CHECK]] ], [ [[TMP35:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 [[INDEX]]
; CHECK-PWR8-NEXT:    [[TMP1:%.*]] = bitcast i8* [[TMP0]] to <16 x i8>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD:%.*]] = load <16 x i8>, <16 x i8>* [[TMP1]], align 16
; CHECK-PWR8-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 16
; CHECK-PWR8-NEXT:    [[TMP3:%.*]] = bitcast i8* [[TMP2]] to <16 x i8>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD4:%.*]] = load <16 x i8>, <16 x i8>* [[TMP3]], align 16
; CHECK-PWR8-NEXT:    [[TMP4:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 32
; CHECK-PWR8-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP4]] to <16 x i8>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD5:%.*]] = load <16 x i8>, <16 x i8>* [[TMP5]], align 16
; CHECK-PWR8-NEXT:    [[TMP6:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 48
; CHECK-PWR8-NEXT:    [[TMP7:%.*]] = bitcast i8* [[TMP6]] to <16 x i8>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD6:%.*]] = load <16 x i8>, <16 x i8>* [[TMP7]], align 16
; CHECK-PWR8-NEXT:    [[TMP8:%.*]] = zext <16 x i8> [[WIDE_LOAD]] to <16 x i32>
; CHECK-PWR8-NEXT:    [[TMP9:%.*]] = zext <16 x i8> [[WIDE_LOAD4]] to <16 x i32>
; CHECK-PWR8-NEXT:    [[TMP10:%.*]] = zext <16 x i8> [[WIDE_LOAD5]] to <16 x i32>
; CHECK-PWR8-NEXT:    [[TMP11:%.*]] = zext <16 x i8> [[WIDE_LOAD6]] to <16 x i32>
; CHECK-PWR8-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 [[INDEX]]
; CHECK-PWR8-NEXT:    [[TMP13:%.*]] = bitcast i8* [[TMP12]] to <16 x i8>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD7:%.*]] = load <16 x i8>, <16 x i8>* [[TMP13]], align 16
; CHECK-PWR8-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i8, i8* [[TMP12]], i64 16
; CHECK-PWR8-NEXT:    [[TMP15:%.*]] = bitcast i8* [[TMP14]] to <16 x i8>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD8:%.*]] = load <16 x i8>, <16 x i8>* [[TMP15]], align 16
; CHECK-PWR8-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i8, i8* [[TMP12]], i64 32
; CHECK-PWR8-NEXT:    [[TMP17:%.*]] = bitcast i8* [[TMP16]] to <16 x i8>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD9:%.*]] = load <16 x i8>, <16 x i8>* [[TMP17]], align 16
; CHECK-PWR8-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, i8* [[TMP12]], i64 48
; CHECK-PWR8-NEXT:    [[TMP19:%.*]] = bitcast i8* [[TMP18]] to <16 x i8>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD10:%.*]] = load <16 x i8>, <16 x i8>* [[TMP19]], align 16
; CHECK-PWR8-NEXT:    [[TMP20:%.*]] = zext <16 x i8> [[WIDE_LOAD7]] to <16 x i32>
; CHECK-PWR8-NEXT:    [[TMP21:%.*]] = zext <16 x i8> [[WIDE_LOAD8]] to <16 x i32>
; CHECK-PWR8-NEXT:    [[TMP22:%.*]] = zext <16 x i8> [[WIDE_LOAD9]] to <16 x i32>
; CHECK-PWR8-NEXT:    [[TMP23:%.*]] = zext <16 x i8> [[WIDE_LOAD10]] to <16 x i32>
; CHECK-PWR8-NEXT:    [[TMP24:%.*]] = sub nsw <16 x i32> [[TMP8]], [[TMP20]]
; CHECK-PWR8-NEXT:    [[TMP25:%.*]] = sub nsw <16 x i32> [[TMP9]], [[TMP21]]
; CHECK-PWR8-NEXT:    [[TMP26:%.*]] = sub nsw <16 x i32> [[TMP10]], [[TMP22]]
; CHECK-PWR8-NEXT:    [[TMP27:%.*]] = sub nsw <16 x i32> [[TMP11]], [[TMP23]]
; CHECK-PWR8-NEXT:    [[TMP28:%.*]] = tail call <16 x i32> @llvm.abs.v16i32(<16 x i32> [[TMP24]], i1 true)
; CHECK-PWR8-NEXT:    [[TMP29:%.*]] = tail call <16 x i32> @llvm.abs.v16i32(<16 x i32> [[TMP25]], i1 true)
; CHECK-PWR8-NEXT:    [[TMP30:%.*]] = tail call <16 x i32> @llvm.abs.v16i32(<16 x i32> [[TMP26]], i1 true)
; CHECK-PWR8-NEXT:    [[TMP31:%.*]] = tail call <16 x i32> @llvm.abs.v16i32(<16 x i32> [[TMP27]], i1 true)
; CHECK-PWR8-NEXT:    [[TMP32]] = add <16 x i32> [[TMP28]], [[VEC_PHI]]
; CHECK-PWR8-NEXT:    [[TMP33]] = add <16 x i32> [[TMP29]], [[VEC_PHI1]]
; CHECK-PWR8-NEXT:    [[TMP34]] = add <16 x i32> [[TMP30]], [[VEC_PHI2]]
; CHECK-PWR8-NEXT:    [[TMP35]] = add <16 x i32> [[TMP31]], [[VEC_PHI3]]
; CHECK-PWR8-NEXT:    [[INDEX_NEXT]] = add nuw nsw i64 [[INDEX]], 64
; CHECK-PWR8-NEXT:    [[TMP36:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1024
; CHECK-PWR8-NEXT:    br i1 [[TMP36]], label [[FOR_COND_CLEANUP:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK-PWR8:       for.cond.cleanup:
; CHECK-PWR8-NEXT:    [[BIN_RDX:%.*]] = add <16 x i32> [[TMP33]], [[TMP32]]
; CHECK-PWR8-NEXT:    [[BIN_RDX11:%.*]] = add <16 x i32> [[BIN_RDX]], [[TMP34]]
; CHECK-PWR8-NEXT:    [[BIN_RDX12:%.*]] = add <16 x i32> [[BIN_RDX11]], [[TMP35]]
; CHECK-PWR8-NEXT:    [[TMP37:%.*]] = tail call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> [[BIN_RDX12]])
; CHECK-PWR8-NEXT:    ret i32 [[TMP37]]
;
; CHECK-PWR9-LABEL: @foo(
; CHECK-PWR9-NEXT:  entry:
; CHECK-PWR9-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK-PWR9:       vector.body:
; CHECK-PWR9-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI:%.*]] = phi <8 x i32> [ zeroinitializer, [[ENTRY]] ], [ [[TMP64:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI1:%.*]] = phi <8 x i32> [ zeroinitializer, [[ENTRY]] ], [ [[TMP65:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI2:%.*]] = phi <8 x i32> [ zeroinitializer, [[ENTRY]] ], [ [[TMP66:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI3:%.*]] = phi <8 x i32> [ zeroinitializer, [[ENTRY]] ], [ [[TMP67:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI4:%.*]] = phi <8 x i32> [ zeroinitializer, [[ENTRY]] ], [ [[TMP68:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI5:%.*]] = phi <8 x i32> [ zeroinitializer, [[ENTRY]] ], [ [[TMP69:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI6:%.*]] = phi <8 x i32> [ zeroinitializer, [[ENTRY]] ], [ [[TMP70:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI7:%.*]] = phi <8 x i32> [ zeroinitializer, [[ENTRY]] ], [ [[TMP71:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 [[INDEX]]
; CHECK-PWR9-NEXT:    [[TMP1:%.*]] = bitcast i8* [[TMP0]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD:%.*]] = load <8 x i8>, <8 x i8>* [[TMP1]], align 16
; CHECK-PWR9-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 8
; CHECK-PWR9-NEXT:    [[TMP3:%.*]] = bitcast i8* [[TMP2]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD8:%.*]] = load <8 x i8>, <8 x i8>* [[TMP3]], align 8
; CHECK-PWR9-NEXT:    [[TMP4:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 16
; CHECK-PWR9-NEXT:    [[TMP5:%.*]] = bitcast i8* [[TMP4]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD9:%.*]] = load <8 x i8>, <8 x i8>* [[TMP5]], align 16
; CHECK-PWR9-NEXT:    [[TMP6:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 24
; CHECK-PWR9-NEXT:    [[TMP7:%.*]] = bitcast i8* [[TMP6]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD10:%.*]] = load <8 x i8>, <8 x i8>* [[TMP7]], align 8
; CHECK-PWR9-NEXT:    [[TMP8:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 32
; CHECK-PWR9-NEXT:    [[TMP9:%.*]] = bitcast i8* [[TMP8]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD11:%.*]] = load <8 x i8>, <8 x i8>* [[TMP9]], align 16
; CHECK-PWR9-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 40
; CHECK-PWR9-NEXT:    [[TMP11:%.*]] = bitcast i8* [[TMP10]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD12:%.*]] = load <8 x i8>, <8 x i8>* [[TMP11]], align 8
; CHECK-PWR9-NEXT:    [[TMP12:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 48
; CHECK-PWR9-NEXT:    [[TMP13:%.*]] = bitcast i8* [[TMP12]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD13:%.*]] = load <8 x i8>, <8 x i8>* [[TMP13]], align 16
; CHECK-PWR9-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 56
; CHECK-PWR9-NEXT:    [[TMP15:%.*]] = bitcast i8* [[TMP14]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD14:%.*]] = load <8 x i8>, <8 x i8>* [[TMP15]], align 8
; CHECK-PWR9-NEXT:    [[TMP16:%.*]] = zext <8 x i8> [[WIDE_LOAD]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP17:%.*]] = zext <8 x i8> [[WIDE_LOAD8]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP18:%.*]] = zext <8 x i8> [[WIDE_LOAD9]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP19:%.*]] = zext <8 x i8> [[WIDE_LOAD10]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP20:%.*]] = zext <8 x i8> [[WIDE_LOAD11]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP21:%.*]] = zext <8 x i8> [[WIDE_LOAD12]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP22:%.*]] = zext <8 x i8> [[WIDE_LOAD13]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP23:%.*]] = zext <8 x i8> [[WIDE_LOAD14]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP24:%.*]] = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 [[INDEX]]
; CHECK-PWR9-NEXT:    [[TMP25:%.*]] = bitcast i8* [[TMP24]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD15:%.*]] = load <8 x i8>, <8 x i8>* [[TMP25]], align 16
; CHECK-PWR9-NEXT:    [[TMP26:%.*]] = getelementptr inbounds i8, i8* [[TMP24]], i64 8
; CHECK-PWR9-NEXT:    [[TMP27:%.*]] = bitcast i8* [[TMP26]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD16:%.*]] = load <8 x i8>, <8 x i8>* [[TMP27]], align 8
; CHECK-PWR9-NEXT:    [[TMP28:%.*]] = getelementptr inbounds i8, i8* [[TMP24]], i64 16
; CHECK-PWR9-NEXT:    [[TMP29:%.*]] = bitcast i8* [[TMP28]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD17:%.*]] = load <8 x i8>, <8 x i8>* [[TMP29]], align 16
; CHECK-PWR9-NEXT:    [[TMP30:%.*]] = getelementptr inbounds i8, i8* [[TMP24]], i64 24
; CHECK-PWR9-NEXT:    [[TMP31:%.*]] = bitcast i8* [[TMP30]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD18:%.*]] = load <8 x i8>, <8 x i8>* [[TMP31]], align 8
; CHECK-PWR9-NEXT:    [[TMP32:%.*]] = getelementptr inbounds i8, i8* [[TMP24]], i64 32
; CHECK-PWR9-NEXT:    [[TMP33:%.*]] = bitcast i8* [[TMP32]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD19:%.*]] = load <8 x i8>, <8 x i8>* [[TMP33]], align 16
; CHECK-PWR9-NEXT:    [[TMP34:%.*]] = getelementptr inbounds i8, i8* [[TMP24]], i64 40
; CHECK-PWR9-NEXT:    [[TMP35:%.*]] = bitcast i8* [[TMP34]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD20:%.*]] = load <8 x i8>, <8 x i8>* [[TMP35]], align 8
; CHECK-PWR9-NEXT:    [[TMP36:%.*]] = getelementptr inbounds i8, i8* [[TMP24]], i64 48
; CHECK-PWR9-NEXT:    [[TMP37:%.*]] = bitcast i8* [[TMP36]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD21:%.*]] = load <8 x i8>, <8 x i8>* [[TMP37]], align 16
; CHECK-PWR9-NEXT:    [[TMP38:%.*]] = getelementptr inbounds i8, i8* [[TMP24]], i64 56
; CHECK-PWR9-NEXT:    [[TMP39:%.*]] = bitcast i8* [[TMP38]] to <8 x i8>*
; CHECK-PWR9-NEXT:    [[WIDE_LOAD22:%.*]] = load <8 x i8>, <8 x i8>* [[TMP39]], align 8
; CHECK-PWR9-NEXT:    [[TMP40:%.*]] = zext <8 x i8> [[WIDE_LOAD15]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP41:%.*]] = zext <8 x i8> [[WIDE_LOAD16]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP42:%.*]] = zext <8 x i8> [[WIDE_LOAD17]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP43:%.*]] = zext <8 x i8> [[WIDE_LOAD18]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP44:%.*]] = zext <8 x i8> [[WIDE_LOAD19]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP45:%.*]] = zext <8 x i8> [[WIDE_LOAD20]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP46:%.*]] = zext <8 x i8> [[WIDE_LOAD21]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP47:%.*]] = zext <8 x i8> [[WIDE_LOAD22]] to <8 x i32>
; CHECK-PWR9-NEXT:    [[TMP48:%.*]] = sub nsw <8 x i32> [[TMP16]], [[TMP40]]
; CHECK-PWR9-NEXT:    [[TMP49:%.*]] = sub nsw <8 x i32> [[TMP17]], [[TMP41]]
; CHECK-PWR9-NEXT:    [[TMP50:%.*]] = sub nsw <8 x i32> [[TMP18]], [[TMP42]]
; CHECK-PWR9-NEXT:    [[TMP51:%.*]] = sub nsw <8 x i32> [[TMP19]], [[TMP43]]
; CHECK-PWR9-NEXT:    [[TMP52:%.*]] = sub nsw <8 x i32> [[TMP20]], [[TMP44]]
; CHECK-PWR9-NEXT:    [[TMP53:%.*]] = sub nsw <8 x i32> [[TMP21]], [[TMP45]]
; CHECK-PWR9-NEXT:    [[TMP54:%.*]] = sub nsw <8 x i32> [[TMP22]], [[TMP46]]
; CHECK-PWR9-NEXT:    [[TMP55:%.*]] = sub nsw <8 x i32> [[TMP23]], [[TMP47]]
; CHECK-PWR9-NEXT:    [[TMP56:%.*]] = tail call <8 x i32> @llvm.abs.v8i32(<8 x i32> [[TMP48]], i1 true)
; CHECK-PWR9-NEXT:    [[TMP57:%.*]] = tail call <8 x i32> @llvm.abs.v8i32(<8 x i32> [[TMP49]], i1 true)
; CHECK-PWR9-NEXT:    [[TMP58:%.*]] = tail call <8 x i32> @llvm.abs.v8i32(<8 x i32> [[TMP50]], i1 true)
; CHECK-PWR9-NEXT:    [[TMP59:%.*]] = tail call <8 x i32> @llvm.abs.v8i32(<8 x i32> [[TMP51]], i1 true)
; CHECK-PWR9-NEXT:    [[TMP60:%.*]] = tail call <8 x i32> @llvm.abs.v8i32(<8 x i32> [[TMP52]], i1 true)
; CHECK-PWR9-NEXT:    [[TMP61:%.*]] = tail call <8 x i32> @llvm.abs.v8i32(<8 x i32> [[TMP53]], i1 true)
; CHECK-PWR9-NEXT:    [[TMP62:%.*]] = tail call <8 x i32> @llvm.abs.v8i32(<8 x i32> [[TMP54]], i1 true)
; CHECK-PWR9-NEXT:    [[TMP63:%.*]] = tail call <8 x i32> @llvm.abs.v8i32(<8 x i32> [[TMP55]], i1 true)
; CHECK-PWR9-NEXT:    [[TMP64]] = add <8 x i32> [[TMP56]], [[VEC_PHI]]
; CHECK-PWR9-NEXT:    [[TMP65]] = add <8 x i32> [[TMP57]], [[VEC_PHI1]]
; CHECK-PWR9-NEXT:    [[TMP66]] = add <8 x i32> [[TMP58]], [[VEC_PHI2]]
; CHECK-PWR9-NEXT:    [[TMP67]] = add <8 x i32> [[TMP59]], [[VEC_PHI3]]
; CHECK-PWR9-NEXT:    [[TMP68]] = add <8 x i32> [[TMP60]], [[VEC_PHI4]]
; CHECK-PWR9-NEXT:    [[TMP69]] = add <8 x i32> [[TMP61]], [[VEC_PHI5]]
; CHECK-PWR9-NEXT:    [[TMP70]] = add <8 x i32> [[TMP62]], [[VEC_PHI6]]
; CHECK-PWR9-NEXT:    [[TMP71]] = add <8 x i32> [[TMP63]], [[VEC_PHI7]]
; CHECK-PWR9-NEXT:    [[INDEX_NEXT]] = add nuw nsw i64 [[INDEX]], 64
; CHECK-PWR9-NEXT:    [[TMP72:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1024
; CHECK-PWR9-NEXT:    br i1 [[TMP72]], label [[FOR_COND_CLEANUP:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK-PWR9:       for.cond.cleanup:
; CHECK-PWR9-NEXT:    [[BIN_RDX:%.*]] = add <8 x i32> [[TMP65]], [[TMP64]]
; CHECK-PWR9-NEXT:    [[BIN_RDX23:%.*]] = add <8 x i32> [[BIN_RDX]], [[TMP66]]
; CHECK-PWR9-NEXT:    [[BIN_RDX24:%.*]] = add <8 x i32> [[BIN_RDX23]], [[TMP67]]
; CHECK-PWR9-NEXT:    [[BIN_RDX25:%.*]] = add <8 x i32> [[BIN_RDX24]], [[TMP68]]
; CHECK-PWR9-NEXT:    [[BIN_RDX26:%.*]] = add <8 x i32> [[BIN_RDX25]], [[TMP69]]
; CHECK-PWR9-NEXT:    [[BIN_RDX27:%.*]] = add <8 x i32> [[BIN_RDX26]], [[TMP70]]
; CHECK-PWR9-NEXT:    [[BIN_RDX28:%.*]] = add <8 x i32> [[BIN_RDX27]], [[TMP71]]
; CHECK-PWR9-NEXT:    [[TMP73:%.*]] = tail call i32 @llvm.vector.reduce.add.v8i32(<8 x i32> [[BIN_RDX28]])
; CHECK-PWR9-NEXT:    ret i32 [[TMP73]]
;




entry:
  br label %for.body

for.cond.cleanup:
  %add.lcssa = phi i32 [ %add, %for.body ]
  ret i32 %add.lcssa

for.body:
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %s.015 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %arrayidx = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %indvars.iv
  %0 = load i8, i8* %arrayidx, align 1
  %conv = zext i8 %0 to i32
  %arrayidx2 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %indvars.iv
  %1 = load i8, i8* %arrayidx2, align 1
  %conv3 = zext i8 %1 to i32
  %sub = sub nsw i32 %conv, %conv3
  %ispos = icmp sgt i32 %sub, -1
  %neg = sub nsw i32 0, %sub
  %2 = select i1 %ispos, i32 %sub, i32 %neg
  %add = add nsw i32 %2, %s.015
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

define i32 @goo() {
; For indvars.iv used in a computating chain only feeding into getelementptr or cmp,
; it will not have vector version and the vector register usage will not exceed the
; available vector register number.
; CHECK-LABEL: @goo(
; CHECK-NEXT:  iter.check:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[ITER_CHECK:%.*]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <16 x i32> [ zeroinitializer, [[ITER_CHECK]] ], [ [[TMP34:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI1:%.*]] = phi <16 x i32> [ zeroinitializer, [[ITER_CHECK]] ], [ [[TMP35:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI2:%.*]] = phi <16 x i32> [ zeroinitializer, [[ITER_CHECK]] ], [ [[TMP36:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI3:%.*]] = phi <16 x i32> [ zeroinitializer, [[ITER_CHECK]] ], [ [[TMP37:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = or i64 [[INDEX]], 3
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 [[TMP0]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8* [[TMP1]] to <16 x i8>*
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <16 x i8>, <16 x i8>* [[TMP2]], align 1
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, i8* [[TMP1]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i8* [[TMP3]] to <16 x i8>*
; CHECK-NEXT:    [[WIDE_LOAD4:%.*]] = load <16 x i8>, <16 x i8>* [[TMP4]], align 1
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds i8, i8* [[TMP1]], i64 32
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i8* [[TMP5]] to <16 x i8>*
; CHECK-NEXT:    [[WIDE_LOAD5:%.*]] = load <16 x i8>, <16 x i8>* [[TMP6]], align 1
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds i8, i8* [[TMP1]], i64 48
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i8* [[TMP7]] to <16 x i8>*
; CHECK-NEXT:    [[WIDE_LOAD6:%.*]] = load <16 x i8>, <16 x i8>* [[TMP8]], align 1
; CHECK-NEXT:    [[TMP9:%.*]] = zext <16 x i8> [[WIDE_LOAD]] to <16 x i32>
; CHECK-NEXT:    [[TMP10:%.*]] = zext <16 x i8> [[WIDE_LOAD4]] to <16 x i32>
; CHECK-NEXT:    [[TMP11:%.*]] = zext <16 x i8> [[WIDE_LOAD5]] to <16 x i32>
; CHECK-NEXT:    [[TMP12:%.*]] = zext <16 x i8> [[WIDE_LOAD6]] to <16 x i32>
; CHECK-NEXT:    [[TMP13:%.*]] = or i64 [[INDEX]], 2
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 [[TMP13]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i8* [[TMP14]] to <16 x i8>*
; CHECK-NEXT:    [[WIDE_LOAD7:%.*]] = load <16 x i8>, <16 x i8>* [[TMP15]], align 2
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i8, i8* [[TMP14]], i64 16
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i8* [[TMP16]] to <16 x i8>*
; CHECK-NEXT:    [[WIDE_LOAD8:%.*]] = load <16 x i8>, <16 x i8>* [[TMP17]], align 2
; CHECK-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, i8* [[TMP14]], i64 32
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i8* [[TMP18]] to <16 x i8>*
; CHECK-NEXT:    [[WIDE_LOAD9:%.*]] = load <16 x i8>, <16 x i8>* [[TMP19]], align 2
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr inbounds i8, i8* [[TMP14]], i64 48
; CHECK-NEXT:    [[TMP21:%.*]] = bitcast i8* [[TMP20]] to <16 x i8>*
; CHECK-NEXT:    [[WIDE_LOAD10:%.*]] = load <16 x i8>, <16 x i8>* [[TMP21]], align 2
; CHECK-NEXT:    [[TMP22:%.*]] = zext <16 x i8> [[WIDE_LOAD7]] to <16 x i32>
; CHECK-NEXT:    [[TMP23:%.*]] = zext <16 x i8> [[WIDE_LOAD8]] to <16 x i32>
; CHECK-NEXT:    [[TMP24:%.*]] = zext <16 x i8> [[WIDE_LOAD9]] to <16 x i32>
; CHECK-NEXT:    [[TMP25:%.*]] = zext <16 x i8> [[WIDE_LOAD10]] to <16 x i32>
; CHECK-NEXT:    [[TMP26:%.*]] = sub nsw <16 x i32> [[TMP9]], [[TMP22]]
; CHECK-NEXT:    [[TMP27:%.*]] = sub nsw <16 x i32> [[TMP10]], [[TMP23]]
; CHECK-NEXT:    [[TMP28:%.*]] = sub nsw <16 x i32> [[TMP11]], [[TMP24]]
; CHECK-NEXT:    [[TMP29:%.*]] = sub nsw <16 x i32> [[TMP12]], [[TMP25]]
; CHECK-NEXT:    [[TMP30:%.*]] = tail call <16 x i32> @llvm.abs.v16i32(<16 x i32> [[TMP26]], i1 true)
; CHECK-NEXT:    [[TMP31:%.*]] = tail call <16 x i32> @llvm.abs.v16i32(<16 x i32> [[TMP27]], i1 true)
; CHECK-NEXT:    [[TMP32:%.*]] = tail call <16 x i32> @llvm.abs.v16i32(<16 x i32> [[TMP28]], i1 true)
; CHECK-NEXT:    [[TMP33:%.*]] = tail call <16 x i32> @llvm.abs.v16i32(<16 x i32> [[TMP29]], i1 true)
; CHECK-NEXT:    [[TMP34]] = add <16 x i32> [[TMP30]], [[VEC_PHI]]
; CHECK-NEXT:    [[TMP35]] = add <16 x i32> [[TMP31]], [[VEC_PHI1]]
; CHECK-NEXT:    [[TMP36]] = add <16 x i32> [[TMP32]], [[VEC_PHI2]]
; CHECK-NEXT:    [[TMP37]] = add <16 x i32> [[TMP33]], [[VEC_PHI3]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw nsw i64 [[INDEX]], 64
; CHECK-NEXT:    [[TMP38:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1024
; CHECK-NEXT:    br i1 [[TMP38]], label [[FOR_COND_CLEANUP:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP2:![0-9]+]]
; CHECK:       for.cond.cleanup:
; CHECK-NEXT:    [[BIN_RDX:%.*]] = add <16 x i32> [[TMP35]], [[TMP34]]
; CHECK-NEXT:    [[BIN_RDX11:%.*]] = add <16 x i32> [[BIN_RDX]], [[TMP36]]
; CHECK-NEXT:    [[BIN_RDX12:%.*]] = add <16 x i32> [[BIN_RDX11]], [[TMP37]]
; CHECK-NEXT:    [[TMP39:%.*]] = tail call i32 @llvm.vector.reduce.add.v16i32(<16 x i32> [[BIN_RDX12]])
; CHECK-NEXT:    ret i32 [[TMP39]]
;


entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  ret i32 %add.lcssa

for.body:                                         ; preds = %for.body, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %s.015 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %tmp1 = add nsw i64 %indvars.iv, 3
  %arrayidx = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %tmp1
  %tmp = load i8, i8* %arrayidx, align 1
  %conv = zext i8 %tmp to i32
  %tmp2 = add nsw i64 %indvars.iv, 2
  %arrayidx2 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %tmp2
  %tmp3 = load i8, i8* %arrayidx2, align 1
  %conv3 = zext i8 %tmp3 to i32
  %sub = sub nsw i32 %conv, %conv3
  %ispos = icmp sgt i32 %sub, -1
  %neg = sub nsw i32 0, %sub
  %tmp4 = select i1 %ispos, i32 %sub, i32 %neg
  %add = add nsw i32 %tmp4, %s.015
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

define i64 @bar(i64* nocapture %a) {
; CHECK-LABEL: @bar(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_IND:%.*]] = phi <2 x i64> [ <i64 0, i64 1>, [[ENTRY]] ], [ [[VEC_IND_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP36:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI12:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP37:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI13:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP38:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI14:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP39:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI15:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP40:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI16:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP41:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI17:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP42:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI18:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP43:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI19:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP44:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI20:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP45:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI21:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP46:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI22:%.*]] = phi <2 x i64> [ zeroinitializer, [[ENTRY]] ], [ [[TMP47:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[STEP_ADD:%.*]] = add <2 x i64> [[VEC_IND]], <i64 2, i64 2>
; CHECK-NEXT:    [[STEP_ADD1:%.*]] = add <2 x i64> [[VEC_IND]], <i64 4, i64 4>
; CHECK-NEXT:    [[STEP_ADD2:%.*]] = add <2 x i64> [[VEC_IND]], <i64 6, i64 6>
; CHECK-NEXT:    [[STEP_ADD3:%.*]] = add <2 x i64> [[VEC_IND]], <i64 8, i64 8>
; CHECK-NEXT:    [[STEP_ADD4:%.*]] = add <2 x i64> [[VEC_IND]], <i64 10, i64 10>
; CHECK-NEXT:    [[STEP_ADD5:%.*]] = add <2 x i64> [[VEC_IND]], <i64 12, i64 12>
; CHECK-NEXT:    [[STEP_ADD6:%.*]] = add <2 x i64> [[VEC_IND]], <i64 14, i64 14>
; CHECK-NEXT:    [[STEP_ADD7:%.*]] = add <2 x i64> [[VEC_IND]], <i64 16, i64 16>
; CHECK-NEXT:    [[STEP_ADD8:%.*]] = add <2 x i64> [[VEC_IND]], <i64 18, i64 18>
; CHECK-NEXT:    [[STEP_ADD9:%.*]] = add <2 x i64> [[VEC_IND]], <i64 20, i64 20>
; CHECK-NEXT:    [[STEP_ADD10:%.*]] = add <2 x i64> [[VEC_IND]], <i64 22, i64 22>
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i64, i64* [[A:%.*]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i64* [[TMP0]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <2 x i64>, <2 x i64>* [[TMP1]], align 8
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 2
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast i64* [[TMP2]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD23:%.*]] = load <2 x i64>, <2 x i64>* [[TMP3]], align 8
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 4
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i64* [[TMP4]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD24:%.*]] = load <2 x i64>, <2 x i64>* [[TMP5]], align 8
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 6
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i64* [[TMP6]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD25:%.*]] = load <2 x i64>, <2 x i64>* [[TMP7]], align 8
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 8
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i64* [[TMP8]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD26:%.*]] = load <2 x i64>, <2 x i64>* [[TMP9]], align 8
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 10
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i64* [[TMP10]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD27:%.*]] = load <2 x i64>, <2 x i64>* [[TMP11]], align 8
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 12
; CHECK-NEXT:    [[TMP13:%.*]] = bitcast i64* [[TMP12]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD28:%.*]] = load <2 x i64>, <2 x i64>* [[TMP13]], align 8
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 14
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i64* [[TMP14]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD29:%.*]] = load <2 x i64>, <2 x i64>* [[TMP15]], align 8
; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 16
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i64* [[TMP16]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD30:%.*]] = load <2 x i64>, <2 x i64>* [[TMP17]], align 8
; CHECK-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 18
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i64* [[TMP18]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD31:%.*]] = load <2 x i64>, <2 x i64>* [[TMP19]], align 8
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 20
; CHECK-NEXT:    [[TMP21:%.*]] = bitcast i64* [[TMP20]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD32:%.*]] = load <2 x i64>, <2 x i64>* [[TMP21]], align 8
; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr inbounds i64, i64* [[TMP0]], i64 22
; CHECK-NEXT:    [[TMP23:%.*]] = bitcast i64* [[TMP22]] to <2 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD33:%.*]] = load <2 x i64>, <2 x i64>* [[TMP23]], align 8
; CHECK-NEXT:    [[TMP24:%.*]] = add nsw <2 x i64> [[WIDE_LOAD]], [[VEC_IND]]
; CHECK-NEXT:    [[TMP25:%.*]] = add nsw <2 x i64> [[STEP_ADD]], [[WIDE_LOAD23]]
; CHECK-NEXT:    [[TMP26:%.*]] = add nsw <2 x i64> [[STEP_ADD1]], [[WIDE_LOAD24]]
; CHECK-NEXT:    [[TMP27:%.*]] = add nsw <2 x i64> [[STEP_ADD2]], [[WIDE_LOAD25]]
; CHECK-NEXT:    [[TMP28:%.*]] = add nsw <2 x i64> [[STEP_ADD3]], [[WIDE_LOAD26]]
; CHECK-NEXT:    [[TMP29:%.*]] = add nsw <2 x i64> [[STEP_ADD4]], [[WIDE_LOAD27]]
; CHECK-NEXT:    [[TMP30:%.*]] = add nsw <2 x i64> [[STEP_ADD5]], [[WIDE_LOAD28]]
; CHECK-NEXT:    [[TMP31:%.*]] = add nsw <2 x i64> [[STEP_ADD6]], [[WIDE_LOAD29]]
; CHECK-NEXT:    [[TMP32:%.*]] = add nsw <2 x i64> [[STEP_ADD7]], [[WIDE_LOAD30]]
; CHECK-NEXT:    [[TMP33:%.*]] = add nsw <2 x i64> [[STEP_ADD8]], [[WIDE_LOAD31]]
; CHECK-NEXT:    [[TMP34:%.*]] = add nsw <2 x i64> [[STEP_ADD9]], [[WIDE_LOAD32]]
; CHECK-NEXT:    [[TMP35:%.*]] = add nsw <2 x i64> [[STEP_ADD10]], [[WIDE_LOAD33]]
; CHECK-NEXT:    store <2 x i64> [[TMP24]], <2 x i64>* [[TMP1]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP25]], <2 x i64>* [[TMP3]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP26]], <2 x i64>* [[TMP5]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP27]], <2 x i64>* [[TMP7]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP28]], <2 x i64>* [[TMP9]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP29]], <2 x i64>* [[TMP11]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP30]], <2 x i64>* [[TMP13]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP31]], <2 x i64>* [[TMP15]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP32]], <2 x i64>* [[TMP17]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP33]], <2 x i64>* [[TMP19]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP34]], <2 x i64>* [[TMP21]], align 8
; CHECK-NEXT:    store <2 x i64> [[TMP35]], <2 x i64>* [[TMP23]], align 8
; CHECK-NEXT:    [[TMP36]] = add <2 x i64> [[TMP24]], [[VEC_PHI]]
; CHECK-NEXT:    [[TMP37]] = add <2 x i64> [[TMP25]], [[VEC_PHI12]]
; CHECK-NEXT:    [[TMP38]] = add <2 x i64> [[TMP26]], [[VEC_PHI13]]
; CHECK-NEXT:    [[TMP39]] = add <2 x i64> [[TMP27]], [[VEC_PHI14]]
; CHECK-NEXT:    [[TMP40]] = add <2 x i64> [[TMP28]], [[VEC_PHI15]]
; CHECK-NEXT:    [[TMP41]] = add <2 x i64> [[TMP29]], [[VEC_PHI16]]
; CHECK-NEXT:    [[TMP42]] = add <2 x i64> [[TMP30]], [[VEC_PHI17]]
; CHECK-NEXT:    [[TMP43]] = add <2 x i64> [[TMP31]], [[VEC_PHI18]]
; CHECK-NEXT:    [[TMP44]] = add <2 x i64> [[TMP32]], [[VEC_PHI19]]
; CHECK-NEXT:    [[TMP45]] = add <2 x i64> [[TMP33]], [[VEC_PHI20]]
; CHECK-NEXT:    [[TMP46]] = add <2 x i64> [[TMP34]], [[VEC_PHI21]]
; CHECK-NEXT:    [[TMP47]] = add <2 x i64> [[TMP35]], [[VEC_PHI22]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw nsw i64 [[INDEX]], 24
; CHECK-NEXT:    [[VEC_IND_NEXT]] = add <2 x i64> [[VEC_IND]], <i64 24, i64 24>
; CHECK-NEXT:    [[TMP48:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1008
; CHECK-NEXT:    br i1 [[TMP48]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP3:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    [[BIN_RDX:%.*]] = add <2 x i64> [[TMP37]], [[TMP36]]
; CHECK-NEXT:    [[BIN_RDX34:%.*]] = add <2 x i64> [[BIN_RDX]], [[TMP38]]
; CHECK-NEXT:    [[BIN_RDX35:%.*]] = add <2 x i64> [[BIN_RDX34]], [[TMP39]]
; CHECK-NEXT:    [[BIN_RDX36:%.*]] = add <2 x i64> [[BIN_RDX35]], [[TMP40]]
; CHECK-NEXT:    [[BIN_RDX37:%.*]] = add <2 x i64> [[BIN_RDX36]], [[TMP41]]
; CHECK-NEXT:    [[BIN_RDX38:%.*]] = add <2 x i64> [[BIN_RDX37]], [[TMP42]]
; CHECK-NEXT:    [[BIN_RDX39:%.*]] = add <2 x i64> [[BIN_RDX38]], [[TMP43]]
; CHECK-NEXT:    [[BIN_RDX40:%.*]] = add <2 x i64> [[BIN_RDX39]], [[TMP44]]
; CHECK-NEXT:    [[BIN_RDX41:%.*]] = add <2 x i64> [[BIN_RDX40]], [[TMP45]]
; CHECK-NEXT:    [[BIN_RDX42:%.*]] = add <2 x i64> [[BIN_RDX41]], [[TMP46]]
; CHECK-NEXT:    [[BIN_RDX43:%.*]] = add <2 x i64> [[BIN_RDX42]], [[TMP47]]
; CHECK-NEXT:    [[TMP49:%.*]] = tail call i64 @llvm.vector.reduce.add.v2i64(<2 x i64> [[BIN_RDX43]])
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1008
; CHECK-NEXT:    [[TMP50:%.*]] = load i64, i64* [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i64 [[TMP50]], 1008
; CHECK-NEXT:    store i64 [[ADD]], i64* [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[ADD2:%.*]] = add nsw i64 [[ADD]], [[TMP49]]
; CHECK-NEXT:    [[ARRAYIDX_1:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1009
; CHECK-NEXT:    [[TMP51:%.*]] = load i64, i64* [[ARRAYIDX_1]], align 8
; CHECK-NEXT:    [[ADD_1:%.*]] = add nsw i64 [[TMP51]], 1009
; CHECK-NEXT:    store i64 [[ADD_1]], i64* [[ARRAYIDX_1]], align 8
; CHECK-NEXT:    [[ADD2_1:%.*]] = add nsw i64 [[ADD_1]], [[ADD2]]
; CHECK-NEXT:    [[ARRAYIDX_2:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1010
; CHECK-NEXT:    [[TMP52:%.*]] = load i64, i64* [[ARRAYIDX_2]], align 8
; CHECK-NEXT:    [[ADD_2:%.*]] = add nsw i64 [[TMP52]], 1010
; CHECK-NEXT:    store i64 [[ADD_2]], i64* [[ARRAYIDX_2]], align 8
; CHECK-NEXT:    [[ADD2_2:%.*]] = add nsw i64 [[ADD_2]], [[ADD2_1]]
; CHECK-NEXT:    [[ARRAYIDX_3:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1011
; CHECK-NEXT:    [[TMP53:%.*]] = load i64, i64* [[ARRAYIDX_3]], align 8
; CHECK-NEXT:    [[ADD_3:%.*]] = add nsw i64 [[TMP53]], 1011
; CHECK-NEXT:    store i64 [[ADD_3]], i64* [[ARRAYIDX_3]], align 8
; CHECK-NEXT:    [[ADD2_3:%.*]] = add nsw i64 [[ADD_3]], [[ADD2_2]]
; CHECK-NEXT:    [[ARRAYIDX_4:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1012
; CHECK-NEXT:    [[TMP54:%.*]] = load i64, i64* [[ARRAYIDX_4]], align 8
; CHECK-NEXT:    [[ADD_4:%.*]] = add nsw i64 [[TMP54]], 1012
; CHECK-NEXT:    store i64 [[ADD_4]], i64* [[ARRAYIDX_4]], align 8
; CHECK-NEXT:    [[ADD2_4:%.*]] = add nsw i64 [[ADD_4]], [[ADD2_3]]
; CHECK-NEXT:    [[ARRAYIDX_5:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1013
; CHECK-NEXT:    [[TMP55:%.*]] = load i64, i64* [[ARRAYIDX_5]], align 8
; CHECK-NEXT:    [[ADD_5:%.*]] = add nsw i64 [[TMP55]], 1013
; CHECK-NEXT:    store i64 [[ADD_5]], i64* [[ARRAYIDX_5]], align 8
; CHECK-NEXT:    [[ADD2_5:%.*]] = add nsw i64 [[ADD_5]], [[ADD2_4]]
; CHECK-NEXT:    [[ARRAYIDX_6:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1014
; CHECK-NEXT:    [[TMP56:%.*]] = load i64, i64* [[ARRAYIDX_6]], align 8
; CHECK-NEXT:    [[ADD_6:%.*]] = add nsw i64 [[TMP56]], 1014
; CHECK-NEXT:    store i64 [[ADD_6]], i64* [[ARRAYIDX_6]], align 8
; CHECK-NEXT:    [[ADD2_6:%.*]] = add nsw i64 [[ADD_6]], [[ADD2_5]]
; CHECK-NEXT:    [[ARRAYIDX_7:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1015
; CHECK-NEXT:    [[TMP57:%.*]] = load i64, i64* [[ARRAYIDX_7]], align 8
; CHECK-NEXT:    [[ADD_7:%.*]] = add nsw i64 [[TMP57]], 1015
; CHECK-NEXT:    store i64 [[ADD_7]], i64* [[ARRAYIDX_7]], align 8
; CHECK-NEXT:    [[ADD2_7:%.*]] = add nsw i64 [[ADD_7]], [[ADD2_6]]
; CHECK-NEXT:    [[ARRAYIDX_8:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1016
; CHECK-NEXT:    [[TMP58:%.*]] = load i64, i64* [[ARRAYIDX_8]], align 8
; CHECK-NEXT:    [[ADD_8:%.*]] = add nsw i64 [[TMP58]], 1016
; CHECK-NEXT:    store i64 [[ADD_8]], i64* [[ARRAYIDX_8]], align 8
; CHECK-NEXT:    [[ADD2_8:%.*]] = add nsw i64 [[ADD_8]], [[ADD2_7]]
; CHECK-NEXT:    [[ARRAYIDX_9:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1017
; CHECK-NEXT:    [[TMP59:%.*]] = load i64, i64* [[ARRAYIDX_9]], align 8
; CHECK-NEXT:    [[ADD_9:%.*]] = add nsw i64 [[TMP59]], 1017
; CHECK-NEXT:    store i64 [[ADD_9]], i64* [[ARRAYIDX_9]], align 8
; CHECK-NEXT:    [[ADD2_9:%.*]] = add nsw i64 [[ADD_9]], [[ADD2_8]]
; CHECK-NEXT:    [[ARRAYIDX_10:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1018
; CHECK-NEXT:    [[TMP60:%.*]] = load i64, i64* [[ARRAYIDX_10]], align 8
; CHECK-NEXT:    [[ADD_10:%.*]] = add nsw i64 [[TMP60]], 1018
; CHECK-NEXT:    store i64 [[ADD_10]], i64* [[ARRAYIDX_10]], align 8
; CHECK-NEXT:    [[ADD2_10:%.*]] = add nsw i64 [[ADD_10]], [[ADD2_9]]
; CHECK-NEXT:    [[ARRAYIDX_11:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1019
; CHECK-NEXT:    [[TMP61:%.*]] = load i64, i64* [[ARRAYIDX_11]], align 8
; CHECK-NEXT:    [[ADD_11:%.*]] = add nsw i64 [[TMP61]], 1019
; CHECK-NEXT:    store i64 [[ADD_11]], i64* [[ARRAYIDX_11]], align 8
; CHECK-NEXT:    [[ADD2_11:%.*]] = add nsw i64 [[ADD_11]], [[ADD2_10]]
; CHECK-NEXT:    [[ARRAYIDX_12:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1020
; CHECK-NEXT:    [[TMP62:%.*]] = load i64, i64* [[ARRAYIDX_12]], align 8
; CHECK-NEXT:    [[ADD_12:%.*]] = add nsw i64 [[TMP62]], 1020
; CHECK-NEXT:    store i64 [[ADD_12]], i64* [[ARRAYIDX_12]], align 8
; CHECK-NEXT:    [[ADD2_12:%.*]] = add nsw i64 [[ADD_12]], [[ADD2_11]]
; CHECK-NEXT:    [[ARRAYIDX_13:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1021
; CHECK-NEXT:    [[TMP63:%.*]] = load i64, i64* [[ARRAYIDX_13]], align 8
; CHECK-NEXT:    [[ADD_13:%.*]] = add nsw i64 [[TMP63]], 1021
; CHECK-NEXT:    store i64 [[ADD_13]], i64* [[ARRAYIDX_13]], align 8
; CHECK-NEXT:    [[ADD2_13:%.*]] = add nsw i64 [[ADD_13]], [[ADD2_12]]
; CHECK-NEXT:    [[ARRAYIDX_14:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1022
; CHECK-NEXT:    [[TMP64:%.*]] = load i64, i64* [[ARRAYIDX_14]], align 8
; CHECK-NEXT:    [[ADD_14:%.*]] = add nsw i64 [[TMP64]], 1022
; CHECK-NEXT:    store i64 [[ADD_14]], i64* [[ARRAYIDX_14]], align 8
; CHECK-NEXT:    [[ADD2_14:%.*]] = add nsw i64 [[ADD_14]], [[ADD2_13]]
; CHECK-NEXT:    [[ARRAYIDX_15:%.*]] = getelementptr inbounds i64, i64* [[A]], i64 1023
; CHECK-NEXT:    [[TMP65:%.*]] = load i64, i64* [[ARRAYIDX_15]], align 8
; CHECK-NEXT:    [[ADD_15:%.*]] = add nsw i64 [[TMP65]], 1023
; CHECK-NEXT:    store i64 [[ADD_15]], i64* [[ARRAYIDX_15]], align 8
; CHECK-NEXT:    [[ADD2_15:%.*]] = add nsw i64 [[ADD_15]], [[ADD2_14]]
; CHECK-NEXT:    ret i64 [[ADD2_15]]
;


entry:
  br label %for.body

for.cond.cleanup:
  %add2.lcssa = phi i64 [ %add2, %for.body ]
  ret i64 %add2.lcssa

for.body:
  %i.012 = phi i64 [ 0, %entry ], [ %inc, %for.body ]
  %s.011 = phi i64 [ 0, %entry ], [ %add2, %for.body ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %i.012
  %0 = load i64, i64* %arrayidx, align 8
  %add = add nsw i64 %0, %i.012
  store i64 %add, i64* %arrayidx, align 8
  %add2 = add nsw i64 %add, %s.011
  %inc = add nuw nsw i64 %i.012, 1
  %exitcond = icmp eq i64 %inc, 1024
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

@d = external global [0 x i64], align 8
@e = external global [0 x i32], align 4
@c = external global [0 x i32], align 4

define void @hoo(i32 %n) {
; CHECK-LABEL: @hoo(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[INDUCTION1:%.*]] = or i64 [[INDEX]], 1
; CHECK-NEXT:    [[INDUCTION2:%.*]] = or i64 [[INDEX]], 2
; CHECK-NEXT:    [[INDUCTION3:%.*]] = or i64 [[INDEX]], 3
; CHECK-NEXT:    [[INDUCTION4:%.*]] = add nuw nsw i64 [[INDEX]], 4
; CHECK-NEXT:    [[INDUCTION5:%.*]] = add nuw nsw i64 [[INDEX]], 5
; CHECK-NEXT:    [[INDUCTION6:%.*]] = add nuw nsw i64 [[INDEX]], 6
; CHECK-NEXT:    [[INDUCTION7:%.*]] = add nuw nsw i64 [[INDEX]], 7
; CHECK-NEXT:    [[INDUCTION8:%.*]] = add nuw nsw i64 [[INDEX]], 8
; CHECK-NEXT:    [[INDUCTION9:%.*]] = add nuw nsw i64 [[INDEX]], 9
; CHECK-NEXT:    [[INDUCTION10:%.*]] = add nuw nsw i64 [[INDEX]], 10
; CHECK-NEXT:    [[INDUCTION11:%.*]] = add nuw nsw i64 [[INDEX]], 11
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDEX]]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION1]]
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION2]]
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION3]]
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION4]]
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION5]]
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION6]]
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION7]]
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION8]]
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION9]]
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION10]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 [[INDUCTION11]]
; CHECK-NEXT:    [[TMP12:%.*]] = load i64, i64* [[TMP0]], align 8
; CHECK-NEXT:    [[TMP13:%.*]] = load i64, i64* [[TMP1]], align 8
; CHECK-NEXT:    [[TMP14:%.*]] = load i64, i64* [[TMP2]], align 8
; CHECK-NEXT:    [[TMP15:%.*]] = load i64, i64* [[TMP3]], align 8
; CHECK-NEXT:    [[TMP16:%.*]] = load i64, i64* [[TMP4]], align 8
; CHECK-NEXT:    [[TMP17:%.*]] = load i64, i64* [[TMP5]], align 8
; CHECK-NEXT:    [[TMP18:%.*]] = load i64, i64* [[TMP6]], align 8
; CHECK-NEXT:    [[TMP19:%.*]] = load i64, i64* [[TMP7]], align 8
; CHECK-NEXT:    [[TMP20:%.*]] = load i64, i64* [[TMP8]], align 8
; CHECK-NEXT:    [[TMP21:%.*]] = load i64, i64* [[TMP9]], align 8
; CHECK-NEXT:    [[TMP22:%.*]] = load i64, i64* [[TMP10]], align 8
; CHECK-NEXT:    [[TMP23:%.*]] = load i64, i64* [[TMP11]], align 8
; CHECK-NEXT:    [[TMP24:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP12]]
; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP13]]
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP14]]
; CHECK-NEXT:    [[TMP27:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP15]]
; CHECK-NEXT:    [[TMP28:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP16]]
; CHECK-NEXT:    [[TMP29:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP17]]
; CHECK-NEXT:    [[TMP30:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP18]]
; CHECK-NEXT:    [[TMP31:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP19]]
; CHECK-NEXT:    [[TMP32:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP20]]
; CHECK-NEXT:    [[TMP33:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP21]]
; CHECK-NEXT:    [[TMP34:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP22]]
; CHECK-NEXT:    [[TMP35:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP23]]
; CHECK-NEXT:    [[TMP36:%.*]] = load i32, i32* [[TMP24]], align 4
; CHECK-NEXT:    [[TMP37:%.*]] = load i32, i32* [[TMP25]], align 4
; CHECK-NEXT:    [[TMP38:%.*]] = load i32, i32* [[TMP26]], align 4
; CHECK-NEXT:    [[TMP39:%.*]] = load i32, i32* [[TMP27]], align 4
; CHECK-NEXT:    [[TMP40:%.*]] = load i32, i32* [[TMP28]], align 4
; CHECK-NEXT:    [[TMP41:%.*]] = load i32, i32* [[TMP29]], align 4
; CHECK-NEXT:    [[TMP42:%.*]] = load i32, i32* [[TMP30]], align 4
; CHECK-NEXT:    [[TMP43:%.*]] = load i32, i32* [[TMP31]], align 4
; CHECK-NEXT:    [[TMP44:%.*]] = load i32, i32* [[TMP32]], align 4
; CHECK-NEXT:    [[TMP45:%.*]] = load i32, i32* [[TMP33]], align 4
; CHECK-NEXT:    [[TMP46:%.*]] = load i32, i32* [[TMP34]], align 4
; CHECK-NEXT:    [[TMP47:%.*]] = load i32, i32* [[TMP35]], align 4
; CHECK-NEXT:    [[TMP48:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDEX]]
; CHECK-NEXT:    [[TMP49:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION1]]
; CHECK-NEXT:    [[TMP50:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION2]]
; CHECK-NEXT:    [[TMP51:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION3]]
; CHECK-NEXT:    [[TMP52:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION4]]
; CHECK-NEXT:    [[TMP53:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION5]]
; CHECK-NEXT:    [[TMP54:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION6]]
; CHECK-NEXT:    [[TMP55:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION7]]
; CHECK-NEXT:    [[TMP56:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION8]]
; CHECK-NEXT:    [[TMP57:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION9]]
; CHECK-NEXT:    [[TMP58:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION10]]
; CHECK-NEXT:    [[TMP59:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 [[INDUCTION11]]
; CHECK-NEXT:    store i32 [[TMP36]], i32* [[TMP48]], align 4
; CHECK-NEXT:    store i32 [[TMP37]], i32* [[TMP49]], align 4
; CHECK-NEXT:    store i32 [[TMP38]], i32* [[TMP50]], align 4
; CHECK-NEXT:    store i32 [[TMP39]], i32* [[TMP51]], align 4
; CHECK-NEXT:    store i32 [[TMP40]], i32* [[TMP52]], align 4
; CHECK-NEXT:    store i32 [[TMP41]], i32* [[TMP53]], align 4
; CHECK-NEXT:    store i32 [[TMP42]], i32* [[TMP54]], align 4
; CHECK-NEXT:    store i32 [[TMP43]], i32* [[TMP55]], align 4
; CHECK-NEXT:    store i32 [[TMP44]], i32* [[TMP56]], align 4
; CHECK-NEXT:    store i32 [[TMP45]], i32* [[TMP57]], align 4
; CHECK-NEXT:    store i32 [[TMP46]], i32* [[TMP58]], align 4
; CHECK-NEXT:    store i32 [[TMP47]], i32* [[TMP59]], align 4
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw nsw i64 [[INDEX]], 12
; CHECK-NEXT:    [[TMP60:%.*]] = icmp eq i64 [[INDEX_NEXT]], 9996
; CHECK-NEXT:    br i1 [[TMP60]], label [[FOR_BODY_PREHEADER:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; CHECK:       for.body.preheader:
; CHECK-NEXT:    [[TMP:%.*]] = load i64, i64* getelementptr inbounds ([0 x i64], [0 x i64]* @d, i64 0, i64 9996), align 8
; CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[ARRAYIDX1]], align 4
; CHECK-NEXT:    store i32 [[TMP1]], i32* getelementptr inbounds ([0 x i32], [0 x i32]* @c, i64 0, i64 9996), align 4
; CHECK-NEXT:    [[TMP_1:%.*]] = load i64, i64* getelementptr inbounds ([0 x i64], [0 x i64]* @d, i64 0, i64 9997), align 8
; CHECK-NEXT:    [[ARRAYIDX1_1:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP_1]]
; CHECK-NEXT:    [[TMP1_1:%.*]] = load i32, i32* [[ARRAYIDX1_1]], align 4
; CHECK-NEXT:    store i32 [[TMP1_1]], i32* getelementptr inbounds ([0 x i32], [0 x i32]* @c, i64 0, i64 9997), align 4
; CHECK-NEXT:    [[TMP_2:%.*]] = load i64, i64* getelementptr inbounds ([0 x i64], [0 x i64]* @d, i64 0, i64 9998), align 8
; CHECK-NEXT:    [[ARRAYIDX1_2:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP_2]]
; CHECK-NEXT:    [[TMP1_2:%.*]] = load i32, i32* [[ARRAYIDX1_2]], align 4
; CHECK-NEXT:    store i32 [[TMP1_2]], i32* getelementptr inbounds ([0 x i32], [0 x i32]* @c, i64 0, i64 9998), align 4
; CHECK-NEXT:    [[TMP_3:%.*]] = load i64, i64* getelementptr inbounds ([0 x i64], [0 x i64]* @d, i64 0, i64 9999), align 8
; CHECK-NEXT:    [[ARRAYIDX1_3:%.*]] = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 [[TMP_3]]
; CHECK-NEXT:    [[TMP1_3:%.*]] = load i32, i32* [[ARRAYIDX1_3]], align 4
; CHECK-NEXT:    store i32 [[TMP1_3]], i32* getelementptr inbounds ([0 x i32], [0 x i32]* @c, i64 0, i64 9999), align 4
; CHECK-NEXT:    ret void
;

entry:
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [0 x i64], [0 x i64]* @d, i64 0, i64 %indvars.iv
  %tmp = load i64, i64* %arrayidx, align 8
  %arrayidx1 = getelementptr inbounds [0 x i32], [0 x i32]* @e, i64 0, i64 %tmp
  %tmp1 = load i32, i32* %arrayidx1, align 4
  %arrayidx3 = getelementptr inbounds [0 x i32], [0 x i32]* @c, i64 0, i64 %indvars.iv
  store i32 %tmp1, i32* %arrayidx3, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 10000
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  ret void
}

define float @float_(float* nocapture readonly %a, float* nocapture readonly %b, i32 %n) {
; CHECK-LABEL: @float_(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[N:%.*]], 0
; CHECK-NEXT:    br i1 [[CMP]], label [[PREHEADER:%.*]], label [[FOR_END:%.*]]
; CHECK:       preheader:
; CHECK-NEXT:    [[T033:%.*]] = zext i32 [[N]] to i64
; CHECK-NEXT:    [[TMP0:%.*]] = add nsw i64 [[T033]], -1
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[TMP0]], 352
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[FOR_PREHEADER:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TMP1:%.*]] = lshr i64 [[TMP0]], 5
; CHECK-NEXT:    [[TMP2:%.*]] = add nuw nsw i64 [[TMP1]], 1
; CHECK-NEXT:    [[N_MOD_VF_LHS_TRUNC:%.*]] = trunc i64 [[TMP2]] to i32
; CHECK-NEXT:    [[N_MOD_VF34:%.*]] = urem i32 [[N_MOD_VF_LHS_TRUNC]], 12
; CHECK-NEXT:    [[N_MOD_VF_ZEXT:%.*]] = zext i32 [[N_MOD_VF34]] to i64
; CHECK-NEXT:    [[N_VEC:%.*]] = sub nuw nsw i64 [[TMP2]], [[N_MOD_VF_ZEXT]]
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP63:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI1:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP64:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI2:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP65:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI3:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP66:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI4:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP67:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI5:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP68:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI6:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP69:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI7:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP70:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI8:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP71:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI9:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP72:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI10:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP73:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI11:%.*]] = phi float [ 0.000000e+00, [[VECTOR_PH]] ], [ [[TMP74:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[OFFSET_IDX:%.*]] = shl i64 [[INDEX]], 5
; CHECK-NEXT:    [[INDUCTION12:%.*]] = or i64 [[OFFSET_IDX]], 32
; CHECK-NEXT:    [[INDUCTION13:%.*]] = or i64 [[OFFSET_IDX]], 64
; CHECK-NEXT:    [[INDUCTION14:%.*]] = or i64 [[OFFSET_IDX]], 96
; CHECK-NEXT:    [[INDUCTION15:%.*]] = add i64 [[OFFSET_IDX]], 128
; CHECK-NEXT:    [[INDUCTION16:%.*]] = add i64 [[OFFSET_IDX]], 160
; CHECK-NEXT:    [[INDUCTION17:%.*]] = add i64 [[OFFSET_IDX]], 192
; CHECK-NEXT:    [[INDUCTION18:%.*]] = add i64 [[OFFSET_IDX]], 224
; CHECK-NEXT:    [[INDUCTION19:%.*]] = add i64 [[OFFSET_IDX]], 256
; CHECK-NEXT:    [[INDUCTION20:%.*]] = add i64 [[OFFSET_IDX]], 288
; CHECK-NEXT:    [[INDUCTION21:%.*]] = add i64 [[OFFSET_IDX]], 320
; CHECK-NEXT:    [[INDUCTION22:%.*]] = add i64 [[OFFSET_IDX]], 352
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds float, float* [[A:%.*]], i64 [[OFFSET_IDX]]
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION12]]
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION13]]
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION14]]
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION15]]
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION16]]
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION17]]
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION18]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION19]]
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION20]]
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION21]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDUCTION22]]
; CHECK-NEXT:    [[TMP15:%.*]] = load float, float* [[TMP3]], align 4
; CHECK-NEXT:    [[TMP16:%.*]] = load float, float* [[TMP4]], align 4
; CHECK-NEXT:    [[TMP17:%.*]] = load float, float* [[TMP5]], align 4
; CHECK-NEXT:    [[TMP18:%.*]] = load float, float* [[TMP6]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = load float, float* [[TMP7]], align 4
; CHECK-NEXT:    [[TMP20:%.*]] = load float, float* [[TMP8]], align 4
; CHECK-NEXT:    [[TMP21:%.*]] = load float, float* [[TMP9]], align 4
; CHECK-NEXT:    [[TMP22:%.*]] = load float, float* [[TMP10]], align 4
; CHECK-NEXT:    [[TMP23:%.*]] = load float, float* [[TMP11]], align 4
; CHECK-NEXT:    [[TMP24:%.*]] = load float, float* [[TMP12]], align 4
; CHECK-NEXT:    [[TMP25:%.*]] = load float, float* [[TMP13]], align 4
; CHECK-NEXT:    [[TMP26:%.*]] = load float, float* [[TMP14]], align 4
; CHECK-NEXT:    [[TMP27:%.*]] = getelementptr inbounds float, float* [[B:%.*]], i64 [[OFFSET_IDX]]
; CHECK-NEXT:    [[TMP28:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION12]]
; CHECK-NEXT:    [[TMP29:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION13]]
; CHECK-NEXT:    [[TMP30:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION14]]
; CHECK-NEXT:    [[TMP31:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION15]]
; CHECK-NEXT:    [[TMP32:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION16]]
; CHECK-NEXT:    [[TMP33:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION17]]
; CHECK-NEXT:    [[TMP34:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION18]]
; CHECK-NEXT:    [[TMP35:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION19]]
; CHECK-NEXT:    [[TMP36:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION20]]
; CHECK-NEXT:    [[TMP37:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION21]]
; CHECK-NEXT:    [[TMP38:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDUCTION22]]
; CHECK-NEXT:    [[TMP39:%.*]] = load float, float* [[TMP27]], align 4
; CHECK-NEXT:    [[TMP40:%.*]] = load float, float* [[TMP28]], align 4
; CHECK-NEXT:    [[TMP41:%.*]] = load float, float* [[TMP29]], align 4
; CHECK-NEXT:    [[TMP42:%.*]] = load float, float* [[TMP30]], align 4
; CHECK-NEXT:    [[TMP43:%.*]] = load float, float* [[TMP31]], align 4
; CHECK-NEXT:    [[TMP44:%.*]] = load float, float* [[TMP32]], align 4
; CHECK-NEXT:    [[TMP45:%.*]] = load float, float* [[TMP33]], align 4
; CHECK-NEXT:    [[TMP46:%.*]] = load float, float* [[TMP34]], align 4
; CHECK-NEXT:    [[TMP47:%.*]] = load float, float* [[TMP35]], align 4
; CHECK-NEXT:    [[TMP48:%.*]] = load float, float* [[TMP36]], align 4
; CHECK-NEXT:    [[TMP49:%.*]] = load float, float* [[TMP37]], align 4
; CHECK-NEXT:    [[TMP50:%.*]] = load float, float* [[TMP38]], align 4
; CHECK-NEXT:    [[TMP51:%.*]] = fadd fast float [[TMP15]], [[VEC_PHI]]
; CHECK-NEXT:    [[TMP52:%.*]] = fadd fast float [[TMP16]], [[VEC_PHI1]]
; CHECK-NEXT:    [[TMP53:%.*]] = fadd fast float [[TMP17]], [[VEC_PHI2]]
; CHECK-NEXT:    [[TMP54:%.*]] = fadd fast float [[TMP18]], [[VEC_PHI3]]
; CHECK-NEXT:    [[TMP55:%.*]] = fadd fast float [[TMP19]], [[VEC_PHI4]]
; CHECK-NEXT:    [[TMP56:%.*]] = fadd fast float [[TMP20]], [[VEC_PHI5]]
; CHECK-NEXT:    [[TMP57:%.*]] = fadd fast float [[TMP21]], [[VEC_PHI6]]
; CHECK-NEXT:    [[TMP58:%.*]] = fadd fast float [[TMP22]], [[VEC_PHI7]]
; CHECK-NEXT:    [[TMP59:%.*]] = fadd fast float [[TMP23]], [[VEC_PHI8]]
; CHECK-NEXT:    [[TMP60:%.*]] = fadd fast float [[TMP24]], [[VEC_PHI9]]
; CHECK-NEXT:    [[TMP61:%.*]] = fadd fast float [[TMP25]], [[VEC_PHI10]]
; CHECK-NEXT:    [[TMP62:%.*]] = fadd fast float [[TMP26]], [[VEC_PHI11]]
; CHECK-NEXT:    [[TMP63]] = fadd fast float [[TMP51]], [[TMP39]]
; CHECK-NEXT:    [[TMP64]] = fadd fast float [[TMP52]], [[TMP40]]
; CHECK-NEXT:    [[TMP65]] = fadd fast float [[TMP53]], [[TMP41]]
; CHECK-NEXT:    [[TMP66]] = fadd fast float [[TMP54]], [[TMP42]]
; CHECK-NEXT:    [[TMP67]] = fadd fast float [[TMP55]], [[TMP43]]
; CHECK-NEXT:    [[TMP68]] = fadd fast float [[TMP56]], [[TMP44]]
; CHECK-NEXT:    [[TMP69]] = fadd fast float [[TMP57]], [[TMP45]]
; CHECK-NEXT:    [[TMP70]] = fadd fast float [[TMP58]], [[TMP46]]
; CHECK-NEXT:    [[TMP71]] = fadd fast float [[TMP59]], [[TMP47]]
; CHECK-NEXT:    [[TMP72]] = fadd fast float [[TMP60]], [[TMP48]]
; CHECK-NEXT:    [[TMP73]] = fadd fast float [[TMP61]], [[TMP49]]
; CHECK-NEXT:    [[TMP74]] = fadd fast float [[TMP62]], [[TMP50]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 12
; CHECK-NEXT:    [[TMP75:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP75]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP5:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    [[IND_END:%.*]] = shl nuw nsw i64 [[N_VEC]], 5
; CHECK-NEXT:    [[BIN_RDX:%.*]] = fadd fast float [[TMP64]], [[TMP63]]
; CHECK-NEXT:    [[BIN_RDX23:%.*]] = fadd fast float [[BIN_RDX]], [[TMP65]]
; CHECK-NEXT:    [[BIN_RDX24:%.*]] = fadd fast float [[BIN_RDX23]], [[TMP66]]
; CHECK-NEXT:    [[BIN_RDX25:%.*]] = fadd fast float [[BIN_RDX24]], [[TMP67]]
; CHECK-NEXT:    [[BIN_RDX26:%.*]] = fadd fast float [[BIN_RDX25]], [[TMP68]]
; CHECK-NEXT:    [[BIN_RDX27:%.*]] = fadd fast float [[BIN_RDX26]], [[TMP69]]
; CHECK-NEXT:    [[BIN_RDX28:%.*]] = fadd fast float [[BIN_RDX27]], [[TMP70]]
; CHECK-NEXT:    [[BIN_RDX29:%.*]] = fadd fast float [[BIN_RDX28]], [[TMP71]]
; CHECK-NEXT:    [[BIN_RDX30:%.*]] = fadd fast float [[BIN_RDX29]], [[TMP72]]
; CHECK-NEXT:    [[BIN_RDX31:%.*]] = fadd fast float [[BIN_RDX30]], [[TMP73]]
; CHECK-NEXT:    [[BIN_RDX32:%.*]] = fadd fast float [[BIN_RDX31]], [[TMP74]]
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i32 [[N_MOD_VF34]], 0
; CHECK-NEXT:    br i1 [[CMP_N]], label [[FOR_END]], label [[FOR_PREHEADER]]
; CHECK:       for.preheader:
; CHECK-NEXT:    [[INDVARS_IV_PH:%.*]] = phi i64 [ 0, [[PREHEADER]] ], [ [[IND_END]], [[MIDDLE_BLOCK]] ]
; CHECK-NEXT:    [[S_02_PH:%.*]] = phi float [ 0.000000e+00, [[PREHEADER]] ], [ [[BIN_RDX32]], [[MIDDLE_BLOCK]] ]
; CHECK-NEXT:    br label [[FOR:%.*]]
; CHECK:       for:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR]] ], [ [[INDVARS_IV_PH]], [[FOR_PREHEADER]] ]
; CHECK-NEXT:    [[S_02:%.*]] = phi float [ [[ADD4:%.*]], [[FOR]] ], [ [[S_02_PH]], [[FOR_PREHEADER]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, float* [[A]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[T1:%.*]] = load float, float* [[ARRAYIDX]], align 4
; CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds float, float* [[B]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[T2:%.*]] = load float, float* [[ARRAYIDX3]], align 4
; CHECK-NEXT:    [[ADD:%.*]] = fadd fast float [[T1]], [[S_02]]
; CHECK-NEXT:    [[ADD4]] = fadd fast float [[ADD]], [[T2]]
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 32
; CHECK-NEXT:    [[CMP1:%.*]] = icmp slt i64 [[INDVARS_IV_NEXT]], [[T033]]
; CHECK-NEXT:    br i1 [[CMP1]], label [[FOR]], label [[FOR_END]], !llvm.loop [[LOOP6:![0-9]+]]
; CHECK:       for.end:
; CHECK-NEXT:    [[S_0_LCSSA:%.*]] = phi float [ 0.000000e+00, [[ENTRY:%.*]] ], [ [[BIN_RDX32]], [[MIDDLE_BLOCK]] ], [ [[ADD4]], [[FOR]] ]
; CHECK-NEXT:    ret float [[S_0_LCSSA]]
;

entry:
  %cmp = icmp sgt i32 %n, 0
  br i1 %cmp, label %preheader, label %for.end

preheader:
  %t0 = sext i32 %n to i64
  br label %for

for:
  %indvars.iv = phi i64 [ 0, %preheader ], [ %indvars.iv.next, %for ]
  %s.02 = phi float [ 0.0, %preheader ], [ %add4, %for ]
  %arrayidx = getelementptr inbounds float, float* %a, i64 %indvars.iv
  %t1 = load float, float* %arrayidx, align 4
  %arrayidx3 = getelementptr inbounds float, float* %b, i64 %indvars.iv
  %t2 = load float, float* %arrayidx3, align 4
  %add = fadd fast float %t1, %s.02
  %add4 = fadd fast float %add, %t2
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 32
  %cmp1 = icmp slt i64 %indvars.iv.next, %t0
  br i1 %cmp1, label %for, label %loopexit

loopexit:
  %add4.lcssa = phi float [ %add4, %for ]
  br label %for.end

for.end:
  %s.0.lcssa = phi float [ 0.0, %entry ], [ %add4.lcssa, %loopexit ]
  ret float %s.0.lcssa
}


define void @double_(double* nocapture %A, i32 %n) nounwind uwtable ssp {
; CHECK-PWR8-LABEL: @double_(
; CHECK-PWR8-NEXT:    [[TMP1:%.*]] = sext i32 [[N:%.*]] to i64
; CHECK-PWR8-NEXT:    [[TMP2:%.*]] = zext i32 [[N]] to i64
; CHECK-PWR8-NEXT:    [[TMP3:%.*]] = add nuw nsw i64 [[TMP2]], 1
; CHECK-PWR8-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp eq i32 [[N]], 0
; CHECK-PWR8-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[SCALAR_PH_PREHEADER:%.*]], label [[VECTOR_PH:%.*]]
; CHECK-PWR8:       vector.ph:
; CHECK-PWR8-NEXT:    [[N_VEC:%.*]] = and i64 [[TMP3]], 8589934590
; CHECK-PWR8-NEXT:    [[TMP4:%.*]] = getelementptr inbounds double, double* [[A:%.*]], i64 -1
; CHECK-PWR8-NEXT:    [[TMP5:%.*]] = add nsw i64 [[N_VEC]], -2
; CHECK-PWR8-NEXT:    [[TMP6:%.*]] = lshr exact i64 [[TMP5]], 1
; CHECK-PWR8-NEXT:    [[TMP7:%.*]] = add nuw i64 [[TMP6]], 1
; CHECK-PWR8-NEXT:    [[XTRAITER:%.*]] = and i64 [[TMP7]], 1
; CHECK-PWR8-NEXT:    [[TMP8:%.*]] = icmp eq i64 [[TMP5]], 0
; CHECK-PWR8-NEXT:    br i1 [[TMP8]], label [[MIDDLE_BLOCK_UNR_LCSSA:%.*]], label [[VECTOR_PH_NEW:%.*]]
; CHECK-PWR8:       vector.ph.new:
; CHECK-PWR8-NEXT:    [[UNROLL_ITER:%.*]] = and i64 [[TMP7]], -2
; CHECK-PWR8-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK-PWR8:       vector.body:
; CHECK-PWR8-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH_NEW]] ], [ [[INDEX_NEXT_1:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[NITER:%.*]] = phi i64 [ 0, [[VECTOR_PH_NEW]] ], [ [[NITER_NEXT_1:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[OFFSET_IDX:%.*]] = sub nsw i64 [[TMP1]], [[INDEX]]
; CHECK-PWR8-NEXT:    [[TMP9:%.*]] = getelementptr inbounds double, double* [[TMP4]], i64 [[OFFSET_IDX]]
; CHECK-PWR8-NEXT:    [[TMP10:%.*]] = bitcast double* [[TMP9]] to <2 x double>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD:%.*]] = load <2 x double>, <2 x double>* [[TMP10]], align 8
; CHECK-PWR8-NEXT:    [[REVERSE:%.*]] = shufflevector <2 x double> [[WIDE_LOAD]], <2 x double> poison, <2 x i32> <i32 1, i32 0>
; CHECK-PWR8-NEXT:    [[TMP11:%.*]] = fadd <2 x double> [[REVERSE]], <double 3.000000e+00, double 3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP12:%.*]] = fmul <2 x double> [[REVERSE]], <double 2.000000e+00, double 2.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP13:%.*]] = fadd <2 x double> [[TMP11]], [[TMP12]]
; CHECK-PWR8-NEXT:    [[TMP14:%.*]] = fadd <2 x double> [[TMP13]], <double 2.000000e+00, double 2.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP15:%.*]] = fmul <2 x double> [[TMP14]], <double 5.000000e-01, double 5.000000e-01>
; CHECK-PWR8-NEXT:    [[TMP16:%.*]] = fadd <2 x double> [[TMP12]], [[TMP15]]
; CHECK-PWR8-NEXT:    [[TMP17:%.*]] = fsub <2 x double> [[TMP16]], [[TMP11]]
; CHECK-PWR8-NEXT:    [[TMP18:%.*]] = fadd <2 x double> [[REVERSE]], [[TMP17]]
; CHECK-PWR8-NEXT:    [[TMP19:%.*]] = fdiv <2 x double> [[TMP14]], [[TMP18]]
; CHECK-PWR8-NEXT:    [[TMP20:%.*]] = fmul <2 x double> [[TMP14]], [[TMP19]]
; CHECK-PWR8-NEXT:    [[TMP21:%.*]] = fmul <2 x double> [[TMP12]], [[TMP20]]
; CHECK-PWR8-NEXT:    [[TMP22:%.*]] = fmul <2 x double> [[TMP11]], [[TMP21]]
; CHECK-PWR8-NEXT:    [[TMP23:%.*]] = fadd <2 x double> [[TMP22]], <double -3.000000e+00, double -3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP24:%.*]] = fsub <2 x double> [[REVERSE]], [[TMP11]]
; CHECK-PWR8-NEXT:    [[TMP25:%.*]] = fadd <2 x double> [[TMP12]], [[TMP24]]
; CHECK-PWR8-NEXT:    [[TMP26:%.*]] = fadd <2 x double> [[TMP25]], [[TMP19]]
; CHECK-PWR8-NEXT:    [[TMP27:%.*]] = fadd <2 x double> [[TMP26]], [[TMP23]]
; CHECK-PWR8-NEXT:    [[TMP28:%.*]] = fadd <2 x double> [[TMP27]], <double 3.000000e+00, double 3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP29:%.*]] = fmul <2 x double> [[REVERSE]], [[TMP28]]
; CHECK-PWR8-NEXT:    [[REVERSE1:%.*]] = shufflevector <2 x double> [[TMP29]], <2 x double> poison, <2 x i32> <i32 1, i32 0>
; CHECK-PWR8-NEXT:    store <2 x double> [[REVERSE1]], <2 x double>* [[TMP10]], align 8
; CHECK-PWR8-NEXT:    [[INDEX_NEXT:%.*]] = or i64 [[INDEX]], 2
; CHECK-PWR8-NEXT:    [[OFFSET_IDX_1:%.*]] = sub nsw i64 [[TMP1]], [[INDEX_NEXT]]
; CHECK-PWR8-NEXT:    [[TMP30:%.*]] = getelementptr inbounds double, double* [[TMP4]], i64 [[OFFSET_IDX_1]]
; CHECK-PWR8-NEXT:    [[TMP31:%.*]] = bitcast double* [[TMP30]] to <2 x double>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD_1:%.*]] = load <2 x double>, <2 x double>* [[TMP31]], align 8
; CHECK-PWR8-NEXT:    [[REVERSE_1:%.*]] = shufflevector <2 x double> [[WIDE_LOAD_1]], <2 x double> poison, <2 x i32> <i32 1, i32 0>
; CHECK-PWR8-NEXT:    [[TMP32:%.*]] = fadd <2 x double> [[REVERSE_1]], <double 3.000000e+00, double 3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP33:%.*]] = fmul <2 x double> [[REVERSE_1]], <double 2.000000e+00, double 2.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP34:%.*]] = fadd <2 x double> [[TMP32]], [[TMP33]]
; CHECK-PWR8-NEXT:    [[TMP35:%.*]] = fadd <2 x double> [[TMP34]], <double 2.000000e+00, double 2.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP36:%.*]] = fmul <2 x double> [[TMP35]], <double 5.000000e-01, double 5.000000e-01>
; CHECK-PWR8-NEXT:    [[TMP37:%.*]] = fadd <2 x double> [[TMP33]], [[TMP36]]
; CHECK-PWR8-NEXT:    [[TMP38:%.*]] = fsub <2 x double> [[TMP37]], [[TMP32]]
; CHECK-PWR8-NEXT:    [[TMP39:%.*]] = fadd <2 x double> [[REVERSE_1]], [[TMP38]]
; CHECK-PWR8-NEXT:    [[TMP40:%.*]] = fdiv <2 x double> [[TMP35]], [[TMP39]]
; CHECK-PWR8-NEXT:    [[TMP41:%.*]] = fmul <2 x double> [[TMP35]], [[TMP40]]
; CHECK-PWR8-NEXT:    [[TMP42:%.*]] = fmul <2 x double> [[TMP33]], [[TMP41]]
; CHECK-PWR8-NEXT:    [[TMP43:%.*]] = fmul <2 x double> [[TMP32]], [[TMP42]]
; CHECK-PWR8-NEXT:    [[TMP44:%.*]] = fadd <2 x double> [[TMP43]], <double -3.000000e+00, double -3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP45:%.*]] = fsub <2 x double> [[REVERSE_1]], [[TMP32]]
; CHECK-PWR8-NEXT:    [[TMP46:%.*]] = fadd <2 x double> [[TMP33]], [[TMP45]]
; CHECK-PWR8-NEXT:    [[TMP47:%.*]] = fadd <2 x double> [[TMP46]], [[TMP40]]
; CHECK-PWR8-NEXT:    [[TMP48:%.*]] = fadd <2 x double> [[TMP47]], [[TMP44]]
; CHECK-PWR8-NEXT:    [[TMP49:%.*]] = fadd <2 x double> [[TMP48]], <double 3.000000e+00, double 3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP50:%.*]] = fmul <2 x double> [[REVERSE_1]], [[TMP49]]
; CHECK-PWR8-NEXT:    [[REVERSE1_1:%.*]] = shufflevector <2 x double> [[TMP50]], <2 x double> poison, <2 x i32> <i32 1, i32 0>
; CHECK-PWR8-NEXT:    store <2 x double> [[REVERSE1_1]], <2 x double>* [[TMP31]], align 8
; CHECK-PWR8-NEXT:    [[INDEX_NEXT_1]] = add nuw nsw i64 [[INDEX]], 4
; CHECK-PWR8-NEXT:    [[NITER_NEXT_1]] = add nuw nsw i64 [[NITER]], 2
; CHECK-PWR8-NEXT:    [[NITER_NCMP_1:%.*]] = icmp eq i64 [[NITER_NEXT_1]], [[UNROLL_ITER]]
; CHECK-PWR8-NEXT:    br i1 [[NITER_NCMP_1]], label [[MIDDLE_BLOCK_UNR_LCSSA]], label [[VECTOR_BODY]], !llvm.loop [[LOOP7:![0-9]+]]
; CHECK-PWR8:       middle.block.unr-lcssa:
; CHECK-PWR8-NEXT:    [[INDEX_UNR:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT_1]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[LCMP_MOD_NOT:%.*]] = icmp eq i64 [[XTRAITER]], 0
; CHECK-PWR8-NEXT:    br i1 [[LCMP_MOD_NOT]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY_EPIL:%.*]]
; CHECK-PWR8:       vector.body.epil:
; CHECK-PWR8-NEXT:    [[OFFSET_IDX_EPIL:%.*]] = sub nsw i64 [[TMP1]], [[INDEX_UNR]]
; CHECK-PWR8-NEXT:    [[TMP51:%.*]] = getelementptr inbounds double, double* [[TMP4]], i64 [[OFFSET_IDX_EPIL]]
; CHECK-PWR8-NEXT:    [[TMP52:%.*]] = bitcast double* [[TMP51]] to <2 x double>*
; CHECK-PWR8-NEXT:    [[WIDE_LOAD_EPIL:%.*]] = load <2 x double>, <2 x double>* [[TMP52]], align 8
; CHECK-PWR8-NEXT:    [[REVERSE_EPIL:%.*]] = shufflevector <2 x double> [[WIDE_LOAD_EPIL]], <2 x double> poison, <2 x i32> <i32 1, i32 0>
; CHECK-PWR8-NEXT:    [[TMP53:%.*]] = fadd <2 x double> [[REVERSE_EPIL]], <double 3.000000e+00, double 3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP54:%.*]] = fmul <2 x double> [[REVERSE_EPIL]], <double 2.000000e+00, double 2.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP55:%.*]] = fadd <2 x double> [[TMP53]], [[TMP54]]
; CHECK-PWR8-NEXT:    [[TMP56:%.*]] = fadd <2 x double> [[TMP55]], <double 2.000000e+00, double 2.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP57:%.*]] = fmul <2 x double> [[TMP56]], <double 5.000000e-01, double 5.000000e-01>
; CHECK-PWR8-NEXT:    [[TMP58:%.*]] = fadd <2 x double> [[TMP54]], [[TMP57]]
; CHECK-PWR8-NEXT:    [[TMP59:%.*]] = fsub <2 x double> [[TMP58]], [[TMP53]]
; CHECK-PWR8-NEXT:    [[TMP60:%.*]] = fadd <2 x double> [[REVERSE_EPIL]], [[TMP59]]
; CHECK-PWR8-NEXT:    [[TMP61:%.*]] = fdiv <2 x double> [[TMP56]], [[TMP60]]
; CHECK-PWR8-NEXT:    [[TMP62:%.*]] = fmul <2 x double> [[TMP56]], [[TMP61]]
; CHECK-PWR8-NEXT:    [[TMP63:%.*]] = fmul <2 x double> [[TMP54]], [[TMP62]]
; CHECK-PWR8-NEXT:    [[TMP64:%.*]] = fmul <2 x double> [[TMP53]], [[TMP63]]
; CHECK-PWR8-NEXT:    [[TMP65:%.*]] = fadd <2 x double> [[TMP64]], <double -3.000000e+00, double -3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP66:%.*]] = fsub <2 x double> [[REVERSE_EPIL]], [[TMP53]]
; CHECK-PWR8-NEXT:    [[TMP67:%.*]] = fadd <2 x double> [[TMP54]], [[TMP66]]
; CHECK-PWR8-NEXT:    [[TMP68:%.*]] = fadd <2 x double> [[TMP67]], [[TMP61]]
; CHECK-PWR8-NEXT:    [[TMP69:%.*]] = fadd <2 x double> [[TMP68]], [[TMP65]]
; CHECK-PWR8-NEXT:    [[TMP70:%.*]] = fadd <2 x double> [[TMP69]], <double 3.000000e+00, double 3.000000e+00>
; CHECK-PWR8-NEXT:    [[TMP71:%.*]] = fmul <2 x double> [[REVERSE_EPIL]], [[TMP70]]
; CHECK-PWR8-NEXT:    [[REVERSE1_EPIL:%.*]] = shufflevector <2 x double> [[TMP71]], <2 x double> poison, <2 x i32> <i32 1, i32 0>
; CHECK-PWR8-NEXT:    store <2 x double> [[REVERSE1_EPIL]], <2 x double>* [[TMP52]], align 8
; CHECK-PWR8-NEXT:    br label [[MIDDLE_BLOCK]]
; CHECK-PWR8:       middle.block:
; CHECK-PWR8-NEXT:    [[IND_END:%.*]] = sub nsw i64 [[TMP1]], [[N_VEC]]
; CHECK-PWR8-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[TMP3]], [[N_VEC]]
; CHECK-PWR8-NEXT:    br i1 [[CMP_N]], label [[DOTLOOPEXIT:%.*]], label [[SCALAR_PH_PREHEADER]]
; CHECK-PWR8:       scalar.ph.preheader:
; CHECK-PWR8-NEXT:    [[INDVARS_IV_PH:%.*]] = phi i64 [ 0, [[TMP0:%.*]] ], [ [[IND_END]], [[MIDDLE_BLOCK]] ]
; CHECK-PWR8-NEXT:    br label [[SCALAR_PH:%.*]]
; CHECK-PWR8:       scalar.ph:
; CHECK-PWR8-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[SCALAR_PH]] ], [ [[INDVARS_IV_PH]], [[SCALAR_PH_PREHEADER]] ]
; CHECK-PWR8-NEXT:    [[TMP72:%.*]] = getelementptr inbounds double, double* [[A]], i64 [[INDVARS_IV]]
; CHECK-PWR8-NEXT:    [[TMP73:%.*]] = load double, double* [[TMP72]], align 8
; CHECK-PWR8-NEXT:    [[TMP74:%.*]] = fadd double [[TMP73]], 3.000000e+00
; CHECK-PWR8-NEXT:    [[TMP75:%.*]] = fmul double [[TMP73]], 2.000000e+00
; CHECK-PWR8-NEXT:    [[TMP76:%.*]] = fadd double [[TMP74]], [[TMP75]]
; CHECK-PWR8-NEXT:    [[TMP77:%.*]] = fadd double [[TMP76]], 2.000000e+00
; CHECK-PWR8-NEXT:    [[TMP78:%.*]] = fmul double [[TMP77]], 5.000000e-01
; CHECK-PWR8-NEXT:    [[TMP79:%.*]] = fadd double [[TMP75]], [[TMP78]]
; CHECK-PWR8-NEXT:    [[TMP80:%.*]] = fsub double [[TMP79]], [[TMP74]]
; CHECK-PWR8-NEXT:    [[TMP81:%.*]] = fadd double [[TMP73]], [[TMP80]]
; CHECK-PWR8-NEXT:    [[TMP82:%.*]] = fdiv double [[TMP77]], [[TMP81]]
; CHECK-PWR8-NEXT:    [[TMP83:%.*]] = fmul double [[TMP77]], [[TMP82]]
; CHECK-PWR8-NEXT:    [[TMP84:%.*]] = fmul double [[TMP75]], [[TMP83]]
; CHECK-PWR8-NEXT:    [[TMP85:%.*]] = fmul double [[TMP74]], [[TMP84]]
; CHECK-PWR8-NEXT:    [[TMP86:%.*]] = fadd double [[TMP85]], -3.000000e+00
; CHECK-PWR8-NEXT:    [[TMP87:%.*]] = fsub double [[TMP73]], [[TMP74]]
; CHECK-PWR8-NEXT:    [[TMP88:%.*]] = fadd double [[TMP75]], [[TMP87]]
; CHECK-PWR8-NEXT:    [[TMP89:%.*]] = fadd double [[TMP88]], [[TMP82]]
; CHECK-PWR8-NEXT:    [[TMP90:%.*]] = fadd double [[TMP89]], [[TMP86]]
; CHECK-PWR8-NEXT:    [[TMP91:%.*]] = fadd double [[TMP90]], 3.000000e+00
; CHECK-PWR8-NEXT:    [[TMP92:%.*]] = fmul double [[TMP73]], [[TMP91]]
; CHECK-PWR8-NEXT:    store double [[TMP92]], double* [[TMP72]], align 8
; CHECK-PWR8-NEXT:    [[INDVARS_IV_NEXT]] = add nsw i64 [[INDVARS_IV]], -1
; CHECK-PWR8-NEXT:    [[TMP93:%.*]] = trunc i64 [[INDVARS_IV]] to i32
; CHECK-PWR8-NEXT:    [[TMP94:%.*]] = icmp eq i32 [[TMP93]], 0
; CHECK-PWR8-NEXT:    br i1 [[TMP94]], label [[DOTLOOPEXIT]], label [[SCALAR_PH]], !llvm.loop [[LOOP8:![0-9]+]]
; CHECK-PWR8:       .loopexit:
; CHECK-PWR8-NEXT:    ret void
;
; CHECK-PWR9-LABEL: @double_(
; CHECK-PWR9-NEXT:    [[TMP1:%.*]] = sext i32 [[N:%.*]] to i64
; CHECK-PWR9-NEXT:    [[TMP2:%.*]] = and i32 [[N]], 1
; CHECK-PWR9-NEXT:    [[LCMP_MOD_NOT_NOT:%.*]] = icmp eq i32 [[TMP2]], 0
; CHECK-PWR9-NEXT:    br i1 [[LCMP_MOD_NOT_NOT]], label [[DOTPROL_LOOPEXIT_UNR_LCSSA:%.*]], label [[DOTPROL_LOOPEXIT:%.*]]
; CHECK-PWR9:       .prol.loopexit.unr-lcssa:
; CHECK-PWR9-NEXT:    [[TMP3:%.*]] = getelementptr inbounds double, double* [[A:%.*]], i64 [[TMP1]]
; CHECK-PWR9-NEXT:    [[TMP4:%.*]] = load double, double* [[TMP3]], align 8
; CHECK-PWR9-NEXT:    [[TMP5:%.*]] = fadd double [[TMP4]], 3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP6:%.*]] = fmul double [[TMP4]], 2.000000e+00
; CHECK-PWR9-NEXT:    [[TMP7:%.*]] = fadd double [[TMP5]], [[TMP6]]
; CHECK-PWR9-NEXT:    [[TMP8:%.*]] = fadd double [[TMP7]], 2.000000e+00
; CHECK-PWR9-NEXT:    [[TMP9:%.*]] = fmul double [[TMP8]], 5.000000e-01
; CHECK-PWR9-NEXT:    [[TMP10:%.*]] = fadd double [[TMP6]], [[TMP9]]
; CHECK-PWR9-NEXT:    [[TMP11:%.*]] = fsub double [[TMP10]], [[TMP5]]
; CHECK-PWR9-NEXT:    [[TMP12:%.*]] = fadd double [[TMP4]], [[TMP11]]
; CHECK-PWR9-NEXT:    [[TMP13:%.*]] = fdiv double [[TMP8]], [[TMP12]]
; CHECK-PWR9-NEXT:    [[TMP14:%.*]] = fmul double [[TMP8]], [[TMP13]]
; CHECK-PWR9-NEXT:    [[TMP15:%.*]] = fmul double [[TMP6]], [[TMP14]]
; CHECK-PWR9-NEXT:    [[TMP16:%.*]] = fmul double [[TMP5]], [[TMP15]]
; CHECK-PWR9-NEXT:    [[TMP17:%.*]] = fadd double [[TMP16]], -3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP18:%.*]] = fsub double [[TMP4]], [[TMP5]]
; CHECK-PWR9-NEXT:    [[TMP19:%.*]] = fadd double [[TMP6]], [[TMP18]]
; CHECK-PWR9-NEXT:    [[TMP20:%.*]] = fadd double [[TMP19]], [[TMP13]]
; CHECK-PWR9-NEXT:    [[TMP21:%.*]] = fadd double [[TMP20]], [[TMP17]]
; CHECK-PWR9-NEXT:    [[TMP22:%.*]] = fadd double [[TMP21]], 3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP23:%.*]] = fmul double [[TMP4]], [[TMP22]]
; CHECK-PWR9-NEXT:    store double [[TMP23]], double* [[TMP3]], align 8
; CHECK-PWR9-NEXT:    [[INDVARS_IV_NEXT_PROL:%.*]] = add nsw i64 [[TMP1]], -1
; CHECK-PWR9-NEXT:    br label [[DOTPROL_LOOPEXIT]]
; CHECK-PWR9:       .prol.loopexit:
; CHECK-PWR9-NEXT:    [[INDVARS_IV_UNR:%.*]] = phi i64 [ [[TMP1]], [[TMP0:%.*]] ], [ [[INDVARS_IV_NEXT_PROL]], [[DOTPROL_LOOPEXIT_UNR_LCSSA]] ]
; CHECK-PWR9-NEXT:    [[TMP24:%.*]] = icmp eq i32 [[N]], 0
; CHECK-PWR9-NEXT:    br i1 [[TMP24]], label [[DOTUNR_LCSSA:%.*]], label [[DOTNEW:%.*]]
; CHECK-PWR9:       .new:
; CHECK-PWR9-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT_1:%.*]], [[DOTNEW]] ], [ [[INDVARS_IV_UNR]], [[DOTPROL_LOOPEXIT]] ]
; CHECK-PWR9-NEXT:    [[TMP25:%.*]] = getelementptr inbounds double, double* [[A]], i64 [[INDVARS_IV]]
; CHECK-PWR9-NEXT:    [[TMP26:%.*]] = load double, double* [[TMP25]], align 8
; CHECK-PWR9-NEXT:    [[TMP27:%.*]] = fadd double [[TMP26]], 3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP28:%.*]] = fmul double [[TMP26]], 2.000000e+00
; CHECK-PWR9-NEXT:    [[TMP29:%.*]] = fadd double [[TMP27]], [[TMP28]]
; CHECK-PWR9-NEXT:    [[TMP30:%.*]] = fadd double [[TMP29]], 2.000000e+00
; CHECK-PWR9-NEXT:    [[TMP31:%.*]] = fmul double [[TMP30]], 5.000000e-01
; CHECK-PWR9-NEXT:    [[TMP32:%.*]] = fadd double [[TMP28]], [[TMP31]]
; CHECK-PWR9-NEXT:    [[TMP33:%.*]] = fsub double [[TMP32]], [[TMP27]]
; CHECK-PWR9-NEXT:    [[TMP34:%.*]] = fadd double [[TMP26]], [[TMP33]]
; CHECK-PWR9-NEXT:    [[TMP35:%.*]] = fdiv double [[TMP30]], [[TMP34]]
; CHECK-PWR9-NEXT:    [[TMP36:%.*]] = fmul double [[TMP30]], [[TMP35]]
; CHECK-PWR9-NEXT:    [[TMP37:%.*]] = fmul double [[TMP28]], [[TMP36]]
; CHECK-PWR9-NEXT:    [[TMP38:%.*]] = fmul double [[TMP27]], [[TMP37]]
; CHECK-PWR9-NEXT:    [[TMP39:%.*]] = fadd double [[TMP38]], -3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP40:%.*]] = fsub double [[TMP26]], [[TMP27]]
; CHECK-PWR9-NEXT:    [[TMP41:%.*]] = fadd double [[TMP28]], [[TMP40]]
; CHECK-PWR9-NEXT:    [[TMP42:%.*]] = fadd double [[TMP41]], [[TMP35]]
; CHECK-PWR9-NEXT:    [[TMP43:%.*]] = fadd double [[TMP42]], [[TMP39]]
; CHECK-PWR9-NEXT:    [[TMP44:%.*]] = fadd double [[TMP43]], 3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP45:%.*]] = fmul double [[TMP26]], [[TMP44]]
; CHECK-PWR9-NEXT:    store double [[TMP45]], double* [[TMP25]], align 8
; CHECK-PWR9-NEXT:    [[INDVARS_IV_NEXT:%.*]] = add nsw i64 [[INDVARS_IV]], -1
; CHECK-PWR9-NEXT:    [[TMP46:%.*]] = getelementptr inbounds double, double* [[A]], i64 [[INDVARS_IV_NEXT]]
; CHECK-PWR9-NEXT:    [[TMP47:%.*]] = load double, double* [[TMP46]], align 8
; CHECK-PWR9-NEXT:    [[TMP48:%.*]] = fadd double [[TMP47]], 3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP49:%.*]] = fmul double [[TMP47]], 2.000000e+00
; CHECK-PWR9-NEXT:    [[TMP50:%.*]] = fadd double [[TMP48]], [[TMP49]]
; CHECK-PWR9-NEXT:    [[TMP51:%.*]] = fadd double [[TMP50]], 2.000000e+00
; CHECK-PWR9-NEXT:    [[TMP52:%.*]] = fmul double [[TMP51]], 5.000000e-01
; CHECK-PWR9-NEXT:    [[TMP53:%.*]] = fadd double [[TMP49]], [[TMP52]]
; CHECK-PWR9-NEXT:    [[TMP54:%.*]] = fsub double [[TMP53]], [[TMP48]]
; CHECK-PWR9-NEXT:    [[TMP55:%.*]] = fadd double [[TMP47]], [[TMP54]]
; CHECK-PWR9-NEXT:    [[TMP56:%.*]] = fdiv double [[TMP51]], [[TMP55]]
; CHECK-PWR9-NEXT:    [[TMP57:%.*]] = fmul double [[TMP51]], [[TMP56]]
; CHECK-PWR9-NEXT:    [[TMP58:%.*]] = fmul double [[TMP49]], [[TMP57]]
; CHECK-PWR9-NEXT:    [[TMP59:%.*]] = fmul double [[TMP48]], [[TMP58]]
; CHECK-PWR9-NEXT:    [[TMP60:%.*]] = fadd double [[TMP59]], -3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP61:%.*]] = fsub double [[TMP47]], [[TMP48]]
; CHECK-PWR9-NEXT:    [[TMP62:%.*]] = fadd double [[TMP49]], [[TMP61]]
; CHECK-PWR9-NEXT:    [[TMP63:%.*]] = fadd double [[TMP62]], [[TMP56]]
; CHECK-PWR9-NEXT:    [[TMP64:%.*]] = fadd double [[TMP63]], [[TMP60]]
; CHECK-PWR9-NEXT:    [[TMP65:%.*]] = fadd double [[TMP64]], 3.000000e+00
; CHECK-PWR9-NEXT:    [[TMP66:%.*]] = fmul double [[TMP47]], [[TMP65]]
; CHECK-PWR9-NEXT:    store double [[TMP66]], double* [[TMP46]], align 8
; CHECK-PWR9-NEXT:    [[INDVARS_IV_NEXT_1]] = add nsw i64 [[INDVARS_IV]], -2
; CHECK-PWR9-NEXT:    [[TMP67:%.*]] = trunc i64 [[INDVARS_IV_NEXT]] to i32
; CHECK-PWR9-NEXT:    [[TMP68:%.*]] = icmp eq i32 [[TMP67]], 0
; CHECK-PWR9-NEXT:    br i1 [[TMP68]], label [[DOTUNR_LCSSA]], label [[DOTNEW]]
; CHECK-PWR9:       .unr-lcssa:
; CHECK-PWR9-NEXT:    ret void
;


  %1 = sext i32 %n to i64
  br label %2

; <label>:2                                       ; preds = %2, %0
  %indvars.iv = phi i64 [ %indvars.iv.next, %2 ], [ %1, %0 ]
  %3 = getelementptr inbounds double, double* %A, i64 %indvars.iv
  %4 = load double, double* %3, align 8
  %5 = fadd double %4, 3.000000e+00
  %6 = fmul double %4, 2.000000e+00
  %7 = fadd double %5, %6
  %8 = fadd double %7, 2.000000e+00
  %9 = fmul double %8, 5.000000e-01
  %10 = fadd double %6, %9
  %11 = fsub double %10, %5
  %12 = fadd double %4, %11
  %13 = fdiv double %8, %12
  %14 = fmul double %13, %8
  %15 = fmul double %6, %14
  %16 = fmul double %5, %15
  %17 = fadd double %16, -3.000000e+00
  %18 = fsub double %4, %5
  %19 = fadd double %6, %18
  %20 = fadd double %13, %19
  %21 = fadd double %20, %17
  %22 = fadd double %21, 3.000000e+00
  %23 = fmul double %4, %22
  store double %23, double* %3, align 8
  %indvars.iv.next = add i64 %indvars.iv, -1
  %24 = trunc i64 %indvars.iv to i32
  %25 = icmp eq i32 %24, 0
  br i1 %25, label %26, label %2

; <label>:26                                      ; preds = %2
  ret void
}

define ppc_fp128 @fp128_(ppc_fp128* nocapture %n, ppc_fp128 %d) nounwind readonly {
; CHECK-PWR8-LABEL: @fp128_(
; CHECK-PWR8-NEXT:  entry:
; CHECK-PWR8-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK-PWR8:       vector.body:
; CHECK-PWR8-NEXT:    [[INDEX:%.*]] = phi i32 [ 0, [[ENTRY:%.*]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI:%.*]] = phi ppc_fp128 [ [[D:%.*]], [[ENTRY]] ], [ [[TMP36:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI1:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP37:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI2:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP38:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI3:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP39:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI4:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP40:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI5:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP41:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI6:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP42:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI7:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP43:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI8:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP44:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI9:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP45:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI10:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP46:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[VEC_PHI11:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP47:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR8-NEXT:    [[INDUCTION12:%.*]] = or i32 [[INDEX]], 1
; CHECK-PWR8-NEXT:    [[INDUCTION13:%.*]] = or i32 [[INDEX]], 2
; CHECK-PWR8-NEXT:    [[INDUCTION14:%.*]] = or i32 [[INDEX]], 3
; CHECK-PWR8-NEXT:    [[INDUCTION15:%.*]] = add nuw nsw i32 [[INDEX]], 4
; CHECK-PWR8-NEXT:    [[INDUCTION16:%.*]] = add nuw nsw i32 [[INDEX]], 5
; CHECK-PWR8-NEXT:    [[INDUCTION17:%.*]] = add nuw nsw i32 [[INDEX]], 6
; CHECK-PWR8-NEXT:    [[INDUCTION18:%.*]] = add nuw nsw i32 [[INDEX]], 7
; CHECK-PWR8-NEXT:    [[INDUCTION19:%.*]] = add nuw nsw i32 [[INDEX]], 8
; CHECK-PWR8-NEXT:    [[INDUCTION20:%.*]] = add nuw nsw i32 [[INDEX]], 9
; CHECK-PWR8-NEXT:    [[INDUCTION21:%.*]] = add nuw nsw i32 [[INDEX]], 10
; CHECK-PWR8-NEXT:    [[INDUCTION22:%.*]] = add nuw nsw i32 [[INDEX]], 11
; CHECK-PWR8-NEXT:    [[TMP0:%.*]] = zext i32 [[INDEX]] to i64
; CHECK-PWR8-NEXT:    [[TMP1:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N:%.*]], i64 [[TMP0]]
; CHECK-PWR8-NEXT:    [[TMP2:%.*]] = zext i32 [[INDUCTION12]] to i64
; CHECK-PWR8-NEXT:    [[TMP3:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP2]]
; CHECK-PWR8-NEXT:    [[TMP4:%.*]] = zext i32 [[INDUCTION13]] to i64
; CHECK-PWR8-NEXT:    [[TMP5:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP4]]
; CHECK-PWR8-NEXT:    [[TMP6:%.*]] = zext i32 [[INDUCTION14]] to i64
; CHECK-PWR8-NEXT:    [[TMP7:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP6]]
; CHECK-PWR8-NEXT:    [[TMP8:%.*]] = zext i32 [[INDUCTION15]] to i64
; CHECK-PWR8-NEXT:    [[TMP9:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP8]]
; CHECK-PWR8-NEXT:    [[TMP10:%.*]] = zext i32 [[INDUCTION16]] to i64
; CHECK-PWR8-NEXT:    [[TMP11:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP10]]
; CHECK-PWR8-NEXT:    [[TMP12:%.*]] = zext i32 [[INDUCTION17]] to i64
; CHECK-PWR8-NEXT:    [[TMP13:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP12]]
; CHECK-PWR8-NEXT:    [[TMP14:%.*]] = zext i32 [[INDUCTION18]] to i64
; CHECK-PWR8-NEXT:    [[TMP15:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP14]]
; CHECK-PWR8-NEXT:    [[TMP16:%.*]] = zext i32 [[INDUCTION19]] to i64
; CHECK-PWR8-NEXT:    [[TMP17:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP16]]
; CHECK-PWR8-NEXT:    [[TMP18:%.*]] = zext i32 [[INDUCTION20]] to i64
; CHECK-PWR8-NEXT:    [[TMP19:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP18]]
; CHECK-PWR8-NEXT:    [[TMP20:%.*]] = zext i32 [[INDUCTION21]] to i64
; CHECK-PWR8-NEXT:    [[TMP21:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP20]]
; CHECK-PWR8-NEXT:    [[TMP22:%.*]] = zext i32 [[INDUCTION22]] to i64
; CHECK-PWR8-NEXT:    [[TMP23:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP22]]
; CHECK-PWR8-NEXT:    [[TMP24:%.*]] = load ppc_fp128, ppc_fp128* [[TMP1]], align 8
; CHECK-PWR8-NEXT:    [[TMP25:%.*]] = load ppc_fp128, ppc_fp128* [[TMP3]], align 8
; CHECK-PWR8-NEXT:    [[TMP26:%.*]] = load ppc_fp128, ppc_fp128* [[TMP5]], align 8
; CHECK-PWR8-NEXT:    [[TMP27:%.*]] = load ppc_fp128, ppc_fp128* [[TMP7]], align 8
; CHECK-PWR8-NEXT:    [[TMP28:%.*]] = load ppc_fp128, ppc_fp128* [[TMP9]], align 8
; CHECK-PWR8-NEXT:    [[TMP29:%.*]] = load ppc_fp128, ppc_fp128* [[TMP11]], align 8
; CHECK-PWR8-NEXT:    [[TMP30:%.*]] = load ppc_fp128, ppc_fp128* [[TMP13]], align 8
; CHECK-PWR8-NEXT:    [[TMP31:%.*]] = load ppc_fp128, ppc_fp128* [[TMP15]], align 8
; CHECK-PWR8-NEXT:    [[TMP32:%.*]] = load ppc_fp128, ppc_fp128* [[TMP17]], align 8
; CHECK-PWR8-NEXT:    [[TMP33:%.*]] = load ppc_fp128, ppc_fp128* [[TMP19]], align 8
; CHECK-PWR8-NEXT:    [[TMP34:%.*]] = load ppc_fp128, ppc_fp128* [[TMP21]], align 8
; CHECK-PWR8-NEXT:    [[TMP35:%.*]] = load ppc_fp128, ppc_fp128* [[TMP23]], align 8
; CHECK-PWR8-NEXT:    [[TMP36]] = fsub fast ppc_fp128 [[VEC_PHI]], [[TMP24]]
; CHECK-PWR8-NEXT:    [[TMP37]] = fsub fast ppc_fp128 [[VEC_PHI1]], [[TMP25]]
; CHECK-PWR8-NEXT:    [[TMP38]] = fsub fast ppc_fp128 [[VEC_PHI2]], [[TMP26]]
; CHECK-PWR8-NEXT:    [[TMP39]] = fsub fast ppc_fp128 [[VEC_PHI3]], [[TMP27]]
; CHECK-PWR8-NEXT:    [[TMP40]] = fsub fast ppc_fp128 [[VEC_PHI4]], [[TMP28]]
; CHECK-PWR8-NEXT:    [[TMP41]] = fsub fast ppc_fp128 [[VEC_PHI5]], [[TMP29]]
; CHECK-PWR8-NEXT:    [[TMP42]] = fsub fast ppc_fp128 [[VEC_PHI6]], [[TMP30]]
; CHECK-PWR8-NEXT:    [[TMP43]] = fsub fast ppc_fp128 [[VEC_PHI7]], [[TMP31]]
; CHECK-PWR8-NEXT:    [[TMP44]] = fsub fast ppc_fp128 [[VEC_PHI8]], [[TMP32]]
; CHECK-PWR8-NEXT:    [[TMP45]] = fsub fast ppc_fp128 [[VEC_PHI9]], [[TMP33]]
; CHECK-PWR8-NEXT:    [[TMP46]] = fsub fast ppc_fp128 [[VEC_PHI10]], [[TMP34]]
; CHECK-PWR8-NEXT:    [[TMP47]] = fsub fast ppc_fp128 [[VEC_PHI11]], [[TMP35]]
; CHECK-PWR8-NEXT:    [[INDEX_NEXT]] = add nuw nsw i32 [[INDEX]], 12
; CHECK-PWR8-NEXT:    [[TMP48:%.*]] = icmp eq i32 [[INDEX_NEXT]], 2040
; CHECK-PWR8-NEXT:    br i1 [[TMP48]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP10:![0-9]+]]
; CHECK-PWR8:       middle.block:
; CHECK-PWR8-NEXT:    [[BIN_RDX:%.*]] = fadd fast ppc_fp128 [[TMP37]], [[TMP36]]
; CHECK-PWR8-NEXT:    [[BIN_RDX23:%.*]] = fadd fast ppc_fp128 [[BIN_RDX]], [[TMP38]]
; CHECK-PWR8-NEXT:    [[BIN_RDX24:%.*]] = fadd fast ppc_fp128 [[BIN_RDX23]], [[TMP39]]
; CHECK-PWR8-NEXT:    [[BIN_RDX25:%.*]] = fadd fast ppc_fp128 [[BIN_RDX24]], [[TMP40]]
; CHECK-PWR8-NEXT:    [[BIN_RDX26:%.*]] = fadd fast ppc_fp128 [[BIN_RDX25]], [[TMP41]]
; CHECK-PWR8-NEXT:    [[BIN_RDX27:%.*]] = fadd fast ppc_fp128 [[BIN_RDX26]], [[TMP42]]
; CHECK-PWR8-NEXT:    [[BIN_RDX28:%.*]] = fadd fast ppc_fp128 [[BIN_RDX27]], [[TMP43]]
; CHECK-PWR8-NEXT:    [[BIN_RDX29:%.*]] = fadd fast ppc_fp128 [[BIN_RDX28]], [[TMP44]]
; CHECK-PWR8-NEXT:    [[BIN_RDX30:%.*]] = fadd fast ppc_fp128 [[BIN_RDX29]], [[TMP45]]
; CHECK-PWR8-NEXT:    [[BIN_RDX31:%.*]] = fadd fast ppc_fp128 [[BIN_RDX30]], [[TMP46]]
; CHECK-PWR8-NEXT:    [[BIN_RDX32:%.*]] = fadd fast ppc_fp128 [[BIN_RDX31]], [[TMP47]]
; CHECK-PWR8-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2040
; CHECK-PWR8-NEXT:    [[TMP49:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX]], align 8
; CHECK-PWR8-NEXT:    [[ARRAYIDX_1:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2041
; CHECK-PWR8-NEXT:    [[TMP50:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_1]], align 8
; CHECK-PWR8-NEXT:    [[TMP51:%.*]] = fadd fast ppc_fp128 [[TMP49]], [[TMP50]]
; CHECK-PWR8-NEXT:    [[ARRAYIDX_2:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2042
; CHECK-PWR8-NEXT:    [[TMP52:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_2]], align 8
; CHECK-PWR8-NEXT:    [[TMP53:%.*]] = fadd fast ppc_fp128 [[TMP51]], [[TMP52]]
; CHECK-PWR8-NEXT:    [[ARRAYIDX_3:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2043
; CHECK-PWR8-NEXT:    [[TMP54:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_3]], align 8
; CHECK-PWR8-NEXT:    [[TMP55:%.*]] = fadd fast ppc_fp128 [[TMP53]], [[TMP54]]
; CHECK-PWR8-NEXT:    [[ARRAYIDX_4:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2044
; CHECK-PWR8-NEXT:    [[TMP56:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_4]], align 8
; CHECK-PWR8-NEXT:    [[TMP57:%.*]] = fadd fast ppc_fp128 [[TMP55]], [[TMP56]]
; CHECK-PWR8-NEXT:    [[ARRAYIDX_5:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2045
; CHECK-PWR8-NEXT:    [[TMP58:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_5]], align 8
; CHECK-PWR8-NEXT:    [[TMP59:%.*]] = fadd fast ppc_fp128 [[TMP57]], [[TMP58]]
; CHECK-PWR8-NEXT:    [[ARRAYIDX_6:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2046
; CHECK-PWR8-NEXT:    [[TMP60:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_6]], align 8
; CHECK-PWR8-NEXT:    [[TMP61:%.*]] = fadd fast ppc_fp128 [[TMP59]], [[TMP60]]
; CHECK-PWR8-NEXT:    [[ARRAYIDX_7:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2047
; CHECK-PWR8-NEXT:    [[TMP62:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_7]], align 8
; CHECK-PWR8-NEXT:    [[TMP63:%.*]] = fadd fast ppc_fp128 [[TMP61]], [[TMP62]]
; CHECK-PWR8-NEXT:    [[SUB_7:%.*]] = fsub fast ppc_fp128 [[BIN_RDX32]], [[TMP63]]
; CHECK-PWR8-NEXT:    ret ppc_fp128 [[SUB_7]]
;
; CHECK-PWR9-LABEL: @fp128_(
; CHECK-PWR9-NEXT:  entry:
; CHECK-PWR9-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK-PWR9:       vector.body:
; CHECK-PWR9-NEXT:    [[INDEX:%.*]] = phi i32 [ 0, [[ENTRY:%.*]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI:%.*]] = phi ppc_fp128 [ [[D:%.*]], [[ENTRY]] ], [ [[TMP36:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI1:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP37:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI2:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP38:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI3:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP39:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI4:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP40:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI5:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP41:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI6:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP42:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI7:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP43:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI8:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP44:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI9:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP45:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI10:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP46:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[VEC_PHI11:%.*]] = phi ppc_fp128 [ 0xM00000000000000000000000000000000, [[ENTRY]] ], [ [[TMP47:%.*]], [[VECTOR_BODY]] ]
; CHECK-PWR9-NEXT:    [[INDUCTION12:%.*]] = or i32 [[INDEX]], 1
; CHECK-PWR9-NEXT:    [[INDUCTION13:%.*]] = or i32 [[INDEX]], 2
; CHECK-PWR9-NEXT:    [[INDUCTION14:%.*]] = or i32 [[INDEX]], 3
; CHECK-PWR9-NEXT:    [[INDUCTION15:%.*]] = add nuw nsw i32 [[INDEX]], 4
; CHECK-PWR9-NEXT:    [[INDUCTION16:%.*]] = add nuw nsw i32 [[INDEX]], 5
; CHECK-PWR9-NEXT:    [[INDUCTION17:%.*]] = add nuw nsw i32 [[INDEX]], 6
; CHECK-PWR9-NEXT:    [[INDUCTION18:%.*]] = add nuw nsw i32 [[INDEX]], 7
; CHECK-PWR9-NEXT:    [[INDUCTION19:%.*]] = add nuw nsw i32 [[INDEX]], 8
; CHECK-PWR9-NEXT:    [[INDUCTION20:%.*]] = add nuw nsw i32 [[INDEX]], 9
; CHECK-PWR9-NEXT:    [[INDUCTION21:%.*]] = add nuw nsw i32 [[INDEX]], 10
; CHECK-PWR9-NEXT:    [[INDUCTION22:%.*]] = add nuw nsw i32 [[INDEX]], 11
; CHECK-PWR9-NEXT:    [[TMP0:%.*]] = zext i32 [[INDEX]] to i64
; CHECK-PWR9-NEXT:    [[TMP1:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N:%.*]], i64 [[TMP0]]
; CHECK-PWR9-NEXT:    [[TMP2:%.*]] = zext i32 [[INDUCTION12]] to i64
; CHECK-PWR9-NEXT:    [[TMP3:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP2]]
; CHECK-PWR9-NEXT:    [[TMP4:%.*]] = zext i32 [[INDUCTION13]] to i64
; CHECK-PWR9-NEXT:    [[TMP5:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP4]]
; CHECK-PWR9-NEXT:    [[TMP6:%.*]] = zext i32 [[INDUCTION14]] to i64
; CHECK-PWR9-NEXT:    [[TMP7:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP6]]
; CHECK-PWR9-NEXT:    [[TMP8:%.*]] = zext i32 [[INDUCTION15]] to i64
; CHECK-PWR9-NEXT:    [[TMP9:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP8]]
; CHECK-PWR9-NEXT:    [[TMP10:%.*]] = zext i32 [[INDUCTION16]] to i64
; CHECK-PWR9-NEXT:    [[TMP11:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP10]]
; CHECK-PWR9-NEXT:    [[TMP12:%.*]] = zext i32 [[INDUCTION17]] to i64
; CHECK-PWR9-NEXT:    [[TMP13:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP12]]
; CHECK-PWR9-NEXT:    [[TMP14:%.*]] = zext i32 [[INDUCTION18]] to i64
; CHECK-PWR9-NEXT:    [[TMP15:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP14]]
; CHECK-PWR9-NEXT:    [[TMP16:%.*]] = zext i32 [[INDUCTION19]] to i64
; CHECK-PWR9-NEXT:    [[TMP17:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP16]]
; CHECK-PWR9-NEXT:    [[TMP18:%.*]] = zext i32 [[INDUCTION20]] to i64
; CHECK-PWR9-NEXT:    [[TMP19:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP18]]
; CHECK-PWR9-NEXT:    [[TMP20:%.*]] = zext i32 [[INDUCTION21]] to i64
; CHECK-PWR9-NEXT:    [[TMP21:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP20]]
; CHECK-PWR9-NEXT:    [[TMP22:%.*]] = zext i32 [[INDUCTION22]] to i64
; CHECK-PWR9-NEXT:    [[TMP23:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 [[TMP22]]
; CHECK-PWR9-NEXT:    [[TMP24:%.*]] = load ppc_fp128, ppc_fp128* [[TMP1]], align 8
; CHECK-PWR9-NEXT:    [[TMP25:%.*]] = load ppc_fp128, ppc_fp128* [[TMP3]], align 8
; CHECK-PWR9-NEXT:    [[TMP26:%.*]] = load ppc_fp128, ppc_fp128* [[TMP5]], align 8
; CHECK-PWR9-NEXT:    [[TMP27:%.*]] = load ppc_fp128, ppc_fp128* [[TMP7]], align 8
; CHECK-PWR9-NEXT:    [[TMP28:%.*]] = load ppc_fp128, ppc_fp128* [[TMP9]], align 8
; CHECK-PWR9-NEXT:    [[TMP29:%.*]] = load ppc_fp128, ppc_fp128* [[TMP11]], align 8
; CHECK-PWR9-NEXT:    [[TMP30:%.*]] = load ppc_fp128, ppc_fp128* [[TMP13]], align 8
; CHECK-PWR9-NEXT:    [[TMP31:%.*]] = load ppc_fp128, ppc_fp128* [[TMP15]], align 8
; CHECK-PWR9-NEXT:    [[TMP32:%.*]] = load ppc_fp128, ppc_fp128* [[TMP17]], align 8
; CHECK-PWR9-NEXT:    [[TMP33:%.*]] = load ppc_fp128, ppc_fp128* [[TMP19]], align 8
; CHECK-PWR9-NEXT:    [[TMP34:%.*]] = load ppc_fp128, ppc_fp128* [[TMP21]], align 8
; CHECK-PWR9-NEXT:    [[TMP35:%.*]] = load ppc_fp128, ppc_fp128* [[TMP23]], align 8
; CHECK-PWR9-NEXT:    [[TMP36]] = fsub fast ppc_fp128 [[VEC_PHI]], [[TMP24]]
; CHECK-PWR9-NEXT:    [[TMP37]] = fsub fast ppc_fp128 [[VEC_PHI1]], [[TMP25]]
; CHECK-PWR9-NEXT:    [[TMP38]] = fsub fast ppc_fp128 [[VEC_PHI2]], [[TMP26]]
; CHECK-PWR9-NEXT:    [[TMP39]] = fsub fast ppc_fp128 [[VEC_PHI3]], [[TMP27]]
; CHECK-PWR9-NEXT:    [[TMP40]] = fsub fast ppc_fp128 [[VEC_PHI4]], [[TMP28]]
; CHECK-PWR9-NEXT:    [[TMP41]] = fsub fast ppc_fp128 [[VEC_PHI5]], [[TMP29]]
; CHECK-PWR9-NEXT:    [[TMP42]] = fsub fast ppc_fp128 [[VEC_PHI6]], [[TMP30]]
; CHECK-PWR9-NEXT:    [[TMP43]] = fsub fast ppc_fp128 [[VEC_PHI7]], [[TMP31]]
; CHECK-PWR9-NEXT:    [[TMP44]] = fsub fast ppc_fp128 [[VEC_PHI8]], [[TMP32]]
; CHECK-PWR9-NEXT:    [[TMP45]] = fsub fast ppc_fp128 [[VEC_PHI9]], [[TMP33]]
; CHECK-PWR9-NEXT:    [[TMP46]] = fsub fast ppc_fp128 [[VEC_PHI10]], [[TMP34]]
; CHECK-PWR9-NEXT:    [[TMP47]] = fsub fast ppc_fp128 [[VEC_PHI11]], [[TMP35]]
; CHECK-PWR9-NEXT:    [[INDEX_NEXT]] = add nuw nsw i32 [[INDEX]], 12
; CHECK-PWR9-NEXT:    [[TMP48:%.*]] = icmp eq i32 [[INDEX_NEXT]], 2040
; CHECK-PWR9-NEXT:    br i1 [[TMP48]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP7:![0-9]+]]
; CHECK-PWR9:       middle.block:
; CHECK-PWR9-NEXT:    [[BIN_RDX:%.*]] = fadd fast ppc_fp128 [[TMP37]], [[TMP36]]
; CHECK-PWR9-NEXT:    [[BIN_RDX23:%.*]] = fadd fast ppc_fp128 [[BIN_RDX]], [[TMP38]]
; CHECK-PWR9-NEXT:    [[BIN_RDX24:%.*]] = fadd fast ppc_fp128 [[BIN_RDX23]], [[TMP39]]
; CHECK-PWR9-NEXT:    [[BIN_RDX25:%.*]] = fadd fast ppc_fp128 [[BIN_RDX24]], [[TMP40]]
; CHECK-PWR9-NEXT:    [[BIN_RDX26:%.*]] = fadd fast ppc_fp128 [[BIN_RDX25]], [[TMP41]]
; CHECK-PWR9-NEXT:    [[BIN_RDX27:%.*]] = fadd fast ppc_fp128 [[BIN_RDX26]], [[TMP42]]
; CHECK-PWR9-NEXT:    [[BIN_RDX28:%.*]] = fadd fast ppc_fp128 [[BIN_RDX27]], [[TMP43]]
; CHECK-PWR9-NEXT:    [[BIN_RDX29:%.*]] = fadd fast ppc_fp128 [[BIN_RDX28]], [[TMP44]]
; CHECK-PWR9-NEXT:    [[BIN_RDX30:%.*]] = fadd fast ppc_fp128 [[BIN_RDX29]], [[TMP45]]
; CHECK-PWR9-NEXT:    [[BIN_RDX31:%.*]] = fadd fast ppc_fp128 [[BIN_RDX30]], [[TMP46]]
; CHECK-PWR9-NEXT:    [[BIN_RDX32:%.*]] = fadd fast ppc_fp128 [[BIN_RDX31]], [[TMP47]]
; CHECK-PWR9-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2040
; CHECK-PWR9-NEXT:    [[TMP49:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX]], align 8
; CHECK-PWR9-NEXT:    [[ARRAYIDX_1:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2041
; CHECK-PWR9-NEXT:    [[TMP50:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_1]], align 8
; CHECK-PWR9-NEXT:    [[TMP51:%.*]] = fadd fast ppc_fp128 [[TMP49]], [[TMP50]]
; CHECK-PWR9-NEXT:    [[ARRAYIDX_2:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2042
; CHECK-PWR9-NEXT:    [[TMP52:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_2]], align 8
; CHECK-PWR9-NEXT:    [[TMP53:%.*]] = fadd fast ppc_fp128 [[TMP51]], [[TMP52]]
; CHECK-PWR9-NEXT:    [[ARRAYIDX_3:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2043
; CHECK-PWR9-NEXT:    [[TMP54:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_3]], align 8
; CHECK-PWR9-NEXT:    [[TMP55:%.*]] = fadd fast ppc_fp128 [[TMP53]], [[TMP54]]
; CHECK-PWR9-NEXT:    [[ARRAYIDX_4:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2044
; CHECK-PWR9-NEXT:    [[TMP56:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_4]], align 8
; CHECK-PWR9-NEXT:    [[TMP57:%.*]] = fadd fast ppc_fp128 [[TMP55]], [[TMP56]]
; CHECK-PWR9-NEXT:    [[ARRAYIDX_5:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2045
; CHECK-PWR9-NEXT:    [[TMP58:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_5]], align 8
; CHECK-PWR9-NEXT:    [[TMP59:%.*]] = fadd fast ppc_fp128 [[TMP57]], [[TMP58]]
; CHECK-PWR9-NEXT:    [[ARRAYIDX_6:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2046
; CHECK-PWR9-NEXT:    [[TMP60:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_6]], align 8
; CHECK-PWR9-NEXT:    [[TMP61:%.*]] = fadd fast ppc_fp128 [[TMP59]], [[TMP60]]
; CHECK-PWR9-NEXT:    [[ARRAYIDX_7:%.*]] = getelementptr inbounds ppc_fp128, ppc_fp128* [[N]], i64 2047
; CHECK-PWR9-NEXT:    [[TMP62:%.*]] = load ppc_fp128, ppc_fp128* [[ARRAYIDX_7]], align 8
; CHECK-PWR9-NEXT:    [[TMP63:%.*]] = fadd fast ppc_fp128 [[TMP61]], [[TMP62]]
; CHECK-PWR9-NEXT:    [[SUB_7:%.*]] = fsub fast ppc_fp128 [[BIN_RDX32]], [[TMP63]]
; CHECK-PWR9-NEXT:    ret ppc_fp128 [[SUB_7]]
;
entry:
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %i.06 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %x.05 = phi ppc_fp128 [ %d, %entry ], [ %sub, %for.body ]
  %arrayidx = getelementptr inbounds ppc_fp128, ppc_fp128* %n, i32 %i.06
  %0 = load ppc_fp128, ppc_fp128* %arrayidx, align 8
  %sub = fsub fast ppc_fp128 %x.05, %0
  %inc = add nsw i32 %i.06, 1
  %exitcond = icmp eq i32 %inc, 2048
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  ret ppc_fp128 %sub
}


define void @fp16_(half* nocapture readonly %pIn, half* nocapture %pOut, i32 %numRows, i32 %numCols, i32 %scale.coerce) #0 {
; CHECK-PWR8-LABEL: @fp16_(
; CHECK-PWR8-NEXT:  entry:
; CHECK-PWR8-NEXT:    [[TMP_0_EXTRACT_TRUNC:%.*]] = trunc i32 [[SCALE_COERCE:%.*]] to i16
; CHECK-PWR8-NEXT:    [[TMP0:%.*]] = bitcast i16 [[TMP_0_EXTRACT_TRUNC]] to half
; CHECK-PWR8-NEXT:    [[MUL:%.*]] = mul i32 [[NUMCOLS:%.*]], [[NUMROWS:%.*]]
; CHECK-PWR8-NEXT:    [[CMP26:%.*]] = icmp ult i32 [[MUL]], 4
; CHECK-PWR8-NEXT:    br i1 [[CMP26]], label [[WHILE_END:%.*]], label [[WHILE_BODY_PREHEADER:%.*]]
; CHECK-PWR8:       while.body.preheader:
; CHECK-PWR8-NEXT:    [[SHR:%.*]] = lshr i32 [[MUL]], 2
; CHECK-PWR8-NEXT:    [[TMP1:%.*]] = add nsw i32 [[SHR]], -1
; CHECK-PWR8-NEXT:    [[XTRAITER:%.*]] = and i32 [[SHR]], 7
; CHECK-PWR8-NEXT:    [[LCMP_MOD_NOT:%.*]] = icmp eq i32 [[XTRAITER]], 0
; CHECK-PWR8-NEXT:    br i1 [[LCMP_MOD_NOT]], label [[WHILE_BODY_PROL_LOOPEXIT:%.*]], label [[WHILE_BODY_PROL:%.*]]
; CHECK-PWR8:       while.body.prol:
; CHECK-PWR8-NEXT:    [[PIN_ADDR_029_PROL:%.*]] = phi half* [ [[ADD_PTR_PROL:%.*]], [[WHILE_BODY_PROL]] ], [ [[PIN:%.*]], [[WHILE_BODY_PREHEADER]] ]
; CHECK-PWR8-NEXT:    [[POUT_ADDR_028_PROL:%.*]] = phi half* [ [[ADD_PTR7_PROL:%.*]], [[WHILE_BODY_PROL]] ], [ [[POUT:%.*]], [[WHILE_BODY_PREHEADER]] ]
; CHECK-PWR8-NEXT:    [[BLKCNT_027_PROL:%.*]] = phi i32 [ [[DEC_PROL:%.*]], [[WHILE_BODY_PROL]] ], [ [[SHR]], [[WHILE_BODY_PREHEADER]] ]
; CHECK-PWR8-NEXT:    [[PROL_ITER:%.*]] = phi i32 [ [[PROL_ITER_NEXT:%.*]], [[WHILE_BODY_PROL]] ], [ 0, [[WHILE_BODY_PREHEADER]] ]
; CHECK-PWR8-NEXT:    [[TMP2:%.*]] = load half, half* [[PIN_ADDR_029_PROL]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2_PROL:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029_PROL]], i64 1
; CHECK-PWR8-NEXT:    [[TMP3:%.*]] = load half, half* [[ARRAYIDX2_PROL]], align 2
; CHECK-PWR8-NEXT:    [[MUL3_PROL:%.*]] = fmul half [[TMP2]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4_PROL:%.*]] = fmul half [[TMP3]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3_PROL]], half* [[POUT_ADDR_028_PROL]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6_PROL:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028_PROL]], i64 1
; CHECK-PWR8-NEXT:    store half [[MUL4_PROL]], half* [[ARRAYIDX6_PROL]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR_PROL]] = getelementptr inbounds half, half* [[PIN_ADDR_029_PROL]], i64 2
; CHECK-PWR8-NEXT:    [[ADD_PTR7_PROL]] = getelementptr inbounds half, half* [[POUT_ADDR_028_PROL]], i64 2
; CHECK-PWR8-NEXT:    [[DEC_PROL]] = add nsw i32 [[BLKCNT_027_PROL]], -1
; CHECK-PWR8-NEXT:    [[PROL_ITER_NEXT]] = add i32 [[PROL_ITER]], 1
; CHECK-PWR8-NEXT:    [[PROL_ITER_CMP_NOT:%.*]] = icmp eq i32 [[PROL_ITER_NEXT]], [[XTRAITER]]
; CHECK-PWR8-NEXT:    br i1 [[PROL_ITER_CMP_NOT]], label [[WHILE_BODY_PROL_LOOPEXIT]], label [[WHILE_BODY_PROL]], !llvm.loop [[LOOP11:![0-9]+]]
; CHECK-PWR8:       while.body.prol.loopexit:
; CHECK-PWR8-NEXT:    [[PIN_ADDR_029_UNR:%.*]] = phi half* [ [[PIN]], [[WHILE_BODY_PREHEADER]] ], [ [[ADD_PTR_PROL]], [[WHILE_BODY_PROL]] ]
; CHECK-PWR8-NEXT:    [[POUT_ADDR_028_UNR:%.*]] = phi half* [ [[POUT]], [[WHILE_BODY_PREHEADER]] ], [ [[ADD_PTR7_PROL]], [[WHILE_BODY_PROL]] ]
; CHECK-PWR8-NEXT:    [[BLKCNT_027_UNR:%.*]] = phi i32 [ [[SHR]], [[WHILE_BODY_PREHEADER]] ], [ [[DEC_PROL]], [[WHILE_BODY_PROL]] ]
; CHECK-PWR8-NEXT:    [[TMP4:%.*]] = icmp ult i32 [[TMP1]], 7
; CHECK-PWR8-NEXT:    br i1 [[TMP4]], label [[WHILE_END]], label [[WHILE_BODY:%.*]]
; CHECK-PWR8:       while.body:
; CHECK-PWR8-NEXT:    [[PIN_ADDR_029:%.*]] = phi half* [ [[ADD_PTR_7:%.*]], [[WHILE_BODY]] ], [ [[PIN_ADDR_029_UNR]], [[WHILE_BODY_PROL_LOOPEXIT]] ]
; CHECK-PWR8-NEXT:    [[POUT_ADDR_028:%.*]] = phi half* [ [[ADD_PTR7_7:%.*]], [[WHILE_BODY]] ], [ [[POUT_ADDR_028_UNR]], [[WHILE_BODY_PROL_LOOPEXIT]] ]
; CHECK-PWR8-NEXT:    [[BLKCNT_027:%.*]] = phi i32 [ [[DEC_7:%.*]], [[WHILE_BODY]] ], [ [[BLKCNT_027_UNR]], [[WHILE_BODY_PROL_LOOPEXIT]] ]
; CHECK-PWR8-NEXT:    [[TMP5:%.*]] = load half, half* [[PIN_ADDR_029]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 1
; CHECK-PWR8-NEXT:    [[TMP6:%.*]] = load half, half* [[ARRAYIDX2]], align 2
; CHECK-PWR8-NEXT:    [[MUL3:%.*]] = fmul half [[TMP5]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4:%.*]] = fmul half [[TMP6]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3]], half* [[POUT_ADDR_028]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 1
; CHECK-PWR8-NEXT:    store half [[MUL4]], half* [[ARRAYIDX6]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 2
; CHECK-PWR8-NEXT:    [[ADD_PTR7:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 2
; CHECK-PWR8-NEXT:    [[TMP7:%.*]] = load half, half* [[ADD_PTR]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2_1:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 3
; CHECK-PWR8-NEXT:    [[TMP8:%.*]] = load half, half* [[ARRAYIDX2_1]], align 2
; CHECK-PWR8-NEXT:    [[MUL3_1:%.*]] = fmul half [[TMP7]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4_1:%.*]] = fmul half [[TMP8]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3_1]], half* [[ADD_PTR7]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6_1:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 3
; CHECK-PWR8-NEXT:    store half [[MUL4_1]], half* [[ARRAYIDX6_1]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR_1:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 4
; CHECK-PWR8-NEXT:    [[ADD_PTR7_1:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 4
; CHECK-PWR8-NEXT:    [[TMP9:%.*]] = load half, half* [[ADD_PTR_1]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2_2:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 5
; CHECK-PWR8-NEXT:    [[TMP10:%.*]] = load half, half* [[ARRAYIDX2_2]], align 2
; CHECK-PWR8-NEXT:    [[MUL3_2:%.*]] = fmul half [[TMP9]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4_2:%.*]] = fmul half [[TMP10]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3_2]], half* [[ADD_PTR7_1]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6_2:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 5
; CHECK-PWR8-NEXT:    store half [[MUL4_2]], half* [[ARRAYIDX6_2]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR_2:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 6
; CHECK-PWR8-NEXT:    [[ADD_PTR7_2:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 6
; CHECK-PWR8-NEXT:    [[TMP11:%.*]] = load half, half* [[ADD_PTR_2]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2_3:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 7
; CHECK-PWR8-NEXT:    [[TMP12:%.*]] = load half, half* [[ARRAYIDX2_3]], align 2
; CHECK-PWR8-NEXT:    [[MUL3_3:%.*]] = fmul half [[TMP11]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4_3:%.*]] = fmul half [[TMP12]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3_3]], half* [[ADD_PTR7_2]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6_3:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 7
; CHECK-PWR8-NEXT:    store half [[MUL4_3]], half* [[ARRAYIDX6_3]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR_3:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 8
; CHECK-PWR8-NEXT:    [[ADD_PTR7_3:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 8
; CHECK-PWR8-NEXT:    [[TMP13:%.*]] = load half, half* [[ADD_PTR_3]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2_4:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 9
; CHECK-PWR8-NEXT:    [[TMP14:%.*]] = load half, half* [[ARRAYIDX2_4]], align 2
; CHECK-PWR8-NEXT:    [[MUL3_4:%.*]] = fmul half [[TMP13]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4_4:%.*]] = fmul half [[TMP14]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3_4]], half* [[ADD_PTR7_3]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6_4:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 9
; CHECK-PWR8-NEXT:    store half [[MUL4_4]], half* [[ARRAYIDX6_4]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR_4:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 10
; CHECK-PWR8-NEXT:    [[ADD_PTR7_4:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 10
; CHECK-PWR8-NEXT:    [[TMP15:%.*]] = load half, half* [[ADD_PTR_4]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2_5:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 11
; CHECK-PWR8-NEXT:    [[TMP16:%.*]] = load half, half* [[ARRAYIDX2_5]], align 2
; CHECK-PWR8-NEXT:    [[MUL3_5:%.*]] = fmul half [[TMP15]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4_5:%.*]] = fmul half [[TMP16]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3_5]], half* [[ADD_PTR7_4]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6_5:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 11
; CHECK-PWR8-NEXT:    store half [[MUL4_5]], half* [[ARRAYIDX6_5]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR_5:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 12
; CHECK-PWR8-NEXT:    [[ADD_PTR7_5:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 12
; CHECK-PWR8-NEXT:    [[TMP17:%.*]] = load half, half* [[ADD_PTR_5]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2_6:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 13
; CHECK-PWR8-NEXT:    [[TMP18:%.*]] = load half, half* [[ARRAYIDX2_6]], align 2
; CHECK-PWR8-NEXT:    [[MUL3_6:%.*]] = fmul half [[TMP17]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4_6:%.*]] = fmul half [[TMP18]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3_6]], half* [[ADD_PTR7_5]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6_6:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 13
; CHECK-PWR8-NEXT:    store half [[MUL4_6]], half* [[ARRAYIDX6_6]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR_6:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 14
; CHECK-PWR8-NEXT:    [[ADD_PTR7_6:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 14
; CHECK-PWR8-NEXT:    [[TMP19:%.*]] = load half, half* [[ADD_PTR_6]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX2_7:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 15
; CHECK-PWR8-NEXT:    [[TMP20:%.*]] = load half, half* [[ARRAYIDX2_7]], align 2
; CHECK-PWR8-NEXT:    [[MUL3_7:%.*]] = fmul half [[TMP19]], [[TMP0]]
; CHECK-PWR8-NEXT:    [[MUL4_7:%.*]] = fmul half [[TMP20]], [[TMP0]]
; CHECK-PWR8-NEXT:    store half [[MUL3_7]], half* [[ADD_PTR7_6]], align 2
; CHECK-PWR8-NEXT:    [[ARRAYIDX6_7:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 15
; CHECK-PWR8-NEXT:    store half [[MUL4_7]], half* [[ARRAYIDX6_7]], align 2
; CHECK-PWR8-NEXT:    [[ADD_PTR_7]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 16
; CHECK-PWR8-NEXT:    [[ADD_PTR7_7]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 16
; CHECK-PWR8-NEXT:    [[DEC_7]] = add nsw i32 [[BLKCNT_027]], -8
; CHECK-PWR8-NEXT:    [[CMP_7:%.*]] = icmp eq i32 [[DEC_7]], 0
; CHECK-PWR8-NEXT:    br i1 [[CMP_7]], label [[WHILE_END]], label [[WHILE_BODY]]
; CHECK-PWR8:       while.end:
; CHECK-PWR8-NEXT:    ret void
;
; CHECK-PWR9-LABEL: @fp16_(
; CHECK-PWR9-NEXT:  entry:
; CHECK-PWR9-NEXT:    [[TMP_0_EXTRACT_TRUNC:%.*]] = trunc i32 [[SCALE_COERCE:%.*]] to i16
; CHECK-PWR9-NEXT:    [[TMP0:%.*]] = bitcast i16 [[TMP_0_EXTRACT_TRUNC]] to half
; CHECK-PWR9-NEXT:    [[MUL:%.*]] = mul i32 [[NUMCOLS:%.*]], [[NUMROWS:%.*]]
; CHECK-PWR9-NEXT:    [[CMP26:%.*]] = icmp ult i32 [[MUL]], 4
; CHECK-PWR9-NEXT:    br i1 [[CMP26]], label [[WHILE_END:%.*]], label [[WHILE_BODY_PREHEADER:%.*]]
; CHECK-PWR9:       while.body.preheader:
; CHECK-PWR9-NEXT:    [[SHR:%.*]] = lshr i32 [[MUL]], 2
; CHECK-PWR9-NEXT:    [[TMP1:%.*]] = add nsw i32 [[SHR]], -1
; CHECK-PWR9-NEXT:    [[XTRAITER:%.*]] = and i32 [[SHR]], 7
; CHECK-PWR9-NEXT:    [[LCMP_MOD_NOT:%.*]] = icmp eq i32 [[XTRAITER]], 0
; CHECK-PWR9-NEXT:    br i1 [[LCMP_MOD_NOT]], label [[WHILE_BODY_PROL_LOOPEXIT:%.*]], label [[WHILE_BODY_PROL:%.*]]
; CHECK-PWR9:       while.body.prol:
; CHECK-PWR9-NEXT:    [[PIN_ADDR_029_PROL:%.*]] = phi half* [ [[ADD_PTR_PROL:%.*]], [[WHILE_BODY_PROL]] ], [ [[PIN:%.*]], [[WHILE_BODY_PREHEADER]] ]
; CHECK-PWR9-NEXT:    [[POUT_ADDR_028_PROL:%.*]] = phi half* [ [[ADD_PTR7_PROL:%.*]], [[WHILE_BODY_PROL]] ], [ [[POUT:%.*]], [[WHILE_BODY_PREHEADER]] ]
; CHECK-PWR9-NEXT:    [[BLKCNT_027_PROL:%.*]] = phi i32 [ [[DEC_PROL:%.*]], [[WHILE_BODY_PROL]] ], [ [[SHR]], [[WHILE_BODY_PREHEADER]] ]
; CHECK-PWR9-NEXT:    [[PROL_ITER:%.*]] = phi i32 [ [[PROL_ITER_NEXT:%.*]], [[WHILE_BODY_PROL]] ], [ 0, [[WHILE_BODY_PREHEADER]] ]
; CHECK-PWR9-NEXT:    [[TMP2:%.*]] = load half, half* [[PIN_ADDR_029_PROL]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2_PROL:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029_PROL]], i64 1
; CHECK-PWR9-NEXT:    [[TMP3:%.*]] = load half, half* [[ARRAYIDX2_PROL]], align 2
; CHECK-PWR9-NEXT:    [[MUL3_PROL:%.*]] = fmul half [[TMP2]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4_PROL:%.*]] = fmul half [[TMP3]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3_PROL]], half* [[POUT_ADDR_028_PROL]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6_PROL:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028_PROL]], i64 1
; CHECK-PWR9-NEXT:    store half [[MUL4_PROL]], half* [[ARRAYIDX6_PROL]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR_PROL]] = getelementptr inbounds half, half* [[PIN_ADDR_029_PROL]], i64 2
; CHECK-PWR9-NEXT:    [[ADD_PTR7_PROL]] = getelementptr inbounds half, half* [[POUT_ADDR_028_PROL]], i64 2
; CHECK-PWR9-NEXT:    [[DEC_PROL]] = add nsw i32 [[BLKCNT_027_PROL]], -1
; CHECK-PWR9-NEXT:    [[PROL_ITER_NEXT]] = add i32 [[PROL_ITER]], 1
; CHECK-PWR9-NEXT:    [[PROL_ITER_CMP_NOT:%.*]] = icmp eq i32 [[PROL_ITER_NEXT]], [[XTRAITER]]
; CHECK-PWR9-NEXT:    br i1 [[PROL_ITER_CMP_NOT]], label [[WHILE_BODY_PROL_LOOPEXIT]], label [[WHILE_BODY_PROL]], !llvm.loop [[LOOP8:![0-9]+]]
; CHECK-PWR9:       while.body.prol.loopexit:
; CHECK-PWR9-NEXT:    [[PIN_ADDR_029_UNR:%.*]] = phi half* [ [[PIN]], [[WHILE_BODY_PREHEADER]] ], [ [[ADD_PTR_PROL]], [[WHILE_BODY_PROL]] ]
; CHECK-PWR9-NEXT:    [[POUT_ADDR_028_UNR:%.*]] = phi half* [ [[POUT]], [[WHILE_BODY_PREHEADER]] ], [ [[ADD_PTR7_PROL]], [[WHILE_BODY_PROL]] ]
; CHECK-PWR9-NEXT:    [[BLKCNT_027_UNR:%.*]] = phi i32 [ [[SHR]], [[WHILE_BODY_PREHEADER]] ], [ [[DEC_PROL]], [[WHILE_BODY_PROL]] ]
; CHECK-PWR9-NEXT:    [[TMP4:%.*]] = icmp ult i32 [[TMP1]], 7
; CHECK-PWR9-NEXT:    br i1 [[TMP4]], label [[WHILE_END]], label [[WHILE_BODY:%.*]]
; CHECK-PWR9:       while.body:
; CHECK-PWR9-NEXT:    [[PIN_ADDR_029:%.*]] = phi half* [ [[ADD_PTR_7:%.*]], [[WHILE_BODY]] ], [ [[PIN_ADDR_029_UNR]], [[WHILE_BODY_PROL_LOOPEXIT]] ]
; CHECK-PWR9-NEXT:    [[POUT_ADDR_028:%.*]] = phi half* [ [[ADD_PTR7_7:%.*]], [[WHILE_BODY]] ], [ [[POUT_ADDR_028_UNR]], [[WHILE_BODY_PROL_LOOPEXIT]] ]
; CHECK-PWR9-NEXT:    [[BLKCNT_027:%.*]] = phi i32 [ [[DEC_7:%.*]], [[WHILE_BODY]] ], [ [[BLKCNT_027_UNR]], [[WHILE_BODY_PROL_LOOPEXIT]] ]
; CHECK-PWR9-NEXT:    [[TMP5:%.*]] = load half, half* [[PIN_ADDR_029]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 1
; CHECK-PWR9-NEXT:    [[TMP6:%.*]] = load half, half* [[ARRAYIDX2]], align 2
; CHECK-PWR9-NEXT:    [[MUL3:%.*]] = fmul half [[TMP5]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4:%.*]] = fmul half [[TMP6]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3]], half* [[POUT_ADDR_028]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 1
; CHECK-PWR9-NEXT:    store half [[MUL4]], half* [[ARRAYIDX6]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 2
; CHECK-PWR9-NEXT:    [[ADD_PTR7:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 2
; CHECK-PWR9-NEXT:    [[TMP7:%.*]] = load half, half* [[ADD_PTR]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2_1:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 3
; CHECK-PWR9-NEXT:    [[TMP8:%.*]] = load half, half* [[ARRAYIDX2_1]], align 2
; CHECK-PWR9-NEXT:    [[MUL3_1:%.*]] = fmul half [[TMP7]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4_1:%.*]] = fmul half [[TMP8]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3_1]], half* [[ADD_PTR7]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6_1:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 3
; CHECK-PWR9-NEXT:    store half [[MUL4_1]], half* [[ARRAYIDX6_1]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR_1:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 4
; CHECK-PWR9-NEXT:    [[ADD_PTR7_1:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 4
; CHECK-PWR9-NEXT:    [[TMP9:%.*]] = load half, half* [[ADD_PTR_1]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2_2:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 5
; CHECK-PWR9-NEXT:    [[TMP10:%.*]] = load half, half* [[ARRAYIDX2_2]], align 2
; CHECK-PWR9-NEXT:    [[MUL3_2:%.*]] = fmul half [[TMP9]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4_2:%.*]] = fmul half [[TMP10]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3_2]], half* [[ADD_PTR7_1]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6_2:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 5
; CHECK-PWR9-NEXT:    store half [[MUL4_2]], half* [[ARRAYIDX6_2]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR_2:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 6
; CHECK-PWR9-NEXT:    [[ADD_PTR7_2:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 6
; CHECK-PWR9-NEXT:    [[TMP11:%.*]] = load half, half* [[ADD_PTR_2]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2_3:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 7
; CHECK-PWR9-NEXT:    [[TMP12:%.*]] = load half, half* [[ARRAYIDX2_3]], align 2
; CHECK-PWR9-NEXT:    [[MUL3_3:%.*]] = fmul half [[TMP11]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4_3:%.*]] = fmul half [[TMP12]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3_3]], half* [[ADD_PTR7_2]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6_3:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 7
; CHECK-PWR9-NEXT:    store half [[MUL4_3]], half* [[ARRAYIDX6_3]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR_3:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 8
; CHECK-PWR9-NEXT:    [[ADD_PTR7_3:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 8
; CHECK-PWR9-NEXT:    [[TMP13:%.*]] = load half, half* [[ADD_PTR_3]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2_4:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 9
; CHECK-PWR9-NEXT:    [[TMP14:%.*]] = load half, half* [[ARRAYIDX2_4]], align 2
; CHECK-PWR9-NEXT:    [[MUL3_4:%.*]] = fmul half [[TMP13]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4_4:%.*]] = fmul half [[TMP14]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3_4]], half* [[ADD_PTR7_3]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6_4:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 9
; CHECK-PWR9-NEXT:    store half [[MUL4_4]], half* [[ARRAYIDX6_4]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR_4:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 10
; CHECK-PWR9-NEXT:    [[ADD_PTR7_4:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 10
; CHECK-PWR9-NEXT:    [[TMP15:%.*]] = load half, half* [[ADD_PTR_4]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2_5:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 11
; CHECK-PWR9-NEXT:    [[TMP16:%.*]] = load half, half* [[ARRAYIDX2_5]], align 2
; CHECK-PWR9-NEXT:    [[MUL3_5:%.*]] = fmul half [[TMP15]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4_5:%.*]] = fmul half [[TMP16]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3_5]], half* [[ADD_PTR7_4]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6_5:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 11
; CHECK-PWR9-NEXT:    store half [[MUL4_5]], half* [[ARRAYIDX6_5]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR_5:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 12
; CHECK-PWR9-NEXT:    [[ADD_PTR7_5:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 12
; CHECK-PWR9-NEXT:    [[TMP17:%.*]] = load half, half* [[ADD_PTR_5]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2_6:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 13
; CHECK-PWR9-NEXT:    [[TMP18:%.*]] = load half, half* [[ARRAYIDX2_6]], align 2
; CHECK-PWR9-NEXT:    [[MUL3_6:%.*]] = fmul half [[TMP17]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4_6:%.*]] = fmul half [[TMP18]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3_6]], half* [[ADD_PTR7_5]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6_6:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 13
; CHECK-PWR9-NEXT:    store half [[MUL4_6]], half* [[ARRAYIDX6_6]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR_6:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 14
; CHECK-PWR9-NEXT:    [[ADD_PTR7_6:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 14
; CHECK-PWR9-NEXT:    [[TMP19:%.*]] = load half, half* [[ADD_PTR_6]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX2_7:%.*]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 15
; CHECK-PWR9-NEXT:    [[TMP20:%.*]] = load half, half* [[ARRAYIDX2_7]], align 2
; CHECK-PWR9-NEXT:    [[MUL3_7:%.*]] = fmul half [[TMP19]], [[TMP0]]
; CHECK-PWR9-NEXT:    [[MUL4_7:%.*]] = fmul half [[TMP20]], [[TMP0]]
; CHECK-PWR9-NEXT:    store half [[MUL3_7]], half* [[ADD_PTR7_6]], align 2
; CHECK-PWR9-NEXT:    [[ARRAYIDX6_7:%.*]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 15
; CHECK-PWR9-NEXT:    store half [[MUL4_7]], half* [[ARRAYIDX6_7]], align 2
; CHECK-PWR9-NEXT:    [[ADD_PTR_7]] = getelementptr inbounds half, half* [[PIN_ADDR_029]], i64 16
; CHECK-PWR9-NEXT:    [[ADD_PTR7_7]] = getelementptr inbounds half, half* [[POUT_ADDR_028]], i64 16
; CHECK-PWR9-NEXT:    [[DEC_7]] = add nsw i32 [[BLKCNT_027]], -8
; CHECK-PWR9-NEXT:    [[CMP_7:%.*]] = icmp eq i32 [[DEC_7]], 0
; CHECK-PWR9-NEXT:    br i1 [[CMP_7]], label [[WHILE_END]], label [[WHILE_BODY]]
; CHECK-PWR9:       while.end:
; CHECK-PWR9-NEXT:    ret void
;
entry:
  %tmp.0.extract.trunc = trunc i32 %scale.coerce to i16
  %0 = bitcast i16 %tmp.0.extract.trunc to half
  %mul = mul i32 %numCols, %numRows
  %shr = lshr i32 %mul, 2
  %cmp26 = icmp eq i32 %shr, 0
  br i1 %cmp26, label %while.end, label %while.body

while.body:                                       ; preds = %entry, %while.body
  %pIn.addr.029 = phi half* [ %add.ptr, %while.body ], [ %pIn, %entry ]
  %pOut.addr.028 = phi half* [ %add.ptr7, %while.body ], [ %pOut, %entry ]
  %blkCnt.027 = phi i32 [ %dec, %while.body ], [ %shr, %entry ]
  %1 = load half, half* %pIn.addr.029, align 2
  %arrayidx2 = getelementptr inbounds half, half* %pIn.addr.029, i32 1
  %2 = load half, half* %arrayidx2, align 2
  %mul3 = fmul half %1, %0
  %mul4 = fmul half %2, %0
  store half %mul3, half* %pOut.addr.028, align 2
  %arrayidx6 = getelementptr inbounds half, half* %pOut.addr.028, i32 1
  store half %mul4, half* %arrayidx6, align 2
  %add.ptr = getelementptr inbounds half, half* %pIn.addr.029, i32 2
  %add.ptr7 = getelementptr inbounds half, half* %pOut.addr.028, i32 2
  %dec = add nsw i32 %blkCnt.027, -1
  %cmp = icmp eq i32 %dec, 0
  br i1 %cmp, label %while.end, label %while.body

while.end:                                        ; preds = %while.body, %entry
  ret void
}
