; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -p loop-vectorize -force-vector-width=4 -S -mtriple=riscv64 -mattr=+v -prefer-control-flow %s | FileCheck %s

define void @conditional_store(ptr %addr, i64 %N, i64 %M) {
; CHECK-LABEL: define void @conditional_store(
; CHECK-SAME: ptr [[ADDR:%.*]], i64 [[N:%.*]], i64 [[M:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[N]], 8
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[N]], 8
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[N]], [[N_MOD_VF]]
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x i64> poison, i64 [[M]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x i64> [[BROADCAST_SPLATINSERT]], <4 x i64> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[LOOP_IF_SPLIT:.*]] ]
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr i64, ptr [[ADDR]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i64, ptr [[TMP2]], i64 4
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i64>, ptr [[TMP2]], align 8
; CHECK-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i64>, ptr [[TMP4]], align 8
; CHECK-NEXT:    [[TMP7:%.*]] = icmp eq <4 x i64> [[WIDE_LOAD]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP8:%.*]] = icmp eq <4 x i64> [[WIDE_LOAD3]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP12:%.*]] = freeze <4 x i1> [[TMP7]]
; CHECK-NEXT:    [[TMP13:%.*]] = freeze <4 x i1> [[TMP8]]
; CHECK-NEXT:    [[TMP14:%.*]] = or <4 x i1> [[TMP12]], [[TMP13]]
; CHECK-NEXT:    [[TMP11:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP14]])
; CHECK-NEXT:    br i1 [[TMP11]], label %[[VECTOR_IF_BB:.*]], label %[[LOOP_IF_SPLIT]]
; CHECK:       [[VECTOR_IF_BB]]:
; CHECK-NEXT:    [[TMP9:%.*]] = add <4 x i64> [[WIDE_LOAD]], splat (i64 1)
; CHECK-NEXT:    [[TMP10:%.*]] = add <4 x i64> [[WIDE_LOAD3]], splat (i64 1)
; CHECK-NEXT:    call void @llvm.masked.store.v4i64.p0(<4 x i64> [[TMP9]], ptr align 8 [[TMP2]], <4 x i1> [[TMP7]])
; CHECK-NEXT:    call void @llvm.masked.store.v4i64.p0(<4 x i64> [[TMP10]], ptr align 8 [[TMP4]], <4 x i1> [[TMP8]])
; CHECK-NEXT:    br label %[[LOOP_IF_SPLIT]]
; CHECK:       [[LOOP_IF_SPLIT]]:
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 8
; CHECK-NEXT:    [[TMP26:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP26]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[N]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], label %[[EXIT:.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N_VEC]], %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ]
; CHECK-NEXT:    br label %[[LOOP:.*]]
; CHECK:       [[LOOP]]:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[INDVARS_IV_NEXT:%.*]], %[[LOOP_CONT:.*]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i64, ptr [[ADDR]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[TMP27:%.*]] = load i64, ptr [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[OR_COND_NOT:%.*]] = icmp eq i64 [[TMP27]], [[M]]
; CHECK-NEXT:    br i1 [[OR_COND_NOT]], label %[[LOOP_IF:.*]], label %[[LOOP_CONT]]
; CHECK:       [[LOOP_IF]]:
; CHECK-NEXT:    [[XOR:%.*]] = add i64 [[TMP27]], 1
; CHECK-NEXT:    store i64 [[XOR]], ptr [[ARRAYIDX]], align 8
; CHECK-NEXT:    br label %[[LOOP_CONT]]
; CHECK:       [[LOOP_CONT]]:
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label %[[EXIT]], label %[[LOOP]], !llvm.loop [[LOOP3:![0-9]+]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop.cont ]
  %arrayidx = getelementptr inbounds i64, ptr %addr, i64 %iv
  %2 = load i64, ptr %arrayidx, align 8
  %or.cond.not = icmp eq i64 %2, %M
  br i1 %or.cond.not, label %loop.if, label %loop.cont

loop.if:
  %stored.val = add i64 %2, 1
  store i64 %stored.val, ptr %arrayidx, align 8
  br label %loop.cont

loop.cont:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond.not = icmp eq i64 %iv.next, %N
  br i1 %exitcond.not, label %exit, label %loop

exit:
  ret void
}

; Test for control flow along with live-out calculated in the conditional block.
define i64 @conditional_liveout_and_store(ptr %addr, i64 %N, i64 %M) {
; CHECK-LABEL: define i64 @conditional_liveout_and_store(
; CHECK-SAME: ptr [[ADDR:%.*]], i64 [[N:%.*]], i64 [[M:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[N]], 8
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[N]], 8
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[N]], [[N_MOD_VF]]
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x i64> poison, i64 [[M]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x i64> [[BROADCAST_SPLATINSERT]], <4 x i64> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[LOOP_IF_SPLIT:.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i64> [ zeroinitializer, %[[VECTOR_PH]] ], [ [[PREDPHI:%.*]], %[[LOOP_IF_SPLIT]] ]
; CHECK-NEXT:    [[VEC_PHI1:%.*]] = phi <4 x i64> [ zeroinitializer, %[[VECTOR_PH]] ], [ [[PREDPHI3:%.*]], %[[LOOP_IF_SPLIT]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i64, ptr [[ADDR]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i64, ptr [[TMP0]], i64 4
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i64>, ptr [[TMP0]], align 8
; CHECK-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i64>, ptr [[TMP1]], align 8
; CHECK-NEXT:    [[TMP2:%.*]] = icmp eq <4 x i64> [[WIDE_LOAD]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq <4 x i64> [[WIDE_LOAD2]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP4:%.*]] = freeze <4 x i1> [[TMP2]]
; CHECK-NEXT:    [[TMP5:%.*]] = freeze <4 x i1> [[TMP3]]
; CHECK-NEXT:    [[TMP6:%.*]] = or <4 x i1> [[TMP4]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP6]])
; CHECK-NEXT:    br i1 [[TMP7]], label %[[VECTOR_IF_BB:.*]], label %[[LOOP_IF_SPLIT]]
; CHECK:       [[VECTOR_IF_BB]]:
; CHECK-NEXT:    [[TMP8:%.*]] = add <4 x i64> [[WIDE_LOAD]], splat (i64 1)
; CHECK-NEXT:    [[TMP9:%.*]] = add <4 x i64> [[WIDE_LOAD2]], splat (i64 1)
; CHECK-NEXT:    call void @llvm.masked.store.v4i64.p0(<4 x i64> [[TMP8]], ptr align 8 [[TMP0]], <4 x i1> [[TMP2]])
; CHECK-NEXT:    call void @llvm.masked.store.v4i64.p0(<4 x i64> [[TMP9]], ptr align 8 [[TMP1]], <4 x i1> [[TMP3]])
; CHECK-NEXT:    br label %[[LOOP_IF_SPLIT]]
; CHECK:       [[LOOP_IF_SPLIT]]:
; CHECK-NEXT:    [[TMP10:%.*]] = add <4 x i64> [[VEC_PHI]], splat (i64 1)
; CHECK-NEXT:    [[TMP11:%.*]] = add <4 x i64> [[VEC_PHI1]], splat (i64 1)
; CHECK-NEXT:    [[PREDPHI]] = select <4 x i1> [[TMP2]], <4 x i64> [[TMP10]], <4 x i64> [[VEC_PHI]]
; CHECK-NEXT:    [[PREDPHI3]] = select <4 x i1> [[TMP3]], <4 x i64> [[TMP11]], <4 x i64> [[VEC_PHI1]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 8
; CHECK-NEXT:    [[TMP12:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP12]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[BIN_RDX:%.*]] = add <4 x i64> [[PREDPHI3]], [[PREDPHI]]
; CHECK-NEXT:    [[TMP13:%.*]] = call i64 @llvm.vector.reduce.add.v4i64(<4 x i64> [[BIN_RDX]])
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[N]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], label %[[EXIT:.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N_VEC]], %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ]
; CHECK-NEXT:    [[BC_MERGE_RDX:%.*]] = phi i64 [ [[TMP13]], %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ]
; CHECK-NEXT:    br label %[[LOOP:.*]]
; CHECK:       [[LOOP]]:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP_CONT:.*]] ]
; CHECK-NEXT:    [[SUM:%.*]] = phi i64 [ [[BC_MERGE_RDX]], %[[SCALAR_PH]] ], [ [[SUM_NEXT:%.*]], %[[LOOP_CONT]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i64, ptr [[ADDR]], i64 [[IV]]
; CHECK-NEXT:    [[VAL:%.*]] = load i64, ptr [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i64 [[VAL]], [[M]]
; CHECK-NEXT:    br i1 [[COND]], label %[[LOOP_IF:.*]], label %[[LOOP_CONT]]
; CHECK:       [[LOOP_IF]]:
; CHECK-NEXT:    [[NEW_VAL:%.*]] = add i64 [[VAL]], 1
; CHECK-NEXT:    store i64 [[NEW_VAL]], ptr [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[SUM_INC:%.*]] = add i64 [[SUM]], 1
; CHECK-NEXT:    br label %[[LOOP_CONT]]
; CHECK:       [[LOOP_CONT]]:
; CHECK-NEXT:    [[SUM_NEXT]] = phi i64 [ [[SUM_INC]], %[[LOOP_IF]] ], [ [[SUM]], %[[LOOP]] ]
; CHECK-NEXT:    [[IV_NEXT]] = add nuw nsw i64 [[IV]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[IV_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[EXIT]], label %[[LOOP]], !llvm.loop [[LOOP5:![0-9]+]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    [[SUM_NEXT_LCSSA:%.*]] = phi i64 [ [[SUM_NEXT]], %[[LOOP_CONT]] ], [ [[TMP13]], %[[MIDDLE_BLOCK]] ]
; CHECK-NEXT:    ret i64 [[SUM_NEXT_LCSSA]]
;
entry:
  br label %loop

loop:
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop.cont ]
  %sum = phi i64 [ 0, %entry ], [ %sum.next, %loop.cont ]
  %arrayidx = getelementptr inbounds i64, ptr %addr, i64 %iv
  %val = load i64, ptr %arrayidx, align 8
  %cond = icmp eq i64 %val, %M
  br i1 %cond, label %loop.if, label %loop.cont

loop.if:
  %new_val = add i64 %val, 1
  store i64 %new_val, ptr %arrayidx, align 8
  %sum.inc = add i64 %sum, 1
  br label %loop.cont

loop.cont:
  %sum.next = phi i64 [ %sum.inc, %loop.if ], [ %sum, %loop ]
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %N
  br i1 %exitcond, label %exit, label %loop

exit:
  ret i64 %sum.next
}

; Test for control flow with live-out calculated in both paths.
define i64 @conditional_liveout_both_path(ptr %addr, i64 %N, i64 %M) {
; CHECK-LABEL: define i64 @conditional_liveout_both_path(
; CHECK-SAME: ptr [[ADDR:%.*]], i64 [[N:%.*]], i64 [[M:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[N]], 8
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[N]], 8
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[N]], [[N_MOD_VF]]
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x i64> poison, i64 [[M]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x i64> [[BROADCAST_SPLATINSERT]], <4 x i64> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[LOOP_IF_SPLIT:.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i64> [ zeroinitializer, %[[VECTOR_PH]] ], [ [[PREDPHI:%.*]], %[[LOOP_IF_SPLIT]] ]
; CHECK-NEXT:    [[VEC_PHI1:%.*]] = phi <4 x i64> [ zeroinitializer, %[[VECTOR_PH]] ], [ [[PREDPHI3:%.*]], %[[LOOP_IF_SPLIT]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr i64, ptr [[ADDR]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr i64, ptr [[TMP0]], i64 4
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i64>, ptr [[TMP0]], align 8
; CHECK-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i64>, ptr [[TMP1]], align 8
; CHECK-NEXT:    [[TMP2:%.*]] = icmp eq <4 x i64> [[WIDE_LOAD]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq <4 x i64> [[WIDE_LOAD2]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP4:%.*]] = add <4 x i64> [[VEC_PHI]], [[WIDE_LOAD]]
; CHECK-NEXT:    [[TMP5:%.*]] = add <4 x i64> [[VEC_PHI1]], [[WIDE_LOAD2]]
; CHECK-NEXT:    [[TMP6:%.*]] = add <4 x i64> [[WIDE_LOAD]], splat (i64 1)
; CHECK-NEXT:    [[TMP7:%.*]] = add <4 x i64> [[WIDE_LOAD2]], splat (i64 1)
; CHECK-NEXT:    [[TMP8:%.*]] = freeze <4 x i1> [[TMP2]]
; CHECK-NEXT:    [[TMP9:%.*]] = freeze <4 x i1> [[TMP3]]
; CHECK-NEXT:    [[TMP10:%.*]] = or <4 x i1> [[TMP8]], [[TMP9]]
; CHECK-NEXT:    [[TMP11:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP10]])
; CHECK-NEXT:    br i1 [[TMP11]], label %[[VECTOR_IF_BB:.*]], label %[[LOOP_IF_SPLIT]]
; CHECK:       [[VECTOR_IF_BB]]:
; CHECK-NEXT:    call void @llvm.masked.store.v4i64.p0(<4 x i64> [[TMP6]], ptr align 8 [[TMP0]], <4 x i1> [[TMP2]])
; CHECK-NEXT:    call void @llvm.masked.store.v4i64.p0(<4 x i64> [[TMP7]], ptr align 8 [[TMP1]], <4 x i1> [[TMP3]])
; CHECK-NEXT:    br label %[[LOOP_IF_SPLIT]]
; CHECK:       [[LOOP_IF_SPLIT]]:
; CHECK-NEXT:    [[TMP12:%.*]] = add <4 x i64> [[VEC_PHI]], [[TMP6]]
; CHECK-NEXT:    [[TMP13:%.*]] = add <4 x i64> [[VEC_PHI1]], [[TMP7]]
; CHECK-NEXT:    [[PREDPHI]] = select <4 x i1> [[TMP2]], <4 x i64> [[TMP12]], <4 x i64> [[TMP4]]
; CHECK-NEXT:    [[PREDPHI3]] = select <4 x i1> [[TMP3]], <4 x i64> [[TMP13]], <4 x i64> [[TMP5]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 8
; CHECK-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP14]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP6:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[BIN_RDX:%.*]] = add <4 x i64> [[PREDPHI3]], [[PREDPHI]]
; CHECK-NEXT:    [[TMP15:%.*]] = call i64 @llvm.vector.reduce.add.v4i64(<4 x i64> [[BIN_RDX]])
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[N]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], label %[[EXIT:.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N_VEC]], %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ]
; CHECK-NEXT:    [[BC_MERGE_RDX:%.*]] = phi i64 [ [[TMP15]], %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ]
; CHECK-NEXT:    br label %[[LOOP:.*]]
; CHECK:       [[LOOP]]:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP_CONT:.*]] ]
; CHECK-NEXT:    [[ACC:%.*]] = phi i64 [ [[BC_MERGE_RDX]], %[[SCALAR_PH]] ], [ [[ACC_NEXT:%.*]], %[[LOOP_CONT]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i64, ptr [[ADDR]], i64 [[IV]]
; CHECK-NEXT:    [[VAL:%.*]] = load i64, ptr [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i64 [[VAL]], [[M]]
; CHECK-NEXT:    br i1 [[COND]], label %[[LOOP_IF:.*]], label %[[LOOP_ELSE:.*]]
; CHECK:       [[LOOP_IF]]:
; CHECK-NEXT:    [[NEW_VAL:%.*]] = add i64 [[VAL]], 1
; CHECK-NEXT:    store i64 [[NEW_VAL]], ptr [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[ACC_IF:%.*]] = add i64 [[ACC]], [[NEW_VAL]]
; CHECK-NEXT:    br label %[[LOOP_CONT]]
; CHECK:       [[LOOP_ELSE]]:
; CHECK-NEXT:    [[ACC_ELSE:%.*]] = add i64 [[ACC]], [[VAL]]
; CHECK-NEXT:    br label %[[LOOP_CONT]]
; CHECK:       [[LOOP_CONT]]:
; CHECK-NEXT:    [[ACC_NEXT]] = phi i64 [ [[ACC_IF]], %[[LOOP_IF]] ], [ [[ACC_ELSE]], %[[LOOP_ELSE]] ]
; CHECK-NEXT:    [[IV_NEXT]] = add nuw nsw i64 [[IV]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[IV_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND]], label %[[EXIT]], label %[[LOOP]], !llvm.loop [[LOOP7:![0-9]+]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    [[ACC_NEXT_LCSSA:%.*]] = phi i64 [ [[ACC_NEXT]], %[[LOOP_CONT]] ], [ [[TMP15]], %[[MIDDLE_BLOCK]] ]
; CHECK-NEXT:    ret i64 [[ACC_NEXT_LCSSA]]
;
entry:
  br label %loop

loop:
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop.cont ]
  %acc = phi i64 [ 0, %entry ], [ %acc.next, %loop.cont ]
  %arrayidx = getelementptr inbounds i64, ptr %addr, i64 %iv
  %val = load i64, ptr %arrayidx, align 8
  %cond = icmp eq i64 %val, %M
  br i1 %cond, label %loop.if, label %loop.else

loop.if:
  %new_val = add i64 %val, 1
  store i64 %new_val, ptr %arrayidx, align 8
  %acc.if = add i64 %acc, %new_val
  br label %loop.cont

loop.else:
  %acc.else = add i64 %acc, %val
  br label %loop.cont

loop.cont:
  %acc.next = phi i64 [ %acc.if, %loop.if ], [ %acc.else, %loop.else ]
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %N
  br i1 %exitcond, label %exit, label %loop

exit:
  ret i64 %acc.next
}
;.
; CHECK: [[LOOP0]] = distinct !{[[LOOP0]], [[META1:![0-9]+]], [[META2:![0-9]+]]}
; CHECK: [[META1]] = !{!"llvm.loop.isvectorized", i32 1}
; CHECK: [[META2]] = !{!"llvm.loop.unroll.runtime.disable"}
; CHECK: [[LOOP3]] = distinct !{[[LOOP3]], [[META2]], [[META1]]}
; CHECK: [[LOOP4]] = distinct !{[[LOOP4]], [[META1]], [[META2]]}
; CHECK: [[LOOP5]] = distinct !{[[LOOP5]], [[META2]], [[META1]]}
; CHECK: [[LOOP6]] = distinct !{[[LOOP6]], [[META1]], [[META2]]}
; CHECK: [[LOOP7]] = distinct !{[[LOOP7]], [[META2]], [[META1]]}
;.
