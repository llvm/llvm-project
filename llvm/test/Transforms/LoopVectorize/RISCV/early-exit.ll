; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 6
; RUN: opt -S < %s -p loop-vectorize -mtriple riscv64 -mattr=+v | FileCheck %s

declare void @init_mem(ptr, i64)

define i8 @predicate_exit_block_successors(ptr %p0) {
; CHECK-LABEL: define i8 @predicate_exit_block_successors(
; CHECK-SAME: ptr [[P0:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[P1:%.*]] = alloca [1024 x i8], align 1
; CHECK-NEXT:    [[P2:%.*]] = alloca [1024 x i8], align 1
; CHECK-NEXT:    call void @init_mem(ptr [[P1]], i64 1024)
; CHECK-NEXT:    call void @init_mem(ptr [[P2]], i64 1024)
; CHECK-NEXT:    br label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[TMP5:%.*]] = call <vscale x 16 x i64> @llvm.stepvector.nxv16i64()
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX1:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_EVL_NEXT:%.*]], %[[VECTOR_BODY_COND_1:.*]] ]
; CHECK-NEXT:    [[AVL:%.*]] = phi i64 [ 64, %[[VECTOR_PH]] ], [ [[AVL_NEXT:%.*]], %[[VECTOR_BODY_COND_1]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.experimental.get.vector.length.i64(i64 [[AVL]], i32 16, i1 true)
; CHECK-NEXT:    [[INDEX:%.*]] = add i64 3, [[INDEX1]]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[INDEX]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = call <vscale x 16 x i8> @llvm.vp.load.nxv16i8.p0(ptr align 1 [[ARRAYIDX]], <vscale x 16 x i1> splat (i1 true), i32 [[TMP1]])
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[INDEX]]
; CHECK-NEXT:    [[WIDE_LOAD2:%.*]] = call <vscale x 16 x i8> @llvm.vp.load.nxv16i8.p0(ptr align 1 [[TMP7]], <vscale x 16 x i1> splat (i1 true), i32 [[TMP1]])
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ne <vscale x 16 x i8> [[WIDE_LOAD]], [[WIDE_LOAD2]]
; CHECK-NEXT:    [[FIRST_ACTIVE_LANE:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.nxv16i1(<vscale x 16 x i1> [[TMP8]], i1 false)
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 16 x i64> poison, i64 [[FIRST_ACTIVE_LANE]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 16 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 16 x i64> poison, <vscale x 16 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ult <vscale x 16 x i64> [[TMP5]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[P0]], i64 [[INDEX]]
; CHECK-NEXT:    [[VP_OP_LOAD2:%.*]] = call <vscale x 16 x i8> @llvm.vp.load.nxv16i8.p0(ptr align 1 [[TMP10]], <vscale x 16 x i1> [[TMP9]], i32 [[TMP1]])
; CHECK-NEXT:    [[TMP13:%.*]] = zext i32 [[TMP1]] to i64
; CHECK-NEXT:    [[INDEX_EVL_NEXT]] = add nuw i64 [[TMP13]], [[INDEX1]]
; CHECK-NEXT:    [[AVL_NEXT]] = sub nuw i64 [[AVL]], [[TMP13]]
; CHECK-NEXT:    [[TMP11:%.*]] = freeze <vscale x 16 x i1> [[TMP8]]
; CHECK-NEXT:    [[TMP12:%.*]] = call i1 @llvm.vector.reduce.or.nxv16i1(<vscale x 16 x i1> [[TMP11]])
; CHECK-NEXT:    br i1 [[TMP12]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[VECTOR_BODY_COND_1]]
; CHECK:       [[VECTOR_BODY_COND_1]]:
; CHECK-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[AVL_NEXT]], 0
; CHECK-NEXT:    br i1 [[TMP14]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[TMP23:%.*]] = sub i64 [[TMP13]], 1
; CHECK-NEXT:    [[TMP19:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP20:%.*]] = mul nuw i64 [[TMP19]], 16
; CHECK-NEXT:    [[TMP21:%.*]] = mul i64 [[TMP20]], 0
; CHECK-NEXT:    [[TMP15:%.*]] = extractelement <vscale x 16 x i8> [[VP_OP_LOAD2]], i64 [[TMP23]]
; CHECK-NEXT:    br label %[[LOOP_END:.*]]
; CHECK:       [[VECTOR_EARLY_EXIT]]:
; CHECK-NEXT:    [[TMP16:%.*]] = call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP17:%.*]] = mul nuw i64 [[TMP16]], 16
; CHECK-NEXT:    [[TMP18:%.*]] = mul i64 [[TMP17]], 0
; CHECK-NEXT:    [[TMP22:%.*]] = extractelement <vscale x 16 x i8> [[WIDE_LOAD]], i64 [[FIRST_ACTIVE_LANE]]
; CHECK-NEXT:    br label %[[LOOP_END]]
; CHECK:       [[LOOP_END]]:
; CHECK-NEXT:    [[RETVAL:%.*]] = phi i8 [ [[TMP22]], %[[VECTOR_EARLY_EXIT]] ], [ [[TMP15]], %[[MIDDLE_BLOCK]] ]
; CHECK-NEXT:    ret i8 [[RETVAL]]
;
entry:
  %p1 = alloca [1024 x i8]
  %p2 = alloca [1024 x i8]
  call void @init_mem(ptr %p1, i64 1024)
  call void @init_mem(ptr %p2, i64 1024)
  br label %loop

loop:
  %index = phi i64 [ %index.next, %loop.inc ], [ 3, %entry ]
  %arrayidx = getelementptr inbounds i8, ptr %p1, i64 %index
  %ld1 = load i8, ptr %arrayidx, align 1
  %arrayidx1 = getelementptr inbounds i8, ptr %p2, i64 %index
  %ld2 = load i8, ptr %arrayidx1, align 1
  %cmp3 = icmp eq i8 %ld1, %ld2
  br i1 %cmp3, label %loop.inc, label %loop.end

loop.inc:
  %arrayidx2 = getelementptr inbounds i8, ptr %p0, i64 %index
  %ld3 = load i8, ptr %arrayidx2
  %index.next = add i64 %index, 1
  %exitcond = icmp ne i64 %index.next, 67
  br i1 %exitcond, label %loop, label %loop.end

loop.end:
  %retval = phi i8 [ %ld1, %loop ], [ %ld3, %loop.inc ]
  ret i8 %retval
}
;.
; CHECK: [[LOOP0]] = distinct !{[[LOOP0]], [[META1:![0-9]+]], [[META2:![0-9]+]]}
; CHECK: [[META1]] = !{!"llvm.loop.isvectorized", i32 1}
; CHECK: [[META2]] = !{!"llvm.loop.unroll.runtime.disable"}
;.
