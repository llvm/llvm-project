; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-globals none --version 6
; RUN: opt -p loop-vectorize -S %s | FileCheck --check-prefixes=COMMON,DEFAULT %s
; RUN: opt -p loop-vectorize -vectorizer-maximize-bandwidth -S %s | FileCheck --check-prefixes=COMMON,MAX-BW %s
; RUN: opt -p loop-vectorize -sve-prefer-fixed-over-scalable-if-equal=false -S %s | FileCheck --check-prefixes=COMMON,PREFER-SVE %s

target triple = "arm64-apple-macosx"

define i64 @early_exit_with_without_dereferenceable(ptr %p1, ptr %p2) {
; COMMON-LABEL: define i64 @early_exit_with_without_dereferenceable(
; COMMON-SAME: ptr [[P1:%.*]], ptr [[P2:%.*]]) {
; COMMON-NEXT:  [[ENTRY:.*:]]
; COMMON-NEXT:    br label %[[SPEC_LOAD_CHECK:.*]]
; COMMON:       [[SPEC_LOAD_CHECK]]:
; COMMON-NEXT:    [[TMP0:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[P1]], i64 16)
; COMMON-NEXT:    [[TMP1:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[P2]], i64 16)
; COMMON-NEXT:    [[TMP2:%.*]] = and i1 [[TMP0]], [[TMP1]]
; COMMON-NEXT:    [[TMP13:%.*]] = xor i1 [[TMP2]], true
; COMMON-NEXT:    br i1 [[TMP13]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; COMMON:       [[VECTOR_PH]]:
; COMMON-NEXT:    br label %[[VECTOR_BODY:.*]]
; COMMON:       [[VECTOR_BODY]]:
; COMMON-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY_INTERIM:.*]] ]
; COMMON-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[INDEX]]
; COMMON-NEXT:    [[TMP4:%.*]] = call <16 x i8> @llvm.speculative.load.v16i8.p0(ptr [[TMP3]])
; COMMON-NEXT:    [[TMP5:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[INDEX]]
; COMMON-NEXT:    [[TMP6:%.*]] = call <16 x i8> @llvm.speculative.load.v16i8.p0(ptr [[TMP5]])
; COMMON-NEXT:    [[TMP7:%.*]] = icmp ne <16 x i8> [[TMP4]], [[TMP6]]
; COMMON-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
; COMMON-NEXT:    [[TMP8:%.*]] = freeze <16 x i1> [[TMP7]]
; COMMON-NEXT:    [[TMP9:%.*]] = call i1 @llvm.vector.reduce.or.v16i1(<16 x i1> [[TMP8]])
; COMMON-NEXT:    [[TMP10:%.*]] = icmp eq i64 [[INDEX_NEXT]], 96
; COMMON-NEXT:    br i1 [[TMP9]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[VECTOR_BODY_INTERIM]]
; COMMON:       [[VECTOR_BODY_INTERIM]]:
; COMMON-NEXT:    br i1 [[TMP10]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; COMMON:       [[MIDDLE_BLOCK]]:
; COMMON-NEXT:    br label %[[SCALAR_PH]]
; COMMON:       [[VECTOR_EARLY_EXIT]]:
; COMMON-NEXT:    [[TMP11:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v16i1(<16 x i1> [[TMP7]], i1 false)
; COMMON-NEXT:    [[TMP12:%.*]] = add i64 [[INDEX]], [[TMP11]]
; COMMON-NEXT:    br label %[[EXIT:.*]]
; COMMON:       [[SCALAR_PH]]:
; COMMON-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 96, %[[MIDDLE_BLOCK]] ], [ 0, %[[SPEC_LOAD_CHECK]] ]
; COMMON-NEXT:    br label %[[LOOP_HEADER:.*]]
; COMMON:       [[LOOP_HEADER]]:
; COMMON-NEXT:    [[IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP_LATCH:.*]] ]
; COMMON-NEXT:    [[GEP_P1:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[IV]]
; COMMON-NEXT:    [[LD1:%.*]] = load i8, ptr [[GEP_P1]], align 1
; COMMON-NEXT:    [[GEP_P2:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[IV]]
; COMMON-NEXT:    [[LD2:%.*]] = load i8, ptr [[GEP_P2]], align 1
; COMMON-NEXT:    [[CMP:%.*]] = icmp eq i8 [[LD1]], [[LD2]]
; COMMON-NEXT:    br i1 [[CMP]], label %[[LOOP_LATCH]], label %[[EXIT]]
; COMMON:       [[LOOP_LATCH]]:
; COMMON-NEXT:    [[IV_NEXT]] = add i64 [[IV]], 1
; COMMON-NEXT:    [[EXITCOND:%.*]] = icmp ne i64 [[IV_NEXT]], 100
; COMMON-NEXT:    br i1 [[EXITCOND]], label %[[LOOP_HEADER]], label %[[EXIT]], !llvm.loop [[LOOP3:![0-9]+]]
; COMMON:       [[EXIT]]:
; COMMON-NEXT:    [[IV_LCSSA:%.*]] = phi i64 [ [[IV]], %[[LOOP_LATCH]] ], [ [[IV]], %[[LOOP_HEADER]] ], [ [[TMP12]], %[[VECTOR_EARLY_EXIT]] ]
; COMMON-NEXT:    ret i64 [[IV_LCSSA]]
;
entry:
  br label %loop.header

loop.header:
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop.latch ]
  %gep.p1 = getelementptr inbounds i8, ptr %p1, i64 %iv
  %ld1 = load i8, ptr %gep.p1, align 1
  %gep.p2 = getelementptr inbounds i8, ptr %p2, i64 %iv
  %ld2 = load i8, ptr %gep.p2, align 1
  %cmp = icmp eq i8 %ld1, %ld2
  br i1 %cmp, label %loop.latch, label %exit

loop.latch:
  %iv.next = add i64 %iv, 1
  %exitcond = icmp ne i64 %iv.next, 100
  br i1 %exitcond, label %loop.header, label %exit

exit:
  ret i64 %iv
}

define i64 @early_exit_mixed_width_no_dereferencable(ptr %A, ptr %B) {
; COMMON-LABEL: define i64 @early_exit_mixed_width_no_dereferencable(
; COMMON-SAME: ptr [[A:%.*]], ptr [[B:%.*]]) {
; COMMON-NEXT:  [[ENTRY:.*:]]
; COMMON-NEXT:    br label %[[SPEC_LOAD_CHECK:.*]]
; COMMON:       [[SPEC_LOAD_CHECK]]:
; COMMON-NEXT:    [[TMP0:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[A]], i64 4)
; COMMON-NEXT:    [[TMP1:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[B]], i64 16)
; COMMON-NEXT:    [[TMP2:%.*]] = and i1 [[TMP0]], [[TMP1]]
; COMMON-NEXT:    [[TMP14:%.*]] = xor i1 [[TMP2]], true
; COMMON-NEXT:    br i1 [[TMP14]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; COMMON:       [[VECTOR_PH]]:
; COMMON-NEXT:    br label %[[VECTOR_BODY:.*]]
; COMMON:       [[VECTOR_BODY]]:
; COMMON-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY_INTERIM:.*]] ]
; COMMON-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[A]], i64 [[INDEX]]
; COMMON-NEXT:    [[TMP4:%.*]] = call <4 x i8> @llvm.speculative.load.v4i8.p0(ptr [[TMP3]])
; COMMON-NEXT:    [[TMP5:%.*]] = getelementptr inbounds i32, ptr [[B]], i64 [[INDEX]]
; COMMON-NEXT:    [[TMP6:%.*]] = call <4 x i32> @llvm.speculative.load.v4i32.p0(ptr [[TMP5]])
; COMMON-NEXT:    [[TMP7:%.*]] = trunc <4 x i32> [[TMP6]] to <4 x i8>
; COMMON-NEXT:    [[TMP8:%.*]] = icmp ne <4 x i8> [[TMP4]], [[TMP7]]
; COMMON-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
; COMMON-NEXT:    [[TMP9:%.*]] = freeze <4 x i1> [[TMP8]]
; COMMON-NEXT:    [[TMP10:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP9]])
; COMMON-NEXT:    [[TMP11:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1024
; COMMON-NEXT:    br i1 [[TMP10]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[VECTOR_BODY_INTERIM]]
; COMMON:       [[VECTOR_BODY_INTERIM]]:
; COMMON-NEXT:    br i1 [[TMP11]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; COMMON:       [[MIDDLE_BLOCK]]:
; COMMON-NEXT:    br label %[[EXIT:.*]]
; COMMON:       [[VECTOR_EARLY_EXIT]]:
; COMMON-NEXT:    [[TMP12:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP8]], i1 false)
; COMMON-NEXT:    [[TMP13:%.*]] = add i64 [[INDEX]], [[TMP12]]
; COMMON-NEXT:    br label %[[EXIT]]
; COMMON:       [[SCALAR_PH]]:
; COMMON-NEXT:    br label %[[LOOP_HEADER:.*]]
; COMMON:       [[LOOP_HEADER]]:
; COMMON-NEXT:    [[IV:%.*]] = phi i64 [ 0, %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP_LATCH:.*]] ]
; COMMON-NEXT:    [[GEP_A:%.*]] = getelementptr inbounds i8, ptr [[A]], i64 [[IV]]
; COMMON-NEXT:    [[LD1:%.*]] = load i8, ptr [[GEP_A]], align 1
; COMMON-NEXT:    [[GEP_B:%.*]] = getelementptr inbounds i32, ptr [[B]], i64 [[IV]]
; COMMON-NEXT:    [[LD2:%.*]] = load i32, ptr [[GEP_B]], align 4
; COMMON-NEXT:    [[LD2_TRUNC:%.*]] = trunc i32 [[LD2]] to i8
; COMMON-NEXT:    [[CMP:%.*]] = icmp eq i8 [[LD1]], [[LD2_TRUNC]]
; COMMON-NEXT:    br i1 [[CMP]], label %[[LOOP_LATCH]], label %[[EXIT]]
; COMMON:       [[LOOP_LATCH]]:
; COMMON-NEXT:    [[IV_NEXT]] = add i64 [[IV]], 1
; COMMON-NEXT:    [[EC:%.*]] = icmp ne i64 [[IV_NEXT]], 1024
; COMMON-NEXT:    br i1 [[EC]], label %[[LOOP_HEADER]], label %[[EXIT]], !llvm.loop [[LOOP5:![0-9]+]]
; COMMON:       [[EXIT]]:
; COMMON-NEXT:    [[IV_LCSSA:%.*]] = phi i64 [ [[IV]], %[[LOOP_LATCH]] ], [ [[IV]], %[[LOOP_HEADER]] ], [ 1023, %[[MIDDLE_BLOCK]] ], [ [[TMP13]], %[[VECTOR_EARLY_EXIT]] ]
; COMMON-NEXT:    ret i64 [[IV_LCSSA]]
;
entry:
  br label %loop.header

loop.header:
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop.latch ]
  %gep.A = getelementptr inbounds i8, ptr %A, i64 %iv
  %ld1 = load i8, ptr %gep.A, align 1
  %gep.B = getelementptr inbounds i32, ptr %B, i64 %iv
  %ld2 = load i32, ptr %gep.B, align 4
  %ld2.trunc = trunc i32 %ld2 to i8
  %cmp = icmp eq i8 %ld1, %ld2.trunc
  br i1 %cmp, label %loop.latch, label %exit

loop.latch:
  %iv.next = add i64 %iv, 1
  %ec = icmp ne i64 %iv.next, 1024
  br i1 %ec, label %loop.header, label %exit

exit:
  ret i64 %iv
}

; Test early exit vectorization with SVE and speculative loads.
define i64 @early_exit_with_spec_load_sve(ptr %p1, ptr %p2) #0 {
; DEFAULT-LABEL: define i64 @early_exit_with_spec_load_sve(
; DEFAULT-SAME: ptr [[P1:%.*]], ptr [[P2:%.*]]) #[[ATTR0:[0-9]+]] {
; DEFAULT-NEXT:  [[ENTRY:.*:]]
; DEFAULT-NEXT:    br label %[[SPEC_LOAD_CHECK:.*]]
; DEFAULT:       [[SPEC_LOAD_CHECK]]:
; DEFAULT-NEXT:    [[TMP0:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[P1]], i64 16)
; DEFAULT-NEXT:    [[TMP1:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[P2]], i64 16)
; DEFAULT-NEXT:    [[TMP2:%.*]] = and i1 [[TMP0]], [[TMP1]]
; DEFAULT-NEXT:    [[TMP13:%.*]] = xor i1 [[TMP2]], true
; DEFAULT-NEXT:    br i1 [[TMP13]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; DEFAULT:       [[VECTOR_PH]]:
; DEFAULT-NEXT:    br label %[[VECTOR_BODY:.*]]
; DEFAULT:       [[VECTOR_BODY]]:
; DEFAULT-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY_INTERIM:.*]] ]
; DEFAULT-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[INDEX]]
; DEFAULT-NEXT:    [[TMP4:%.*]] = call <16 x i8> @llvm.speculative.load.v16i8.p0(ptr [[TMP3]])
; DEFAULT-NEXT:    [[TMP5:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[INDEX]]
; DEFAULT-NEXT:    [[TMP6:%.*]] = call <16 x i8> @llvm.speculative.load.v16i8.p0(ptr [[TMP5]])
; DEFAULT-NEXT:    [[TMP7:%.*]] = icmp ne <16 x i8> [[TMP4]], [[TMP6]]
; DEFAULT-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
; DEFAULT-NEXT:    [[TMP8:%.*]] = freeze <16 x i1> [[TMP7]]
; DEFAULT-NEXT:    [[TMP9:%.*]] = call i1 @llvm.vector.reduce.or.v16i1(<16 x i1> [[TMP8]])
; DEFAULT-NEXT:    [[TMP10:%.*]] = icmp eq i64 [[INDEX_NEXT]], 96
; DEFAULT-NEXT:    br i1 [[TMP9]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[VECTOR_BODY_INTERIM]]
; DEFAULT:       [[VECTOR_BODY_INTERIM]]:
; DEFAULT-NEXT:    br i1 [[TMP10]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP6:![0-9]+]]
; DEFAULT:       [[MIDDLE_BLOCK]]:
; DEFAULT-NEXT:    br label %[[SCALAR_PH]]
; DEFAULT:       [[VECTOR_EARLY_EXIT]]:
; DEFAULT-NEXT:    [[TMP11:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v16i1(<16 x i1> [[TMP7]], i1 false)
; DEFAULT-NEXT:    [[TMP12:%.*]] = add i64 [[INDEX]], [[TMP11]]
; DEFAULT-NEXT:    br label %[[EXIT:.*]]
; DEFAULT:       [[SCALAR_PH]]:
; DEFAULT-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 96, %[[MIDDLE_BLOCK]] ], [ 0, %[[SPEC_LOAD_CHECK]] ]
; DEFAULT-NEXT:    br label %[[LOOP_HEADER:.*]]
; DEFAULT:       [[LOOP_HEADER]]:
; DEFAULT-NEXT:    [[IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP_LATCH:.*]] ]
; DEFAULT-NEXT:    [[GEP_P1:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[IV]]
; DEFAULT-NEXT:    [[LD1:%.*]] = load i8, ptr [[GEP_P1]], align 1
; DEFAULT-NEXT:    [[GEP_P2:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[IV]]
; DEFAULT-NEXT:    [[LD2:%.*]] = load i8, ptr [[GEP_P2]], align 1
; DEFAULT-NEXT:    [[CMP:%.*]] = icmp eq i8 [[LD1]], [[LD2]]
; DEFAULT-NEXT:    br i1 [[CMP]], label %[[LOOP_LATCH]], label %[[EXIT]]
; DEFAULT:       [[LOOP_LATCH]]:
; DEFAULT-NEXT:    [[IV_NEXT]] = add i64 [[IV]], 1
; DEFAULT-NEXT:    [[EXITCOND:%.*]] = icmp ne i64 [[IV_NEXT]], 100
; DEFAULT-NEXT:    br i1 [[EXITCOND]], label %[[LOOP_HEADER]], label %[[EXIT]], !llvm.loop [[LOOP7:![0-9]+]]
; DEFAULT:       [[EXIT]]:
; DEFAULT-NEXT:    [[IV_LCSSA:%.*]] = phi i64 [ [[IV]], %[[LOOP_LATCH]] ], [ [[IV]], %[[LOOP_HEADER]] ], [ [[TMP12]], %[[VECTOR_EARLY_EXIT]] ]
; DEFAULT-NEXT:    ret i64 [[IV_LCSSA]]
;
; MAX-BW-LABEL: define i64 @early_exit_with_spec_load_sve(
; MAX-BW-SAME: ptr [[P1:%.*]], ptr [[P2:%.*]]) #[[ATTR0:[0-9]+]] {
; MAX-BW-NEXT:  [[ENTRY:.*:]]
; MAX-BW-NEXT:    br label %[[SPEC_LOAD_CHECK:.*]]
; MAX-BW:       [[SPEC_LOAD_CHECK]]:
; MAX-BW-NEXT:    [[TMP0:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[P1]], i64 16)
; MAX-BW-NEXT:    [[TMP1:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[P2]], i64 16)
; MAX-BW-NEXT:    [[TMP2:%.*]] = and i1 [[TMP0]], [[TMP1]]
; MAX-BW-NEXT:    [[TMP13:%.*]] = xor i1 [[TMP2]], true
; MAX-BW-NEXT:    br i1 [[TMP13]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; MAX-BW:       [[VECTOR_PH]]:
; MAX-BW-NEXT:    br label %[[VECTOR_BODY:.*]]
; MAX-BW:       [[VECTOR_BODY]]:
; MAX-BW-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY_INTERIM:.*]] ]
; MAX-BW-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[INDEX]]
; MAX-BW-NEXT:    [[TMP4:%.*]] = call <16 x i8> @llvm.speculative.load.v16i8.p0(ptr [[TMP3]])
; MAX-BW-NEXT:    [[TMP5:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[INDEX]]
; MAX-BW-NEXT:    [[TMP6:%.*]] = call <16 x i8> @llvm.speculative.load.v16i8.p0(ptr [[TMP5]])
; MAX-BW-NEXT:    [[TMP7:%.*]] = icmp ne <16 x i8> [[TMP4]], [[TMP6]]
; MAX-BW-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
; MAX-BW-NEXT:    [[TMP8:%.*]] = freeze <16 x i1> [[TMP7]]
; MAX-BW-NEXT:    [[TMP9:%.*]] = call i1 @llvm.vector.reduce.or.v16i1(<16 x i1> [[TMP8]])
; MAX-BW-NEXT:    [[TMP10:%.*]] = icmp eq i64 [[INDEX_NEXT]], 96
; MAX-BW-NEXT:    br i1 [[TMP9]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[VECTOR_BODY_INTERIM]]
; MAX-BW:       [[VECTOR_BODY_INTERIM]]:
; MAX-BW-NEXT:    br i1 [[TMP10]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP6:![0-9]+]]
; MAX-BW:       [[MIDDLE_BLOCK]]:
; MAX-BW-NEXT:    br label %[[SCALAR_PH]]
; MAX-BW:       [[VECTOR_EARLY_EXIT]]:
; MAX-BW-NEXT:    [[TMP11:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v16i1(<16 x i1> [[TMP7]], i1 false)
; MAX-BW-NEXT:    [[TMP12:%.*]] = add i64 [[INDEX]], [[TMP11]]
; MAX-BW-NEXT:    br label %[[EXIT:.*]]
; MAX-BW:       [[SCALAR_PH]]:
; MAX-BW-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 96, %[[MIDDLE_BLOCK]] ], [ 0, %[[SPEC_LOAD_CHECK]] ]
; MAX-BW-NEXT:    br label %[[LOOP_HEADER:.*]]
; MAX-BW:       [[LOOP_HEADER]]:
; MAX-BW-NEXT:    [[IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP_LATCH:.*]] ]
; MAX-BW-NEXT:    [[GEP_P1:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[IV]]
; MAX-BW-NEXT:    [[LD1:%.*]] = load i8, ptr [[GEP_P1]], align 1
; MAX-BW-NEXT:    [[GEP_P2:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[IV]]
; MAX-BW-NEXT:    [[LD2:%.*]] = load i8, ptr [[GEP_P2]], align 1
; MAX-BW-NEXT:    [[CMP:%.*]] = icmp eq i8 [[LD1]], [[LD2]]
; MAX-BW-NEXT:    br i1 [[CMP]], label %[[LOOP_LATCH]], label %[[EXIT]]
; MAX-BW:       [[LOOP_LATCH]]:
; MAX-BW-NEXT:    [[IV_NEXT]] = add i64 [[IV]], 1
; MAX-BW-NEXT:    [[EXITCOND:%.*]] = icmp ne i64 [[IV_NEXT]], 100
; MAX-BW-NEXT:    br i1 [[EXITCOND]], label %[[LOOP_HEADER]], label %[[EXIT]], !llvm.loop [[LOOP7:![0-9]+]]
; MAX-BW:       [[EXIT]]:
; MAX-BW-NEXT:    [[IV_LCSSA:%.*]] = phi i64 [ [[IV]], %[[LOOP_LATCH]] ], [ [[IV]], %[[LOOP_HEADER]] ], [ [[TMP12]], %[[VECTOR_EARLY_EXIT]] ]
; MAX-BW-NEXT:    ret i64 [[IV_LCSSA]]
;
; PREFER-SVE-LABEL: define i64 @early_exit_with_spec_load_sve(
; PREFER-SVE-SAME: ptr [[P1:%.*]], ptr [[P2:%.*]]) #[[ATTR0:[0-9]+]] {
; PREFER-SVE-NEXT:  [[ENTRY:.*]]:
; PREFER-SVE-NEXT:    [[TMP0:%.*]] = call i64 @llvm.vscale.i64()
; PREFER-SVE-NEXT:    [[TMP1:%.*]] = shl nuw nsw i64 [[TMP0]], 4
; PREFER-SVE-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 100, [[TMP1]]
; PREFER-SVE-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[SPEC_LOAD_CHECK:.*]]
; PREFER-SVE:       [[SPEC_LOAD_CHECK]]:
; PREFER-SVE-NEXT:    [[TMP2:%.*]] = call i64 @llvm.vscale.i64()
; PREFER-SVE-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <vscale x 16 x i64> poison, i64 [[TMP2]], i64 0
; PREFER-SVE-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <vscale x 16 x i64> [[BROADCAST_SPLATINSERT]], <vscale x 16 x i64> poison, <vscale x 16 x i32> zeroinitializer
; PREFER-SVE-NEXT:    [[TMP3:%.*]] = shl nuw <vscale x 16 x i64> [[BROADCAST_SPLAT]], splat (i64 4)
; PREFER-SVE-NEXT:    [[TMP4:%.*]] = extractelement <vscale x 16 x i64> [[TMP3]], i32 0
; PREFER-SVE-NEXT:    [[TMP5:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[P1]], i64 [[TMP4]])
; PREFER-SVE-NEXT:    [[TMP6:%.*]] = extractelement <vscale x 16 x i64> [[TMP3]], i32 0
; PREFER-SVE-NEXT:    [[TMP7:%.*]] = call i1 @llvm.can.load.speculatively.p0(ptr [[P2]], i64 [[TMP6]])
; PREFER-SVE-NEXT:    [[TMP8:%.*]] = and i1 [[TMP5]], [[TMP7]]
; PREFER-SVE-NEXT:    [[TMP20:%.*]] = xor i1 [[TMP8]], true
; PREFER-SVE-NEXT:    br i1 [[TMP20]], label %[[SCALAR_PH]], label %[[VECTOR_PH:.*]]
; PREFER-SVE:       [[VECTOR_PH]]:
; PREFER-SVE-NEXT:    [[TMP9:%.*]] = shl nuw i64 [[TMP2]], 4
; PREFER-SVE-NEXT:    [[N_MOD_VF:%.*]] = urem i64 100, [[TMP9]]
; PREFER-SVE-NEXT:    [[N_VEC:%.*]] = sub i64 100, [[N_MOD_VF]]
; PREFER-SVE-NEXT:    br label %[[VECTOR_BODY:.*]]
; PREFER-SVE:       [[VECTOR_BODY]]:
; PREFER-SVE-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY_INTERIM:.*]] ]
; PREFER-SVE-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[INDEX]]
; PREFER-SVE-NEXT:    [[TMP11:%.*]] = call <vscale x 16 x i8> @llvm.speculative.load.nxv16i8.p0(ptr [[TMP10]])
; PREFER-SVE-NEXT:    [[TMP12:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[INDEX]]
; PREFER-SVE-NEXT:    [[TMP13:%.*]] = call <vscale x 16 x i8> @llvm.speculative.load.nxv16i8.p0(ptr [[TMP12]])
; PREFER-SVE-NEXT:    [[TMP14:%.*]] = icmp ne <vscale x 16 x i8> [[TMP11]], [[TMP13]]
; PREFER-SVE-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], [[TMP9]]
; PREFER-SVE-NEXT:    [[TMP15:%.*]] = freeze <vscale x 16 x i1> [[TMP14]]
; PREFER-SVE-NEXT:    [[TMP16:%.*]] = call i1 @llvm.vector.reduce.or.nxv16i1(<vscale x 16 x i1> [[TMP15]])
; PREFER-SVE-NEXT:    [[TMP17:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; PREFER-SVE-NEXT:    br i1 [[TMP16]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[VECTOR_BODY_INTERIM]]
; PREFER-SVE:       [[VECTOR_BODY_INTERIM]]:
; PREFER-SVE-NEXT:    br i1 [[TMP17]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP6:![0-9]+]]
; PREFER-SVE:       [[MIDDLE_BLOCK]]:
; PREFER-SVE-NEXT:    [[CMP_N:%.*]] = icmp eq i64 100, [[N_VEC]]
; PREFER-SVE-NEXT:    [[IND_ESCAPE:%.*]] = sub i64 [[N_VEC]], 1
; PREFER-SVE-NEXT:    br i1 [[CMP_N]], label %[[EXIT:.*]], label %[[SCALAR_PH]]
; PREFER-SVE:       [[VECTOR_EARLY_EXIT]]:
; PREFER-SVE-NEXT:    [[TMP18:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.nxv16i1(<vscale x 16 x i1> [[TMP14]], i1 false)
; PREFER-SVE-NEXT:    [[TMP19:%.*]] = add i64 [[INDEX]], [[TMP18]]
; PREFER-SVE-NEXT:    br label %[[EXIT]]
; PREFER-SVE:       [[SCALAR_PH]]:
; PREFER-SVE-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N_VEC]], %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ], [ 0, %[[SPEC_LOAD_CHECK]] ]
; PREFER-SVE-NEXT:    br label %[[LOOP_HEADER:.*]]
; PREFER-SVE:       [[LOOP_HEADER]]:
; PREFER-SVE-NEXT:    [[IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], %[[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], %[[LOOP_LATCH:.*]] ]
; PREFER-SVE-NEXT:    [[GEP_P1:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[IV]]
; PREFER-SVE-NEXT:    [[LD1:%.*]] = load i8, ptr [[GEP_P1]], align 1
; PREFER-SVE-NEXT:    [[GEP_P2:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[IV]]
; PREFER-SVE-NEXT:    [[LD2:%.*]] = load i8, ptr [[GEP_P2]], align 1
; PREFER-SVE-NEXT:    [[CMP:%.*]] = icmp eq i8 [[LD1]], [[LD2]]
; PREFER-SVE-NEXT:    br i1 [[CMP]], label %[[LOOP_LATCH]], label %[[EXIT]]
; PREFER-SVE:       [[LOOP_LATCH]]:
; PREFER-SVE-NEXT:    [[IV_NEXT]] = add i64 [[IV]], 1
; PREFER-SVE-NEXT:    [[EXITCOND:%.*]] = icmp ne i64 [[IV_NEXT]], 100
; PREFER-SVE-NEXT:    br i1 [[EXITCOND]], label %[[LOOP_HEADER]], label %[[EXIT]], !llvm.loop [[LOOP7:![0-9]+]]
; PREFER-SVE:       [[EXIT]]:
; PREFER-SVE-NEXT:    [[IV_LCSSA:%.*]] = phi i64 [ [[IV]], %[[LOOP_LATCH]] ], [ [[IV]], %[[LOOP_HEADER]] ], [ [[IND_ESCAPE]], %[[MIDDLE_BLOCK]] ], [ [[TMP19]], %[[VECTOR_EARLY_EXIT]] ]
; PREFER-SVE-NEXT:    ret i64 [[IV_LCSSA]]
;
entry:
  br label %loop.header

loop.header:
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop.latch ]
  %gep.p1 = getelementptr inbounds i8, ptr %p1, i64 %iv
  %ld1 = load i8, ptr %gep.p1, align 1
  %gep.p2 = getelementptr inbounds i8, ptr %p2, i64 %iv
  %ld2 = load i8, ptr %gep.p2, align 1
  %cmp = icmp eq i8 %ld1, %ld2
  br i1 %cmp, label %loop.latch, label %exit

loop.latch:
  %iv.next = add i64 %iv, 1
  %exitcond = icmp ne i64 %iv.next, 100
  br i1 %exitcond, label %loop.header, label %exit

exit:
  ret i64 %iv
}

attributes #0 = { "target-features"="+sve" "target-cpu"="neoverse-v2" vscale_range(1,16) }
