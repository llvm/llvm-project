; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-globals none --version 6
; RUN: opt -p loop-vectorize -S %s | FileCheck %s

; In this test, the hot loop is mostly vectorizable, but with one gather
; operation that is not. In this case it is still desirable to vectorize.

target triple = "arm64-apple-macosx15.0.0"

define void @decompress_offsets(i64 noundef %0, ptr noalias noundef nonnull readonly align 1 captures(none) %1, i64 noundef %2, ptr noalias noundef readonly align 4 captures(none) dereferenceable(1024) %3, ptr noalias noundef readonly align 4 captures(none) dereferenceable(1024) %4, ptr noalias noundef align 8 captures(none) dereferenceable(2048) %5) {
; CHECK-LABEL: define void @decompress_offsets(
; CHECK-SAME: i64 noundef [[TMP0:%.*]], ptr noalias noundef nonnull readonly align 1 captures(none) [[TMP1:%.*]], i64 noundef [[TMP2:%.*]], ptr noalias noundef readonly align 4 captures(none) dereferenceable(1024) [[TMP3:%.*]], ptr noalias noundef readonly align 4 captures(none) dereferenceable(1024) [[TMP4:%.*]], ptr noalias noundef align 8 captures(none) dereferenceable(2048) [[TMP5:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP6:%.*]] = trunc i64 [[TMP0]] to i32
; CHECK-NEXT:    br label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP7:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP8:%.*]] = add i64 [[INDEX]], 1
; CHECK-NEXT:    [[TMP9:%.*]] = add i64 [[INDEX]], 2
; CHECK-NEXT:    [[TMP10:%.*]] = add i64 [[INDEX]], 3
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw i32, ptr [[TMP4]], i64 [[TMP7]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i32>, ptr [[TMP11]], align 4
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds nuw i32, ptr [[TMP3]], i64 [[TMP7]]
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds nuw i32, ptr [[TMP3]], i64 [[TMP8]]
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr inbounds nuw i32, ptr [[TMP3]], i64 [[TMP9]]
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr inbounds nuw i32, ptr [[TMP3]], i64 [[TMP10]]
; CHECK-NEXT:    [[TMP19:%.*]] = load i32, ptr [[TMP15]], align 4
; CHECK-NEXT:    [[TMP17:%.*]] = load i32, ptr [[TMP13]], align 4
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[TMP14]], align 4
; CHECK-NEXT:    [[TMP28:%.*]] = load i32, ptr [[TMP20]], align 4
; CHECK-NEXT:    [[TMP23:%.*]] = add i32 [[TMP19]], [[TMP6]]
; CHECK-NEXT:    [[TMP29:%.*]] = add i32 [[TMP17]], [[TMP6]]
; CHECK-NEXT:    [[TMP30:%.*]] = add i32 [[TMP18]], [[TMP6]]
; CHECK-NEXT:    [[TMP33:%.*]] = add i32 [[TMP28]], [[TMP6]]
; CHECK-NEXT:    [[TMP24:%.*]] = insertelement <4 x i32> poison, i32 [[TMP23]], i32 0
; CHECK-NEXT:    [[TMP25:%.*]] = insertelement <4 x i32> [[TMP24]], i32 [[TMP29]], i32 1
; CHECK-NEXT:    [[TMP34:%.*]] = insertelement <4 x i32> [[TMP25]], i32 [[TMP30]], i32 2
; CHECK-NEXT:    [[TMP27:%.*]] = insertelement <4 x i32> [[TMP34]], i32 [[TMP33]], i32 3
; CHECK-NEXT:    [[TMP31:%.*]] = lshr i32 [[TMP23]], 3
; CHECK-NEXT:    [[TMP16:%.*]] = lshr i32 [[TMP29]], 3
; CHECK-NEXT:    [[TMP21:%.*]] = lshr i32 [[TMP30]], 3
; CHECK-NEXT:    [[TMP35:%.*]] = lshr i32 [[TMP33]], 3
; CHECK-NEXT:    [[TMP32:%.*]] = and <4 x i32> [[TMP27]], splat (i32 7)
; CHECK-NEXT:    [[TMP36:%.*]] = zext nneg i32 [[TMP31]] to i64
; CHECK-NEXT:    [[TMP26:%.*]] = zext nneg i32 [[TMP16]] to i64
; CHECK-NEXT:    [[TMP22:%.*]] = zext nneg i32 [[TMP21]] to i64
; CHECK-NEXT:    [[TMP60:%.*]] = zext nneg i32 [[TMP35]] to i64
; CHECK-NEXT:    [[TMP37:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP1]], i64 [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP1]], i64 [[TMP26]]
; CHECK-NEXT:    [[TMP39:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP1]], i64 [[TMP22]]
; CHECK-NEXT:    [[TMP40:%.*]] = getelementptr inbounds nuw i8, ptr [[TMP1]], i64 [[TMP60]]
; CHECK-NEXT:    [[TMP41:%.*]] = load i64, ptr [[TMP37]], align 1
; CHECK-NEXT:    [[TMP42:%.*]] = load i64, ptr [[TMP38]], align 1
; CHECK-NEXT:    [[TMP43:%.*]] = load i64, ptr [[TMP39]], align 1
; CHECK-NEXT:    [[TMP44:%.*]] = load i64, ptr [[TMP40]], align 1
; CHECK-NEXT:    [[TMP45:%.*]] = insertelement <4 x i64> poison, i64 [[TMP41]], i32 0
; CHECK-NEXT:    [[TMP46:%.*]] = insertelement <4 x i64> [[TMP45]], i64 [[TMP42]], i32 1
; CHECK-NEXT:    [[TMP47:%.*]] = insertelement <4 x i64> [[TMP46]], i64 [[TMP43]], i32 2
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <4 x i64> [[TMP47]], i64 [[TMP44]], i32 3
; CHECK-NEXT:    [[TMP49:%.*]] = zext nneg <4 x i32> [[TMP32]] to <4 x i64>
; CHECK-NEXT:    [[TMP50:%.*]] = lshr <4 x i64> [[TMP48]], [[TMP49]]
; CHECK-NEXT:    [[TMP51:%.*]] = and <4 x i32> [[WIDE_LOAD]], splat (i32 63)
; CHECK-NEXT:    [[TMP52:%.*]] = zext nneg <4 x i32> [[TMP51]] to <4 x i64>
; CHECK-NEXT:    [[TMP53:%.*]] = shl nsw <4 x i64> splat (i64 -1), [[TMP52]]
; CHECK-NEXT:    [[TMP54:%.*]] = xor <4 x i64> [[TMP53]], splat (i64 -1)
; CHECK-NEXT:    [[TMP55:%.*]] = and <4 x i64> [[TMP50]], [[TMP54]]
; CHECK-NEXT:    [[TMP56:%.*]] = getelementptr inbounds nuw i64, ptr [[TMP5]], i64 [[TMP7]]
; CHECK-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i64>, ptr [[TMP56]], align 8
; CHECK-NEXT:    [[TMP57:%.*]] = add <4 x i64> [[WIDE_LOAD1]], splat (i64 2147483648)
; CHECK-NEXT:    [[TMP58:%.*]] = add <4 x i64> [[TMP57]], [[TMP55]]
; CHECK-NEXT:    store <4 x i64> [[TMP58]], ptr [[TMP56]], align 8
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
; CHECK-NEXT:    [[TMP59:%.*]] = icmp eq i64 [[INDEX_NEXT]], 256
; CHECK-NEXT:    br i1 [[TMP59]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    br label %[[EXIT:.*]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;

entry:
  %7 = trunc i64 %0 to i32
  br label %loop

loop:
  %10 = phi i64 [ 0, %entry ], [ %11, %loop ]
  %11 = add nuw nsw i64 %10, 1
  %12 = getelementptr inbounds nuw i32, ptr %4, i64 %10
  %13 = load i32, ptr %12, align 4
  %14 = getelementptr inbounds nuw i32, ptr %3, i64 %10
  %15 = load i32, ptr %14, align 4
  %16 = add i32 %15, %7
  %17 = lshr i32 %16, 3
  %18 = and i32 %16, 7
  %19 = zext nneg i32 %17 to i64
  %20 = getelementptr inbounds nuw i8, ptr %1, i64 %19
  %21 = load i64, ptr %20, align 1
  %22 = zext nneg i32 %18 to i64
  %23 = lshr i64 %21, %22
  %24 = and i32 %13, 63
  %25 = zext nneg i32 %24 to i64
  %26 = shl nsw i64 -1, %25
  %27 = xor i64 %26, -1
  %28 = and i64 %23, %27
  %29 = getelementptr inbounds nuw i64, ptr %5, i64 %10
  %30 = load i64, ptr %29, align 8
  %31 = add i64 %30, 2147483648
  %32 = add i64 %31, %28
  store i64 %32, ptr %29, align 8
  %33 = icmp eq i64 %11, 256
  br i1 %33, label %exit, label %loop

exit:
  ret void
}
