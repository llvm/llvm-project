; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-globals none --filter-out-after "^scalar.ph:" --version 5
; RUN: opt -passes=loop-vectorize -force-vector-interleave=1 -force-vector-width=4 -enable-epilogue-vectorization=false -S < %s | FileCheck %s

define i32 @common_sext(ptr %a, ptr %b, ptr %c, i32 %N) {
; CHECK-LABEL: define i32 @common_sext(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]], ptr [[C:%.*]], i32 [[N:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[CMP28_NOT:%.*]] = icmp ult i32 [[N]], 2
; CHECK-NEXT:    [[DIV27:%.*]] = lshr i32 [[N]], 1
; CHECK-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext nneg i32 [[DIV27]] to i64
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[WIDE_TRIP_COUNT]], 4
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[WIDE_TRIP_COUNT]], 4
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[WIDE_TRIP_COUNT]], [[N_MOD_VF]]
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw i8, ptr [[A]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds nuw i8, ptr [[C]], i64 [[INDEX]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP0]], align 1
; CHECK-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
; CHECK-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP2]], align 1
; CHECK-NEXT:    [[TMP6:%.*]] = sext <4 x i8> [[WIDE_LOAD]] to <4 x i32>
; CHECK-NEXT:    [[TMP7:%.*]] = sext <4 x i8> [[WIDE_LOAD1]] to <4 x i32>
; CHECK-NEXT:    [[TMP8:%.*]] = sext <4 x i8> [[WIDE_LOAD2]] to <4 x i32>
; CHECK-NEXT:    [[TMP9:%.*]] = add nsw <4 x i32> [[TMP6]], [[TMP7]]
; CHECK-NEXT:    [[TMP10:%.*]] = add nsw <4 x i32> [[TMP8]], [[TMP7]]
; CHECK-NEXT:    [[TMP11:%.*]] = add <4 x i32> [[TMP9]], [[TMP10]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
; CHECK-NEXT:    [[TMP12:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP12]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x i32> [[TMP11]], i32 3
; CHECK-NEXT:    [[VECTOR_RECUR_EXTRACT:%.*]] = extractelement <4 x i32> [[TMP11]], i32 3
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[WIDE_TRIP_COUNT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], [[EXIT:label %.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
;
entry:
  %cmp28.not = icmp ult i32 %N, 2
  %div27 = lshr i32 %N, 1
  %wide.trip.count = zext nneg i32 %div27 to i64
  br label %for.body

for.body:                                         ; preds = %for.body.preheader, %for.body
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %for.body ]
  %res = phi i32 [ 0, %entry ], [ %add3, %for.body ]
  %a.ptr = getelementptr inbounds nuw i8, ptr %a, i64 %iv
  %b.ptr = getelementptr inbounds nuw i8, ptr %b, i64 %iv
  %c.ptr = getelementptr inbounds nuw i8, ptr %c, i64 %iv
  %a.val = load i8, ptr %a.ptr, align 1
  %b.val = load i8, ptr %b.ptr, align 1
  %c.val = load i8, ptr %c.ptr, align 1
  %a.ext = sext i8 %a.val to i32
  %b.ext = sext i8 %b.val to i32
  %b.ext2 = sext i8 %b.val to i32
  %c.ext = sext i8 %c.val to i32
  %add = add nsw i32 %a.ext, %b.ext
  %add2 = add nsw i32 %c.ext, %b.ext2
  %add3 = add i32 %add, %add2
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %wide.trip.count
  br i1 %exitcond, label %exit, label %for.body

exit:                                 ; preds = %exit.loopexit, %entry
  %res.0.lcssa = phi i32 [ %add3, %for.body ]
  ret i32 %res.0.lcssa
}

define i32 @common_zext(ptr %a, ptr %b, ptr %c, i32 %N) {
; CHECK-LABEL: define i32 @common_zext(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]], ptr [[C:%.*]], i32 [[N:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[CMP28_NOT:%.*]] = icmp ult i32 [[N]], 2
; CHECK-NEXT:    [[DIV27:%.*]] = lshr i32 [[N]], 1
; CHECK-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext nneg i32 [[DIV27]] to i64
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[WIDE_TRIP_COUNT]], 4
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[WIDE_TRIP_COUNT]], 4
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[WIDE_TRIP_COUNT]], [[N_MOD_VF]]
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds nuw i8, ptr [[A]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds nuw i8, ptr [[C]], i64 [[INDEX]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP0]], align 1
; CHECK-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
; CHECK-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP11]], align 1
; CHECK-NEXT:    [[TMP4:%.*]] = zext <4 x i8> [[WIDE_LOAD]] to <4 x i32>
; CHECK-NEXT:    [[TMP5:%.*]] = zext <4 x i8> [[WIDE_LOAD1]] to <4 x i32>
; CHECK-NEXT:    [[TMP13:%.*]] = zext <4 x i8> [[WIDE_LOAD2]] to <4 x i32>
; CHECK-NEXT:    [[TMP6:%.*]] = add nsw <4 x i32> [[TMP4]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = add nsw <4 x i32> [[TMP13]], [[TMP5]]
; CHECK-NEXT:    [[TMP8:%.*]] = add <4 x i32> [[TMP6]], [[TMP7]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
; CHECK-NEXT:    [[TMP9:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP9]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[TMP8]], i32 3
; CHECK-NEXT:    [[VECTOR_RECUR_EXTRACT:%.*]] = extractelement <4 x i32> [[TMP8]], i32 3
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[WIDE_TRIP_COUNT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], [[EXIT:label %.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
;
entry:
  %cmp28.not = icmp ult i32 %N, 2
  %div27 = lshr i32 %N, 1
  %wide.trip.count = zext nneg i32 %div27 to i64
  br label %for.body

for.body:                                         ; preds = %for.body.preheader, %for.body
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %for.body ]
  %res = phi i32 [ 0, %entry ], [ %add3, %for.body ]
  %a.ptr = getelementptr inbounds nuw i8, ptr %a, i64 %iv
  %b.ptr = getelementptr inbounds nuw i8, ptr %b, i64 %iv
  %c.ptr = getelementptr inbounds nuw i8, ptr %c, i64 %iv
  %a.val = load i8, ptr %a.ptr, align 1
  %b.val = load i8, ptr %b.ptr, align 1
  %c.val = load i8, ptr %c.ptr, align 1
  %a.ext = zext i8 %a.val to i32
  %b.ext = zext i8 %b.val to i32
  %b.ext2 = zext i8 %b.val to i32
  %c.ext = zext i8 %c.val to i32
  %add = add nsw i32 %a.ext, %b.ext
  %add2 = add nsw i32 %c.ext, %b.ext2
  %add3 = add i32 %add, %add2
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %wide.trip.count
  br i1 %exitcond, label %exit, label %for.body

exit:                                 ; preds = %exit.loopexit, %entry
  %res.0.lcssa = phi i32 [ %add3, %for.body ]
  ret i32 %res.0.lcssa
}

define i32 @common_sext_different_types(ptr %a, ptr %b, ptr %c, i32 %N) {
; CHECK-LABEL: define i32 @common_sext_different_types(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]], ptr [[C:%.*]], i32 [[N:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[CMP28_NOT:%.*]] = icmp ult i32 [[N]], 2
; CHECK-NEXT:    [[DIV27:%.*]] = lshr i32 [[N]], 1
; CHECK-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext nneg i32 [[DIV27]] to i64
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[WIDE_TRIP_COUNT]], 4
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[WIDE_TRIP_COUNT]], 4
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[WIDE_TRIP_COUNT]], [[N_MOD_VF]]
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP1:%.*]] = add i64 [[INDEX]], 1
; CHECK-NEXT:    [[TMP2:%.*]] = add i64 [[INDEX]], 2
; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[INDEX]], 3
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw i8, ptr [[A]], i64 [[TMP0]]
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[TMP0]]
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[TMP1]]
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[TMP2]]
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw i8, ptr [[C]], i64 [[TMP0]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP4]], align 1
; CHECK-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP5]], align 1
; CHECK-NEXT:    [[TMP12:%.*]] = load i16, ptr [[TMP5]], align 1
; CHECK-NEXT:    [[TMP13:%.*]] = load i16, ptr [[TMP6]], align 1
; CHECK-NEXT:    [[TMP14:%.*]] = load i16, ptr [[TMP7]], align 1
; CHECK-NEXT:    [[TMP15:%.*]] = load i16, ptr [[TMP8]], align 1
; CHECK-NEXT:    [[TMP16:%.*]] = insertelement <4 x i16> poison, i16 [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP17:%.*]] = insertelement <4 x i16> [[TMP16]], i16 [[TMP13]], i32 1
; CHECK-NEXT:    [[TMP18:%.*]] = insertelement <4 x i16> [[TMP17]], i16 [[TMP14]], i32 2
; CHECK-NEXT:    [[TMP19:%.*]] = insertelement <4 x i16> [[TMP18]], i16 [[TMP15]], i32 3
; CHECK-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP9]], align 1
; CHECK-NEXT:    [[TMP21:%.*]] = sext <4 x i8> [[WIDE_LOAD]] to <4 x i32>
; CHECK-NEXT:    [[TMP22:%.*]] = sext <4 x i8> [[WIDE_LOAD1]] to <4 x i32>
; CHECK-NEXT:    [[TMP23:%.*]] = sext <4 x i16> [[TMP19]] to <4 x i32>
; CHECK-NEXT:    [[TMP24:%.*]] = sext <4 x i8> [[WIDE_LOAD2]] to <4 x i32>
; CHECK-NEXT:    [[TMP25:%.*]] = add nsw <4 x i32> [[TMP21]], [[TMP22]]
; CHECK-NEXT:    [[TMP26:%.*]] = add nsw <4 x i32> [[TMP24]], [[TMP23]]
; CHECK-NEXT:    [[TMP27:%.*]] = add <4 x i32> [[TMP25]], [[TMP26]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
; CHECK-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP28]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP6:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[TMP29:%.*]] = extractelement <4 x i32> [[TMP27]], i32 3
; CHECK-NEXT:    [[VECTOR_RECUR_EXTRACT:%.*]] = extractelement <4 x i32> [[TMP27]], i32 3
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[WIDE_TRIP_COUNT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], [[EXIT:label %.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
;
entry:
  %cmp28.not = icmp ult i32 %N, 2
  %div27 = lshr i32 %N, 1
  %wide.trip.count = zext nneg i32 %div27 to i64
  br label %for.body

for.body:                                         ; preds = %for.body.preheader, %for.body
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %for.body ]
  %res = phi i32 [ 0, %entry ], [ %add3, %for.body ]
  %a.ptr = getelementptr inbounds nuw i8, ptr %a, i64 %iv
  %b.ptr = getelementptr inbounds nuw i8, ptr %b, i64 %iv
  %b.ptr2 = getelementptr inbounds nuw i16, ptr %b, i64 %iv
  %c.ptr = getelementptr inbounds nuw i8, ptr %c, i64 %iv
  %a.val = load i8, ptr %a.ptr, align 1
  %b.val = load i8, ptr %b.ptr, align 1
  %b.val2 = load i16, ptr %b.ptr, align 1
  %c.val = load i8, ptr %c.ptr, align 1
  %a.ext = sext i8 %a.val to i32
  %b.ext = sext i8 %b.val to i32
  %b.ext2 = sext i16 %b.val2 to i32
  %c.ext = sext i8 %c.val to i32
  %add = add nsw i32 %a.ext, %b.ext
  %add2 = add nsw i32 %c.ext, %b.ext2
  %add3 = add i32 %add, %add2
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %wide.trip.count
  br i1 %exitcond, label %exit, label %for.body

exit:                                 ; preds = %exit.loopexit, %entry
  %res.0.lcssa = phi i32 [ %add3, %for.body ]
  ret i32 %res.0.lcssa
}
define i32 @common_zext_different_types(ptr %a, ptr %b, ptr %c, i32 %N) {
; CHECK-LABEL: define i32 @common_zext_different_types(
; CHECK-SAME: ptr [[A:%.*]], ptr [[B:%.*]], ptr [[C:%.*]], i32 [[N:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[CMP28_NOT:%.*]] = icmp ult i32 [[N]], 2
; CHECK-NEXT:    [[DIV27:%.*]] = lshr i32 [[N]], 1
; CHECK-NEXT:    [[WIDE_TRIP_COUNT:%.*]] = zext nneg i32 [[DIV27]] to i64
; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[WIDE_TRIP_COUNT]], 4
; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label %[[SCALAR_PH:.*]], label %[[VECTOR_PH:.*]]
; CHECK:       [[VECTOR_PH]]:
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[WIDE_TRIP_COUNT]], 4
; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[WIDE_TRIP_COUNT]], [[N_MOD_VF]]
; CHECK-NEXT:    br label %[[VECTOR_BODY:.*]]
; CHECK:       [[VECTOR_BODY]]:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP1:%.*]] = add i64 [[INDEX]], 1
; CHECK-NEXT:    [[TMP2:%.*]] = add i64 [[INDEX]], 2
; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[INDEX]], 3
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds nuw i8, ptr [[A]], i64 [[TMP0]]
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[TMP0]]
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[TMP1]]
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[TMP2]]
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds nuw i8, ptr [[B]], i64 [[TMP3]]
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds nuw i8, ptr [[C]], i64 [[TMP0]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP4]], align 1
; CHECK-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP5]], align 1
; CHECK-NEXT:    [[TMP12:%.*]] = load i16, ptr [[TMP5]], align 1
; CHECK-NEXT:    [[TMP13:%.*]] = load i16, ptr [[TMP6]], align 1
; CHECK-NEXT:    [[TMP14:%.*]] = load i16, ptr [[TMP7]], align 1
; CHECK-NEXT:    [[TMP15:%.*]] = load i16, ptr [[TMP8]], align 1
; CHECK-NEXT:    [[TMP16:%.*]] = insertelement <4 x i16> poison, i16 [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP17:%.*]] = insertelement <4 x i16> [[TMP16]], i16 [[TMP13]], i32 1
; CHECK-NEXT:    [[TMP18:%.*]] = insertelement <4 x i16> [[TMP17]], i16 [[TMP14]], i32 2
; CHECK-NEXT:    [[TMP19:%.*]] = insertelement <4 x i16> [[TMP18]], i16 [[TMP15]], i32 3
; CHECK-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP9]], align 1
; CHECK-NEXT:    [[TMP21:%.*]] = zext <4 x i8> [[WIDE_LOAD]] to <4 x i32>
; CHECK-NEXT:    [[TMP22:%.*]] = zext <4 x i8> [[WIDE_LOAD1]] to <4 x i32>
; CHECK-NEXT:    [[TMP23:%.*]] = zext <4 x i16> [[TMP19]] to <4 x i32>
; CHECK-NEXT:    [[TMP24:%.*]] = zext <4 x i8> [[WIDE_LOAD2]] to <4 x i32>
; CHECK-NEXT:    [[TMP25:%.*]] = add nsw <4 x i32> [[TMP21]], [[TMP22]]
; CHECK-NEXT:    [[TMP26:%.*]] = add nsw <4 x i32> [[TMP24]], [[TMP23]]
; CHECK-NEXT:    [[TMP27:%.*]] = add <4 x i32> [[TMP25]], [[TMP26]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
; CHECK-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP28]], label %[[MIDDLE_BLOCK:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP8:![0-9]+]]
; CHECK:       [[MIDDLE_BLOCK]]:
; CHECK-NEXT:    [[TMP29:%.*]] = extractelement <4 x i32> [[TMP27]], i32 3
; CHECK-NEXT:    [[VECTOR_RECUR_EXTRACT:%.*]] = extractelement <4 x i32> [[TMP27]], i32 3
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[WIDE_TRIP_COUNT]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[CMP_N]], [[EXIT:label %.*]], label %[[SCALAR_PH]]
; CHECK:       [[SCALAR_PH]]:
;
entry:
  %cmp28.not = icmp ult i32 %N, 2
  %div27 = lshr i32 %N, 1
  %wide.trip.count = zext nneg i32 %div27 to i64
  br label %for.body

for.body:                                         ; preds = %for.body.preheader, %for.body
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %for.body ]
  %res = phi i32 [ 0, %entry ], [ %add3, %for.body ]
  %a.ptr = getelementptr inbounds nuw i8, ptr %a, i64 %iv
  %b.ptr = getelementptr inbounds nuw i8, ptr %b, i64 %iv
  %b.ptr2 = getelementptr inbounds nuw i16, ptr %b, i64 %iv
  %c.ptr = getelementptr inbounds nuw i8, ptr %c, i64 %iv
  %a.val = load i8, ptr %a.ptr, align 1
  %b.val = load i8, ptr %b.ptr, align 1
  %b.val2 = load i16, ptr %b.ptr, align 1
  %c.val = load i8, ptr %c.ptr, align 1
  %a.ext = zext i8 %a.val to i32
  %b.ext = zext i8 %b.val to i32
  %b.ext2 = zext i16 %b.val2 to i32
  %c.ext = zext i8 %c.val to i32
  %add = add nsw i32 %a.ext, %b.ext
  %add2 = add nsw i32 %c.ext, %b.ext2
  %add3 = add i32 %add, %add2
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %wide.trip.count
  br i1 %exitcond, label %exit, label %for.body

exit:                                 ; preds = %exit.loopexit, %entry
  %res.0.lcssa = phi i32 [ %add3, %for.body ]
  ret i32 %res.0.lcssa
}
