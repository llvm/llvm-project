; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -S -loop-vectorize -force-vector-width=2 -force-vector-interleave=1 -enable-interleaved-mem-accesses=true < %s | FileCheck %s

; When merging two stores with interleaved access vectorization, make sure we
; propagate the alias information from all scalar stores to form the most
; generic alias info.

target datalayout = "e-m:o-i64:64-i128:128-n32:64-S128"
target triple = "arm64-apple-ios5.0.0"

%struct.Vec4r = type { double, double, double, double }
%struct.Vec2r = type { double, double }

define void @foobar(%struct.Vec4r* nocapture readonly %p, i32 %i)
; CHECK-LABEL: @foobar(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[CP:%.*]] = alloca [20 x %struct.Vec2r], align 8
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [20 x %struct.Vec2r]* [[CP]] to i8*
; CHECK-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP2:%.*]] = add i64 [[INDEX]], 1
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT_VEC4R:%.*]], %struct.Vec4r* [[P:%.*]], i64 [[TMP1]], i32 0
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [[STRUCT_VEC4R]], %struct.Vec4r* [[P]], i64 [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = load double, double* [[TMP3]], align 8, !tbaa [[TBAA3:![0-9]+]]
; CHECK-NEXT:    [[TMP6:%.*]] = load double, double* [[TMP4]], align 8, !tbaa [[TBAA3]]
; CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x double> poison, double [[TMP5]], i32 0
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <2 x double> [[TMP7]], double [[TMP6]], i32 1
; CHECK-NEXT:    [[TMP9:%.*]] = fmul <2 x double> [[TMP8]], <double 2.000000e+00, double 2.000000e+00>
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT_VEC4R]], %struct.Vec4r* [[P]], i64 [[TMP1]], i32 1
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT_VEC4R]], %struct.Vec4r* [[P]], i64 [[TMP2]], i32 1
; CHECK-NEXT:    [[TMP12:%.*]] = load double, double* [[TMP10]], align 8, !tbaa [[TBAA8:![0-9]+]]
; CHECK-NEXT:    [[TMP13:%.*]] = load double, double* [[TMP11]], align 8, !tbaa [[TBAA8]]
; CHECK-NEXT:    [[TMP14:%.*]] = insertelement <2 x double> poison, double [[TMP12]], i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = insertelement <2 x double> [[TMP14]], double [[TMP13]], i32 1
; CHECK-NEXT:    [[TMP16:%.*]] = fmul <2 x double> [[TMP15]], <double 3.000000e+00, double 3.000000e+00>
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds [20 x %struct.Vec2r], [20 x %struct.Vec2r]* [[CP]], i64 0, i64 [[TMP1]], i32 1
; CHECK-NEXT:    [[TMP18:%.*]] = getelementptr inbounds double, double* [[TMP17]], i32 -1
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast double* [[TMP18]] to <4 x double>*
; CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <2 x double> [[TMP9]], <2 x double> [[TMP16]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    [[INTERLEAVED_VEC:%.*]] = shufflevector <4 x double> [[TMP20]], <4 x double> poison, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
; CHECK-NEXT:    store <4 x double> [[INTERLEAVED_VEC]], <4 x double>* [[TMP19]], align 8, !tbaa [[TBAA9:![0-9]+]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 2
; CHECK-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[INDEX_NEXT]], 4
; CHECK-NEXT:    br i1 [[TMP21]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP10:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 4, 4
; CHECK-NEXT:    br i1 [[CMP_N]], label [[FOR_COND_CLEANUP:%.*]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 4, [[MIDDLE_BLOCK]] ], [ 0, [[ENTRY:%.*]] ]
; CHECK-NEXT:    br label [[FOR_BODY:%.*]]
; CHECK:       for.cond.cleanup:
; CHECK-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [20 x %struct.Vec2r], [20 x %struct.Vec2r]* [[CP]], i64 0, i64 0
; CHECK-NEXT:    call void @g(%struct.Vec2r* nonnull [[ARRAYDECAY]])
; CHECK-NEXT:    ret void
; CHECK:       for.body:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ], [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ]
; CHECK-NEXT:    [[X:%.*]] = getelementptr inbounds [[STRUCT_VEC4R]], %struct.Vec4r* [[P]], i64 [[INDVARS_IV]], i32 0
; CHECK-NEXT:    [[TMP22:%.*]] = load double, double* [[X]], align 8, !tbaa [[TBAA3]]
; CHECK-NEXT:    [[MUL:%.*]] = fmul double [[TMP22]], 2.000000e+00
; CHECK-NEXT:    [[X4:%.*]] = getelementptr inbounds [20 x %struct.Vec2r], [20 x %struct.Vec2r]* [[CP]], i64 0, i64 [[INDVARS_IV]], i32 0
; CHECK-NEXT:    store double [[MUL]], double* [[X4]], align 8, !tbaa [[TBAA12:![0-9]+]]
; CHECK-NEXT:    [[Y:%.*]] = getelementptr inbounds [[STRUCT_VEC4R]], %struct.Vec4r* [[P]], i64 [[INDVARS_IV]], i32 1
; CHECK-NEXT:    [[TMP23:%.*]] = load double, double* [[Y]], align 8, !tbaa [[TBAA8]]
; CHECK-NEXT:    [[MUL7:%.*]] = fmul double [[TMP23]], 3.000000e+00
; CHECK-NEXT:    [[Y10:%.*]] = getelementptr inbounds [20 x %struct.Vec2r], [20 x %struct.Vec2r]* [[CP]], i64 0, i64 [[INDVARS_IV]], i32 1
; CHECK-NEXT:    store double [[MUL7]], double* [[Y10]], align 8, !tbaa [[TBAA14:![0-9]+]]
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 4
; CHECK-NEXT:    br i1 [[EXITCOND]], label [[FOR_COND_CLEANUP]], label [[FOR_BODY]], !llvm.loop [[LOOP15:![0-9]+]]
;
{
entry:
  %cp = alloca [20 x %struct.Vec2r], align 8
  %0 = bitcast [20 x %struct.Vec2r]* %cp to i8*
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %arraydecay = getelementptr inbounds [20 x %struct.Vec2r], [20 x %struct.Vec2r]* %cp, i64 0, i64 0
  call void @g(%struct.Vec2r* nonnull %arraydecay) #4
  ret void

for.body:                                         ; preds = %for.body, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %x = getelementptr inbounds %struct.Vec4r, %struct.Vec4r* %p, i64 %indvars.iv, i32 0
  %1 = load double, double* %x, align 8, !tbaa !3
  %mul = fmul double %1, 2.000000e+00
  %x4 = getelementptr inbounds [20 x %struct.Vec2r], [20 x %struct.Vec2r]* %cp, i64 0, i64 %indvars.iv, i32 0

; The new store should alias any double rather than one of the fields of Vec2r.
  store double %mul, double* %x4, align 8, !tbaa !8
  %y = getelementptr inbounds %struct.Vec4r, %struct.Vec4r* %p, i64 %indvars.iv, i32 1
  %2 = load double, double* %y, align 8, !tbaa !10
  %mul7 = fmul double %2, 3.000000e+00
  %y10 = getelementptr inbounds [20 x %struct.Vec2r], [20 x %struct.Vec2r]* %cp, i64 0, i64 %indvars.iv, i32 1
  store double %mul7, double* %y10, align 8, !tbaa !11
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 4
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

declare void @g(%struct.Vec2r*)

!llvm.module.flags = !{!0, !1}
!llvm.ident = !{!2}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!"clang version 6.0.0 (trunk 319007) (llvm/trunk 319324)"}
!3 = !{!4, !5, i64 0}
!4 = !{!"Vec4r", !5, i64 0, !5, i64 8, !5, i64 16, !5, i64 24}
!5 = !{!"double", !6, i64 0}
!6 = !{!"omnipotent char", !7, i64 0}
!7 = !{!"Simple C/C++ TBAA"}
!8 = !{!9, !5, i64 0}
!9 = !{!"Vec2r", !5, i64 0, !5, i64 8}
!10 = !{!4, !5, i64 8}
!11 = !{!9, !5, i64 8}
