; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -basic-aa -scoped-noalias-aa -loop-vectorize -licm -force-vector-width=2 \
; RUN:     -force-vector-interleave=1 -S < %s | FileCheck %s

target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"

; In order to vectorize the inner loop, it needs to be versioned with
; memchecks between {A} x {B, C} first:
;
;   for (i = 0; i < n; i++)
;     for (j = 0; j < m; j++)
;         A[j] += B[i] + C[j];
;
; Since in the versioned vector loop A and B can no longer alias, B[i] can be
; LICM'ed from the inner loop.


define void @f(i32* %a, i32* %b, i32* %c) {
; CHECK-LABEL: @f(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[A1:%.*]] = bitcast i32* [[A:%.*]] to i8*
; CHECK-NEXT:    [[C7:%.*]] = bitcast i32* [[C:%.*]] to i8*
; CHECK-NEXT:    [[SCEVGEP:%.*]] = getelementptr i32, i32* [[A]], i64 20
; CHECK-NEXT:    [[SCEVGEP2:%.*]] = bitcast i32* [[SCEVGEP]] to i8*
; CHECK-NEXT:    [[SCEVGEP8:%.*]] = getelementptr i32, i32* [[C]], i64 20
; CHECK-NEXT:    [[SCEVGEP89:%.*]] = bitcast i32* [[SCEVGEP8]] to i8*
; CHECK-NEXT:    [[BOUND010:%.*]] = icmp ult i8* [[A1]], [[SCEVGEP89]]
; CHECK-NEXT:    [[BOUND111:%.*]] = icmp ult i8* [[C7]], [[SCEVGEP2]]
; CHECK-NEXT:    [[FOUND_CONFLICT12:%.*]] = and i1 [[BOUND010]], [[BOUND111]]
; CHECK-NEXT:    br label [[OUTER:%.*]]
; CHECK:       outer:
; CHECK-NEXT:    [[I_2:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[I:%.*]], [[INNER_END:%.*]] ]
; CHECK-NEXT:    [[SCEVGEP3:%.*]] = getelementptr i32, i32* [[B:%.*]], i64 [[I_2]]
; CHECK-NEXT:    [[SCEVGEP34:%.*]] = bitcast i32* [[SCEVGEP3]] to i8*
; CHECK-NEXT:    [[TMP0:%.*]] = add i64 [[I_2]], 1
; CHECK-NEXT:    [[SCEVGEP5:%.*]] = getelementptr i32, i32* [[B]], i64 [[TMP0]]
; CHECK-NEXT:    [[SCEVGEP56:%.*]] = bitcast i32* [[SCEVGEP5]] to i8*
; CHECK-NEXT:    [[ARRAYIDXB:%.*]] = getelementptr inbounds i32, i32* [[B]], i64 [[I_2]]
; CHECK-NEXT:    br label [[INNER_PH:%.*]]
; CHECK:       inner.ph:
; CHECK-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_MEMCHECK:%.*]]
; CHECK:       vector.memcheck:
; CHECK-NEXT:    [[BOUND0:%.*]] = icmp ult i8* [[A1]], [[SCEVGEP56]]
; CHECK-NEXT:    [[BOUND1:%.*]] = icmp ult i8* [[SCEVGEP34]], [[SCEVGEP2]]
; CHECK-NEXT:    [[FOUND_CONFLICT:%.*]] = and i1 [[BOUND0]], [[BOUND1]]
; CHECK-NEXT:    [[CONFLICT_RDX:%.*]] = or i1 [[FOUND_CONFLICT]], [[FOUND_CONFLICT12]]
; CHECK-NEXT:    br i1 [[CONFLICT_RDX]], label [[SCALAR_PH]], label [[VECTOR_PH:%.*]]
; CHECK:       vector.ph:
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[ARRAYIDXB]], align 4, !alias.scope !0
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <2 x i32> poison, i32 [[TMP1]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <2 x i32> [[BROADCAST_SPLATINSERT]], <2 x i32> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP2:%.*]] = add i64 [[INDEX]], 0
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i32, i32* [[A]], i64 [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds i32, i32* [[TMP3]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i32* [[TMP4]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <2 x i32>, <2 x i32>* [[TMP5]], align 4, !alias.scope !3, !noalias !5
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds i32, i32* [[C]], i64 [[TMP2]]
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds i32, i32* [[TMP6]], i32 0
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i32* [[TMP7]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD13:%.*]] = load <2 x i32>, <2 x i32>* [[TMP8]], align 4, !alias.scope !7
; CHECK-NEXT:    [[TMP9:%.*]] = add nuw <2 x i32> [[WIDE_LOAD]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    [[TMP10:%.*]] = add nuw <2 x i32> [[TMP9]], [[WIDE_LOAD13]]
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i32* [[TMP4]] to <2 x i32>*
; CHECK-NEXT:    store <2 x i32> [[TMP10]], <2 x i32>* [[TMP11]], align 4, !alias.scope !3, !noalias !5
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 2
; CHECK-NEXT:    [[TMP12:%.*]] = icmp eq i64 [[INDEX_NEXT]], 20
; CHECK-NEXT:    br i1 [[TMP12]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP8:![0-9]+]]
; CHECK:       middle.block:
; CHECK-NEXT:    br i1 true, label [[INNER_END]], label [[SCALAR_PH]]
; CHECK:       scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 20, [[MIDDLE_BLOCK]] ], [ 0, [[INNER_PH]] ], [ 0, [[VECTOR_MEMCHECK]] ]
; CHECK-NEXT:    br label [[INNER:%.*]]
; CHECK:       inner:
; CHECK-NEXT:    [[J_2:%.*]] = phi i64 [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ], [ [[J:%.*]], [[INNER]] ]
; CHECK-NEXT:    [[ARRAYIDXA:%.*]] = getelementptr inbounds i32, i32* [[A]], i64 [[J_2]]
; CHECK-NEXT:    [[LOADA:%.*]] = load i32, i32* [[ARRAYIDXA]], align 4
; CHECK-NEXT:    [[LOADB:%.*]] = load i32, i32* [[ARRAYIDXB]], align 4
; CHECK-NEXT:    [[ARRAYIDXC:%.*]] = getelementptr inbounds i32, i32* [[C]], i64 [[J_2]]
; CHECK-NEXT:    [[LOADC:%.*]] = load i32, i32* [[ARRAYIDXC]], align 4
; CHECK-NEXT:    [[ADD:%.*]] = add nuw i32 [[LOADA]], [[LOADB]]
; CHECK-NEXT:    [[ADD2:%.*]] = add nuw i32 [[ADD]], [[LOADC]]
; CHECK-NEXT:    store i32 [[ADD2]], i32* [[ARRAYIDXA]], align 4
; CHECK-NEXT:    [[J]] = add nuw nsw i64 [[J_2]], 1
; CHECK-NEXT:    [[COND1:%.*]] = icmp eq i64 [[J]], 20
; CHECK-NEXT:    br i1 [[COND1]], label [[INNER_END_LOOPEXIT:%.*]], label [[INNER]], !llvm.loop [[LOOP10:![0-9]+]]
; CHECK:       inner.end.loopexit:
; CHECK-NEXT:    br label [[INNER_END]]
; CHECK:       inner.end:
; CHECK-NEXT:    [[I]] = add nuw nsw i64 [[I_2]], 1
; CHECK-NEXT:    [[COND2:%.*]] = icmp eq i64 [[I]], 30
; CHECK-NEXT:    br i1 [[COND2]], label [[OUTER_END:%.*]], label [[OUTER]]
; CHECK:       outer.end:
; CHECK-NEXT:    ret void
;
entry:
  br label %outer

outer:
  %i.2 = phi i64 [ 0, %entry ], [ %i, %inner.end ]
  %arrayidxB = getelementptr inbounds i32, i32* %b, i64 %i.2
  br label %inner.ph

inner.ph:
  br label %inner

inner:
  %j.2 = phi i64 [ 0, %inner.ph ], [ %j, %inner ]

  %arrayidxA = getelementptr inbounds i32, i32* %a, i64 %j.2
  %loadA = load i32, i32* %arrayidxA, align 4

  %loadB = load i32, i32* %arrayidxB, align 4

  %arrayidxC = getelementptr inbounds i32, i32* %c, i64 %j.2
  %loadC = load i32, i32* %arrayidxC, align 4

  %add = add nuw i32 %loadA, %loadB
  %add2 = add nuw i32 %add, %loadC

  store i32 %add2, i32* %arrayidxA, align 4

  %j = add nuw nsw i64 %j.2, 1
  %cond1 = icmp eq i64 %j, 20
  br i1 %cond1, label %inner.end, label %inner

inner.end:
  %i = add nuw nsw i64 %i.2, 1
  %cond2 = icmp eq i64 %i, 30
  br i1 %cond2, label %outer.end, label %outer

outer.end:
  ret void
}
