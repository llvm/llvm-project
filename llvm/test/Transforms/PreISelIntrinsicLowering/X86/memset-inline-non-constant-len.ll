; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-globals all --version 5
; RUN: opt -mtriple=x86_64-pc-linux-gnu -passes=pre-isel-intrinsic-lowering -S -o - %s | FileCheck %s

; Constant length memset.inline should be left unmodified.
define void @memset_32(ptr %a, i8 %value) nounwind {
; CHECK-LABEL: define void @memset_32(
; CHECK-SAME: ptr [[A:%.*]], i8 [[VALUE:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:    call void @llvm.memset.inline.p0.i64(ptr [[A]], i8 [[VALUE]], i64 32, i1 false)
; CHECK-NEXT:    tail call void @llvm.memset.inline.p0.i64(ptr [[A]], i8 [[VALUE]], i64 32, i1 true)
; CHECK-NEXT:    ret void
;
  call void @llvm.memset.inline.p0.i64(ptr %a, i8 %value, i64 32, i1 0)
  tail call void @llvm.memset.inline.p0.i64(ptr %a, i8 %value, i64 32, i1 1)
  ret void
}

define void @memset_x(ptr %a, i8 %value, i64 %x) nounwind !prof !0 {
; CHECK-LABEL: define void @memset_x(
; CHECK-SAME: ptr [[A:%.*]], i8 [[VALUE:%.*]], i64 [[X:%.*]]) #[[ATTR0]] !prof [[PROF0:![0-9]+]] {
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 0, [[X]]
; CHECK-NEXT:    br i1 [[TMP1]], label %[[SPLIT:.*]], label %[[LOADSTORELOOP:.*]], !prof [[PROF1:![0-9]+]]
; CHECK:       [[LOADSTORELOOP]]:
; CHECK-NEXT:    [[TMP2:%.*]] = phi i64 [ 0, [[TMP0:%.*]] ], [ [[TMP4:%.*]], %[[LOADSTORELOOP]] ]
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[A]], i64 [[TMP2]]
; CHECK-NEXT:    store i8 [[VALUE]], ptr [[TMP3]], align 1
; CHECK-NEXT:    [[TMP4]] = add i64 [[TMP2]], 1
; CHECK-NEXT:    [[TMP5:%.*]] = icmp ult i64 [[TMP4]], [[X]]
; CHECK-NEXT:    br i1 [[TMP5]], label %[[LOADSTORELOOP]], label %[[SPLIT]], !prof [[PROF2:![0-9]+]]
; CHECK:       [[SPLIT]]:
; CHECK-NEXT:    [[TMP6:%.*]] = icmp eq i64 0, [[X]]
; CHECK-NEXT:    br i1 [[TMP6]], label %[[SPLIT1:.*]], label %[[LOADSTORELOOP2:.*]], !prof [[PROF3:![0-9]+]]
; CHECK:       [[LOADSTORELOOP2]]:
; CHECK-NEXT:    [[TMP7:%.*]] = phi i64 [ 0, %[[SPLIT]] ], [ [[TMP9:%.*]], %[[LOADSTORELOOP2]] ]
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds i8, ptr [[A]], i64 [[TMP7]]
; CHECK-NEXT:    store volatile i8 [[VALUE]], ptr [[TMP8]], align 1
; CHECK-NEXT:    [[TMP9]] = add i64 [[TMP7]], 1
; CHECK-NEXT:    [[TMP10:%.*]] = icmp ult i64 [[TMP9]], [[X]]
; CHECK-NEXT:    br i1 [[TMP10]], label %[[LOADSTORELOOP2]], label %[[SPLIT1]], !prof [[PROF3]]
; CHECK:       [[SPLIT1]]:
; CHECK-NEXT:    ret void
;
  call void @llvm.memset.inline.p0.i64(ptr %a, i8 %value, i64 %x, i1 0), !prof !1
  tail call void @llvm.memset.inline.p0.i64(ptr %a, i8 %value, i64 %x, i1 1)
  ret void
}

!0 = !{!"function_entry_count", i32 10}
!1 = !{!"VP", i32 1, i32 100, i32 5, i32 10, i32 16, i32 13}
;.
; CHECK: attributes #[[ATTR0]] = { nounwind }
; CHECK: attributes #[[ATTR1:[0-9]+]] = { nocallback nofree nounwind willreturn memory(argmem: write) }
;.
; CHECK: [[PROF0]] = !{!"function_entry_count", i32 10}
; CHECK: [[PROF1]] = !{!"branch_weights", i32 1048575, i32 1}
; CHECK: [[PROF2]] = !{!"branch_weights", i32 3, i32 1}
; CHECK: [[PROF3]] = !{!"unknown", !"lower-mem-intrinsics"}
;.
