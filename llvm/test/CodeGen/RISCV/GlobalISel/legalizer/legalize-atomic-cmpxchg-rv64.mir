# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=riscv64 -mattr=+a,+zacas,+zabha -run-pass=legalizer %s -o - \
# RUN: | FileCheck %s --check-prefixes=RV32IA-ZABHA
# RUN: llc -mtriple=riscv64 -mattr=+a -run-pass=legalizer %s -o - \
# RUN: | FileCheck %s --check-prefixes=RV32IA

---
name:            cmpxchg_i8
body:             |
  bb.0:
    liveins: $x10

    ; RV32IA-ZABHA-LABEL: name: cmpxchg_i8
    ; RV32IA-ZABHA: liveins: $x10
    ; RV32IA-ZABHA-NEXT: {{  $}}
    ; RV32IA-ZABHA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-ZABHA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-ZABHA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-ZABHA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s8))
    ; RV32IA-ZABHA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-ZABHA-NEXT: PseudoRET implicit $x10
    ;
    ; RV32IA-LABEL: name: cmpxchg_i8
    ; RV32IA: liveins: $x10
    ; RV32IA-NEXT: {{  $}}
    ; RV32IA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s8))
    ; RV32IA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-NEXT: PseudoRET implicit $x10
    %0:_(p0) = COPY $x10
    %1:_(s8) = G_CONSTANT i8 0
    %2:_(s8) = G_CONSTANT i8 1
    %3:_(s8) = G_ATOMIC_CMPXCHG %0, %1, %2 :: (load store monotonic (s8))
    %4:_(s64) = G_ANYEXT %3
    $x10 = COPY %4(s64)
    PseudoRET implicit $x10
...
---
name:            cmpxchg_i16
body:             |
  bb.0:
    liveins: $x10

    ; RV32IA-ZABHA-LABEL: name: cmpxchg_i16
    ; RV32IA-ZABHA: liveins: $x10
    ; RV32IA-ZABHA-NEXT: {{  $}}
    ; RV32IA-ZABHA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-ZABHA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-ZABHA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-ZABHA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s16))
    ; RV32IA-ZABHA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-ZABHA-NEXT: PseudoRET implicit $x10
    ;
    ; RV32IA-LABEL: name: cmpxchg_i16
    ; RV32IA: liveins: $x10
    ; RV32IA-NEXT: {{  $}}
    ; RV32IA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s16))
    ; RV32IA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-NEXT: PseudoRET implicit $x10
    %0:_(p0) = COPY $x10
    %1:_(s16) = G_CONSTANT i16 0
    %2:_(s16) = G_CONSTANT i16 1
    %3:_(s16) = G_ATOMIC_CMPXCHG %0, %1, %2 :: (load store monotonic (s16))
    %4:_(s64) = G_ANYEXT %3
    $x10 = COPY %4(s64)
    PseudoRET implicit $x10
...
---
name:            cmpxchg_i32
body:             |
  bb.0:
    liveins: $x10

    ; RV32IA-ZABHA-LABEL: name: cmpxchg_i32
    ; RV32IA-ZABHA: liveins: $x10
    ; RV32IA-ZABHA-NEXT: {{  $}}
    ; RV32IA-ZABHA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-ZABHA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-ZABHA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-ZABHA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s32))
    ; RV32IA-ZABHA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-ZABHA-NEXT: PseudoRET implicit $x10
    ;
    ; RV32IA-LABEL: name: cmpxchg_i32
    ; RV32IA: liveins: $x10
    ; RV32IA-NEXT: {{  $}}
    ; RV32IA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s32))
    ; RV32IA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-NEXT: PseudoRET implicit $x10
    %0:_(p0) = COPY $x10
    %1:_(s32) = G_CONSTANT i32 0
    %2:_(s32) = G_CONSTANT i32 1
    %3:_(s32) = G_ATOMIC_CMPXCHG %0, %1, %2 :: (load store monotonic (s32))
    %4:_(s64) = G_ANYEXT %3
    $x10 = COPY %4(s64)
    PseudoRET implicit $x10
...
---
name:            cmpxchg_i64
body:             |
  bb.0:
    liveins: $x10

    ; RV32IA-ZABHA-LABEL: name: cmpxchg_i64
    ; RV32IA-ZABHA: liveins: $x10
    ; RV32IA-ZABHA-NEXT: {{  $}}
    ; RV32IA-ZABHA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-ZABHA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-ZABHA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-ZABHA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s64))
    ; RV32IA-ZABHA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-ZABHA-NEXT: PseudoRET implicit $x10
    ;
    ; RV32IA-LABEL: name: cmpxchg_i64
    ; RV32IA: liveins: $x10
    ; RV32IA-NEXT: {{  $}}
    ; RV32IA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s64))
    ; RV32IA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-NEXT: PseudoRET implicit $x10
    %0:_(p0) = COPY $x10
    %1:_(s64) = G_CONSTANT i64 0
    %2:_(s64) = G_CONSTANT i64 1
    %3:_(s64) = G_ATOMIC_CMPXCHG %0, %1, %2 :: (load store monotonic (s64))
    $x10 = COPY %3(s64)
    PseudoRET implicit $x10
...
---
name:            cmpxchg_with_success_i32

body:             |
  bb.0:
    liveins: $x10

    ; RV32IA-ZABHA-LABEL: name: cmpxchg_with_success_i32
    ; RV32IA-ZABHA: liveins: $x10
    ; RV32IA-ZABHA-NEXT: {{  $}}
    ; RV32IA-ZABHA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-ZABHA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-ZABHA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-ZABHA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s32))
    ; RV32IA-ZABHA-NEXT: [[SEXT_INREG:%[0-9]+]]:_(s64) = G_SEXT_INREG [[ATOMIC_CMPXCHG]], 32
    ; RV32IA-ZABHA-NEXT: [[ICMP:%[0-9]+]]:_(s64) = G_ICMP intpred(eq), [[SEXT_INREG]](s64), [[C]]
    ; RV32IA-ZABHA-NEXT: ADJCALLSTACKDOWN 0, 0, implicit-def $x2, implicit $x2
    ; RV32IA-ZABHA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-ZABHA-NEXT: $x11 = COPY [[ICMP]](s64)
    ; RV32IA-ZABHA-NEXT: PseudoCALL target-flags(riscv-call) &__muldi3, csr_ilp32_lp64, implicit-def $x1, implicit $x10, implicit $x11, implicit-def $x10
    ; RV32IA-ZABHA-NEXT: ADJCALLSTACKUP 0, 0, implicit-def $x2, implicit $x2
    ; RV32IA-ZABHA-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x10
    ; RV32IA-ZABHA-NEXT: $x10 = COPY [[COPY1]](s64)
    ; RV32IA-ZABHA-NEXT: PseudoRET implicit $x10
    ;
    ; RV32IA-LABEL: name: cmpxchg_with_success_i32
    ; RV32IA: liveins: $x10
    ; RV32IA-NEXT: {{  $}}
    ; RV32IA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s32))
    ; RV32IA-NEXT: [[SEXT_INREG:%[0-9]+]]:_(s64) = G_SEXT_INREG [[ATOMIC_CMPXCHG]], 32
    ; RV32IA-NEXT: [[ICMP:%[0-9]+]]:_(s64) = G_ICMP intpred(eq), [[SEXT_INREG]](s64), [[C]]
    ; RV32IA-NEXT: ADJCALLSTACKDOWN 0, 0, implicit-def $x2, implicit $x2
    ; RV32IA-NEXT: $x10 = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-NEXT: $x11 = COPY [[ICMP]](s64)
    ; RV32IA-NEXT: PseudoCALL target-flags(riscv-call) &__muldi3, csr_ilp32_lp64, implicit-def $x1, implicit $x10, implicit $x11, implicit-def $x10
    ; RV32IA-NEXT: ADJCALLSTACKUP 0, 0, implicit-def $x2, implicit $x2
    ; RV32IA-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x10
    ; RV32IA-NEXT: $x10 = COPY [[COPY1]](s64)
    ; RV32IA-NEXT: PseudoRET implicit $x10
    %0:_(p0) = COPY $x10
    %1:_(s32) = G_CONSTANT i32 0
    %2:_(s32) = G_CONSTANT i32 1
    %3:_(s32), %4:_(s1) = G_ATOMIC_CMPXCHG_WITH_SUCCESS %0, %1, %2 :: (load store monotonic (s32))
    %5:_(s32) = G_ANYEXT %4
    %6:_(s32) = G_MUL %3, %5
    %7:_(s64) = G_ANYEXT %6
    $x10 = COPY %7(s64)
    PseudoRET implicit $x10
...
---
name:            cmpxchg_with_success_i64

body:             |
  bb.0:
    liveins: $x10

    ; RV32IA-ZABHA-LABEL: name: cmpxchg_with_success_i64
    ; RV32IA-ZABHA: liveins: $x10
    ; RV32IA-ZABHA-NEXT: {{  $}}
    ; RV32IA-ZABHA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-ZABHA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-ZABHA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-ZABHA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s64))
    ; RV32IA-ZABHA-NEXT: [[ICMP:%[0-9]+]]:_(s64) = G_ICMP intpred(eq), [[ATOMIC_CMPXCHG]](s64), [[C]]
    ; RV32IA-ZABHA-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-ZABHA-NEXT: ADJCALLSTACKDOWN 0, 0, implicit-def $x2, implicit $x2
    ; RV32IA-ZABHA-NEXT: $x10 = COPY [[COPY1]](s64)
    ; RV32IA-ZABHA-NEXT: $x11 = COPY [[ICMP]](s64)
    ; RV32IA-ZABHA-NEXT: PseudoCALL target-flags(riscv-call) &__muldi3, csr_ilp32_lp64, implicit-def $x1, implicit $x10, implicit $x11, implicit-def $x10
    ; RV32IA-ZABHA-NEXT: ADJCALLSTACKUP 0, 0, implicit-def $x2, implicit $x2
    ; RV32IA-ZABHA-NEXT: [[COPY2:%[0-9]+]]:_(s64) = COPY $x10
    ; RV32IA-ZABHA-NEXT: $x10 = COPY [[COPY2]](s64)
    ; RV32IA-ZABHA-NEXT: PseudoRET implicit $x10
    ;
    ; RV32IA-LABEL: name: cmpxchg_with_success_i64
    ; RV32IA: liveins: $x10
    ; RV32IA-NEXT: {{  $}}
    ; RV32IA-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x10
    ; RV32IA-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; RV32IA-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; RV32IA-NEXT: [[ATOMIC_CMPXCHG:%[0-9]+]]:_(s64) = G_ATOMIC_CMPXCHG [[COPY]](p0), [[C]], [[C1]] :: (load store monotonic (s64))
    ; RV32IA-NEXT: [[ICMP:%[0-9]+]]:_(s64) = G_ICMP intpred(eq), [[ATOMIC_CMPXCHG]](s64), [[C]]
    ; RV32IA-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY [[ATOMIC_CMPXCHG]](s64)
    ; RV32IA-NEXT: ADJCALLSTACKDOWN 0, 0, implicit-def $x2, implicit $x2
    ; RV32IA-NEXT: $x10 = COPY [[COPY1]](s64)
    ; RV32IA-NEXT: $x11 = COPY [[ICMP]](s64)
    ; RV32IA-NEXT: PseudoCALL target-flags(riscv-call) &__muldi3, csr_ilp32_lp64, implicit-def $x1, implicit $x10, implicit $x11, implicit-def $x10
    ; RV32IA-NEXT: ADJCALLSTACKUP 0, 0, implicit-def $x2, implicit $x2
    ; RV32IA-NEXT: [[COPY2:%[0-9]+]]:_(s64) = COPY $x10
    ; RV32IA-NEXT: $x10 = COPY [[COPY2]](s64)
    ; RV32IA-NEXT: PseudoRET implicit $x10
    %0:_(p0) = COPY $x10
    %1:_(s64) = G_CONSTANT i64 0
    %2:_(s64) = G_CONSTANT i64 1
    %3:_(s64), %4:_(s1) = G_ATOMIC_CMPXCHG_WITH_SUCCESS %0, %1, %2 :: (load store monotonic (s64))
    %5:_(s64) = G_ANYEXT %4
    %6:_(s64) = G_MUL %3, %5
    $x10 = COPY %6(s64)
    PseudoRET implicit $x10
...
