; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s -mtriple=riscv32 -mattr=+v,+zvfbfmin -verify-machineinstrs | FileCheck %s
; RUN: llc < %s -mtriple=riscv64 -mattr=+v,+zvfbfmin -verify-machineinstrs | FileCheck %s

define <vscale x 1 x bfloat> @nxv1bf16(<vscale x 1 x bfloat> %vm, <vscale x 1 x bfloat> %vs) {
; CHECK-LABEL: nxv1bf16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a0, 8
; CHECK-NEXT:    vsetvli a1, zero, e16, mf4, ta, ma
; CHECK-NEXT:    vand.vx v9, v9, a0
; CHECK-NEXT:    addi a0, a0, -1
; CHECK-NEXT:    vand.vx v8, v8, a0
; CHECK-NEXT:    vor.vv v8, v8, v9
; CHECK-NEXT:    ret
  %r = call <vscale x 1 x bfloat> @llvm.copysign.nxv1bf16(<vscale x 1 x bfloat> %vm, <vscale x 1 x bfloat> %vs)
  ret <vscale x 1 x bfloat> %r
}

define <vscale x 2 x bfloat> @nxv2bf16(<vscale x 2 x bfloat> %vm, <vscale x 2 x bfloat> %vs) {
; CHECK-LABEL: nxv2bf16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a0, 8
; CHECK-NEXT:    vsetvli a1, zero, e16, mf2, ta, ma
; CHECK-NEXT:    vand.vx v9, v9, a0
; CHECK-NEXT:    addi a0, a0, -1
; CHECK-NEXT:    vand.vx v8, v8, a0
; CHECK-NEXT:    vor.vv v8, v8, v9
; CHECK-NEXT:    ret
  %r = call <vscale x 2 x bfloat> @llvm.copysign.nxv2bf16(<vscale x 2 x bfloat> %vm, <vscale x 2 x bfloat> %vs)
  ret <vscale x 2 x bfloat> %r
}

define <vscale x 4 x bfloat> @nxv4bf16(<vscale x 4 x bfloat> %vm, <vscale x 4 x bfloat> %vs) {
; CHECK-LABEL: nxv4bf16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a0, 8
; CHECK-NEXT:    vsetvli a1, zero, e16, m1, ta, ma
; CHECK-NEXT:    vand.vx v9, v9, a0
; CHECK-NEXT:    addi a0, a0, -1
; CHECK-NEXT:    vand.vx v8, v8, a0
; CHECK-NEXT:    vor.vv v8, v8, v9
; CHECK-NEXT:    ret
  %r = call <vscale x 4 x bfloat> @llvm.copysign.nxv4bf16(<vscale x 4 x bfloat> %vm, <vscale x 4 x bfloat> %vs)
  ret <vscale x 4 x bfloat> %r
}

define <vscale x 8 x bfloat> @nxv8bf16(<vscale x 8 x bfloat> %vm, <vscale x 8 x bfloat> %vs) {
; CHECK-LABEL: nxv8bf16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a0, 8
; CHECK-NEXT:    vsetvli a1, zero, e16, m2, ta, ma
; CHECK-NEXT:    vand.vx v10, v10, a0
; CHECK-NEXT:    addi a0, a0, -1
; CHECK-NEXT:    vand.vx v8, v8, a0
; CHECK-NEXT:    vor.vv v8, v8, v10
; CHECK-NEXT:    ret
  %r = call <vscale x 8 x bfloat> @llvm.copysign.nxv8bf16(<vscale x 8 x bfloat> %vm, <vscale x 8 x bfloat> %vs)
  ret <vscale x 8 x bfloat> %r
}

define <vscale x 16 x bfloat> @nxv16bf16(<vscale x 16 x bfloat> %vm, <vscale x 16 x bfloat> %vs) {
; CHECK-LABEL: nxv16bf16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a0, 8
; CHECK-NEXT:    vsetvli a1, zero, e16, m4, ta, ma
; CHECK-NEXT:    vand.vx v12, v12, a0
; CHECK-NEXT:    addi a0, a0, -1
; CHECK-NEXT:    vand.vx v8, v8, a0
; CHECK-NEXT:    vor.vv v8, v8, v12
; CHECK-NEXT:    ret
  %r = call <vscale x 16 x bfloat> @llvm.copysign.nxv16bf16(<vscale x 16 x bfloat> %vm, <vscale x 16 x bfloat> %vs)
  ret <vscale x 16 x bfloat> %r
}

define <vscale x 32 x bfloat> @nxv32bf32(<vscale x 32 x bfloat> %vm, <vscale x 32 x bfloat> %vs) {
; CHECK-LABEL: nxv32bf32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a0, 8
; CHECK-NEXT:    vsetvli a1, zero, e16, m8, ta, ma
; CHECK-NEXT:    vand.vx v16, v16, a0
; CHECK-NEXT:    addi a0, a0, -1
; CHECK-NEXT:    vand.vx v8, v8, a0
; CHECK-NEXT:    vor.vv v8, v8, v16
; CHECK-NEXT:    ret
  %r = call <vscale x 32 x bfloat> @llvm.copysign.nxv32bf32(<vscale x 32 x bfloat> %vm, <vscale x 32 x bfloat> %vs)
  ret <vscale x 32 x bfloat> %r
}
