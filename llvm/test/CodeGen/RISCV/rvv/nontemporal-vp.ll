; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=riscv64 -mattr=+zihintntl,+f,+d,+zfh,+v < %s | FileCheck %s -check-prefix=CHECK-RV64V
; RUN: llc -mtriple=riscv32 -mattr=+zihintntl,+f,+d,+zfh,+v < %s | FileCheck %s -check-prefix=CHECK-RV32V
; RUN: llc -mtriple=riscv64 -mattr=+zihintntl,+f,+d,+zfh,+v,+c < %s | FileCheck %s -check-prefix=CHECK-RV64VC
; RUN: llc -mtriple=riscv32 -mattr=+zihintntl,+f,+d,+zfh,+v,+c < %s | FileCheck %s -check-prefix=CHECK-RV32VC


define <16 x i8> @test_nontemporal_vp_load_v16i8_P1(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v16i8_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vle8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v16i8_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vle8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v16i8_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v16i8_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.load.v16i8.p0(ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_load_v16i8_PALL(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v16i8_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vle8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v16i8_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vle8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v16i8_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v16i8_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.load.v16i8.p0(ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_load_v16i8_S1(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v16i8_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vle8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v16i8_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vle8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v16i8_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v16i8_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.load.v16i8.p0(ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_load_v16i8_ALL(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v16i8_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vle8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v16i8_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vle8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v16i8_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v16i8_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.load.v16i8.p0(ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <16 x i8> %x
}

define <16 x i8> @test_nontemporal_vp_load_v16i8_DEFAULT(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v16i8_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vle8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v16i8_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vle8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v16i8_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v16i8_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vle8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.load.v16i8.p0(ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <16 x i8> %x
}


define void @test_nontemporal_vp_store_v16i8_P1(<16 x i8> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v16i8_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vse8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v16i8_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vse8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v16i8_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v16i8_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v16i8.p0(<16 x i8> %val, ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_store_v16i8_PALL(<16 x i8> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v16i8_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vse8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v16i8_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vse8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v16i8_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v16i8_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v16i8.p0(<16 x i8> %val, ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_store_v16i8_S1(<16 x i8> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v16i8_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vse8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v16i8_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vse8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v16i8_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v16i8_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v16i8.p0(<16 x i8> %val, ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_store_v16i8_ALL(<16 x i8> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v16i8_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vse8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v16i8_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vse8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v16i8_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v16i8_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v16i8.p0(<16 x i8> %val, ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_store_v16i8_DEFAULT(<16 x i8> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v16i8_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vse8.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v16i8_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vse8.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v16i8_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v16i8_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vse8.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v16i8.p0(<16 x i8> %val, ptr %p, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <16 x i8> @test_nontemporal_vp_gather_v16i8_P1(<16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v16i8_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v16i8_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v16i8_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v16i8_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.gather.v16i8.v16p0(<16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_gather_v16i8_PALL(<16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v16i8_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v16i8_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v16i8_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v16i8_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.gather.v16i8.v16p0(<16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_gather_v16i8_S1(<16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v16i8_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v16i8_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v16i8_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v16i8_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.gather.v16i8.v16p0(<16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_gather_v16i8_ALL(<16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v16i8_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v16i8_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v16i8_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v16i8_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.gather.v16i8.v16p0(<16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <16 x i8> %x
}

define <16 x i8> @test_nontemporal_vp_gather_v16i8_DEFAULT(<16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v16i8_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v16i8_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v16i8_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vluxei64.v v16, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v16i8_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vluxei32.v v12, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.vp.gather.v16i8.v16p0(<16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <16 x i8> %x
}


define void @test_nontemporal_vp_scatter_v16i8_P1(<16 x i8> %val, <16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v16i8_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v16i8_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v16i8_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v16i8_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v16i8.v16p0(<16 x i8> %val, <16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_scatter_v16i8_PALL(<16 x i8> %val, <16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v16i8_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v16i8_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v16i8_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v16i8_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v16i8.v16p0(<16 x i8> %val, <16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_scatter_v16i8_S1(<16 x i8> %val, <16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v16i8_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v16i8_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v16i8_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v16i8_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v16i8.v16p0(<16 x i8> %val, <16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_scatter_v16i8_ALL(<16 x i8> %val, <16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v16i8_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v16i8_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v16i8_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v16i8_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v16i8.v16p0(<16 x i8> %val, <16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_scatter_v16i8_DEFAULT(<16 x i8> %val, <16 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v16i8_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v16i8_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v16i8_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v16
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v16i8_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v12
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v16i8.v16p0(<16 x i8> %val, <16 x ptr> %ptrs, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <16 x i8> @test_nontemporal_vp_strided.load_v16i8_P1(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v16i8_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v16i8_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v16i8_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v16i8_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.experimental.vp.strided.load.v16i8.i64(ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_strided.load_v16i8_PALL(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v16i8_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v16i8_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v16i8_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v16i8_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.experimental.vp.strided.load.v16i8.i64(ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_strided.load_v16i8_S1(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v16i8_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v16i8_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v16i8_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v16i8_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.experimental.vp.strided.load.v16i8.i64(ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <16 x i8> %x
}


define <16 x i8> @test_nontemporal_vp_strided.load_v16i8_ALL(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v16i8_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v16i8_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v16i8_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v16i8_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.experimental.vp.strided.load.v16i8.i64(ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <16 x i8> %x
}

define <16 x i8> @test_nontemporal_vp_strided.load_v16i8_DEFAULT(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v16i8_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v16i8_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v16i8_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v16i8_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vlse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <16 x i8> @llvm.experimental.vp.strided.load.v16i8.i64(ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <16 x i8> %x
}


define void @test_nontemporal_vp_strided.store_v16i8_P1(<16 x i8> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v16i8_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v16i8_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v16i8_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v16i8_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v16i8.i64(<16 x i8> %val, ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_strided.store_v16i8_PALL(<16 x i8> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v16i8_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v16i8_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v16i8_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v16i8_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v16i8.i64(<16 x i8> %val, ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_strided.store_v16i8_S1(<16 x i8> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v16i8_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v16i8_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v16i8_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v16i8_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v16i8.i64(<16 x i8> %val, ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_strided.store_v16i8_ALL(<16 x i8> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v16i8_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v16i8_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v16i8_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v16i8_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v16i8.i64(<16 x i8> %val, ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_strided.store_v16i8_DEFAULT(<16 x i8> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v16i8_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v16i8_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v16i8_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e8, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v16i8_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e8, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsse8.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v16i8.i64(<16 x i8> %val, ptr %p, i64 %stride, <16 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <8 x i16> @test_nontemporal_vp_load_v8i16_P1(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v8i16_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vle16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v8i16_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vle16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v8i16_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v8i16_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.load.v8i16.p0(ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_load_v8i16_PALL(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v8i16_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vle16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v8i16_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vle16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v8i16_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v8i16_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.load.v8i16.p0(ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_load_v8i16_S1(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v8i16_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vle16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v8i16_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vle16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v8i16_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v8i16_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.load.v8i16.p0(ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_load_v8i16_ALL(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v8i16_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vle16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v8i16_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vle16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v8i16_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v8i16_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.load.v8i16.p0(ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <8 x i16> %x
}

define <8 x i16> @test_nontemporal_vp_load_v8i16_DEFAULT(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v8i16_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vle16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v8i16_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vle16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v8i16_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v8i16_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vle16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.load.v8i16.p0(ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <8 x i16> %x
}


define void @test_nontemporal_vp_store_v8i16_P1(<8 x i16> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v8i16_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vse16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v8i16_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vse16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v8i16_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v8i16_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v8i16.p0(<8 x i16> %val, ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_store_v8i16_PALL(<8 x i16> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v8i16_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vse16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v8i16_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vse16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v8i16_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v8i16_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v8i16.p0(<8 x i16> %val, ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_store_v8i16_S1(<8 x i16> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v8i16_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vse16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v8i16_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vse16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v8i16_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v8i16_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v8i16.p0(<8 x i16> %val, ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_store_v8i16_ALL(<8 x i16> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v8i16_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vse16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v8i16_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vse16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v8i16_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v8i16_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v8i16.p0(<8 x i16> %val, ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_store_v8i16_DEFAULT(<8 x i16> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v8i16_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vse16.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v8i16_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vse16.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v8i16_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v8i16_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vse16.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v8i16.p0(<8 x i16> %val, ptr %p, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <8 x i16> @test_nontemporal_vp_gather_v8i16_P1(<8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v8i16_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v8i16_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v8i16_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v8i16_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.gather.v8i16.v8p0(<8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_gather_v8i16_PALL(<8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v8i16_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v8i16_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v8i16_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v8i16_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.gather.v8i16.v8p0(<8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_gather_v8i16_S1(<8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v8i16_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v8i16_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v8i16_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v8i16_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.gather.v8i16.v8p0(<8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_gather_v8i16_ALL(<8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v8i16_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v8i16_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v8i16_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v8i16_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.gather.v8i16.v8p0(<8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <8 x i16> %x
}

define <8 x i16> @test_nontemporal_vp_gather_v8i16_DEFAULT(<8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v8i16_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v8i16_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v8i16_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vluxei64.v v12, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v8i16_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vluxei32.v v10, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.vp.gather.v8i16.v8p0(<8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <8 x i16> %x
}


define void @test_nontemporal_vp_scatter_v8i16_P1(<8 x i16> %val, <8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v8i16_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v8i16_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v8i16_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v8i16_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v8i16.v8p0(<8 x i16> %val, <8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_scatter_v8i16_PALL(<8 x i16> %val, <8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v8i16_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v8i16_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v8i16_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v8i16_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v8i16.v8p0(<8 x i16> %val, <8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_scatter_v8i16_S1(<8 x i16> %val, <8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v8i16_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v8i16_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v8i16_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v8i16_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v8i16.v8p0(<8 x i16> %val, <8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_scatter_v8i16_ALL(<8 x i16> %val, <8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v8i16_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v8i16_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v8i16_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v8i16_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v8i16.v8p0(<8 x i16> %val, <8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_scatter_v8i16_DEFAULT(<8 x i16> %val, <8 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v8i16_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v8i16_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v8i16_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v12
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v8i16_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v10
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v8i16.v8p0(<8 x i16> %val, <8 x ptr> %ptrs, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <8 x i16> @test_nontemporal_vp_strided.load_v8i16_P1(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v8i16_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v8i16_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v8i16_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v8i16_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.experimental.vp.strided.load.v8i16.i64(ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_strided.load_v8i16_PALL(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v8i16_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v8i16_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v8i16_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v8i16_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.experimental.vp.strided.load.v8i16.i64(ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_strided.load_v8i16_S1(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v8i16_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v8i16_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v8i16_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v8i16_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.experimental.vp.strided.load.v8i16.i64(ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <8 x i16> %x
}


define <8 x i16> @test_nontemporal_vp_strided.load_v8i16_ALL(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v8i16_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v8i16_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v8i16_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v8i16_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.experimental.vp.strided.load.v8i16.i64(ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <8 x i16> %x
}

define <8 x i16> @test_nontemporal_vp_strided.load_v8i16_DEFAULT(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v8i16_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v8i16_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v8i16_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v8i16_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vlse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <8 x i16> @llvm.experimental.vp.strided.load.v8i16.i64(ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <8 x i16> %x
}


define void @test_nontemporal_vp_strided.store_v8i16_P1(<8 x i16> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v8i16_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v8i16_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v8i16_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v8i16_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v8i16.i64(<8 x i16> %val, ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_strided.store_v8i16_PALL(<8 x i16> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v8i16_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v8i16_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v8i16_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v8i16_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v8i16.i64(<8 x i16> %val, ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_strided.store_v8i16_S1(<8 x i16> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v8i16_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v8i16_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v8i16_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v8i16_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v8i16.i64(<8 x i16> %val, ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_strided.store_v8i16_ALL(<8 x i16> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v8i16_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v8i16_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v8i16_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v8i16_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v8i16.i64(<8 x i16> %val, ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_strided.store_v8i16_DEFAULT(<8 x i16> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v8i16_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v8i16_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v8i16_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e16, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v8i16_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e16, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsse16.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v8i16.i64(<8 x i16> %val, ptr %p, i64 %stride, <8 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <4 x i32> @test_nontemporal_vp_load_v4i32_P1(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v4i32_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vle32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v4i32_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vle32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v4i32_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v4i32_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.load.v4i32.p0(ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_load_v4i32_PALL(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v4i32_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vle32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v4i32_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vle32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v4i32_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v4i32_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.load.v4i32.p0(ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_load_v4i32_S1(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v4i32_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vle32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v4i32_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vle32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v4i32_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v4i32_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.load.v4i32.p0(ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_load_v4i32_ALL(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v4i32_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vle32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v4i32_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vle32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v4i32_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v4i32_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.load.v4i32.p0(ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <4 x i32> %x
}

define <4 x i32> @test_nontemporal_vp_load_v4i32_DEFAULT(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v4i32_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vle32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v4i32_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vle32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v4i32_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v4i32_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vle32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.load.v4i32.p0(ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <4 x i32> %x
}


define void @test_nontemporal_vp_store_v4i32_P1(<4 x i32> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v4i32_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vse32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v4i32_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vse32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v4i32_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v4i32_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v4i32.p0(<4 x i32> %val, ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_store_v4i32_PALL(<4 x i32> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v4i32_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vse32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v4i32_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vse32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v4i32_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v4i32_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v4i32.p0(<4 x i32> %val, ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_store_v4i32_S1(<4 x i32> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v4i32_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vse32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v4i32_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vse32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v4i32_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v4i32_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v4i32.p0(<4 x i32> %val, ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_store_v4i32_ALL(<4 x i32> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v4i32_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vse32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v4i32_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vse32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v4i32_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v4i32_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v4i32.p0(<4 x i32> %val, ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_store_v4i32_DEFAULT(<4 x i32> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v4i32_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vse32.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v4i32_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vse32.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v4i32_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v4i32_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vse32.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v4i32.p0(<4 x i32> %val, ptr %p, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <4 x i32> @test_nontemporal_vp_gather_v4i32_P1(<4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v4i32_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v4i32_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v4i32_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v4i32_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.gather.v4i32.v4p0(<4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_gather_v4i32_PALL(<4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v4i32_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v4i32_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v4i32_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v4i32_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.gather.v4i32.v4p0(<4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_gather_v4i32_S1(<4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v4i32_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v4i32_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v4i32_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v4i32_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.gather.v4i32.v4p0(<4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_gather_v4i32_ALL(<4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v4i32_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v4i32_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v4i32_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v4i32_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.gather.v4i32.v4p0(<4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <4 x i32> %x
}

define <4 x i32> @test_nontemporal_vp_gather_v4i32_DEFAULT(<4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v4i32_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64V-NEXT:    vmv.v.v v8, v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v4i32_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v4i32_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vluxei64.v v10, (zero), v8
; CHECK-RV64VC-NEXT:    vmv.v.v v8, v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v4i32_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vluxei32.v v8, (zero), v8
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.vp.gather.v4i32.v4p0(<4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <4 x i32> %x
}


define void @test_nontemporal_vp_scatter_v4i32_P1(<4 x i32> %val, <4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v4i32_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v4i32_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v4i32_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v4i32_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v4i32.v4p0(<4 x i32> %val, <4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_scatter_v4i32_PALL(<4 x i32> %val, <4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v4i32_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v4i32_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v4i32_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v4i32_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v4i32.v4p0(<4 x i32> %val, <4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_scatter_v4i32_S1(<4 x i32> %val, <4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v4i32_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v4i32_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v4i32_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v4i32_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v4i32.v4p0(<4 x i32> %val, <4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_scatter_v4i32_ALL(<4 x i32> %val, <4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v4i32_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v4i32_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v4i32_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v4i32_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v4i32.v4p0(<4 x i32> %val, <4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_scatter_v4i32_DEFAULT(<4 x i32> %val, <4 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v4i32_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v4i32_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v4i32_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v10
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v4i32_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v4i32.v4p0(<4 x i32> %val, <4 x ptr> %ptrs, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <4 x i32> @test_nontemporal_vp_strided.load_v4i32_P1(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v4i32_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v4i32_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v4i32_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v4i32_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.experimental.vp.strided.load.v4i32.i64(ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_strided.load_v4i32_PALL(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v4i32_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v4i32_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v4i32_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v4i32_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.experimental.vp.strided.load.v4i32.i64(ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_strided.load_v4i32_S1(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v4i32_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v4i32_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v4i32_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v4i32_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.experimental.vp.strided.load.v4i32.i64(ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <4 x i32> %x
}


define <4 x i32> @test_nontemporal_vp_strided.load_v4i32_ALL(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v4i32_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v4i32_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v4i32_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v4i32_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.experimental.vp.strided.load.v4i32.i64(ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <4 x i32> %x
}

define <4 x i32> @test_nontemporal_vp_strided.load_v4i32_DEFAULT(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v4i32_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v4i32_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v4i32_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v4i32_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vlse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <4 x i32> @llvm.experimental.vp.strided.load.v4i32.i64(ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <4 x i32> %x
}


define void @test_nontemporal_vp_strided.store_v4i32_P1(<4 x i32> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v4i32_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v4i32_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v4i32_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v4i32_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v4i32.i64(<4 x i32> %val, ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_strided.store_v4i32_PALL(<4 x i32> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v4i32_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v4i32_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v4i32_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v4i32_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v4i32.i64(<4 x i32> %val, ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_strided.store_v4i32_S1(<4 x i32> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v4i32_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v4i32_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v4i32_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v4i32_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v4i32.i64(<4 x i32> %val, ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_strided.store_v4i32_ALL(<4 x i32> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v4i32_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v4i32_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v4i32_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v4i32_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v4i32.i64(<4 x i32> %val, ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_strided.store_v4i32_DEFAULT(<4 x i32> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v4i32_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v4i32_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v4i32_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e32, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v4i32_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e32, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsse32.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v4i32.i64(<4 x i32> %val, ptr %p, i64 %stride, <4 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <2 x i64> @test_nontemporal_vp_load_v2i64_P1(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v2i64_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vle64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v2i64_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vle64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v2i64_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v2i64_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.load.v2i64.p0(ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_load_v2i64_PALL(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v2i64_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vle64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v2i64_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vle64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v2i64_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v2i64_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.load.v2i64.p0(ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_load_v2i64_S1(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v2i64_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vle64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v2i64_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vle64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v2i64_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v2i64_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.load.v2i64.p0(ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_load_v2i64_ALL(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v2i64_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vle64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v2i64_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vle64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v2i64_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v2i64_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.load.v2i64.p0(ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <2 x i64> %x
}

define <2 x i64> @test_nontemporal_vp_load_v2i64_DEFAULT(ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_load_v2i64_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vle64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_load_v2i64_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vle64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_load_v2i64_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_load_v2i64_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vle64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.load.v2i64.p0(ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <2 x i64> %x
}


define void @test_nontemporal_vp_store_v2i64_P1(<2 x i64> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v2i64_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vse64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v2i64_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vse64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v2i64_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v2i64_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v2i64.p0(<2 x i64> %val, ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_store_v2i64_PALL(<2 x i64> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v2i64_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vse64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v2i64_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vse64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v2i64_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v2i64_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v2i64.p0(<2 x i64> %val, ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_store_v2i64_S1(<2 x i64> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v2i64_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vse64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v2i64_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vse64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v2i64_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v2i64_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v2i64.p0(<2 x i64> %val, ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_store_v2i64_ALL(<2 x i64> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v2i64_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vse64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v2i64_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vse64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v2i64_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v2i64_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v2i64.p0(<2 x i64> %val, ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_store_v2i64_DEFAULT(<2 x i64> %val, ptr %p, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_store_v2i64_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vse64.v v8, (a0)
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_store_v2i64_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vse64.v v8, (a0)
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_store_v2i64_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_store_v2i64_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vse64.v v8, (a0)
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.store.v2i64.p0(<2 x i64> %val, ptr %p, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <2 x i64> @test_nontemporal_vp_gather_v2i64_P1(<2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v2i64_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v2i64_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v2i64_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v2i64_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v9
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.gather.v2i64.v2p0(<2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_gather_v2i64_PALL(<2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v2i64_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v2i64_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v2i64_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v2i64_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v9
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.gather.v2i64.v2p0(<2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_gather_v2i64_S1(<2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v2i64_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v2i64_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v2i64_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v2i64_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v9
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.gather.v2i64.v2p0(<2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_gather_v2i64_ALL(<2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v2i64_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v2i64_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v2i64_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v2i64_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v9
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.gather.v2i64.v2p0(<2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <2 x i64> %x
}

define <2 x i64> @test_nontemporal_vp_gather_v2i64_DEFAULT(<2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_gather_v2i64_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_gather_v2i64_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32V-NEXT:    vmv.v.v v8, v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_gather_v2i64_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vluxei64.v v8, (zero), v8
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_gather_v2i64_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vluxei32.v v9, (zero), v8
; CHECK-RV32VC-NEXT:    vmv.v.v v8, v9
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.vp.gather.v2i64.v2p0(<2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <2 x i64> %x
}


define void @test_nontemporal_vp_scatter_v2i64_P1(<2 x i64> %val, <2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v2i64_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v2i64_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v2i64_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v2i64_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v2i64.v2p0(<2 x i64> %val, <2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_scatter_v2i64_PALL(<2 x i64> %val, <2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v2i64_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v2i64_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v2i64_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v2i64_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v2i64.v2p0(<2 x i64> %val, <2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_scatter_v2i64_S1(<2 x i64> %val, <2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v2i64_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v2i64_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v2i64_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v2i64_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v2i64.v2p0(<2 x i64> %val, <2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_scatter_v2i64_ALL(<2 x i64> %val, <2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v2i64_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v2i64_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v2i64_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v2i64_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v2i64.v2p0(<2 x i64> %val, <2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_scatter_v2i64_DEFAULT(<2 x i64> %val, <2 x ptr> %ptrs, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_scatter_v2i64_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_scatter_v2i64_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_scatter_v2i64_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsoxei64.v v8, (zero), v9
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_scatter_v2i64_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsoxei32.v v8, (zero), v9
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.vp.scatter.v2i64.v2p0(<2 x i64> %val, <2 x ptr> %ptrs, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


define <2 x i64> @test_nontemporal_vp_strided.load_v2i64_P1(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v2i64_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v2i64_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v2i64_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v2i64_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.experimental.vp.strided.load.v2i64.i64(ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_strided.load_v2i64_PALL(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v2i64_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v2i64_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v2i64_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v2i64_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.experimental.vp.strided.load.v2i64.i64(ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_strided.load_v2i64_S1(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v2i64_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v2i64_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v2i64_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v2i64_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.experimental.vp.strided.load.v2i64.i64(ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret <2 x i64> %x
}


define <2 x i64> @test_nontemporal_vp_strided.load_v2i64_ALL(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v2i64_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v2i64_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v2i64_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v2i64_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.experimental.vp.strided.load.v2i64.i64(ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret <2 x i64> %x
}

define <2 x i64> @test_nontemporal_vp_strided.load_v2i64_DEFAULT(ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.load_v2i64_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.load_v2i64_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.load_v2i64_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.load_v2i64_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vlse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  %x = call <2 x i64> @llvm.experimental.vp.strided.load.v2i64.i64(ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret <2 x i64> %x
}


define void @test_nontemporal_vp_strided.store_v2i64_P1(<2 x i64> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v2i64_P1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.p1
; CHECK-RV64V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v2i64_P1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.p1
; CHECK-RV32V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v2i64_P1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.p1
; CHECK-RV64VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v2i64_P1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.p1
; CHECK-RV32VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v2i64.i64(<2 x i64> %val, ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !1
  ret void
}


define void @test_nontemporal_vp_strided.store_v2i64_PALL(<2 x i64> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v2i64_PALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.pall
; CHECK-RV64V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v2i64_PALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.pall
; CHECK-RV32V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v2i64_PALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.pall
; CHECK-RV64VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v2i64_PALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.pall
; CHECK-RV32VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v2i64.i64(<2 x i64> %val, ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !2
  ret void
}


define void @test_nontemporal_vp_strided.store_v2i64_S1(<2 x i64> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v2i64_S1:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.s1
; CHECK-RV64V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v2i64_S1:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.s1
; CHECK-RV32V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v2i64_S1:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.s1
; CHECK-RV64VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v2i64_S1:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.s1
; CHECK-RV32VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v2i64.i64(<2 x i64> %val, ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !3
  ret void
}


define void @test_nontemporal_vp_strided.store_v2i64_ALL(<2 x i64> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v2i64_ALL:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v2i64_ALL:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v2i64_ALL:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v2i64_ALL:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v2i64.i64(<2 x i64> %val, ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0, !riscv-nontemporal-domain !4
  ret void
}

define void @test_nontemporal_vp_strided.store_v2i64_DEFAULT(<2 x i64> %val, ptr %p, i64 %stride, i32 zeroext %vl) {
; CHECK-RV64V-LABEL: test_nontemporal_vp_strided.store_v2i64_DEFAULT:
; CHECK-RV64V:       # %bb.0:
; CHECK-RV64V-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64V-NEXT:    ntl.all
; CHECK-RV64V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64V-NEXT:    ret
;
; CHECK-RV32V-LABEL: test_nontemporal_vp_strided.store_v2i64_DEFAULT:
; CHECK-RV32V:       # %bb.0:
; CHECK-RV32V-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32V-NEXT:    ntl.all
; CHECK-RV32V-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32V-NEXT:    ret
;
; CHECK-RV64VC-LABEL: test_nontemporal_vp_strided.store_v2i64_DEFAULT:
; CHECK-RV64VC:       # %bb.0:
; CHECK-RV64VC-NEXT:    vsetvli zero, a2, e64, m1, ta, ma
; CHECK-RV64VC-NEXT:    c.ntl.all
; CHECK-RV64VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV64VC-NEXT:    ret
;
; CHECK-RV32VC-LABEL: test_nontemporal_vp_strided.store_v2i64_DEFAULT:
; CHECK-RV32VC:       # %bb.0:
; CHECK-RV32VC-NEXT:    vsetvli zero, a3, e64, m1, ta, ma
; CHECK-RV32VC-NEXT:    c.ntl.all
; CHECK-RV32VC-NEXT:    vsse64.v v8, (a0), a1
; CHECK-RV32VC-NEXT:    ret
  call void @llvm.experimental.vp.strided.store.v2i64.i64(<2 x i64> %val, ptr %p, i64 %stride, <2 x i1> splat(i1 true), i32 %vl), !nontemporal !0
  ret void
}


!0 = !{i32 1}
!1 = !{i32 2}
!2 = !{i32 3}
!3 = !{i32 4}
!4 = !{i32 5}

