; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=riscv64 -mattr=+v -verify-machineinstrs | FileCheck %s

declare <vscale x 8 x i8> @llvm.vp.udiv.nxv8i8(<vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i1>, i32)
declare <vscale x 4 x i16> @llvm.vp.udiv.nxv4i16(<vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i1>, i32)
declare <vscale x 2 x i32> @llvm.vp.udiv.nxv2i32(<vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i1>, i32)
declare <vscale x 1 x i64> @llvm.vp.udiv.nxv1i64(<vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i1>, i32)
declare <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i1>, i32)
declare <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i1>, i32)
declare <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i1>, i32)
declare <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i1>, i32)
declare <vscale x 8 x i8> @llvm.vp.urem.nxv8i8(<vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i1>, i32)
declare <vscale x 4 x i16> @llvm.vp.urem.nxv4i16(<vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i1>, i32)
declare <vscale x 2 x i32> @llvm.vp.urem.nxv2i32(<vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i1>, i32)
declare <vscale x 1 x i64> @llvm.vp.urem.nxv1i64(<vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i1>, i32)
declare <vscale x 8 x i8> @llvm.vp.srem.nxv8i8(<vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i1>, i32)
declare <vscale x 4 x i16> @llvm.vp.srem.nxv4i16(<vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i1>, i32)
declare <vscale x 2 x i32> @llvm.vp.srem.nxv2i32(<vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i1>, i32)
declare <vscale x 1 x i64> @llvm.vp.srem.nxv1i64(<vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i1>, i32)
declare <vscale x 8 x i8> @llvm.vp.shl.nxv8i8(<vscale x 8 x i8>, <vscale x 8 x i8>, <vscale x 8 x i1>, i32)
declare <vscale x 4 x i16> @llvm.vp.shl.nxv4i16(<vscale x 4 x i16>, <vscale x 4 x i16>, <vscale x 4 x i1>, i32)
declare <vscale x 2 x i32> @llvm.vp.shl.nxv2i32(<vscale x 2 x i32>, <vscale x 2 x i32>, <vscale x 2 x i1>, i32)
declare <vscale x 1 x i64> @llvm.vp.shl.nxv1i64(<vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i1>, i32)


define <vscale x 8 x i8> @vpudiv_by_max_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_max_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v0, v8, -1, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmerge.vim v8, v8, 1, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 255, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.udiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpudiv_by_max_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_max_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v0, v8, -1, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmerge.vim v8, v8, 1, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 65535, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.udiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpudiv_by_max_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_max_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v0, v8, -1, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmerge.vim v8, v8, 1, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 4294967295, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.udiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpudiv_by_max_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_max_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v0, v8, -1, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmerge.vim v8, v8, 1, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 18446744073709551615, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.udiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @fold_vpudiv_vpurem_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: fold_vpudiv_vpurem_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vsrl.vi v9, v8, 7, v0.t
; CHECK-NEXT:    li a0, -128
; CHECK-NEXT:    vmul.vx v10, v9, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    vsetvli a0, zero, e8, m1, ta, ma
; CHECK-NEXT:    vadd.vv v8, v9, v8
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 128, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.udiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  %u = call <vscale x 8 x i8> @llvm.vp.urem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  %x = add <vscale x 8 x i8> %v, %u
  ret <vscale x 8 x i8> %x
}

define <vscale x 4 x i16> @fold_vpudiv_vpurem_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: fold_vpudiv_vpurem_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vsrl.vi v9, v8, 14, v0.t
; CHECK-NEXT:    lui a0, 4
; CHECK-NEXT:    vmul.vx v10, v9, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    vsetvli a0, zero, e16, m1, ta, ma
; CHECK-NEXT:    vadd.vv v8, v9, v8
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 16384, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.udiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  %u = call <vscale x 4 x i16> @llvm.vp.urem.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  %x = add <vscale x 4 x i16> %v, %u
  ret <vscale x 4 x i16> %x
}

define <vscale x 2 x i32> @fold_vpudiv_vpurem_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: fold_vpudiv_vpurem_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vsrl.vi v9, v8, 14, v0.t
; CHECK-NEXT:    lui a0, 4
; CHECK-NEXT:    vmul.vx v10, v9, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; CHECK-NEXT:    vadd.vv v8, v9, v8
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 16384, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.udiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  %u = call <vscale x 2 x i32> @llvm.vp.urem.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  %x = add <vscale x 2 x i32> %v, %u
  ret <vscale x 2 x i32> %x
}

define <vscale x 1 x i64> @fold_vpudiv_vpurem_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: fold_vpudiv_vpurem_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vsrl.vi v9, v8, 14, v0.t
; CHECK-NEXT:    lui a0, 4
; CHECK-NEXT:    vmul.vx v10, v9, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    vsetvli a0, zero, e64, m1, ta, ma
; CHECK-NEXT:    vadd.vv v8, v9, v8
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 16384, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.udiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  %u = call <vscale x 1 x i64> @llvm.vp.urem.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  %x = add <vscale x 1 x i64> %v, %u
  ret <vscale x 1 x i64> %x
}

define <vscale x 8 x i8> @vpudiv_by_shl2_nxv8i8(<vscale x 8 x i8> %va, i8 %b, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_shl2_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    andi a0, a0, 255
; CHECK-NEXT:    addi a0, a0, 1
; CHECK-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-NEXT:    vsrl.vx v8, v8, a0, v0.t
; CHECK-NEXT:    ret
  %sh = shl i8 2, %b
  %vec = insertelement <vscale x 8 x i8> undef, i8 %sh, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.udiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpudiv_by_shl2_nxv4i16(<vscale x 4 x i16> %va, i16 %b, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_shl2_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    slli a0, a0, 48
; CHECK-NEXT:    srli a0, a0, 48
; CHECK-NEXT:    addi a0, a0, 1
; CHECK-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-NEXT:    vsrl.vx v8, v8, a0, v0.t
; CHECK-NEXT:    ret
  %sh = shl i16 2, %b
  %vec = insertelement <vscale x 4 x i16> undef, i16 %sh, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.udiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpudiv_by_shl2_nxv2i32(<vscale x 2 x i32> %va, i32 %b, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_shl2_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    slli a0, a0, 32
; CHECK-NEXT:    srli a0, a0, 32
; CHECK-NEXT:    addi a0, a0, 1
; CHECK-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-NEXT:    vsrl.vx v8, v8, a0, v0.t
; CHECK-NEXT:    ret
  %sh = shl i32 2, %b
  %vec = insertelement <vscale x 2 x i32> undef, i32 %sh, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.udiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpudiv_by_shl2_nxv1i64(<vscale x 1 x i64> %va, i64 %b, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_shl2_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addi a0, a0, 1
; CHECK-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-NEXT:    vsrl.vx v8, v8, a0, v0.t
; CHECK-NEXT:    ret
  %sh = shl i64 2, %b
  %vec = insertelement <vscale x 1 x i64> undef, i64 %sh, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.udiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpudiv_by_vpshl2_nxv8i8(<vscale x 8 x i8> %va, i8 %b, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_vpshl2_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a2, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.x v9, a0
; CHECK-NEXT:    vsetvli zero, a1, e8, m1, ta, ma
; CHECK-NEXT:    vadd.vi v9, v9, 2, v0.t
; CHECK-NEXT:    vsrl.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec1 = insertelement <vscale x 8 x i8> undef, i8 4, i32 0
  %splat1 = shufflevector <vscale x 8 x i8> %vec1, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %vec2 = insertelement <vscale x 8 x i8> undef, i8 %b, i32 0
  %splat2 = shufflevector <vscale x 8 x i8> %vec2, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %sh = call <vscale x 8 x i8> @llvm.vp.shl.nxv8i8(<vscale x 8 x i8> %splat1, <vscale x 8 x i8> %splat2, <vscale x 8 x i1> %m, i32 %evl)
  %v = call <vscale x 8 x i8> @llvm.vp.udiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %sh, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpudiv_by_vpshl2_nxv4i16(<vscale x 4 x i16> %va, i16 %b, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_vpshl2_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a2, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.x v9, a0
; CHECK-NEXT:    vsetvli zero, a1, e16, m1, ta, ma
; CHECK-NEXT:    vadd.vi v9, v9, 2, v0.t
; CHECK-NEXT:    vsrl.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec1 = insertelement <vscale x 4 x i16> undef, i16 4, i32 0
  %splat1 = shufflevector <vscale x 4 x i16> %vec1, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %vec2 = insertelement <vscale x 4 x i16> undef, i16 %b, i32 0
  %splat2 = shufflevector <vscale x 4 x i16> %vec2, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %sh = call <vscale x 4 x i16> @llvm.vp.shl.nxv4i16(<vscale x 4 x i16> %splat1, <vscale x 4 x i16> %splat2, <vscale x 4 x i1> %m, i32 %evl)
  %v = call <vscale x 4 x i16> @llvm.vp.udiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %sh, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpudiv_by_vpshl2_nxv2i32(<vscale x 2 x i32> %va, i32 %b, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_vpshl2_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a2, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.x v9, a0
; CHECK-NEXT:    vsetvli zero, a1, e32, m1, ta, ma
; CHECK-NEXT:    vadd.vi v9, v9, 2, v0.t
; CHECK-NEXT:    vsrl.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec1 = insertelement <vscale x 2 x i32> undef, i32 4, i32 0
  %splat1 = shufflevector <vscale x 2 x i32> %vec1, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %vec2 = insertelement <vscale x 2 x i32> undef, i32 %b, i32 0
  %splat2 = shufflevector <vscale x 2 x i32> %vec2, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %sh = call <vscale x 2 x i32> @llvm.vp.shl.nxv2i32(<vscale x 2 x i32> %splat1, <vscale x 2 x i32> %splat2, <vscale x 2 x i1> %m, i32 %evl)
  %v = call <vscale x 2 x i32> @llvm.vp.udiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %sh, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpudiv_by_vpshl2_nxv1i64(<vscale x 1 x i64> %va, i64 %b, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_vpshl2_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a2, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.x v9, a0
; CHECK-NEXT:    vsetvli zero, a1, e64, m1, ta, ma
; CHECK-NEXT:    vadd.vi v9, v9, 2, v0.t
; CHECK-NEXT:    vsrl.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec1 = insertelement <vscale x 1 x i64> undef, i64 4, i32 0
  %splat1 = shufflevector <vscale x 1 x i64> %vec1, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %vec2 = insertelement <vscale x 1 x i64> undef, i64 %b, i32 0
  %splat2 = shufflevector <vscale x 1 x i64> %vec2, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %sh = call <vscale x 1 x i64> @llvm.vp.shl.nxv1i64(<vscale x 1 x i64> %splat1, <vscale x 1 x i64> %splat2, <vscale x 1 x i1> %m, i32 %evl)
  %v = call <vscale x 1 x i64> @llvm.vp.udiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %sh, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpudiv_by_const_no_add_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_const_no_add_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a1, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v9, 5
; CHECK-NEXT:    li a1, -51
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vsrl.vi v10, v10, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v9, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v10, v8, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 5, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.udiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpudiv_by_const_no_add_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_const_no_add_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a1, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v9, 5
; CHECK-NEXT:    lui a1, 1048573
; CHECK-NEXT:    addiw a1, a1, -819
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vsrl.vi v10, v10, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v9, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v10, v8, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 5, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.udiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpudiv_by_const_no_add_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_const_no_add_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a1, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v9, 5
; CHECK-NEXT:    lui a1, 838861
; CHECK-NEXT:    addiw a1, a1, -819
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vsrl.vi v10, v10, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v9, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v10, v8, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 5, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.udiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpudiv_by_const_no_add_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_const_no_add_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, %hi(.LCPI19_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI19_0)(a1)
; CHECK-NEXT:    vsetvli a2, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v9, 5
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vsrl.vi v10, v10, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v9, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v10, v8, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 5, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.udiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpudiv_by_const_with_add_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_const_with_add_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a1, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v9, 7
; CHECK-NEXT:    li a1, 37
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vsub.vv v11, v8, v10, v0.t
; CHECK-NEXT:    li a0, -128
; CHECK-NEXT:    vmulhu.vx v11, v11, a0, v0.t
; CHECK-NEXT:    vadd.vv v10, v11, v10, v0.t
; CHECK-NEXT:    vsrl.vi v10, v10, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v9, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v10, v8, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 7, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.udiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpudiv_by_const_with_add_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_const_with_add_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a1, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v9, 7
; CHECK-NEXT:    lui a1, 2
; CHECK-NEXT:    addiw a1, a1, 1171
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vsub.vv v11, v8, v10, v0.t
; CHECK-NEXT:    lui a0, 1048568
; CHECK-NEXT:    vmulhu.vx v11, v11, a0, v0.t
; CHECK-NEXT:    vadd.vv v10, v11, v10, v0.t
; CHECK-NEXT:    vsrl.vi v10, v10, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v9, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v10, v8, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 7, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.udiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpudiv_by_const_with_add_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_const_with_add_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a1, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v9, 7
; CHECK-NEXT:    lui a1, 149797
; CHECK-NEXT:    addiw a1, a1, -1755
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vsub.vv v11, v8, v10, v0.t
; CHECK-NEXT:    lui a0, 524288
; CHECK-NEXT:    vmulhu.vx v11, v11, a0, v0.t
; CHECK-NEXT:    vadd.vv v10, v11, v10, v0.t
; CHECK-NEXT:    vsrl.vi v10, v10, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v9, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v10, v8, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 7, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.udiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpudiv_by_const_with_add_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_const_with_add_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, %hi(.LCPI23_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI23_0)(a1)
; CHECK-NEXT:    vsetvli a2, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v9, 7
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vsub.vv v11, v8, v10, v0.t
; CHECK-NEXT:    li a0, -1
; CHECK-NEXT:    slli a0, a0, 63
; CHECK-NEXT:    vmulhu.vx v11, v11, a0, v0.t
; CHECK-NEXT:    vadd.vv v10, v11, v10, v0.t
; CHECK-NEXT:    vsrl.vi v10, v10, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v9, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v10, v8, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 7, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.udiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsdiv_by_neg1_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_neg1_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vrsub.vi v8, v8, 0, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 -1, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 1 x i64> @vpsdiv_by_neg1_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_neg1_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vrsub.vi v8, v8, 0, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 -1, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 4 x i16> @vpsdiv_by_neg1_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_neg1_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vrsub.vi v8, v8, 0, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 -1, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsdiv_by_neg1_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_neg1_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vrsub.vi v8, v8, 0, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 -1, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 8 x i8> @vpsdiv_by_min_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_min_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, -128
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmseq.vx v0, v8, a1, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmerge.vim v8, v8, 1, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 -128, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 1 x i64> @vpsdiv_by_min_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_min_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, -1
; CHECK-NEXT:    slli a1, a1, 63
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmseq.vx v0, v8, a1, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmerge.vim v8, v8, 1, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 -9223372036854775808, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 4 x i16> @vpsdiv_by_min_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_min_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, 1048568
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmseq.vx v0, v8, a1, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmerge.vim v8, v8, 1, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 -32768, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsdiv_by_min_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_min_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, 524288
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmseq.vx v0, v8, a1, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmerge.vim v8, v8, 1, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 -2147483648, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 4 x i16> @vpsdiv_pow2_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_pow2_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmv1r.v v9, v0
; CHECK-NEXT:    vsetvli a1, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v10, 4
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v11, v10, -1, v0.t
; CHECK-NEXT:    vmseq.vi v10, v10, 1, v0.t
; CHECK-NEXT:    vmor.mm v10, v10, v11
; CHECK-NEXT:    vsra.vi v11, v8, 15, v0.t
; CHECK-NEXT:    vsrl.vi v11, v11, 14, v0.t
; CHECK-NEXT:    vadd.vv v11, v8, v11, v0.t
; CHECK-NEXT:    vsra.vi v11, v11, 2, v0.t
; CHECK-NEXT:    vmv.v.v v0, v10
; CHECK-NEXT:    vmerge.vvm v8, v11, v8, v0
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vrsub.vi v10, v8, 0, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v11, 0
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vmsgt.vi v0, v11, 4, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v8, v10, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 4, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 8 x i8> @vpsdiv_pow2_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_pow2_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmv1r.v v9, v0
; CHECK-NEXT:    vsetvli a1, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v10, 4
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v11, v10, -1, v0.t
; CHECK-NEXT:    vmseq.vi v10, v10, 1, v0.t
; CHECK-NEXT:    vmor.mm v10, v10, v11
; CHECK-NEXT:    vsra.vi v11, v8, 7, v0.t
; CHECK-NEXT:    vsrl.vi v11, v11, 6, v0.t
; CHECK-NEXT:    vadd.vv v11, v8, v11, v0.t
; CHECK-NEXT:    vsra.vi v11, v11, 2, v0.t
; CHECK-NEXT:    vmv.v.v v0, v10
; CHECK-NEXT:    vmerge.vvm v8, v11, v8, v0
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vrsub.vi v10, v8, 0, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v11, 0
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vmsgt.vi v0, v11, 4, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v8, v10, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 4, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 2 x i32> @vpsdiv_pow2_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_pow2_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmv1r.v v9, v0
; CHECK-NEXT:    vsetvli a1, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v10, 4
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v11, v10, -1, v0.t
; CHECK-NEXT:    vmseq.vi v10, v10, 1, v0.t
; CHECK-NEXT:    vmor.mm v10, v10, v11
; CHECK-NEXT:    vsra.vi v11, v8, 31, v0.t
; CHECK-NEXT:    vsrl.vi v11, v11, 30, v0.t
; CHECK-NEXT:    vadd.vv v11, v8, v11, v0.t
; CHECK-NEXT:    vsra.vi v11, v11, 2, v0.t
; CHECK-NEXT:    vmv.v.v v0, v10
; CHECK-NEXT:    vmerge.vvm v8, v11, v8, v0
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vrsub.vi v10, v8, 0, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v11, 0
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vmsgt.vi v0, v11, 4, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v8, v10, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 4, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsdiv_pow2_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_pow2_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmv1r.v v9, v0
; CHECK-NEXT:    vsetvli a1, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v10, 4
; CHECK-NEXT:    li a1, 63
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vsra.vx v11, v8, a1, v0.t
; CHECK-NEXT:    li a1, 62
; CHECK-NEXT:    vsrl.vx v11, v11, a1, v0.t
; CHECK-NEXT:    vadd.vv v11, v8, v11, v0.t
; CHECK-NEXT:    vsra.vi v11, v11, 2, v0.t
; CHECK-NEXT:    vmseq.vi v12, v10, -1, v0.t
; CHECK-NEXT:    vmseq.vi v10, v10, 1, v0.t
; CHECK-NEXT:    vmor.mm v0, v10, v12
; CHECK-NEXT:    vmerge.vvm v8, v11, v8, v0
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vrsub.vi v10, v8, 0, v0.t
; CHECK-NEXT:    vsetvli a1, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v11, 0
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmsgt.vi v0, v11, 4, v0.t
; CHECK-NEXT:    vmerge.vvm v8, v8, v10, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 4, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsdiv_const_no_ashr_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_no_ashr_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    li a0, 86
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 0, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 7, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 3, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpsdiv_const_no_ashr_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_no_ashr_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    lui a0, 5
; CHECK-NEXT:    addiw a0, a0, 1366
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 0, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 15, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 3, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsdiv_const_no_ashr_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_no_ashr_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    lui a0, 349525
; CHECK-NEXT:    addiw a0, a0, 1366
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 0, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 31, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 3, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsdiv_const_no_ashr_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_no_ashr_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, %hi(.LCPI39_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI39_0)(a1)
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    vmulh.vx v8, v8, a1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 0, v0.t
; CHECK-NEXT:    li a0, 63
; CHECK-NEXT:    vsrl.vx v9, v8, a0, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 3, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsdiv_const_ashr_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_ashr_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    li a0, 103
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 1, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 7, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 5, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpsdiv_const_ashr_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_ashr_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    lui a0, 6
; CHECK-NEXT:    addiw a0, a0, 1639
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 1, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 15, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 5, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsdiv_const_ashr_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_ashr_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    lui a0, 419430
; CHECK-NEXT:    addiw a0, a0, 1639
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 1, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 31, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 5, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsdiv_const_ashr_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_ashr_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, %hi(.LCPI43_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI43_0)(a1)
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    vmulh.vx v8, v8, a1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 1, v0.t
; CHECK-NEXT:    li a0, 63
; CHECK-NEXT:    vsrl.vx v9, v8, a0, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 5, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsdiv_const_add_ashr_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_add_ashr_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, 1
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, a1, v0.t
; CHECK-NEXT:    li a0, -109
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 2, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 7, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 7, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpsdiv_const_add_ashr_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_add_ashr_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, 1
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, a1, v0.t
; CHECK-NEXT:    lui a0, 1048569
; CHECK-NEXT:    addiw a0, a0, -1911
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 3, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 15, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 15, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsdiv_const_add_ashr_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_add_ashr_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, 1
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, a1, v0.t
; CHECK-NEXT:    lui a0, 599186
; CHECK-NEXT:    addiw a0, a0, 1171
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 2, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 31, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 7, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsdiv_const_add_ashr_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_add_ashr_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, %hi(.LCPI47_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI47_0)(a1)
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    li a0, 1
; CHECK-NEXT:    vmul.vx v9, v8, a0, v0.t
; CHECK-NEXT:    vmulh.vx v8, v8, a1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 3, v0.t
; CHECK-NEXT:    li a0, 63
; CHECK-NEXT:    vsrl.vx v9, v8, a0, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 15, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsdiv_const_sub_ashr_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_sub_ashr_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, -1
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, a1, v0.t
; CHECK-NEXT:    li a0, 109
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 2, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 7, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 -7, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpsdiv_const_sub_ashr_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_sub_ashr_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, -1
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, a1, v0.t
; CHECK-NEXT:    lui a0, 7
; CHECK-NEXT:    addiw a0, a0, 1911
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 3, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 15, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 -15, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsdiv_const_sub_ashr_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_sub_ashr_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, -1
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, a1, v0.t
; CHECK-NEXT:    lui a0, 449390
; CHECK-NEXT:    addiw a0, a0, -1171
; CHECK-NEXT:    vmulh.vx v8, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 2, v0.t
; CHECK-NEXT:    vsrl.vi v9, v8, 31, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 -7, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsdiv_const_sub_ashr_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_const_sub_ashr_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, %hi(.LCPI51_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI51_0)(a1)
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    li a0, -1
; CHECK-NEXT:    vmul.vx v9, v8, a0, v0.t
; CHECK-NEXT:    vmulh.vx v8, v8, a1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsra.vi v8, v8, 1, v0.t
; CHECK-NEXT:    li a0, 63
; CHECK-NEXT:    vsrl.vx v9, v8, a0, v0.t
; CHECK-NEXT:    vand.vi v9, v9, -1, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 -3, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 1 x i64> @vpurem_by_max_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_max_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v0, v8, -1, v0.t
; CHECK-NEXT:    vmerge.vim v8, v8, 0, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 18446744073709551615, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.urem.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 4 x i16> @vpurem_by_max_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_max_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v0, v8, -1, v0.t
; CHECK-NEXT:    vmerge.vim v8, v8, 0, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 65535, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.urem.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 8 x i8> @vpurem_by_max_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_max_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v0, v8, -1, v0.t
; CHECK-NEXT:    vmerge.vim v8, v8, 0, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 255, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.urem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 2 x i32> @vpurem_by_max_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_max_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmseq.vi v0, v8, -1, v0.t
; CHECK-NEXT:    vmerge.vim v8, v8, 0, v0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 4294967295, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.urem.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpurem_by_const_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_const_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmv1r.v v9, v0
; CHECK-NEXT:    lui a1, %hi(.LCPI56_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI56_0)(a1)
; CHECK-NEXT:    vsetvli a2, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v10, 5
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v11, v8, a1, v0.t
; CHECK-NEXT:    vsrl.vi v11, v11, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v10, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v10, v11, v8, v0
; CHECK-NEXT:    li a0, 5
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vmul.vx v10, v10, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 5, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.urem.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 4 x i16> @vpurem_by_const_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_const_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmv1r.v v9, v0
; CHECK-NEXT:    vsetvli a1, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v10, 5
; CHECK-NEXT:    lui a1, 1048573
; CHECK-NEXT:    addiw a1, a1, -819
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v11, v8, a1, v0.t
; CHECK-NEXT:    vsrl.vi v11, v11, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v10, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v10, v11, v8, v0
; CHECK-NEXT:    li a0, 5
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vmul.vx v10, v10, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 5, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.urem.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 8 x i8> @vpurem_by_const_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_const_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmv1r.v v9, v0
; CHECK-NEXT:    vsetvli a1, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v10, 5
; CHECK-NEXT:    li a1, -51
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v11, v8, a1, v0.t
; CHECK-NEXT:    vsrl.vi v11, v11, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v10, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v10, v11, v8, v0
; CHECK-NEXT:    li a0, 5
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vmul.vx v10, v10, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 5, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.urem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 2 x i32> @vpurem_by_const_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_const_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmv1r.v v9, v0
; CHECK-NEXT:    vsetvli a1, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v10, 5
; CHECK-NEXT:    lui a1, 838861
; CHECK-NEXT:    addiw a1, a1, -819
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v11, v8, a1, v0.t
; CHECK-NEXT:    vsrl.vi v11, v11, 2, v0.t
; CHECK-NEXT:    vmseq.vi v0, v10, 1, v0.t
; CHECK-NEXT:    vmerge.vvm v10, v11, v8, v0
; CHECK-NEXT:    li a0, 5
; CHECK-NEXT:    vmv1r.v v0, v9
; CHECK-NEXT:    vmul.vx v10, v10, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 5, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.urem.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsrem_by_const_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_const_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lui a1, %hi(.LCPI60_0)
; CHECK-NEXT:    ld a1, %lo(.LCPI60_0)(a1)
; CHECK-NEXT:    vsetvli zero, a0, e64, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    vmulh.vx v10, v8, a1, v0.t
; CHECK-NEXT:    vadd.vv v9, v10, v9, v0.t
; CHECK-NEXT:    vsra.vi v9, v9, 1, v0.t
; CHECK-NEXT:    li a0, 63
; CHECK-NEXT:    vsrl.vx v10, v9, a0, v0.t
; CHECK-NEXT:    vand.vi v10, v10, -1, v0.t
; CHECK-NEXT:    vadd.vv v9, v9, v10, v0.t
; CHECK-NEXT:    li a0, 5
; CHECK-NEXT:    vmul.vx v9, v9, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 5, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.srem.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 4 x i16> @vpsrem_by_const_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_const_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e16, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    lui a0, 6
; CHECK-NEXT:    addiw a0, a0, 1639
; CHECK-NEXT:    vmulh.vx v10, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v9, v10, v9, v0.t
; CHECK-NEXT:    vsra.vi v9, v9, 1, v0.t
; CHECK-NEXT:    vsrl.vi v10, v9, 15, v0.t
; CHECK-NEXT:    vand.vi v10, v10, -1, v0.t
; CHECK-NEXT:    vadd.vv v9, v9, v10, v0.t
; CHECK-NEXT:    li a0, 5
; CHECK-NEXT:    vmul.vx v9, v9, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 5, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.srem.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 8 x i8> @vpsrem_by_const_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_const_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    li a0, 103
; CHECK-NEXT:    vmulh.vx v10, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v9, v10, v9, v0.t
; CHECK-NEXT:    vsra.vi v9, v9, 1, v0.t
; CHECK-NEXT:    vsrl.vi v10, v9, 7, v0.t
; CHECK-NEXT:    vand.vi v10, v10, -1, v0.t
; CHECK-NEXT:    vadd.vv v9, v9, v10, v0.t
; CHECK-NEXT:    li a0, 5
; CHECK-NEXT:    vmul.vx v9, v9, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 5, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.srem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 2 x i32> @vpsrem_by_const_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_const_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli zero, a0, e32, m1, ta, ma
; CHECK-NEXT:    vmul.vx v9, v8, zero, v0.t
; CHECK-NEXT:    lui a0, 419430
; CHECK-NEXT:    addiw a0, a0, 1639
; CHECK-NEXT:    vmulh.vx v10, v8, a0, v0.t
; CHECK-NEXT:    vadd.vv v9, v10, v9, v0.t
; CHECK-NEXT:    vsra.vi v9, v9, 1, v0.t
; CHECK-NEXT:    vsrl.vi v10, v9, 31, v0.t
; CHECK-NEXT:    vand.vi v10, v10, -1, v0.t
; CHECK-NEXT:    vadd.vv v9, v9, v10, v0.t
; CHECK-NEXT:    li a0, 5
; CHECK-NEXT:    vmul.vx v9, v9, a0, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v9, v0.t
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 5, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.srem.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 8 x i8> @vpudiv_by_1_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_1_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 1, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpudiv_by_1_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_1_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 1, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpudiv_by_1_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_1_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 1, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpudiv_by_1_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudiv_by_1_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 1, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsdiv_by_1_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_1_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 1, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpsdiv_by_1_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_1_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 1, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.sdiv.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsdiv_by_1_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_1_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 1, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.sdiv.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsdiv_by_1_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdiv_by_1_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 1, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.sdiv.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpurem_by_1_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_1_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 1, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.urem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpurem_by_1_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_1_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 1, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.urem.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpurem_by_1_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_1_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 1, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.urem.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpurem_by_1_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpurem_by_1_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 1, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.urem.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsrem_by_1_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_1_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 1, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.srem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpsrem_by_1_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_1_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 1, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.srem.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsrem_by_1_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_1_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 1, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.srem.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsrem_by_1_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_1_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 1, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.srem.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsrem_by_neg1_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_neg1_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 8 x i8> undef, i8 -1, i32 0
  %splat = shufflevector <vscale x 8 x i8> %vec, <vscale x 8 x i8> poison, <vscale x 8 x i32> zeroinitializer
  %v = call <vscale x 8 x i8> @llvm.vp.srem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %splat, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %v
}

define <vscale x 4 x i16> @vpsrem_by_neg1_nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_neg1_nxv4i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e16, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 4 x i16> undef, i16 -1, i32 0
  %splat = shufflevector <vscale x 4 x i16> %vec, <vscale x 4 x i16> poison, <vscale x 4 x i32> zeroinitializer
  %v = call <vscale x 4 x i16> @llvm.vp.srem.nxv4i16(<vscale x 4 x i16> %va, <vscale x 4 x i16> %splat, <vscale x 4 x i1> %m, i32 %evl)
  ret <vscale x 4 x i16> %v
}

define <vscale x 2 x i32> @vpsrem_by_neg1_nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_neg1_nxv2i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e32, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 2 x i32> undef, i32 -1, i32 0
  %splat = shufflevector <vscale x 2 x i32> %vec, <vscale x 2 x i32> poison, <vscale x 2 x i32> zeroinitializer
  %v = call <vscale x 2 x i32> @llvm.vp.srem.nxv2i32(<vscale x 2 x i32> %va, <vscale x 2 x i32> %splat, <vscale x 2 x i1> %m, i32 %evl)
  ret <vscale x 2 x i32> %v
}

define <vscale x 1 x i64> @vpsrem_by_neg1_nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsrem_by_neg1_nxv1i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetvli a0, zero, e64, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v8, 0
; CHECK-NEXT:    ret
  %vec = insertelement <vscale x 1 x i64> undef, i64 -1, i32 0
  %splat = shufflevector <vscale x 1 x i64> %vec, <vscale x 1 x i64> poison, <vscale x 1 x i32> zeroinitializer
  %v = call <vscale x 1 x i64> @llvm.vp.srem.nxv1i64(<vscale x 1 x i64> %va, <vscale x 1 x i64> %splat, <vscale x 1 x i1> %m, i32 %evl)
  ret <vscale x 1 x i64> %v
}

define <vscale x 8 x i8> @vpsdivrem_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> %vb, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpsdivrem_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, 109
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmulh.vx v9, v8, a1, v0.t
; CHECK-NEXT:    li a0, -7
; CHECK-NEXT:    vsub.vv v9, v9, v8, v0.t
; CHECK-NEXT:    vsra.vi v9, v9, 2, v0.t
; CHECK-NEXT:    vsrl.vi v10, v9, 7, v0.t
; CHECK-NEXT:    vand.vi v10, v10, -1, v0.t
; CHECK-NEXT:    vadd.vv v9, v9, v10, v0.t
; CHECK-NEXT:    vmul.vx v10, v9, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    ret
  %v = call <vscale x 8 x i8> @llvm.vp.srem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> splat (i8 -7), <vscale x 8 x i1> %m, i32 %evl)
  %w = call <vscale x 8 x i8> @llvm.vp.sdiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> splat (i8 -7), <vscale x 8 x i1> %m, i32 %evl)
  %x = call <vscale x 8 x i8> @llvm.vp.add.nxv8i8(<vscale x 8 x i8> %v, <vscale x 8 x i8> %w, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %x
}

define <vscale x 8 x i8> @vpudivrem_nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i1> %m, i32 zeroext %evl) {
; CHECK-LABEL: vpudivrem_nxv8i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, 37
; CHECK-NEXT:    vsetvli zero, a0, e8, m1, ta, ma
; CHECK-NEXT:    vmulhu.vx v9, v8, a1, v0.t
; CHECK-NEXT:    li a0, -128
; CHECK-NEXT:    vsub.vv v10, v8, v9, v0.t
; CHECK-NEXT:    vmulhu.vx v10, v10, a0, v0.t
; CHECK-NEXT:    li a0, 7
; CHECK-NEXT:    vadd.vv v9, v10, v9, v0.t
; CHECK-NEXT:    vsrl.vi v9, v9, 2, v0.t
; CHECK-NEXT:    vmul.vx v10, v9, a0, v0.t
; CHECK-NEXT:    vadd.vv v8, v8, v9, v0.t
; CHECK-NEXT:    vsub.vv v8, v8, v10, v0.t
; CHECK-NEXT:    ret
  %v = call <vscale x 8 x i8> @llvm.vp.urem.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> splat (i8 7), <vscale x 8 x i1> %m, i32 %evl)
  %w = call <vscale x 8 x i8> @llvm.vp.udiv.nxv8i8(<vscale x 8 x i8> %va, <vscale x 8 x i8> splat (i8 7), <vscale x 8 x i1> %m, i32 %evl)
  %x = call <vscale x 8 x i8> @llvm.vp.add.nxv8i8(<vscale x 8 x i8> %v, <vscale x 8 x i8> %w, <vscale x 8 x i1> %m, i32 %evl)
  ret <vscale x 8 x i8> %x
}
