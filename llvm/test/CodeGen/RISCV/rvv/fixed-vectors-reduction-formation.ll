; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv32 -mattr=+v,+m -verify-machineinstrs < %s | FileCheck %s
; RUN: llc -mtriple=riscv64 -mattr=+v,+m -verify-machineinstrs < %s | FileCheck %s

define i32 @reduce_sum_2xi32(<2 x i32> %v) {
; CHECK-LABEL: reduce_sum_2xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 2, e32, mf2, ta, ma
; CHECK-NEXT:    vmv.s.x v9, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v9
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %e0 = extractelement <2 x i32> %v, i32 0
  %e1 = extractelement <2 x i32> %v, i32 1
  %add0 = add i32 %e0, %e1
  ret i32 %add0
}

define i32 @reduce_sum_4xi32(<4 x i32> %v) {
; CHECK-LABEL: reduce_sum_4xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 4, e32, m1, ta, ma
; CHECK-NEXT:    vmv.s.x v9, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v9
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %e0 = extractelement <4 x i32> %v, i32 0
  %e1 = extractelement <4 x i32> %v, i32 1
  %e2 = extractelement <4 x i32> %v, i32 2
  %e3 = extractelement <4 x i32> %v, i32 3
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  ret i32 %add2
}


define i32 @reduce_sum_8xi32(<8 x i32> %v) {
; CHECK-LABEL: reduce_sum_8xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 8, e32, m2, ta, ma
; CHECK-NEXT:    vmv.s.x v10, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v10
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %e0 = extractelement <8 x i32> %v, i32 0
  %e1 = extractelement <8 x i32> %v, i32 1
  %e2 = extractelement <8 x i32> %v, i32 2
  %e3 = extractelement <8 x i32> %v, i32 3
  %e4 = extractelement <8 x i32> %v, i32 4
  %e5 = extractelement <8 x i32> %v, i32 5
  %e6 = extractelement <8 x i32> %v, i32 6
  %e7 = extractelement <8 x i32> %v, i32 7
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  %add5 = add i32 %add4, %e6
  %add6 = add i32 %add5, %e7
  ret i32 %add6
}

define i32 @reduce_sum_16xi32(<16 x i32> %v) {
; CHECK-LABEL: reduce_sum_16xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 16, e32, m4, ta, ma
; CHECK-NEXT:    vmv.s.x v12, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v12
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %e5 = extractelement <16 x i32> %v, i32 5
  %e6 = extractelement <16 x i32> %v, i32 6
  %e7 = extractelement <16 x i32> %v, i32 7
  %e8 = extractelement <16 x i32> %v, i32 8
  %e9 = extractelement <16 x i32> %v, i32 9
  %e10 = extractelement <16 x i32> %v, i32 10
  %e11 = extractelement <16 x i32> %v, i32 11
  %e12 = extractelement <16 x i32> %v, i32 12
  %e13 = extractelement <16 x i32> %v, i32 13
  %e14 = extractelement <16 x i32> %v, i32 14
  %e15 = extractelement <16 x i32> %v, i32 15
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  %add5 = add i32 %add4, %e6
  %add6 = add i32 %add5, %e7
  %add7 = add i32 %add6, %e8
  %add8 = add i32 %add7, %e9
  %add9 = add i32 %add8, %e10
  %add10 = add i32 %add9, %e11
  %add11 = add i32 %add10, %e12
  %add12 = add i32 %add11, %e13
  %add13 = add i32 %add12, %e14
  %add14 = add i32 %add13, %e15
  ret i32 %add14
}

define i32 @reduce_sum_16xi32_prefix2(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 2, e32, mf2, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    vmv.s.x v9, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v9
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %add0 = add i32 %e0, %e1
  ret i32 %add0
}

define i32 @reduce_sum_16xi32_prefix3(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix3:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 4, e32, m1, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    vmv.s.x v9, zero
; CHECK-NEXT:    vslideup.vi v8, v9, 3
; CHECK-NEXT:    vredsum.vs v8, v8, v9
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  ret i32 %add1
}

define i32 @reduce_sum_16xi32_prefix4(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix4:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 4, e32, m1, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    vmv.s.x v9, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v9
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  ret i32 %add2
}

define i32 @reduce_sum_16xi32_prefix5(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix5:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, 224
; CHECK-NEXT:    vsetivli zero, 8, e8, mf2, ta, ma
; CHECK-NEXT:    vmv.s.x v0, a1
; CHECK-NEXT:    vmv.v.i v8, -1
; CHECK-NEXT:    vmerge.vim v8, v8, 0, v0
; CHECK-NEXT:    vsetvli zero, zero, e32, m2, ta, ma
; CHECK-NEXT:    vle32.v v10, (a0)
; CHECK-NEXT:    vsext.vf4 v12, v8
; CHECK-NEXT:    vand.vv v8, v10, v12
; CHECK-NEXT:    vmv.s.x v10, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v10
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  ret i32 %add3
}

define i32 @reduce_sum_16xi32_prefix6(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix6:
; CHECK:       # %bb.0:
; CHECK-NEXT:    li a1, 192
; CHECK-NEXT:    vsetivli zero, 8, e8, mf2, ta, ma
; CHECK-NEXT:    vmv.s.x v0, a1
; CHECK-NEXT:    vmv.v.i v8, -1
; CHECK-NEXT:    vmerge.vim v8, v8, 0, v0
; CHECK-NEXT:    vsetvli zero, zero, e32, m2, ta, ma
; CHECK-NEXT:    vle32.v v10, (a0)
; CHECK-NEXT:    vsext.vf4 v12, v8
; CHECK-NEXT:    vand.vv v8, v10, v12
; CHECK-NEXT:    vmv.s.x v10, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v10
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %e5 = extractelement <16 x i32> %v, i32 5
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  ret i32 %add4
}

define i32 @reduce_sum_16xi32_prefix7(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix7:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 8, e32, m2, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    vmv.s.x v10, zero
; CHECK-NEXT:    vslideup.vi v8, v10, 7
; CHECK-NEXT:    vredsum.vs v8, v8, v10
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %e5 = extractelement <16 x i32> %v, i32 5
  %e6 = extractelement <16 x i32> %v, i32 6
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  %add5 = add i32 %add4, %e6
  ret i32 %add5
}

define i32 @reduce_sum_16xi32_prefix8(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 8, e32, m2, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    vmv.s.x v10, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v10
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %e5 = extractelement <16 x i32> %v, i32 5
  %e6 = extractelement <16 x i32> %v, i32 6
  %e7 = extractelement <16 x i32> %v, i32 7
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  %add5 = add i32 %add4, %e6
  %add6 = add i32 %add5, %e7
  ret i32 %add6
}

define i32 @reduce_sum_16xi32_prefix9(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix9:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 16, e32, m4, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    li a0, -512
; CHECK-NEXT:    vmv.s.x v0, a0
; CHECK-NEXT:    vsetvli zero, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v12, -1
; CHECK-NEXT:    vmerge.vim v12, v12, 0, v0
; CHECK-NEXT:    vsetvli zero, zero, e32, m4, ta, ma
; CHECK-NEXT:    vsext.vf4 v16, v12
; CHECK-NEXT:    vand.vv v8, v8, v16
; CHECK-NEXT:    vmv.s.x v12, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v12
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %e5 = extractelement <16 x i32> %v, i32 5
  %e6 = extractelement <16 x i32> %v, i32 6
  %e7 = extractelement <16 x i32> %v, i32 7
  %e8 = extractelement <16 x i32> %v, i32 8
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  %add5 = add i32 %add4, %e6
  %add6 = add i32 %add5, %e7
  %add7 = add i32 %add6, %e8
  ret i32 %add7
}

define i32 @reduce_sum_16xi32_prefix13(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix13:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 16, e32, m4, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    lui a0, 14
; CHECK-NEXT:    vmv.s.x v0, a0
; CHECK-NEXT:    vsetvli zero, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v12, -1
; CHECK-NEXT:    vmerge.vim v12, v12, 0, v0
; CHECK-NEXT:    vsetvli zero, zero, e32, m4, ta, ma
; CHECK-NEXT:    vsext.vf4 v16, v12
; CHECK-NEXT:    vand.vv v8, v8, v16
; CHECK-NEXT:    vmv.s.x v12, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v12
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %e5 = extractelement <16 x i32> %v, i32 5
  %e6 = extractelement <16 x i32> %v, i32 6
  %e7 = extractelement <16 x i32> %v, i32 7
  %e8 = extractelement <16 x i32> %v, i32 8
  %e9 = extractelement <16 x i32> %v, i32 9
  %e10 = extractelement <16 x i32> %v, i32 10
  %e11 = extractelement <16 x i32> %v, i32 11
  %e12 = extractelement <16 x i32> %v, i32 12
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  %add5 = add i32 %add4, %e6
  %add6 = add i32 %add5, %e7
  %add7 = add i32 %add6, %e8
  %add8 = add i32 %add7, %e9
  %add9 = add i32 %add8, %e10
  %add10 = add i32 %add9, %e11
  %add11 = add i32 %add10, %e12
  ret i32 %add11
}


define i32 @reduce_sum_16xi32_prefix14(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix14:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 16, e32, m4, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    lui a0, 12
; CHECK-NEXT:    vmv.s.x v0, a0
; CHECK-NEXT:    vsetvli zero, zero, e8, m1, ta, ma
; CHECK-NEXT:    vmv.v.i v12, -1
; CHECK-NEXT:    vmerge.vim v12, v12, 0, v0
; CHECK-NEXT:    vsetvli zero, zero, e32, m4, ta, ma
; CHECK-NEXT:    vsext.vf4 v16, v12
; CHECK-NEXT:    vand.vv v8, v8, v16
; CHECK-NEXT:    vmv.s.x v12, zero
; CHECK-NEXT:    vredsum.vs v8, v8, v12
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %e5 = extractelement <16 x i32> %v, i32 5
  %e6 = extractelement <16 x i32> %v, i32 6
  %e7 = extractelement <16 x i32> %v, i32 7
  %e8 = extractelement <16 x i32> %v, i32 8
  %e9 = extractelement <16 x i32> %v, i32 9
  %e10 = extractelement <16 x i32> %v, i32 10
  %e11 = extractelement <16 x i32> %v, i32 11
  %e12 = extractelement <16 x i32> %v, i32 12
  %e13 = extractelement <16 x i32> %v, i32 13
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  %add5 = add i32 %add4, %e6
  %add6 = add i32 %add5, %e7
  %add7 = add i32 %add6, %e8
  %add8 = add i32 %add7, %e9
  %add9 = add i32 %add8, %e10
  %add10 = add i32 %add9, %e11
  %add11 = add i32 %add10, %e12
  %add12 = add i32 %add11, %e13
  ret i32 %add12
}

define i32 @reduce_sum_16xi32_prefix15(ptr %p) {
; CHECK-LABEL: reduce_sum_16xi32_prefix15:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsetivli zero, 16, e32, m4, ta, ma
; CHECK-NEXT:    vle32.v v8, (a0)
; CHECK-NEXT:    vmv.s.x v12, zero
; CHECK-NEXT:    vslideup.vi v8, v12, 15
; CHECK-NEXT:    vredsum.vs v8, v8, v12
; CHECK-NEXT:    vmv.x.s a0, v8
; CHECK-NEXT:    ret
  %v = load <16 x i32>, ptr %p, align 256
  %e0 = extractelement <16 x i32> %v, i32 0
  %e1 = extractelement <16 x i32> %v, i32 1
  %e2 = extractelement <16 x i32> %v, i32 2
  %e3 = extractelement <16 x i32> %v, i32 3
  %e4 = extractelement <16 x i32> %v, i32 4
  %e5 = extractelement <16 x i32> %v, i32 5
  %e6 = extractelement <16 x i32> %v, i32 6
  %e7 = extractelement <16 x i32> %v, i32 7
  %e8 = extractelement <16 x i32> %v, i32 8
  %e9 = extractelement <16 x i32> %v, i32 9
  %e10 = extractelement <16 x i32> %v, i32 10
  %e11 = extractelement <16 x i32> %v, i32 11
  %e12 = extractelement <16 x i32> %v, i32 12
  %e13 = extractelement <16 x i32> %v, i32 13
  %e14 = extractelement <16 x i32> %v, i32 14
  %add0 = add i32 %e0, %e1
  %add1 = add i32 %add0, %e2
  %add2 = add i32 %add1, %e3
  %add3 = add i32 %add2, %e4
  %add4 = add i32 %add3, %e5
  %add5 = add i32 %add4, %e6
  %add6 = add i32 %add5, %e7
  %add7 = add i32 %add6, %e8
  %add8 = add i32 %add7, %e9
  %add9 = add i32 %add8, %e10
  %add10 = add i32 %add9, %e11
  %add11 = add i32 %add10, %e12
  %add12 = add i32 %add11, %e13
  %add13 = add i32 %add12, %e14
  ret i32 %add13
}
