; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv32 -mattr=+v -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=RV32I %s
; RUN: llc -mtriple=riscv64 -mattr=+v -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=RV64I %s

define <16 x i8> @constraint_vr(<16 x i8> %0, <16 x i8> %1) nounwind {
; RV32I-LABEL: constraint_vr:
; RV32I:       # %bb.0:
; RV32I-NEXT:    #APP
; RV32I-NEXT:    vadd.vv v8, v8, v9
; RV32I-NEXT:    #NO_APP
; RV32I-NEXT:    ret
;
; RV64I-LABEL: constraint_vr:
; RV64I:       # %bb.0:
; RV64I-NEXT:    #APP
; RV64I-NEXT:    vadd.vv v8, v8, v9
; RV64I-NEXT:    #NO_APP
; RV64I-NEXT:    ret
  %a = tail call <16 x i8> asm "vadd.vv $0, $1, $2", "=^vr,^vr,^vr"(
    <16 x i8> %0, <16 x i8> %1)
  ret <16 x i8> %a
}

define <16 x i8> @constraint_vd(<16 x i8> %0, <16 x i8> %1) nounwind {
; RV32I-LABEL: constraint_vd:
; RV32I:       # %bb.0:
; RV32I-NEXT:    #APP
; RV32I-NEXT:    vadd.vv v8, v8, v9
; RV32I-NEXT:    #NO_APP
; RV32I-NEXT:    ret
;
; RV64I-LABEL: constraint_vd:
; RV64I:       # %bb.0:
; RV64I-NEXT:    #APP
; RV64I-NEXT:    vadd.vv v8, v8, v9
; RV64I-NEXT:    #NO_APP
; RV64I-NEXT:    ret
  %a = tail call <16 x i8> asm "vadd.vv $0, $1, $2", "=^vd,^vr,^vr"(
    <16 x i8> %0, <16 x i8> %1)
  ret <16 x i8> %a
}

define <16 x i1> @constraint_vm(<16 x i1> %0, <16 x i1> %1) nounwind {
; RV32I-LABEL: constraint_vm:
; RV32I:       # %bb.0:
; RV32I-NEXT:    vmv1r.v v9, v0
; RV32I-NEXT:    vmv1r.v v0, v8
; RV32I-NEXT:    #APP
; RV32I-NEXT:    vadd.vv v8, v9, v0
; RV32I-NEXT:    #NO_APP
; RV32I-NEXT:    vsetivli zero, 16, e8, m1, ta, ma
; RV32I-NEXT:    vand.vi v8, v8, 1
; RV32I-NEXT:    vmsne.vi v0, v8, 0
; RV32I-NEXT:    ret
;
; RV64I-LABEL: constraint_vm:
; RV64I:       # %bb.0:
; RV64I-NEXT:    vmv1r.v v9, v0
; RV64I-NEXT:    vmv1r.v v0, v8
; RV64I-NEXT:    #APP
; RV64I-NEXT:    vadd.vv v8, v9, v0
; RV64I-NEXT:    #NO_APP
; RV64I-NEXT:    vsetivli zero, 16, e8, m1, ta, ma
; RV64I-NEXT:    vand.vi v8, v8, 1
; RV64I-NEXT:    vmsne.vi v0, v8, 0
; RV64I-NEXT:    ret
  %a = tail call <16 x i1> asm "vadd.vv $0, $1, $2", "=^vr,^vr,^vm"(
    <16 x i1> %0, <16 x i1> %1)
  ret <16 x i1> %a
}
