; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc -mtriple=riscv32 -mattr=+m -verify-machineinstrs < %s | FileCheck %s --check-prefixes=CHECK,RV32IM
; RUN: llc -mtriple=riscv64 -mattr=+m -verify-machineinstrs < %s | FileCheck %s --check-prefixes=CHECK,RV64IM

declare i8 @use(i8, i1)

define void @commutative_clmul_i8(i8 %x, i8 %y, ptr %p0, ptr %p1) {
  %xy = call i8 @llvm.clmul.i8(i8 %x, i8 %y)
  %yx = call i8 @llvm.clmul.i8(i8 %y, i8 %x)
  store i8 %xy, ptr %p0
  store i8 %yx, ptr %p1
  ret void
}

define void @commutative_clmulh_i8(i8 %x, i8 %y, ptr %p0, ptr %p1) {
  %x.ext = zext i8 %x to i16
  %y.ext = zext i8 %y to i16
  %clmul_xy = call i16 @llvm.clmul.i16(i16 %x.ext, i16 %y.ext)
  %clmul_yx = call i16 @llvm.clmul.i16(i16 %y.ext, i16 %x.ext)
  %clmul_xy_lshr = lshr i16 %clmul_xy, 8
  %clmul_yx_lshr = lshr i16 %clmul_yx, 8
  %clmulh_xy = trunc i16 %clmul_xy_lshr to i8
  %clmulh_yx = trunc i16 %clmul_yx_lshr to i8
  store i8 %clmulh_xy, ptr %p0
  store i8 %clmulh_yx, ptr %p1
  ret void
}

define void @commutative_clmulr_i8(i8 %x, i8 %y, ptr %p0, ptr %p1) {
  %x.ext = zext i8 %x to i16
  %y.ext = zext i8 %y to i16
  %clmul_xy = call i16 @llvm.clmul.i16(i16 %x.ext, i16 %y.ext)
  %clmul_yx = call i16 @llvm.clmul.i16(i16 %y.ext, i16 %x.ext)
  %clmul_xy_lshr = lshr i16 %clmul_xy, 7
  %clmul_yx_lshr = lshr i16 %clmul_yx, 7
  %clmulh_xy = trunc i16 %clmul_xy_lshr to i8
  %clmulh_yx = trunc i16 %clmul_yx_lshr to i8
  store i8 %clmulh_xy, ptr %p0
  store i8 %clmulh_yx, ptr %p1
  ret void
}

define void @mul_use_commutative_clmul_i8(i8 %x, i8 %y, ptr %p0, ptr %p1) {
  %xy = call i8 @llvm.clmul.i8(i8 %x, i8 %y)
  %yx = call i8 @llvm.clmul.i8(i8 %y, i8 %x)
  store i8 %xy, ptr %p0
  call void @use(i8 %xy)
  store i8 %yx, ptr %p1
  ret void
}

define void @neg_commutative_clmul_i8(i8 %x, i8 %y, ptr %p0, ptr %p1) {
  %xy = call i8 @llvm.clmul.i8(i8 %x, i8 %y)
  store i8 %xy, ptr %p0
  store i8 %xy, ptr %p1
  ret void
}

declare void @vector_use(<2 x i64>)

define void @commutative_clmul_v2i64(<2 x i64> %x, <2 x i64> %y, ptr %p0, ptr %p1) {
  %xy = call <2 x i64> @llvm.clmul.v2i64(<2 x i64> %x, <2 x i64> %y)
  %yx = call <2 x i64> @llvm.clmul.v2i64(<2 x i64> %y, <2 x i64> %x)
  store <2 x i64> %xy, ptr %p0
  store <2 x i64> %yx, ptr %p1
  ret void
}

define void @commutative_clmulh_v2i64(<2 x i64> %x, <2 x i64> %y, ptr %p0, ptr %p1) {
  %x.ext = zext <2 x i64> %x to <2 x i128>
  %y.ext = zext <2 x i64> %y to <2 x i128>
  %clmul_xy = call <2 x i128> @llvm.clmul.v2i128(<2 x i128> %x.ext, <2 x i128> %y.ext)
  %clmul_yx = call <2 x i128> @llvm.clmul.v2i128(<2 x i128> %y.ext, <2 x i128> %x.ext)
  %clmul_xy_lshr = lshr <2 x i128> %clmul_xy, splat (i128 64)
  %clmul_yx_lshr = lshr <2 x i128> %clmul_yx, splat (i128 64)
  %clmulh_xy = trunc <2 x i128> %clmul_xy_lshr to <2 x i64>
  %clmulh_yx = trunc <2 x i128> %clmul_yx_lshr to <2 x i64>
  store <2 x i64> %clmulh_xy, ptr %p0
  store <2 x i64> %clmulh_yx, ptr %p1
  ret void
}

define void @commutative_clmulr_v2i64(<2 x i64> %x, <2 x i64> %y, ptr %p0, ptr %p1) {
  %x.ext = zext <2 x i64> %x to <2 x i128>
  %y.ext = zext <2 x i64> %y to <2 x i128>
  %clmul_xy = call <2 x i128> @llvm.clmul.v2i128(<2 x i128> %x.ext, <2 x i128> %y.ext)
  %clmul_yx = call <2 x i128> @llvm.clmul.v2i128(<2 x i128> %y.ext, <2 x i128> %x.ext)
  %clmul_xy_lshr = lshr <2 x i128> %clmul_xy, splat (i128 63)
  %clmul_yx_lshr = lshr <2 x i128> %clmul_yx, splat (i128 63)
  %clmulh_xy = trunc <2 x i128> %clmul_xy_lshr to <2 x i64>
  %clmulh_yx = trunc <2 x i128> %clmul_yx_lshr to <2 x i64>
  store <2 x i64> %clmulh_xy, ptr %p0
  store <2 x i64> %clmulh_yx, ptr %p1
  ret void
}

define void @mul_use_commutative_clmul_v2i64(<2 x i64> %x, <2 x i64> %y, ptr %p0, ptr %p1) {
  %xy = call <2 x i64> @llvm.clmul.v2i64(<2 x i64> %x, <2 x i64> %y)
  %yx = call <2 x i64> @llvm.clmul.v2i64(<2 x i64> %y, <2 x i64> %x)
  store <2 x i64> %xy, ptr %p0
  call void @vector_use(<2 x i64> %xy)
  store <2 x i64> %yx, ptr %p1
  ret void
}
