; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 6
; RUN: llc -mtriple=riscv64 -mattr='+v' -stop-before=riscv-insert-vsetvli %s -o - | FileCheck %s

define <32 x i64> @main(i1 %tobool93.not, <32 x i64> %0, <32 x i64> %1) #0 {
  ; CHECK-LABEL: name: main
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.2(0x40000000), %bb.1(0x40000000)
  ; CHECK-NEXT:   liveins: $x10, $x11, $v8m8, $v16m8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gpr = COPY $x11
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   BNE $x0, $x0, %bb.2
  ; CHECK-NEXT:   PseudoBR %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1.BS_LABEL_5:
  ; CHECK-NEXT:   renamable $v8m8 = PseudoVMV_V_I_M8 undef renamable $v8m8, 0, 16 /* vl */, 6 /* e64 */, 0 /* tu, mu */
  ; CHECK-NEXT:   $v16m8 = COPY renamable $v8m8
  ; CHECK-NEXT:   PseudoRET implicit $v8m8, implicit $v16m8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.BS_LABEL_8:
  ; CHECK-NEXT:   successors: %bb.4(0x40000000), %bb.3(0x40000000)
  ; CHECK-NEXT:   liveins: $v8m8:0x0000000000000002, $v16m8:0x0000000000000006
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   renamable $v24m8 = PseudoVLE64_V_M8 undef renamable $v24m8, [[COPY]], 16 /* vl */, 6 /* e64 */, 2 /* tu, ma */ :: (load (s1024))
  ; CHECK-NEXT:   [[ANDI:%[0-9]+]]:gpr = ANDI [[COPY1]], 1
  ; CHECK-NEXT:   BNE [[ANDI]], $x0, %bb.4
  ; CHECK-NEXT:   PseudoBR %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.cond.true94:
  ; CHECK-NEXT:   successors: %bb.4(0x80000000)
  ; CHECK-NEXT:   liveins: $v8m8:0x0000000000000002, $v16m8:0x0000000000000006, $v24m8:0x0000000000000002
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.4.cond.end98:
  ; CHECK-NEXT:   successors: %bb.6(0x30000000), %bb.5(0x50000000)
  ; CHECK-NEXT:   liveins: $v8m8:0x0000000000000002, $v16m8:0x0000000000000006, $v24m8:0x0000000000000002
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PseudoVMV_X_S:%[0-9]+]]:gpr = PseudoVMV_X_S killed renamable $v24, 6 /* e64 */
  ; CHECK-NEXT:   BEQ [[PseudoVMV_X_S]], $x0, %bb.6
  ; CHECK-NEXT:   PseudoBR %bb.5
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.5.cond.true108:
  ; CHECK-NEXT:   successors: %bb.7(0x80000000)
  ; CHECK-NEXT:   liveins: $v8m8:0x0000000000000002, $v16m8:0x0000000000000006
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   VS8R_V renamable $v8m8, %stack.0 :: (store (<vscale x 1 x s512>) into %stack.0, align 8)
  ; CHECK-NEXT:   PseudoBR %bb.7
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.6.cond.false111:
  ; CHECK-NEXT:   successors: %bb.7(0x80000000)
  ; CHECK-NEXT:   liveins: $v8m8:0x0000000000000002, $v16m8:0x0000000000000006
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   VS8R_V renamable $v8m8, %stack.0 :: (store (<vscale x 1 x s512>) into %stack.0, align 8)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.7.cond.end113:
  ; CHECK-NEXT:   successors: %bb.8(0x40000000), %bb.9(0x40000000)
  ; CHECK-NEXT:   liveins: $v16m8:0x0000000000000006
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   renamable $v0m8 = PseudoVMV_V_I_M8 undef renamable $v0m8, 0, 16 /* vl */, 6 /* e64 */, 0 /* tu, mu */
  ; CHECK-NEXT:   renamable $v24m8 = COPY renamable $v0m8
  ; CHECK-NEXT:   renamable $v8m2 = PseudoVSLIDEDOWN_VI_M2 undef renamable $v8m2, killed renamable $v16m2, 2, 1 /* vl */, 6 /* e64 */, 3 /* ta, ma */
  ; CHECK-NEXT:   [[PseudoVMV_X_S1:%[0-9]+]]:gpr = PseudoVMV_X_S killed renamable $v8, 6 /* e64 */
  ; CHECK-NEXT:   renamable $v24m8 = PseudoVMV_V_V_M8 killed renamable $v24m8, killed renamable $v0m8, 1 /* vl */, 6 /* e64 */, 0 /* tu, mu */
  ; CHECK-NEXT:   BNE [[PseudoVMV_X_S1]], $x0, %bb.9
  ; CHECK-NEXT:   PseudoBR %bb.8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.8.cond.true128:
  ; CHECK-NEXT:   successors: %bb.9(0x80000000)
  ; CHECK-NEXT:   liveins: $v24m8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.9.cond.end133:
  ; CHECK-NEXT:   liveins: $v24m8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   renamable $v0m8 = PseudoVMV_V_I_M8 undef renamable $v0m8, 0, 16 /* vl */, 6 /* e64 */, 0 /* tu, mu */
  ; CHECK-NEXT:   renamable $v16 = COPY renamable $v0
  ; CHECK-NEXT:   renamable $v8m8 = VL8RE8_V %stack.0 :: (load (<vscale x 1 x s512>) from %stack.0, align 8)
  ; CHECK-NEXT:   [[PseudoVMV_X_S2:%[0-9]+]]:gpr = PseudoVMV_X_S killed renamable $v8, 5 /* e32 */
  ; CHECK-NEXT:   renamable $v8m8 = COPY renamable $v0m8
  ; CHECK-NEXT:   early-clobber renamable $v17 = PseudoVMSLEU_VV_M8 killed renamable $v0m8, killed renamable $v24m8, 16 /* vl */, 6 /* e64 */
  ; CHECK-NEXT:   renamable $v16 = PseudoVMV_S_X killed renamable $v16, $x0, 16 /* vl */, 6 /* e64 */
  ; CHECK-NEXT:   renamable $v16 = PseudoVMV_S_X killed renamable $v16, [[PseudoVMV_X_S2]], 16 /* vl */, 6 /* e64 */
  ; CHECK-NEXT:   renamable $v24m8 = PseudoVMV_V_I_M8 undef renamable $v24m8, 0, 16 /* vl */, 6 /* e64 */, 0 /* tu, mu */
  ; CHECK-NEXT:   renamable $v8 = COPY killed renamable $v16
  ; CHECK-NEXT:   $v0 = COPY killed renamable $v17
  ; CHECK-NEXT:   renamable $v16m8 = PseudoVMERGE_VIM_M8 undef renamable $v16m8, killed renamable $v24m8, -1, $v0, 16 /* vl */, 6 /* e64 */
  ; CHECK-NEXT:   renamable $v24m8 = PseudoVMV_V_I_M8 undef renamable $v24m8, 0, 16 /* vl */, 6 /* e64 */, 0 /* tu, mu */
  ; CHECK-NEXT:   early-clobber renamable $v0 = PseudoVMSLEU_VV_M8 killed renamable $v24m8, killed renamable $v8m8, 16 /* vl */, 6 /* e64 */
  ; CHECK-NEXT:   renamable $v8m8 = PseudoVMV_V_I_M8 undef renamable $v8m8, 0, 16 /* vl */, 6 /* e64 */, 0 /* tu, mu */
  ; CHECK-NEXT:   renamable $v8m8 = PseudoVMERGE_VIM_M8 undef renamable $v8m8, killed renamable $v8m8, -1, $v0, 16 /* vl */, 6 /* e64 */
  ; CHECK-NEXT:   PseudoRET implicit $v8m8, implicit $v16m8
entry:
  switch i32 0, label %BS_LABEL_5 [
    i32 3, label %BS_LABEL_5
    i32 4, label %BS_LABEL_8
  ]

BS_LABEL_5:                                       ; preds = %entry, %entry
  ret <32 x i64> zeroinitializer

BS_LABEL_8:                                       ; preds = %entry
  %conv76 = zext <32 x i8> zeroinitializer to <32 x i64>
  %. = select i1 false, <32 x i64> zeroinitializer, <32 x i64> zeroinitializer
  br i1 %tobool93.not, label %cond.end98, label %cond.true94

cond.true94:                                      ; preds = %BS_LABEL_8
  %vecext95 = extractelement <32 x i64> zeroinitializer, i64 0
  br label %cond.end98

cond.end98:                                       ; preds = %cond.true94, %BS_LABEL_8
  %vecext106 = extractelement <32 x i64> %1, i64 0
  %tobool107.not = icmp eq i64 %vecext106, 0
  br i1 %tobool107.not, label %cond.false111, label %cond.true108

cond.true108:                                     ; preds = %cond.end98
  %vecext109 = extractelement <32 x i64> zeroinitializer, i64 0
  br label %cond.end113

cond.false111:                                    ; preds = %cond.end98
  %vecext112 = extractelement <32 x i64> zeroinitializer, i64 0
  br label %cond.end113

cond.end113:                                      ; preds = %cond.false111, %cond.true108
  %cond114 = phi i64 [ 0, %cond.true108 ], [ 1, %cond.false111 ]
  %2 = insertelement <32 x i64> zeroinitializer, i64 %cond114, i64 0
  %vecext123 = extractelement <32 x i64> %conv76, i64 0
  %3 = insertelement <32 x i64> %2, i64 0, i64 0
  %vecinit125 = insertelement <32 x i64> %3, i64 %vecext123, i64 16
  %vecext126 = extractelement <32 x i64> %0, i64 18
  %cmp = icmp ult i64 %vecext126, 1
  br i1 %cmp, label %cond.true128, label %cond.end133

cond.true128:                                     ; preds = %cond.end113
  %vecext129 = extractelement <32 x i64> zeroinitializer, i64 0
  br label %cond.end133

cond.end133:                                      ; preds = %cond.true128, %cond.end113
  %vecinit147 = insertelement <32 x i64> %vecinit125, i64 0, i64 0
  %4 = bitcast <32 x i64> %0 to <64 x i32>
  %sh_prom = extractelement <64 x i32> %4, i64 0
  %conv164 = sext i32 %sh_prom to i64
  %vecinit165 = insertelement <32 x i64> %vecinit147, i64 %conv164, i64 0
  %cmp166 = icmp ule <32 x i64> %., %vecinit165
  %sext = sext <32 x i1> %cmp166 to <32 x i64>
  ret <32 x i64> %sext
}

attributes #0 = { "target-features"="+v" }
