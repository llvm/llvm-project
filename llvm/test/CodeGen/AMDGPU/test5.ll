; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 6
; RUN: llc -mtriple=amdgcn -mcpu=gfx1200 -stop-after=amdgpu-early-register-spilling -verify-machineinstrs -print-after=amdgpu-early-register-spilling -max-vgprs=10 < %s 2>&1 | FileCheck %s

;
;       bb.0.entry
;           |
;    bb.1.loop.header<--+
;       /   |           |
;  bb.2.bb1 |           |
;       \   |           |
;      bb.5.Flow        |
;       /   |           |
;  bb.6.bb3 |           |
;       \   |           |
;      bb.3.Flow1       |
;       /   |           |
;  bb.4.bb2 |           |
;       \   |           |
;    bb.7.loop.latch----+
;           |
;       bb.8.exit
;
define amdgpu_ps void @test5(ptr addrspace(1) %p1, ptr addrspace(1) %p2, ptr addrspace(1) %p3, i32 %TC) {
  ; CHECK-LABEL: name: test5
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
  ; CHECK-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:vgpr_32 = COPY $vgpr6
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:vgpr_32 = COPY $vgpr5
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:vgpr_32 = COPY $vgpr4
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:vgpr_32 = COPY $vgpr3
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:vgpr_32 = COPY $vgpr2
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:vgpr_32 = COPY $vgpr1
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:vgpr_32 = COPY $vgpr0
  ; CHECK-NEXT:   [[REG_SEQUENCE:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[COPY2]], %subreg.sub0, [[COPY1]], %subreg.sub1
  ; CHECK-NEXT:   [[REG_SEQUENCE1:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[COPY4]], %subreg.sub0, [[COPY3]], %subreg.sub1
  ; CHECK-NEXT:   [[REG_SEQUENCE2:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[COPY6]], %subreg.sub0, [[COPY5]], %subreg.sub1
  ; CHECK-NEXT:   [[GLOBAL_LOAD_UBYTE:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_UBYTE [[REG_SEQUENCE2]], 0, 0, implicit $exec :: (load (s8) from %ir.p1, addrspace 1)
  ; CHECK-NEXT:   [[GLOBAL_LOAD_UBYTE1:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_UBYTE [[REG_SEQUENCE2]], 1, 0, implicit $exec :: (load (s8) from %ir.p1 + 1, addrspace 1)
  ; CHECK-NEXT:   [[V_LSHL_OR_B32_e64_:%[0-9]+]]:vgpr_32 = V_LSHL_OR_B32_e64 [[GLOBAL_LOAD_UBYTE1]], 8, [[GLOBAL_LOAD_UBYTE]], implicit $exec
  ; CHECK-NEXT:   [[GLOBAL_LOAD_UBYTE2:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_UBYTE [[REG_SEQUENCE2]], 2, 0, implicit $exec :: (load (s8) from %ir.p1 + 2, addrspace 1)
  ; CHECK-NEXT:   [[GLOBAL_LOAD_UBYTE3:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_UBYTE [[REG_SEQUENCE2]], 3, 0, implicit $exec :: (load (s8) from %ir.p1 + 3, addrspace 1)
  ; CHECK-NEXT:   [[V_LSHL_OR_B32_e64_1:%[0-9]+]]:vgpr_32 = V_LSHL_OR_B32_e64 [[GLOBAL_LOAD_UBYTE3]], 8, [[GLOBAL_LOAD_UBYTE2]], implicit $exec
  ; CHECK-NEXT:   [[V_LSHL_OR_B32_e64_2:%[0-9]+]]:vgpr_32 = V_LSHL_OR_B32_e64 [[V_LSHL_OR_B32_e64_1]], 16, [[V_LSHL_OR_B32_e64_]], implicit $exec
  ; CHECK-NEXT:   SI_SPILL_V64_SAVE [[REG_SEQUENCE]], %stack.0, $sgpr32, 0, implicit $exec :: (store (s64) into %stack.0, align 4, addrspace 5)
  ; CHECK-NEXT:   [[S_MOV_B32_:%[0-9]+]]:sreg_32 = S_MOV_B32 0
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1.loop.header:
  ; CHECK-NEXT:   successors: %bb.2(0x40000000), %bb.5(0x40000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:sreg_32 = PHI [[S_MOV_B32_]], %bb.0, %19, %bb.7
  ; CHECK-NEXT:   [[PHI1:%[0-9]+]]:vreg_64 = PHI undef %32:vreg_64, %bb.0, %12, %bb.7
  ; CHECK-NEXT:   [[PHI2:%[0-9]+]]:sreg_32 = PHI [[S_MOV_B32_]], %bb.0, %18, %bb.7
  ; CHECK-NEXT:   [[PHI3:%[0-9]+]]:vgpr_32 = PHI [[V_LSHL_OR_B32_e64_2]], %bb.0, %17, %bb.7
  ; CHECK-NEXT:   [[V_CMP_GE_I32_e64_:%[0-9]+]]:sreg_32 = V_CMP_GE_I32_e64 [[PHI2]], [[V_LSHL_OR_B32_e64_2]], implicit $exec
  ; CHECK-NEXT:   [[V_CMP_LT_I32_e64_:%[0-9]+]]:sreg_32 = V_CMP_LT_I32_e64 [[PHI2]], [[V_LSHL_OR_B32_e64_2]], implicit $exec
  ; CHECK-NEXT:   [[SI_IF:%[0-9]+]]:sreg_32 = SI_IF [[V_CMP_LT_I32_e64_]], %bb.5, implicit-def dead $exec, implicit-def dead $scc, implicit $exec
  ; CHECK-NEXT:   S_BRANCH %bb.2
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.bb1:
  ; CHECK-NEXT:   successors: %bb.5(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[S_ASHR_I32_:%[0-9]+]]:sreg_32_xm0 = S_ASHR_I32 [[PHI2]], 31, implicit-def dead $scc
  ; CHECK-NEXT:   [[REG_SEQUENCE3:%[0-9]+]]:sreg_64 = REG_SEQUENCE [[PHI2]], %subreg.sub0, [[S_ASHR_I32_]], %subreg.sub1
  ; CHECK-NEXT:   [[S_LSHL_B64_:%[0-9]+]]:sreg_64 = nsw S_LSHL_B64 [[REG_SEQUENCE3]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   [[V_ADD_CO_U32_e64_:%[0-9]+]]:vgpr_32, [[V_ADD_CO_U32_e64_1:%[0-9]+]]:sreg_32_xm0_xexec = V_ADD_CO_U32_e64 [[REG_SEQUENCE1]].sub0, [[S_LSHL_B64_]].sub0, 0, implicit $exec
  ; CHECK-NEXT:   %92:vgpr_32, dead $sgpr_null = V_ADDC_U32_e64 [[S_LSHL_B64_]].sub1, [[REG_SEQUENCE1]].sub1, [[V_ADD_CO_U32_e64_1]], 0, implicit $exec
  ; CHECK-NEXT:   [[REG_SEQUENCE4:%[0-9]+]]:vreg_64 = REG_SEQUENCE [[V_ADD_CO_U32_e64_]], %subreg.sub0, %92, %subreg.sub1
  ; CHECK-NEXT:   [[GLOBAL_LOAD_DWORD:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_DWORD [[REG_SEQUENCE4]], 0, 0, implicit $exec :: (load (s32) from %ir.gep, addrspace 1)
  ; CHECK-NEXT:   [[V_CMP_LE_I32_e64_:%[0-9]+]]:sreg_32 = V_CMP_LE_I32_e64 [[GLOBAL_LOAD_DWORD]], [[V_LSHL_OR_B32_e64_2]], implicit $exec
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:sreg_32 = COPY $exec_lo
  ; CHECK-NEXT:   [[S_ANDN2_B32_:%[0-9]+]]:sreg_32 = S_ANDN2_B32 [[V_CMP_GE_I32_e64_]], $exec_lo, implicit-def dead $scc
  ; CHECK-NEXT:   [[S_AND_B32_:%[0-9]+]]:sreg_32 = S_AND_B32 [[V_CMP_LE_I32_e64_]], $exec_lo, implicit-def dead $scc
  ; CHECK-NEXT:   [[S_OR_B32_:%[0-9]+]]:sreg_32 = S_OR_B32 [[S_ANDN2_B32_]], [[S_AND_B32_]], implicit-def dead $scc
  ; CHECK-NEXT:   S_BRANCH %bb.5
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.Flow1:
  ; CHECK-NEXT:   successors: %bb.4(0x40000000), %bb.7(0x40000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PHI4:%[0-9]+]]:sreg_32 = PHI %13, %bb.5, %82, %bb.6
  ; CHECK-NEXT:   [[PHI5:%[0-9]+]]:vgpr_32 = PHI undef %61:vgpr_32, %bb.5, %16, %bb.6
  ; CHECK-NEXT:   SI_END_CF %15, implicit-def dead $exec, implicit-def dead $scc, implicit $exec
  ; CHECK-NEXT:   [[SI_IF1:%[0-9]+]]:sreg_32 = SI_IF [[PHI4]], %bb.7, implicit-def dead $exec, implicit-def dead $scc, implicit $exec
  ; CHECK-NEXT:   S_BRANCH %bb.4
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.4.bb2:
  ; CHECK-NEXT:   successors: %bb.7(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   GLOBAL_STORE_DWORD %12, [[PHI3]], 0, 0, implicit $exec :: (store (s32) into %ir.9, addrspace 1)
  ; CHECK-NEXT:   [[V_MOV_B32_e32_:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 1, implicit $exec
  ; CHECK-NEXT:   S_BRANCH %bb.7
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.5.Flow:
  ; CHECK-NEXT:   successors: %bb.6(0x40000000), %bb.3(0x40000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PHI6:%[0-9]+]]:sreg_32 = PHI [[V_CMP_GE_I32_e64_]], %bb.1, [[S_OR_B32_]], %bb.2
  ; CHECK-NEXT:   [[PHI7:%[0-9]+]]:sreg_32 = PHI [[S_MOV_B32_]], %bb.1, [[COPY7]], %bb.2
  ; CHECK-NEXT:   [[PHI8:%[0-9]+]]:vreg_64 = PHI [[PHI1]], %bb.1, [[REG_SEQUENCE4]], %bb.2
  ; CHECK-NEXT:   SI_END_CF [[SI_IF]], implicit-def dead $exec, implicit-def dead $scc, implicit $exec
  ; CHECK-NEXT:   [[SI_IF2:%[0-9]+]]:sreg_32 = SI_IF [[PHI6]], %bb.3, implicit-def dead $exec, implicit-def dead $scc, implicit $exec
  ; CHECK-NEXT:   S_BRANCH %bb.6
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.6.bb3:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[V_LSHRREV_B32_e64_:%[0-9]+]]:vgpr_32 = V_LSHRREV_B32_e64 31, [[PHI3]], implicit $exec
  ; CHECK-NEXT:   [[V_ADD_U32_e64_:%[0-9]+]]:vgpr_32 = V_ADD_U32_e64 [[PHI3]], [[V_LSHRREV_B32_e64_]], 0, implicit $exec
  ; CHECK-NEXT:   [[V_ASHRREV_I32_e64_:%[0-9]+]]:vgpr_32 = V_ASHRREV_I32_e64 1, [[V_ADD_U32_e64_]], implicit $exec
  ; CHECK-NEXT:   [[S_ANDN2_B32_1:%[0-9]+]]:sreg_32 = S_ANDN2_B32 [[PHI7]], $exec_lo, implicit-def dead $scc
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:sreg_32 = COPY [[S_ANDN2_B32_1]]
  ; CHECK-NEXT:   S_BRANCH %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.7.loop.latch:
  ; CHECK-NEXT:   successors: %bb.8(0x04000000), %bb.1(0x7c000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PHI9:%[0-9]+]]:vgpr_32 = PHI [[PHI5]], %bb.3, [[V_MOV_B32_e32_]], %bb.4
  ; CHECK-NEXT:   SI_END_CF [[SI_IF1]], implicit-def dead $exec, implicit-def dead $scc, implicit $exec
  ; CHECK-NEXT:   [[S_ADD_I32_:%[0-9]+]]:sreg_32 = S_ADD_I32 [[PHI2]], 1, implicit-def dead $scc
  ; CHECK-NEXT:   [[V_CMP_GE_U32_e64_:%[0-9]+]]:sreg_32 = V_CMP_GE_U32_e64 [[S_ADD_I32_]], [[COPY]], implicit $exec
  ; CHECK-NEXT:   [[SI_IF_BREAK:%[0-9]+]]:sreg_32 = SI_IF_BREAK [[V_CMP_GE_U32_e64_]], [[PHI]], implicit-def dead $scc
  ; CHECK-NEXT:   SI_LOOP [[SI_IF_BREAK]], %bb.1, implicit-def dead $exec, implicit-def dead $scc, implicit $exec
  ; CHECK-NEXT:   S_BRANCH %bb.8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.8.exit:
  ; CHECK-NEXT:   SI_END_CF [[SI_IF_BREAK]], implicit-def dead $exec, implicit-def dead $scc, implicit $exec
  ; CHECK-NEXT:   [[SI_SPILL_V64_RESTORE:%[0-9]+]]:vreg_64 = SI_SPILL_V64_RESTORE %stack.0, $sgpr32, 0, implicit $exec :: (load (s64) from %stack.0, align 4, addrspace 5)
  ; CHECK-NEXT:   GLOBAL_STORE_DWORD [[SI_SPILL_V64_RESTORE]], [[PHI9]], 0, 0, implicit $exec :: (store (s32) into %ir.p3, addrspace 1)
  ; CHECK-NEXT:   S_ENDPGM 0
entry:
;     entry
;       |
;   loop.header<-+
;    |    |      |
;   bb1   |      |
;    | \  |      |
;   bb2 bb3      |
;    |   |       |
;   loop.latch---+
;       |
;      exit
   %ld1 = load i32, ptr addrspace(1) %p1, align 1
   br label %loop.header

loop.header:
   %phi.inc = phi i32 [ 0, %entry ], [ %inc, %loop.latch ]
   %phi1 = phi i32 [ %ld1, %entry ], [ %phi2, %loop.latch ]
   %cond1 = icmp slt i32 %phi.inc, %ld1
   br i1 %cond1, label %bb1, label %bb3

bb1:
   %sext = sext i32 %phi.inc to i64
   %gep = getelementptr inbounds i32, ptr addrspace(1) %p2, i64 %sext
   %ld2 = load i32, ptr addrspace(1) %gep, align 4
   %cond2 = icmp sgt i32 %ld2, %ld1
   br i1 %cond2, label %bb2, label %bb3

bb2:
   store i32 %phi1, ptr addrspace(1) %gep, align 4
   br label %loop.latch

bb3:
   %div = sdiv i32 %phi1, 2
   br label %loop.latch

loop.latch:
   %phi2 = phi i32 [ 1, %bb2 ], [ %div, %bb3 ]
   %inc = add i32 %phi.inc, 1
   %cond3 = icmp ult i32 %inc, %TC
   br i1 %cond3, label %loop.header, label %exit

exit:
   store i32 %phi2, ptr addrspace(1) %p3, align 4
   ret void
}
