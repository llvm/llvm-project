; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5

; RUN: llc -mtriple=amdgcn-amd-amdpal -mcpu=gfx1030 < %s | FileCheck -check-prefixes=GFX10 %s
; RUN: llc -mtriple=amdgcn-amd-amdpal -mcpu=gfx1030 -amdgpu-enable-diff-baseptr-mem-clustering=false < %s | FileCheck -check-prefixes=GFX10N %s
define amdgpu_kernel void @compute_mad(ptr addrspace(4) %i18, ptr addrspace(4) %i21, ptr addrspace(1) nocapture noundef writeonly align 4 %arg, i32 noundef %arg1) #1 {
; GFX10-LABEL: compute_mad:
; GFX10:       ; %bb.0: ; %bb
; GFX10-NEXT:    s_clause 0x2
; GFX10-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x0
; GFX10-NEXT:    s_load_dword s6, s[4:5], 0x18
; GFX10-NEXT:    s_load_dwordx2 s[4:5], s[4:5], 0x10
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    s_clause 0x1
; GFX10-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x0
; GFX10-NEXT:    s_load_dword s2, s[2:3], 0x4
; GFX10-NEXT:    s_add_i32 s6, s6, 1
; GFX10-NEXT:    v_mul_lo_u32 v1, s6, v0
; GFX10-NEXT:    v_add_nc_u32_e32 v2, s6, v1
; GFX10-NEXT:    v_add_nc_u32_e32 v1, 1, v1
; GFX10-NEXT:    v_mul_lo_u32 v2, v2, v0
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    s_and_b32 s2, s2, 0xffff
; GFX10-NEXT:    v_mul_lo_u32 v3, v2, v1
; GFX10-NEXT:    v_add_nc_u32_e32 v1, v3, v1
; GFX10-NEXT:    v_mul_lo_u32 v2, v1, v2
; GFX10-NEXT:    v_add_nc_u32_e32 v1, 1, v3
; GFX10-NEXT:    v_mul_lo_u32 v4, v2, v1
; GFX10-NEXT:    v_add_nc_u32_e32 v3, v4, v1
; GFX10-NEXT:    v_mad_u64_u32 v[0:1], null, s8, s2, v[0:1]
; GFX10-NEXT:    v_mul_lo_u32 v1, v3, v2
; GFX10-NEXT:    v_add_co_u32 v2, s0, s0, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, null, s1, 0, s0
; GFX10-NEXT:    v_mad_u64_u32 v[4:5], null, v1, v4, v[1:2]
; GFX10-NEXT:    v_lshlrev_b64 v[2:3], 2, v[2:3]
; GFX10-NEXT:    v_mad_u64_u32 v[0:1], null, v4, v1, v[4:5]
; GFX10-NEXT:    v_add_co_u32 v1, vcc_lo, s4, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v2, null, s5, v3, vcc_lo
; GFX10-NEXT:    global_store_dword v[1:2], v0, off
; GFX10-NEXT:    s_endpgm
;
; GFX10N-LABEL: compute_mad:
; GFX10N:       ; %bb.0: ; %bb
; GFX10N-NEXT:    s_load_dword s0, s[4:5], 0x18
; GFX10N-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10N-NEXT:    s_add_i32 s0, s0, 1
; GFX10N-NEXT:    v_mul_lo_u32 v1, s0, v0
; GFX10N-NEXT:    v_add_nc_u32_e32 v2, s0, v1
; GFX10N-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x0
; GFX10N-NEXT:    v_add_nc_u32_e32 v1, 1, v1
; GFX10N-NEXT:    s_load_dwordx2 s[4:5], s[4:5], 0x10
; GFX10N-NEXT:    v_mul_lo_u32 v2, v2, v0
; GFX10N-NEXT:    v_mul_lo_u32 v3, v2, v1
; GFX10N-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10N-NEXT:    s_load_dword s2, s[2:3], 0x4
; GFX10N-NEXT:    v_add_nc_u32_e32 v1, v3, v1
; GFX10N-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x0
; GFX10N-NEXT:    v_mul_lo_u32 v2, v1, v2
; GFX10N-NEXT:    v_add_nc_u32_e32 v1, 1, v3
; GFX10N-NEXT:    v_mul_lo_u32 v4, v2, v1
; GFX10N-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10N-NEXT:    s_and_b32 s2, s2, 0xffff
; GFX10N-NEXT:    v_add_nc_u32_e32 v3, v4, v1
; GFX10N-NEXT:    v_mad_u64_u32 v[0:1], null, s8, s2, v[0:1]
; GFX10N-NEXT:    v_mul_lo_u32 v1, v3, v2
; GFX10N-NEXT:    v_add_co_u32 v2, s0, s0, v0
; GFX10N-NEXT:    v_add_co_ci_u32_e64 v3, null, s1, 0, s0
; GFX10N-NEXT:    v_mad_u64_u32 v[4:5], null, v1, v4, v[1:2]
; GFX10N-NEXT:    v_lshlrev_b64 v[2:3], 2, v[2:3]
; GFX10N-NEXT:    v_mad_u64_u32 v[0:1], null, v4, v1, v[4:5]
; GFX10N-NEXT:    v_add_co_u32 v1, vcc_lo, s4, v2
; GFX10N-NEXT:    v_add_co_ci_u32_e64 v2, null, s5, v3, vcc_lo
; GFX10N-NEXT:    global_store_dword v[1:2], v0, off
; GFX10N-NEXT:    s_endpgm
bb:
  %i = tail call i32 @llvm.amdgcn.workitem.id.x(), !range !0
  %i2 = add i32 %arg1, 1
  %i3 = mul i32 %i2, %i
  %i4 = add i32 %i3, %i2
  %i5 = mul i32 %i4, %i
  %i6 = add i32 %i3, 1
  %i7 = mul i32 %i5, %i6
  %i8 = add i32 %i7, %i6
  %i9 = mul i32 %i8, %i5
  %i10 = add i32 %i7, 1
  %i11 = mul i32 %i9, %i10
  %i12 = add i32 %i11, %i10
  %i13 = mul i32 %i12, %i9
  %i14 = add i32 %i11, 1
  %i15 = add i32 %i13, 1
  %i16 = mul i32 %i13, %i14
  %i17 = mul i32 %i16, %i15
  %i19 = load i64, ptr addrspace(4) %i18, align 8
  %i20 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %i22 = getelementptr i8, ptr addrspace(4) %i21, i64 4
  %i23 = load i16, ptr addrspace(4) %i22, align 4
  %i24 = zext i16 %i23 to i32
  %i25 = mul i32 %i20, %i24
  %i26 = add i32 %i25, %i
  %i27 = zext i32 %i26 to i64
  %i28 = add i64 %i19, %i27
  %i29 = getelementptr inbounds i32, ptr addrspace(1) %arg, i64 %i28
  store i32 %i17, ptr addrspace(1) %i29, align 4
  ret void
}

declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #2
declare i32 @llvm.amdgcn.workitem.id.x() #2
declare align 4 ptr addrspace(4) @llvm.amdgcn.dispatch.ptr() #2
declare i32 @llvm.amdgcn.workgroup.id.x() #2
declare i64 @llvm.amdgcn.mul.u24(i32, i32)
declare i64 @llvm.amdgcn.mul.i24(i32, i32)

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(none) }
attributes #1 = { mustprogress nofree nosync nounwind willreturn memory(read, argmem: readwrite, inaccessiblemem: none) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!0 = !{i32 0, i32 1024}
