; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -march=amdgcn -mcpu=gfx1300 -verify-machineinstrs < %s | FileCheck %s --check-prefix=GFX13

define amdgpu_ps void @test_swmma_f32_16x16x32_iu8_clamp(<2 x i32> %A, <4 x i32> %B, <8 x float> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32_16x16x32_iu8_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32_16x16_iu8 v[6:13], v[0:1], v[2:5], v[6:13], v14 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[15:16], v[10:13], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[15:16], v[6:9], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32.16x16x32.iu8.clamp(i1 1, <2 x i32> %A, i1 1, <4 x i32> %B, <8 x float> %C, i32 %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32i32_16x16x32_iu8_clamp(<2 x i32> %A, <4 x i32> %B, <8 x i32> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32i32_16x16x32_iu8_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32i32_16x16_iu8 v[6:13], v[0:1], v[2:5], v[6:13], v14 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[15:16], v[10:13], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[15:16], v[6:9], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32i32.16x16x32.iu8.clamp(i1 1, <2 x i32> %A, i1 1, <4 x i32> %B, <8 x i32> %C, i32 %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_i32_16x16x32_iu8_clamp(<2 x i32> %A, <4 x i32> %B, <8 x i32> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_i32_16x16x32_iu8_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_i32_16x16_iu8 v[6:13], v[0:1], v[2:5], v[6:13], v14 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[15:16], v[10:13], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[15:16], v[6:9], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.swmma.i32.16x16x32.iu8.clamp(i1 1, <2 x i32> %A, i1 1, <4 x i32> %B, <8 x i32> %C, i32 %Index, i1 1, i1 1)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32_16x16x32_iu4_clamp(i32 %A, <2 x i32> %B, <8 x float> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32_16x16x32_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32_16x16_iu4 v[3:10], v0, v[1:2], v[3:10], v11 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[12:13], v[7:10], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[12:13], v[3:6], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32.16x16x32.iu4.clamp(i1 1, i32 %A, i1 1, <2 x i32> %B, <8 x float> %C, i32 %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32i32_16x16x32_iu4_clamp(i32 %A, <2 x i32> %B, <8 x i32> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32i32_16x16x32_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32i32_16x16_iu4 v[3:10], v0, v[1:2], v[3:10], v11 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[12:13], v[7:10], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[12:13], v[3:6], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32i32.16x16x32.iu4.clamp(i1 1, i32 %A, i1 1, <2 x i32> %B, <8 x i32> %C, i32 %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_i32_16x16x32_iu4_clamp(i32 %A, <2 x i32> %B, <8 x i32> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_i32_16x16x32_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_i32_16x16_iu4 v[3:10], v0, v[1:2], v[3:10], v11 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[12:13], v[7:10], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[12:13], v[3:6], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.swmma.i32.16x16x32.iu4.clamp(i1 1, i32 %A, i1 1, <2 x i32> %B, <8 x i32> %C, i32 %Index, i1 1, i1 1)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32_16x16x64_iu8_clamp(<4 x i32> %A, <8 x i32> %B, <8 x float> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32_16x16x64_iu8_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32_16x16_iu8 v[12:19], v[0:3], v[4:11], v[12:19], v20 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[21:22], v[16:19], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[21:22], v[12:15], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32.16x16x64.iu8.clamp(i1 1, <4 x i32> %A, i1 1, <8 x i32> %B, <8 x float> %C, i32 %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32i32_16x16x64_iu8_clamp(<4 x i32> %A, <8 x i32> %B, <8 x i32> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32i32_16x16x64_iu8_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32i32_16x16_iu8 v[12:19], v[0:3], v[4:11], v[12:19], v20 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[21:22], v[16:19], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[21:22], v[12:15], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32i32.16x16x64.iu8.clamp(i1 1, <4 x i32> %A, i1 1, <8 x i32> %B, <8 x i32> %C, i32 %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_i32_16x16x64_iu8_clamp(<4 x i32> %A, <8 x i32> %B, <8 x i32> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_i32_16x16x64_iu8_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_i32_16x16_iu8 v[12:19], v[0:3], v[4:11], v[12:19], v20 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[21:22], v[16:19], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[21:22], v[12:15], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.swmma.i32.16x16x64.iu8.clamp(i1 1, <4 x i32> %A, i1 1, <8 x i32> %B, <8 x i32> %C, i32 %Index, i1 1, i1 1)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32_16x16x64_iu4_clamp(<2 x i32> %A, <4 x i32> %B, <8 x float> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32_16x16x64_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32_16x16_iu4 v[6:13], v[0:1], v[2:5], v[6:13], v14 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[15:16], v[10:13], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[15:16], v[6:9], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32.16x16x64.iu4.clamp(i1 1, <2 x i32> %A, i1 1, <4 x i32> %B, <8 x float> %C, i32 %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32i32_16x16x64_iu4_clamp(<2 x i32> %A, <4 x i32> %B, <8 x i32> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32i32_16x16x64_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32i32_16x16_iu4 v[6:13], v[0:1], v[2:5], v[6:13], v14 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[15:16], v[10:13], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[15:16], v[6:9], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32i32.16x16x64.iu4.clamp(i1 1, <2 x i32> %A, i1 1, <4 x i32> %B, <8 x i32> %C, i32 %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_i32_16x16x64_iu4_clamp(<2 x i32> %A, <4 x i32> %B, <8 x i32> %C, i32 %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_i32_16x16x64_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_i32_16x16_iu4 v[6:13], v[0:1], v[2:5], v[6:13], v14 signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[15:16], v[10:13], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[15:16], v[6:9], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.swmma.i32.16x16x64.iu4.clamp(i1 1, <2 x i32> %A, i1 1, <4 x i32> %B, <8 x i32> %C, i32 %Index, i1 1, i1 1)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32_16x16x128_iu4_clamp(<4 x i32> %A, <8 x i32> %B, <8 x float> %C, <2 x i32> %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32_16x16x128_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32_16x16_iu4 v[12:19], v[0:3], v[4:11], v[12:19], v[20:21] signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[22:23], v[16:19], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[22:23], v[12:15], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32.16x16x128.iu4.clamp(i1 1, <4 x i32> %A, i1 1, <8 x i32> %B, <8 x float> %C, <2 x i32> %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_f32i32_16x16x128_iu4_clamp(<4 x i32> %A, <8 x i32> %B, <8 x i32> %C, <2 x i32> %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_f32i32_16x16x128_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_f32i32_16x16_iu4 v[12:19], v[0:3], v[4:11], v[12:19], v[20:21] signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[22:23], v[16:19], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[22:23], v[12:15], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmma.f32i32.16x16x128.iu4.clamp(i1 1, <4 x i32> %A, i1 1, <8 x i32> %B, <8 x i32> %C, <2 x i32> %Index, i1 1, i1 1)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}
define amdgpu_ps void @test_swmma_i32_16x16x128_iu4_clamp(<4 x i32> %A, <8 x i32> %B, <8 x i32> %C, <2 x i32> %Index, ptr addrspace(1) %out) {
; GFX13-LABEL: test_swmma_i32_16x16x128_iu4_clamp:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_swmma_i32_16x16_iu4 v[12:19], v[0:3], v[4:11], v[12:19], v[20:21] signed_a signed_b sparse_index_odd clamp
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    global_store_b128 v[22:23], v[16:19], off offset:16 scope:SCOPE_SE
; GFX13-NEXT:    global_store_b128 v[22:23], v[12:15], off scope:SCOPE_SE
; GFX13-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.swmma.i32.16x16x128.iu4.clamp(i1 1, <4 x i32> %A, i1 1, <8 x i32> %B, <8 x i32> %C, <2 x i32> %Index, i1 1, i1 1)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}
