; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn -mcpu=gfx1200 < %s | FileCheck -check-prefix=GCN %s

declare i32 @llvm.amdgcn.atomic.cond.sub.u32.p1(ptr addrspace(1), i32)


define amdgpu_kernel void @test_isel_single_lane(ptr addrspace(1) %in, ptr addrspace(1) %out) #0 {
; GCN-LABEL: test_isel_single_lane:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GCN-NEXT:    s_wait_kmcnt 0x0
; GCN-NEXT:    s_load_b32 s4, s[0:1], 0x58
; GCN-NEXT:    s_wait_kmcnt 0x0
; GCN-NEXT:    v_dual_mov_b32 v0, 0 :: v_dual_mov_b32 v1, s4
; GCN-NEXT:    global_atomic_cond_sub_u32 v1, v0, v1, s[0:1] offset:16 th:TH_ATOMIC_RETURN
; GCN-NEXT:    s_wait_loadcnt 0x0
; GCN-NEXT:    v_readfirstlane_b32 s0, v1
; GCN-NEXT:    s_addk_co_i32 s0, 0xf4
; GCN-NEXT:    s_delay_alu instid0(SALU_CYCLE_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GCN-NEXT:    s_lshl_b32 s1, s0, 4
; GCN-NEXT:    s_mul_i32 s0, s0, s1
; GCN-NEXT:    s_delay_alu instid0(SALU_CYCLE_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GCN-NEXT:    s_lshl_b32 s0, s0, 12
; GCN-NEXT:    s_sub_co_i32 s0, s1, s0
; GCN-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GCN-NEXT:    v_mov_b32_e32 v1, s0
; GCN-NEXT:    global_store_b32 v0, v1, s[2:3]
; GCN-NEXT:    s_endpgm
        %gep0 = getelementptr i32, ptr addrspace(1) %in, i32 22
        %val0 = load i32, ptr addrspace(1) %gep0, align 4
        %gep1 = getelementptr i32, ptr addrspace(1) %in, i32 4
        %val1 = call i32 @llvm.amdgcn.atomic.cond.sub.u32.p0(ptr addrspace(1) %gep1, i32 %val0)
        %res0 = add i32 %val1, 244
        %res1 = shl i32 %res0, 4
        %res2 = mul i32 %res0, %res1
        %res3 = shl i32 %res2, 12
        %res4 = sub i32 %res1, %res3
        store i32 %res4, ptr addrspace(1) %out
        ret void
}


attributes #0 = {
  "amdgpu-flat-work-group-size"="1,1"
  "amdgpu-waves-per-eu"="1,1"
  "uniform-work-group-size"="true"
}
