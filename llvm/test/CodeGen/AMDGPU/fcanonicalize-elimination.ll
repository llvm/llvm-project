; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc -mtriple=amdgcn -mcpu=gfx801 -denormal-fp-math-f32=preserve-sign < %s | FileCheck -enable-var-scope -check-prefixes=GCN,VI,VI-FLUSH,GCN-FLUSH %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx801 -denormal-fp-math-f32=ieee < %s | FileCheck -enable-var-scope -check-prefixes=GCN,VI,VI-DENORM,GCN-DENORM %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx900 -denormal-fp-math-f32=ieee < %s | FileCheck -enable-var-scope -check-prefixes=GCN,GFX9,GFX9-DENORM,GCN-DENORM %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx900 -denormal-fp-math-f32=preserve-sign < %s | FileCheck -enable-var-scope -check-prefixes=GCN,GFX9,GFX9-FLUSH,GCN-FLUSH %s

; GCN-LABEL: {{^}}test_no_fold_canonicalize_loaded_value_f32:
; VI: v_mul_f32_e32 v{{[0-9]+}}, 1.0, v{{[0-9]+}}
; GFX9: v_max_f32_e32 v{{[0-9]+}}, v{{[0-9]+}}, v{{[0-9]+}}
define amdgpu_kernel void @test_no_fold_canonicalize_loaded_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_no_fold_canonicalize_loaded_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, 1.0, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_no_fold_canonicalize_loaded_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %v = load float, ptr addrspace(1) %gep, align 4
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: {{^}}test_fold_canonicalize_fmul_value_f32:
; GCN: v_mul_f32_e32 [[V:v[0-9]+]], 0x41700000, v{{[0-9]+}}
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
; GCN-NOT: 1.0
define amdgpu_kernel void @test_fold_canonicalize_fmul_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_fmul_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, 0x41700000, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fmul_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mul_f32_e32 v1, 0x41700000, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = fmul float %load, 15.0
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: {{^}}test_fold_canonicalize_fmul_legacy_value_f32:
; GCN: v_mul_legacy_f32_e32 [[V:v[0-9]+]], 0x41700000, v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fmul_legacy_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_fmul_legacy_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_legacy_f32_e32 v2, 0x41700000, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fmul_legacy_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mul_legacy_f32_e32 v1, 0x41700000, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = call float @llvm.amdgcn.fmul.legacy(float %load, float 15.0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: {{^}}test_fold_canonicalize_sub_value_f32:
; GCN: v_sub_f32_e32 [[V:v[0-9]+]], 0x41700000, v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_sub_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_sub_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_sub_f32_e32 v2, 0x41700000, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_sub_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_sub_f32_e32 v1, 0x41700000, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = fsub float 15.0, %load
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: {{^}}test_fold_canonicalize_add_value_f32:
; GCN: v_add_f32_e32 [[V:v[0-9]+]], 0x41700000, v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_add_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_add_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_add_f32_e32 v2, 0x41700000, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_add_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_add_f32_e32 v1, 0x41700000, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = fadd float %load, 15.0
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: {{^}}test_fold_canonicalize_sqrt_value_f32:
; GCN: v_sqrt_f32_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_sqrt_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_sqrt_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_sqrt_f32_e32 v2, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_sqrt_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_sqrt_f32_e32 v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = call afn float @llvm.sqrt.f32(float %load)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fceil_value_f32:
; GCN: v_ceil_f32_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fceil_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_fceil_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_ceil_f32_e32 v2, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fceil_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_ceil_f32_e32 v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = call float @llvm.ceil.f32(float %load)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_floor_value_f32:
; GCN: v_floor_f32_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_floor_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_floor_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_floor_f32_e32 v2, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_floor_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_floor_f32_e32 v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = call float @llvm.floor.f32(float %load)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fma_value_f32:
; GCN: s_mov_b32 [[SREG:s[0-9]+]], 0x41700000
; GCN: v_fma_f32 [[V:v[0-9]+]], v{{[0-9]+}}, [[SREG]], [[SREG]]
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fma_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_fma_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_mov_b32 s0, 0x41700000
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_fma_f32 v2, v2, s0, s0
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fma_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_mov_b32 s2, 0x41700000
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_fma_f32 v1, v1, s2, s2
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = call float @llvm.fma.f32(float %load, float 15.0, float 15.0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fmad_ftz_value_f32:
; GCN: v_mac_f32_e32 [[V:v[0-9]+]], 0x41700000, v{{[0-9]+$}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fmad_ftz_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_fmad_ftz_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    v_mov_b32_e32 v3, 0x41700000
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mac_f32_e32 v3, 0x41700000, v2
; VI-NEXT:    flat_store_dword v[0:1], v3
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fmad_ftz_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    v_mov_b32_e32 v2, 0x41700000
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mac_f32_e32 v2, 0x41700000, v1
; GFX9-NEXT:    global_store_dword v0, v2, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = call float @llvm.amdgcn.fmad.ftz.f32(float %load, float 15.0, float 15.0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fmuladd_value_f32:
; GCN-FLUSH: v_mac_f32_e32 [[V:v[0-9]+]], 0x41700000, v{{[0-9]+}}
; GCN-DENORM: s_mov_b32 [[SREG:s[0-9]+]], 0x41700000
; GCN-DENORM: v_fma_f32 [[V:v[0-9]+]], v{{[0-9]+}}, [[SREG]], [[SREG]]
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
; GCN-NOT: 1.0
define amdgpu_kernel void @test_fold_canonicalize_fmuladd_value_f32(ptr addrspace(1) %arg) {
; VI-FLUSH-LABEL: test_fold_canonicalize_fmuladd_value_f32:
; VI-FLUSH:       ; %bb.0:
; VI-FLUSH-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-FLUSH-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-FLUSH-NEXT:    v_mov_b32_e32 v3, 0x41700000
; VI-FLUSH-NEXT:    s_waitcnt lgkmcnt(0)
; VI-FLUSH-NEXT:    v_mov_b32_e32 v1, s1
; VI-FLUSH-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-FLUSH-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-FLUSH-NEXT:    flat_load_dword v2, v[0:1]
; VI-FLUSH-NEXT:    s_waitcnt vmcnt(0)
; VI-FLUSH-NEXT:    v_mac_f32_e32 v3, 0x41700000, v2
; VI-FLUSH-NEXT:    flat_store_dword v[0:1], v3
; VI-FLUSH-NEXT:    s_endpgm
;
; VI-DENORM-LABEL: test_fold_canonicalize_fmuladd_value_f32:
; VI-DENORM:       ; %bb.0:
; VI-DENORM-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-DENORM-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-DENORM-NEXT:    s_waitcnt lgkmcnt(0)
; VI-DENORM-NEXT:    v_mov_b32_e32 v1, s1
; VI-DENORM-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-DENORM-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-DENORM-NEXT:    flat_load_dword v2, v[0:1]
; VI-DENORM-NEXT:    s_mov_b32 s0, 0x41700000
; VI-DENORM-NEXT:    s_waitcnt vmcnt(0)
; VI-DENORM-NEXT:    v_fma_f32 v2, v2, s0, s0
; VI-DENORM-NEXT:    flat_store_dword v[0:1], v2
; VI-DENORM-NEXT:    s_endpgm
;
; GFX9-DENORM-LABEL: test_fold_canonicalize_fmuladd_value_f32:
; GFX9-DENORM:       ; %bb.0:
; GFX9-DENORM-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-DENORM-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-DENORM-NEXT:    s_mov_b32 s2, 0x41700000
; GFX9-DENORM-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-DENORM-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-DENORM-NEXT:    s_waitcnt vmcnt(0)
; GFX9-DENORM-NEXT:    v_fma_f32 v1, v1, s2, s2
; GFX9-DENORM-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-DENORM-NEXT:    s_endpgm
;
; GFX9-FLUSH-LABEL: test_fold_canonicalize_fmuladd_value_f32:
; GFX9-FLUSH:       ; %bb.0:
; GFX9-FLUSH-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-FLUSH-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-FLUSH-NEXT:    v_mov_b32_e32 v2, 0x41700000
; GFX9-FLUSH-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-FLUSH-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-FLUSH-NEXT:    s_waitcnt vmcnt(0)
; GFX9-FLUSH-NEXT:    v_mac_f32_e32 v2, 0x41700000, v1
; GFX9-FLUSH-NEXT:    global_store_dword v0, v2, s[0:1]
; GFX9-FLUSH-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = call float @llvm.fmuladd.f32(float %load, float 15.0, float 15.0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_canonicalize_value_f32:
; GCN: {{flat|global}}_load_dword [[LOAD:v[0-9]+]],
; VI:  v_mul_f32_e32 [[V:v[0-9]+]], 1.0, [[LOAD]]
; GFX9: v_max_f32_e32 [[V:v[0-9]+]], [[LOAD]], [[LOAD]]

; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_canonicalize_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_canonicalize_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, 1.0, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_canonicalize_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = call float @llvm.canonicalize.f32(float %load)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fpextend_value_f64_f32:
; GCN: v_cvt_f64_f32_e32 [[V:v\[[0-9]+:[0-9]+\]]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dwordx2 v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fpextend_value_f64_f32(ptr addrspace(1) %arg, ptr addrspace(1) %out) {
; VI-LABEL: test_fold_canonicalize_fpextend_value_f64_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v1, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v2, s1
; VI-NEXT:    v_add_u32_e32 v1, vcc, s0, v1
; VI-NEXT:    v_addc_u32_e32 v2, vcc, 0, v2, vcc
; VI-NEXT:    flat_load_dword v1, v[1:2]
; VI-NEXT:    v_lshlrev_b32_e32 v2, 3, v0
; VI-NEXT:    v_mov_b32_e32 v3, s3
; VI-NEXT:    v_add_u32_e32 v2, vcc, s2, v2
; VI-NEXT:    v_addc_u32_e32 v3, vcc, 0, v3, vcc
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_cvt_f64_f32_e32 v[0:1], v1
; VI-NEXT:    flat_store_dwordx2 v[2:3], v[0:1]
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fpextend_value_f64_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v1, 2, v0
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 3, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v1, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cvt_f64_f32_e32 v[1:2], v1
; GFX9-NEXT:    global_store_dwordx2 v0, v[1:2], s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = fpext float %load to double
  %canonicalized = tail call double @llvm.canonicalize.f64(double %v)
  %gep2 = getelementptr inbounds double, ptr addrspace(1) %out, i32 %id
  store double %canonicalized, ptr addrspace(1) %gep2, align 8
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fpextend_value_f32_f16:
; GCN: v_cvt_f32_f16_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fpextend_value_f32_f16(ptr addrspace(1) %arg, ptr addrspace(1) %out) {
; VI-LABEL: test_fold_canonicalize_fpextend_value_f32_f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v1, 1, v0
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v2, s1
; VI-NEXT:    v_add_u32_e32 v1, vcc, s0, v1
; VI-NEXT:    v_addc_u32_e32 v2, vcc, 0, v2, vcc
; VI-NEXT:    flat_load_ushort v1, v[1:2]
; VI-NEXT:    v_mov_b32_e32 v2, s3
; VI-NEXT:    v_add_u32_e32 v0, vcc, s2, v0
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_cvt_f32_f16_e32 v3, v1
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v2, vcc
; VI-NEXT:    flat_store_dword v[0:1], v3
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fpextend_value_f32_f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v1, 1, v0
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_ushort v1, v1, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cvt_f32_f16_e32 v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds half, ptr addrspace(1) %arg, i32 %id
  %load = load half, ptr addrspace(1) %gep, align 2
  %v = fpext half %load to float
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  %gep2 = getelementptr inbounds float, ptr addrspace(1) %out, i32 %id
  store float %canonicalized, ptr addrspace(1) %gep2, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fpextend_value_f32_f16_flushf16:
; GCN: v_cvt_f32_f16_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fpextend_value_f32_f16_flushf16(ptr addrspace(1) %arg, ptr addrspace(1) %out) #2 {
; VI-LABEL: test_fold_canonicalize_fpextend_value_f32_f16_flushf16:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v1, 1, v0
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v2, s1
; VI-NEXT:    v_add_u32_e32 v1, vcc, s0, v1
; VI-NEXT:    v_addc_u32_e32 v2, vcc, 0, v2, vcc
; VI-NEXT:    flat_load_ushort v1, v[1:2]
; VI-NEXT:    v_mov_b32_e32 v2, s3
; VI-NEXT:    v_add_u32_e32 v0, vcc, s2, v0
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_cvt_f32_f16_e32 v3, v1
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v2, vcc
; VI-NEXT:    flat_store_dword v[0:1], v3
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fpextend_value_f32_f16_flushf16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v1, 1, v0
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_ushort v1, v1, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cvt_f32_f16_e32 v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds half, ptr addrspace(1) %arg, i32 %id
  %load = load half, ptr addrspace(1) %gep, align 2
  %v = fpext half %load to float
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  %gep2 = getelementptr inbounds float, ptr addrspace(1) %out, i32 %id
  store float %canonicalized, ptr addrspace(1) %gep2, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fpround_value_f32_f64:
; GCN: v_cvt_f32_f64_e32 [[V:v[0-9]+]], v[{{[0-9:]+}}]
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fpround_value_f32_f64(ptr addrspace(1) %arg, ptr addrspace(1) %out) {
; VI-LABEL: test_fold_canonicalize_fpround_value_f32_f64:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v1, 3, v0
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v2, s1
; VI-NEXT:    v_add_u32_e32 v1, vcc, s0, v1
; VI-NEXT:    v_addc_u32_e32 v2, vcc, 0, v2, vcc
; VI-NEXT:    flat_load_dwordx2 v[1:2], v[1:2]
; VI-NEXT:    v_mov_b32_e32 v3, s3
; VI-NEXT:    v_add_u32_e32 v0, vcc, s2, v0
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_cvt_f32_f64_e32 v2, v[1:2]
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v3, vcc
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fpround_value_f32_f64:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v1, 3, v0
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dwordx2 v[1:2], v1, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cvt_f32_f64_e32 v1, v[1:2]
; GFX9-NEXT:    global_store_dword v0, v1, s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds double, ptr addrspace(1) %arg, i32 %id
  %load = load double, ptr addrspace(1) %gep, align 8
  %v = fptrunc double %load to float
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  %gep2 = getelementptr inbounds float, ptr addrspace(1) %out, i32 %id
  store float %canonicalized, ptr addrspace(1) %gep2, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fpround_value_f16_f32:
; GCN: v_cvt_f16_f32_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_max
; GCN-NOT: v_mul
; GCN: {{flat|global}}_store_short v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fpround_value_f16_f32(ptr addrspace(1) %arg, ptr addrspace(1) %out) {
; VI-LABEL: test_fold_canonicalize_fpround_value_f16_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v1, 2, v0
; VI-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v2, s1
; VI-NEXT:    v_add_u32_e32 v1, vcc, s0, v1
; VI-NEXT:    v_addc_u32_e32 v2, vcc, 0, v2, vcc
; VI-NEXT:    flat_load_dword v1, v[1:2]
; VI-NEXT:    v_mov_b32_e32 v2, s3
; VI-NEXT:    v_add_u32_e32 v0, vcc, s2, v0
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_cvt_f16_f32_e32 v3, v1
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v2, vcc
; VI-NEXT:    flat_store_short v[0:1], v3
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fpround_value_f16_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v1, 2, v0
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v1, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cvt_f16_f32_e32 v1, v1
; GFX9-NEXT:    global_store_short v0, v1, s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = fptrunc float %load to half
  %canonicalized = tail call half @llvm.canonicalize.f16(half %v)
  %gep2 = getelementptr inbounds half, ptr addrspace(1) %out, i32 %id
  store half %canonicalized, ptr addrspace(1) %gep2, align 2
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fpround_value_f16_f32_flushf16:
; GCN: v_cvt_f16_f32_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_max
; GCN-NOT: v_mul
; GCN: {{flat|global}}_store_short v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fpround_value_f16_f32_flushf16(ptr addrspace(1) %arg, ptr addrspace(1) %out) #2 {
; VI-LABEL: test_fold_canonicalize_fpround_value_f16_f32_flushf16:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v1, 2, v0
; VI-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v2, s1
; VI-NEXT:    v_add_u32_e32 v1, vcc, s0, v1
; VI-NEXT:    v_addc_u32_e32 v2, vcc, 0, v2, vcc
; VI-NEXT:    flat_load_dword v1, v[1:2]
; VI-NEXT:    v_mov_b32_e32 v2, s3
; VI-NEXT:    v_add_u32_e32 v0, vcc, s2, v0
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_cvt_f16_f32_e32 v3, v1
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v2, vcc
; VI-NEXT:    flat_store_short v[0:1], v3
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fpround_value_f16_f32_flushf16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v1, 2, v0
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v1, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cvt_f16_f32_e32 v1, v1
; GFX9-NEXT:    global_store_short v0, v1, s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = fptrunc float %load to half
  %canonicalized = tail call half @llvm.canonicalize.f16(half %v)
  %gep2 = getelementptr inbounds half, ptr addrspace(1) %out, i32 %id
  store half %canonicalized, ptr addrspace(1) %gep2, align 2
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fpround_value_v2f16_v2f32:
; GCN-DAG: v_cvt_f16_f32_e32 [[V0:v[0-9]+]], v{{[0-9]+}}
; VI-DAG: v_cvt_f16_f32_sdwa [[V1:v[0-9]+]], v{{[0-9]+}}
; VI: v_or_b32_e32 [[V:v[0-9]+]], [[V0]], [[V1]]
; GFX9: v_cvt_f16_f32_e32 [[V1:v[0-9]+]], v{{[0-9]+}}
; GFX9: v_pack_b32_f16 [[V:v[0-9]+]], [[V1]], [[V0]]
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fpround_value_v2f16_v2f32(ptr addrspace(1) %arg, ptr addrspace(1) %out) {
; VI-LABEL: test_fold_canonicalize_fpround_value_v2f16_v2f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v1, 3, v0
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v2, s1
; VI-NEXT:    v_add_u32_e32 v1, vcc, s0, v1
; VI-NEXT:    v_addc_u32_e32 v2, vcc, 0, v2, vcc
; VI-NEXT:    flat_load_dwordx2 v[1:2], v[1:2]
; VI-NEXT:    v_mov_b32_e32 v3, s3
; VI-NEXT:    v_add_u32_e32 v0, vcc, s2, v0
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_cvt_f16_f32_e32 v1, v1
; VI-NEXT:    v_cvt_f16_f32_sdwa v2, v2 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:DWORD
; VI-NEXT:    v_or_b32_e32 v2, v1, v2
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v3, vcc
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fpround_value_v2f16_v2f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v1, 3, v0
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dwordx2 v[1:2], v1, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cvt_f16_f32_e32 v2, v2
; GFX9-NEXT:    v_cvt_f16_f32_e32 v1, v1
; GFX9-NEXT:    v_pack_b32_f16 v1, v1, v2
; GFX9-NEXT:    global_store_dword v0, v1, s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds <2 x float>, ptr addrspace(1) %arg, i32 %id
  %load = load <2 x float>, ptr addrspace(1) %gep, align 8
  %v = fptrunc <2 x float> %load to <2 x half>
  %canonicalized = tail call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %v)
  %gep2 = getelementptr inbounds <2 x half>, ptr addrspace(1) %out, i32 %id
  store <2 x half> %canonicalized, ptr addrspace(1) %gep2, align 4
  ret void
}

; GCN-LABEL: test_no_fold_canonicalize_fneg_value_f32:
; VI:  v_mul_f32_e32 v{{[0-9]+}}, -1.0, v{{[0-9]+}}
; GFX9: v_max_f32_e64 v{{[0-9]+}}, -v{{[0-9]+}}, -v{{[0-9]+}}
define amdgpu_kernel void @test_no_fold_canonicalize_fneg_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_no_fold_canonicalize_fneg_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, -1.0, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_no_fold_canonicalize_fneg_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e64 v1, -v1, -v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = fneg float %load
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fneg_value_f32:
; GCN: v_xor_b32_e32 [[V:v[0-9]+]], 0x80000000, v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fneg_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_fneg_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_add_f32_e32 v2, 0, v2
; VI-NEXT:    v_xor_b32_e32 v2, 0x80000000, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fneg_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_add_f32_e32 v1, 0, v1
; GFX9-NEXT:    v_xor_b32_e32 v1, 0x80000000, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v0 = fadd float %load, 0.0
  %v = fneg float %v0
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_no_fold_canonicalize_fabs_value_f32:
; VI:  v_mul_f32_e64 v{{[0-9]+}}, 1.0, |v{{[0-9]+}}|
; GFX9: v_max_f32_e64 v{{[0-9]+}}, |v{{[0-9]+}}|, |v{{[0-9]+}}|
define amdgpu_kernel void @test_no_fold_canonicalize_fabs_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_no_fold_canonicalize_fabs_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e64 v2, 1.0, |v2|
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_no_fold_canonicalize_fabs_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e64 v1, |v1|, |v1|
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = tail call float @llvm.fabs.f32(float %load)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_no_fold_canonicalize_fcopysign_value_f32:
; VI:  v_mul_f32_e64 v{{[0-9]+}}, 1.0, |v{{[0-9]+}}|
; GFX9: v_max_f32_e64 v{{[0-9]+}}, |v{{[0-9]+}}|, |v{{[0-9]+}}|

; GCN-NOT: v_mul_
; GCN-NOT: v_max_
define amdgpu_kernel void @test_no_fold_canonicalize_fcopysign_value_f32(ptr addrspace(1) %arg, float %sign) {
; VI-LABEL: test_no_fold_canonicalize_fcopysign_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e64 v2, 1.0, |v2|
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_no_fold_canonicalize_fcopysign_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e64 v1, |v1|, |v1|
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %canon.load = tail call float @llvm.canonicalize.f32(float %load)
  %copysign = call float @llvm.copysign.f32(float %canon.load, float %sign)
  %v = tail call float @llvm.fabs.f32(float %load)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fabs_value_f32:
; GCN: v_and_b32_e32 [[V:v[0-9]+]], 0x7fffffff, v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_fabs_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_fabs_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_add_f32_e32 v2, 0, v2
; VI-NEXT:    v_and_b32_e32 v2, 0x7fffffff, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_fabs_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_add_f32_e32 v1, 0, v1
; GFX9-NEXT:    v_and_b32_e32 v1, 0x7fffffff, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v0 = fadd float %load, 0.0
  %v = tail call float @llvm.fabs.f32(float %v0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_sin_value_f32:
; GCN: v_sin_f32_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_sin_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_sin_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, 0.15915494, v2
; VI-NEXT:    v_fract_f32_e32 v2, v2
; VI-NEXT:    v_sin_f32_e32 v2, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_sin_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mul_f32_e32 v1, 0.15915494, v1
; GFX9-NEXT:    v_sin_f32_e32 v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = tail call float @llvm.sin.f32(float %load)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_cos_value_f32:
; GCN: v_cos_f32_e32 [[V:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_cos_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_cos_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, 0.15915494, v2
; VI-NEXT:    v_fract_f32_e32 v2, v2
; VI-NEXT:    v_cos_f32_e32 v2, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_cos_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mul_f32_e32 v1, 0.15915494, v1
; GFX9-NEXT:    v_cos_f32_e32 v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = tail call float @llvm.cos.f32(float %load)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_sin_value_f16:
; GCN: v_sin_f16_e32 [[V0:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_short v{{.+}}, [[V0]]
define amdgpu_kernel void @test_fold_canonicalize_sin_value_f16(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_sin_value_f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_ushort v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f16_e32 v2, 0.15915494, v2
; VI-NEXT:    v_fract_f16_e32 v2, v2
; VI-NEXT:    v_sin_f16_e32 v2, v2
; VI-NEXT:    flat_store_short v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_sin_value_f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_ushort v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mul_f16_e32 v1, 0.15915494, v1
; GFX9-NEXT:    v_sin_f16_e32 v1, v1
; GFX9-NEXT:    global_store_short v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds half, ptr addrspace(1) %arg, i32 %id
  %load = load half, ptr addrspace(1) %gep, align 2
  %v = tail call half @llvm.sin.f16(half %load)
  %canonicalized = tail call half @llvm.canonicalize.f16(half %v)
  store half %canonicalized, ptr addrspace(1) %gep, align 2
  ret void
}

; GCN-LABEL: test_fold_canonicalize_cos_value_f16:
; GCN: v_cos_f16_e32 [[V0:v[0-9]+]], v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_short v{{.+}}, [[V0]]
define amdgpu_kernel void @test_fold_canonicalize_cos_value_f16(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_cos_value_f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_ushort v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f16_e32 v2, 0.15915494, v2
; VI-NEXT:    v_fract_f16_e32 v2, v2
; VI-NEXT:    v_cos_f16_e32 v2, v2
; VI-NEXT:    flat_store_short v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_cos_value_f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_ushort v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mul_f16_e32 v1, 0.15915494, v1
; GFX9-NEXT:    v_cos_f16_e32 v1, v1
; GFX9-NEXT:    global_store_short v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds half, ptr addrspace(1) %arg, i32 %id
  %load = load half, ptr addrspace(1) %gep, align 2
  %v = tail call half @llvm.cos.f16(half %load)
  %canonicalized = tail call half @llvm.canonicalize.f16(half %v)
  store half %canonicalized, ptr addrspace(1) %gep, align 2
  ret void
}

; GCN-LABEL: test_fold_canonicalize_qNaN_value_f32:
; GCN: v_mov_b32_e32 [[V:v[0-9]+]], 0x7fc00000
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_qNaN_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_qNaN_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    v_mov_b32_e32 v2, 0x7fc00000
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_qNaN_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    v_mov_b32_e32 v1, 0x7fc00000
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %canonicalized = tail call float @llvm.canonicalize.f32(float 0x7FF8000000000000)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_minnum_value_from_load_f32_ieee_mode:
; GCN: {{flat|global}}_load_dword [[VAL:v[0-9]+]]
; VI: v_mul_f32_e32 [[QUIET:v[0-9]+]], 1.0, [[VAL]]
; GFX9: v_max_f32_e32 [[QUIET:v[0-9]+]], [[VAL]], [[VAL]]

; GCN: v_min_f32_e32 [[V:v[0-9]+]], 0, [[QUIET]]
; GCN-NOT: v_max
; GCN-NOT: v_mul

; GFX9: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_minnum_value_from_load_f32_ieee_mode(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_minnum_value_from_load_f32_ieee_mode:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, 1.0, v2
; VI-NEXT:    v_min_f32_e32 v2, 0, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_minnum_value_from_load_f32_ieee_mode:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    v_min_f32_e32 v1, 0, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = tail call float @llvm.minnum.f32(float %load, float 0.0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; define amdgpu_kernel void @test_fold_canonicalize_minnum_value_from_load_f32_nnan_ieee_mode(ptr addrspace(1) %arg) #1 {
;   %id = tail call i32 @llvm.amdgcn.workitem.id.x()
;   %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
;   %load = load float, ptr addrspace(1) %gep, align 4
;   %v = tail call float @llvm.minnum.f32(float %load, float 0.0)
;   %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
;   store float %canonicalized, ptr addrspace(1) %gep, align 4
;   ret void
; }

; GCN-LABEL: test_fold_canonicalize_minnum_value_f32:
; GCN: v_min_f32_e32 [[V:v[0-9]+]], 0, v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_minnum_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_minnum_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_add_f32_e32 v2, 0, v2
; VI-NEXT:    v_min_f32_e32 v2, 0, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_minnum_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_add_f32_e32 v1, 0, v1
; GFX9-NEXT:    v_min_f32_e32 v1, 0, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v0 = fadd float %load, 0.0
  %v = tail call float @llvm.minnum.f32(float %v0, float 0.0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; FIXME: Should there be more checks here? minnum with sNaN operand might get simplified away.

; GCN-LABEL: test_fold_canonicalize_sNaN_value_f32:
; GCN: {{flat|global}}_load_dword [[LOAD:v[0-9]+]]
; VI: v_mul_f32_e32 v{{[0-9]+}}, 1.0, [[LOAD]]
; GFX9: v_max_f32_e32 v{{[0-9]+}}, [[LOAD]], [[LOAD]]
define amdgpu_kernel void @test_fold_canonicalize_sNaN_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_sNaN_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, 1.0, v2
; VI-NEXT:    v_min_f32_e32 v2, 0x7fc00000, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_sNaN_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    v_min_f32_e32 v1, 0x7fc00000, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = tail call float @llvm.minnum.f32(float %load, float bitcast (i32 2139095041 to float))
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; define amdgpu_kernel void @test_fold_canonicalize_denorm_value_f32(ptr addrspace(1) %arg) {
;   %id = tail call i32 @llvm.amdgcn.workitem.id.x()
;   %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
;   %load = load float, ptr addrspace(1) %gep, align 4
;   %v = tail call float @llvm.minnum.f32(float %load, float bitcast (i32 8388607 to float))
;   %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
;   store float %canonicalized, ptr addrspace(1) %gep, align 4
;   ret void
; }

; GCN-LABEL: test_fold_canonicalize_maxnum_value_from_load_f32_ieee_mode:
; GCN: {{flat|global}}_load_dword [[VAL:v[0-9]+]]

; GFX9:  v_max_f32_e32 [[RESULT:v[0-9]+]], 0, [[VAL]]

; VI-FLUSH:    v_mul_f32_e32 [[QUIET:v[0-9]+]], 1.0, [[VAL]]
; VI-FLUSH:    v_max_f32_e32 [[RESULT:v[0-9]+]], 0, [[QUIET]]

; VI-DENORM: v_max_f32_e32 [[RESULT:v[0-9]+]], 0, [[VAL]]

; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN:  {{flat|global}}_store_dword v{{.+}}, [[RESULT]]
define amdgpu_kernel void @test_fold_canonicalize_maxnum_value_from_load_f32_ieee_mode(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_maxnum_value_from_load_f32_ieee_mode:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v2, 1.0, v2
; VI-NEXT:    v_max_f32_e32 v2, 0, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_maxnum_value_from_load_f32_ieee_mode:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    v_max_f32_e32 v1, 0, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v = tail call float @llvm.maxnum.f32(float %load, float 0.0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_maxnum_value_f32:
; GCN: v_max_f32_e32 [[V:v[0-9]+]], 0, v{{[0-9]+}}
; GCN-NOT: v_max
; GCN-NOT: v_mul
; GCN: {{flat|global}}_store_dword v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_maxnum_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_maxnum_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_add_f32_e32 v2, 0, v2
; VI-NEXT:    v_max_f32_e32 v2, 0, v2
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_maxnum_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_add_f32_e32 v1, 0, v1
; GFX9-NEXT:    v_max_f32_e32 v1, 0, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load = load float, ptr addrspace(1) %gep, align 4
  %v0 = fadd float %load, 0.0
  %v = tail call float @llvm.maxnum.f32(float %v0, float 0.0)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; GCN-LABEL: test_fold_canonicalize_maxnum_value_f64:
; GCN: v_max_f64 [[V:v\[[0-9]+:[0-9]+\]]], v[{{[0-9:]+}}], 0
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN:  {{flat|global}}_store_dwordx2 v{{.+}}, [[V]]
define amdgpu_kernel void @test_fold_canonicalize_maxnum_value_f64(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_maxnum_value_f64:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 3, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dwordx2 v[2:3], v[0:1]
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_add_f64 v[2:3], v[2:3], 0
; VI-NEXT:    v_max_f64 v[2:3], v[2:3], 0
; VI-NEXT:    flat_store_dwordx2 v[0:1], v[2:3]
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_maxnum_value_f64:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v2, 3, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dwordx2 v[0:1], v2, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_add_f64 v[0:1], v[0:1], 0
; GFX9-NEXT:    v_max_f64 v[0:1], v[0:1], 0
; GFX9-NEXT:    global_store_dwordx2 v2, v[0:1], s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds double, ptr addrspace(1) %arg, i32 %id
  %load = load double, ptr addrspace(1) %gep, align 8
  %v0 = fadd double %load, 0.0
  %v = tail call double @llvm.maxnum.f64(double %v0, double 0.0)
  %canonicalized = tail call double @llvm.canonicalize.f64(double %v)
  store double %canonicalized, ptr addrspace(1) %gep, align 8
  ret void
}

; GCN-LABEL: test_fold_canonicalize_fmul_value_f32_no_ieee:
; GCN: v_mul_f32_e32 [[V:v[0-9]+]], 0x41700000, v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN-NEXT: ; return
define amdgpu_ps float @test_fold_canonicalize_fmul_value_f32_no_ieee(float %arg) {
; GCN-LABEL: test_fold_canonicalize_fmul_value_f32_no_ieee:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    v_mul_f32_e32 v0, 0x41700000, v0
; GCN-NEXT:    ; return to shader part epilog
entry:
  %v = fmul float %arg, 15.0
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  ret float %canonicalized
}

; GCN-LABEL: test_fold_canonicalize_fmul_nnan_value_f32_no_ieee:
; GCN: v_mul_f32_e32 [[V:v[0-9]+]], 0x41700000, v{{[0-9]+}}
; GCN-NOT: v_mul
; GCN-NOT: v_max
; GCN-NEXT: ; return
define amdgpu_ps float @test_fold_canonicalize_fmul_nnan_value_f32_no_ieee(float %arg) {
; GCN-LABEL: test_fold_canonicalize_fmul_nnan_value_f32_no_ieee:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    v_mul_f32_e32 v0, 0x41700000, v0
; GCN-NEXT:    ; return to shader part epilog
entry:
  %v = fmul nnan float %arg, 15.0
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}test_fold_canonicalize_fdiv_value_f32_no_ieee:
; GCN: v_div_fixup_f32
; GCN-NOT: v_max
; GCN-NOT: v_mul
; GCN: ; return
define amdgpu_ps float @test_fold_canonicalize_fdiv_value_f32_no_ieee(float %arg0) {
; VI-FLUSH-LABEL: test_fold_canonicalize_fdiv_value_f32_no_ieee:
; VI-FLUSH:       ; %bb.0: ; %entry
; VI-FLUSH-NEXT:    s_mov_b32 s2, 0x41700000
; VI-FLUSH-NEXT:    v_div_scale_f32 v1, s[0:1], v0, v0, s2
; VI-FLUSH-NEXT:    v_div_scale_f32 v2, vcc, s2, v0, s2
; VI-FLUSH-NEXT:    v_rcp_f32_e32 v3, v1
; VI-FLUSH-NEXT:    s_setreg_imm32_b32 hwreg(HW_REG_MODE, 4, 2), 3
; VI-FLUSH-NEXT:    v_fma_f32 v4, -v1, v3, 1.0
; VI-FLUSH-NEXT:    v_fma_f32 v3, v4, v3, v3
; VI-FLUSH-NEXT:    v_mul_f32_e32 v4, v2, v3
; VI-FLUSH-NEXT:    v_fma_f32 v5, -v1, v4, v2
; VI-FLUSH-NEXT:    v_fma_f32 v4, v5, v3, v4
; VI-FLUSH-NEXT:    v_fma_f32 v1, -v1, v4, v2
; VI-FLUSH-NEXT:    s_setreg_imm32_b32 hwreg(HW_REG_MODE, 4, 2), 0
; VI-FLUSH-NEXT:    v_div_fmas_f32 v1, v1, v3, v4
; VI-FLUSH-NEXT:    v_div_fixup_f32 v0, v1, v0, s2
; VI-FLUSH-NEXT:    ; return to shader part epilog
;
; VI-DENORM-LABEL: test_fold_canonicalize_fdiv_value_f32_no_ieee:
; VI-DENORM:       ; %bb.0: ; %entry
; VI-DENORM-NEXT:    s_mov_b32 s2, 0x41700000
; VI-DENORM-NEXT:    v_div_scale_f32 v1, s[0:1], v0, v0, s2
; VI-DENORM-NEXT:    v_div_scale_f32 v2, vcc, s2, v0, s2
; VI-DENORM-NEXT:    v_rcp_f32_e32 v3, v1
; VI-DENORM-NEXT:    v_fma_f32 v4, -v1, v3, 1.0
; VI-DENORM-NEXT:    v_fma_f32 v3, v4, v3, v3
; VI-DENORM-NEXT:    v_mul_f32_e32 v4, v2, v3
; VI-DENORM-NEXT:    v_fma_f32 v5, -v1, v4, v2
; VI-DENORM-NEXT:    v_fma_f32 v4, v5, v3, v4
; VI-DENORM-NEXT:    v_fma_f32 v1, -v1, v4, v2
; VI-DENORM-NEXT:    v_div_fmas_f32 v1, v1, v3, v4
; VI-DENORM-NEXT:    v_div_fixup_f32 v0, v1, v0, s2
; VI-DENORM-NEXT:    ; return to shader part epilog
;
; GFX9-DENORM-LABEL: test_fold_canonicalize_fdiv_value_f32_no_ieee:
; GFX9-DENORM:       ; %bb.0: ; %entry
; GFX9-DENORM-NEXT:    s_mov_b32 s2, 0x41700000
; GFX9-DENORM-NEXT:    v_div_scale_f32 v1, s[0:1], v0, v0, s2
; GFX9-DENORM-NEXT:    v_div_scale_f32 v2, vcc, s2, v0, s2
; GFX9-DENORM-NEXT:    v_rcp_f32_e32 v3, v1
; GFX9-DENORM-NEXT:    v_fma_f32 v4, -v1, v3, 1.0
; GFX9-DENORM-NEXT:    v_fma_f32 v3, v4, v3, v3
; GFX9-DENORM-NEXT:    v_mul_f32_e32 v4, v2, v3
; GFX9-DENORM-NEXT:    v_fma_f32 v5, -v1, v4, v2
; GFX9-DENORM-NEXT:    v_fma_f32 v4, v5, v3, v4
; GFX9-DENORM-NEXT:    v_fma_f32 v1, -v1, v4, v2
; GFX9-DENORM-NEXT:    v_div_fmas_f32 v1, v1, v3, v4
; GFX9-DENORM-NEXT:    v_div_fixup_f32 v0, v1, v0, s2
; GFX9-DENORM-NEXT:    ; return to shader part epilog
;
; GFX9-FLUSH-LABEL: test_fold_canonicalize_fdiv_value_f32_no_ieee:
; GFX9-FLUSH:       ; %bb.0: ; %entry
; GFX9-FLUSH-NEXT:    s_mov_b32 s2, 0x41700000
; GFX9-FLUSH-NEXT:    v_div_scale_f32 v1, s[0:1], v0, v0, s2
; GFX9-FLUSH-NEXT:    v_div_scale_f32 v2, vcc, s2, v0, s2
; GFX9-FLUSH-NEXT:    v_rcp_f32_e32 v3, v1
; GFX9-FLUSH-NEXT:    s_setreg_imm32_b32 hwreg(HW_REG_MODE, 4, 2), 3
; GFX9-FLUSH-NEXT:    v_fma_f32 v4, -v1, v3, 1.0
; GFX9-FLUSH-NEXT:    v_fma_f32 v3, v4, v3, v3
; GFX9-FLUSH-NEXT:    v_mul_f32_e32 v4, v2, v3
; GFX9-FLUSH-NEXT:    v_fma_f32 v5, -v1, v4, v2
; GFX9-FLUSH-NEXT:    v_fma_f32 v4, v5, v3, v4
; GFX9-FLUSH-NEXT:    v_fma_f32 v1, -v1, v4, v2
; GFX9-FLUSH-NEXT:    s_setreg_imm32_b32 hwreg(HW_REG_MODE, 4, 2), 0
; GFX9-FLUSH-NEXT:    v_div_fmas_f32 v1, v1, v3, v4
; GFX9-FLUSH-NEXT:    v_div_fixup_f32 v0, v1, v0, s2
; GFX9-FLUSH-NEXT:    ; return to shader part epilog
entry:
  %v = fdiv float 15.0, %arg0
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}test_fold_canonicalize_load_nnan_value_f32
; GFX9-DENORM: global_load_dword [[V:v[0-9]+]],
; GFX9-DENORM: global_store_dword v{{[0-9]+}}, [[V]], s{{\[[0-9]+:[0-9]+\]}}
; GFX9-DENORM-NOT: 1.0
; GFX9-DENORM-NOT: v_max
; VI-FLUSH: v_mul_f32_e32 v{{[0-9]+}}, 1.0, v{{[0-9]+}}
; GFX9-FLUSH: v_max_f32_e32 v{{[0-9]+}}, v{{[0-9]+}}, v{{[0-9]+}}
define amdgpu_kernel void @test_fold_canonicalize_load_nnan_value_f32(ptr addrspace(1) %arg, ptr addrspace(1) %out) #1 {
; VI-LABEL: test_fold_canonicalize_load_nnan_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v2, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v2
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v0, v[0:1]
; VI-NEXT:    v_mov_b32_e32 v1, s3
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v3, 1.0, v0
; VI-NEXT:    v_add_u32_e32 v0, vcc, s2, v2
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_store_dword v[0:1], v3
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_load_nnan_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    global_store_dword v0, v1, s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %v = load float, ptr addrspace(1) %gep, align 4
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  %gep2 = getelementptr inbounds float, ptr addrspace(1) %out, i32 %id
  store float %canonicalized, ptr addrspace(1) %gep2, align 4
  ret void
}

; GCN-LABEL: {{^}}test_fold_canonicalize_load_nnan_value_f64
; GCN: {{flat|global}}_load_dwordx2 [[V:v\[[0-9:]+\]]],
; GCN: {{flat|global}}_store_dwordx2 v{{.+}}, [[V]]
; GCN-NOT: v_mul_
; GCN-NOT: v_max_
define amdgpu_kernel void @test_fold_canonicalize_load_nnan_value_f64(ptr addrspace(1) %arg, ptr addrspace(1) %out) #1 {
; VI-LABEL: test_fold_canonicalize_load_nnan_value_f64:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v2, 3, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v2
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dwordx2 v[0:1], v[0:1]
; VI-NEXT:    v_mov_b32_e32 v3, s3
; VI-NEXT:    v_add_u32_e32 v2, vcc, s2, v2
; VI-NEXT:    v_addc_u32_e32 v3, vcc, 0, v3, vcc
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; VI-NEXT:    flat_store_dwordx2 v[2:3], v[0:1]
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_load_nnan_value_f64:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v2, 3, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dwordx2 v[0:1], v2, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GFX9-NEXT:    global_store_dwordx2 v2, v[0:1], s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds double, ptr addrspace(1) %arg, i32 %id
  %v = load double, ptr addrspace(1) %gep, align 8
  %canonicalized = tail call double @llvm.canonicalize.f64(double %v)
  %gep2 = getelementptr inbounds double, ptr addrspace(1) %out, i32 %id
  store double %canonicalized, ptr addrspace(1) %gep2, align 8
  ret void
}

; GCN-LABEL: {{^}}test_fold_canonicalize_load_nnan_value_f16
; GCN: {{flat|global}}_load_ushort [[V1:v[0-9]+]],
; GCN: v_max_f16_e32 [[V2:v[0-9]+]], [[V1]], [[V1]]
; GCN: {{flat|global}}_store_short v{{.+}}, [[V2]]
define amdgpu_kernel void @test_fold_canonicalize_load_nnan_value_f16(ptr addrspace(1) %arg, ptr addrspace(1) %out) #1 {
; VI-LABEL: test_fold_canonicalize_load_nnan_value_f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v2, 1, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v2
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_ushort v0, v[0:1]
; VI-NEXT:    v_mov_b32_e32 v1, s3
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_max_f16_e32 v3, v0, v0
; VI-NEXT:    v_add_u32_e32 v0, vcc, s2, v2
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_store_short v[0:1], v3
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_load_nnan_value_f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 1, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_ushort v1, v0, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_f16_e32 v1, v1, v1
; GFX9-NEXT:    global_store_short v0, v1, s[2:3]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds half, ptr addrspace(1) %arg, i32 %id
  %v = load half, ptr addrspace(1) %gep, align 2
  %canonicalized = tail call half @llvm.canonicalize.f16(half %v)
  %gep2 = getelementptr inbounds half, ptr addrspace(1) %out, i32 %id
  store half %canonicalized, ptr addrspace(1) %gep2, align 2
  ret void
}

; GCN-LABEL: {{^}}test_fold_canonicalize_select_value_f32:
; GCN: v_add_f32
; GCN: v_add_f32
; GCN: v_cndmask_b32
; GCN-NOT: v_mul_
; GCN-NOT: v_max_
define amdgpu_kernel void @test_fold_canonicalize_select_value_f32(ptr addrspace(1) %arg) {
; VI-LABEL: test_fold_canonicalize_select_value_f32:
; VI:       ; %bb.0:
; VI-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; VI-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; VI-NEXT:    s_waitcnt lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, s1
; VI-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; VI-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; VI-NEXT:    flat_load_dword v2, v[0:1] glc
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    flat_load_dword v3, v[0:1] glc
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    flat_load_dword v4, v[0:1] glc
; VI-NEXT:    s_waitcnt vmcnt(0)
; VI-NEXT:    v_add_f32_e32 v2, 0x41700000, v2
; VI-NEXT:    v_add_f32_e32 v3, 0x42000000, v3
; VI-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v4
; VI-NEXT:    v_cndmask_b32_e32 v2, v3, v2, vcc
; VI-NEXT:    flat_store_dword v[0:1], v2
; VI-NEXT:    s_endpgm
;
; GFX9-LABEL: test_fold_canonicalize_select_value_f32:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_load_dword v1, v0, s[0:1] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    global_load_dword v2, v0, s[0:1] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    ; kill: killed $vgpr0_vgpr1
; GFX9-NEXT:    global_load_dword v3, v[0:1], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_add_f32_e32 v1, 0x41700000, v1
; GFX9-NEXT:    v_add_f32_e32 v2, 0x42000000, v2
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v3
; GFX9-NEXT:    v_cndmask_b32_e32 v1, v2, v1, vcc
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %gep = getelementptr inbounds float, ptr addrspace(1) %arg, i32 %id
  %load0 = load volatile float, ptr addrspace(1) %gep, align 4
  %load1 = load volatile float, ptr addrspace(1) %gep, align 4
  %load2 = load volatile i32, ptr addrspace(1) poison, align 4
  %v0 = fadd float %load0, 15.0
  %v1 = fadd float %load1, 32.0
  %cond = icmp eq i32 %load2, 0
  %select = select i1 %cond, float %v0, float %v1
  %canonicalized = tail call float @llvm.canonicalize.f32(float %select)
  store float %canonicalized, ptr addrspace(1) %gep, align 4
  ret void
}

; Need to quiet the nan with a separate instruction since it will be
; passed through the minnum.
; FIXME: canonicalize doens't work correctly without ieee_mode

; GCN-LABEL: {{^}}test_fold_canonicalize_minnum_value_no_ieee_mode:
; GFX9-NOT: v0
; GFX9-NOT: v1
; GFX9: v_min_f32_e32 v0, v0, v1
; GFX9-NEXT: ; return to shader

; VI-FLUSH: v_min_f32_e32 v0, v0, v1
; VI-FLUSH-NEXT: v_mul_f32_e32 v0, 1.0, v0
; VI-FLUSH-NEXT: ; return

; VI-DENORM-NOT: v0
; VI-DENORM: v_min_f32_e32 v0, v0, v1
; VI-DENORM-NEXT: ; return
define amdgpu_ps float @test_fold_canonicalize_minnum_value_no_ieee_mode(float %arg0, float %arg1) {
; VI-FLUSH-LABEL: test_fold_canonicalize_minnum_value_no_ieee_mode:
; VI-FLUSH:       ; %bb.0:
; VI-FLUSH-NEXT:    v_min_f32_e32 v0, v0, v1
; VI-FLUSH-NEXT:    v_mul_f32_e32 v0, 1.0, v0
; VI-FLUSH-NEXT:    ; return to shader part epilog
;
; VI-DENORM-LABEL: test_fold_canonicalize_minnum_value_no_ieee_mode:
; VI-DENORM:       ; %bb.0:
; VI-DENORM-NEXT:    v_min_f32_e32 v0, v0, v1
; VI-DENORM-NEXT:    ; return to shader part epilog
;
; GFX9-LABEL: test_fold_canonicalize_minnum_value_no_ieee_mode:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_min_f32_e32 v0, v0, v1
; GFX9-NEXT:    ; return to shader part epilog
  %v = tail call float @llvm.minnum.f32(float %arg0, float %arg1)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}test_fold_canonicalize_minnum_value_ieee_mode:
; GFX9: v_min_f32_e32 v0, v0, v1
; GFX9-NEXT: s_setpc_b64

; VI-DAG: v_mul_f32_e32 v0, 1.0, v0
; VI-DAG: v_mul_f32_e32 v1, 1.0, v1
; VI: v_min_f32_e32 v0, v0, v1

; VI-NEXT: s_setpc_b64
define float @test_fold_canonicalize_minnum_value_ieee_mode(float %arg0, float %arg1) {
; VI-LABEL: test_fold_canonicalize_minnum_value_ieee_mode:
; VI:       ; %bb.0:
; VI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v1, 1.0, v1
; VI-NEXT:    v_mul_f32_e32 v0, 1.0, v0
; VI-NEXT:    v_min_f32_e32 v0, v0, v1
; VI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: test_fold_canonicalize_minnum_value_ieee_mode:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    v_max_f32_e32 v0, v0, v0
; GFX9-NEXT:    v_min_f32_e32 v0, v0, v1
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %v = tail call float @llvm.minnum.f32(float %arg0, float %arg1)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  ret float %canonicalized
}

; Canonicalizing flush necessary pre-gfx9
; GCN-LABEL: {{^}}test_fold_canonicalize_minnum_value_no_ieee_mode_nnan:
; GCN: v_min_f32_e32 v0, v0, v1
; VI-FLUSH-NEXT: v_mul_f32_e32 v0, 1.0, v0
; GCN-NEXT: ; return
define amdgpu_ps float @test_fold_canonicalize_minnum_value_no_ieee_mode_nnan(float %arg0, float %arg1) #1 {
; VI-FLUSH-LABEL: test_fold_canonicalize_minnum_value_no_ieee_mode_nnan:
; VI-FLUSH:       ; %bb.0:
; VI-FLUSH-NEXT:    v_min_f32_e32 v0, v0, v1
; VI-FLUSH-NEXT:    v_mul_f32_e32 v0, 1.0, v0
; VI-FLUSH-NEXT:    ; return to shader part epilog
;
; VI-DENORM-LABEL: test_fold_canonicalize_minnum_value_no_ieee_mode_nnan:
; VI-DENORM:       ; %bb.0:
; VI-DENORM-NEXT:    v_min_f32_e32 v0, v0, v1
; VI-DENORM-NEXT:    ; return to shader part epilog
;
; GFX9-LABEL: test_fold_canonicalize_minnum_value_no_ieee_mode_nnan:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_min_f32_e32 v0, v0, v1
; GFX9-NEXT:    ; return to shader part epilog
  %v = tail call float @llvm.minnum.f32(float %arg0, float %arg1)
  %canonicalized = tail call float @llvm.canonicalize.f32(float %v)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_build_vector_v2f16:
; GFX9-DAG: v_add_f16_e32
; GFX9-DAG: v_mul_f16_e32
; GFX9-NOT: v_max
; GFX9-NOT: v_pk_max
define <2 x half> @v_test_canonicalize_build_vector_v2f16(<2 x half> %vec) {
; VI-LABEL: v_test_canonicalize_build_vector_v2f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v2, 0x4400
; VI-NEXT:    v_add_f16_e32 v1, 1.0, v0
; VI-NEXT:    v_mul_f16_sdwa v0, v0, v2 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:DWORD src1_sel:DWORD
; VI-NEXT:    v_or_b32_e32 v0, v1, v0
; VI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_build_vector_v2f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_add_f16_e32 v1, 1.0, v0
; GFX9-NEXT:    v_mul_f16_e32 v0, 4.0, v0
; GFX9-NEXT:    v_pack_b32_f16 v0, v1, v0
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %lo = extractelement <2 x half> %vec, i32 0
  %hi = extractelement <2 x half> %vec, i32 1
  %lo.op = fadd half %lo, 1.0
  %hi.op = fmul half %lo, 4.0
  %ins0 = insertelement <2 x half> poison, half %lo.op, i32 0
  %ins1 = insertelement <2 x half> %ins0, half %hi.op, i32 1
  %canonicalized = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %ins1)
  ret <2 x half> %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_build_vector_noncanon1_v2f16:
; GFX9: v_add_f16_e32
; GFX9: v_pk_max
define <2 x half> @v_test_canonicalize_build_vector_noncanon1_v2f16(<2 x half> %vec) {
; VI-LABEL: v_test_canonicalize_build_vector_noncanon1_v2f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-NEXT:    v_add_f16_e32 v1, 1.0, v0
; VI-NEXT:    v_max_f16_sdwa v0, v0, v0 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:WORD_1 src1_sel:WORD_1
; VI-NEXT:    v_or_b32_e32 v0, v1, v0
; VI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_build_vector_noncanon1_v2f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_add_f16_e32 v1, 1.0, v0
; GFX9-NEXT:    s_mov_b32 s4, 0xffff
; GFX9-NEXT:    v_bfi_b32 v0, s4, v1, v0
; GFX9-NEXT:    v_pk_max_f16 v0, v0, v0
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %lo = extractelement <2 x half> %vec, i32 0
  %lo.op = fadd half %lo, 1.0
  %ins = insertelement <2 x half> %vec, half %lo.op, i32 0
  %canonicalized = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %ins)
  ret <2 x half> %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_build_vector_noncanon0_v2f16:
; GFX9: v_add_f16_sdwa
; GFX9: v_pk_max
define <2 x half> @v_test_canonicalize_build_vector_noncanon0_v2f16(<2 x half> %vec) {
; VI-LABEL: v_test_canonicalize_build_vector_noncanon0_v2f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v1, 0x3c00
; VI-NEXT:    v_add_f16_sdwa v1, v0, v1 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:WORD_1 src1_sel:DWORD
; VI-NEXT:    v_max_f16_e32 v0, v0, v0
; VI-NEXT:    v_or_b32_e32 v0, v0, v1
; VI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_build_vector_noncanon0_v2f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v1, 0x3c00
; GFX9-NEXT:    v_add_f16_sdwa v1, v0, v1 dst_sel:DWORD dst_unused:UNUSED_PAD src0_sel:WORD_1 src1_sel:DWORD
; GFX9-NEXT:    s_mov_b32 s4, 0x5040100
; GFX9-NEXT:    v_perm_b32 v0, v1, v0, s4
; GFX9-NEXT:    v_pk_max_f16 v0, v0, v0
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %hi = extractelement <2 x half> %vec, i32 1
  %hi.op = fadd half %hi, 1.0
  %ins = insertelement <2 x half> %vec, half %hi.op, i32 1
  %canonicalized = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %ins)
  ret <2 x half> %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_extract_element_v2f16:
; GFX9: s_waitcnt
; GFX9-NEXT: v_mul_f16_e32 v0, 4.0, v0
; GFX9-NEXT: s_setpc_b64
define half @v_test_canonicalize_extract_element_v2f16(<2 x half> %vec) {
; GCN-LABEL: v_test_canonicalize_extract_element_v2f16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_mul_f16_e32 v0, 4.0, v0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %vec.op = fmul <2 x half> %vec, <half 4.0, half 4.0>
  %elt = extractelement <2 x half> %vec.op, i32 0
  %canonicalized = call half @llvm.canonicalize.f16(half %elt)
  ret half %canonicalized
}

; define <2 x half> @v_test_canonicalize_insertelement_v2f16(<2 x half> %vec, half %val, i32 %idx) {
;   %vec.op = fmul <2 x half> %vec, <half 4.0, half 4.0>
;   %ins.op = fmul half %val, 8.0
;   %ins = insertelement <2 x half> %vec.op, half %ins.op, i32 %idx
;   %canonicalized = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %ins)
;   ret <2 x half> %canonicalized
; }

; GCN-LABEL: {{^}}v_test_canonicalize_insertelement_noncanon_vec_v2f16:
; GFX9: v_mul_f16
; GFX9: v_pk_max_f16 v0, v0, v0
; GFX9-NEXT: s_setpc_b64
define <2 x half> @v_test_canonicalize_insertelement_noncanon_vec_v2f16(<2 x half> %vec, half %val, i32 %idx) {
; VI-LABEL: v_test_canonicalize_insertelement_noncanon_vec_v2f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-NEXT:    v_mul_f16_e32 v1, 0x4800, v1
; VI-NEXT:    v_lshlrev_b32_e32 v3, 16, v1
; VI-NEXT:    v_lshlrev_b32_e32 v2, 4, v2
; VI-NEXT:    s_mov_b32 s4, 0xffff
; VI-NEXT:    v_or_b32_e32 v1, v1, v3
; VI-NEXT:    v_lshlrev_b32_e64 v2, v2, s4
; VI-NEXT:    v_bfi_b32 v0, v2, v1, v0
; VI-NEXT:    v_max_f16_sdwa v1, v0, v0 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:WORD_1 src1_sel:WORD_1
; VI-NEXT:    v_max_f16_e32 v0, v0, v0
; VI-NEXT:    v_or_b32_e32 v0, v0, v1
; VI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_insertelement_noncanon_vec_v2f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_mul_f16_e32 v1, 0x4800, v1
; GFX9-NEXT:    v_lshlrev_b32_e32 v2, 4, v2
; GFX9-NEXT:    s_mov_b32 s4, 0xffff
; GFX9-NEXT:    v_pack_b32_f16 v1, v1, v1
; GFX9-NEXT:    v_lshlrev_b32_e64 v2, v2, s4
; GFX9-NEXT:    v_bfi_b32 v0, v2, v1, v0
; GFX9-NEXT:    v_pk_max_f16 v0, v0, v0
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %ins.op = fmul half %val, 8.0
  %ins = insertelement <2 x half> %vec, half %ins.op, i32 %idx
  %canonicalized = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %ins)
  ret <2 x half> %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_insertelement_noncanon_insval_v2f16:
; GFX9: v_pk_mul_f16
; GFX9: v_pk_max_f16 v0, v0, v0
; GFX9-NEXT: s_setpc_b64
define <2 x half> @v_test_canonicalize_insertelement_noncanon_insval_v2f16(<2 x half> %vec, half %val, i32 %idx) {
; VI-LABEL: v_test_canonicalize_insertelement_noncanon_insval_v2f16:
; VI:       ; %bb.0:
; VI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-NEXT:    v_mov_b32_e32 v3, 0x4400
; VI-NEXT:    v_mul_f16_sdwa v3, v0, v3 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:WORD_1 src1_sel:DWORD
; VI-NEXT:    v_mul_f16_e32 v0, 4.0, v0
; VI-NEXT:    v_or_b32_e32 v0, v0, v3
; VI-NEXT:    v_mov_b32_e32 v3, 16
; VI-NEXT:    s_mov_b32 s4, 0xffff
; VI-NEXT:    v_lshlrev_b32_sdwa v3, v3, v1 dst_sel:DWORD dst_unused:UNUSED_PAD src0_sel:DWORD src1_sel:WORD_0
; VI-NEXT:    v_lshlrev_b32_e32 v2, 4, v2
; VI-NEXT:    v_or_b32_sdwa v1, v1, v3 dst_sel:DWORD dst_unused:UNUSED_PAD src0_sel:WORD_0 src1_sel:DWORD
; VI-NEXT:    v_lshlrev_b32_e64 v2, v2, s4
; VI-NEXT:    v_bfi_b32 v0, v2, v1, v0
; VI-NEXT:    v_max_f16_sdwa v1, v0, v0 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:WORD_1 src1_sel:WORD_1
; VI-NEXT:    v_max_f16_e32 v0, v0, v0
; VI-NEXT:    v_or_b32_e32 v0, v0, v1
; VI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_insertelement_noncanon_insval_v2f16:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    s_mov_b32 s4, 0x5040100
; GFX9-NEXT:    v_perm_b32 v1, v1, v1, s4
; GFX9-NEXT:    v_lshlrev_b32_e32 v2, 4, v2
; GFX9-NEXT:    s_mov_b32 s4, 0xffff
; GFX9-NEXT:    v_pk_mul_f16 v0, v0, 4.0 op_sel_hi:[1,0]
; GFX9-NEXT:    v_lshlrev_b32_e64 v2, v2, s4
; GFX9-NEXT:    v_bfi_b32 v0, v2, v1, v0
; GFX9-NEXT:    v_pk_max_f16 v0, v0, v0
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %vec.op = fmul <2 x half> %vec, <half 4.0, half 4.0>
  %ins = insertelement <2 x half> %vec.op, half %val, i32 %idx
  %canonicalized = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %ins)
  ret <2 x half> %canonicalized
}

; define <2 x half> @v_test_canonicalize_cvt_pkrtz(float %a, float %b) {
;   %cvt = call <2 x half> @llvm.amdgcn.cvt.pkrtz(float %a, float %b)
;   %canonicalized = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %cvt)
;   ret <2 x half> %canonicalized
; }

; GCN-LABEL: {{^}}v_test_canonicalize_cubeid:
; GCN: s_waitcnt
; GCN-NEXT: v_cubeid_f32 v0, v0, v1, v2
; GCN-NEXT: s_setpc_b64
define float @v_test_canonicalize_cubeid(float %a, float %b, float %c) {
; GCN-LABEL: v_test_canonicalize_cubeid:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_cubeid_f32 v0, v0, v1, v2
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cvt = call float @llvm.amdgcn.cubeid(float %a, float %b, float %c)
  %canonicalized = call float @llvm.canonicalize.f32(float %cvt)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_frexp_mant:
; GCN: s_waitcnt
; GCN-NEXT: v_frexp_mant_f32_e32 v0, v0
; GCN-NEXT: s_setpc_b64
define float @v_test_canonicalize_frexp_mant(float %a) {
; GCN-LABEL: v_test_canonicalize_frexp_mant:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_frexp_mant_f32_e32 v0, v0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cvt = call float @llvm.amdgcn.frexp.mant.f32(float %a)
  %canonicalized = call float @llvm.canonicalize.f32(float %cvt)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_amdgcn_log:
; GCN: s_waitcnt
; GCN-NEXT: v_log_f32
; GCN-NEXT: s_setpc_b64
define float @v_test_canonicalize_amdgcn_log(float %a) {
; GCN-LABEL: v_test_canonicalize_amdgcn_log:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_log_f32_e32 v0, v0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %log = call float @llvm.amdgcn.log.f32(float %a)
  %canonicalized = call float @llvm.canonicalize.f32(float %log)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_amdgcn_exp2:
; GCN: s_waitcnt
; GCN-NEXT: v_exp_f32
; GCN-NEXT: s_setpc_b64
define float @v_test_canonicalize_amdgcn_exp2(float %a) {
; GCN-LABEL: v_test_canonicalize_amdgcn_exp2:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_exp_f32_e32 v0, v0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %log = call float @llvm.amdgcn.exp2.f32(float %a)
  %canonicalized = call float @llvm.canonicalize.f32(float %log)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_minimum:
; GCN: s_waitcnt
; GCN-NEXT: v_min_f32_e32 [[MIN:v[0-9]+]], v0, v1
; GCN-NEXT: v_mov_b32_e32 [[K:v[0-9]+]], 0x7fc00000
; GCN-NEXT: v_cmp_o_f32_e32 vcc, v0, v1
; GCN-NEXT: v_cndmask_b32_e32 v0, [[K]], [[MIN]], vcc
; VI-FLUSH-NEXT: v_mul_f32_e32 v0, 1.0, v0
; GCN-NEXT: s_setpc_b64
define float @v_test_canonicalize_minimum(float %a, float %b) {
; VI-FLUSH-LABEL: v_test_canonicalize_minimum:
; VI-FLUSH:       ; %bb.0:
; VI-FLUSH-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-FLUSH-NEXT:    v_cmp_u_f32_e32 vcc, v1, v1
; VI-FLUSH-NEXT:    v_cndmask_b32_e32 v0, v0, v1, vcc
; VI-FLUSH-NEXT:    v_cmp_u_f32_e32 vcc, v0, v0
; VI-FLUSH-NEXT:    v_cndmask_b32_e32 v1, v1, v0, vcc
; VI-FLUSH-NEXT:    v_min_f32_e32 v0, v0, v1
; VI-FLUSH-NEXT:    v_mul_f32_e32 v0, 1.0, v0
; VI-FLUSH-NEXT:    s_setpc_b64 s[30:31]
;
; VI-DENORM-LABEL: v_test_canonicalize_minimum:
; VI-DENORM:       ; %bb.0:
; VI-DENORM-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-DENORM-NEXT:    v_cmp_u_f32_e32 vcc, v1, v1
; VI-DENORM-NEXT:    v_cndmask_b32_e32 v0, v0, v1, vcc
; VI-DENORM-NEXT:    v_cmp_u_f32_e32 vcc, v0, v0
; VI-DENORM-NEXT:    v_cndmask_b32_e32 v1, v1, v0, vcc
; VI-DENORM-NEXT:    v_min_f32_e32 v0, v0, v1
; VI-DENORM-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_minimum:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_cmp_u_f32_e32 vcc, v1, v1
; GFX9-NEXT:    v_cndmask_b32_e32 v0, v0, v1, vcc
; GFX9-NEXT:    v_cmp_u_f32_e32 vcc, v0, v0
; GFX9-NEXT:    v_cndmask_b32_e32 v1, v1, v0, vcc
; GFX9-NEXT:    v_min_f32_e32 v0, v0, v1
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %min = call float @llvm.minimum.f32(float %a, float %b)
  %canonicalized = call float @llvm.canonicalize.f32(float %min)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_maximum:
; GCN: s_waitcnt
; GCN-NEXT: v_max_f32_e32 [[MIN:v[0-9]+]], v0, v1
; GCN-NEXT: v_mov_b32_e32 [[K:v[0-9]+]], 0x7fc00000
; GCN-NEXT: v_cmp_o_f32_e32 vcc, v0, v1
; GCN-NEXT: v_cndmask_b32_e32 v0, [[K]], [[MIN]], vcc
; VI-FLUSH-NEXT: v_mul_f32_e32 v0, 1.0, v0
; GCN-NEXT: s_setpc_b64
define float @v_test_canonicalize_maximum(float %a, float %b) {
; VI-FLUSH-LABEL: v_test_canonicalize_maximum:
; VI-FLUSH:       ; %bb.0:
; VI-FLUSH-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-FLUSH-NEXT:    v_cmp_u_f32_e32 vcc, v1, v1
; VI-FLUSH-NEXT:    v_cndmask_b32_e32 v0, v0, v1, vcc
; VI-FLUSH-NEXT:    v_cmp_u_f32_e32 vcc, v0, v0
; VI-FLUSH-NEXT:    v_cndmask_b32_e32 v1, v1, v0, vcc
; VI-FLUSH-NEXT:    v_max_f32_e32 v0, v0, v1
; VI-FLUSH-NEXT:    v_mul_f32_e32 v0, 1.0, v0
; VI-FLUSH-NEXT:    s_setpc_b64 s[30:31]
;
; VI-DENORM-LABEL: v_test_canonicalize_maximum:
; VI-DENORM:       ; %bb.0:
; VI-DENORM-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-DENORM-NEXT:    v_cmp_u_f32_e32 vcc, v1, v1
; VI-DENORM-NEXT:    v_cndmask_b32_e32 v0, v0, v1, vcc
; VI-DENORM-NEXT:    v_cmp_u_f32_e32 vcc, v0, v0
; VI-DENORM-NEXT:    v_cndmask_b32_e32 v1, v1, v0, vcc
; VI-DENORM-NEXT:    v_max_f32_e32 v0, v0, v1
; VI-DENORM-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_maximum:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_cmp_u_f32_e32 vcc, v1, v1
; GFX9-NEXT:    v_cndmask_b32_e32 v0, v0, v1, vcc
; GFX9-NEXT:    v_cmp_u_f32_e32 vcc, v0, v0
; GFX9-NEXT:    v_cndmask_b32_e32 v1, v1, v0, vcc
; GFX9-NEXT:    v_max_f32_e32 v0, v0, v1
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %min = call float @llvm.maximum.f32(float %a, float %b)
  %canonicalized = call float @llvm.canonicalize.f32(float %min)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_minimumnum:
; GCN: s_waitcnt
; VI-NEXT: v_mul_f32_e32 v1, 1.0, v1
; VI-NEXT: v_mul_f32_e32 v0, 1.0, v0

; GFX9-NEXT: v_max_f32_e32 v1, v1, v1
; GFX9-NEXT: v_max_f32_e32 v0, v0, v0

; GCN-NEXT: v_min_f32_e32 v0, v0, v1
; GCN-NEXT: s_setpc_b64
define float @v_test_canonicalize_minimumnum(float %a, float %b) {
; VI-LABEL: v_test_canonicalize_minimumnum:
; VI:       ; %bb.0:
; VI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v1, 1.0, v1
; VI-NEXT:    v_mul_f32_e32 v0, 1.0, v0
; VI-NEXT:    v_min_f32_e32 v0, v0, v1
; VI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_minimumnum:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    v_max_f32_e32 v0, v0, v0
; GFX9-NEXT:    v_min_f32_e32 v0, v0, v1
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %min = call float @llvm.minimumnum.f32(float %a, float %b)
  %canonicalized = call float @llvm.canonicalize.f32(float %min)
  ret float %canonicalized
}

; GCN-LABEL: {{^}}v_test_canonicalize_maximumnum:
; GCN: s_waitcnt
; VI-NEXT: v_mul_f32_e32 v1, 1.0, v1
; VI-NEXT: v_mul_f32_e32 v0, 1.0, v0

; GFX9-NEXT: v_max_f32_e32 v1, v1, v1
; GFX9-NEXT: v_max_f32_e32 v0, v0, v0

; GCN-NEXT: v_max_f32_e32 v0, v0, v1
; GCN-NEXT: s_setpc_b64
define float @v_test_canonicalize_maximumnum(float %a, float %b) {
; VI-LABEL: v_test_canonicalize_maximumnum:
; VI:       ; %bb.0:
; VI-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-NEXT:    v_mul_f32_e32 v1, 1.0, v1
; VI-NEXT:    v_mul_f32_e32 v0, 1.0, v0
; VI-NEXT:    v_max_f32_e32 v0, v0, v1
; VI-NEXT:    s_setpc_b64 s[30:31]
;
; GFX9-LABEL: v_test_canonicalize_maximumnum:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GFX9-NEXT:    v_max_f32_e32 v1, v1, v1
; GFX9-NEXT:    v_max_f32_e32 v0, v0, v0
; GFX9-NEXT:    v_max_f32_e32 v0, v0, v1
; GFX9-NEXT:    s_setpc_b64 s[30:31]
  %min = call float @llvm.maximumnum.f32(float %a, float %b)
  %canonicalized = call float @llvm.canonicalize.f32(float %min)
  ret float %canonicalized
}

; Avoid failing the test on FreeBSD11.0 which will match the GCN-NOT: 1.0
; in the .amd_amdgpu_isa "amdgcn-unknown-freebsd11.0--gfx802" directive
; GCN: .amd_amdgpu_isa

declare float @llvm.canonicalize.f32(float) #0
declare float @llvm.copysign.f32(float, float) #0
declare float @llvm.amdgcn.fmul.legacy(float, float) #0
declare float @llvm.amdgcn.fmad.ftz.f32(float, float, float) #0
declare double @llvm.canonicalize.f64(double) #0
declare half @llvm.canonicalize.f16(half) #0
declare <2 x half> @llvm.canonicalize.v2f16(<2 x half>) #0
declare i32 @llvm.amdgcn.workitem.id.x() #0
declare float @llvm.sqrt.f32(float) #0
declare float @llvm.ceil.f32(float) #0
declare float @llvm.floor.f32(float) #0
declare float @llvm.fma.f32(float, float, float) #0
declare float @llvm.fmuladd.f32(float, float, float) #0
declare float @llvm.fabs.f32(float) #0
declare float @llvm.sin.f32(float) #0
declare float @llvm.cos.f32(float) #0
declare half @llvm.sin.f16(half) #0
declare half @llvm.cos.f16(half) #0
declare float @llvm.minnum.f32(float, float) #0
declare float @llvm.maxnum.f32(float, float) #0
declare double @llvm.maxnum.f64(double, double) #0
declare <2 x half> @llvm.amdgcn.cvt.pkrtz(float, float) #0
declare float @llvm.amdgcn.cubeid(float, float, float) #0
declare float @llvm.amdgcn.frexp.mant.f32(float) #0
declare float @llvm.amdgcn.log.f32(float) #0
declare float @llvm.amdgcn.exp2.f32(float) #0

attributes #0 = { nounwind readnone }
attributes #1 = { "no-nans-fp-math"="true" }
attributes #2 = { "denormal-fp-math"="preserve-sign,preserve-sign" "denormal-fp-math-f32"="ieee,ieee" }
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; GCN-DENORM: {{.*}}
; GCN-FLUSH: {{.*}}
