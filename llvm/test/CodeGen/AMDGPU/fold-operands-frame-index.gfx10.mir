# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
# RUN: llc -mtriple=amdgcn -mcpu=gfx1030 -verify-machineinstrs -run-pass=si-fold-operands %s -o - | FileCheck %s
# RUN: llc -mtriple=amdgcn -mcpu=gfx1200 -verify-machineinstrs -run-pass=si-fold-operands %s -o - | FileCheck %s

---
name:  fold_frame_index__v_add_u32_e32__const_v_fi
tracksRegLiveness: true
frameInfo:
  maxAlignment:    4
  localFrameSize:  16384
stack:
  - { id: 0, size: 16384, alignment: 4, local-offset: 0 }
body:             |
  bb.0:
    ; CHECK-LABEL: name: fold_frame_index__v_add_u32_e32__const_v_fi
    ; CHECK: [[V_ADD_U32_e32_:%[0-9]+]]:vgpr_32 = V_ADD_U32_e32 128, %stack.0, implicit $exec
    ; CHECK-NEXT: $vgpr0 = COPY [[V_ADD_U32_e32_]]
    ; CHECK-NEXT: SI_RETURN implicit $vgpr0
    %0:vgpr_32 = V_MOV_B32_e32 %stack.0, implicit $exec
    %1:vgpr_32 = V_ADD_U32_e32 128, %0, implicit $exec
    $vgpr0 = COPY %1
    SI_RETURN implicit $vgpr0
...

---
name:  fold_frame_index__v_add_co_u32_e64__v_fi_const
tracksRegLiveness: true
frameInfo:
  maxAlignment:    4
  localFrameSize:  16384
stack:
  - { id: 0, size: 16384, alignment: 4, local-offset: 0 }
body:             |
  bb.0:
    ; CHECK-LABEL: name: fold_frame_index__v_add_co_u32_e64__v_fi_const
    ; CHECK: [[V_ADD_CO_U32_e64_:%[0-9]+]]:vgpr_32, [[V_ADD_CO_U32_e64_1:%[0-9]+]]:sreg_32 = V_ADD_CO_U32_e64 %stack.0, 128, 0, implicit $exec
    ; CHECK-NEXT: $vgpr0 = COPY [[V_ADD_CO_U32_e64_]]
    ; CHECK-NEXT: SI_RETURN implicit $vgpr0
    %0:vgpr_32 = V_MOV_B32_e32 %stack.0, implicit $exec
    %1:vgpr_32, %2:sreg_32 = V_ADD_CO_U32_e64 %0, 128, 0, implicit $exec
    $vgpr0 = COPY %1
    SI_RETURN implicit $vgpr0
...



---
name:  fold_frame_index__v_add_u32_e64__const_v_fi
tracksRegLiveness: true
frameInfo:
  maxAlignment:    4
  localFrameSize:  16384
stack:
  - { id: 0, size: 16384, alignment: 4, local-offset: 0 }
body:             |
  bb.0:
    ; CHECK-LABEL: name: fold_frame_index__v_add_u32_e64__const_v_fi
    ; CHECK: [[V_ADD_U32_e64_:%[0-9]+]]:vgpr_32 = V_ADD_U32_e64 128, %stack.0, 0, implicit $exec
    ; CHECK-NEXT: $sgpr4 = COPY [[V_ADD_U32_e64_]]
    ; CHECK-NEXT: SI_RETURN implicit $sgpr4
    %0:vgpr_32 = V_MOV_B32_e32 %stack.0, implicit $exec
    %1:vgpr_32 = V_ADD_U32_e64 128, %0, 0, implicit $exec
    $sgpr4 = COPY %1
    SI_RETURN implicit $sgpr4
...

---
name:  fold_frame_index__v_add_u32_e64___v_fi_const
tracksRegLiveness: true
frameInfo:
  maxAlignment:    4
  localFrameSize:  16384
stack:
  - { id: 0, size: 16384, alignment: 4, local-offset: 0 }
body:             |
  bb.0:
    ; CHECK-LABEL: name: fold_frame_index__v_add_u32_e64___v_fi_const
    ; CHECK: [[V_ADD_U32_e64_:%[0-9]+]]:vgpr_32 = V_ADD_U32_e64 %stack.0, 128, 0, implicit $exec
    ; CHECK-NEXT: $sgpr4 = COPY [[V_ADD_U32_e64_]]
    ; CHECK-NEXT: SI_RETURN implicit $sgpr4
    %0:vgpr_32 = V_MOV_B32_e32 %stack.0, implicit $exec
    %1:vgpr_32 = V_ADD_U32_e64 %0, 128, 0, implicit $exec
    $sgpr4 = COPY %1
    SI_RETURN implicit $sgpr4
...

---
name:  fold_frame_index__v_add_co_u32_e64___fi_const_v
tracksRegLiveness: true
frameInfo:
  maxAlignment:    4
  localFrameSize:  16384
stack:
  - { id: 0, size: 16384, alignment: 4, local-offset: 0 }
body:             |
  bb.0:
    ; CHECK-LABEL: name: fold_frame_index__v_add_co_u32_e64___fi_const_v
    ; CHECK: [[V_ADD_CO_U32_e64_:%[0-9]+]]:vgpr_32, [[V_ADD_CO_U32_e64_1:%[0-9]+]]:sreg_32 = V_ADD_CO_U32_e64 128, %stack.0, 0, implicit $exec
    ; CHECK-NEXT: $vgpr0 = COPY [[V_ADD_CO_U32_e64_]]
    ; CHECK-NEXT: SI_RETURN implicit $vgpr0
    %0:vgpr_32 = V_MOV_B32_e32 %stack.0, implicit $exec
    %1:vgpr_32, %2:sreg_32 = V_ADD_CO_U32_e64 128, %0, 0, implicit $exec
    $vgpr0 = COPY %1
    SI_RETURN implicit $vgpr0
...

---
name:  fold_frame_index__v_add_co_u32_e64__v_fi_imm
tracksRegLiveness: true
frameInfo:
  maxAlignment:    4
  localFrameSize:  16384
stack:
  - { id: 0, size: 16384, alignment: 4, local-offset: 0 }
body:             |
  bb.0:
    ; CHECK-LABEL: name: fold_frame_index__v_add_co_u32_e64__v_fi_imm
    ; CHECK: [[V_ADD_CO_U32_e64_:%[0-9]+]]:vgpr_32, [[V_ADD_CO_U32_e64_1:%[0-9]+]]:sreg_32 = V_ADD_CO_U32_e64 %stack.0, 64, 0, implicit $exec
    ; CHECK-NEXT: $vgpr0 = COPY [[V_ADD_CO_U32_e64_]]
    ; CHECK-NEXT: SI_RETURN implicit $vgpr0
    %0:vgpr_32 = V_MOV_B32_e32 %stack.0, implicit $exec
    %1:vgpr_32, %2:sreg_32 = V_ADD_CO_U32_e64 %0, 64, 0, implicit $exec
    $vgpr0 = COPY %1
    SI_RETURN implicit $vgpr0
...

