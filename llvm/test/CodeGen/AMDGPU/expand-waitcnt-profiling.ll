; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc -mtriple=amdgcn -mcpu=gfx900 -amdgpu-expand-waitcnt-profiling -verify-machineinstrs < %s | FileCheck --check-prefix=EXPAND %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx900 -verify-machineinstrs < %s | FileCheck --check-prefix=NOEXPAND %s

; This test demonstrates the waitcnt expansion feature for PC-sampling profiling.
; The expansion transforms a single waitcnt instruction into a sequence of waitcnts
; with decreasing counter values to help identify which specific memory operation
; is causing a bottleneck.
;
; The kernels below keep multiple memory operations in flight before each waitcnt
; so that ScoreBrackets tracks a non-zero number of outstanding events. When
; -amdgpu-expand-waitcnt-profiling is enabled, each combined wait is expanded
; into a descending sequence (e.g. outstanding=3 emits lgkmcnt(2), (1), (0))
; which lets PC-sampling attribute long-latency stalls to the specific operation.

define amdgpu_kernel void @case1_single_counter_lgkmcnt(
; EXPAND-LABEL: case1_single_counter_lgkmcnt:
; EXPAND:       ; %bb.0:
; EXPAND-NEXT:    s_load_dwordx8 s[8:15], s[4:5], 0x24
; EXPAND-NEXT:    v_mov_b32_e32 v0, 0
; EXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; EXPAND-NEXT:    s_load_dword s0, s[8:9], 0x0
; EXPAND-NEXT:    s_load_dword s1, s[10:11], 0x0
; EXPAND-NEXT:    s_load_dword s2, s[12:13], 0x0
; EXPAND-NEXT:    s_waitcnt lgkmcnt(2)
; EXPAND-NEXT:    s_waitcnt lgkmcnt(1)
; EXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; EXPAND-NEXT:    s_add_i32 s0, s0, s1
; EXPAND-NEXT:    s_add_i32 s0, s0, s2
; EXPAND-NEXT:    v_mov_b32_e32 v1, s0
; EXPAND-NEXT:    global_store_dword v0, v1, s[14:15]
; EXPAND-NEXT:    s_endpgm
;
; NOEXPAND-LABEL: case1_single_counter_lgkmcnt:
; NOEXPAND:       ; %bb.0:
; NOEXPAND-NEXT:    s_load_dwordx8 s[8:15], s[4:5], 0x24
; NOEXPAND-NEXT:    v_mov_b32_e32 v0, 0
; NOEXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; NOEXPAND-NEXT:    s_load_dword s0, s[8:9], 0x0
; NOEXPAND-NEXT:    s_load_dword s1, s[10:11], 0x0
; NOEXPAND-NEXT:    s_load_dword s2, s[12:13], 0x0
; NOEXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; NOEXPAND-NEXT:    s_add_i32 s0, s0, s1
; NOEXPAND-NEXT:    s_add_i32 s0, s0, s2
; NOEXPAND-NEXT:    v_mov_b32_e32 v1, s0
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[14:15]
; NOEXPAND-NEXT:    s_endpgm
    ptr addrspace(4) %ptr_a,
    ptr addrspace(4) %ptr_b,
    ptr addrspace(4) %ptr_c,
    ptr addrspace(1) %out) {
  ; Three scalar loads - increment lgkmcnt
  %val_a = load i32, ptr addrspace(4) %ptr_a, align 4
  %val_b = load i32, ptr addrspace(4) %ptr_b, align 4
  %val_c = load i32, ptr addrspace(4) %ptr_c, align 4

  ; Use all three values
  %sum1 = add i32 %val_a, %val_b
  %sum2 = add i32 %sum1, %val_c

  store i32 %sum2, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @case2_independent_counters(
; EXPAND-LABEL: case2_independent_counters:
; EXPAND:       ; %bb.0:
; EXPAND-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; EXPAND-NEXT:    s_load_dwordx2 s[6:7], s[4:5], 0x34
; EXPAND-NEXT:    v_mov_b32_e32 v0, 0
; EXPAND-NEXT:    s_waitcnt lgkmcnt(1)
; EXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; EXPAND-NEXT:    s_load_dword s4, s[0:1], 0x0
; EXPAND-NEXT:    s_load_dword s5, s[2:3], 0x0
; EXPAND-NEXT:    s_waitcnt lgkmcnt(1)
; EXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; EXPAND-NEXT:    s_add_i32 s0, s4, s5
; EXPAND-NEXT:    v_mov_b32_e32 v1, s0
; EXPAND-NEXT:    global_store_dword v0, v1, s[6:7]
; EXPAND-NEXT:    s_endpgm
;
; NOEXPAND-LABEL: case2_independent_counters:
; NOEXPAND:       ; %bb.0:
; NOEXPAND-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; NOEXPAND-NEXT:    s_load_dwordx2 s[6:7], s[4:5], 0x34
; NOEXPAND-NEXT:    v_mov_b32_e32 v0, 0
; NOEXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; NOEXPAND-NEXT:    s_load_dword s4, s[0:1], 0x0
; NOEXPAND-NEXT:    s_load_dword s5, s[2:3], 0x0
; NOEXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; NOEXPAND-NEXT:    s_add_i32 s0, s4, s5
; NOEXPAND-NEXT:    v_mov_b32_e32 v1, s0
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[6:7]
; NOEXPAND-NEXT:    s_endpgm
    ptr addrspace(1) %global_ptr,
    ptr addrspace(4) %scalar_ptr,
    ptr addrspace(1) %out) {
  ; Global memory load - increments vmcnt
  %global_val = load i32, ptr addrspace(1) %global_ptr, align 4

  ; Scalar memory load - increments lgkmcnt
  %scalar_val = load i32, ptr addrspace(4) %scalar_ptr, align 4

  ; Use both values - compiler must wait for both counters
  %result = add i32 %global_val, %scalar_val

  store i32 %result, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @case3_overlapping_counters(
; EXPAND-LABEL: case3_overlapping_counters:
; EXPAND:       ; %bb.0:
; EXPAND-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; EXPAND-NEXT:    s_load_dwordx2 s[6:7], s[4:5], 0x34
; EXPAND-NEXT:    v_mov_b32_e32 v0, 0
; EXPAND-NEXT:    v_mov_b32_e32 v1, 1
; EXPAND-NEXT:    v_mov_b32_e32 v2, 2
; EXPAND-NEXT:    s_waitcnt lgkmcnt(1)
; EXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v1, s[0:1]
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:4
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:8
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:12
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:16
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:20
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:24
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:28
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:32
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:36
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:40
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:44
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    s_add_u32 s2, s2, s6
; EXPAND-NEXT:    s_addc_u32 s3, s3, s7
; EXPAND-NEXT:    global_load_dword v1, v0, s[2:3] glc
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:48
; EXPAND-NEXT:    s_waitcnt vmcnt(0)
; EXPAND-NEXT:    s_endpgm
;
; NOEXPAND-LABEL: case3_overlapping_counters:
; NOEXPAND:       ; %bb.0:
; NOEXPAND-NEXT:    s_load_dwordx4 s[0:3], s[4:5], 0x24
; NOEXPAND-NEXT:    s_load_dwordx2 s[6:7], s[4:5], 0x34
; NOEXPAND-NEXT:    v_mov_b32_e32 v0, 0
; NOEXPAND-NEXT:    v_mov_b32_e32 v1, 1
; NOEXPAND-NEXT:    v_mov_b32_e32 v2, 2
; NOEXPAND-NEXT:    s_waitcnt lgkmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[0:1]
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:4
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:8
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:12
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:16
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:20
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:24
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:28
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:32
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:36
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:40
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v2, s[0:1] offset:44
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    s_add_u32 s2, s2, s6
; NOEXPAND-NEXT:    s_addc_u32 s3, s3, s7
; NOEXPAND-NEXT:    global_load_dword v1, v0, s[2:3] glc
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    global_store_dword v0, v1, s[0:1] offset:48
; NOEXPAND-NEXT:    s_waitcnt vmcnt(0)
; NOEXPAND-NEXT:    s_endpgm
    ptr addrspace(1) %buf,
    ptr addrspace(1) %data,
    i64 %offset) {
  ; Issue 12 stores to buffer - each increments vmcnt
  %ptr0 = getelementptr i32, ptr addrspace(1) %buf, i64 0
  store volatile i32 1, ptr addrspace(1) %ptr0, align 4
  %ptr1 = getelementptr i32, ptr addrspace(1) %buf, i64 1
  store volatile i32 2, ptr addrspace(1) %ptr1, align 4
  %ptr2 = getelementptr i32, ptr addrspace(1) %buf, i64 2
  store volatile i32 1, ptr addrspace(1) %ptr2, align 4
  %ptr3 = getelementptr i32, ptr addrspace(1) %buf, i64 3
  store volatile i32 2, ptr addrspace(1) %ptr3, align 4
  %ptr4 = getelementptr i32, ptr addrspace(1) %buf, i64 4
  store volatile i32 1, ptr addrspace(1) %ptr4, align 4
  %ptr5 = getelementptr i32, ptr addrspace(1) %buf, i64 5
  store volatile i32 2, ptr addrspace(1) %ptr5, align 4
  %ptr6 = getelementptr i32, ptr addrspace(1) %buf, i64 6
  store volatile i32 1, ptr addrspace(1) %ptr6, align 4
  %ptr7 = getelementptr i32, ptr addrspace(1) %buf, i64 7
  store volatile i32 2, ptr addrspace(1) %ptr7, align 4
  %ptr8 = getelementptr i32, ptr addrspace(1) %buf, i64 8
  store volatile i32 1, ptr addrspace(1) %ptr8, align 4
  %ptr9 = getelementptr i32, ptr addrspace(1) %buf, i64 9
  store volatile i32 2, ptr addrspace(1) %ptr9, align 4
  %ptr10 = getelementptr i32, ptr addrspace(1) %buf, i64 10
  store volatile i32 1, ptr addrspace(1) %ptr10, align 4
  %ptr11 = getelementptr i32, ptr addrspace(1) %buf, i64 11
  store volatile i32 2, ptr addrspace(1) %ptr11, align 4

  ; Load from potentially aliasing address - also increments vmcnt
  %data_ptr = getelementptr i8, ptr addrspace(1) %data, i64 %offset
  %loaded = load volatile i32, ptr addrspace(1) %data_ptr, align 4

  ; Store the loaded value
  %ptr12 = getelementptr i32, ptr addrspace(1) %buf, i64 12
  store volatile i32 %loaded, ptr addrspace(1) %ptr12, align 4

  ret void
}
