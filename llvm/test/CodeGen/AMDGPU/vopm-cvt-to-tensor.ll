; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=amdgcn -mcpu=gfx1300 < %s | FileCheck %s --check-prefix=GFX13

define amdgpu_ps void @test_cvt_to_tensor_i4_fp32_8x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i4_fp32_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_fp32 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i4.fp32.scatter2(<4 x float> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i4_fp32_4x4(<4 x float> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i4_fp32_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_fp32 v0, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i4.fp32(<4 x float> %acc_in, i32 2, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i4_fp32_4x2(<4 x float> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i4_fp32_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_fp32 v0, v[0:3] clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i4.fp32(<4 x float> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i4_fp16_8x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i4_fp16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_fp16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i4.fp16.scatter2(<8 x half> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i4_fp16_4x4(<8 x half> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i4_fp16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_fp16 v0, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i4.fp16.v8f16(<8 x half> %acc_in, i32 2, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i4_fp16_4x2(<4 x half> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i4_fp16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_fp16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i4.fp16.v4f16(<4 x half> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i4_bf16_8x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i4_bf16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_bf16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i4.bf16.scatter2(<8 x bfloat> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i4_bf16_4x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i4_bf16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_bf16 v0, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i4.bf16.v8bf16(<8 x bfloat> %acc_in, i32 2, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i4_bf16_4x2(<4 x bfloat> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i4_bf16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i4_bf16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i4.bf16.v4bf16(<4 x bfloat> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_fp32_8x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u4_fp32_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_fp32 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u4.fp32.scatter2(<4 x float> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_fp32_4x4(<4 x float> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u4_fp32_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_fp32 v0, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u4.fp32(<4 x float> %acc_in, i32 2, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_fp32_4x2(<4 x float> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u4_fp32_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_fp32 v0, v[0:3] clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u4.fp32(<4 x float> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_fp16_8x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u4_fp16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_fp16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u4.fp16.scatter2(<8 x half> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_fp16_4x4(<8 x half> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u4_fp16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_fp16 v0, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u4.fp16.v8f16(<8 x half> %acc_in, i32 2, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_fp16_4x2(<4 x half> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u4_fp16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_fp16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u4.fp16.v4f16(<4 x half> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_bf16_8x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u4_bf16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_bf16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u4.bf16.scatter2(<8 x bfloat> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_bf16_4x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u4_bf16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_bf16 v0, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u4.bf16.v8bf16(<8 x bfloat> %acc_in, i32 2, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u4_bf16_4x2(<4 x bfloat> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u4_bf16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u4_bf16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u4.bf16.v4bf16(<4 x bfloat> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_fp32_8x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i8_fp32_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_fp32 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i8.fp32.scatter2(<4 x float> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_fp32_4x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i8_fp32_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_fp32 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i8.fp32.scatter2(<4 x float> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_fp32_4x2(<4 x float> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i8_fp32_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_fp32 v0, v[0:3] clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i8.fp32(<4 x float> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_fp16_8x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i8_fp16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_fp16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i8.fp16.scatter2(<8 x half> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_fp16_4x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i8_fp16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_fp16 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i8.fp16.scatter2(<8 x half> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_fp16_4x2(<4 x half> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i8_fp16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_fp16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i8.fp16(<4 x half> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_bf16_8x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i8_bf16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_bf16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i8.bf16.scatter2(<8 x bfloat> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_bf16_4x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_i8_bf16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_bf16 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.i8.bf16.scatter2(<8 x bfloat> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_i8_bf16_4x2(<4 x bfloat> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_i8_bf16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_i8_bf16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.i8.bf16(<4 x bfloat> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_fp32_8x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u8_fp32_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_fp32 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u8.fp32.scatter2(<4 x float> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_fp32_4x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u8_fp32_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_fp32 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u8.fp32.scatter2(<4 x float> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_fp32_4x2(<4 x float> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u8_fp32_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_fp32 v0, v[0:3] clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u8.fp32(<4 x float> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_fp16_8x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u8_fp16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_fp16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u8.fp16.scatter2(<8 x half> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_fp16_4x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u8_fp16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_fp16 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u8.fp16.scatter2(<8 x half> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_fp16_4x2(<4 x half> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u8_fp16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_fp16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u8.fp16(<4 x half> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_bf16_8x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u8_bf16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_bf16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u8.bf16.scatter2(<8 x bfloat> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_bf16_4x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_u8_bf16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_bf16 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.u8.bf16.scatter2(<8 x bfloat> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_u8_bf16_4x2(<4 x bfloat> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_u8_bf16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_u8_bf16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.u8.bf16(<4 x bfloat> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_fp32_8x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_fp32_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_fp32 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.fp8.fp32.scatter2(<4 x float> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_fp32_4x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_fp32_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_fp32 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.fp8.fp32.scatter2(<4 x float> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_fp32_4x2(<4 x float> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_fp32_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_fp32 v0, v[0:3] clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.fp8.fp32(<4 x float> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_fp16_8x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_fp16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_fp16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.fp8.fp16.scatter2(<8 x half> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_fp16_4x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_fp16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_fp16 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.fp8.fp16.scatter2(<8 x half> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_fp16_4x2(<4 x half> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_fp16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_fp16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.fp8.fp16(<4 x half> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_bf16_8x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_bf16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_bf16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.fp8.bf16.scatter2(<8 x bfloat> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_bf16_4x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_bf16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_bf16 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.fp8.bf16.scatter2(<8 x bfloat> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp8_bf16_4x2(<4 x bfloat> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_fp8_bf16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp8_bf16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.fp8.bf16(<4 x bfloat> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_fp32_8x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_fp32_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_fp32 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.bf8.fp32.scatter2(<4 x float> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_fp32_4x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_fp32_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_fp32 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.bf8.fp32.scatter2(<4 x float> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_fp32_4x2(<4 x float> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_fp32_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_fp32 v0, v[0:3] clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.bf8.fp32(<4 x float> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_fp16_8x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_fp16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_fp16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.bf8.fp16.scatter2(<8 x half> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_fp16_4x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_fp16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_fp16 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.bf8.fp16.scatter2(<8 x half> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_fp16_4x2(<4 x half> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_fp16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_fp16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.bf8.fp16(<4 x half> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_bf16_8x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_bf16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_bf16 v0, v1, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.bf8.bf16.scatter2(<8 x bfloat> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_bf16_4x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_bf16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_bf16 v0, v1, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { i32, i32 } @llvm.amdgcn.cvt.to.tensor.bf8.bf16.scatter2(<8 x bfloat> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { i32, i32 } %pair, 0
  %dst1 = extractvalue { i32, i32 } %pair, 1
  store i32 %dst0, ptr addrspace(1) %out0
  store i32 %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf8_bf16_4x2(<4 x bfloat> %acc_in, ptr addrspace(1) %out0) {
; GFX13-LABEL: test_cvt_to_tensor_bf8_bf16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf8_bf16 v0, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %dest = call i32 @llvm.amdgcn.cvt.to.tensor.bf8.bf16(<4 x bfloat> %acc_in, i32 0, i1 1)
  store i32 %dest, ptr addrspace(1) %out0
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_fp32_8x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_fp32_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_fp32 v0, v1, v2, v3, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x half>, <2 x half>, <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.fp32.scatter4(<4 x float> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 0
  %dst1 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 1
  %dst2 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 2
  %dst3 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 3
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  store <2 x half> %dst2, ptr addrspace(1) %out2
  store <2 x half> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_fp32_4x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_fp32_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_fp32 v0, v1, v2, v3, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x half>, <2 x half>, <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.fp32.scatter4(<4 x float> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 0
  %dst1 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 1
  %dst2 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 2
  %dst3 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 3
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  store <2 x half> %dst2, ptr addrspace(1) %out2
  store <2 x half> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_fp32_4x2(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_fp32_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_fp32 v0, v1, v[0:3] clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.fp32.scatter2(<4 x float> %acc_in, i32 0, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half> } %pair, 0
  %dst1 = extractvalue { <2 x half>, <2 x half> } %pair, 1
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_fp16_8x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_fp16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_fp16 v0, v1, v2, v3, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x half>, <2 x half>, <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.fp16.scatter4(<8 x half> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 0
  %dst1 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 1
  %dst2 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 2
  %dst3 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 3
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  store <2 x half> %dst2, ptr addrspace(1) %out2
  store <2 x half> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_fp16_4x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_fp16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_fp16 v0, v1, v2, v3, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x half>, <2 x half>, <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.fp16.scatter4(<8 x half> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 0
  %dst1 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 1
  %dst2 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 2
  %dst3 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 3
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  store <2 x half> %dst2, ptr addrspace(1) %out2
  store <2 x half> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_fp16_4x2(<4 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_fp16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_fp16 v0, v1, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    global_store_b32 v[4:5], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.fp16.scatter2(<4 x half> %acc_in, i32 0, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half> } %pair, 0
  %dst1 = extractvalue { <2 x half>, <2 x half> } %pair, 1
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_bf16_8x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_bf16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_bf16 v0, v1, v2, v3, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x half>, <2 x half>, <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.bf16.scatter4(<8 x bfloat> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 0
  %dst1 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 1
  %dst2 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 2
  %dst3 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 3
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  store <2 x half> %dst2, ptr addrspace(1) %out2
  store <2 x half> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_bf16_4x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_bf16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_bf16 v0, v1, v2, v3, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x half>, <2 x half>, <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.bf16.scatter4(<8 x bfloat> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 0
  %dst1 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 1
  %dst2 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 2
  %dst3 = extractvalue { <2 x half>, <2 x half>, <2 x half>, <2 x half> } %quad, 3
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  store <2 x half> %dst2, ptr addrspace(1) %out2
  store <2 x half> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_fp16_bf16_4x2(<4 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_fp16_bf16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_fp16_bf16 v0, v1, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    global_store_b32 v[4:5], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { <2 x half>, <2 x half> } @llvm.amdgcn.cvt.to.tensor.fp16.bf16.scatter2(<4 x bfloat> %acc_in, i32 0, i1 1)
  %dst0 = extractvalue { <2 x half>, <2 x half> } %pair, 0
  %dst1 = extractvalue { <2 x half>, <2 x half> } %pair, 1
  store <2 x half> %dst0, ptr addrspace(1) %out0
  store <2 x half> %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_fp32_8x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_fp32_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_fp32 v0, v1, v2, v3, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.fp32.scatter4(<4 x float> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 1
  %dst2 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 2
  %dst3 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 3
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  store <2 x bfloat> %dst2, ptr addrspace(1) %out2
  store <2 x bfloat> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_fp32_4x4(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_fp32_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_fp32 v0, v1, v2, v3, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.fp32.scatter4(<4 x float> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 1
  %dst2 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 2
  %dst3 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 3
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  store <2 x bfloat> %dst2, ptr addrspace(1) %out2
  store <2 x bfloat> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_fp32_4x2(<4 x float> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_fp32_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_fp32 v0, v1, v[0:3] clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.fp32.scatter2(<4 x float> %acc_in, i32 0, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat> } %pair, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat> } %pair, 1
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_fp16_8x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_fp16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_fp16 v0, v1, v2, v3, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.fp16.scatter4(<8 x half> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 1
  %dst2 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 2
  %dst3 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 3
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  store <2 x bfloat> %dst2, ptr addrspace(1) %out2
  store <2 x bfloat> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_fp16_4x4(<8 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_fp16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_fp16 v0, v1, v2, v3, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.fp16.scatter4(<8 x half> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 1
  %dst2 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 2
  %dst3 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 3
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  store <2 x bfloat> %dst2, ptr addrspace(1) %out2
  store <2 x bfloat> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_fp16_4x2(<4 x half> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_fp16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_fp16 v0, v1, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    global_store_b32 v[4:5], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.fp16.scatter2(<4 x half> %acc_in, i32 0, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat> } %pair, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat> } %pair, 1
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_bf16_8x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_bf16_8x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_bf16 v0, v1, v2, v3, v[0:3] aux_data:4 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.bf16.scatter4(<8 x bfloat> %acc_in, i32 4, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 1
  %dst2 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 2
  %dst3 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 3
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  store <2 x bfloat> %dst2, ptr addrspace(1) %out2
  store <2 x bfloat> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_bf16_4x4(<8 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_bf16_4x4:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_bf16 v0, v1, v2, v3, v[0:3] aux_data:2 clamp
; GFX13-NEXT:    global_store_b32 v[4:5], v0, off
; GFX13-NEXT:    global_store_b32 v[6:7], v1, off
; GFX13-NEXT:    global_store_b32 v[8:9], v2, off
; GFX13-NEXT:    global_store_b32 v[10:11], v3, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %quad = call { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.bf16.scatter4(<8 x bfloat> %acc_in, i32 2, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 1
  %dst2 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 2
  %dst3 = extractvalue { <2 x bfloat>, <2 x bfloat>, <2 x bfloat>, <2 x bfloat> } %quad, 3
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  store <2 x bfloat> %dst2, ptr addrspace(1) %out2
  store <2 x bfloat> %dst3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_ps void @test_cvt_to_tensor_bf16_bf16_4x2(<4 x bfloat> %acc_in, ptr addrspace(1) %out0, ptr addrspace(1) %out1) {
; GFX13-LABEL: test_cvt_to_tensor_bf16_bf16_4x2:
; GFX13:       ; %bb.0: ; %bb
; GFX13-NEXT:    v_cvt_to_tensor_bf16_bf16 v0, v1, v[0:1] clamp
; GFX13-NEXT:    global_store_b32 v[2:3], v0, off
; GFX13-NEXT:    global_store_b32 v[4:5], v1, off
; GFX13-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX13-NEXT:    s_endpgm
bb:
  %pair = call { <2 x bfloat>, <2 x bfloat> } @llvm.amdgcn.cvt.to.tensor.bf16.bf16.scatter2(<4 x bfloat> %acc_in, i32 0, i1 1)
  %dst0 = extractvalue { <2 x bfloat>, <2 x bfloat> } %pair, 0
  %dst1 = extractvalue { <2 x bfloat>, <2 x bfloat> } %pair, 1
  store <2 x bfloat> %dst0, ptr addrspace(1) %out0
  store <2 x bfloat> %dst1, ptr addrspace(1) %out1
  ret void
}

