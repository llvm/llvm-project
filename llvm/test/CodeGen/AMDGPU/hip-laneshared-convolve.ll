; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn-- -mcpu=gfx1300 -amdgpu-promote-lane-shared=false -stop-after=finalize-isel -verify-machineinstrs -o - %s | FileCheck %s
; RUN: llc -mtriple=amdgcn-- -mcpu=gfx1300 -stop-after=finalize-isel -o - %s | FileCheck -check-prefix=VIDX %s
target datalayout = "A5"

@weights = external local_unnamed_addr addrspace(10) global <9 x i32>, align 64
@col_center = external local_unnamed_addr addrspace(10) global <3 x i32>, align 16
@col_left = external local_unnamed_addr addrspace(10) global <3 x i32>, align 16
@col_right = external local_unnamed_addr addrspace(10) global <3 x i32>, align 16
@out = external local_unnamed_addr addrspace(10) global <8 x i16>, align 16

; Function Attrs: convergent mustprogress nofree norecurse nosync nounwind memory(readwrite, argmem: none, inaccessiblemem: none)
define dso_local amdgpu_kernel void @_Z36test_amdgcn_convolve_f16_fp8_3x3_4x4v() local_unnamed_addr {
  ; CHECK-LABEL: name: _Z36test_amdgcn_convolve_f16_fp8_3x3_4x4v
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   [[S_MOV_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 160
  ; CHECK-NEXT:   [[SCRATCH_LOAD_DWORDX3_SADDR:%[0-9]+]]:vreg_96_align2 = SCRATCH_LOAD_DWORDX3_SADDR killed [[S_MOV_B32_]], 0, 0, implicit $exec, implicit $flat_scr :: (dereferenceable load (s96) from @col_center, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 144
  ; CHECK-NEXT:   [[SCRATCH_LOAD_DWORDX3_SADDR1:%[0-9]+]]:vreg_96_align2 = SCRATCH_LOAD_DWORDX3_SADDR killed [[S_MOV_B32_1]], 0, 0, implicit $exec, implicit $flat_scr :: (dereferenceable load (s96) from @col_left, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 128
  ; CHECK-NEXT:   [[SCRATCH_LOAD_DWORDX3_SADDR2:%[0-9]+]]:vreg_96_align2 = SCRATCH_LOAD_DWORDX3_SADDR killed [[S_MOV_B32_2]], 0, 0, implicit $exec, implicit $flat_scr :: (dereferenceable load (s96) from @col_right, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 96
  ; CHECK-NEXT:   [[SCRATCH_LOAD_DWORD_SADDR:%[0-9]+]]:vgpr_32 = SCRATCH_LOAD_DWORD_SADDR killed [[S_MOV_B32_3]], 0, 0, implicit $exec, implicit $flat_scr :: (dereferenceable load (s32) from @weights + 32, align 32, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_4:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 80
  ; CHECK-NEXT:   [[SCRATCH_LOAD_DWORDX4_SADDR:%[0-9]+]]:vreg_128_align2 = SCRATCH_LOAD_DWORDX4_SADDR killed [[S_MOV_B32_4]], 0, 0, implicit $exec, implicit $flat_scr :: (dereferenceable load (s128) from @weights + 16, addrspace 10)
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:vgpr_32 = COPY [[SCRATCH_LOAD_DWORDX4_SADDR]].sub3
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:vgpr_32 = COPY [[SCRATCH_LOAD_DWORDX4_SADDR]].sub2
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:vgpr_32 = COPY [[SCRATCH_LOAD_DWORDX4_SADDR]].sub1
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:vgpr_32 = COPY [[SCRATCH_LOAD_DWORDX4_SADDR]].sub0
  ; CHECK-NEXT:   [[S_MOV_B32_5:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 64
  ; CHECK-NEXT:   [[SCRATCH_LOAD_DWORDX4_SADDR1:%[0-9]+]]:vreg_128_align2 = SCRATCH_LOAD_DWORDX4_SADDR killed [[S_MOV_B32_5]], 0, 0, implicit $exec, implicit $flat_scr :: (dereferenceable load (s128) from @weights, align 64, addrspace 10)
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:vgpr_32 = COPY [[SCRATCH_LOAD_DWORDX4_SADDR1]].sub3
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:vgpr_32 = COPY [[SCRATCH_LOAD_DWORDX4_SADDR1]].sub2
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:vgpr_32 = COPY [[SCRATCH_LOAD_DWORDX4_SADDR1]].sub1
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:vgpr_32 = COPY [[SCRATCH_LOAD_DWORDX4_SADDR1]].sub0
  ; CHECK-NEXT:   [[DEF:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[DEF1:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[DEF2:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[DEF3:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[DEF4:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[DEF5:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[DEF6:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[DEF7:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[DEF8:%[0-9]+]]:sgpr_32 = IMPLICIT_DEF
  ; CHECK-NEXT:   [[REG_SEQUENCE:%[0-9]+]]:vreg_288_align2 = REG_SEQUENCE [[COPY7]], %subreg.sub0, [[COPY6]], %subreg.sub1, [[COPY5]], %subreg.sub2, [[COPY4]], %subreg.sub3, [[COPY3]], %subreg.sub4, [[COPY2]], %subreg.sub5, [[COPY1]], %subreg.sub6, [[COPY]], %subreg.sub7, [[SCRATCH_LOAD_DWORD_SADDR]], %subreg.sub8
  ; CHECK-NEXT:   [[S_MOV_B32_6:%[0-9]+]]:sreg_32 = S_MOV_B32 0
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_6]]
  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_6]]
  ; CHECK-NEXT:   [[COPY10:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_6]]
  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_6]]
  ; CHECK-NEXT:   [[REG_SEQUENCE1:%[0-9]+]]:vreg_128_align2 = REG_SEQUENCE [[COPY8]], %subreg.sub0, [[COPY9]], %subreg.sub1, [[COPY10]], %subreg.sub2, [[COPY11]], %subreg.sub3
  ; CHECK-NEXT:   [[COPY12:%[0-9]+]]:vreg_288_align2 = COPY [[REG_SEQUENCE]]
  ; CHECK-NEXT:   [[V_CONVOLVE_F16_FP8_FP8_3x3_4x4_:%[0-9]+]]:vreg_128_align2 = contract V_CONVOLVE_F16_FP8_FP8_3x3_4x4 killed [[REG_SEQUENCE1]], killed [[COPY12]], killed [[SCRATCH_LOAD_DWORDX3_SADDR]], killed [[SCRATCH_LOAD_DWORDX3_SADDR1]], killed [[SCRATCH_LOAD_DWORDX3_SADDR2]], 42, -1, 0, 0, implicit $exec
  ; CHECK-NEXT:   [[S_MOV_B32_7:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 0
  ; CHECK-NEXT:   SCRATCH_STORE_DWORDX4_SADDR killed [[V_CONVOLVE_F16_FP8_FP8_3x3_4x4_]], killed [[S_MOV_B32_7]], 0, 0, implicit $exec, implicit $flat_scr :: (store (s128) into @out, !tbaa !0, addrspace 10)
  ; CHECK-NEXT:   S_ENDPGM 0
  ;
  ; VIDX-LABEL: name: _Z36test_amdgcn_convolve_f16_fp8_3x3_4x4v
  ; VIDX: bb.0.entry:
  ; VIDX-NEXT:   [[S_MOV_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 112
  ; VIDX-NEXT:   [[S_LSHR_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_]], 2, implicit-def dead $scc
  ; VIDX-NEXT:   [[V_LOAD_IDX:%[0-9]+]]:vreg_96_align2 = V_LOAD_IDX [[S_LSHR_B32_]], 0, implicit $exec :: (dereferenceable load (s96) from @col_center, align 16, addrspace 10)
  ; VIDX-NEXT:   [[S_MOV_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 96
  ; VIDX-NEXT:   [[S_LSHR_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_1]], 2, implicit-def dead $scc
  ; VIDX-NEXT:   [[V_LOAD_IDX1:%[0-9]+]]:vreg_96_align2 = V_LOAD_IDX [[S_LSHR_B32_1]], 0, implicit $exec :: (dereferenceable load (s96) from @col_left, align 16, addrspace 10)
  ; VIDX-NEXT:   [[S_MOV_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 80
  ; VIDX-NEXT:   [[S_LSHR_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_2]], 2, implicit-def dead $scc
  ; VIDX-NEXT:   [[V_LOAD_IDX2:%[0-9]+]]:vreg_96_align2 = V_LOAD_IDX [[S_LSHR_B32_2]], 0, implicit $exec :: (dereferenceable load (s96) from @col_right, align 16, addrspace 10)
  ; VIDX-NEXT:   [[S_MOV_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 16
  ; VIDX-NEXT:   [[S_LSHR_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_3]], 2, implicit-def dead $scc
  ; VIDX-NEXT:   [[V_LOAD_IDX3:%[0-9]+]]:vreg_288_align2 = V_LOAD_IDX [[S_LSHR_B32_3]], 0, implicit $exec :: (dereferenceable load (s288) from @weights, align 64, addrspace 10)
  ; VIDX-NEXT:   [[S_MOV_B32_4:%[0-9]+]]:sreg_32 = S_MOV_B32 0
  ; VIDX-NEXT:   [[COPY:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_4]]
  ; VIDX-NEXT:   [[COPY1:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_4]]
  ; VIDX-NEXT:   [[COPY2:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_4]]
  ; VIDX-NEXT:   [[COPY3:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_4]]
  ; VIDX-NEXT:   [[REG_SEQUENCE:%[0-9]+]]:vreg_128_align2 = REG_SEQUENCE [[COPY]], %subreg.sub0, [[COPY1]], %subreg.sub1, [[COPY2]], %subreg.sub2, [[COPY3]], %subreg.sub3
  ; VIDX-NEXT:   [[V_CONVOLVE_F16_FP8_FP8_3x3_4x4_:%[0-9]+]]:vreg_128_align2 = contract V_CONVOLVE_F16_FP8_FP8_3x3_4x4 killed [[REG_SEQUENCE]], killed [[V_LOAD_IDX3]], killed [[V_LOAD_IDX]], killed [[V_LOAD_IDX1]], killed [[V_LOAD_IDX2]], 42, -1, 0, 0, implicit $exec
  ; VIDX-NEXT:   [[S_MOV_B32_5:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 0
  ; VIDX-NEXT:   [[S_LSHR_B32_4:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_5]], 2, implicit-def dead $scc
  ; VIDX-NEXT:   V_STORE_IDX [[V_CONVOLVE_F16_FP8_FP8_3x3_4x4_]], [[S_LSHR_B32_4]], 0, implicit $exec :: (store (s128) into @out, !tbaa !0, addrspace 10)
  ; VIDX-NEXT:   S_ENDPGM 0
entry:
  %vec30 = load <3 x i32>, ptr addrspace(10) @col_center, align 16
  %vec31 = load <3 x i32>, ptr addrspace(10) @col_left, align 16
  %vec32 = load <3 x i32>, ptr addrspace(10) @col_right, align 16
  %wei = load <9 x i32>, ptr addrspace(10) @weights, align 64
  %0 = tail call contract <8 x half> @llvm.amdgcn.convolve.f16.fp8.fp8.3x3.v8f16.v8f16.v9i32.v3i32(<8 x half> zeroinitializer, <9 x i32> %wei, <3 x i32> %vec30, <3 x i32> %vec31, <3 x i32> %vec32, i32 42, i1 true)
  store <8 x half> %0, ptr addrspace(10) @out, align 16, !tbaa !4
  ret void
}

; Function Attrs: convergent mustprogress nocallback nofree nosync nounwind willreturn memory(none)
declare <8 x half> @llvm.amdgcn.convolve.f16.fp8.fp8.3x3.v8f16.v8f16.v9i32.v3i32(<8 x half>, <9 x i32>, <3 x i32>, <3 x i32>, <3 x i32>, i32 immarg, i1 immarg) #1

!4 = !{!5, !5, i64 0}
!5 = !{!"omnipotent char", !6, i64 0}
!6 = !{!"Simple C++ TBAA"}
