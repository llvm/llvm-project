; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn -mcpu=gfx1300 -amdgpu-promote-private=true -verify-machineinstrs -stop-after=amdgpu-idx-reg-alloc < %s | FileCheck -check-prefix=ALLOC %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx1300 -amdgpu-promote-private=true -verify-machineinstrs -stop-after=prologepilog < %s | FileCheck -check-prefix=GFX13 %s

@exchange = external local_unnamed_addr addrspace(10) global [40 x i32], align 4
define dso_local amdgpu_kernel void @test_wavegroup_entry(i64 %idx0, i64 %idx1, i64 %idx2, i64 %idx3) "amdgpu-wavegroup-enable" !reqd_work_group_size !{i32 128, i32 1, i32 1} {
  ; ALLOC-LABEL: name: test_wavegroup_entry
  ; ALLOC: bb.0.bb:
  ; ALLOC-NEXT:   liveins: $sgpr4_sgpr5
  ; ALLOC-NEXT: {{  $}}
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 0
  ; ALLOC-NEXT:   [[COPY:%[0-9]+]]:sreg_32_xm0_xexec = COPY $idx0
  ; ALLOC-NEXT:   [[COPY1:%[0-9]+]]:sgpr_64(p4) = COPY $sgpr4_sgpr5
  ; ALLOC-NEXT:   [[S_LOAD_DWORDX8_IMM:%[0-9]+]]:sgpr_256 = S_LOAD_DWORDX8_IMM [[COPY1]](p4), 36, 0 :: (dereferenceable invariant load (s256) from %ir.idx0.kernarg.offset, align 4, addrspace 4)
  ; ALLOC-NEXT:   [[S_LSHL_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub0, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub2, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub4, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub6, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHR_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx2 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_]]
  ; ALLOC-NEXT:   [[S_LSHR_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_1]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx3 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_1]]
  ; ALLOC-NEXT:   [[S_LSHR_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_2]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHR_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_3]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx1 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_3]]
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_2]]
  ; ALLOC-NEXT:   BUNDLE implicit-def dead $stg_srcc, implicit-def dead $stg_srcb, implicit-def dead $stg_srca, implicit-def $stg_dsta, implicit $idx0, implicit $exec, implicit $idx3, implicit $idx2, implicit $idx1 {
  ; ALLOC-NEXT:     $stg_srcc = V_LOAD_IDX $idx0, 0, implicit $exec :: (load (s32) from %ir.o.3, addrspace 10)
  ; ALLOC-NEXT:     $stg_srcb = V_LOAD_IDX $idx3, 0, implicit $exec :: (load (s32) from %ir.o.2, addrspace 10)
  ; ALLOC-NEXT:     $stg_srca = V_LOAD_IDX $idx2, 0, implicit $exec :: (load (s32) from %ir.o.1, addrspace 10)
  ; ALLOC-NEXT:     $stg_dsta = nuw nsw V_LSHL_ADD_U32_e64 internal killed $stg_srca, internal killed $stg_srcb, internal killed $stg_srcc, implicit $exec
  ; ALLOC-NEXT:     V_STORE_IDX internal $stg_dsta, $idx1, 0, implicit $exec :: (store (s32) into %ir.o.4, addrspace 10)
  ; ALLOC-NEXT:   }
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 [[COPY]]
  ; ALLOC-NEXT:   S_ENDPGM 0
  ;
  ; GFX13-LABEL: name: test_wavegroup_entry
  ; GFX13: bb.0.bb:
  ; GFX13-NEXT:   liveins: $sgpr4_sgpr5, $sgpr8
  ; GFX13-NEXT: {{  $}}
  ; GFX13-NEXT:   $sgpr0 = S_GETREG_B32 7195, implicit $mode
  ; GFX13-NEXT:   $sgpr1 = S_MUL_I32 $sgpr0, target-index(amdgpu-num-vgprs)
  ; GFX13-NEXT:   $sgpr1 = S_ADD_U32 $sgpr1, 40, implicit-def $scc
  ; GFX13-NEXT:   $idx0 = S_SET_GPR_IDX_U32 $sgpr1
  ; GFX13-NEXT:   $sgpr33 = S_MUL_I32 $sgpr0, $sgpr8
  ; GFX13-NEXT:   SCHED_BARRIER 0
  ; GFX13-NEXT:   renamable $sgpr0_sgpr1_sgpr2_sgpr3_sgpr4_sgpr5_sgpr6_sgpr7 = S_LOAD_DWORDX8_IMM killed renamable $sgpr4_sgpr5, 36, 0 :: (dereferenceable invariant load (s256) from %ir.idx0.kernarg.offset, align 4, addrspace 4)
  ; GFX13-NEXT:   renamable $sgpr1 = COPY $sgpr1
  ; GFX13-NEXT:   renamable $sgpr0 = S_LSHL_B32 renamable $sgpr0, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr2 = S_LSHL_B32 renamable $sgpr2, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr3 = S_LSHL_B32 renamable $sgpr4, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr4 = S_LSHL_B32 killed renamable $sgpr6, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr0 = S_LSHR_B32 killed renamable $sgpr0, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr2 = S_LSHR_B32 killed renamable $sgpr2, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr3 = S_LSHR_B32 killed renamable $sgpr3, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr4 = S_LSHR_B32 killed renamable $sgpr4, 2, implicit-def dead $scc
  ; GFX13-NEXT:   $idx2 = S_SET_GPR_IDX_U32 killed renamable $sgpr0
  ; GFX13-NEXT:   $idx3 = S_SET_GPR_IDX_U32 killed renamable $sgpr2
  ; GFX13-NEXT:   $idx1 = S_SET_GPR_IDX_U32 killed renamable $sgpr4
  ; GFX13-NEXT:   $idx0 = S_SET_GPR_IDX_U32 killed renamable $sgpr3
  ; GFX13-NEXT:   BUNDLE implicit-def dead $stg_srcc, implicit-def dead $stg_srcb, implicit-def dead $stg_srca, implicit-def dead $stg_dsta, implicit $idx0, implicit $exec, implicit $idx3, implicit $idx2, implicit killed $idx1 {
  ; GFX13-NEXT:     $stg_srcc = V_LOAD_IDX $idx0, 0, implicit $exec :: (load (s32) from %ir.o.3, addrspace 10)
  ; GFX13-NEXT:     $stg_srcb = V_LOAD_IDX $idx3, 0, implicit $exec :: (load (s32) from %ir.o.2, addrspace 10)
  ; GFX13-NEXT:     $stg_srca = V_LOAD_IDX $idx2, 0, implicit $exec :: (load (s32) from %ir.o.1, addrspace 10)
  ; GFX13-NEXT:     $stg_dsta = nuw nsw V_LSHL_ADD_U32_e64 internal killed $stg_srca, internal killed $stg_srcb, internal killed $stg_srcc, implicit $exec
  ; GFX13-NEXT:     V_STORE_IDX internal $stg_dsta, $idx1, 0, implicit $exec :: (store (s32) into %ir.o.4, addrspace 10)
  ; GFX13-NEXT:   }
  ; GFX13-NEXT:   dead $idx0 = S_SET_GPR_IDX_U32 killed renamable $sgpr1
  ; GFX13-NEXT:   S_ENDPGM 0
bb:
  %o.1 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx0
  %o.2 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx1
  %o.3 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx2
  %o.4 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx3
  %x = load i32, ptr addrspace(10) %o.1, align 4
  %y = load i32, ptr addrspace(10) %o.2, align 4
  %z = load i32, ptr addrspace(10) %o.3, align 4
  %shifted = shl i32 %x, %y
  %a = add nuw nsw i32 %shifted, %z
  store i32 %a, ptr addrspace(10) %o.4, align 4
  ret void
}

define dso_local amdgpu_kernel void @test_wavegroup_entry_private(i64 %idx0, i64 %idx1, i64 %idx2, i64 %idx3) "amdgpu-wavegroup-enable" !reqd_work_group_size !{i32 128, i32 1, i32 1} {
  ; ALLOC-LABEL: name: test_wavegroup_entry_private
  ; ALLOC: bb.0.bb:
  ; ALLOC-NEXT:   liveins: $sgpr4_sgpr5
  ; ALLOC-NEXT: {{  $}}
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 0
  ; ALLOC-NEXT:   [[COPY:%[0-9]+]]:sreg_32_xm0_xexec = COPY $idx0
  ; ALLOC-NEXT:   [[COPY1:%[0-9]+]]:sgpr_64(p4) = COPY $sgpr4_sgpr5
  ; ALLOC-NEXT:   [[S_LOAD_DWORDX8_IMM:%[0-9]+]]:sgpr_256 = S_LOAD_DWORDX8_IMM [[COPY1]](p4), 36, 0 :: (dereferenceable invariant load (s256) from %ir.idx0.kernarg.offset, align 4, addrspace 4)
  ; ALLOC-NEXT:   [[S_LSHL_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub0, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub2, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub4, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub6, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHR_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx2 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_]]
  ; ALLOC-NEXT:   [[S_LSHR_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_1]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx3 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_1]]
  ; ALLOC-NEXT:   [[S_LSHR_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_2]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHR_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_3]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx1 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_3]]
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_2]]
  ; ALLOC-NEXT:   BUNDLE implicit-def dead $stg_srcc, implicit-def dead $stg_srcb, implicit-def dead $stg_srca, implicit-def $stg_dsta, implicit $idx0, implicit $exec, implicit $idx3, implicit $idx2, implicit $idx1 {
  ; ALLOC-NEXT:     $stg_srcc = V_LOAD_IDX $idx0, 0, implicit $exec :: (load (s32) from %ir.o.3, addrspace 10)
  ; ALLOC-NEXT:     $stg_srcb = V_LOAD_IDX $idx3, 0, implicit $exec :: (load (s32) from %ir.o.2, addrspace 5)
  ; ALLOC-NEXT:     $stg_srca = V_LOAD_IDX $idx2, 0, implicit $exec :: (load (s32) from %ir.o.1, addrspace 5)
  ; ALLOC-NEXT:     $stg_dsta = nuw nsw V_LSHL_ADD_U32_e64 internal killed $stg_srca, internal killed $stg_srcb, internal killed $stg_srcc, implicit $exec
  ; ALLOC-NEXT:     V_STORE_IDX internal $stg_dsta, $idx1, 0, implicit $exec :: (store (s32) into %ir.o.4, addrspace 5)
  ; ALLOC-NEXT:   }
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 [[COPY]]
  ; ALLOC-NEXT:   S_ENDPGM 0
  ;
  ; GFX13-LABEL: name: test_wavegroup_entry_private
  ; GFX13: bb.0.bb:
  ; GFX13-NEXT:   liveins: $sgpr4_sgpr5, $sgpr8
  ; GFX13-NEXT: {{  $}}
  ; GFX13-NEXT:   $sgpr0 = S_GETREG_B32 7195, implicit $mode
  ; GFX13-NEXT:   $sgpr1 = S_MUL_I32 $sgpr0, target-index(amdgpu-num-vgprs)
  ; GFX13-NEXT:   $sgpr1 = S_ADD_U32 $sgpr1, 40, implicit-def $scc
  ; GFX13-NEXT:   $idx0 = S_SET_GPR_IDX_U32 $sgpr1
  ; GFX13-NEXT:   $sgpr33 = S_MUL_I32 $sgpr0, $sgpr8
  ; GFX13-NEXT:   SCHED_BARRIER 0
  ; GFX13-NEXT:   renamable $sgpr0_sgpr1_sgpr2_sgpr3_sgpr4_sgpr5_sgpr6_sgpr7 = S_LOAD_DWORDX8_IMM killed renamable $sgpr4_sgpr5, 36, 0 :: (dereferenceable invariant load (s256) from %ir.idx0.kernarg.offset, align 4, addrspace 4)
  ; GFX13-NEXT:   renamable $sgpr1 = COPY $sgpr1
  ; GFX13-NEXT:   renamable $sgpr0 = S_LSHL_B32 renamable $sgpr0, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr2 = S_LSHL_B32 renamable $sgpr2, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr3 = S_LSHL_B32 renamable $sgpr4, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr4 = S_LSHL_B32 killed renamable $sgpr6, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr0 = S_LSHR_B32 killed renamable $sgpr0, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr2 = S_LSHR_B32 killed renamable $sgpr2, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr3 = S_LSHR_B32 killed renamable $sgpr3, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr4 = S_LSHR_B32 killed renamable $sgpr4, 2, implicit-def dead $scc
  ; GFX13-NEXT:   $idx2 = S_SET_GPR_IDX_U32 killed renamable $sgpr0
  ; GFX13-NEXT:   $idx3 = S_SET_GPR_IDX_U32 killed renamable $sgpr2
  ; GFX13-NEXT:   $idx1 = S_SET_GPR_IDX_U32 killed renamable $sgpr4
  ; GFX13-NEXT:   $idx0 = S_SET_GPR_IDX_U32 killed renamable $sgpr3
  ; GFX13-NEXT:   $vgpr0 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr1 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr2 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr3 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr4 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr5 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr6 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr7 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr8 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr9 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr10 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr11 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr12 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr13 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr14 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr15 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr16 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr17 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr18 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr19 = IMPLICIT_DEF
  ; GFX13-NEXT:   BUNDLE implicit-def dead $stg_srcc, implicit-def dead $stg_srcb, implicit-def dead $stg_srca, implicit-def dead $stg_dsta, implicit $idx0, implicit $exec, implicit $idx3, implicit $idx2, implicit killed $idx1, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7, implicit $vgpr8, implicit $vgpr9, implicit $vgpr10, implicit $vgpr11, implicit $vgpr12, implicit $vgpr13, implicit $vgpr14, implicit $vgpr15, implicit $vgpr16, implicit $vgpr17, implicit $vgpr18, implicit $vgpr19, implicit-def $vgpr0, implicit-def $vgpr1, implicit-def $vgpr2, implicit-def $vgpr3, implicit-def $vgpr4, implicit-def $vgpr5, implicit-def $vgpr6, implicit-def $vgpr7, implicit-def $vgpr8, implicit-def $vgpr9, implicit-def $vgpr10, implicit-def $vgpr11, implicit-def $vgpr12, implicit-def $vgpr13, implicit-def $vgpr14, implicit-def $vgpr15, implicit-def $vgpr16, implicit-def $vgpr17, implicit-def $vgpr18, implicit-def $vgpr19 {
  ; GFX13-NEXT:     $stg_srcc = V_LOAD_IDX $idx0, 0, implicit $exec :: (load (s32) from %ir.o.3, addrspace 10)
  ; GFX13-NEXT:     $stg_srcb = V_LOAD_IDX $idx3, 0, implicit $exec, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7, implicit $vgpr8, implicit $vgpr9, implicit $vgpr10, implicit $vgpr11, implicit $vgpr12, implicit $vgpr13, implicit $vgpr14, implicit $vgpr15, implicit $vgpr16, implicit $vgpr17, implicit $vgpr18, implicit $vgpr19 :: (load (s32) from %ir.o.2, addrspace 5)
  ; GFX13-NEXT:     $stg_srca = V_LOAD_IDX $idx2, 0, implicit $exec, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7, implicit $vgpr8, implicit $vgpr9, implicit $vgpr10, implicit $vgpr11, implicit $vgpr12, implicit $vgpr13, implicit $vgpr14, implicit $vgpr15, implicit $vgpr16, implicit $vgpr17, implicit $vgpr18, implicit $vgpr19 :: (load (s32) from %ir.o.1, addrspace 5)
  ; GFX13-NEXT:     $stg_dsta = nuw nsw V_LSHL_ADD_U32_e64 internal killed $stg_srca, internal killed $stg_srcb, internal killed $stg_srcc, implicit $exec
  ; GFX13-NEXT:     V_STORE_IDX internal $stg_dsta, $idx1, 0, implicit $exec, implicit $vgpr0, implicit-def $vgpr0, implicit $vgpr1, implicit-def $vgpr1, implicit $vgpr2, implicit-def $vgpr2, implicit $vgpr3, implicit-def $vgpr3, implicit $vgpr4, implicit-def $vgpr4, implicit $vgpr5, implicit-def $vgpr5, implicit $vgpr6, implicit-def $vgpr6, implicit $vgpr7, implicit-def $vgpr7, implicit $vgpr8, implicit-def $vgpr8, implicit $vgpr9, implicit-def $vgpr9, implicit $vgpr10, implicit-def $vgpr10, implicit $vgpr11, implicit-def $vgpr11, implicit $vgpr12, implicit-def $vgpr12, implicit $vgpr13, implicit-def $vgpr13, implicit $vgpr14, implicit-def $vgpr14, implicit $vgpr15, implicit-def $vgpr15, implicit $vgpr16, implicit-def $vgpr16, implicit $vgpr17, implicit-def $vgpr17, implicit $vgpr18, implicit-def $vgpr18, implicit $vgpr19, implicit-def $vgpr19 :: (store (s32) into %ir.o.4, addrspace 5)
  ; GFX13-NEXT:   }
  ; GFX13-NEXT:   dead $idx0 = S_SET_GPR_IDX_U32 killed renamable $sgpr1
  ; GFX13-NEXT:   S_ENDPGM 0
bb:
  %p = alloca [20 x i32], align 4, addrspace(5)
  %o.1 = getelementptr [20 x i32], ptr addrspace(5) %p, i64 0, i64 %idx0
  %o.2 = getelementptr [20 x i32], ptr addrspace(5) %p, i64 0, i64 %idx1
  %o.3 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx2
  %o.4 = getelementptr [20 x i32], ptr addrspace(5) %p, i64 0, i64 %idx3
  %x = load i32, ptr addrspace(5) %o.1, align 4
  %y = load i32, ptr addrspace(5) %o.2, align 4
  %z = load i32, ptr addrspace(10) %o.3, align 4
  %shifted = shl i32 %x, %y
  %a = add nuw nsw i32 %shifted, %z
  store i32 %a, ptr addrspace(5) %o.4, align 4
  ret void
}

define dso_local amdgpu_kernel void @test_nonwavegroup_entry(i64 %idx0, i64 %idx1, i64 %idx2, i64 %idx3) {
  ; ALLOC-LABEL: name: test_nonwavegroup_entry
  ; ALLOC: bb.0.bb:
  ; ALLOC-NEXT:   liveins: $sgpr4_sgpr5
  ; ALLOC-NEXT: {{  $}}
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 0
  ; ALLOC-NEXT:   [[COPY:%[0-9]+]]:sreg_32_xm0_xexec = COPY $idx0
  ; ALLOC-NEXT:   [[COPY1:%[0-9]+]]:sgpr_64(p4) = COPY $sgpr4_sgpr5
  ; ALLOC-NEXT:   [[S_LOAD_DWORDX8_IMM:%[0-9]+]]:sgpr_256 = S_LOAD_DWORDX8_IMM [[COPY1]](p4), 36, 0 :: (dereferenceable invariant load (s256) from %ir.idx0.kernarg.offset, align 4, addrspace 4)
  ; ALLOC-NEXT:   [[S_LSHL_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub0, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub2, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub4, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub6, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHR_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx2 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_]]
  ; ALLOC-NEXT:   [[S_LSHR_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_1]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx3 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_1]]
  ; ALLOC-NEXT:   [[S_LSHR_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_2]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHR_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_3]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx1 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_3]]
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_2]]
  ; ALLOC-NEXT:   BUNDLE implicit-def dead $stg_srcc, implicit-def dead $stg_srcb, implicit-def dead $stg_srca, implicit-def $stg_dsta, implicit $idx0, implicit $exec, implicit $idx3, implicit $idx2, implicit $idx1 {
  ; ALLOC-NEXT:     $stg_srcc = V_LOAD_IDX $idx0, 0, implicit $exec :: (load (s32) from %ir.o.3, addrspace 10)
  ; ALLOC-NEXT:     $stg_srcb = V_LOAD_IDX $idx3, 0, implicit $exec :: (load (s32) from %ir.o.2, addrspace 10)
  ; ALLOC-NEXT:     $stg_srca = V_LOAD_IDX $idx2, 0, implicit $exec :: (load (s32) from %ir.o.1, addrspace 10)
  ; ALLOC-NEXT:     $stg_dsta = nuw nsw V_LSHL_ADD_U32_e64 internal killed $stg_srca, internal killed $stg_srcb, internal killed $stg_srcc, implicit $exec
  ; ALLOC-NEXT:     V_STORE_IDX internal $stg_dsta, $idx1, 0, implicit $exec :: (store (s32) into %ir.o.4, addrspace 10)
  ; ALLOC-NEXT:   }
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 [[COPY]]
  ; ALLOC-NEXT:   S_ENDPGM 0
  ;
  ; GFX13-LABEL: name: test_nonwavegroup_entry
  ; GFX13: bb.0.bb:
  ; GFX13-NEXT:   liveins: $sgpr4_sgpr5
  ; GFX13-NEXT: {{  $}}
  ; GFX13-NEXT:   renamable $sgpr0_sgpr1_sgpr2_sgpr3_sgpr4_sgpr5_sgpr6_sgpr7 = S_LOAD_DWORDX8_IMM killed renamable $sgpr4_sgpr5, 36, 0 :: (dereferenceable invariant load (s256) from %ir.idx0.kernarg.offset, align 4, addrspace 4)
  ; GFX13-NEXT:   renamable $sgpr0 = S_LSHL_B32 renamable $sgpr0, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr2 = S_LSHL_B32 renamable $sgpr2, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr3 = S_LSHL_B32 renamable $sgpr4, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr4 = S_LSHL_B32 killed renamable $sgpr6, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr0 = S_LSHR_B32 killed renamable $sgpr0, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr2 = S_LSHR_B32 killed renamable $sgpr2, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr3 = S_LSHR_B32 killed renamable $sgpr3, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr4 = S_LSHR_B32 killed renamable $sgpr4, 2, implicit-def dead $scc
  ; GFX13-NEXT:   $idx2 = S_SET_GPR_IDX_U32 killed renamable $sgpr0
  ; GFX13-NEXT:   $idx3 = S_SET_GPR_IDX_U32 killed renamable $sgpr2
  ; GFX13-NEXT:   $idx1 = S_SET_GPR_IDX_U32 killed renamable $sgpr4
  ; GFX13-NEXT:   $idx0 = S_SET_GPR_IDX_U32 killed renamable $sgpr3
  ; GFX13-NEXT:   BUNDLE implicit-def dead $stg_srcc, implicit-def dead $stg_srcb, implicit-def dead $stg_srca, implicit-def dead $stg_dsta, implicit $idx0, implicit $exec, implicit $idx3, implicit $idx2, implicit killed $idx1 {
  ; GFX13-NEXT:     $stg_srcc = V_LOAD_IDX $idx0, 0, implicit $exec :: (load (s32) from %ir.o.3, addrspace 10)
  ; GFX13-NEXT:     $stg_srcb = V_LOAD_IDX $idx3, 0, implicit $exec :: (load (s32) from %ir.o.2, addrspace 10)
  ; GFX13-NEXT:     $stg_srca = V_LOAD_IDX $idx2, 0, implicit $exec :: (load (s32) from %ir.o.1, addrspace 10)
  ; GFX13-NEXT:     $stg_dsta = nuw nsw V_LSHL_ADD_U32_e64 internal killed $stg_srca, internal killed $stg_srcb, internal killed $stg_srcc, implicit $exec
  ; GFX13-NEXT:     V_STORE_IDX internal $stg_dsta, $idx1, 0, implicit $exec :: (store (s32) into %ir.o.4, addrspace 10)
  ; GFX13-NEXT:   }
  ; GFX13-NEXT:   dead $idx0 = S_SET_GPR_IDX_U32 0
  ; GFX13-NEXT:   S_ENDPGM 0
bb:
  %o.1 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx0
  %o.2 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx1
  %o.3 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx2
  %o.4 = getelementptr [40 x i32], ptr addrspace(10) @exchange, i64 0, i64 %idx3
  %x = load i32, ptr addrspace(10) %o.1, align 4
  %y = load i32, ptr addrspace(10) %o.2, align 4
  %z = load i32, ptr addrspace(10) %o.3, align 4
  %shifted = shl i32 %x, %y
  %a = add nuw nsw i32 %shifted, %z
  store i32 %a, ptr addrspace(10) %o.4, align 4
  ret void
}

define dso_local amdgpu_kernel void @test_nonwavegroup_entry_private(i64 %idx0, i64 %idx1, i64 %idx2, i64 %idx3) {
  ; ALLOC-LABEL: name: test_nonwavegroup_entry_private
  ; ALLOC: bb.0.bb:
  ; ALLOC-NEXT:   liveins: $sgpr4_sgpr5
  ; ALLOC-NEXT: {{  $}}
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 0
  ; ALLOC-NEXT:   [[COPY:%[0-9]+]]:sreg_32_xm0_xexec = COPY $idx0
  ; ALLOC-NEXT:   [[COPY1:%[0-9]+]]:sgpr_64(p4) = COPY $sgpr4_sgpr5
  ; ALLOC-NEXT:   [[S_LOAD_DWORDX8_IMM:%[0-9]+]]:sgpr_256 = S_LOAD_DWORDX8_IMM [[COPY1]](p4), 36, 0 :: (dereferenceable invariant load (s256) from %ir.idx0.kernarg.offset, align 4, addrspace 4)
  ; ALLOC-NEXT:   [[S_LSHL_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub0, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub2, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub4, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHL_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHL_B32 [[S_LOAD_DWORDX8_IMM]].sub6, 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHR_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx2 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_]]
  ; ALLOC-NEXT:   [[S_LSHR_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_1]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx3 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_1]]
  ; ALLOC-NEXT:   [[S_LSHR_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_2]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   [[S_LSHR_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_LSHL_B32_3]], 2, implicit-def dead $scc
  ; ALLOC-NEXT:   $idx1 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_3]]
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 [[S_LSHR_B32_2]]
  ; ALLOC-NEXT:   BUNDLE implicit-def dead $stg_srcc, implicit-def dead $stg_srcb, implicit-def dead $stg_srca, implicit-def $stg_dsta, implicit $idx0, implicit $exec, implicit $idx3, implicit $idx2, implicit $idx1 {
  ; ALLOC-NEXT:     $stg_srcc = V_LOAD_IDX $idx0, 0, implicit $exec :: (load (s32) from %ir.o.3, addrspace 5)
  ; ALLOC-NEXT:     $stg_srcb = V_LOAD_IDX $idx3, 0, implicit $exec :: (load (s32) from %ir.o.2, addrspace 5)
  ; ALLOC-NEXT:     $stg_srca = V_LOAD_IDX $idx2, 0, implicit $exec :: (load (s32) from %ir.o.1, addrspace 5)
  ; ALLOC-NEXT:     $stg_dsta = nuw nsw V_LSHL_ADD_U32_e64 internal killed $stg_srca, internal killed $stg_srcb, internal killed $stg_srcc, implicit $exec
  ; ALLOC-NEXT:     V_STORE_IDX internal $stg_dsta, $idx1, 0, implicit $exec :: (store (s32) into %ir.o.4, addrspace 5)
  ; ALLOC-NEXT:   }
  ; ALLOC-NEXT:   $idx0 = S_SET_GPR_IDX_U32 [[COPY]]
  ; ALLOC-NEXT:   S_ENDPGM 0
  ;
  ; GFX13-LABEL: name: test_nonwavegroup_entry_private
  ; GFX13: bb.0.bb:
  ; GFX13-NEXT:   liveins: $sgpr4_sgpr5
  ; GFX13-NEXT: {{  $}}
  ; GFX13-NEXT:   renamable $sgpr0_sgpr1_sgpr2_sgpr3_sgpr4_sgpr5_sgpr6_sgpr7 = S_LOAD_DWORDX8_IMM killed renamable $sgpr4_sgpr5, 36, 0 :: (dereferenceable invariant load (s256) from %ir.idx0.kernarg.offset, align 4, addrspace 4)
  ; GFX13-NEXT:   renamable $sgpr0 = S_LSHL_B32 renamable $sgpr0, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr2 = S_LSHL_B32 renamable $sgpr2, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr3 = S_LSHL_B32 renamable $sgpr4, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr4 = S_LSHL_B32 killed renamable $sgpr6, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr0 = S_LSHR_B32 killed renamable $sgpr0, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr2 = S_LSHR_B32 killed renamable $sgpr2, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr3 = S_LSHR_B32 killed renamable $sgpr3, 2, implicit-def dead $scc
  ; GFX13-NEXT:   renamable $sgpr4 = S_LSHR_B32 killed renamable $sgpr4, 2, implicit-def dead $scc
  ; GFX13-NEXT:   $idx2 = S_SET_GPR_IDX_U32 killed renamable $sgpr0
  ; GFX13-NEXT:   $idx3 = S_SET_GPR_IDX_U32 killed renamable $sgpr2
  ; GFX13-NEXT:   $idx1 = S_SET_GPR_IDX_U32 killed renamable $sgpr4
  ; GFX13-NEXT:   $idx0 = S_SET_GPR_IDX_U32 killed renamable $sgpr3
  ; GFX13-NEXT:   $vgpr0 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr1 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr2 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr3 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr4 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr5 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr6 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr7 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr8 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr9 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr10 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr11 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr12 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr13 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr14 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr15 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr16 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr17 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr18 = IMPLICIT_DEF
  ; GFX13-NEXT:   $vgpr19 = IMPLICIT_DEF
  ; GFX13-NEXT:   BUNDLE implicit-def dead $stg_srcc, implicit-def dead $stg_srcb, implicit-def dead $stg_srca, implicit-def dead $stg_dsta, implicit $idx0, implicit $exec, implicit $idx3, implicit $idx2, implicit killed $idx1, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7, implicit $vgpr8, implicit $vgpr9, implicit $vgpr10, implicit $vgpr11, implicit $vgpr12, implicit $vgpr13, implicit $vgpr14, implicit $vgpr15, implicit $vgpr16, implicit $vgpr17, implicit $vgpr18, implicit $vgpr19, implicit-def $vgpr0, implicit-def $vgpr1, implicit-def $vgpr2, implicit-def $vgpr3, implicit-def $vgpr4, implicit-def $vgpr5, implicit-def $vgpr6, implicit-def $vgpr7, implicit-def $vgpr8, implicit-def $vgpr9, implicit-def $vgpr10, implicit-def $vgpr11, implicit-def $vgpr12, implicit-def $vgpr13, implicit-def $vgpr14, implicit-def $vgpr15, implicit-def $vgpr16, implicit-def $vgpr17, implicit-def $vgpr18, implicit-def $vgpr19 {
  ; GFX13-NEXT:     $stg_srcc = V_LOAD_IDX $idx0, 0, implicit $exec, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7, implicit $vgpr8, implicit $vgpr9, implicit $vgpr10, implicit $vgpr11, implicit $vgpr12, implicit $vgpr13, implicit $vgpr14, implicit $vgpr15, implicit $vgpr16, implicit $vgpr17, implicit $vgpr18, implicit $vgpr19 :: (load (s32) from %ir.o.3, addrspace 5)
  ; GFX13-NEXT:     $stg_srcb = V_LOAD_IDX $idx3, 0, implicit $exec, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7, implicit $vgpr8, implicit $vgpr9, implicit $vgpr10, implicit $vgpr11, implicit $vgpr12, implicit $vgpr13, implicit $vgpr14, implicit $vgpr15, implicit $vgpr16, implicit $vgpr17, implicit $vgpr18, implicit $vgpr19 :: (load (s32) from %ir.o.2, addrspace 5)
  ; GFX13-NEXT:     $stg_srca = V_LOAD_IDX $idx2, 0, implicit $exec, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7, implicit $vgpr8, implicit $vgpr9, implicit $vgpr10, implicit $vgpr11, implicit $vgpr12, implicit $vgpr13, implicit $vgpr14, implicit $vgpr15, implicit $vgpr16, implicit $vgpr17, implicit $vgpr18, implicit $vgpr19 :: (load (s32) from %ir.o.1, addrspace 5)
  ; GFX13-NEXT:     $stg_dsta = nuw nsw V_LSHL_ADD_U32_e64 internal killed $stg_srca, internal killed $stg_srcb, internal killed $stg_srcc, implicit $exec
  ; GFX13-NEXT:     V_STORE_IDX internal $stg_dsta, $idx1, 0, implicit $exec, implicit $vgpr0, implicit-def $vgpr0, implicit $vgpr1, implicit-def $vgpr1, implicit $vgpr2, implicit-def $vgpr2, implicit $vgpr3, implicit-def $vgpr3, implicit $vgpr4, implicit-def $vgpr4, implicit $vgpr5, implicit-def $vgpr5, implicit $vgpr6, implicit-def $vgpr6, implicit $vgpr7, implicit-def $vgpr7, implicit $vgpr8, implicit-def $vgpr8, implicit $vgpr9, implicit-def $vgpr9, implicit $vgpr10, implicit-def $vgpr10, implicit $vgpr11, implicit-def $vgpr11, implicit $vgpr12, implicit-def $vgpr12, implicit $vgpr13, implicit-def $vgpr13, implicit $vgpr14, implicit-def $vgpr14, implicit $vgpr15, implicit-def $vgpr15, implicit $vgpr16, implicit-def $vgpr16, implicit $vgpr17, implicit-def $vgpr17, implicit $vgpr18, implicit-def $vgpr18, implicit $vgpr19, implicit-def $vgpr19 :: (store (s32) into %ir.o.4, addrspace 5)
  ; GFX13-NEXT:   }
  ; GFX13-NEXT:   dead $idx0 = S_SET_GPR_IDX_U32 0
  ; GFX13-NEXT:   S_ENDPGM 0
bb:
  %p = alloca [20 x i32], align 4, addrspace(5)
  %o.1 = getelementptr [20 x i32], ptr addrspace(5) %p, i64 0, i64 %idx0
  %o.2 = getelementptr [20 x i32], ptr addrspace(5) %p, i64 0, i64 %idx1
  %o.3 = getelementptr [20 x i32], ptr addrspace(5) %p, i64 0, i64 %idx2
  %o.4 = getelementptr [20 x i32], ptr addrspace(5) %p, i64 0, i64 %idx3
  %x = load i32, ptr addrspace(5) %o.1, align 4
  %y = load i32, ptr addrspace(5) %o.2, align 4
  %z = load i32, ptr addrspace(5) %o.3, align 4
  %shifted = shl i32 %x, %y
  %a = add nuw nsw i32 %shifted, %z
  store i32 %a, ptr addrspace(5) %o.4, align 4
  ret void
}
