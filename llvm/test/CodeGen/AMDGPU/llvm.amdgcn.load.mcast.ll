; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -global-isel=0 -march=amdgcn -mcpu=gfx1300 -O3 -verify-machineinstrs < %s | FileCheck -check-prefixes=CHECK %s
target datalayout = "A5"

@out = external local_unnamed_addr addrspace(10) global <8 x float>, align 32
@dst2 = external local_unnamed_addr addrspace(10) global <8 x float>, align 32

; TODO: add ds and dds src to private vgprs
; TODO: add dds src to laneshared
; TODO: globalisel

;///////////////////////////////laneshared tests/////////////////////////////
; Global

define void @load_mcast_b32_vaddr(ptr addrspace(1) %addr, ptr addrspace(1) %use, i32 %mask) {
; CHECK-LABEL: load_mcast_b32_vaddr:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_readfirstlane_b32 s0, v4
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 m0, s0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b32 g1[0], v[0:1], off offset:16 th:TH_LOAD_HT scope:SCOPE_SE
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b32 v[2:3], g1[0], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 10, i32 %mask)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_vaddr_imm_mask(ptr addrspace(1) %addr, ptr addrspace(1) %use) {
; CHECK-LABEL: load_mcast_b32_vaddr_imm_mask:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 7
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b32 g1[0], v[0:1], off offset:16 th:TH_LOAD_HT scope:SCOPE_SE
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b32 v[2:3], g1[0], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 10, i32 7)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_vaddr_imm_mask_dstgep(ptr addrspace(1) %addr, ptr addrspace(1) %use) {
; CHECK-LABEL: load_mcast_b32_vaddr_imm_mask_dstgep:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 7
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b32 g1[6], v[0:1], off offset:16 th:TH_LOAD_HT scope:SCOPE_SE
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b32 v[2:3], g1[6], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(1) %addr, i32 4
  %outgep = getelementptr [8 x float], ptr addrspace(10) @out, i32 0, i32 6
  call void @llvm.amdgcn.load.mcast.b32.p10.p1(ptr addrspace(10) %outgep, ptr addrspace(1) %gep, i32 10, i32 7)
  %val = load float, ptr addrspace(10) %outgep, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_vaddr_imm_mask_dst2(ptr addrspace(1) %addr, ptr addrspace(1) %use) {
; CHECK-LABEL: load_mcast_b32_vaddr_imm_mask_dst2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 7
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b32 g1[0], v[0:1], off offset:16 th:TH_LOAD_HT scope:SCOPE_SE
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b32 v[2:3], g1[0], off
; CHECK-NEXT:    global_load_mcast_b32 g1[8], v[0:1], off offset:16 th:TH_LOAD_HT scope:SCOPE_SE
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b32 v[2:3], g1[8], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 10, i32 7)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  call void @llvm.amdgcn.load.mcast.b32.p10.p1(ptr addrspace(10) @dst2, ptr addrspace(1) %gep, i32 10, i32 7)
  %val2 = load float, ptr addrspace(10) @dst2, align 4
  store float %val2, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_vaddr_imm_mask_comp(ptr addrspace(1) %addr, ptr addrspace(1) %use) {
; CHECK-LABEL: load_mcast_b32_vaddr_imm_mask_comp:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 7
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b32 g1[3], v[0:1], off offset:16 th:TH_LOAD_HT scope:SCOPE_SE
; CHECK-NEXT:    global_store_b32 v[2:3], g1[0], off
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p1(ptr addrspace(10) getelementptr inbounds (float, ptr addrspace(10) @out, i32 3), ptr addrspace(1) %gep, i32 10, i32 7)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_saddr(ptr addrspace(1) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask) {
; CHECK-LABEL: load_mcast_b32_saddr:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_mov_b32_e32 v2, 0
; CHECK-NEXT:    s_mov_b32 m0, s2
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b32 g1[0], v2, s[0:1] offset:16 th:TH_LOAD_NT_HT scope:SCOPE_DEV
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b32 v[0:1], g1[0], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 22, i32 %mask)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_monitor_b32_saddr_scale_offset(ptr addrspace(1) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask, i32 %idx) {
; CHECK-LABEL: load_mcast_monitor_b32_saddr_scale_offset:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, s2
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b32 g1[0], v2, s[0:1] scale_offset th:TH_LOAD_BYPASS scope:SCOPE_SYS
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b32 v[0:1], g1[0], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %idxprom = sext i32 %idx to i64
  %gep = getelementptr float, ptr addrspace(1) %addr, i64 %idxprom
  call void @llvm.amdgcn.load.mcast.b32.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 27, i32 inreg %mask)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b64_vaddr(ptr addrspace(1) %addr, ptr addrspace(1) %use, i32 %mask) {
; CHECK-LABEL: load_mcast_b64_vaddr:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_readfirstlane_b32 s0, v4
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 m0, s0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b64 g1[0:1], v[0:1], off offset:32 th:TH_LOAD_NT
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b64 v[2:3], g1[0:1], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <2 x float>, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b64.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 1, i32 %mask)
  %val = load <2 x float>, ptr addrspace(10) @out, align 4
  store <2 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b64_vaddr_imm_mask(ptr addrspace(1) %addr, ptr addrspace(1) %use) {
; CHECK-LABEL: load_mcast_b64_vaddr_imm_mask:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 0x10007
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b64 g1[0:1], v[0:1], off offset:32 th:TH_LOAD_HT scope:SCOPE_SE
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b64 v[2:3], g1[0:1], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <2 x float>, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b64.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 10, i32 65543)
  %val = load <2 x float>, ptr addrspace(10) @out, align 4
  store <2 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b64_saddr(ptr addrspace(1) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask) {
; CHECK-LABEL: load_mcast_b64_saddr:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_mov_b32_e32 v2, 0
; CHECK-NEXT:    s_mov_b32 m0, s2
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b64 g1[0:1], v2, s[0:1] offset:32 th:TH_LOAD_NT_HT scope:SCOPE_DEV
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b64 v[0:1], g1[0:1], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <2 x float>, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b64.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 22, i32 %mask)
  %val = load <2 x float>, ptr addrspace(10) @out, align 4
  store <2 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_monitor_b64_saddr_scale_offset(ptr addrspace(1) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask, i32 %idx) {
; CHECK-LABEL: load_mcast_monitor_b64_saddr_scale_offset:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, s2
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b64 g1[0:1], v2, s[0:1] scale_offset th:TH_LOAD_BYPASS scope:SCOPE_SYS
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b64 v[0:1], g1[0:1], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %idxprom = sext i32 %idx to i64
  %gep = getelementptr <2 x float>, ptr addrspace(1) %addr, i64 %idxprom
  call void @llvm.amdgcn.load.mcast.b64.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 27, i32 inreg %mask)
  %val = load <2 x float>, ptr addrspace(10) @out, align 4
  store <2 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b128_vaddr(ptr addrspace(1) %addr, ptr addrspace(1) %use, i32 %mask) {
; CHECK-LABEL: load_mcast_b128_vaddr:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_readfirstlane_b32 s0, v4
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 m0, s0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b128 g1[0:3], v[0:1], off offset:64 th:TH_LOAD_NT
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b128 v[2:3], g1[0:3], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <4 x float>, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b128.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 1, i32 %mask)
  %val = load <4 x float>, ptr addrspace(10) @out, align 4
  store <4 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b128_vaddr_imm_mask(ptr addrspace(1) %addr, ptr addrspace(1) %use) {
; CHECK-LABEL: load_mcast_b128_vaddr_imm_mask:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 15
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b128 g1[0:3], v[0:1], off offset:64 th:TH_LOAD_HT scope:SCOPE_SE
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b128 v[2:3], g1[0:3], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <4 x float>, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b128.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 10, i32 15)
  %val = load <4 x float>, ptr addrspace(10) @out, align 4
  store <4 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b128_saddr(ptr addrspace(1) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask) {
; CHECK-LABEL: load_mcast_b128_saddr:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_mov_b32_e32 v2, 0
; CHECK-NEXT:    s_mov_b32 m0, s2
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    global_load_mcast_b128 g1[0:3], v2, s[0:1] offset:64 th:TH_LOAD_BYPASS scope:SCOPE_SYS
; CHECK-NEXT:    s_wait_loadcnt 0x0
; CHECK-NEXT:    global_store_b128 v[0:1], g1[0:3], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <4 x float>, ptr addrspace(1) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b128.p10.p1(ptr addrspace(10) @out, ptr addrspace(1) %gep, i32 27, i32 inreg %mask)
  %val = load <4 x float>, ptr addrspace(10) @out, align 4
  store <4 x float> %val, ptr addrspace(1) %use
  ret void
}

; DS

define void @load_mcast_b32_vaddr_local(ptr addrspace(3) %addr, ptr addrspace(1) %use, i32 %mask) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b32_vaddr_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_readfirstlane_b32 s0, v3
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 s1, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s1
; CHECK-NEXT:    s_mov_b32 m0, s0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b32 g1[0], v0 offset:16
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b32 v[1:2], g1[0], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 10, i32 %mask)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_vaddr_imm_mask_local(ptr addrspace(3) %addr, ptr addrspace(1) %use) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b32_vaddr_imm_mask_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 7
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b32 g1[0], v0 offset:16
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b32 v[1:2], g1[0], off
; CHECK-NEXT:    s_mov_b32 s0, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s0
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 10, i32 7)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_vaddr_imm_mask_dstgep_local(ptr addrspace(3) %addr, ptr addrspace(1) %use) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b32_vaddr_imm_mask_dstgep_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 7
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b32 g1[6], v0 offset:16
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b32 v[1:2], g1[6], off
; CHECK-NEXT:    s_mov_b32 s0, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s0
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(3) %addr, i32 4
  %outgep = getelementptr [8 x float], ptr addrspace(10) @out, i32 0, i32 6
  call void @llvm.amdgcn.load.mcast.b32.p10.p3(ptr addrspace(10) %outgep, ptr addrspace(3) %gep, i32 10, i32 7)
  %val = load float, ptr addrspace(10) %outgep, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_vaddr_imm_mask_dst2_local(ptr addrspace(3) %addr, ptr addrspace(1) %use) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b32_vaddr_imm_mask_dst2_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 7
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b32 g1[0], v0 offset:16
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b32 v[1:2], g1[0], off
; CHECK-NEXT:    ds_load_mcast_b32 g1[8], v0 offset:16
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b32 v[1:2], g1[8], off
; CHECK-NEXT:    s_mov_b32 s0, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s0
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 10, i32 7)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  call void @llvm.amdgcn.load.mcast.b32.p10.p3(ptr addrspace(10) @dst2, ptr addrspace(3) %gep, i32 10, i32 7)
  %val2 = load float, ptr addrspace(10) @dst2, align 4
  store float %val2, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_vaddr_imm_mask_comp_local(ptr addrspace(3) %addr, ptr addrspace(1) %use) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b32_vaddr_imm_mask_comp_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 7
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b32 g1[3], v0 offset:16
; CHECK-NEXT:    global_store_b32 v[1:2], g1[0], off
; CHECK-NEXT:    s_mov_b32 s0, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s0
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p3(ptr addrspace(10) getelementptr inbounds (float, ptr addrspace(10) @out, i32 3), ptr addrspace(3) %gep, i32 10, i32 7)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b32_saddr_local(ptr addrspace(3) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b32_saddr_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_mov_b32_e32 v2, s0
; CHECK-NEXT:    s_mov_b32 m0, s1
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 s2, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b32 g1[0], v2 offset:16
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b32 v[0:1], g1[0], off
; CHECK-NEXT:    s_mov_b32 s33, s2
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr float, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b32.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 22, i32 %mask)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_monitor_b32_saddr_scale_offset_local(ptr addrspace(3) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask, i32 %idx) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_monitor_b32_saddr_scale_offset_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_lshl_add_u32 v2, v2, 2, s0
; CHECK-NEXT:    s_mov_b32 m0, s1
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 s2, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b32 g1[0], v2
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b32 v[0:1], g1[0], off
; CHECK-NEXT:    s_mov_b32 s33, s2
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %idxprom = sext i32 %idx to i64
  %gep = getelementptr float, ptr addrspace(3) %addr, i64 %idxprom
  call void @llvm.amdgcn.load.mcast.b32.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 27, i32 inreg %mask)
  %val = load float, ptr addrspace(10) @out, align 4
  store float %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b64_vaddr_local(ptr addrspace(3) %addr, ptr addrspace(1) %use, i32 %mask) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b64_vaddr_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_readfirstlane_b32 s0, v3
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 s1, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s1
; CHECK-NEXT:    s_mov_b32 m0, s0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b64 g1[0:1], v0 offset:32
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b64 v[1:2], g1[0:1], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <2 x float>, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b64.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 1, i32 %mask)
  %val = load <2 x float>, ptr addrspace(10) @out, align 4
  store <2 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b64_vaddr_imm_mask_local(ptr addrspace(3) %addr, ptr addrspace(1) %use) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b64_vaddr_imm_mask_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 0x10007
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b64 g1[0:1], v0 offset:32
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b64 v[1:2], g1[0:1], off
; CHECK-NEXT:    s_mov_b32 s0, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s0
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <2 x float>, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b64.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 10, i32 65543)
  %val = load <2 x float>, ptr addrspace(10) @out, align 4
  store <2 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b64_saddr_local(ptr addrspace(3) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b64_saddr_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_mov_b32_e32 v2, s0
; CHECK-NEXT:    s_mov_b32 m0, s1
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 s2, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b64 g1[0:1], v2 offset:32
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b64 v[0:1], g1[0:1], off
; CHECK-NEXT:    s_mov_b32 s33, s2
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <2 x float>, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b64.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 22, i32 %mask)
  %val = load <2 x float>, ptr addrspace(10) @out, align 4
  store <2 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_monitor_b64_saddr_scale_offset_local(ptr addrspace(3) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask, i32 %idx) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_monitor_b64_saddr_scale_offset_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_lshl_add_u32 v2, v2, 3, s0
; CHECK-NEXT:    s_mov_b32 m0, s1
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 s2, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b64 g1[0:1], v2
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b64 v[0:1], g1[0:1], off
; CHECK-NEXT:    s_mov_b32 s33, s2
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %idxprom = sext i32 %idx to i64
  %gep = getelementptr <2 x float>, ptr addrspace(3) %addr, i64 %idxprom
  call void @llvm.amdgcn.load.mcast.b64.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 27, i32 inreg %mask)
  %val = load <2 x float>, ptr addrspace(10) @out, align 4
  store <2 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b128_vaddr_local(ptr addrspace(3) %addr, ptr addrspace(1) %use, i32 %mask) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b128_vaddr_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_readfirstlane_b32 s0, v3
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 s1, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s1
; CHECK-NEXT:    s_mov_b32 m0, s0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b128 g1[0:3], v0 offset:64
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b128 v[1:2], g1[0:3], off
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <4 x float>, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b128.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 1, i32 %mask)
  %val = load <4 x float>, ptr addrspace(10) @out, align 4
  store <4 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b128_vaddr_imm_mask_local(ptr addrspace(3) %addr, ptr addrspace(1) %use) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b128_vaddr_imm_mask_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_mov_b32 m0, 15
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b128 g1[0:3], v0 offset:64
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b128 v[1:2], g1[0:3], off
; CHECK-NEXT:    s_mov_b32 s0, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_mov_b32 s33, s0
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <4 x float>, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b128.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 10, i32 15)
  %val = load <4 x float>, ptr addrspace(10) @out, align 4
  store <4 x float> %val, ptr addrspace(1) %use
  ret void
}

define void @load_mcast_b128_saddr_local(ptr addrspace(3) inreg %addr, ptr addrspace(1) %use, i32 inreg %mask) "amdgpu-wavegroup-enable" {
; CHECK-LABEL: load_mcast_b128_saddr_local:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_wait_loadcnt_dscnt 0x0
; CHECK-NEXT:    s_wait_expcnt 0x0
; CHECK-NEXT:    s_wait_samplecnt 0x0
; CHECK-NEXT:    s_wait_rtscnt 0x0
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    v_mov_b32_e32 v2, s0
; CHECK-NEXT:    s_mov_b32 m0, s1
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, 0
; CHECK-NEXT:    s_mov_b32 s2, s33
; CHECK-NEXT:    s_mov_b32 s33, s32
; CHECK-NEXT:    s_set_vgpr_frames 0x44 ; vsrc0_idx=0 vsrc1_idx=1 vsrc2_idx=0 vdst_idx=1 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    ds_load_mcast_b128 g1[0:3], v2 offset:64
; CHECK-NEXT:    s_wait_dscnt 0x0
; CHECK-NEXT:    global_store_b128 v[0:1], g1[0:3], off
; CHECK-NEXT:    s_mov_b32 s33, s2
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_set_pc_i64 s[30:31]
entry:
  %gep = getelementptr <4 x float>, ptr addrspace(3) %addr, i32 4
  call void @llvm.amdgcn.load.mcast.b128.p10.p3(ptr addrspace(10) @out, ptr addrspace(3) %gep, i32 27, i32 inreg %mask)
  %val = load <4 x float>, ptr addrspace(10) @out, align 4
  store <4 x float> %val, ptr addrspace(1) %use
  ret void
}

; Make sure all laneshared variables are called directly or indirectly by a wavegroup kernel
define amdgpu_kernel void @dummy_kernel() "amdgpu-wavegroup-enable" !reqd_work_group_size !{i32 32, i32 8, i32 1} {
; CHECK-LABEL: dummy_kernel:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    s_getreg_b32 s9, hwreg(HW_REG_WAVE_GROUP_INFO, 16, 4)
; CHECK-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; CHECK-NEXT:    s_mul_i32 s10, s9, max(32, load_mcast_b32_vaddr_imm_mask_dst2.num_vgpr)
; CHECK-NEXT:    s_mul_i32 s33, s9, s8
; CHECK-NEXT:    s_add_co_u32 s10, s10, 16
; CHECK-NEXT:    s_add_co_u32 s32, s33, 0
; CHECK-NEXT:    s_set_gpr_idx_u32 idx0, s10
; CHECK-NEXT:    ; sched_barrier mask(0x00000000)
; CHECK-NEXT:    s_mov_b64 s[10:11], s[6:7]
; CHECK-NEXT:    s_get_pc_i64 s[6:7]
; CHECK-NEXT:    s_add_nc_u64 s[6:7], s[6:7], load_mcast_b32_vaddr_imm_mask_dst2@gotpcrel+4
; CHECK-NEXT:    v_mov_b32_e32 v31, v0
; CHECK-NEXT:    s_load_b64 s[12:13], s[6:7], 0x0
; CHECK-NEXT:    s_add_nc_u64 s[8:9], s[4:5], 36
; CHECK-NEXT:    s_mov_b64 s[4:5], s[0:1]
; CHECK-NEXT:    s_mov_b64 s[6:7], s[2:3]
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    s_swap_pc_i64 s[30:31], s[12:13]
; CHECK-NEXT:    s_endpgm
  call void @load_mcast_b32_vaddr_imm_mask_dst2()
  ret void
}

