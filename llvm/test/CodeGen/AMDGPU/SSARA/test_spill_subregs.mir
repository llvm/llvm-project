# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx900 -run-pass=amdgpu-ssa-spiller %s -verify-machineinstrs -o - | FileCheck %s

--- |
  define amdgpu_kernel void @test_subreg_spill() #0 {
  entry:
    ret void
  }

  attributes #0 = {
    nounwind "amdgpu-num-vgpr"="8" "target-cpu"="gfx900"
  }
...

---
name:            test_subreg_spill
tracksRegLiveness: true
fixedStack:      []
stack:           []
entry_values:    []
callSites:       []
debugValueSubstitutions: []
constants:       []

machineFunctionInfo:
  explicitKernArgSize: 8
  maxKernArgAlign: 8
  ldsSize:         0
  gdsSize:         0
  dynLDSAlign:     1

  scratchRSrcReg:    '$sgpr96_sgpr97_sgpr98_sgpr99'
  frameOffsetReg:    '$fp_reg'
  stackPtrOffsetReg: '$sgpr32'

  bytesInStackArgArea: 0
  returnsVoid:         true
  argumentInfo:
    kernargSegmentPtr: { reg: '$sgpr2_sgpr3' }

body:             |
  ; CHECK-LABEL: name: test_subreg_spill
  ; CHECK: bb.0:
  ; CHECK-NEXT:   successors: %bb.1(0x40000000), %bb.2(0x40000000)
  ; CHECK-NEXT:   liveins: $vgpr0
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   %idx:vgpr_32 = COPY $vgpr0
  ; CHECK-NEXT:   %a:vgpr_32 = V_MOV_B32_e32 10, implicit $exec
  ; CHECK-NEXT:   %b:vgpr_32 = V_MOV_B32_e32 20, implicit $exec
  ; CHECK-NEXT:   %c:vgpr_32 = V_MOV_B32_e32 30, implicit $exec
  ; CHECK-NEXT:   %d:vgpr_32 = V_MOV_B32_e32 40, implicit $exec
  ; CHECK-NEXT:   %large:vreg_128 = REG_SEQUENCE %a, %subreg.sub0, %b, %subreg.sub1, %c, %subreg.sub2, %d, %subreg.sub3
  ; CHECK-NEXT:   [[V_MOV_B32_e32_:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 1, implicit $exec
  ; CHECK-NEXT:   [[V_MOV_B32_e32_1:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 2, implicit $exec
  ; CHECK-NEXT:   [[V_MOV_B32_e32_2:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 3, implicit $exec
  ; CHECK-NEXT:   [[V_MOV_B32_e32_3:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 4, implicit $exec
  ; CHECK-NEXT:   SI_SPILL_V32_SAVE %large.sub2, %stack.0, $sgpr32, 0, implicit $exec :: (store (s128) into %stack.0, align 4, addrspace 5)
  ; CHECK-NEXT:   [[V_MOV_B32_e32_4:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 5, implicit $exec
  ; CHECK-NEXT:   SI_SPILL_V32_SAVE %large.sub1, %stack.1, $sgpr32, 0, implicit $exec :: (store (s128) into %stack.1, align 4, addrspace 5)
  ; CHECK-NEXT:   [[V_MOV_B32_e32_5:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 6, implicit $exec
  ; CHECK-NEXT:   SI_SPILL_V32_SAVE %large.sub0, %stack.2, $sgpr32, 0, implicit $exec :: (store (s128) into %stack.2, align 4, addrspace 5)
  ; CHECK-NEXT:   [[V_MOV_B32_e32_6:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 7, implicit $exec
  ; CHECK-NEXT:   [[V_MOV_B32_e32_7:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 8, implicit $exec
  ; CHECK-NEXT:   SI_SPILL_V32_SAVE killed [[V_MOV_B32_e32_6]], %stack.3, $sgpr32, 0, implicit $exec :: (store (s32) into %stack.3, addrspace 5)
  ; CHECK-NEXT:   %cmp:sreg_64 = V_CMP_NE_U32_e64 %idx, [[V_MOV_B32_e32_3]], implicit $exec
  ; CHECK-NEXT:   $vcc = COPY %cmp
  ; CHECK-NEXT:   S_CBRANCH_VCCNZ %bb.1, implicit $vcc
  ; CHECK-NEXT:   S_BRANCH %bb.2
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   %use1:vgpr_32 = V_ADD_U32_e32 [[V_MOV_B32_e32_]], [[V_MOV_B32_e32_1]], implicit $exec
  ; CHECK-NEXT:   [[SI_SPILL_V32_RESTORE:%[0-9]+]]:vgpr_32 = SI_SPILL_V32_RESTORE %stack.0, $sgpr32, 0, implicit $exec :: (load (s128) from %stack.0, align 4, addrspace 5)
  ; CHECK-NEXT:   %s2:vgpr_32 = COPY [[SI_SPILL_V32_RESTORE]], implicit $exec
  ; CHECK-NEXT:   %r1:vgpr_32 = V_ADD_U32_e32 %s2, %use1, implicit $exec
  ; CHECK-NEXT:   S_BRANCH %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   %use2:vgpr_32 = V_ADD_U32_e32 [[V_MOV_B32_e32_2]], [[V_MOV_B32_e32_4]], implicit $exec
  ; CHECK-NEXT:   [[SI_SPILL_V32_RESTORE1:%[0-9]+]]:vgpr_32 = SI_SPILL_V32_RESTORE %stack.1, $sgpr32, 0, implicit $exec :: (load (s128) from %stack.1, align 4, addrspace 5)
  ; CHECK-NEXT:   %s1:vgpr_32 = COPY [[SI_SPILL_V32_RESTORE1]], implicit $exec
  ; CHECK-NEXT:   %r2:vgpr_32 = V_ADD_U32_e32 %s1, %use2, implicit $exec
  ; CHECK-NEXT:   S_BRANCH %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3:
  ; CHECK-NEXT:   %phi_r:vgpr_32 = PHI %r1, %bb.1, %r2, %bb.2
  ; CHECK-NEXT:   %phi_use:vgpr_32 = PHI %use1, %bb.1, %use2, %bb.2
  ; CHECK-NEXT:   [[SI_SPILL_V32_RESTORE2:%[0-9]+]]:vgpr_32 = SI_SPILL_V32_RESTORE %stack.2, $sgpr32, 0, implicit $exec :: (load (s128) from %stack.2, align 4, addrspace 5)
  ; CHECK-NEXT:   %s0:vgpr_32 = COPY [[SI_SPILL_V32_RESTORE2]], implicit $exec
  ; CHECK-NEXT:   dead %final:vgpr_32 = V_ADD_U32_e32 %phi_r, %s0, implicit $exec
  ; CHECK-NEXT:   [[SI_SPILL_V32_RESTORE3:%[0-9]+]]:vgpr_32 = SI_SPILL_V32_RESTORE %stack.3, $sgpr32, 0, implicit $exec :: (load (s32) from %stack.3, addrspace 5)
  ; CHECK-NEXT:   dead %u1:vgpr_32 = V_ADD_U32_e32 [[V_MOV_B32_e32_5]], [[SI_SPILL_V32_RESTORE3]], implicit $exec
  ; CHECK-NEXT:   dead %u2:vgpr_32 = V_ADD_U32_e32 [[V_MOV_B32_e32_7]], %phi_use, implicit $exec
  ; CHECK-NEXT:   S_ENDPGM 0
  bb.0:
    successors: %bb.1(0x40000000), %bb.2(0x40000000); %bb.1(50.00%), %bb.2(50.00%)
    liveins: $vgpr0
    %idx:vgpr_32 = COPY $vgpr0
    %a:vgpr_32 = V_MOV_B32_e32 10, implicit $exec
    %b:vgpr_32 = V_MOV_B32_e32 20, implicit $exec
    %c:vgpr_32 = V_MOV_B32_e32 30, implicit $exec
    %d:vgpr_32 = V_MOV_B32_e32 40, implicit $exec
    %large:vreg_128 = REG_SEQUENCE %a:vgpr_32, %subreg.sub0, %b:vgpr_32, %subreg.sub1, %c:vgpr_32, %subreg.sub2, %d:vgpr_32, %subreg.sub3
    %6:vgpr_32 = V_MOV_B32_e32 1, implicit $exec
    %7:vgpr_32 = V_MOV_B32_e32 2, implicit $exec
    %8:vgpr_32 = V_MOV_B32_e32 3, implicit $exec
    %9:vgpr_32 = V_MOV_B32_e32 4, implicit $exec
    %10:vgpr_32 = V_MOV_B32_e32 5, implicit $exec
    %11:vgpr_32 = V_MOV_B32_e32 6, implicit $exec
    %12:vgpr_32 = V_MOV_B32_e32 7, implicit $exec
    %13:vgpr_32 = V_MOV_B32_e32 8, implicit $exec
    %cmp:sreg_64 = V_CMP_NE_U32_e64 %idx:vgpr_32, %9:vgpr_32, implicit $exec
    $vcc = COPY %cmp:sreg_64
    S_CBRANCH_VCCNZ %bb.1, implicit $vcc
    S_BRANCH %bb.2

  bb.1:
    successors: %bb.3(0x80000000)
    %use1:vgpr_32 = V_ADD_U32_e32 %6, %7, implicit $exec
    %s2:vgpr_32 = COPY %large.sub2, implicit $exec
    %r1:vgpr_32 = V_ADD_U32_e32 %s2, %use1, implicit $exec
    S_BRANCH %bb.3

  bb.2:
    successors: %bb.3(0x80000000)
    %use2:vgpr_32 = V_ADD_U32_e32 %8, %10, implicit $exec
    %s1:vgpr_32 = COPY %large.sub1, implicit $exec
    %r2:vgpr_32 = V_ADD_U32_e32 %s1, %use2, implicit $exec
    S_BRANCH %bb.3

  bb.3:
    %phi_r:vgpr_32 = PHI %r1, %bb.1, %r2, %bb.2
    %phi_use:vgpr_32 = PHI %use1, %bb.1, %use2, %bb.2
    %s0:vgpr_32 = COPY %large.sub0, implicit $exec
    %final:vgpr_32 = V_ADD_U32_e32 %phi_r, %s0, implicit $exec
    %u1:vgpr_32 = V_ADD_U32_e32 %11, %12, implicit $exec
    %u2:vgpr_32 = V_ADD_U32_e32 %13, %phi_use, implicit $exec
    S_ENDPGM 0



