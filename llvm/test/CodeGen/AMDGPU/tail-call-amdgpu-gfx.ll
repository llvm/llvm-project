; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=amdgcn--amdpal -mcpu=gfx900 -verify-machineinstrs < %s | FileCheck -check-prefixes=GCN -enable-var-scope %s
; RUN: llc -global-isel -mtriple=amdgcn--amdpal -mcpu=gfx900 -verify-machineinstrs < %s | FileCheck -check-prefixes=GCN -enable-var-scope %s

; FIXME: @caller uses s[4:5] to store the address of @callee.
;        These registers are callee-save in the amdgpu_gfx calling convention, so they must not be clobbered, but they are clobbered here.

; Callee with VGPR arguments
define hidden amdgpu_gfx float @callee(float %v.arg0, float %v.arg1) {
; GCN-LABEL: callee:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_add_f32_e32 v0, v0, v1
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add = fadd float %v.arg0, %v.arg1
  ret float %add
}

define amdgpu_gfx float @caller(float %arg0) {
; GCN-LABEL: caller:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    s_xor_saveexec_b64 s[34:35], -1
; GCN-NEXT:    buffer_store_dword v2, off, s[0:3], s32 ; 4-byte Folded Spill
; GCN-NEXT:    s_mov_b64 exec, s[34:35]
; GCN-NEXT:    v_writelane_b32 v2, s4, 0
; GCN-NEXT:    v_writelane_b32 v2, s5, 1
; GCN-NEXT:    s_getpc_b64 s[4:5]
; GCN-NEXT:    s_add_u32 s4, s4, callee@rel32@lo+4
; GCN-NEXT:    s_addc_u32 s5, s5, callee@rel32@hi+12
; GCN-NEXT:    v_add_f32_e32 v0, 1.0, v0
; GCN-NEXT:    v_mov_b32_e32 v1, 2.0
; GCN-NEXT:    v_readlane_b32 s5, v2, 1
; GCN-NEXT:    v_readlane_b32 s4, v2, 0
; GCN-NEXT:    s_xor_saveexec_b64 s[34:35], -1
; GCN-NEXT:    buffer_load_dword v2, off, s[0:3], s32 ; 4-byte Folded Reload
; GCN-NEXT:    s_mov_b64 exec, s[34:35]
; GCN-NEXT:    s_setpc_b64 s[4:5]
  %add = fadd float %arg0, 1.0
  %call = tail call amdgpu_gfx float @callee(float %add, float 2.0)
  ret float %call
}
