; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn -mcpu=gfx1200 -amdgpu-sgpr-hazard-regalloc=0 < %s | FileCheck -check-prefix DEF %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx1200 -amdgpu-sgpr-hazard-regalloc=1 < %s | FileCheck -check-prefix V1 %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx1200 -amdgpu-sgpr-hazard-regalloc=2 < %s | FileCheck -check-prefix V2 %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx1200 -amdgpu-sgpr-hazard-regalloc=3 < %s | FileCheck -check-prefix V3 %s

define amdgpu_ps float @fadd_f32(float inreg %a, float inreg %b, float %c, float %d, ptr addrspace(1) %out, <4 x i32> inreg %desc) {
; DEF-LABEL: fadd_f32:
; DEF:       ; %bb.0: ; %entry
; DEF-NEXT:    s_mov_b32 s6, s4
; DEF-NEXT:    s_mov_b32 s4, s2
; DEF-NEXT:    s_add_f32 s2, s0, s1
; DEF-NEXT:    s_sub_f32 s1, s0, s1
; DEF-NEXT:    s_mov_b32 s7, s5
; DEF-NEXT:    s_mov_b32 s5, s3
; DEF-NEXT:    s_delay_alu instid0(SALU_CYCLE_1) | instskip(NEXT) | instid1(VALU_DEP_1)
; DEF-NEXT:    v_dual_add_f32 v0, s2, v0 :: v_dual_add_f32 v1, s1, v1
; DEF-NEXT:    v_readfirstlane_b32 s0, v0
; DEF-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; DEF-NEXT:    v_readfirstlane_b32 s3, v1
; DEF-NEXT:    v_mul_f32_e32 v4, v0, v1
; DEF-NEXT:    s_and_b32 s0, s0, s3
; DEF-NEXT:    global_store_b32 v[2:3], v4, off
; DEF-NEXT:    s_wait_alu 0xfffe
; DEF-NEXT:    s_cmp_lg_u32 s0, 0
; DEF-NEXT:    s_mov_b32 s0, 0
; DEF-NEXT:    s_cbranch_scc0 .LBB0_5
; DEF-NEXT:  ; %bb.1: ; %false
; DEF-NEXT:    s_buffer_load_b32 s3, s[4:7], 0x0
; DEF-NEXT:    s_and_b32 s1, s2, s1
; DEF-NEXT:    v_add_f32_e32 v0, v0, v1
; DEF-NEXT:    s_mov_b32 s8, exec_lo
; DEF-NEXT:    s_wait_kmcnt 0x0
; DEF-NEXT:    s_wait_alu 0xfffe
; DEF-NEXT:    s_lshl_b32 s1, s3, s1
; DEF-NEXT:    s_wait_alu 0xfffe
; DEF-NEXT:    v_cmp_ne_u32_e32 vcc_lo, s1, v1
; DEF-NEXT:    s_and_not1_b32 s1, exec_lo, vcc_lo
; DEF-NEXT:    s_wait_alu 0xfffe
; DEF-NEXT:    s_and_not1_b32 s8, s8, s1
; DEF-NEXT:    s_cbranch_scc0 .LBB0_6
; DEF-NEXT:  ; %bb.2: ; %false
; DEF-NEXT:    s_and_b32 exec_lo, exec_lo, s8
; DEF-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; DEF-NEXT:    s_and_not1_b32 vcc_lo, exec_lo, s0
; DEF-NEXT:    s_cbranch_vccnz .LBB0_4
; DEF-NEXT:  .LBB0_3: ; %true
; DEF-NEXT:    v_mul_f32_e32 v0, v1, v4
; DEF-NEXT:  .LBB0_4: ; %final
; DEF-NEXT:    s_branch .LBB0_7
; DEF-NEXT:  .LBB0_5:
; DEF-NEXT:    ; implicit-def: $vgpr0
; DEF-NEXT:    s_branch .LBB0_3
; DEF-NEXT:  .LBB0_6:
; DEF-NEXT:    s_mov_b32 exec_lo, 0
; DEF-NEXT:    export mrt0 off, off, off, off done
; DEF-NEXT:    s_endpgm
; DEF-NEXT:  .LBB0_7:
;
; V1-LABEL: fadd_f32:
; V1:       ; %bb.0: ; %entry
; V1-NEXT:    s_add_f32 s104, s0, s1
; V1-NEXT:    s_sub_f32 s103, s0, s1
; V1-NEXT:    s_delay_alu instid0(SALU_CYCLE_3) | instskip(NEXT) | instid1(VALU_DEP_1)
; V1-NEXT:    v_dual_add_f32 v0, s104, v0 :: v_dual_add_f32 v1, s103, v1
; V1-NEXT:    v_readfirstlane_b32 s0, v0
; V1-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; V1-NEXT:    v_readfirstlane_b32 s1, v1
; V1-NEXT:    v_mul_f32_e32 v4, v0, v1
; V1-NEXT:    s_and_b32 s0, s0, s1
; V1-NEXT:    global_store_b32 v[2:3], v4, off
; V1-NEXT:    s_cmp_lg_u32 s0, 0
; V1-NEXT:    s_mov_b32 s0, 0
; V1-NEXT:    s_cbranch_scc0 .LBB0_5
; V1-NEXT:  ; %bb.1: ; %false
; V1-NEXT:    s_mov_b32 s7, s5
; V1-NEXT:    s_mov_b32 s6, s4
; V1-NEXT:    s_mov_b32 s5, s3
; V1-NEXT:    s_mov_b32 s4, s2
; V1-NEXT:    s_and_b32 s2, s104, s103
; V1-NEXT:    s_buffer_load_b32 s1, s[4:7], 0x0
; V1-NEXT:    v_add_f32_e32 v0, v0, v1
; V1-NEXT:    s_mov_b32 s8, exec_lo
; V1-NEXT:    s_wait_kmcnt 0x0
; V1-NEXT:    s_lshl_b32 vcc_hi, s1, s2
; V1-NEXT:    s_delay_alu instid0(SALU_CYCLE_1) | instskip(SKIP_1) | instid1(SALU_CYCLE_1)
; V1-NEXT:    v_cmp_ne_u32_e32 vcc_lo, vcc_hi, v1
; V1-NEXT:    s_and_not1_b32 s1, exec_lo, vcc_lo
; V1-NEXT:    s_and_not1_b32 s8, s8, s1
; V1-NEXT:    s_cbranch_scc0 .LBB0_6
; V1-NEXT:  ; %bb.2: ; %false
; V1-NEXT:    s_and_b32 exec_lo, exec_lo, s8
; V1-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; V1-NEXT:    s_and_not1_b32 vcc_lo, exec_lo, s0
; V1-NEXT:    s_wait_alu 0xfffe
; V1-NEXT:    s_cbranch_vccnz .LBB0_4
; V1-NEXT:  .LBB0_3: ; %true
; V1-NEXT:    v_mul_f32_e32 v0, v1, v4
; V1-NEXT:  .LBB0_4: ; %final
; V1-NEXT:    s_branch .LBB0_7
; V1-NEXT:  .LBB0_5:
; V1-NEXT:    ; implicit-def: $vgpr0
; V1-NEXT:    s_branch .LBB0_3
; V1-NEXT:  .LBB0_6:
; V1-NEXT:    s_mov_b32 exec_lo, 0
; V1-NEXT:    export mrt0 off, off, off, off done
; V1-NEXT:    s_endpgm
; V1-NEXT:  .LBB0_7:
;
; V2-LABEL: fadd_f32:
; V2:       ; %bb.0: ; %entry
; V2-NEXT:    s_add_f32 s62, s0, s1
; V2-NEXT:    s_sub_f32 s61, s0, s1
; V2-NEXT:    s_delay_alu instid0(SALU_CYCLE_3) | instskip(NEXT) | instid1(VALU_DEP_1)
; V2-NEXT:    v_dual_add_f32 v0, s62, v0 :: v_dual_add_f32 v1, s61, v1
; V2-NEXT:    v_readfirstlane_b32 s1, v0
; V2-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; V2-NEXT:    v_readfirstlane_b32 vcc_lo, v1
; V2-NEXT:    v_mul_f32_e32 v4, v0, v1
; V2-NEXT:    s_and_b32 s1, s1, vcc_lo
; V2-NEXT:    global_store_b32 v[2:3], v4, off
; V2-NEXT:    s_cmp_lg_u32 s1, 0
; V2-NEXT:    s_mov_b32 s1, 0
; V2-NEXT:    s_cbranch_scc0 .LBB0_5
; V2-NEXT:  ; %bb.1: ; %false
; V2-NEXT:    s_mov_b32 s55, s5
; V2-NEXT:    s_mov_b32 s54, s4
; V2-NEXT:    s_mov_b32 s53, s3
; V2-NEXT:    s_mov_b32 s52, s2
; V2-NEXT:    v_add_f32_e32 v0, v0, v1
; V2-NEXT:    s_buffer_load_b32 vcc_lo, s[52:55], 0x0
; V2-NEXT:    s_and_b32 s54, s62, s61
; V2-NEXT:    s_mov_b32 s69, exec_lo
; V2-NEXT:    s_wait_kmcnt 0x0
; V2-NEXT:    s_lshl_b32 s67, vcc_lo, s54
; V2-NEXT:    s_delay_alu instid0(SALU_CYCLE_1) | instskip(SKIP_1) | instid1(SALU_CYCLE_1)
; V2-NEXT:    v_cmp_ne_u32_e32 vcc_lo, s67, v1
; V2-NEXT:    s_and_not1_b32 vcc_lo, exec_lo, vcc_lo
; V2-NEXT:    s_and_not1_b32 s69, s69, vcc_lo
; V2-NEXT:    s_cbranch_scc0 .LBB0_6
; V2-NEXT:  ; %bb.2: ; %false
; V2-NEXT:    s_and_b32 exec_lo, exec_lo, s69
; V2-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; V2-NEXT:    s_and_not1_b32 vcc_lo, exec_lo, s1
; V2-NEXT:    s_cbranch_vccnz .LBB0_4
; V2-NEXT:  .LBB0_3: ; %true
; V2-NEXT:    v_mul_f32_e32 v0, v1, v4
; V2-NEXT:  .LBB0_4: ; %final
; V2-NEXT:    s_branch .LBB0_7
; V2-NEXT:  .LBB0_5:
; V2-NEXT:    ; implicit-def: $vgpr0
; V2-NEXT:    s_branch .LBB0_3
; V2-NEXT:  .LBB0_6:
; V2-NEXT:    s_mov_b32 exec_lo, 0
; V2-NEXT:    export mrt0 off, off, off, off done
; V2-NEXT:    s_endpgm
; V2-NEXT:  .LBB0_7:
;
; V3-LABEL: fadd_f32:
; V3:       ; %bb.0: ; %entry
; V3-NEXT:    s_add_f32 s104, s0, s1
; V3-NEXT:    s_sub_f32 s82, s0, s1
; V3-NEXT:    s_delay_alu instid0(SALU_CYCLE_3) | instskip(NEXT) | instid1(VALU_DEP_1)
; V3-NEXT:    v_dual_add_f32 v0, s104, v0 :: v_dual_add_f32 v1, s82, v1
; V3-NEXT:    v_readfirstlane_b32 s0, v0
; V3-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; V3-NEXT:    v_readfirstlane_b32 s1, v1
; V3-NEXT:    v_mul_f32_e32 v4, v0, v1
; V3-NEXT:    s_and_b32 s0, s0, s1
; V3-NEXT:    global_store_b32 v[2:3], v4, off
; V3-NEXT:    s_cmp_lg_u32 s0, 0
; V3-NEXT:    s_mov_b32 s0, 0
; V3-NEXT:    s_cbranch_scc0 .LBB0_5
; V3-NEXT:  ; %bb.1: ; %false
; V3-NEXT:    s_mov_b32 s7, s5
; V3-NEXT:    s_mov_b32 s6, s4
; V3-NEXT:    s_mov_b32 s5, s3
; V3-NEXT:    s_mov_b32 s4, s2
; V3-NEXT:    v_add_f32_e32 v0, v0, v1
; V3-NEXT:    s_buffer_load_b32 s1, s[4:7], 0x0
; V3-NEXT:    s_and_b32 s4, s104, s82
; V3-NEXT:    s_mov_b32 s8, exec_lo
; V3-NEXT:    s_wait_kmcnt 0x0
; V3-NEXT:    s_lshl_b32 s82, s1, s4
; V3-NEXT:    s_wait_alu 0xfffe
; V3-NEXT:    v_cmp_ne_u32_e32 vcc_lo, s82, v1
; V3-NEXT:    s_and_not1_b32 s1, exec_lo, vcc_lo
; V3-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; V3-NEXT:    s_and_not1_b32 s8, s8, s1
; V3-NEXT:    s_cbranch_scc0 .LBB0_6
; V3-NEXT:  ; %bb.2: ; %false
; V3-NEXT:    s_and_b32 exec_lo, exec_lo, s8
; V3-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; V3-NEXT:    s_and_not1_b32 vcc_lo, exec_lo, s0
; V3-NEXT:    s_cbranch_vccnz .LBB0_4
; V3-NEXT:  .LBB0_3: ; %true
; V3-NEXT:    v_mul_f32_e32 v0, v1, v4
; V3-NEXT:  .LBB0_4: ; %final
; V3-NEXT:    s_branch .LBB0_7
; V3-NEXT:  .LBB0_5:
; V3-NEXT:    ; implicit-def: $vgpr0
; V3-NEXT:    s_branch .LBB0_3
; V3-NEXT:  .LBB0_6:
; V3-NEXT:    s_mov_b32 exec_lo, 0
; V3-NEXT:    export mrt0 off, off, off, off done
; V3-NEXT:    s_endpgm
; V3-NEXT:  .LBB0_7:
entry:
   %s.0 = fadd float %a, %b
   %s.1 = fsub float %a, %b
   %v.0 = fadd float %c, %s.0
   %v.1 = fadd float %d, %s.1
   %v.2 = fmul float %v.0, %v.1
   store float %v.2, ptr addrspace(1) %out
   %tmp.0 = bitcast float %v.0 to i32
   %tmp.1 = bitcast float %v.1 to i32
   %tmp.2 = bitcast float %s.0 to i32
   %tmp.3 = bitcast float %s.1 to i32
   %s.3 = call i32 @llvm.amdgcn.readfirstlane.i32(i32 %tmp.0)
   %s.4 = call i32 @llvm.amdgcn.readfirstlane.i32(i32 %tmp.1)
   %s.5 = and i32 %s.3, %s.4
   %s.6 = and i32 %tmp.2, %tmp.3
   %c.0 = icmp eq i32 %s.5, 0
   br i1 %c.0, label %true, label %false
true:
   %v.3 = fmul float %v.1, %v.2
   br label %final
false:
   %v.4 = fadd float %v.0, %v.1
   %s.7 = call i32 @llvm.amdgcn.s.buffer.load.i32(<4 x i32> %desc, i32 0, i32 0)
   %s.8 = shl i32 %s.7, %s.6
   %c.1 = icmp ne i32 %tmp.1, %s.8
   call void @llvm.amdgcn.wqm.demote(i1 %c.1)
   br label %final
final:
   %res = phi float [ %v.4, %false ], [ %v.3, %true ]
   ret float %res
}

declare i32 @llvm.amdgcn.readfirstlane.i32(i32)
declare i32 @llvm.amdgcn.s.buffer.load.i32(<4 x i32>, i32, i32 immarg)
declare void @llvm.amdgcn.wqm.demote(i1)
