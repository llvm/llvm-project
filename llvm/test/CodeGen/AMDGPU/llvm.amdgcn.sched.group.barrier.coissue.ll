; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn -mcpu=gfx90a -verify-machineinstrs -misched-cluster=0  < %s | FileCheck -check-prefix=GFX90A %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx942 -verify-machineinstrs -misched-cluster=0  < %s | FileCheck -check-prefix=GFX942 %s

; gfx90a doesn't have coissue instruciton feature so the sched.group.barrier is meaningless

define amdgpu_kernel void @test_sched_group_barrier_pipeline_interleave_COISSUE_MFMA(ptr addrspace(3) noalias %in, ptr addrspace(3) noalias %out, ptr addrspace(3) noalias %in1) #0 {
; GCN-LABEL: test_sched_group_barrier_pipeline_interleave_PACK_MFMA:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GCN-NEXT:    v_and_b32_e32 v6, 0x3ff, v0
; GCN-NEXT:    v_lshlrev_b32_e32 v8, 7, v6
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_add_u32_e32 v7, s0, v8
; GCN-NEXT:    s_movk_i32 s0, 0xff88
; GCN-NEXT:    v_mad_i32_i24 v9, v6, s0, v7
; GCN-NEXT:    ds_read2st64_b64 v[0:3], v9 offset1:1
; GCN-NEXT:    ds_read_b64 v[4:5], v9 offset:5120
; GCN-NEXT:    ds_read_b128 a[28:31], v7 offset:112
; GCN-NEXT:    ds_read_b128 a[24:27], v7 offset:96
; GCN-NEXT:    ds_read_b128 a[20:23], v7 offset:80
; GCN-NEXT:    ds_read_b128 a[16:19], v7 offset:64
; GCN-NEXT:    ds_read_b128 a[0:3], v7
; GCN-NEXT:    ds_read_b128 a[4:7], v7 offset:16
; GCN-NEXT:    ds_read_b128 a[8:11], v7 offset:32
; GCN-NEXT:    ds_read_b128 a[12:15], v7 offset:48
; GCN-NEXT:    s_waitcnt lgkmcnt(8)
; GCN-NEXT:    v_pk_fma_f32 v[0:1], v[0:1], v[4:5], 0 op_sel_hi:[1,1,0]
; GCN-NEXT:    v_add_u32_e32 v4, 0xc00, v9
; GCN-NEXT:    v_lshl_add_u32 v10, v6, 3, v4
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; GCN-NEXT:    ds_read2st64_b64 v[4:7], v10 offset0:4 offset1:5
; GCN-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GCN-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_pk_fma_f32 v[4:5], v[2:3], v[4:5], v[0:1]
; GCN-NEXT:    ds_read2st64_b64 v[0:3], v9 offset0:3 offset1:6
; GCN-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GCN-NEXT:    s_nop 0
; GCN-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v4, v5, a[0:31]
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_pk_fma_f32 v[0:1], v[0:1], v[6:7], v[4:5]
; GCN-NEXT:    ds_read_b64 v[4:5], v10 offset:3584
; GCN-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GCN-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GCN-NEXT:    s_nop 0
; GCN-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_pk_fma_f32 v[0:1], v[2:3], v[4:5], v[0:1]
; GCN-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GCN-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GCN-NEXT:    s_nop 1
; GCN-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; GCN-NEXT:    v_add_u32_e32 v0, s1, v8
; GCN-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GCN-NEXT:    s_nop 7
; GCN-NEXT:    s_nop 7
; GCN-NEXT:    s_nop 1
; GCN-NEXT:    ds_write_b128 v0, a[28:31] offset:112
; GCN-NEXT:    ds_write_b128 v0, a[24:27] offset:96
; GCN-NEXT:    ds_write_b128 v0, a[20:23] offset:80
; GCN-NEXT:    ds_write_b128 v0, a[16:19] offset:64
; GCN-NEXT:    ds_write_b128 v0, a[12:15] offset:48
; GCN-NEXT:    ds_write_b128 v0, a[8:11] offset:32
; GCN-NEXT:    ds_write_b128 v0, a[4:7] offset:16
; GCN-NEXT:    ds_write_b128 v0, a[0:3]
; GCN-NEXT:    s_endpgm
;
; EXACTCUTOFF-LABEL: test_sched_group_barrier_pipeline_interleave_PACK_MFMA:
; EXACTCUTOFF:       ; %bb.0: ; %entry
; EXACTCUTOFF-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; EXACTCUTOFF-NEXT:    v_and_b32_e32 v6, 0x3ff, v0
; EXACTCUTOFF-NEXT:    v_lshlrev_b32_e32 v8, 7, v6
; EXACTCUTOFF-NEXT:    s_waitcnt lgkmcnt(0)
; EXACTCUTOFF-NEXT:    v_add_u32_e32 v7, s0, v8
; EXACTCUTOFF-NEXT:    s_movk_i32 s0, 0xff88
; EXACTCUTOFF-NEXT:    v_mad_i32_i24 v9, v6, s0, v7
; EXACTCUTOFF-NEXT:    ds_read2st64_b64 v[0:3], v9 offset1:1
; EXACTCUTOFF-NEXT:    ds_read_b64 v[4:5], v9 offset:5120
; EXACTCUTOFF-NEXT:    ds_read_b128 a[28:31], v7 offset:112
; EXACTCUTOFF-NEXT:    ds_read_b128 a[24:27], v7 offset:96
; EXACTCUTOFF-NEXT:    ds_read_b128 a[20:23], v7 offset:80
; EXACTCUTOFF-NEXT:    ds_read_b128 a[16:19], v7 offset:64
; EXACTCUTOFF-NEXT:    ds_read_b128 a[0:3], v7
; EXACTCUTOFF-NEXT:    ds_read_b128 a[4:7], v7 offset:16
; EXACTCUTOFF-NEXT:    ds_read_b128 a[8:11], v7 offset:32
; EXACTCUTOFF-NEXT:    ds_read_b128 a[12:15], v7 offset:48
; EXACTCUTOFF-NEXT:    s_waitcnt lgkmcnt(8)
; EXACTCUTOFF-NEXT:    v_pk_fma_f32 v[0:1], v[0:1], v[4:5], 0 op_sel_hi:[1,1,0]
; EXACTCUTOFF-NEXT:    v_add_u32_e32 v4, 0xc00, v9
; EXACTCUTOFF-NEXT:    v_lshl_add_u32 v10, v6, 3, v4
; EXACTCUTOFF-NEXT:    s_waitcnt lgkmcnt(0)
; EXACTCUTOFF-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; EXACTCUTOFF-NEXT:    ds_read2st64_b64 v[4:7], v10 offset0:4 offset1:5
; EXACTCUTOFF-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; EXACTCUTOFF-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; EXACTCUTOFF-NEXT:    s_waitcnt lgkmcnt(0)
; EXACTCUTOFF-NEXT:    v_pk_fma_f32 v[4:5], v[2:3], v[4:5], v[0:1]
; EXACTCUTOFF-NEXT:    ds_read2st64_b64 v[0:3], v9 offset0:3 offset1:6
; EXACTCUTOFF-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; EXACTCUTOFF-NEXT:    s_nop 0
; EXACTCUTOFF-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v4, v5, a[0:31]
; EXACTCUTOFF-NEXT:    s_waitcnt lgkmcnt(0)
; EXACTCUTOFF-NEXT:    v_pk_fma_f32 v[0:1], v[0:1], v[6:7], v[4:5]
; EXACTCUTOFF-NEXT:    ds_read_b64 v[4:5], v10 offset:3584
; EXACTCUTOFF-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; EXACTCUTOFF-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; EXACTCUTOFF-NEXT:    s_nop 0
; EXACTCUTOFF-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; EXACTCUTOFF-NEXT:    s_waitcnt lgkmcnt(0)
; EXACTCUTOFF-NEXT:    v_pk_fma_f32 v[0:1], v[2:3], v[4:5], v[0:1]
; EXACTCUTOFF-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; EXACTCUTOFF-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; EXACTCUTOFF-NEXT:    s_nop 1
; EXACTCUTOFF-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; EXACTCUTOFF-NEXT:    v_add_u32_e32 v0, s1, v8
; EXACTCUTOFF-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; EXACTCUTOFF-NEXT:    s_nop 7
; EXACTCUTOFF-NEXT:    s_nop 7
; EXACTCUTOFF-NEXT:    s_nop 1
; EXACTCUTOFF-NEXT:    ds_write_b128 v0, a[28:31] offset:112
; EXACTCUTOFF-NEXT:    ds_write_b128 v0, a[24:27] offset:96
; EXACTCUTOFF-NEXT:    ds_write_b128 v0, a[20:23] offset:80
; EXACTCUTOFF-NEXT:    ds_write_b128 v0, a[16:19] offset:64
; EXACTCUTOFF-NEXT:    ds_write_b128 v0, a[12:15] offset:48
; EXACTCUTOFF-NEXT:    ds_write_b128 v0, a[8:11] offset:32
; EXACTCUTOFF-NEXT:    ds_write_b128 v0, a[4:7] offset:16
; EXACTCUTOFF-NEXT:    ds_write_b128 v0, a[0:3]
; EXACTCUTOFF-NEXT:    s_endpgm
; GFX90A-LABEL: test_sched_group_barrier_pipeline_interleave_COISSUE_MFMA:
; GFX90A:       ; %bb.0: ; %entry
; GFX90A-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX90A-NEXT:    v_and_b32_e32 v6, 0x3ff, v0
; GFX90A-NEXT:    v_lshlrev_b32_e32 v8, 7, v6
; GFX90A-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GFX90A-NEXT:    s_waitcnt lgkmcnt(0)
; GFX90A-NEXT:    v_add_u32_e32 v7, s0, v8
; GFX90A-NEXT:    s_movk_i32 s0, 0xff88
; GFX90A-NEXT:    v_mad_i32_i24 v9, v6, s0, v7
; GFX90A-NEXT:    ds_read2st64_b64 v[0:3], v9 offset1:1
; GFX90A-NEXT:    ds_read_b64 v[4:5], v9 offset:5120
; GFX90A-NEXT:    ds_read_b128 a[28:31], v7 offset:112
; GFX90A-NEXT:    ds_read_b128 a[24:27], v7 offset:96
; GFX90A-NEXT:    ds_read_b128 a[20:23], v7 offset:80
; GFX90A-NEXT:    ds_read_b128 a[16:19], v7 offset:64
; GFX90A-NEXT:    ds_read_b128 a[0:3], v7
; GFX90A-NEXT:    ds_read_b128 a[4:7], v7 offset:16
; GFX90A-NEXT:    ds_read_b128 a[8:11], v7 offset:32
; GFX90A-NEXT:    ds_read_b128 a[12:15], v7 offset:48
; GFX90A-NEXT:    s_waitcnt lgkmcnt(8)
; GFX90A-NEXT:    v_pk_fma_f32 v[0:1], v[0:1], v[4:5], 0 op_sel_hi:[1,1,0]
; GFX90A-NEXT:    v_add_u32_e32 v4, 0xc00, v9
; GFX90A-NEXT:    v_lshl_add_u32 v10, v6, 3, v4
; GFX90A-NEXT:    s_waitcnt lgkmcnt(0)
; GFX90A-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; GFX90A-NEXT:    ds_read2st64_b64 v[4:7], v10 offset0:4 offset1:5
; GFX90A-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GFX90A-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GFX90A-NEXT:    s_waitcnt lgkmcnt(0)
; GFX90A-NEXT:    v_pk_fma_f32 v[4:5], v[2:3], v[4:5], v[0:1]
; GFX90A-NEXT:    ds_read2st64_b64 v[0:3], v9 offset0:3 offset1:6
; GFX90A-NEXT:    s_waitcnt lgkmcnt(0)
; GFX90A-NEXT:    v_pk_fma_f32 v[0:1], v[0:1], v[6:7], v[4:5]
; GFX90A-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v4, v5, a[0:31]
; GFX90A-NEXT:    ds_read_b64 v[4:5], v10 offset:3584
; GFX90A-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GFX90A-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GFX90A-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; GFX90A-NEXT:    s_waitcnt lgkmcnt(0)
; GFX90A-NEXT:    v_pk_fma_f32 v[0:1], v[2:3], v[4:5], v[0:1]
; GFX90A-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GFX90A-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GFX90A-NEXT:    s_nop 1
; GFX90A-NEXT:    v_mfma_f32_32x32x1f32 a[0:31], v0, v1, a[0:31]
; GFX90A-NEXT:    v_add_u32_e32 v0, s1, v8
; GFX90A-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GFX90A-NEXT:    s_nop 7
; GFX90A-NEXT:    s_nop 7
; GFX90A-NEXT:    s_nop 1
; GFX90A-NEXT:    ds_write_b128 v0, a[28:31] offset:112
; GFX90A-NEXT:    ds_write_b128 v0, a[24:27] offset:96
; GFX90A-NEXT:    ds_write_b128 v0, a[20:23] offset:80
; GFX90A-NEXT:    ds_write_b128 v0, a[16:19] offset:64
; GFX90A-NEXT:    ds_write_b128 v0, a[12:15] offset:48
; GFX90A-NEXT:    ds_write_b128 v0, a[8:11] offset:32
; GFX90A-NEXT:    ds_write_b128 v0, a[4:7] offset:16
; GFX90A-NEXT:    ds_write_b128 v0, a[0:3]
; GFX90A-NEXT:    s_endpgm
;
; GFX942-LABEL: test_sched_group_barrier_pipeline_interleave_COISSUE_MFMA:
; GFX942:       ; %bb.0: ; %entry
; GFX942-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX942-NEXT:    v_and_b32_e32 v6, 0x3ff, v0
; GFX942-NEXT:    v_lshlrev_b32_e32 v8, 7, v6
; GFX942-NEXT:    s_waitcnt lgkmcnt(0)
; GFX942-NEXT:    v_add_u32_e32 v7, s0, v8
; GFX942-NEXT:    s_movk_i32 s0, 0xff88
; GFX942-NEXT:    v_mad_i32_i24 v9, v6, s0, v7
; GFX942-NEXT:    ds_read2st64_b64 v[0:3], v9 offset1:1
; GFX942-NEXT:    ds_read_b64 v[4:5], v9 offset:5120
; GFX942-NEXT:    ds_read_b128 a[28:31], v7 offset:112
; GFX942-NEXT:    ds_read_b128 a[24:27], v7 offset:96
; GFX942-NEXT:    ds_read_b128 a[20:23], v7 offset:80
; GFX942-NEXT:    ds_read_b128 a[16:19], v7 offset:64
; GFX942-NEXT:    ds_read_b128 a[0:3], v7
; GFX942-NEXT:    ds_read_b128 a[4:7], v7 offset:16
; GFX942-NEXT:    ds_read_b128 a[8:11], v7 offset:32
; GFX942-NEXT:    ds_read_b128 a[12:15], v7 offset:48
; GFX942-NEXT:    s_waitcnt lgkmcnt(8)
; GFX942-NEXT:    v_pk_fma_f32 v[0:1], v[0:1], v[4:5], 0 op_sel_hi:[1,1,0]
; GFX942-NEXT:    v_add_u32_e32 v4, 0xc00, v9
; GFX942-NEXT:    v_lshl_add_u32 v10, v6, 3, v4
; GFX942-NEXT:    s_waitcnt lgkmcnt(0)
; GFX942-NEXT:    v_mfma_f32_32x32x1_2b_f32 a[0:31], v0, v1, a[0:31]
; GFX942-NEXT:    ds_read2st64_b64 v[4:7], v10 offset0:4 offset1:5
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GFX942-NEXT:    s_waitcnt lgkmcnt(0)
; GFX942-NEXT:    v_pk_fma_f32 v[4:5], v[2:3], v[4:5], v[0:1]
; GFX942-NEXT:    ds_read2st64_b64 v[0:3], v9 offset0:3 offset1:6
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GFX942-NEXT:    s_nop 0
; GFX942-NEXT:    v_mfma_f32_32x32x1_2b_f32 a[0:31], v4, v5, a[0:31]
; GFX942-NEXT:    s_waitcnt lgkmcnt(0)
; GFX942-NEXT:    v_pk_fma_f32 v[0:1], v[0:1], v[6:7], v[4:5]
; GFX942-NEXT:    ds_read_b64 v[4:5], v10 offset:3584
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GFX942-NEXT:    s_nop 0
; GFX942-NEXT:    v_mfma_f32_32x32x1_2b_f32 a[0:31], v0, v1, a[0:31]
; GFX942-NEXT:    s_waitcnt lgkmcnt(0)
; GFX942-NEXT:    v_pk_fma_f32 v[0:1], v[2:3], v[4:5], v[0:1]
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000800) size(1) SyncID(0)
; GFX942-NEXT:    s_nop 1
; GFX942-NEXT:    v_mfma_f32_32x32x1_2b_f32 a[0:31], v0, v1, a[0:31]
; GFX942-NEXT:    v_add_u32_e32 v0, s1, v8
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000008) size(1) SyncID(0)
; GFX942-NEXT:    s_nop 7
; GFX942-NEXT:    s_nop 7
; GFX942-NEXT:    s_nop 0
; GFX942-NEXT:    ds_write_b128 v0, a[28:31] offset:112
; GFX942-NEXT:    ds_write_b128 v0, a[24:27] offset:96
; GFX942-NEXT:    ds_write_b128 v0, a[20:23] offset:80
; GFX942-NEXT:    ds_write_b128 v0, a[16:19] offset:64
; GFX942-NEXT:    ds_write_b128 v0, a[12:15] offset:48
; GFX942-NEXT:    ds_write_b128 v0, a[8:11] offset:32
; GFX942-NEXT:    ds_write_b128 v0, a[4:7] offset:16
; GFX942-NEXT:    ds_write_b128 v0, a[0:3]
; GFX942-NEXT:    s_endpgm
entry:
  %idx = call i32 @llvm.amdgcn.workitem.id.x()
  %load.0.addr = getelementptr <32 x float>, ptr addrspace(3) %in, i32 %idx
  %load.0 = load <32 x float>, ptr addrspace(3) %load.0.addr
  %el.0.addr = getelementptr <2 x float>, ptr addrspace(3) %in, i32 %idx
  %el.0 = load <2 x float>, ptr addrspace(3) %el.0.addr
  %el.1.addr = getelementptr <2 x float>, ptr addrspace(3) %el.0.addr, i32 64
  %el.1 = load <2 x float>, ptr addrspace(3) %el.1.addr
  %el.2.addr = getelementptr <2 x float>, ptr addrspace(3) %el.1.addr, i32 128
  %el.2 = load <2 x float>, ptr addrspace(3) %el.2.addr
  %el.3.addr = getelementptr <2 x float>, ptr addrspace(3) %el.2.addr, i32 192
  %el.3 = load <2 x float>, ptr addrspace(3) %el.3.addr
  %el.4.addr = getelementptr <2 x float>, ptr addrspace(3) %el.3.addr, i32 256
  %el.4 = load <2 x float>, ptr addrspace(3) %el.4.addr
  %el.5.addr = getelementptr <2 x float>, ptr addrspace(3) %el.4.addr, i32 %idx
  %el.5 = load <2 x float>, ptr addrspace(3) %el.5.addr
  %el.6.addr = getelementptr <2 x float>, ptr addrspace(3) %el.5.addr, i32 64
  %el.6 = load <2 x float>, ptr addrspace(3) %el.6.addr
  %el.7.addr = getelementptr <2 x float>, ptr addrspace(3) %el.6.addr, i32 128
  %el.7 = load <2 x float>, ptr addrspace(3) %el.7.addr
  %v0 = tail call contract <2 x float> @llvm.fma.v2f32(<2 x float> %el.0, <2 x float> %el.4, <2 x float> <float 0.0, float 0.0>)
  %v1 = tail call contract <2 x float> @llvm.fma.v2f32(<2 x float> %el.1, <2 x float> %el.5, <2 x float> %v0)
  %v2 = tail call contract <2 x float> @llvm.fma.v2f32(<2 x float> %el.2, <2 x float> %el.6, <2 x float> %v1)
  %v3 = tail call contract <2 x float> @llvm.fma.v2f32(<2 x float> %el.3, <2 x float> %el.7, <2 x float> %v2)
  %op0 = extractelement <2 x float> %v0, i32 0
  %op1 = extractelement <2 x float> %v0, i32 1
  %op2 = extractelement <2 x float> %v1, i32 0
  %op3 = extractelement <2 x float> %v1, i32 1
  %op4 = extractelement <2 x float> %v2, i32 0
  %op5 = extractelement <2 x float> %v2, i32 1
  %op6 = extractelement <2 x float> %v3, i32 0
  %op7 = extractelement <2 x float> %v3, i32 1
  %mai.0 = tail call <32 x float> @llvm.amdgcn.mfma.f32.32x32x1f32(float %op0, float %op1, <32 x float> %load.0, i32 0, i32 0, i32 0)
  %mai.1 = tail call <32 x float> @llvm.amdgcn.mfma.f32.32x32x1f32(float %op2, float %op3, <32 x float> %mai.0, i32 0, i32 0, i32 0)
  %mai.2 = tail call <32 x float> @llvm.amdgcn.mfma.f32.32x32x1f32(float %op4, float %op5, <32 x float> %mai.1, i32 0, i32 0, i32 0)
  %mai.3 = tail call <32 x float> @llvm.amdgcn.mfma.f32.32x32x1f32(float %op6, float %op7, <32 x float> %mai.2, i32 0, i32 0, i32 0)
  ; 1 PACK
  call void @llvm.amdgcn.sched.group.barrier(i32 2048, i32 1, i32 0)
  ; 1 MFMA
  call void @llvm.amdgcn.sched.group.barrier(i32 8, i32 1, i32 0)
  ; 1 PACK
  call void @llvm.amdgcn.sched.group.barrier(i32 2048, i32 1, i32 0)
  ; 1 MFMA
  call void @llvm.amdgcn.sched.group.barrier(i32 8, i32 1, i32 0)
  ; 1 PACK
  call void @llvm.amdgcn.sched.group.barrier(i32 2048, i32 1, i32 0)
  ; 1 MFMA
  call void @llvm.amdgcn.sched.group.barrier(i32 8, i32 1, i32 0)
  ; 1 PACK
  call void @llvm.amdgcn.sched.group.barrier(i32 2048, i32 1, i32 0)
  ; 1 MFMA
  call void @llvm.amdgcn.sched.group.barrier(i32 8, i32 1, i32 0)
  %store.addr = getelementptr <32 x float>, ptr addrspace(3) %out, i32 %idx
  store <32 x float> %mai.3, ptr addrspace(3) %store.addr
  ret void
}

