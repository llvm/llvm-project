# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 6
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx950 --passes=machine-scheduler --amdgpu-no-added-latency-before-atomic-fence  -o - %s | FileCheck %s -check-prefix=NO-LATENCY
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx950 --passes=machine-scheduler  -o - %s | FileCheck %s -check-prefix=LATENCY

# Ensure ATOMIC_FENCE is scheduled before load uses when --amdgpu-no-added-latency-before-atomic-fence is used.
---
name: test_barrier_fence_scheduling
tracksRegLiveness: true
registers:
  - { id: 0, class: vgpr_32 }
  - { id: 1, class: vreg_64_align2 }
  - { id: 2, class: vgpr_32 }
  - { id: 3, class: vgpr_32 }
  - { id: 4, class: vgpr_32 }
  - { id: 5, class: vreg_64_align2 }
  - { id: 6, class: vreg_64_align2 }
  - { id: 7, class: vreg_64_align2 }
  - { id: 8, class: vreg_64_align2 }
  - { id: 9, class: vreg_64_align2 }
  - { id: 10, class: vreg_64_align2 }
  - { id: 11, class: vreg_64_align2 }
  - { id: 12, class: vreg_64_align2 }
  - { id: 13, class: vreg_64_align2 }
  - { id: 14, class: vreg_64_align2 }
  - { id: 15, class: vgpr_32 }
  - { id: 16, class: vgpr_32 }
body: |
  bb.0:

    ; Load 4 half-precision values from global memory
    ; NO-LATENCY-LABEL: name: test_barrier_fence_scheduling
    ; NO-LATENCY: [[GLOBAL_LOAD_USHORT:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_USHORT undef %1:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    ; NO-LATENCY-NEXT: [[GLOBAL_LOAD_USHORT1:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_USHORT undef %1:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    ; NO-LATENCY-NEXT: [[GLOBAL_LOAD_USHORT2:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_USHORT undef %1:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    ; NO-LATENCY-NEXT: [[GLOBAL_LOAD_USHORT3:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_USHORT undef %1:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    ; NO-LATENCY-NEXT: undef [[V_MOV_B32_e32_:%[0-9]+]].sub0:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    ; NO-LATENCY-NEXT: [[V_MOV_B32_e32_:%[0-9]+]].sub1:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    ; NO-LATENCY-NEXT: undef [[V_MOV_B32_e32_1:%[0-9]+]].sub0:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    ; NO-LATENCY-NEXT: undef [[V_CVT_F32_F16_e32_:%[0-9]+]].sub0:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 [[GLOBAL_LOAD_USHORT]], implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: undef [[V_CVT_F32_F16_e32_1:%[0-9]+]].sub0:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 [[GLOBAL_LOAD_USHORT1]], implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_CVT_F32_F16_e32_1:%[0-9]+]].sub1:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 [[GLOBAL_LOAD_USHORT2]], implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_CVT_F32_F16_e32_:%[0-9]+]].sub1:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 [[GLOBAL_LOAD_USHORT3]], implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_MOV_B32_e32_1:%[0-9]+]].sub1:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    ; NO-LATENCY-NEXT: ATOMIC_FENCE 5, 7
    ; NO-LATENCY-NEXT: [[V_PK_ADD_F32_:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_ADD_F32 8, [[V_CVT_F32_F16_e32_1]], 11, [[V_MOV_B32_e32_]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_PK_FMA_F32_:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_FMA_F32 8, [[V_CVT_F32_F16_e32_]], 0, [[V_MOV_B32_e32_1]], 8, [[V_MOV_B32_e32_1]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_PK_MUL_F32_:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, [[V_MOV_B32_e32_]], 8, [[V_PK_ADD_F32_]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_PK_MUL_F32_1:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, [[V_MOV_B32_e32_]], 8, [[V_PK_MUL_F32_]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_PK_ADD_F32_1:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_ADD_F32 8, [[V_PK_FMA_F32_]], 8, [[V_PK_MUL_F32_1]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_PK_MUL_F32_2:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, [[V_MOV_B32_e32_]], 8, [[V_PK_ADD_F32_1]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_CVT_F16_F32_e32_:%[0-9]+]]:vgpr_32 = nofpexcept V_CVT_F16_F32_e32 [[V_PK_MUL_F32_2]].sub0, implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: [[V_CVT_F16_F32_e32_1:%[0-9]+]]:vgpr_32 = nofpexcept V_CVT_F16_F32_e32 [[V_PK_MUL_F32_2]].sub1, implicit $mode, implicit $exec
    ; NO-LATENCY-NEXT: S_BARRIER
    ; NO-LATENCY-NEXT: ATOMIC_FENCE 4, 7
    ; NO-LATENCY-NEXT: GLOBAL_STORE_SHORT undef %1:vreg_64_align2, [[V_CVT_F16_F32_e32_]], 0, 0, implicit $exec :: (store (s16), addrspace 1)
    ; NO-LATENCY-NEXT: GLOBAL_STORE_SHORT undef %1:vreg_64_align2, [[V_CVT_F16_F32_e32_1]], 0, 0, implicit $exec :: (store (s16), addrspace 1)
    ; NO-LATENCY-NEXT: S_ENDPGM 0
    ;
    ; LATENCY-LABEL: name: test_barrier_fence_scheduling
    ; LATENCY: [[GLOBAL_LOAD_USHORT:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_USHORT undef %1:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    ; LATENCY-NEXT: [[GLOBAL_LOAD_USHORT1:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_USHORT undef %1:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    ; LATENCY-NEXT: [[GLOBAL_LOAD_USHORT2:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_USHORT undef %1:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    ; LATENCY-NEXT: [[GLOBAL_LOAD_USHORT3:%[0-9]+]]:vgpr_32 = GLOBAL_LOAD_USHORT undef %1:vreg_64_align2, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    ; LATENCY-NEXT: undef [[V_MOV_B32_e32_:%[0-9]+]].sub0:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    ; LATENCY-NEXT: [[V_MOV_B32_e32_:%[0-9]+]].sub1:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    ; LATENCY-NEXT: undef [[V_CVT_F32_F16_e32_:%[0-9]+]].sub0:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 [[GLOBAL_LOAD_USHORT]], implicit $mode, implicit $exec
    ; LATENCY-NEXT: undef [[V_CVT_F32_F16_e32_1:%[0-9]+]].sub0:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 [[GLOBAL_LOAD_USHORT1]], implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_CVT_F32_F16_e32_1:%[0-9]+]].sub1:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 [[GLOBAL_LOAD_USHORT3]], implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_CVT_F32_F16_e32_:%[0-9]+]].sub1:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 [[GLOBAL_LOAD_USHORT2]], implicit $mode, implicit $exec
    ; LATENCY-NEXT: undef [[V_MOV_B32_e32_1:%[0-9]+]].sub0:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    ; LATENCY-NEXT: [[V_MOV_B32_e32_1:%[0-9]+]].sub1:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    ; LATENCY-NEXT: [[V_PK_ADD_F32_:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_ADD_F32 8, [[V_CVT_F32_F16_e32_1]], 11, [[V_MOV_B32_e32_]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_PK_FMA_F32_:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_FMA_F32 8, [[V_CVT_F32_F16_e32_]], 0, [[V_MOV_B32_e32_1]], 8, [[V_MOV_B32_e32_1]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_PK_MUL_F32_:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, [[V_MOV_B32_e32_]], 8, [[V_PK_ADD_F32_]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_PK_MUL_F32_1:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, [[V_MOV_B32_e32_]], 8, [[V_PK_MUL_F32_]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_PK_ADD_F32_1:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_ADD_F32 8, [[V_PK_FMA_F32_]], 8, [[V_PK_MUL_F32_1]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_PK_MUL_F32_2:%[0-9]+]]:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, [[V_MOV_B32_e32_]], 8, [[V_PK_ADD_F32_1]], 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_CVT_F16_F32_e32_:%[0-9]+]]:vgpr_32 = nofpexcept V_CVT_F16_F32_e32 [[V_PK_MUL_F32_2]].sub0, implicit $mode, implicit $exec
    ; LATENCY-NEXT: [[V_CVT_F16_F32_e32_1:%[0-9]+]]:vgpr_32 = nofpexcept V_CVT_F16_F32_e32 [[V_PK_MUL_F32_2]].sub1, implicit $mode, implicit $exec
    ; LATENCY-NEXT: ATOMIC_FENCE 5, 7
    ; LATENCY-NEXT: S_BARRIER
    ; LATENCY-NEXT: ATOMIC_FENCE 4, 7
    ; LATENCY-NEXT: GLOBAL_STORE_SHORT undef %1:vreg_64_align2, [[V_CVT_F16_F32_e32_]], 0, 0, implicit $exec :: (store (s16), addrspace 1)
    ; LATENCY-NEXT: GLOBAL_STORE_SHORT undef %1:vreg_64_align2, [[V_CVT_F16_F32_e32_1]], 0, 0, implicit $exec :: (store (s16), addrspace 1)
    ; LATENCY-NEXT: S_ENDPGM 0
    %0:vgpr_32 = GLOBAL_LOAD_USHORT undef %1, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    %2:vgpr_32 = GLOBAL_LOAD_USHORT undef %1, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    %3:vgpr_32 = GLOBAL_LOAD_USHORT undef %1, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)
    %4:vgpr_32 = GLOBAL_LOAD_USHORT undef %1, 0, 0, implicit $exec :: ("amdgpu-noclobber" load (s16), addrspace 1)

    ; Convert loaded halfs to floats (use the loaded values)
    undef %5.sub0:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 %0, implicit $mode, implicit $exec
    %5.sub1:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 %3, implicit $mode, implicit $exec
    undef %6.sub0:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 %2, implicit $mode, implicit $exec
    %6.sub1:vreg_64_align2 = nofpexcept V_CVT_F32_F16_e32 %4, implicit $mode, implicit $exec

    ; Initialize constants for computation
    undef %7.sub0:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    %7.sub1:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    undef %8.sub0:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec
    %8.sub1:vreg_64_align2 = V_MOV_B32_e32 1065353216, implicit $exec

    ; Computation chain: multiply, add, fma operations
    %9:vreg_64_align2 = nofpexcept V_PK_ADD_F32 8, %6, 11, %7, 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    %10:vreg_64_align2 = nofpexcept V_PK_FMA_F32 8, %5, 0, %8, 8, %8, 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    %11:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, %7, 8, %9, 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    %12:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, %7, 8, %11, 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    %13:vreg_64_align2 = nofpexcept V_PK_ADD_F32 8, %10, 8, %12, 0, 0, 0, 0, 0, implicit $mode, implicit $exec
    %14:vreg_64_align2 = nofpexcept V_PK_MUL_F32 8, %7, 8, %13, 0, 0, 0, 0, 0, implicit $mode, implicit $exec

    ; Fence before barrier
    ATOMIC_FENCE 5, 7
    S_BARRIER
    ATOMIC_FENCE 4, 7

    ; Store results back
    %15:vgpr_32 = nofpexcept V_CVT_F16_F32_e32 %14.sub0, implicit $mode, implicit $exec
    GLOBAL_STORE_SHORT undef %1, %15, 0, 0, implicit $exec :: (store (s16), addrspace 1)
    %16:vgpr_32 = nofpexcept V_CVT_F16_F32_e32 %14.sub1, implicit $mode, implicit $exec
    GLOBAL_STORE_SHORT undef %1, %16, 0, 0, implicit $exec :: (store (s16), addrspace 1)
    S_ENDPGM 0


