; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --check-attributes --check-globals all --version 5
; RUN: opt -S -mtriple=amdgcn-amd-amdhsa -passes=amdgpu-split-kernel-arguments -amdgpu-enable-split-kernel-args < %s | FileCheck %s
; RUN: opt -S -mtriple=amdgcn-amd-amdhsa -passes=amdgpu-split-kernel-arguments -amdgpu-enable-split-kernel-args < %s > %t.ll
; RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx1100 < %t.ll | FileCheck --check-prefix=GCN %s
;
; The LLVM IR is from the following HIP program:
;
; struct A {
; int i;
; char c;
; long l;
; int *p;
; };

; struct B {
; char c;
; A a1;
; int i;
; A a2;
; };
;
; __global__ void test(int *out, int i, A a, char c, B b) {
;  *out = i + a.l + c + a.l + b.a1.c;
;  b.a2.p[2] = a.l + b.a2.c;
;}
;
%struct.A = type { i32, i8, i64, ptr }
%struct.B = type { i8, %struct.A, i32, %struct.A }

; The "amdgpu-original-arg" function parameter attribute encodes how is the
; argument split from the original kernel argument.
;
; Format: "amdgpu-original-arg"="OrigIndex:OrigOffset"
; - OrigIndex: Index of the original kernel argument before splitting
; - OrigOffset: Byte offset within the original argument

;--- Main test case for successful split ---

define amdgpu_kernel void @_Z4testPii1Ac1B(
; CHECK-LABEL: define amdgpu_kernel void @_Z4testPii1Ac1B(
; CHECK-SAME: ptr addrspace(1) noundef writeonly captures(none) initializes((0, 4)) [[OUT:%.*]], i32 noundef [[I:%.*]], i64 "amdgpu-original-arg"="2:8" [[A_L:%.*]], i8 noundef [[C:%.*]], i8 "amdgpu-original-arg"="4:12" [[B_A1_C:%.*]], i8 "amdgpu-original-arg"="4:44" [[B_A2_C:%.*]], ptr "amdgpu-original-arg"="4:56" [[B_A2_P:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr [[B_A2_P]] to ptr addrspace(1)
; CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[I]] to i64
; CHECK-NEXT:    [[CONV3:%.*]] = sext i8 [[C]] to i64
; CHECK-NEXT:    [[CONV8:%.*]] = sext i8 [[B_A1_C]] to i64
; CHECK-NEXT:    [[FACTOR:%.*]] = shl i64 [[A_L]], 1
; CHECK-NEXT:    [[ADD4:%.*]] = add nsw i64 [[CONV]], [[CONV3]]
; CHECK-NEXT:    [[ADD6:%.*]] = add i64 [[ADD4]], [[FACTOR]]
; CHECK-NEXT:    [[ADD9:%.*]] = add i64 [[ADD6]], [[CONV8]]
; CHECK-NEXT:    [[CONV10:%.*]] = trunc i64 [[ADD9]] to i32
; CHECK-NEXT:    store i32 [[CONV10]], ptr addrspace(1) [[OUT]], align 4
; CHECK-NEXT:    [[B_A2_C_SEXT:%.*]] = sext i8 [[B_A2_C]] to i64
; CHECK-NEXT:    [[ADD14:%.*]] = add nsw i64 [[A_L]], [[B_A2_C_SEXT]]
; CHECK-NEXT:    [[CONV15:%.*]] = trunc i64 [[ADD14]] to i32
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i32, ptr addrspace(1) [[TMP1]], i64 2
; CHECK-NEXT:    store i32 [[CONV15]], ptr addrspace(1) [[ARRAYIDX]], align 4
; CHECK-NEXT:    ret void
;
  ptr addrspace(1) noundef writeonly captures(none) initializes((0, 4)) %out,
  i32 noundef %i,
  ptr addrspace(4) noundef readonly byref(%struct.A) align 8 captures(none) %a,
  i8 noundef %c,
  ptr addrspace(4) noundef readonly byref(%struct.B) align 8 captures(none) %b
) {
entry:
  ; Load a.l from struct A
  %a.l.addr = getelementptr inbounds nuw i8, ptr addrspace(4) %a, i64 8
  %a.l = load i64, ptr addrspace(4) %a.l.addr, align 8

  ; Load b.a1.c from struct B
  %b.a1.c.addr = getelementptr inbounds nuw i8, ptr addrspace(4) %b, i64 12
  %b.a1.c = load i8, ptr addrspace(4) %b.a1.c.addr, align 4

  ; Load b.a2.c from struct B
  %b.a2.c.addr = getelementptr inbounds nuw i8, ptr addrspace(4) %b, i64 44
  %b.a2.c = load i8, ptr addrspace(4) %b.a2.c.addr, align 4

  ; Load b.a2.p from struct B
  %b.a2.p.addr = getelementptr inbounds nuw i8, ptr addrspace(4) %b, i64 56
  %b.a2.p = load ptr, ptr addrspace(4) %b.a2.p.addr, align 8

  ; Cast b.a2.p to global address space
  %b.a2.p.global = addrspacecast ptr %b.a2.p to ptr addrspace(1)

  ; Compute i + a.l + c + a.l + b.a1.c
  %i.zext = zext i32 %i to i64
  %c.sext = sext i8 %c to i64
  %b.a1.c.sext = sext i8 %b.a1.c to i64
  %a.l.x2 = shl i64 %a.l, 1

  %tmp_sum1 = add nsw i64 %i.zext, %c.sext
  %tmp_sum2 = add i64 %tmp_sum1, %a.l.x2
  %tmp_sum3 = add i64 %tmp_sum2, %b.a1.c.sext
  %result = trunc i64 %tmp_sum3 to i32
  store i32 %result, ptr addrspace(1) %out, align 4

  ; Compute a.l + b.a2.c and store to b.a2.p[2]
  %b.a2.c.sext = sext i8 %b.a2.c to i64
  %sum_store = add nsw i64 %a.l, %b.a2.c.sext
  %store_val = trunc i64 %sum_store to i32

  %b.a2.p.elem2 = getelementptr inbounds i32, ptr addrspace(1) %b.a2.p.global, i64 2
  store i32 %store_val, ptr addrspace(1) %b.a2.p.elem2, align 4

  ret void
}

; --- Re-split test: arg #0 and #1 were split previously, arg #2 is byref struct ---
; The second run of the pass must flatten arg #2 into three new parameters.
;
define amdgpu_kernel void @test_resplit(
; CHECK-LABEL: define amdgpu_kernel void @test_resplit(
; CHECK-SAME: i32 "amdgpu-original-arg"="1:0" [[A_I:%.*]], i64 "amdgpu-original-arg"="1:8" [[A_L:%.*]], i8 "amdgpu-original-arg"="2:12" [[B_A1_C:%.*]], i8 "amdgpu-original-arg"="2:44" [[B_A2_C:%.*]], ptr addrspace(1) noundef "amdgpu-original-arg"="3:0" [[DST:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[A_I_ZEXT:%.*]] = zext i32 [[A_I]] to i64
; CHECK-NEXT:    [[B_A1_C_SEXT:%.*]] = sext i8 [[B_A1_C]] to i64
; CHECK-NEXT:    [[B_A2_C_SEXT:%.*]] = sext i8 [[B_A2_C]] to i64
; CHECK-NEXT:    [[SUM1:%.*]] = add i64 [[A_I_ZEXT]], [[A_L]]
; CHECK-NEXT:    [[SUM2:%.*]] = add i64 [[SUM1]], [[B_A1_C_SEXT]]
; CHECK-NEXT:    [[SUM3:%.*]] = add i64 [[SUM2]], [[B_A2_C_SEXT]]
; CHECK-NEXT:    [[TRUNC:%.*]] = trunc i64 [[SUM3]] to i32
; CHECK-NEXT:    store i32 [[TRUNC]], ptr addrspace(1) [[DST]], align 4
; CHECK-NEXT:    ret void
;
  i32 "amdgpu-original-arg"="1:0"  %a.i,          ; piece of original arg #1
  i64 "amdgpu-original-arg"="1:8"  %a.l,          ; piece of original arg #1
  ptr addrspace(4) noundef readonly
  byref(%struct.B) align 8 %b,               ; original arg #2 (to split)
  ptr addrspace(1) noundef %dst) {               ; ordinary output pointer
entry:
  ; load b.a1.c  (offset 12)
  %b.a1.c.addr = getelementptr inbounds i8, ptr addrspace(4) %b, i64 12
  %b.a1.c      = load i8, ptr addrspace(4) %b.a1.c.addr, align 4

  ; load b.a2.c  (offset 44)
  %b.a2.c.addr = getelementptr inbounds i8, ptr addrspace(4) %b, i64 44
  %b.a2.c      = load i8, ptr addrspace(4) %b.a2.c.addr, align 4

  ; sum up and store to the separate dst pointer
  %a.i.zext      = zext i32 %a.i to i64
  %b.a1.c.sext   = sext i8  %b.a1.c to i64
  %b.a2.c.sext   = sext i8  %b.a2.c to i64
  %sum1          = add i64 %a.i.zext, %a.l
  %sum2          = add i64 %sum1, %b.a1.c.sext
  %sum3          = add i64 %sum2, %b.a2.c.sext
  %sum.trunc     = trunc i64 %sum3 to i32
  store i32 %sum.trunc, ptr addrspace(1) %dst, align 4
  ret void
}

; --- Additional test cases for passthrough logic ---

; Test case for a struct argument that is never used.
; Should not be split.
define amdgpu_kernel void @test_unused_arg(ptr addrspace(4) byref(%struct.A) %unused_arg) {
; CHECK-LABEL: define amdgpu_kernel void @test_unused_arg(
; CHECK-SAME: ptr addrspace(4) byref([[STRUCT_A:%.*]]) [[UNUSED_ARG:%.*]]) {
; CHECK-NEXT:    ret void
;
  ret void
}

; Test case for a pointer argument that does not have the 'byref' attribute.
; Should not be split.
define amdgpu_kernel void @test_no_byref_arg(ptr %ptr) {
; CHECK-LABEL: define amdgpu_kernel void @test_no_byref_arg(
; CHECK-SAME: ptr [[PTR:%.*]]) {
; CHECK-NEXT:    [[VAL:%.*]] = load i32, ptr [[PTR]], align 4
; CHECK-NEXT:    ret void
;
  %val = load i32, ptr %ptr, align 4
  ret void
}

; Test case for a 'byref' argument that points to a non-struct type.
; Should not be split.
define amdgpu_kernel void @test_byref_non_struct_arg(ptr byref(i32) %ptr) {
; CHECK-LABEL: define amdgpu_kernel void @test_byref_non_struct_arg(
; CHECK-SAME: ptr byref(i32) [[PTR:%.*]]) {
; CHECK-NEXT:    [[VAL:%.*]] = load i32, ptr [[PTR]], align 4
; CHECK-NEXT:    ret void
;
  %val = load i32, ptr %ptr, align 4
  ret void
}

; Test case for an argument that is used by an unsupported instruction (a store).
; Should not be split.
define amdgpu_kernel void @test_unsupported_user(ptr byref(%struct.A) %a) {
; CHECK-LABEL: define amdgpu_kernel void @test_unsupported_user(
; CHECK-SAME: ptr byref([[STRUCT_A:%.*]]) [[A:%.*]]) {
; CHECK-NEXT:    store ptr null, ptr [[A]], align 8
; CHECK-NEXT:    ret void
;
  store ptr null, ptr %a, align 8
  ret void
}

; Test case for a load from a GEP with a variable, non-constant offset.
; Should not be split.
define amdgpu_kernel void @test_variable_offset(ptr byref(%struct.A) %a, i32 %idx) {
  ; GEP into the 'p' field (a ptr) with a variable index.
; CHECK-LABEL: define amdgpu_kernel void @test_variable_offset(
; CHECK-SAME: ptr byref([[STRUCT_A:%.*]]) [[A:%.*]], i32 [[IDX:%.*]]) {
; CHECK-NEXT:    [[P_FIELD_PTR:%.*]] = getelementptr inbounds [[STRUCT_A]], ptr [[A]], i32 [[IDX]]
; CHECK-NEXT:    [[P_FIELD_VAL:%.*]] = load ptr, ptr [[P_FIELD_PTR]], align 8
; CHECK-NEXT:    ret void
;
  %p_field_ptr = getelementptr inbounds %struct.A, ptr %a, i32 %idx
  %p_field_val = load ptr, ptr %p_field_ptr, align 8
  ret void
}

; GCN:   - .address_space:  global
; GCN-NEXT:     .name:           out
; GCN-NEXT:     .offset:         0
; GCN-NEXT:     .size:           8
; GCN-NEXT:     .value_kind:     global_buffer
; GCN-NEXT:   - .name:           i
; GCN-NEXT:     .offset:         8
; GCN-NEXT:     .size:           4
; GCN-NEXT:     .value_kind:     by_value
; GCN-NEXT:   - .name:           a.l
; GCN-NEXT:     .offset:         16
; GCN-NEXT:     .original_arg_index: 2
; GCN-NEXT:     .original_arg_offset: 8
; GCN-NEXT:     .size:           8
; GCN-NEXT:     .value_kind:     by_value
; GCN-NEXT:   - .name:           c
; GCN-NEXT:     .offset:         24
; GCN-NEXT:     .size:           1
; GCN-NEXT:     .value_kind:     by_value
; GCN-NEXT:   - .name:           b.a1.c
; GCN-NEXT:     .offset:         25
; GCN-NEXT:     .original_arg_index: 4
; GCN-NEXT:     .original_arg_offset: 12
; GCN-NEXT:     .size:           1
; GCN-NEXT:     .value_kind:     by_value
; GCN-NEXT:   - .name:           b.a2.c
; GCN-NEXT:     .offset:         26
; GCN-NEXT:     .original_arg_index: 4
; GCN-NEXT:     .original_arg_offset: 44
; GCN-NEXT:     .size:           1
; GCN-NEXT:     .value_kind:     by_value
; GCN-NEXT:   - .address_space:  generic
; GCN-NEXT:     .name:           b.a2.p
; GCN-NEXT:     .offset:         32
; GCN-NEXT:     .original_arg_index: 4
; GCN-NEXT:     .original_arg_offset: 56
; GCN-NEXT:     .size:           8
; GCN-NEXT:     .value_kind:     global_buffer
