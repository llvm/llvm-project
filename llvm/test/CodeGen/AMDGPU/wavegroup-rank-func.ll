; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn-- -mcpu=gfx1300 -stop-after=finalize-isel -o - %s | FileCheck %s
target datalayout = "A5"

@weights = external local_unnamed_addr addrspace(10) global <9 x i32>, align 64
@col_center = external local_unnamed_addr addrspace(10) global <3 x i32>, align 16
@col_left = external local_unnamed_addr addrspace(10) global <3 x i32>, align 16
@col_right = external local_unnamed_addr addrspace(10) global <3 x i32>, align 16
@out = external local_unnamed_addr addrspace(10) global <8 x i16>, align 16

@sem1 = internal addrspace(3) global target("amdgcn.semaphore", 1) poison
@sem2 = internal addrspace(3) global target("amdgcn.semaphore", 2) poison

define private amdgpu_kernel void @input(ptr addrspace(1) %inbuf, ptr addrspace(1) %wbuf, ptr addrspace(1) %outbuf) "amdgpu-wavegroup-enable" "amdgpu-wavegroup-rank-function" {
  ; CHECK-LABEL: name: input
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   liveins: $sgpr4_sgpr5
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:sgpr_64(p4) = COPY $sgpr4_sgpr5
  ; CHECK-NEXT:   [[S_LOAD_DWORDX4_IMM:%[0-9]+]]:sgpr_128 = S_LOAD_DWORDX4_IMM [[COPY]](p4), 36, 0 :: (dereferenceable invariant load (s128) from %ir.inbuf.kernarg.offset, align 4, addrspace 4)
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub1
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub0
  ; CHECK-NEXT:   [[REG_SEQUENCE:%[0-9]+]]:sreg_64 = REG_SEQUENCE killed [[COPY2]], %subreg.sub0, killed [[COPY1]], %subreg.sub1
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub3
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX4_IMM]].sub2
  ; CHECK-NEXT:   [[REG_SEQUENCE1:%[0-9]+]]:sreg_64 = REG_SEQUENCE killed [[COPY4]], %subreg.sub0, killed [[COPY3]], %subreg.sub1
  ; CHECK-NEXT:   [[S_LOAD_DWORDX3_IMM:%[0-9]+]]:sgpr_96 = S_LOAD_DWORDX3_IMM [[REG_SEQUENCE]], 0, 0 :: ("amdgpu-noclobber" load (s96) from %ir.1, align 16, addrspace 1)
  ; CHECK-NEXT:   [[S_LOAD_DWORDX3_IMM1:%[0-9]+]]:sgpr_96 = S_LOAD_DWORDX3_IMM [[REG_SEQUENCE]], 256, 0 :: ("amdgpu-noclobber" load (s96) from %ir.ld.p1, align 16, addrspace 1)
  ; CHECK-NEXT:   [[S_LOAD_DWORDX3_IMM2:%[0-9]+]]:sgpr_96 = S_LOAD_DWORDX3_IMM [[REG_SEQUENCE]], 512, 0 :: ("amdgpu-noclobber" load (s96) from %ir.ld.p2, align 16, addrspace 1)
  ; CHECK-NEXT:   [[S_LOAD_DWORDX8_IMM:%[0-9]+]]:sgpr_256 = S_LOAD_DWORDX8_IMM [[REG_SEQUENCE1]], 0, 0 :: ("amdgpu-noclobber" load (s256) from %ir.2, align 64, addrspace 1)
  ; CHECK-NEXT:   [[S_LOAD_DWORD_IMM:%[0-9]+]]:sreg_32_xm0_xexec = S_LOAD_DWORD_IMM [[REG_SEQUENCE1]], 32, 0 :: ("amdgpu-noclobber" load (s32) from %ir.2 + 32, align 32, addrspace 1)
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX8_IMM]].sub7
  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX8_IMM]].sub6
  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX8_IMM]].sub5
  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX8_IMM]].sub4
  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX8_IMM]].sub3
  ; CHECK-NEXT:   [[COPY10:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX8_IMM]].sub2
  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX8_IMM]].sub1
  ; CHECK-NEXT:   [[COPY12:%[0-9]+]]:sreg_32 = COPY [[S_LOAD_DWORDX8_IMM]].sub0
  ; CHECK-NEXT:   [[COPY13:%[0-9]+]]:vgpr_32 = COPY killed [[COPY12]]
  ; CHECK-NEXT:   [[COPY14:%[0-9]+]]:vgpr_32 = COPY killed [[COPY11]]
  ; CHECK-NEXT:   [[COPY15:%[0-9]+]]:vgpr_32 = COPY killed [[COPY10]]
  ; CHECK-NEXT:   [[COPY16:%[0-9]+]]:vgpr_32 = COPY killed [[COPY9]]
  ; CHECK-NEXT:   [[COPY17:%[0-9]+]]:vgpr_32 = COPY killed [[COPY8]]
  ; CHECK-NEXT:   [[COPY18:%[0-9]+]]:vgpr_32 = COPY killed [[COPY7]]
  ; CHECK-NEXT:   [[COPY19:%[0-9]+]]:vgpr_32 = COPY killed [[COPY6]]
  ; CHECK-NEXT:   [[COPY20:%[0-9]+]]:vgpr_32 = COPY killed [[COPY5]]
  ; CHECK-NEXT:   [[COPY21:%[0-9]+]]:vgpr_32 = COPY killed [[S_LOAD_DWORD_IMM]]
  ; CHECK-NEXT:   [[REG_SEQUENCE2:%[0-9]+]]:av_288_align2 = REG_SEQUENCE killed [[COPY13]], %subreg.sub0, killed [[COPY14]], %subreg.sub1, killed [[COPY15]], %subreg.sub2, killed [[COPY16]], %subreg.sub3, killed [[COPY17]], %subreg.sub4, killed [[COPY18]], %subreg.sub5, killed [[COPY19]], %subreg.sub6, killed [[COPY20]], %subreg.sub7, killed [[COPY21]], %subreg.sub8
  ; CHECK-NEXT:   [[S_MOV_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 96
  ; CHECK-NEXT:   [[COPY22:%[0-9]+]]:vreg_96_align2 = COPY [[S_LOAD_DWORDX3_IMM]]
  ; CHECK-NEXT:   [[S_LSHR_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   V_STORE_IDX [[COPY22]], [[S_LSHR_B32_]], 0, implicit $exec :: (store (s96) into @col_center, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 80
  ; CHECK-NEXT:   [[COPY23:%[0-9]+]]:vreg_96_align2 = COPY [[S_LOAD_DWORDX3_IMM1]]
  ; CHECK-NEXT:   [[S_LSHR_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_1]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   V_STORE_IDX [[COPY23]], [[S_LSHR_B32_1]], 0, implicit $exec :: (store (s96) into @col_left, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 64
  ; CHECK-NEXT:   [[COPY24:%[0-9]+]]:vreg_96_align2 = COPY [[S_LOAD_DWORDX3_IMM2]]
  ; CHECK-NEXT:   [[S_LSHR_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_2]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   V_STORE_IDX [[COPY24]], [[S_LSHR_B32_2]], 0, implicit $exec :: (store (s96) into @col_right, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 0
  ; CHECK-NEXT:   [[S_LSHR_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_3]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   V_STORE_IDX [[REG_SEQUENCE2]], [[S_LSHR_B32_3]], 0, implicit $exec :: (store (s288) into @weights, align 64, addrspace 10)
  ; CHECK-NEXT:   S_SEMA_SIGNAL 17
  ; CHECK-NEXT:   S_ENDPGM 0
entry:
  %vec30 = load <3 x i32>, ptr addrspace(1) %inbuf, align 16
  %ld.p1 = getelementptr <3 x i32>, ptr addrspace(1) %inbuf, i64 16
  %vec31 = load <3 x i32>, ptr addrspace(1) %ld.p1, align 16
  %ld.p2 = getelementptr <3 x i32>, ptr addrspace(1) %inbuf, i64 32
  %vec32 = load <3 x i32>, ptr addrspace(1) %ld.p2, align 16
  %wei = load <9 x i32>, ptr addrspace(1) %wbuf, align 64

  store <3 x i32> %vec30, ptr addrspace(10) @col_center, align 16
  store <3 x i32> %vec31, ptr addrspace(10) @col_left, align 16
  store <3 x i32> %vec32, ptr addrspace(10) @col_right, align 16
  store <9 x i32> %wei, ptr addrspace(10) @weights, align 64
  call void @llvm.amdgcn.s.sema.signal(ptr addrspace(3) @sem1)
  ret void
}

define private amdgpu_kernel void @compute(ptr addrspace(1) %inbuf, ptr addrspace(1) %wbuf, ptr addrspace(1) %outbuf) "amdgpu-wavegroup-enable" "amdgpu-wavegroup-rank-function" {
  ; CHECK-LABEL: name: compute
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   S_SEMA_WAIT 1
  ; CHECK-NEXT:   [[S_MOV_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 112
  ; CHECK-NEXT:   [[S_LSHR_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   [[V_LOAD_IDX:%[0-9]+]]:vreg_96_align2 = V_LOAD_IDX [[S_LSHR_B32_]], 0, implicit $exec :: (dereferenceable load (s96) from @col_center, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 96
  ; CHECK-NEXT:   [[S_LSHR_B32_1:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_1]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   [[V_LOAD_IDX1:%[0-9]+]]:vreg_96_align2 = V_LOAD_IDX [[S_LSHR_B32_1]], 0, implicit $exec :: (dereferenceable load (s96) from @col_left, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 80
  ; CHECK-NEXT:   [[S_LSHR_B32_2:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_2]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   [[V_LOAD_IDX2:%[0-9]+]]:vreg_96_align2 = V_LOAD_IDX [[S_LSHR_B32_2]], 0, implicit $exec :: (dereferenceable load (s96) from @col_right, align 16, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 16
  ; CHECK-NEXT:   [[S_LSHR_B32_3:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_3]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   [[V_LOAD_IDX3:%[0-9]+]]:vreg_288_align2 = V_LOAD_IDX [[S_LSHR_B32_3]], 0, implicit $exec :: (dereferenceable load (s288) from @weights, align 64, addrspace 10)
  ; CHECK-NEXT:   [[S_MOV_B32_4:%[0-9]+]]:sreg_32 = S_MOV_B32 0
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_4]]
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_4]]
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_4]]
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_4]]
  ; CHECK-NEXT:   [[REG_SEQUENCE:%[0-9]+]]:vreg_128_align2 = REG_SEQUENCE [[COPY]], %subreg.sub0, [[COPY1]], %subreg.sub1, [[COPY2]], %subreg.sub2, [[COPY3]], %subreg.sub3
  ; CHECK-NEXT:   [[V_CONVOLVE_F16_FP8_FP8_3x3_4x4_:%[0-9]+]]:vreg_128_align2 = contract V_CONVOLVE_F16_FP8_FP8_3x3_4x4 killed [[REG_SEQUENCE]], killed [[V_LOAD_IDX3]], killed [[V_LOAD_IDX]], killed [[V_LOAD_IDX1]], killed [[V_LOAD_IDX2]], 42, -1, 0, 0, implicit $exec
  ; CHECK-NEXT:   [[S_MOV_B32_5:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 0
  ; CHECK-NEXT:   [[S_LSHR_B32_4:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_5]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   V_STORE_IDX [[V_CONVOLVE_F16_FP8_FP8_3x3_4x4_]], [[S_LSHR_B32_4]], 0, implicit $exec :: (store (s128) into @out, !tbaa !1, addrspace 10)
  ; CHECK-NEXT:   S_SEMA_SIGNAL 33
  ; CHECK-NEXT:   S_ENDPGM 0
entry:
  call void @llvm.amdgcn.s.sema.wait(ptr addrspace(3) @sem1)
  %vec30 = load <3 x i32>, ptr addrspace(10) @col_center, align 16
  %vec31 = load <3 x i32>, ptr addrspace(10) @col_left, align 16
  %vec32 = load <3 x i32>, ptr addrspace(10) @col_right, align 16
  %wei = load <9 x i32>, ptr addrspace(10) @weights, align 64
  %0 = tail call contract <8 x half> @llvm.amdgcn.convolve.f16.fp8.fp8.3x3.v8f16.v8f16.v9i32.v3i32(<8 x half> zeroinitializer, <9 x i32> %wei, <3 x i32> %vec30, <3 x i32> %vec31, <3 x i32> %vec32, i32 42, i1 true)
  store <8 x half> %0, ptr addrspace(10) @out, align 16, !tbaa !4
  call void @llvm.amdgcn.s.sema.signal(ptr addrspace(3) @sem2)
  ret void
}

define private amdgpu_kernel void @output(ptr addrspace(1) %inbuf, ptr addrspace(1) %wbuf, ptr addrspace(1) %outbuf) "amdgpu-wavegroup-enable" "amdgpu-wavegroup-rank-function" {
  ; CHECK-LABEL: name: output
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   liveins: $sgpr4_sgpr5
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:sgpr_64(p4) = COPY $sgpr4_sgpr5
  ; CHECK-NEXT:   [[S_LOAD_DWORDX2_IMM:%[0-9]+]]:sreg_64_xexec_xnull = S_LOAD_DWORDX2_IMM [[COPY]](p4), 52, 0 :: (dereferenceable invariant load (s64) from %ir.outbuf.kernarg.offset, align 4, addrspace 4)
  ; CHECK-NEXT:   [[V_MOV_B32_e32_:%[0-9]+]]:vgpr_32 = V_MOV_B32_e32 0, implicit $exec
  ; CHECK-NEXT:   S_SEMA_WAIT 1
  ; CHECK-NEXT:   [[S_MOV_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_MOV_B32 0
  ; CHECK-NEXT:   [[S_LSHR_B32_:%[0-9]+]]:sreg_32_xexec_hi = S_LSHR_B32 [[S_MOV_B32_]], 2, implicit-def dead $scc
  ; CHECK-NEXT:   [[V_LOAD_IDX:%[0-9]+]]:vreg_128_align2 = V_LOAD_IDX [[S_LSHR_B32_]], 0, implicit $exec :: (dereferenceable load (s128) from @out, addrspace 10)
  ; CHECK-NEXT:   GLOBAL_STORE_DWORDX4_SADDR killed [[V_MOV_B32_e32_]], killed [[V_LOAD_IDX]], killed [[S_LOAD_DWORDX2_IMM]], 0, 0, implicit $exec :: (store (s128) into %ir.outbuf.load, addrspace 1)
  ; CHECK-NEXT:   S_ENDPGM 0
entry:
  call void @llvm.amdgcn.s.sema.wait(ptr addrspace(3) @sem2)
  %0 = load <8 x half>, ptr addrspace(10) @out, align 16
  store <8 x half> %0, ptr addrspace(1) %outbuf, align 16
  ret void
}

; Function Attrs: convergent mustprogress nofree norecurse nosync nounwind memory(readwrite, argmem: none, inaccessiblemem: none)
define amdgpu_kernel void @main(ptr addrspace(1) %inbuf, ptr addrspace(1) %wbuf, ptr addrspace(1) %outbuf) "amdgpu-wavegroup-enable" !reqd_work_group_size !{i32 32, i32 12, i32 1} {
  ; CHECK-LABEL: name: main
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.1(0x40000000), %bb.2(0x40000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[SI_PC_ADD_REL_OFFSET64_:%[0-9]+]]:sreg_64 = SI_PC_ADD_REL_OFFSET64 target-flags(amdgpu-rel64) @input
  ; CHECK-NEXT:   [[S_GETREG_B32_const:%[0-9]+]]:sgpr_32 = S_GETREG_B32_const 7195
  ; CHECK-NEXT:   S_CMP_EQ_U32 [[S_GETREG_B32_const]], 0, implicit-def $scc
  ; CHECK-NEXT:   S_CBRANCH_SCC0 %bb.1, implicit $scc
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2:
  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   S_SETPC_B64 [[SI_PC_ADD_REL_OFFSET64_]]
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1.entry:
  ; CHECK-NEXT:   successors: %bb.3(0x40000000), %bb.4(0x40000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   $idx0 = S_ADD_GPR_IDX_U32 target-index(amdgpu-num-vgprs-rank0), $idx0
  ; CHECK-NEXT:   [[SI_PC_ADD_REL_OFFSET64_1:%[0-9]+]]:sreg_64 = SI_PC_ADD_REL_OFFSET64 target-flags(amdgpu-rel64) @compute
  ; CHECK-NEXT:   [[S_GETREG_B32_const1:%[0-9]+]]:sgpr_32 = S_GETREG_B32_const 7195
  ; CHECK-NEXT:   S_CMP_EQ_U32 [[S_GETREG_B32_const1]], 1, implicit-def $scc
  ; CHECK-NEXT:   S_CBRANCH_SCC0 %bb.3, implicit $scc
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.4:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   S_SETPC_B64 [[SI_PC_ADD_REL_OFFSET64_1]]
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.entry:
  ; CHECK-NEXT:   successors: %bb.5(0x40000000), %bb.6(0x40000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   $idx0 = S_ADD_GPR_IDX_U32 target-index(amdgpu-num-vgprs-rank1), $idx0
  ; CHECK-NEXT:   [[SI_PC_ADD_REL_OFFSET64_2:%[0-9]+]]:sreg_64 = SI_PC_ADD_REL_OFFSET64 target-flags(amdgpu-rel64) @output
  ; CHECK-NEXT:   [[S_GETREG_B32_const2:%[0-9]+]]:sgpr_32 = S_GETREG_B32_const 7195
  ; CHECK-NEXT:   S_CMP_EQ_U32 [[S_GETREG_B32_const2]], 2, implicit-def $scc
  ; CHECK-NEXT:   S_CBRANCH_SCC0 %bb.5, implicit $scc
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.6:
  ; CHECK-NEXT:   successors: %bb.5(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   S_SETPC_B64 [[SI_PC_ADD_REL_OFFSET64_2]]
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.5.entry:
  ; CHECK-NEXT:   $idx0 = S_ADD_GPR_IDX_U32 target-index(amdgpu-num-vgprs-rank2), $idx0
  ; CHECK-NEXT:   S_ENDPGM 0
entry:
  call void @llvm.amdgcn.wavegroup.rank(i32 0, ptr @input)
  call void @llvm.amdgcn.wavegroup.rank(i32 1, ptr @compute)
  call void @llvm.amdgcn.wavegroup.rank(i32 2, ptr @output)
  ret void
}

; Function Attrs: convergent mustprogress nocallback nofree nosync nounwind willreturn memory(none)
declare <8 x half> @llvm.amdgcn.convolve.f16.fp8.fp8.3x3.v8f16.v8f16.v9i32.v3i32(<8 x half>, <9 x i32>, <3 x i32>, <3 x i32>, <3 x i32>, i32 immarg, i1 immarg) #1

!4 = !{!5, !5, i64 0}
!5 = !{!"omnipotent char", !6, i64 0}
!6 = !{!"Simple C++ TBAA"}

