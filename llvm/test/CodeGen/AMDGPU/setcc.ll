; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn-- -verify-machineinstrs < %s | FileCheck -allow-deprecated-dag-overlap -check-prefix=GCN -check-prefix=FUNC %s
; RUN: llc -mtriple=r600-- -mcpu=redwood -verify-machineinstrs < %s | FileCheck -allow-deprecated-dag-overlap -check-prefix=R600 -check-prefix=FUNC %s

declare i32 @llvm.amdgcn.workitem.id.x() nounwind readnone

; FUNC-LABEL: {{^}}setcc_v2i32:
; R600-DAG: SETE_INT * T{{[0-9]+\.[XYZW]}}, KC0[3].X, KC0[3].Z
; R600-DAG: SETE_INT * T{{[0-9]+\.[XYZW]}}, KC0[2].W, KC0[3].Y

; GCN: s_cmp_eq_u32
; GCN: s_cmp_eq_u32
define amdgpu_kernel void @setcc_v2i32(ptr addrspace(1) %out, <2 x i32> %a, <2 x i32> %b) #0 {
; GCN-LABEL: setcc_v2i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_cmp_eq_u32 s4, s6
; GCN-NEXT:    s_cselect_b64 s[8:9], -1, 0
; GCN-NEXT:    s_cmp_eq_u32 s5, s7
; GCN-NEXT:    s_cselect_b64 s[4:5], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v1, 0, -1, s[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[8:9]
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[0:3], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: setcc_v2i32:
; R600:       ; %bb.0:
; R600-NEXT:    ALU 3, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.XY, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETE_INT * T0.Y, KC0[3].X, KC0[3].Z,
; R600-NEXT:     SETE_INT * T0.X, KC0[2].W, KC0[3].Y,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
  %result = icmp eq <2 x i32> %a, %b
  %sext = sext <2 x i1> %result to <2 x i32>
  store <2 x i32> %sext, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}setcc_v4i32:
; R600-DAG: SETE_INT * T{{[0-9]+\.[XYZW], T[0-9]+\.[XYZW], T[0-9]+\.[XYZW]}}
; R600-DAG: SETE_INT * T{{[0-9]+\.[XYZW], T[0-9]+\.[XYZW], T[0-9]+\.[XYZW]}}
; R600-DAG: SETE_INT * T{{[0-9]+\.[XYZW], T[0-9]+\.[XYZW], T[0-9]+\.[XYZW]}}
; R600-DAG: SETE_INT * T{{[0-9]+\.[XYZW], T[0-9]+\.[XYZW], T[0-9]+\.[XYZW]}}

; GCN: s_cmp_eq_u32
; GCN: s_cmp_eq_u32
; GCN: s_cmp_eq_u32
; GCN: s_cmp_eq_u32
define amdgpu_kernel void @setcc_v4i32(ptr addrspace(1) %out, ptr addrspace(1) %in) #0 {
; GCN-LABEL: setcc_v4i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x9
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dwordx8 s[0:7], s[10:11], 0x0
; GCN-NEXT:    s_mov_b32 s11, 0xf000
; GCN-NEXT:    s_mov_b32 s10, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_cmp_eq_u32 s0, s4
; GCN-NEXT:    s_cselect_b64 s[12:13], -1, 0
; GCN-NEXT:    s_cmp_eq_u32 s1, s5
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    s_cmp_eq_u32 s2, s6
; GCN-NEXT:    v_cndmask_b32_e64 v1, 0, -1, s[0:1]
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    s_cmp_eq_u32 s3, s7
; GCN-NEXT:    v_cndmask_b32_e64 v2, 0, -1, s[0:1]
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v3, 0, -1, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[12:13]
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[8:11], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: setcc_v4i32:
; R600:       ; %bb.0:
; R600-NEXT:    ALU 0, @10, KC0[CB0:0-32], KC1[]
; R600-NEXT:    TEX 1 @6
; R600-NEXT:    ALU 5, @11, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.XYZW, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    Fetch clause starting at 6:
; R600-NEXT:     VTX_READ_128 T1.XYZW, T0.X, 16, #1
; R600-NEXT:     VTX_READ_128 T0.XYZW, T0.X, 0, #1
; R600-NEXT:    ALU clause starting at 10:
; R600-NEXT:     MOV * T0.X, KC0[2].Z,
; R600-NEXT:    ALU clause starting at 11:
; R600-NEXT:     SETE_INT * T0.W, T0.W, T1.W,
; R600-NEXT:     SETE_INT * T0.Z, T0.Z, T1.Z,
; R600-NEXT:     SETE_INT * T0.Y, T0.Y, T1.Y,
; R600-NEXT:     SETE_INT T0.X, T0.X, T1.X,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
  %b_ptr = getelementptr <4 x i32>, ptr addrspace(1) %in, i32 1
  %a = load <4 x i32>, ptr addrspace(1) %in
  %b = load <4 x i32>, ptr addrspace(1) %b_ptr
  %result = icmp eq <4 x i32> %a, %b
  %sext = sext <4 x i1> %result to <4 x i32>
  store <4 x i32> %sext, ptr addrspace(1) %out
  ret void
}

;;;==========================================================================;;;
;; Float comparisons
;;;==========================================================================;;;

; FUNC-LABEL: {{^}}f32_oeq:
; R600: SETE_DX10
; GCN: v_cmp_eq_f32
define amdgpu_kernel void @f32_oeq(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_oeq:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_eq_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_oeq:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETE_DX10 * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp oeq float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_ogt:
; R600: SETGT_DX10
; GCN: v_cmp_gt_f32
define amdgpu_kernel void @f32_ogt(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_ogt:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_gt_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_ogt:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGT_DX10 * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp ogt float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_oge:
; R600: SETGE_DX10
; GCN: v_cmp_ge_f32
define amdgpu_kernel void @f32_oge(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_oge:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_oge:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGE_DX10 * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp oge float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_olt:
; R600: SETGT_DX10
; GCN: v_cmp_lt_f32
define amdgpu_kernel void @f32_olt(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_olt:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_olt:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGT_DX10 * T1.X, KC0[2].W, KC0[2].Z,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp olt float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_ole:
; R600: SETGE_DX10
; GCN: v_cmp_le_f32
define amdgpu_kernel void @f32_ole(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_ole:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_le_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_ole:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGE_DX10 * T1.X, KC0[2].W, KC0[2].Z,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp ole float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_one:
; R600-DAG: SETGT_DX10
; R600-DAG: SETGT_DX10
; R600-DAG: OR_INT
; R600-DAG: SETNE_INT

; GCN: v_cmp_lg_f32_e32 vcc
; GCN-NEXT: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1, vcc
define amdgpu_kernel void @f32_one(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_one:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_lg_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_one:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 5, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.X, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETGT_DX10 T0.W, KC0[2].Z, KC0[2].W,
; R600-NEXT:     SETGT_DX10 * T1.W, KC0[2].W, KC0[2].Z,
; R600-NEXT:     OR_INT * T0.W, PV.W, PS,
; R600-NEXT:     SETNE_INT T0.X, PV.W, 0.0,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp one float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_ord:
; R600-DAG: SETE_DX10
; R600-DAG: SETE_DX10
; R600-DAG: AND_INT
; R600-DAG: SETNE_INT
; GCN: v_cmp_o_f32
define amdgpu_kernel void @f32_ord(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_ord:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_o_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_ord:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 5, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.X, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETE_DX10 T0.W, KC0[2].Z, KC0[2].Z,
; R600-NEXT:     SETE_DX10 * T1.W, KC0[2].W, KC0[2].W,
; R600-NEXT:     AND_INT * T0.W, PV.W, PS,
; R600-NEXT:     SETNE_INT T0.X, PV.W, 0.0,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp ord float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_ueq:
; R600-DAG: SETGT_DX10
; R600-DAG: SETGT_DX10
; R600-DAG: OR_INT
; R600-DAG: SETE_INT

; GCN: v_cmp_nlg_f32_e32 vcc
; GCN-NEXT: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1, vcc
define amdgpu_kernel void @f32_ueq(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_ueq:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_nlg_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_ueq:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 5, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.X, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETGT_DX10 T0.W, KC0[2].Z, KC0[2].W,
; R600-NEXT:     SETGT_DX10 * T1.W, KC0[2].W, KC0[2].Z,
; R600-NEXT:     OR_INT * T0.W, PV.W, PS,
; R600-NEXT:     SETE_INT T0.X, PV.W, 0.0,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp ueq float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_ugt:
; R600: SETGE
; R600: SETE_DX10
; GCN: v_cmp_nle_f32_e32 vcc
; GCN-NEXT: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1, vcc
define amdgpu_kernel void @f32_ugt(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_ugt:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_nle_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_ugt:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 3, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.X, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETGE * T0.W, KC0[2].W, KC0[2].Z,
; R600-NEXT:     SETE_DX10 T0.X, PV.W, 0.0,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp ugt float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_uge:
; R600: SETGT
; R600: SETE_DX10

; GCN: v_cmp_nlt_f32_e32 vcc
; GCN-NEXT: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1, vcc
define amdgpu_kernel void @f32_uge(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_uge:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_nlt_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_uge:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 3, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.X, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETGT * T0.W, KC0[2].W, KC0[2].Z,
; R600-NEXT:     SETE_DX10 T0.X, PV.W, 0.0,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp uge float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_ult:
; R600: SETGE
; R600: SETE_DX10

; GCN: v_cmp_nge_f32_e32 vcc
; GCN-NEXT: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1, vcc
define amdgpu_kernel void @f32_ult(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_ult:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_nge_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_ult:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 3, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.X, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETGE * T0.W, KC0[2].Z, KC0[2].W,
; R600-NEXT:     SETE_DX10 T0.X, PV.W, 0.0,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp ult float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_ule:
; R600: SETGT
; R600: SETE_DX10

; GCN: v_cmp_ngt_f32_e32 vcc
; GCN-NEXT: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1, vcc
define amdgpu_kernel void @f32_ule(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_ule:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_ngt_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_ule:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 3, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.X, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETGT * T0.W, KC0[2].Z, KC0[2].W,
; R600-NEXT:     SETE_DX10 T0.X, PV.W, 0.0,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp ule float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_une:
; R600: SETNE_DX10
; GCN: v_cmp_neq_f32
define amdgpu_kernel void @f32_une(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_une:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_neq_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_une:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETNE_DX10 * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp une float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}f32_uno:
; R600: SETNE_DX10
; R600: SETNE_DX10
; R600: OR_INT
; R600: SETNE_INT
; GCN: v_cmp_u_f32
define amdgpu_kernel void @f32_uno(ptr addrspace(1) %out, float %a, float %b) #0 {
; GCN-LABEL: f32_uno:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s3
; GCN-NEXT:    v_cmp_u_f32_e32 vcc, s2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: f32_uno:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 5, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.X, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     SETNE_DX10 T0.W, KC0[2].Z, KC0[2].Z,
; R600-NEXT:     SETNE_DX10 * T1.W, KC0[2].W, KC0[2].W,
; R600-NEXT:     OR_INT * T0.W, PV.W, PS,
; R600-NEXT:     SETNE_INT T0.X, PV.W, 0.0,
; R600-NEXT:     LSHR * T1.X, KC0[2].Y, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = fcmp uno float %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

;;;==========================================================================;;;
;; 32-bit integer comparisons
;;;==========================================================================;;;

; FUNC-LABEL: {{^}}i32_eq:
; R600: SETE_INT
; GCN: s_cmp_eq_u32
define amdgpu_kernel void @i32_eq(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_eq:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_eq_u32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_eq:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETE_INT * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp eq i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_ne:
; R600: SETNE_INT
; GCN: s_cmp_lg_u32
define amdgpu_kernel void @i32_ne(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_ne:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_lg_u32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_ne:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETNE_INT * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp ne i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_ugt:
; R600: SETGT_UINT
; GCN: s_cmp_gt_u32
define amdgpu_kernel void @i32_ugt(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_ugt:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_gt_u32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_ugt:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGT_UINT * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp ugt i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_uge:
; R600: SETGE_UINT
; GCN: s_cmp_ge_u32
define amdgpu_kernel void @i32_uge(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_uge:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_ge_u32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_uge:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGE_UINT * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp uge i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_ult:
; R600: SETGT_UINT
; GCN: s_cmp_lt_u32
define amdgpu_kernel void @i32_ult(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_ult:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_lt_u32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_ult:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGT_UINT * T1.X, KC0[2].W, KC0[2].Z,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp ult i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_ule:
; R600: SETGE_UINT
; GCN: s_cmp_le_u32
define amdgpu_kernel void @i32_ule(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_ule:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_le_u32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_ule:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGE_UINT * T1.X, KC0[2].W, KC0[2].Z,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp ule i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_sgt:
; R600: SETGT_INT
; GCN: s_cmp_gt_i32
define amdgpu_kernel void @i32_sgt(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_sgt:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_gt_i32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_sgt:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGT_INT * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp sgt i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_sge:
; R600: SETGE_INT
; GCN: s_cmp_ge_i32
define amdgpu_kernel void @i32_sge(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_sge:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_ge_i32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_sge:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGE_INT * T1.X, KC0[2].Z, KC0[2].W,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp sge i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_slt:
; R600: SETGT_INT
; GCN: s_cmp_lt_i32
define amdgpu_kernel void @i32_slt(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_slt:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_lt_i32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_slt:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGT_INT * T1.X, KC0[2].W, KC0[2].Z,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp slt i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FUNC-LABEL: {{^}}i32_sle:
; R600: SETGE_INT
; GCN: s_cmp_le_i32
define amdgpu_kernel void @i32_sle(ptr addrspace(1) %out, i32 %a, i32 %b) #0 {
; GCN-LABEL: i32_sle:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s0
; GCN-NEXT:    s_mov_b32 s5, s1
; GCN-NEXT:    s_cmp_le_i32 s2, s3
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, s[0:1]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: i32_sle:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 2, @4, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.X, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    ALU clause starting at 4:
; R600-NEXT:     LSHR T0.X, KC0[2].Y, literal.x,
; R600-NEXT:     SETGE_INT * T1.X, KC0[2].W, KC0[2].Z,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
entry:
  %0 = icmp sle i32 %a, %b
  %1 = sext i1 %0 to i32
  store i32 %1, ptr addrspace(1) %out
  ret void
}

; FIXME: This does 4 compares
; FUNC-LABEL: {{^}}v3i32_eq:
; GCN-DAG: v_cmp_eq_u32
; GCN-DAG: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1,
; GCN-DAG: v_cmp_eq_u32
; GCN-DAG: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1,
; GCN-DAG: v_cmp_eq_u32
; GCN-DAG: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1,
; GCN: s_endpgm
define amdgpu_kernel void @v3i32_eq(ptr addrspace(1) %out, ptr addrspace(1) %ptra, ptr addrspace(1) %ptrb) #0 {
; GCN-LABEL: v3i32_eq:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s11, 0xf000
; GCN-NEXT:    s_mov_b32 s10, 0
; GCN-NEXT:    v_lshlrev_b32_e32 v7, 4, v0
; GCN-NEXT:    v_mov_b32_e32 v8, 0
; GCN-NEXT:    s_mov_b64 s[2:3], s[10:11]
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b64 s[8:9], s[6:7]
; GCN-NEXT:    buffer_load_dwordx4 v[0:3], v[7:8], s[8:11], 0 addr64
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    buffer_load_dwordx4 v[3:6], v[7:8], s[0:3], 0 addr64
; GCN-NEXT:    s_mov_b64 s[6:7], s[10:11]
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v4
; GCN-NEXT:    v_cndmask_b32_e64 v1, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, v2, v5
; GCN-NEXT:    v_cndmask_b32_e64 v2, 0, -1, vcc
; GCN-NEXT:    buffer_store_dword v2, v[7:8], s[4:7], 0 addr64 offset:8
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], v[7:8], s[4:7], 0 addr64
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: v3i32_eq:
; R600:       ; %bb.0:
; R600-NEXT:    ALU 3, @10, KC0[CB0:0-32], KC1[]
; R600-NEXT:    TEX 1 @6
; R600-NEXT:    ALU 9, @14, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T2.X, T3.X, 0
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.XY, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    Fetch clause starting at 6:
; R600-NEXT:     VTX_READ_128 T1.XYZW, T1.X, 0, #1
; R600-NEXT:     VTX_READ_128 T2.XYZW, T0.X, 0, #1
; R600-NEXT:    ALU clause starting at 10:
; R600-NEXT:     LSHL * T0.W, T0.X, literal.x,
; R600-NEXT:    4(5.605194e-45), 0(0.000000e+00)
; R600-NEXT:     ADD_INT T0.X, KC0[2].Z, PV.W,
; R600-NEXT:     ADD_INT * T1.X, KC0[2].W, PV.W,
; R600-NEXT:    ALU clause starting at 14:
; R600-NEXT:     SETE_INT * T0.Y, T2.Y, T1.Y,
; R600-NEXT:     SETE_INT T0.X, T2.X, T1.X,
; R600-NEXT:     ADD_INT * T0.W, KC0[2].Y, T0.W,
; R600-NEXT:     LSHR T1.X, PV.W, literal.x,
; R600-NEXT:     SETE_INT * T2.X, T2.Z, T1.Z,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
; R600-NEXT:     ADD_INT * T0.W, T0.W, literal.x,
; R600-NEXT:    8(1.121039e-44), 0(0.000000e+00)
; R600-NEXT:     LSHR * T3.X, PV.W, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
  %tid = call i32 @llvm.amdgcn.workitem.id.x() nounwind readnone
  %gep.a = getelementptr <3 x i32>, ptr addrspace(1) %ptra, i32 %tid
  %gep.b = getelementptr <3 x i32>, ptr addrspace(1) %ptrb, i32 %tid
  %gep.out = getelementptr <3 x i32>, ptr addrspace(1) %out, i32 %tid
  %a = load <3 x i32>, ptr addrspace(1) %gep.a
  %b = load <3 x i32>, ptr addrspace(1) %gep.b
  %cmp = icmp eq <3 x i32> %a, %b
  %ext = sext <3 x i1> %cmp to <3 x i32>
  store <3 x i32> %ext, ptr addrspace(1) %gep.out
  ret void
}

; FUNC-LABEL: {{^}}v3i8_eq:
; GCN-DAG: v_cmp_eq_u32
; GCN-DAG: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1,
; GCN-DAG: v_cmp_eq_u32
; GCN-DAG: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1,
; GCN-DAG: v_cmp_eq_u32
; GCN-DAG: v_cndmask_b32_e64 {{v[0-9]+}}, 0, -1,
; GCN: s_endpgm
define amdgpu_kernel void @v3i8_eq(ptr addrspace(1) %out, ptr addrspace(1) %ptra, ptr addrspace(1) %ptrb) #0 {
; GCN-LABEL: v3i8_eq:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s11, 0xf000
; GCN-NEXT:    s_mov_b32 s10, 0
; GCN-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
; GCN-NEXT:    v_mov_b32_e32 v1, 0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b64 s[8:9], s[6:7]
; GCN-NEXT:    buffer_load_dword v2, v[0:1], s[8:11], 0 addr64
; GCN-NEXT:    v_mov_b32_e32 v3, 0xff
; GCN-NEXT:    s_mov_b64 s[2:3], s[10:11]
; GCN-NEXT:    s_mov_b64 s[6:7], s[10:11]
; GCN-NEXT:    buffer_load_dword v4, v[0:1], s[0:3], 0 addr64
; GCN-NEXT:    s_waitcnt vmcnt(1)
; GCN-NEXT:    v_and_b32_e32 v5, 0xff, v2
; GCN-NEXT:    v_bfe_u32 v6, v2, 8, 8
; GCN-NEXT:    v_bfe_u32 v2, v2, 16, 8
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    v_and_b32_e32 v7, 0xff, v4
; GCN-NEXT:    v_bfe_u32 v8, v4, 8, 8
; GCN-NEXT:    v_bfe_u32 v4, v4, 16, 8
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, v5, v7
; GCN-NEXT:    v_cndmask_b32_e32 v5, 0, v3, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, v6, v8
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, v2, v4
; GCN-NEXT:    v_cndmask_b32_e32 v2, 0, v3, vcc
; GCN-NEXT:    v_lshlrev_b32_e32 v3, 8, v6
; GCN-NEXT:    v_or_b32_e32 v3, v5, v3
; GCN-NEXT:    buffer_store_byte v2, v[0:1], s[4:7], 0 addr64 offset:2
; GCN-NEXT:    buffer_store_short v3, v[0:1], s[4:7], 0 addr64
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: v3i8_eq:
; R600:       ; %bb.0:
; R600-NEXT:    ALU 3, @10, KC0[CB0:0-32], KC1[]
; R600-NEXT:    TEX 1 @6
; R600-NEXT:    ALU 41, @14, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT MSKOR T8.XW, T9.X
; R600-NEXT:    MEM_RAT MSKOR T7.XW, T0.X
; R600-NEXT:    CF_END
; R600-NEXT:    Fetch clause starting at 6:
; R600-NEXT:     VTX_READ_32 T7.X, T7.X, 0, #1
; R600-NEXT:     VTX_READ_32 T0.X, T0.X, 0, #1
; R600-NEXT:    ALU clause starting at 10:
; R600-NEXT:     LSHL * T0.W, T0.X, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
; R600-NEXT:     ADD_INT T0.X, KC0[2].W, PV.W,
; R600-NEXT:     ADD_INT * T7.X, KC0[2].Z, PV.W,
; R600-NEXT:    ALU clause starting at 14:
; R600-NEXT:     MOV * T1.W, literal.x,
; R600-NEXT:    8(1.121039e-44), 0(0.000000e+00)
; R600-NEXT:     AND_INT T0.Y, T0.X, literal.x,
; R600-NEXT:     BFE_UINT T0.Z, T0.X, literal.y, PV.W,
; R600-NEXT:     BFE_UINT T2.W, T7.X, literal.y, PV.W, BS:VEC_120/SCL_212
; R600-NEXT:     AND_INT * T3.W, T7.X, literal.x,
; R600-NEXT:    255(3.573311e-43), 8(1.121039e-44)
; R600-NEXT:     SETE_INT T2.W, PV.W, PV.Z,
; R600-NEXT:     SETE_INT * T3.W, PS, PV.Y,
; R600-NEXT:     AND_INT T0.Z, PS, literal.x,
; R600-NEXT:     LSHL T2.W, PV.W, literal.y,
; R600-NEXT:     ADD_INT * T0.W, KC0[2].Y, T0.W,
; R600-NEXT:    255(3.573311e-43), 8(1.121039e-44)
; R600-NEXT:     AND_INT T3.W, PS, literal.x,
; R600-NEXT:     OR_INT * T2.W, PV.Z, PV.W,
; R600-NEXT:    3(4.203895e-45), 0(0.000000e+00)
; R600-NEXT:     AND_INT T2.W, PS, literal.x,
; R600-NEXT:     LSHL * T3.W, PV.W, literal.y,
; R600-NEXT:    65535(9.183409e-41), 3(4.203895e-45)
; R600-NEXT:     LSHL T8.X, PV.W, PS,
; R600-NEXT:     LSHL * T8.W, literal.x, PS,
; R600-NEXT:    65535(9.183409e-41), 0(0.000000e+00)
; R600-NEXT:     MOV T8.Y, 0.0,
; R600-NEXT:     BFE_UINT T0.Z, T0.X, literal.x, T1.W, BS:VEC_021/SCL_122
; R600-NEXT:     BFE_UINT T1.W, T7.X, literal.x, T1.W, BS:VEC_120/SCL_212
; R600-NEXT:     ADD_INT * T2.W, T0.W, literal.y,
; R600-NEXT:    16(2.242078e-44), 2(2.802597e-45)
; R600-NEXT:     AND_INT T3.W, PS, literal.x,
; R600-NEXT:     SETE_INT * T1.W, PV.W, PV.Z,
; R600-NEXT:    3(4.203895e-45), 0(0.000000e+00)
; R600-NEXT:     AND_INT T1.W, PS, literal.x,
; R600-NEXT:     LSHL * T3.W, PV.W, literal.y,
; R600-NEXT:    255(3.573311e-43), 3(4.203895e-45)
; R600-NEXT:     LSHL T7.X, PV.W, PS,
; R600-NEXT:     LSHL * T7.W, literal.x, PS,
; R600-NEXT:    255(3.573311e-43), 0(0.000000e+00)
; R600-NEXT:     MOV T7.Y, 0.0,
; R600-NEXT:     MOV T8.Z, 0.0,
; R600-NEXT:     MOV * T7.Z, 0.0,
; R600-NEXT:     LSHR T0.X, T2.W, literal.x,
; R600-NEXT:     LSHR * T9.X, T0.W, literal.x,
; R600-NEXT:    2(2.802597e-45), 0(0.000000e+00)
  %tid = call i32 @llvm.amdgcn.workitem.id.x() nounwind readnone
  %gep.a = getelementptr <3 x i8>, ptr addrspace(1) %ptra, i32 %tid
  %gep.b = getelementptr <3 x i8>, ptr addrspace(1) %ptrb, i32 %tid
  %gep.out = getelementptr <3 x i8>, ptr addrspace(1) %out, i32 %tid
  %a = load <3 x i8>, ptr addrspace(1) %gep.a
  %b = load <3 x i8>, ptr addrspace(1) %gep.b
  %cmp = icmp eq <3 x i8> %a, %b
  %ext = sext <3 x i1> %cmp to <3 x i8>
  store <3 x i8> %ext, ptr addrspace(1) %gep.out
  ret void
}

; Make sure we don't try to emit i1 setcc ops
; FUNC-LABEL: setcc-i1
; GCN: s_bitcmp0_b32 s{{[0-9]+}}, 0
define amdgpu_kernel void @setcc-i1(i32 %in) #0 {
  %and = and i32 %in, 1
  %cmp = icmp eq i32 %and, 0
  br i1 %cmp, label %endif, label %if
if:
  unreachable
endif:
  ret void
}

; FUNC-LABEL: setcc-i1-and-xor
; GCN-DAG: v_cmp_nge_f32_e64 [[A:s\[[0-9]+:[0-9]+\]]], s{{[0-9]+}}, 0{{$}}
; GCN-DAG: v_cmp_nle_f32_e64 [[B:s\[[0-9]+:[0-9]+\]]], s{{[0-9]+}}, 1.0
; GCN: s_or_b64 s[2:3], [[A]], [[B]]
define amdgpu_kernel void @setcc-i1-and-xor(ptr addrspace(1) %out, float %cond) #0 {
bb0:
  %tmp5 = fcmp oge float %cond, 0.000000e+00
  %tmp7 = fcmp ole float %cond, 1.000000e+00
  %tmp9 = and i1 %tmp5, %tmp7
  %tmp11 = xor i1 %tmp9, 1
  br i1 %tmp11, label %bb2, label %bb1

bb1:
  store i32 0, ptr addrspace(1) %out
  br label %bb2

bb2:
  ret void
}

; FUNC-LABEL: setcc_v2i32_expand
; GCN: s_cmp_gt_i32
; GCN: s_cmp_gt_i32
define amdgpu_kernel void @setcc_v2i32_expand(
; GCN-LABEL: setcc_v2i32_expand:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx8 s[0:7], s[4:5], 0x9
; GCN-NEXT:    s_mov_b32 s11, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x0
; GCN-NEXT:    s_mov_b32 s10, -1
; GCN-NEXT:    s_mov_b32 s8, s6
; GCN-NEXT:    s_mov_b32 s9, s7
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[2:3], 0x0
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[4:5], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_cmp_gt_i32 s1, 1
; GCN-NEXT:    s_cselect_b64 s[6:7], -1, 0
; GCN-NEXT:    s_cmp_gt_i32 s0, 1
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, s[6:7]
; GCN-NEXT:    s_cselect_b64 s[0:1], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v1, 0, 1, s[0:1]
; GCN-NEXT:    v_lshlrev_b32_e32 v0, 31, v0
; GCN-NEXT:    s_cmp_lt_i32 s5, 0x47800001
; GCN-NEXT:    v_lshlrev_b32_e32 v1, 31, v1
; GCN-NEXT:    v_xor_b32_e32 v0, s3, v0
; GCN-NEXT:    s_cselect_b64 vcc, -1, 0
; GCN-NEXT:    s_cmp_lt_i32 s4, 0x47800001
; GCN-NEXT:    v_xor_b32_e32 v2, s2, v1
; GCN-NEXT:    v_cndmask_b32_e32 v1, 1.0, v0, vcc
; GCN-NEXT:    s_cselect_b64 vcc, -1, 0
; GCN-NEXT:    v_cndmask_b32_e32 v0, 1.0, v2, vcc
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[8:11], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: setcc_v2i32_expand:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 0, @14, KC0[CB0:0-32], KC1[]
; R600-NEXT:    TEX 0 @8
; R600-NEXT:    ALU 1, @15, KC0[CB0:0-32], KC1[]
; R600-NEXT:    TEX 1 @10
; R600-NEXT:    ALU 14, @17, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T0.XY, T1.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    Fetch clause starting at 8:
; R600-NEXT:     VTX_READ_64 T0.XY, T0.X, 0, #1
; R600-NEXT:    Fetch clause starting at 10:
; R600-NEXT:     VTX_READ_64 T2.XY, T2.X, 0, #1
; R600-NEXT:     VTX_READ_64 T1.XY, T1.X, 0, #1
; R600-NEXT:    ALU clause starting at 14:
; R600-NEXT:     MOV * T0.X, KC0[2].Y,
; R600-NEXT:    ALU clause starting at 15:
; R600-NEXT:     MOV T1.X, KC0[2].Z,
; R600-NEXT:     MOV * T2.X, KC0[2].W,
; R600-NEXT:    ALU clause starting at 17:
; R600-NEXT:     SETGT_INT * T0.W, T0.Y, 1,
; R600-NEXT:     CNDE_INT T0.W, PV.W, 0.0, literal.x,
; R600-NEXT:     SETGT_INT * T1.W, T0.X, 1,
; R600-NEXT:    -2147483648(-0.000000e+00), 0(0.000000e+00)
; R600-NEXT:     CNDE_INT T0.Z, PS, 0.0, literal.x,
; R600-NEXT:     XOR_INT T0.W, PV.W, T1.Y,
; R600-NEXT:     SETGT_INT * T1.W, T2.Y, literal.y,
; R600-NEXT:    -2147483648(-0.000000e+00), 1199570944(6.553600e+04)
; R600-NEXT:     CNDE_INT T0.Y, PS, PV.W, literal.x,
; R600-NEXT:     SETGT_INT T0.W, T2.X, literal.y,
; R600-NEXT:     XOR_INT * T1.W, PV.Z, T1.X,
; R600-NEXT:    1065353216(1.000000e+00), 1199570944(6.553600e+04)
; R600-NEXT:     CNDE_INT T0.X, PV.W, PS, literal.x,
; R600-NEXT:     LSHR * T1.X, KC0[3].X, literal.y,
; R600-NEXT:    1065353216(1.000000e+00), 2(2.802597e-45)
  ptr addrspace(1) %a,
  ptr addrspace(1) %b,
  ptr addrspace(1) %c,
  ptr addrspace(1) %r) {
entry:
  %a.val = load <2 x i32>, ptr addrspace(1) %a
  %b.val = load <2 x i32>, ptr addrspace(1) %b
  %c.val = load <2 x i32>, ptr addrspace(1) %c

  %icmp.val.1 = icmp sgt <2 x i32> %a.val, <i32 1, i32 1>
  %zext.val.1 = zext <2 x i1> %icmp.val.1 to <2 x i32>
  %shl.val.1 = shl nuw <2 x i32> %zext.val.1, <i32 31, i32 31>
  %xor.val.1 = xor <2 x i32> %shl.val.1, %b.val
  %bitcast.val.1 = bitcast <2 x i32> %xor.val.1 to <2 x float>
  %icmp.val.2 = icmp sgt <2 x i32> %c.val, <i32 1199570944, i32 1199570944>
  %select.val.1 = select <2 x i1> %icmp.val.2, <2 x float> <float 1.000000e+00, float 1.000000e+00>, <2 x float> %bitcast.val.1

  store <2 x float> %select.val.1, ptr addrspace(1) %r
  ret void
}

; FUNC-LABEL: setcc_v4i32_expand
; GCN: s_cmp_gt_i32
; GCN: s_cmp_gt_i32
; GCN: s_cmp_gt_i32
; GCN: s_cmp_gt_i32
define amdgpu_kernel void @setcc_v4i32_expand(
; GCN-LABEL: setcc_v4i32_expand:
; GCN:       ; %bb.0: ; %entry
; GCN-NEXT:    s_load_dwordx8 s[4:11], s[4:5], 0x9
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_load_dwordx4 s[12:15], s[4:5], 0x0
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_mov_b32 s0, s10
; GCN-NEXT:    s_mov_b32 s1, s11
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[6:7], 0x0
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[8:9], 0x0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_cmp_gt_i32 s15, 1
; GCN-NEXT:    s_cselect_b64 s[16:17], -1, 0
; GCN-NEXT:    s_cmp_gt_i32 s14, 1
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, s[16:17]
; GCN-NEXT:    s_cselect_b64 s[14:15], -1, 0
; GCN-NEXT:    s_cmp_gt_i32 s13, 1
; GCN-NEXT:    v_cndmask_b32_e64 v1, 0, 1, s[14:15]
; GCN-NEXT:    v_lshlrev_b32_e32 v0, 31, v0
; GCN-NEXT:    s_cselect_b64 s[14:15], -1, 0
; GCN-NEXT:    s_cmp_gt_i32 s12, 1
; GCN-NEXT:    v_cndmask_b32_e64 v2, 0, 1, s[14:15]
; GCN-NEXT:    v_lshlrev_b32_e32 v1, 31, v1
; GCN-NEXT:    v_xor_b32_e32 v0, s7, v0
; GCN-NEXT:    s_cselect_b64 s[12:13], -1, 0
; GCN-NEXT:    v_cndmask_b32_e64 v3, 0, 1, s[12:13]
; GCN-NEXT:    v_lshlrev_b32_e32 v2, 31, v2
; GCN-NEXT:    v_xor_b32_e32 v1, s6, v1
; GCN-NEXT:    s_cmp_lt_i32 s11, 0x47800001
; GCN-NEXT:    v_lshlrev_b32_e32 v4, 31, v3
; GCN-NEXT:    v_xor_b32_e32 v5, s5, v2
; GCN-NEXT:    s_cselect_b64 vcc, -1, 0
; GCN-NEXT:    v_cndmask_b32_e32 v3, 1.0, v0, vcc
; GCN-NEXT:    s_cmp_lt_i32 s10, 0x47800001
; GCN-NEXT:    v_xor_b32_e32 v0, s4, v4
; GCN-NEXT:    s_cselect_b64 vcc, -1, 0
; GCN-NEXT:    v_cndmask_b32_e32 v2, 1.0, v1, vcc
; GCN-NEXT:    s_cmp_lt_i32 s9, 0x47800001
; GCN-NEXT:    s_cselect_b64 vcc, -1, 0
; GCN-NEXT:    v_cndmask_b32_e32 v1, 1.0, v5, vcc
; GCN-NEXT:    s_cmp_lt_i32 s8, 0x47800001
; GCN-NEXT:    s_cselect_b64 vcc, -1, 0
; GCN-NEXT:    v_cndmask_b32_e32 v0, 1.0, v0, vcc
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[0:3], 0
; GCN-NEXT:    s_endpgm
;
; R600-LABEL: setcc_v4i32_expand:
; R600:       ; %bb.0: ; %entry
; R600-NEXT:    ALU 0, @14, KC0[CB0:0-32], KC1[]
; R600-NEXT:    TEX 0 @8
; R600-NEXT:    ALU 1, @15, KC0[CB0:0-32], KC1[]
; R600-NEXT:    TEX 1 @10
; R600-NEXT:    ALU 28, @17, KC0[CB0:0-32], KC1[]
; R600-NEXT:    MEM_RAT_CACHELESS STORE_RAW T1.XYZW, T0.X, 1
; R600-NEXT:    CF_END
; R600-NEXT:    PAD
; R600-NEXT:    Fetch clause starting at 8:
; R600-NEXT:     VTX_READ_128 T0.XYZW, T0.X, 0, #1
; R600-NEXT:    Fetch clause starting at 10:
; R600-NEXT:     VTX_READ_128 T2.XYZW, T2.X, 0, #1
; R600-NEXT:     VTX_READ_128 T1.XYZW, T1.X, 0, #1
; R600-NEXT:    ALU clause starting at 14:
; R600-NEXT:     MOV * T0.X, KC0[2].Y,
; R600-NEXT:    ALU clause starting at 15:
; R600-NEXT:     MOV T1.X, KC0[2].Z,
; R600-NEXT:     MOV * T2.X, KC0[2].W,
; R600-NEXT:    ALU clause starting at 17:
; R600-NEXT:     SETGT_INT T0.W, T0.W, 1,
; R600-NEXT:     SETGT_INT * T3.W, T0.Z, 1,
; R600-NEXT:     CNDE_INT * T0.W, PV.W, 0.0, literal.x,
; R600-NEXT:    -2147483648(-0.000000e+00), 0(0.000000e+00)
; R600-NEXT:     XOR_INT T3.Y, PV.W, T1.W,
; R600-NEXT:     SETGT_INT T0.Z, T2.W, literal.x,
; R600-NEXT:     CNDE_INT T0.W, T3.W, 0.0, literal.y, BS:VEC_201
; R600-NEXT:     SETGT_INT * T1.W, T0.Y, 1,
; R600-NEXT:    1199570944(6.553600e+04), -2147483648(-0.000000e+00)
; R600-NEXT:     CNDE_INT T3.X, PS, 0.0, literal.x,
; R600-NEXT:     SETGT_INT T0.Y, T2.Z, literal.y,
; R600-NEXT:     XOR_INT T1.Z, PV.W, T1.Z,
; R600-NEXT:     SETGT_INT T0.W, T0.X, 1,
; R600-NEXT:     CNDE_INT * T1.W, PV.Z, PV.Y, literal.z,
; R600-NEXT:    -2147483648(-0.000000e+00), 1199570944(6.553600e+04)
; R600-NEXT:    1065353216(1.000000e+00), 0(0.000000e+00)
; R600-NEXT:     CNDE_INT T3.Y, PV.W, 0.0, literal.x,
; R600-NEXT:     CNDE_INT T1.Z, PV.Y, PV.Z, literal.y,
; R600-NEXT:     SETGT_INT T0.W, T2.Y, literal.z,
; R600-NEXT:     XOR_INT * T2.W, PV.X, T1.Y,
; R600-NEXT:    -2147483648(-0.000000e+00), 1065353216(1.000000e+00)
; R600-NEXT:    1199570944(6.553600e+04), 0(0.000000e+00)
; R600-NEXT:     CNDE_INT T1.Y, PV.W, PS, literal.x,
; R600-NEXT:     SETGT_INT T0.W, T2.X, literal.y,
; R600-NEXT:     XOR_INT * T2.W, PV.Y, T1.X,
; R600-NEXT:    1065353216(1.000000e+00), 1199570944(6.553600e+04)
; R600-NEXT:     CNDE_INT T1.X, PV.W, PS, literal.x,
; R600-NEXT:     LSHR * T0.X, KC0[3].X, literal.y,
; R600-NEXT:    1065353216(1.000000e+00), 2(2.802597e-45)
  ptr addrspace(1) %a,
  ptr addrspace(1) %b,
  ptr addrspace(1) %c,
  ptr addrspace(1) %r) {
entry:
  %a.val = load <4 x i32>, ptr addrspace(1) %a
  %b.val = load <4 x i32>, ptr addrspace(1) %b
  %c.val = load <4 x i32>, ptr addrspace(1) %c

  %icmp.val.1 = icmp sgt <4 x i32> %a.val, <i32 1, i32 1, i32 1, i32 1>
  %zext.val.1 = zext <4 x i1> %icmp.val.1 to <4 x i32>
  %shl.val.1 = shl nuw <4 x i32> %zext.val.1, <i32 31, i32 31, i32 31, i32 31>
  %xor.val.1 = xor <4 x i32> %shl.val.1, %b.val
  %bitcast.val.1 = bitcast <4 x i32> %xor.val.1 to <4 x float>
  %icmp.val.2 = icmp sgt <4 x i32> %c.val, <i32 1199570944, i32 1199570944, i32 1199570944, i32 1199570944>
  %select.val.1 = select <4 x i1> %icmp.val.2, <4 x float> <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>, <4 x float> %bitcast.val.1

  store <4 x float> %select.val.1, ptr addrspace(1) %r
  ret void
}

attributes #0 = { nounwind "amdgpu-no-dispatch-id" "amdgpu-no-dispatch-ptr" "amdgpu-no-implicitarg-ptr" "amdgpu-no-lds-kernel-id" "amdgpu-no-queue-ptr" "amdgpu-no-workgroup-id-x" "amdgpu-no-workgroup-id-y" "amdgpu-no-workgroup-id-z" "amdgpu-no-workitem-id-x" "amdgpu-no-workitem-id-y" "amdgpu-no-workitem-id-z" }
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; FUNC: {{.*}}
