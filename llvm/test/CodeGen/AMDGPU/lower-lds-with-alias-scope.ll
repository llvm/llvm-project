; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn -mcpu=gfx900 -O3 < %s | FileCheck -check-prefixes=GCN,GFX9 %s
; RUN: llc -mtriple=amdgcn -mcpu=gfx942 -O3 < %s | FileCheck -check-prefixes=GCN,GFX942 %s

@a = internal unnamed_addr addrspace(3) global [64 x i32] poison, align 4
@b = internal unnamed_addr addrspace(3) global [64 x i32] poison, align 4
@c = internal unnamed_addr addrspace(3) global [64 x i32] poison, align 4

define amdgpu_kernel void @ds_load_stores_aainfo(ptr addrspace(1) %arg, i32 %i) {
; GFX9-LABEL: ds_load_stores_aainfo:
; GFX9:       ; %bb.0: ; %bb
; GFX9-NEXT:    s_load_dword s0, s[4:5], 0x2c
; GFX9-NEXT:    v_mov_b32_e32 v0, 1
; GFX9-NEXT:    v_mov_b32_e32 v1, 0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_lshl_b32 s0, s0, 2
; GFX9-NEXT:    v_mov_b32_e32 v4, s0
; GFX9-NEXT:    ds_read2_b32 v[2:3], v4 offset1:1
; GFX9-NEXT:    ds_write_b64 v1, v[0:1] offset:512
; GFX9-NEXT:    ds_read2_b32 v[4:5], v4 offset0:64 offset1:65
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX9-NEXT:    ; sched_group_barrier mask(0x00000100) size(1) SyncID(0)
; GFX9-NEXT:    ; sched_group_barrier mask(0x00000200) size(1) SyncID(0)
; GFX9-NEXT:    ; sched_group_barrier mask(0x00000100) size(1) SyncID(0)
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, v2, v4
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, v3, v5, vcc
; GFX9-NEXT:    global_store_dwordx2 v1, v[2:3], s[0:1]
; GFX9-NEXT:    s_endpgm
;
; GFX942-LABEL: ds_load_stores_aainfo:
; GFX942:       ; %bb.0: ; %bb
; GFX942-NEXT:    s_load_dword s0, s[4:5], 0x2c
; GFX942-NEXT:    v_mov_b32_e32 v0, 1
; GFX942-NEXT:    v_mov_b32_e32 v1, 0
; GFX942-NEXT:    s_waitcnt lgkmcnt(0)
; GFX942-NEXT:    s_lshl_b32 s0, s0, 2
; GFX942-NEXT:    v_mov_b32_e32 v4, s0
; GFX942-NEXT:    ds_read2_b32 v[2:3], v4 offset1:1
; GFX942-NEXT:    ds_write_b64 v1, v[0:1] offset:512
; GFX942-NEXT:    ds_read2_b32 v[4:5], v4 offset0:64 offset1:65
; GFX942-NEXT:    s_load_dwordx2 s[0:1], s[4:5], 0x24
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000100) size(1) SyncID(0)
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000200) size(1) SyncID(0)
; GFX942-NEXT:    ; sched_group_barrier mask(0x00000100) size(1) SyncID(0)
; GFX942-NEXT:    s_waitcnt lgkmcnt(0)
; GFX942-NEXT:    v_lshl_add_u64 v[2:3], v[2:3], 0, v[4:5]
; GFX942-NEXT:    global_store_dwordx2 v1, v[2:3], s[0:1]
; GFX942-NEXT:    s_endpgm
bb:
  %gep.a = getelementptr inbounds [64 x i32], ptr addrspace(3) @a, i32 0, i32 %i
  %gep.b = getelementptr inbounds [64 x i32], ptr addrspace(3) @b, i32 0, i32 %i

  %val.a = load i64, ptr addrspace(3) %gep.a, align 4, !tbaa !0, !alias.scope !6, !noalias !5
  %val.b = load i64, ptr addrspace(3) %gep.b, align 4, !tbaa !0, !alias.scope !6, !noalias !5

  store i64 1, ptr addrspace(3) @c, align 4, !tbaa !0, !noalias !2

  %val = add i64 %val.a, %val.b
  store i64 %val, ptr addrspace(1) %arg, align 4

  tail call void @llvm.amdgcn.sched.group.barrier(i32 256, i32 1, i32 0)
  tail call void @llvm.amdgcn.sched.group.barrier(i32 512, i32 1, i32 0)
  tail call void @llvm.amdgcn.sched.group.barrier(i32 256, i32 1, i32 0)
  ret void
}

  !0 = !{!"omnipotent char", !1, i64 0}
  !1 = !{!1}
  !2 = !{!3}
  !3 = distinct !{!3, !4}
  !4 = distinct !{!4}
  !5 = !{!3}
  !6 = !{!7}
  !7 = !{!7, !4}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; GCN: {{.*}}
