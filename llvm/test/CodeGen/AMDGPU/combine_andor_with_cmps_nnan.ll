; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 2
; RUN: llc -mtriple=amdgcn -mcpu=gfx1100 -mattr=+real-true16 -amdgpu-enable-delay-alu=0 < %s | FileCheck %s -check-prefixes=GCN,GCN-TRUE16
; RUN: llc -mtriple=amdgcn -mcpu=gfx1100 -mattr=-real-true16 -amdgpu-enable-delay-alu=0 < %s | FileCheck %s -check-prefixes=GCN,GCN-FAKE16

; The tests check the following optimization of DAGCombiner:
; CMP(A,C)||CMP(B,C) => CMP(MIN/MAX(A,B), C)
; CMP(A,C)&&CMP(B,C) => CMP(MIN/MAX(A,B), C)

define i1 @test54(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test54:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %arg3
  %cmp2 = fcmp nnan olt float %arg2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test55(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test55:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_le_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ole double %arg1, %arg3
  %cmp2 = fcmp nnan ole double %arg2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test56(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test56:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ogt double %arg1, %arg3
  %cmp2 = fcmp nnan ogt double %arg2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test57(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test57:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan oge float %arg1, %arg3
  %cmp2 = fcmp nnan oge float %arg2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test58(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test58:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ugt double %arg1, %arg3
  %cmp2 = fcmp nnan ugt double %arg2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test59(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test59:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan uge float %arg1, %arg3
  %cmp2 = fcmp nnan uge float %arg2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test60(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test60:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_le_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ule float %arg1, %arg3
  %cmp2 = fcmp nnan ule float %arg2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test61(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test61:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_lt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ult double %arg1, %arg3
  %cmp2 = fcmp nnan ult double %arg2, %arg3
  %and1 = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test62(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test62:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v0, 1.0, v0 :: v_dual_add_f32 v1, 2.0, v1
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, 1.0
  %add2 = fadd nnan float %arg2, 2.0
  %cmp1 = fcmp nnan olt float %add1, %arg3
  %cmp2 = fcmp nnan olt float %add2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test63(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test63:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_add_f64 v[0:1], v[0:1], 1.0
; GCN-NEXT:    v_add_f64 v[2:3], v[2:3], 2.0
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_le_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan double %arg1, 1.0
  %add2 = fadd nnan double %arg2, 2.0
  %cmp1 = fcmp nnan ole double %add1, %arg3
  %cmp2 = fcmp nnan ole double %add2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test64(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test64:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_add_f64 v[0:1], v[0:1], 1.0
; GCN-NEXT:    v_add_f64 v[2:3], v[2:3], 2.0
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan double %arg1, 1.0
  %add2 = fadd nnan double %arg2, 2.0
  %cmp1 = fcmp nnan ogt double %add1, %arg3
  %cmp2 = fcmp nnan ogt double %add2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test65(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test65:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v0, 1.0, v0 :: v_dual_add_f32 v1, 2.0, v1
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, 1.0
  %add2 = fadd nnan float %arg2, 2.0
  %cmp1 = fcmp nnan oge float %add1, %arg3
  %cmp2 = fcmp nnan oge float %add2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test66(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test66:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_add_f64 v[0:1], v[0:1], 1.0
; GCN-NEXT:    v_add_f64 v[2:3], v[2:3], 2.0
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan double %arg1, 1.0
  %add2 = fadd nnan double %arg2, 2.0
  %cmp1 = fcmp nnan ugt double %add1, %arg3
  %cmp2 = fcmp nnan ugt double %add2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test67(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test67:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v0, 1.0, v0 :: v_dual_add_f32 v1, 2.0, v1
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, 1.0
  %add2 = fadd nnan float %arg2, 2.0
  %cmp1 = fcmp nnan uge float %add1, %arg3
  %cmp2 = fcmp nnan uge float %add2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test68(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test68:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v0, 1.0, v0 :: v_dual_add_f32 v1, 2.0, v1
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_le_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, 1.0
  %add2 = fadd nnan float %arg2, 2.0
  %cmp1 = fcmp nnan ule float %add1, %arg3
  %cmp2 = fcmp nnan ule float %add2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test69(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test69:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_add_f64 v[0:1], v[0:1], 1.0
; GCN-NEXT:    v_add_f64 v[2:3], v[2:3], 2.0
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_lt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan double %arg1, 1.0
  %add2 = fadd nnan double %arg2, 2.0
  %cmp1 = fcmp nnan ult double %add1, %arg3
  %cmp2 = fcmp nnan ult double %add2, %arg3
  %and1 = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test70(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test70:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan olt float %var1, %arg3
  %cmp2 = fcmp nnan olt float %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test71(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test71:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_le_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ole double %var1, %arg3
  %cmp2 = fcmp nnan ole double %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test72(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test72:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ogt double %var1, %arg3
  %cmp2 = fcmp nnan ogt double %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test73(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test73:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan oge float %var1, %arg3
  %cmp2 = fcmp nnan oge float %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test74(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test74:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ugt double %var1, %arg3
  %cmp2 = fcmp nnan ugt double %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test75(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test75:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan uge float %var1, %arg3
  %cmp2 = fcmp nnan uge float %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test76(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test76:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_le_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan ule float %var1, %arg3
  %cmp2 = fcmp nnan ule float %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test77(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test77:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_lt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ult double %var1, %arg3
  %cmp2 = fcmp nnan ult double %var2, %arg3
  %and1 = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test78(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test78:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %arg3
  %cmp2 = fcmp nnan ogt float %arg3, %arg2
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test79(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test79:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ult float %arg1, %arg3
  %cmp2 = fcmp nnan ugt float %arg3, %arg2
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test80(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test80:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v0, 1.0, v0 :: v_dual_add_f32 v1, 2.0, v1
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, 1.0
  %add2 = fadd nnan float %arg2, 2.0
  %cmp1 = fcmp nnan oge float %add1, %arg3
  %cmp2 = fcmp nnan ole float %arg3, %add2
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test81(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test81:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_add_f64 v[0:1], v[0:1], 1.0
; GCN-NEXT:    v_add_f64 v[2:3], v[2:3], 2.0
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan double %arg1, 1.0
  %add2 = fadd nnan double %arg2, 2.0
  %cmp1 = fcmp nnan ugt double %add1, %arg3
  %cmp2 = fcmp nnan ult double %arg3, %add2
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test82(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test82:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_le_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ole double %var1, %arg3
  %cmp2 = fcmp nnan oge double %arg3, %var2
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test83(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test83:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_le_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan ule float %var1, %arg3
  %cmp2 = fcmp nnan uge float %arg3, %var2
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test84(half %arg1, half %arg2, half %arg3) {
; GCN-TRUE16-LABEL: test84:
; GCN-TRUE16:       ; %bb.0:
; GCN-TRUE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-TRUE16-NEXT:    v_min_f16_e32 v0.l, v0.l, v1.l
; GCN-TRUE16-NEXT:    v_cmp_lt_f16_e32 vcc_lo, v0.l, v2.l
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    s_setpc_b64 s[30:31]
;
; GCN-FAKE16-LABEL: test84:
; GCN-FAKE16:       ; %bb.0:
; GCN-FAKE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-FAKE16-NEXT:    v_min_f16_e32 v0, v0, v1
; GCN-FAKE16-NEXT:    v_cmp_lt_f16_e32 vcc_lo, v0, v2
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan half @llvm.canonicalize.f16(half %arg1)
  %var2 = call nnan half @llvm.canonicalize.f16(half %arg2)
  %cmp1 = fcmp nnan olt half %var1, %arg3
  %cmp2 = fcmp nnan olt half %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define <2 x i1> @test85(<2 x half> %arg1, <2 x half> %arg2, <2 x half> %arg3) {
; GCN-TRUE16-LABEL: test85:
; GCN-TRUE16:       ; %bb.0:
; GCN-TRUE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-TRUE16-NEXT:    v_pk_max_f16 v0, v0, v0
; GCN-TRUE16-NEXT:    v_pk_max_f16 v1, v1, v1
; GCN-TRUE16-NEXT:    v_pk_min_f16 v1, v0, v1
; GCN-TRUE16-NEXT:    v_cmp_le_f16_e32 vcc_lo, v1.l, v2.l
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    v_cmp_le_f16_e32 vcc_lo, v1.h, v2.h
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v1, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    s_setpc_b64 s[30:31]
;
; GCN-FAKE16-LABEL: test85:
; GCN-FAKE16:       ; %bb.0:
; GCN-FAKE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-FAKE16-NEXT:    v_pk_max_f16 v0, v0, v0
; GCN-FAKE16-NEXT:    v_pk_max_f16 v1, v1, v1
; GCN-FAKE16-NEXT:    v_pk_min_f16 v0, v0, v1
; GCN-FAKE16-NEXT:    v_lshrrev_b32_e32 v1, 16, v2
; GCN-FAKE16-NEXT:    v_lshrrev_b32_e32 v3, 16, v0
; GCN-FAKE16-NEXT:    v_cmp_le_f16_e32 vcc_lo, v0, v2
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    v_cmp_le_f16_e32 vcc_lo, v3, v1
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v1, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %arg1)
  %var2 = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %arg2)
  %cmp1 = fcmp nnan ole <2 x half> %var1, %arg3
  %cmp2 = fcmp nnan ole <2 x half> %var2, %arg3
  %or1  = or <2 x i1> %cmp1, %cmp2
  ret <2 x i1> %or1
}

define <2 x i1> @test86(<2 x half> %arg1, <2 x half> %arg2, <2 x half> %arg3) {
; GCN-TRUE16-LABEL: test86:
; GCN-TRUE16:       ; %bb.0:
; GCN-TRUE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-TRUE16-NEXT:    v_pk_max_f16 v0, v0, v0
; GCN-TRUE16-NEXT:    v_pk_max_f16 v1, v1, v1
; GCN-TRUE16-NEXT:    v_pk_max_f16 v1, v0, v1
; GCN-TRUE16-NEXT:    v_cmp_gt_f16_e32 vcc_lo, v1.l, v2.l
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    v_cmp_gt_f16_e32 vcc_lo, v1.h, v2.h
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v1, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    s_setpc_b64 s[30:31]
;
; GCN-FAKE16-LABEL: test86:
; GCN-FAKE16:       ; %bb.0:
; GCN-FAKE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-FAKE16-NEXT:    v_pk_max_f16 v0, v0, v0
; GCN-FAKE16-NEXT:    v_pk_max_f16 v1, v1, v1
; GCN-FAKE16-NEXT:    v_pk_max_f16 v0, v0, v1
; GCN-FAKE16-NEXT:    v_lshrrev_b32_e32 v1, 16, v2
; GCN-FAKE16-NEXT:    v_lshrrev_b32_e32 v3, 16, v0
; GCN-FAKE16-NEXT:    v_cmp_gt_f16_e32 vcc_lo, v0, v2
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    v_cmp_gt_f16_e32 vcc_lo, v3, v1
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v1, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %arg1)
  %var2 = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %arg2)
  %cmp1 = fcmp nnan ogt <2 x half> %var1, %arg3
  %cmp2 = fcmp nnan ogt <2 x half> %var2, %arg3
  %or1  = or <2 x i1> %cmp1, %cmp2
  ret <2 x i1> %or1
}

define i1 @test87(half %arg1, half %arg2, half %arg3) {
; GCN-TRUE16-LABEL: test87:
; GCN-TRUE16:       ; %bb.0:
; GCN-TRUE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-TRUE16-NEXT:    v_max_f16_e32 v0.l, v0.l, v1.l
; GCN-TRUE16-NEXT:    v_cmp_ge_f16_e32 vcc_lo, v0.l, v2.l
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    s_setpc_b64 s[30:31]
;
; GCN-FAKE16-LABEL: test87:
; GCN-FAKE16:       ; %bb.0:
; GCN-FAKE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-FAKE16-NEXT:    v_max_f16_e32 v0, v0, v1
; GCN-FAKE16-NEXT:    v_cmp_ge_f16_e32 vcc_lo, v0, v2
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan half @llvm.canonicalize.f16(half %arg1)
  %var2 = call nnan half @llvm.canonicalize.f16(half %arg2)
  %cmp1 = fcmp nnan oge half %var1, %arg3
  %cmp2 = fcmp nnan oge half %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define <2 x i1> @test88(<2 x half> %arg1, <2 x half> %arg2, <2 x half> %arg3) {
; GCN-TRUE16-LABEL: test88:
; GCN-TRUE16:       ; %bb.0:
; GCN-TRUE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-TRUE16-NEXT:    v_pk_max_f16 v0, v0, v0
; GCN-TRUE16-NEXT:    v_pk_max_f16 v1, v1, v1
; GCN-TRUE16-NEXT:    v_pk_min_f16 v1, v0, v1
; GCN-TRUE16-NEXT:    v_cmp_gt_f16_e32 vcc_lo, v1.l, v2.l
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    v_cmp_gt_f16_e32 vcc_lo, v1.h, v2.h
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v1, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    s_setpc_b64 s[30:31]
;
; GCN-FAKE16-LABEL: test88:
; GCN-FAKE16:       ; %bb.0:
; GCN-FAKE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-FAKE16-NEXT:    v_pk_max_f16 v0, v0, v0
; GCN-FAKE16-NEXT:    v_pk_max_f16 v1, v1, v1
; GCN-FAKE16-NEXT:    v_pk_min_f16 v0, v0, v1
; GCN-FAKE16-NEXT:    v_lshrrev_b32_e32 v1, 16, v2
; GCN-FAKE16-NEXT:    v_lshrrev_b32_e32 v3, 16, v0
; GCN-FAKE16-NEXT:    v_cmp_gt_f16_e32 vcc_lo, v0, v2
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    v_cmp_gt_f16_e32 vcc_lo, v3, v1
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v1, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %arg1)
  %var2 = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %arg2)
  %cmp1 = fcmp nnan ugt <2 x half> %var1, %arg3
  %cmp2 = fcmp nnan ugt <2 x half> %var2, %arg3
  %and1  = and <2 x i1> %cmp1, %cmp2
  ret <2 x i1> %and1
}

define i1 @test89(half %arg1, half %arg2, half %arg3) {
; GCN-TRUE16-LABEL: test89:
; GCN-TRUE16:       ; %bb.0:
; GCN-TRUE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-TRUE16-NEXT:    v_min_f16_e32 v0.l, v0.l, v1.l
; GCN-TRUE16-NEXT:    v_cmp_ge_f16_e32 vcc_lo, v0.l, v2.l
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    s_setpc_b64 s[30:31]
;
; GCN-FAKE16-LABEL: test89:
; GCN-FAKE16:       ; %bb.0:
; GCN-FAKE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-FAKE16-NEXT:    v_min_f16_e32 v0, v0, v1
; GCN-FAKE16-NEXT:    v_cmp_ge_f16_e32 vcc_lo, v0, v2
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan half @llvm.canonicalize.f16(half %arg1)
  %var2 = call nnan half @llvm.canonicalize.f16(half %arg2)
  %cmp1 = fcmp nnan uge half %var1, %arg3
  %cmp2 = fcmp nnan uge half %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test90(half %arg1, half %arg2, half %arg3) {
; GCN-TRUE16-LABEL: test90:
; GCN-TRUE16:       ; %bb.0:
; GCN-TRUE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-TRUE16-NEXT:    v_max_f16_e32 v0.l, v0.l, v1.l
; GCN-TRUE16-NEXT:    v_cmp_le_f16_e32 vcc_lo, v0.l, v2.l
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    s_setpc_b64 s[30:31]
;
; GCN-FAKE16-LABEL: test90:
; GCN-FAKE16:       ; %bb.0:
; GCN-FAKE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-FAKE16-NEXT:    v_max_f16_e32 v0, v0, v1
; GCN-FAKE16-NEXT:    v_cmp_le_f16_e32 vcc_lo, v0, v2
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan half @llvm.canonicalize.f16(half %arg1)
  %var2 = call nnan half @llvm.canonicalize.f16(half %arg2)
  %cmp1 = fcmp nnan ule half %var1, %arg3
  %cmp2 = fcmp nnan ule half %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define <2 x i1> @test91(<2 x half> %arg1, <2 x half> %arg2, <2 x half> %arg3) {
; GCN-TRUE16-LABEL: test91:
; GCN-TRUE16:       ; %bb.0:
; GCN-TRUE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-TRUE16-NEXT:    v_pk_max_f16 v0, v0, v0
; GCN-TRUE16-NEXT:    v_pk_max_f16 v1, v1, v1
; GCN-TRUE16-NEXT:    v_pk_max_f16 v1, v0, v1
; GCN-TRUE16-NEXT:    v_cmp_lt_f16_e32 vcc_lo, v1.l, v2.l
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    v_cmp_lt_f16_e32 vcc_lo, v1.h, v2.h
; GCN-TRUE16-NEXT:    v_cndmask_b32_e64 v1, 0, 1, vcc_lo
; GCN-TRUE16-NEXT:    s_setpc_b64 s[30:31]
;
; GCN-FAKE16-LABEL: test91:
; GCN-FAKE16:       ; %bb.0:
; GCN-FAKE16-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-FAKE16-NEXT:    v_pk_max_f16 v0, v0, v0
; GCN-FAKE16-NEXT:    v_pk_max_f16 v1, v1, v1
; GCN-FAKE16-NEXT:    v_pk_max_f16 v0, v0, v1
; GCN-FAKE16-NEXT:    v_lshrrev_b32_e32 v1, 16, v2
; GCN-FAKE16-NEXT:    v_lshrrev_b32_e32 v3, 16, v0
; GCN-FAKE16-NEXT:    v_cmp_lt_f16_e32 vcc_lo, v0, v2
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    v_cmp_lt_f16_e32 vcc_lo, v3, v1
; GCN-FAKE16-NEXT:    v_cndmask_b32_e64 v1, 0, 1, vcc_lo
; GCN-FAKE16-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %arg1)
  %var2 = call <2 x half> @llvm.canonicalize.v2f16(<2 x half> %arg2)
  %cmp1 = fcmp nnan ult <2 x half> %var1, %arg3
  %cmp2 = fcmp nnan ult <2 x half> %var2, %arg3
  %and1 = and <2 x i1> %cmp1, %cmp2
  ret <2 x i1> %and1
}

define i1 @test107(float %arg1, float %arg2, float %arg3, float %C) {
; GCN-LABEL: test107:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min3_f32 v0, v0, v1, v2
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %C
  %cmp2 = fcmp nnan olt float %arg2, %C
  %cmp3 = fcmp nnan olt float %arg3, %C
  %or1 = or i1 %cmp1, %cmp2
  %or2 = or i1 %or1, %cmp3
  ret i1 %or2
}

define i1 @test108(float %arg1, float %arg2, float %arg3, float %C) {
; GCN-LABEL: test108:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max3_f32 v0, v0, v1, v2
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ult float %arg1, %C
  %cmp2 = fcmp nnan ult float %arg2, %C
  %cmp3 = fcmp nnan ult float %arg3, %C
  %and1 = and i1 %cmp1, %cmp2
  %and2 = and i1 %and1, %cmp3
  ret i1 %and2
}

define i1 @test109(float %arg1, float %arg2, float %arg3, float %arg4, float %C) {
; GCN-LABEL: test109:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_min_f32 v0, v0, v1 :: v_dual_max_f32 v1, v2, v3
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v4
; GCN-NEXT:    v_cmp_gt_f32_e64 s0, v1, v4
; GCN-NEXT:    s_or_b32 s0, vcc_lo, s0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, s0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %C
  %cmp2 = fcmp nnan olt float %arg2, %C
  %cmp3 = fcmp nnan ogt float %arg3, %C
  %cmp4 = fcmp nnan ogt float %arg4, %C
  %or1 = or i1 %cmp1, %cmp2
  %or2 = or i1 %cmp3, %cmp4
  %or3 = or i1 %or1, %or2
  ret i1 %or3
}

define i1 @test110(float %arg1, float %arg2, float %arg3, float %arg4, float %C1, float %C2, float %C3, float %C4, float %C) #0 {
; GCN-LABEL: test110:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v0, v0, v4 :: v_dual_add_f32 v1, v1, v5
; GCN-NEXT:    v_dual_add_f32 v2, v2, v6 :: v_dual_add_f32 v3, v3, v7
; GCN-NEXT:    v_dual_max_f32 v0, v0, v1 :: v_dual_min_f32 v1, v2, v3
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v8
; GCN-NEXT:    v_cmp_gt_f32_e64 s0, v1, v8
; GCN-NEXT:    s_and_b32 s0, vcc_lo, s0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, s0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, %C1
  %add2 = fadd nnan float %arg2, %C2
  %add3 = fadd nnan float %arg3, %C3
  %add4 = fadd nnan float %arg4, %C4
  %cmp1 = fcmp nnan ult float %add1, %C
  %cmp2 = fcmp nnan ult float %add2, %C
  %cmp3 = fcmp nnan ugt float %add3, %C
  %cmp4 = fcmp nnan ugt float %add4, %C
  %or1 = and i1 %cmp1, %cmp2
  %or2 = and i1 %cmp3, %cmp4
  %or3 = and i1 %or1, %or2
  ret i1 %or3
}

define i1 @test111(float %arg1, float %arg2, float %arg3, float %arg4, float %arg5, float %arg6, float %arg7, float %arg8, float %C) {
; GCN-LABEL: test111:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v2, v2, v3
; GCN-NEXT:    v_min3_f32 v0, v0, v1, v2
; GCN-NEXT:    v_min_f32_e32 v0, v0, v4
; GCN-NEXT:    v_min3_f32 v0, v5, v6, v0
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v8
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %C
  %cmp2 = fcmp nnan olt float %arg2, %C
  %or1  = or i1 %cmp1, %cmp2
  %cmp3 = fcmp nnan olt float %arg3, %C
  %cmp4 = fcmp nnan olt float %arg4, %C
  %or2  = or i1 %cmp3, %cmp4
  %cmp5 = fcmp nnan olt float %arg5, %C
  %or3 = or i1 %or1, %or2
  %or4 = or i1 %or3, %cmp5
  %cmp6 = fcmp nnan olt float %arg6, %C
  %cmp7 = fcmp nnan olt float %arg7, %C
  %or5 = or i1 %cmp6, %cmp7
  %cmp8 = fcmp nnan olt float %arg8, %C
  %or6 = or i1 %or5, %or4
  %or7 = or i1 %or6, %cmp8
  ret i1 %or6
}

define i1 @test112(float %arg1, float %arg2, float %arg3, float %arg4, float %arg5, float %arg6, float %arg7, float %arg8, float %C) {
; GCN-LABEL: test112:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v2, v2, v3
; GCN-NEXT:    v_min3_f32 v0, v0, v1, v2
; GCN-NEXT:    v_min_f32_e32 v0, v0, v4
; GCN-NEXT:    v_min3_f32 v0, v5, v6, v0
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v8
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %C
  %cmp2 = fcmp nnan olt float %arg2, %C
  %or1  = or i1 %cmp1, %cmp2
  %cmp3 = fcmp nnan olt float %arg3, %C
  %cmp4 = fcmp nnan olt float %arg4, %C
  %or2  = or i1 %cmp3, %cmp4
  %cmp5 = fcmp nnan ult float %arg5, %C
  %or3 = or i1 %or1, %or2
  %or4 = or i1 %or3, %cmp5
  %cmp6 = fcmp nnan olt float %arg6, %C
  %cmp7 = fcmp nnan olt float %arg7, %C
  %or5 = or i1 %cmp6, %cmp7
  %cmp8 = fcmp nnan ult float %arg8, %C
  %or6 = or i1 %or5, %or4
  %or7 = or i1 %or6, %cmp8
  ret i1 %or6
}

define i1 @test113(float %arg1, float %arg2, float %arg3, float %C) {
; GCN-LABEL: test113:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_maxmin_f32 v0, v0, v1, v2
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ult float %arg1, %C
  %cmp2 = fcmp nnan ult float %arg2, %C
  %cmp3 = fcmp nnan olt float %arg3, %C
  %and1 = and i1 %cmp1, %cmp2
  %or1 = or i1 %and1, %cmp3
  ret i1 %or1
}

define i1 @test114(float %arg1, float %arg2, float %arg3, float %C) {
; GCN-LABEL: test114:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v2, v3
; GCN-NEXT:    v_cmp_gt_f32_e64 s0, v0, v3
; GCN-NEXT:    s_and_b32 s0, s0, vcc_lo
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, s0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ogt float %arg1, %C
  %cmp2 = fcmp nnan ogt float %arg2, %C
  %cmp3 = fcmp nnan ult float %arg3, %C
  %and1 = or i1 %cmp1, %cmp2
  %or1 = and i1 %and1, %cmp3
  ret i1 %or1
}

define i1 @test115(float %arg1, float %arg2, float %arg3, float %arg4, float %C) {
; GCN-LABEL: test115:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v2, v2, v3
; GCN-NEXT:    v_min3_f32 v0, v0, v1, v2
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v4
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %C
  %cmp2 = fcmp nnan olt float %arg2, %C
  %var3 = call nnan float @llvm.canonicalize.f32(float %arg3)
  %var4 = call nnan float @llvm.canonicalize.f32(float %arg4)
  %cmp3 = fcmp nnan ult float %var3, %C
  %cmp4 = fcmp nnan ult float %var4, %C
  %or1 = or i1 %cmp1, %cmp2
  %and1 = and i1 %cmp3, %cmp4
  %or2 = or i1 %or1, %and1
  ret i1 %or2
}

define i1 @test116(float %arg1, float %arg2, float %arg3, float %arg4, float %arg5, float %arg6, float %arg7, float %arg8, float %arg9, float %arg10, float %C) {
; GCN-LABEL: test116:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v8, v8, v9
; GCN-NEXT:    v_dual_max_f32 v2, v2, v3 :: v_dual_min_f32 v3, v4, v5
; GCN-NEXT:    v_max_f32_e32 v4, v6, v7
; GCN-NEXT:    v_min3_f32 v0, v0, v1, v8
; GCN-NEXT:    v_cmp_gt_f32_e32 vcc_lo, v2, v10
; GCN-NEXT:    v_cmp_lt_f32_e64 s0, v3, v10
; GCN-NEXT:    v_cmp_gt_f32_e64 s1, v4, v10
; GCN-NEXT:    v_cmp_lt_f32_e64 s2, v0, v10
; GCN-NEXT:    s_or_b32 s0, s0, s1
; GCN-NEXT:    s_or_b32 s1, s2, vcc_lo
; GCN-NEXT:    s_or_b32 s0, s0, s1
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, s0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %C
  %cmp2 = fcmp nnan olt float %arg2, %C
  %cmp3 = fcmp nnan ogt float %arg3, %C
  %cmp4 = fcmp nnan ogt float %arg4, %C
  %cmp5 = fcmp nnan olt float %arg5, %C
  %cmp6 = fcmp nnan olt float %arg6, %C
  %cmp7 = fcmp nnan ogt float %arg7, %C
  %cmp8 = fcmp nnan ogt float %arg8, %C
  %cmp9 = fcmp nnan olt float %arg9, %C
  %cmp10 = fcmp nnan olt float %arg10, %C
  %or1 = or i1 %cmp1, %cmp2
  %or2 = or i1 %cmp3, %cmp4
  %or3 = or i1 %cmp5, %cmp6
  %or4 = or i1 %cmp7, %cmp8
  %or5 = or i1 %cmp9, %cmp10
  %or6 = or i1 %or1, %or2
  %or7 = or i1 %or3, %or4
  %or8 = or i1 %or5, %or6
  %or9 = or i1 %or7, %or8
  ret i1 %or9
}

define i1 @test117(float %arg1, float %arg2, float %arg3, float %arg4, float %arg5, float %arg6, float %arg7, float %arg8, float %arg9, float %arg10, float %arg11, float %arg12, float %C1, float %C2) {
; GCN-LABEL: test117:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v6, v6, v7
; GCN-NEXT:    v_dual_min_f32 v0, v0, v1 :: v_dual_min_f32 v1, v10, v11
; GCN-NEXT:    v_min_f32_e32 v2, v2, v3
; GCN-NEXT:    v_min3_f32 v3, v4, v5, v6
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v12
; GCN-NEXT:    v_min3_f32 v0, v8, v9, v1
; GCN-NEXT:    v_cmp_lt_f32_e64 s0, v2, v13
; GCN-NEXT:    v_cmp_lt_f32_e64 s1, v3, v13
; GCN-NEXT:    v_cmp_lt_f32_e64 s2, v0, v12
; GCN-NEXT:    s_or_b32 s0, vcc_lo, s0
; GCN-NEXT:    s_or_b32 s0, s0, s1
; GCN-NEXT:    s_or_b32 s0, s2, s0
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, s0
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %C1
  %cmp2 = fcmp nnan olt float %arg2, %C1
  %cmp3 = fcmp nnan olt float %arg3, %C2
  %cmp4 = fcmp nnan olt float %arg4, %C2
  %cmp5 = fcmp nnan olt float %arg5, %C2
  %cmp6 = fcmp nnan olt float %arg6, %C2
  %cmp7 = fcmp nnan olt float %arg7, %C2
  %cmp8 = fcmp nnan olt float %arg8, %C2
  %cmp9 = fcmp nnan olt float %arg9, %C1
  %cmp10 = fcmp nnan olt float %arg10, %C1
  %cmp11 = fcmp nnan olt float %arg11, %C1
  %cmp12 = fcmp nnan olt float %arg12, %C1
  %or1 = or i1 %cmp1, %cmp2
  %or2 = or i1 %cmp3, %cmp4
  %or3 = or i1 %cmp5, %cmp6
  %or4 = or i1 %cmp7, %cmp8
  %or5 = or i1 %cmp9, %cmp10
  %or6 = or i1 %cmp11, %cmp12
  %or7 = or i1 %or1, %or2
  %or8 = or i1 %or3, %or4
  %or9 = or i1 %or5, %or6
  %or10 = or i1 %or7, %or8
  %or11 = or i1 %or9, %or10
  ret i1 %or11
}


define i1 @test118(float %arg1, float %arg2, float %arg3, float %arg4, float %C1, float %C2, float %C3, float %C4, float %C) #0 {
; GCN-LABEL: test118:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v0, v0, v4 :: v_dual_add_f32 v1, v1, v5
; GCN-NEXT:    v_dual_add_f32 v2, v2, v6 :: v_dual_add_f32 v3, v3, v7
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_max3_f32 v0, v0, v2, v3
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v8
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, %C1
  %add2 = fadd nnan float %arg2, %C2
  %add3 = fadd nnan float %arg3, %C3
  %add4 = fadd nnan float %arg4, %C4
  %cmp1 = fcmp nnan ult float %add1, %C
  %cmp2 = fcmp nnan ult float %add2, %C
  %cmp3 = fcmp nnan ult float %add3, %C
  %cmp4 = fcmp nnan ult float %add4, %C
  %or1 = or i1 %cmp1, %cmp2
  %and1 = and i1 %cmp3, %cmp4
  %and2 = and i1 %or1, %and1
  ret i1 %and2
}

define i1 @test119(float %arg1, float %arg2, float %arg3, float %arg4, float %C1, float %C2, float %C3, float %C4, float %C) #0 {
; GCN-LABEL: test119:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v2, v2, v6 :: v_dual_add_f32 v3, v3, v7
; GCN-NEXT:    v_dual_add_f32 v0, v0, v4 :: v_dual_add_f32 v1, v1, v5
; GCN-NEXT:    v_min_f32_e32 v2, v2, v3
; GCN-NEXT:    v_minmax_f32 v0, v0, v1, v2
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v8
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, %C1
  %add2 = fadd nnan float %arg2, %C2
  %add3 = fadd nnan float %arg3, %C3
  %add4 = fadd nnan float %arg4, %C4
  %cmp1 = fcmp nnan ult float %add1, %C
  %cmp2 = fcmp nnan ult float %add2, %C
  %cmp3 = fcmp nnan ult float %add3, %C
  %cmp4 = fcmp nnan ult float %add4, %C
  %or1 = or i1 %cmp1, %cmp2
  %and1 = or i1 %cmp3, %cmp4
  %and2 = and i1 %or1, %and1
  ret i1 %and2
}

define i1 @test120(float %arg1, float %arg2, float %arg3, float %arg4, float %C1, float %C2, float %C3, float %C4, float %C) #0 {
; GCN-LABEL: test120:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v2, v2, v6 :: v_dual_add_f32 v3, v3, v7
; GCN-NEXT:    v_dual_add_f32 v0, v0, v4 :: v_dual_add_f32 v1, v1, v5
; GCN-NEXT:    v_max_f32_e32 v2, v2, v3
; GCN-NEXT:    v_min3_f32 v0, v0, v1, v2
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v8
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, %C1
  %add2 = fadd nnan float %arg2, %C2
  %add3 = fadd nnan float %arg3, %C3
  %add4 = fadd nnan float %arg4, %C4
  %cmp1 = fcmp nnan ult float %add1, %C
  %cmp2 = fcmp nnan ult float %add2, %C
  %cmp3 = fcmp nnan ult float %add3, %C
  %cmp4 = fcmp nnan ult float %add4, %C
  %or1 = or i1 %cmp1, %cmp2
  %and1 = and i1 %cmp3, %cmp4
  %and2 = or i1 %or1, %and1
  ret i1 %and2
}

define i1 @test121(float %arg1, float %arg2, float %arg3, float %arg4, float %C1, float %C2, float %C3, float %C4, float %C) #0 {
; GCN-LABEL: test121:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_dual_add_f32 v2, v2, v6 :: v_dual_add_f32 v3, v3, v7
; GCN-NEXT:    v_dual_add_f32 v0, v0, v4 :: v_dual_add_f32 v1, v1, v5
; GCN-NEXT:    v_max_f32_e32 v2, v2, v3
; GCN-NEXT:    v_maxmin_f32 v0, v0, v1, v2
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v8
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %add1 = fadd nnan float %arg1, %C1
  %add2 = fadd nnan float %arg2, %C2
  %add3 = fadd nnan float %arg3, %C3
  %add4 = fadd nnan float %arg4, %C4
  %cmp1 = fcmp nnan ult float %add1, %C
  %cmp2 = fcmp nnan ult float %add2, %C
  %cmp3 = fcmp nnan ult float %add3, %C
  %cmp4 = fcmp nnan ult float %add4, %C
  %or1 = and i1 %cmp1, %cmp2
  %and1 = and i1 %cmp3, %cmp4
  %and2 = or i1 %or1, %and1
  ret i1 %and2
}

define i1 @test122(double %arg1, double %arg2, double %arg3) #1 {
; GCN-LABEL: test122:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_lt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ult double %arg1, %arg3
  %cmp2 = fcmp nnan ult double %arg2, %arg3
  %or1 = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test123(double %arg1, double %arg2, double %arg3) #1 {
; GCN-LABEL: test123:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ogt double %var1, %arg3
  %cmp2 = fcmp nnan ogt double %var2, %arg3
  %or1 = and i1 %cmp1, %cmp2
 ret i1 %or1
}

define i1 @test134(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test134:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %arg3
  %cmp2 = fcmp nnan ogt float %arg3, %arg2
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test135(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test135:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ult float %arg1, %arg3
  %cmp2 = fcmp nnan ugt float %arg3, %arg2
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test136(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test136:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_le_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ole double %var1, %arg3
  %cmp2 = fcmp nnan oge double %arg3, %var2
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test137(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test137:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_le_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan ule float %var1, %arg3
  %cmp2 = fcmp nnan uge float %arg3, %var2
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test138(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test138:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan olt float %arg1, %arg3
  %cmp2 = fcmp nnan olt float %arg2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test139(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test139:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_le_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ole double %arg1, %arg3
  %cmp2 = fcmp nnan ole double %arg2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test140(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test140:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ogt double %arg1, %arg3
  %cmp2 = fcmp nnan ogt double %arg2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test141(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test141:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan oge float %arg1, %arg3
  %cmp2 = fcmp nnan oge float %arg2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test142(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test142:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ugt double %arg1, %arg3
  %cmp2 = fcmp nnan ugt double %arg2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test143(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test143:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan uge float %arg1, %arg3
  %cmp2 = fcmp nnan uge float %arg2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test144(float %arg1, float %arg2, float %arg3) #0 {
; GCN-LABEL: test144:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_le_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ule float %arg1, %arg3
  %cmp2 = fcmp nnan ule float %arg2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test145(double %arg1, double %arg2, double %arg3) #0 {
; GCN-LABEL: test145:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_lt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %cmp1 = fcmp nnan ult double %arg1, %arg3
  %cmp2 = fcmp nnan ult double %arg2, %arg3
  %or1 = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test146(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test146:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_lt_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan olt float %var1, %arg3
  %cmp2 = fcmp nnan olt float %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test147(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test147:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_le_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ole double %var1, %arg3
  %cmp2 = fcmp nnan ole double %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test148(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test148:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ogt double %var1, %arg3
  %cmp2 = fcmp nnan ogt double %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test149(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test149:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan oge float %var1, %arg3
  %cmp2 = fcmp nnan oge float %var2, %arg3
  %and1  = and i1 %cmp1, %cmp2
  ret i1 %and1
}

define i1 @test150(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test150:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_gt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ugt double %var1, %arg3
  %cmp2 = fcmp nnan ugt double %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test151(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test151:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan uge float %var1, %arg3
  %cmp2 = fcmp nnan uge float %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test152(float %arg1, float %arg2, float %arg3) {
; GCN-LABEL: test152:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_min_f32_e32 v0, v0, v1
; GCN-NEXT:    v_cmp_le_f32_e32 vcc_lo, v0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan float @llvm.canonicalize.f32(float %arg1)
  %var2 = call nnan float @llvm.canonicalize.f32(float %arg2)
  %cmp1 = fcmp nnan ule float %var1, %arg3
  %cmp2 = fcmp nnan ule float %var2, %arg3
  %or1  = or i1 %cmp1, %cmp2
  ret i1 %or1
}

define i1 @test153(double %arg1, double %arg2, double %arg3) {
; GCN-LABEL: test153:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GCN-NEXT:    v_max_f64 v[0:1], v[0:1], v[0:1]
; GCN-NEXT:    v_max_f64 v[2:3], v[2:3], v[2:3]
; GCN-NEXT:    v_min_f64 v[0:1], v[0:1], v[2:3]
; GCN-NEXT:    v_cmp_lt_f64_e32 vcc_lo, v[0:1], v[4:5]
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, vcc_lo
; GCN-NEXT:    s_setpc_b64 s[30:31]
  %var1 = call nnan double @llvm.canonicalize.f64(double %arg1)
  %var2 = call nnan double @llvm.canonicalize.f64(double %arg2)
  %cmp1 = fcmp nnan ult double %var1, %arg3
  %cmp2 = fcmp nnan ult double %var2, %arg3
  %or1 = or i1 %cmp1, %cmp2
  ret i1 %or1
}

declare double @llvm.canonicalize.f64(double)
declare float @llvm.canonicalize.f32(float)
declare half @llvm.canonicalize.f16(half)
declare <2 x half> @llvm.canonicalize.v2f16(<2 x half>)

attributes #0 = { nounwind "amdgpu-ieee"="false" }
attributes #1 = { nounwind "no-nans-fp-math"="true" }
