; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=amdgcn-mesa-mesa3d -mcpu=gfx1210 < %s | FileCheck -check-prefixes=GFX1210,GFX1210-SDAG %s
; RUN: llc -global-isel -mtriple=amdgcn-mesa-mesa3d -mcpu=gfx1210 < %s | FileCheck -check-prefixes=GFX1210,GFX1210-GISEL %s

; Test using saddr addressing mode of flat_* atomic instructions.

define amdgpu_ps void @flat_xchg_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xchg_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_swap_b32 v0, v1, s[2:3] scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw xchg ptr %gep0, i32 %data syncscope("agent") seq_cst
  ret void
}

; Maximum positive offset on gfx10
define amdgpu_ps void @flat_xchg_saddr_i32_nortn_offset_2047(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xchg_saddr_i32_nortn_offset_2047:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_swap_b32 v0, v1, s[2:3] offset:2047 scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 2047
  %unused = atomicrmw xchg ptr %gep1, i32 %data syncscope("agent") seq_cst
  ret void
}

; Maximum negative offset on gfx10
define amdgpu_ps void @flat_xchg_saddr_i32_nortn_offset_neg2048(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xchg_saddr_i32_nortn_offset_neg2048:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_swap_b32 v0, v1, s[2:3] offset:-2048 scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -2048
  %unused = atomicrmw xchg ptr %gep1, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps float @flat_xchg_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xchg_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_swap_b32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw xchg ptr %gep0, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_xchg_saddr_i32_rtn_2048(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xchg_saddr_i32_rtn_2048:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_swap_b32 v0, v0, v1, s[2:3] offset:2048 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 2048
  %rtn = atomicrmw xchg ptr %gep1, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_xchg_saddr_i32_rtn_neg2048(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xchg_saddr_i32_rtn_neg2048:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_swap_b32 v0, v0, v1, s[2:3] offset:-2048 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -2048
  %rtn = atomicrmw xchg ptr %gep1, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

; --------------------------------------------------------------------------------
; Uniformity edge cases
; --------------------------------------------------------------------------------

@ptr.in.lds = internal addrspace(3) global ptr undef

; Base pointer is uniform, but also in VGPRs
define amdgpu_ps float @flat_xchg_saddr_uniform_ptr_in_vgprs_rtn(i32 %voffset, i32 %data) {
; GFX1210-SDAG-LABEL: flat_xchg_saddr_uniform_ptr_in_vgprs_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_mov_b32_e32 v2, 0
; GFX1210-SDAG-NEXT:    ds_load_b64 v[2:3], v2
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    v_readfirstlane_b32 s0, v2
; GFX1210-SDAG-NEXT:    v_readfirstlane_b32 s1, v3
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_swap_b32 v0, v0, v1, s[0:1] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_xchg_saddr_uniform_ptr_in_vgprs_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_mov_b32_e32 v2, 0
; GFX1210-GISEL-NEXT:    ds_load_b64 v[2:3], v2
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    v_add_co_u32 v2, vcc_lo, v2, v0
; GFX1210-GISEL-NEXT:    v_add_co_ci_u32_e32 v3, vcc_lo, 0, v3, vcc_lo
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_swap_b32 v0, v[2:3], v1 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %sbase = load ptr, ptr addrspace(3) @ptr.in.lds
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw xchg ptr %gep0, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

; Base pointer is uniform, but also in VGPRs, with imm offset
define amdgpu_ps float @flat_xchg_saddr_uniform_ptr_in_vgprs_rtn_immoffset(i32 %voffset, i32 %data) {
; GFX1210-SDAG-LABEL: flat_xchg_saddr_uniform_ptr_in_vgprs_rtn_immoffset:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_mov_b32_e32 v2, 0
; GFX1210-SDAG-NEXT:    ds_load_b64 v[2:3], v2
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    v_readfirstlane_b32 s0, v2
; GFX1210-SDAG-NEXT:    v_readfirstlane_b32 s1, v3
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_swap_b32 v0, v0, v1, s[0:1] offset:42 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_xchg_saddr_uniform_ptr_in_vgprs_rtn_immoffset:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_mov_b32_e32 v2, 0
; GFX1210-GISEL-NEXT:    ds_load_b64 v[2:3], v2
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    v_add_co_u32 v2, vcc_lo, v2, v0
; GFX1210-GISEL-NEXT:    v_add_co_ci_u32_e32 v3, vcc_lo, 0, v3, vcc_lo
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_swap_b32 v0, v[2:3], v1 offset:42 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %sbase = load ptr, ptr addrspace(3) @ptr.in.lds
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 42
  %rtn = atomicrmw xchg ptr %gep1, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

; Base pointer is uniform, but also in VGPRs
define amdgpu_ps void @flat_xchg_saddr_uniform_ptr_in_vgprs_nortn(i32 %voffset, i32 %data) {
; GFX1210-SDAG-LABEL: flat_xchg_saddr_uniform_ptr_in_vgprs_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_mov_b32_e32 v2, 0
; GFX1210-SDAG-NEXT:    ds_load_b64 v[2:3], v2
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    v_readfirstlane_b32 s0, v2
; GFX1210-SDAG-NEXT:    v_readfirstlane_b32 s1, v3
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_swap_b32 v0, v1, s[0:1] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_xchg_saddr_uniform_ptr_in_vgprs_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_mov_b32_e32 v2, 0
; GFX1210-GISEL-NEXT:    ds_load_b64 v[2:3], v2
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    v_add_co_u32 v2, vcc_lo, v2, v0
; GFX1210-GISEL-NEXT:    v_add_co_ci_u32_e32 v3, vcc_lo, 0, v3, vcc_lo
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_swap_b32 v[2:3], v1 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %sbase = load ptr, ptr addrspace(3) @ptr.in.lds
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw xchg ptr %gep0, i32 %data syncscope("agent") seq_cst
  ret void
}

; Base pointer is uniform, but also in VGPRs, with imm offset
define amdgpu_ps void @flat_xchg_saddr_uniform_ptr_in_vgprs_nortn_immoffset(i32 %voffset, i32 %data) {
; GFX1210-SDAG-LABEL: flat_xchg_saddr_uniform_ptr_in_vgprs_nortn_immoffset:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_mov_b32_e32 v2, 0
; GFX1210-SDAG-NEXT:    ds_load_b64 v[2:3], v2
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    v_readfirstlane_b32 s0, v2
; GFX1210-SDAG-NEXT:    v_readfirstlane_b32 s1, v3
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_swap_b32 v0, v1, s[0:1] offset:42 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_xchg_saddr_uniform_ptr_in_vgprs_nortn_immoffset:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_mov_b32_e32 v2, 0
; GFX1210-GISEL-NEXT:    ds_load_b64 v[2:3], v2
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    v_add_co_u32 v2, vcc_lo, v2, v0
; GFX1210-GISEL-NEXT:    v_add_co_ci_u32_e32 v3, vcc_lo, 0, v3, vcc_lo
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_swap_b32 v[2:3], v1 offset:42 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %sbase = load ptr, ptr addrspace(3) @ptr.in.lds
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 42
  %unused = atomicrmw xchg ptr %gep1, i32 %data syncscope("agent") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; All atomicrmw ops
; --------------------------------------------------------------------------------

; --------------------------------------------------------------------------------
; atomicrmw xchg
; --------------------------------------------------------------------------------

define amdgpu_ps <2 x float> @flat_xchg_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_xchg_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_swap_b64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_xchg_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_swap_b64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw xchg ptr %gep0, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_xchg_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_xchg_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_swap_b64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_xchg_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_swap_b64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw xchg ptr %gep1, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_xchg_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_xchg_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_swap_b64 v0, v[2:3], s[2:3] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_xchg_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_swap_b64 v0, v[4:5], s[2:3] scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw xchg ptr %gep0, i64 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_xchg_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_xchg_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_swap_b64 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_xchg_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_swap_b64 v0, v[4:5], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw xchg ptr %gep1, i64 %data syncscope("agent") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw add
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_add_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_add_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_add_u32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw add ptr %gep0, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_add_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_add_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_add_u32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw add ptr %gep1, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_add_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_add_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_add_u32 v0, v1, s[2:3] scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw add ptr %gep0, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_add_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_add_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_add_u32 v0, v1, s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw add ptr %gep1, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_add_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_add_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_add_u64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_add_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_add_u64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw add ptr %gep0, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_add_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_add_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_add_u64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_add_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_add_u64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw add ptr %gep1, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_add_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_add_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_add_u64 v0, v[2:3], s[2:3] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_add_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_add_u64 v0, v[4:5], s[2:3] scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw add ptr %gep0, i64 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_add_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_add_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_add_u64 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_add_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_add_u64 v0, v[4:5], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw add ptr %gep1, i64 %data syncscope("agent") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw sub
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_sub_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_sub_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_sub_u32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw sub ptr %gep0, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_sub_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_sub_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_sub_u32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw sub ptr %gep1, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_sub_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_sub_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_sub_u32 v0, v1, s[2:3] scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw sub ptr %gep0, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_sub_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_sub_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_sub_u32 v0, v1, s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw sub ptr %gep1, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_sub_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_sub_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_sub_u64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_sub_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_sub_u64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw sub ptr %gep0, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_sub_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_sub_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_sub_u64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_sub_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_sub_u64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw sub ptr %gep1, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_sub_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_sub_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_sub_u64 v0, v[2:3], s[2:3] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_sub_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_sub_u64 v0, v[4:5], s[2:3] scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw sub ptr %gep0, i64 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_sub_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_sub_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_sub_u64 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_sub_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_sub_u64 v0, v[4:5], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw sub ptr %gep1, i64 %data syncscope("agent") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw and
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_and_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_and_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_and_b32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw and ptr %gep0, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_and_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_and_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_and_b32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw and ptr %gep1, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_and_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_and_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_and_b32 v0, v1, s[2:3] scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw and ptr %gep0, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_and_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_and_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_and_b32 v0, v1, s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw and ptr %gep1, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_and_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_and_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_and_b64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_and_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_and_b64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw and ptr %gep0, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_and_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_and_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_and_b64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_and_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_and_b64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw and ptr %gep1, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_and_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_and_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_and_b64 v0, v[2:3], s[2:3] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_and_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_and_b64 v0, v[4:5], s[2:3] scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw and ptr %gep0, i64 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_and_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_and_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_and_b64 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_and_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_and_b64 v0, v[4:5], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw and ptr %gep1, i64 %data syncscope("agent") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw or
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_or_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_or_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_or_b32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw or ptr %gep0, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_or_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_or_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_or_b32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw or ptr %gep1, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_or_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_or_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_or_b32 v0, v1, s[2:3] scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw or ptr %gep0, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_or_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_or_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_or_b32 v0, v1, s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw or ptr %gep1, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_or_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_or_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_or_b64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_or_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_or_b64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw or ptr %gep0, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_or_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_or_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_or_b64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_or_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_or_b64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw or ptr %gep1, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_or_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_or_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_or_b64 v0, v[2:3], s[2:3] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_or_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_or_b64 v0, v[4:5], s[2:3] scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw or ptr %gep0, i64 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_or_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_or_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_or_b64 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_or_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_or_b64 v0, v[4:5], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw or ptr %gep1, i64 %data syncscope("agent") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw xor
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_xor_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xor_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_xor_b32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw xor ptr %gep0, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_xor_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xor_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_xor_b32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw xor ptr %gep1, i32 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_xor_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xor_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_xor_b32 v0, v1, s[2:3] scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw xor ptr %gep0, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_xor_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_xor_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-NEXT:    flat_atomic_xor_b32 v0, v1, s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw xor ptr %gep1, i32 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_xor_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_xor_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_xor_b64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_xor_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_xor_b64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw xor ptr %gep0, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_xor_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_xor_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_xor_b64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_xor_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_xor_b64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw xor ptr %gep1, i64 %data syncscope("agent") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_xor_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_xor_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_xor_b64 v0, v[2:3], s[2:3] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_xor_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_xor_b64 v0, v[4:5], s[2:3] scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw xor ptr %gep0, i64 %data syncscope("agent") seq_cst
  ret void
}

define amdgpu_ps void @flat_xor_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_xor_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    flat_atomic_xor_b64 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_xor_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    flat_atomic_xor_b64 v0, v[4:5], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw xor ptr %gep1, i64 %data syncscope("agent") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw max
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_max_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_max_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_max_i32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw max ptr %gep0, i32 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_max_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_max_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_max_i32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw max ptr %gep1, i32 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_max_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_max_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_max_i32 v0, v1, s[2:3]
; GFX1210-NEXT:    s_wait_dscnt 0x0
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw max ptr %gep0, i32 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps void @flat_max_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_max_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_max_i32 v0, v1, s[2:3] offset:-128
; GFX1210-NEXT:    s_wait_dscnt 0x0
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw max ptr %gep1, i32 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_max_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_max_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_max_i64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_max_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_max_i64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw max ptr %gep0, i64 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_max_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_max_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_max_i64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_max_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_max_i64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw max ptr %gep1, i64 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_max_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_max_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_max_i64 v0, v[2:3], s[2:3]
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_max_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_max_i64 v0, v[4:5], s[2:3]
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw max ptr %gep0, i64 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps void @flat_max_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_max_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_max_i64 v0, v[2:3], s[2:3] offset:-128
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_max_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_max_i64 v0, v[4:5], s[2:3] offset:-128
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw max ptr %gep1, i64 %data syncscope("workgroup") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw min
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_min_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_min_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_min_i32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw min ptr %gep0, i32 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_min_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_min_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_min_i32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw min ptr %gep1, i32 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_min_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_min_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_min_i32 v0, v1, s[2:3]
; GFX1210-NEXT:    s_wait_dscnt 0x0
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw min ptr %gep0, i32 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps void @flat_min_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_min_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_min_i32 v0, v1, s[2:3] offset:-128
; GFX1210-NEXT:    s_wait_dscnt 0x0
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw min ptr %gep1, i32 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_min_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_min_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_min_i64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_min_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_min_i64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw min ptr %gep0, i64 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_min_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_min_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_min_i64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_min_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_min_i64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw min ptr %gep1, i64 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_min_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_min_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_min_i64 v0, v[2:3], s[2:3]
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_min_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_min_i64 v0, v[4:5], s[2:3]
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw min ptr %gep0, i64 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps void @flat_min_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_min_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_min_i64 v0, v[2:3], s[2:3] offset:-128
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_min_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_min_i64 v0, v[4:5], s[2:3] offset:-128
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw min ptr %gep1, i64 %data syncscope("workgroup") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw umax
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_umax_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_umax_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_max_u32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw umax ptr %gep0, i32 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_umax_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_umax_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_max_u32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw umax ptr %gep1, i32 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_umax_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_umax_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_max_u32 v0, v1, s[2:3]
; GFX1210-NEXT:    s_wait_dscnt 0x0
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw umax ptr %gep0, i32 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps void @flat_umax_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_umax_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_max_u32 v0, v1, s[2:3] offset:-128
; GFX1210-NEXT:    s_wait_dscnt 0x0
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw umax ptr %gep1, i32 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_umax_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_umax_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_max_u64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_umax_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_max_u64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw umax ptr %gep0, i64 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_umax_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_umax_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_max_u64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_umax_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_max_u64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw umax ptr %gep1, i64 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_umax_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_umax_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_max_u64 v0, v[2:3], s[2:3]
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_umax_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_max_u64 v0, v[4:5], s[2:3]
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw umax ptr %gep0, i64 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps void @flat_umax_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_umax_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_max_u64 v0, v[2:3], s[2:3] offset:-128
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_umax_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_max_u64 v0, v[4:5], s[2:3] offset:-128
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw umax ptr %gep1, i64 %data syncscope("workgroup") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw umin
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_umin_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_umin_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_min_u32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw umin ptr %gep0, i32 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_umin_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_umin_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_min_u32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw umin ptr %gep1, i32 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_umin_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_umin_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_min_u32 v0, v1, s[2:3]
; GFX1210-NEXT:    s_wait_dscnt 0x0
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw umin ptr %gep0, i32 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps void @flat_umin_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_umin_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_min_u32 v0, v1, s[2:3] offset:-128
; GFX1210-NEXT:    s_wait_dscnt 0x0
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw umin ptr %gep1, i32 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_umin_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_umin_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_min_u64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_umin_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_min_u64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw umin ptr %gep0, i64 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_umin_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_umin_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_min_u64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_umin_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_min_u64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw umin ptr %gep1, i64 %data syncscope("workgroup") seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_umin_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_umin_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_min_u64 v0, v[2:3], s[2:3]
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_umin_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_min_u64 v0, v[4:5], s[2:3]
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw umin ptr %gep0, i64 %data syncscope("workgroup") seq_cst
  ret void
}

define amdgpu_ps void @flat_umin_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_umin_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_min_u64 v0, v[2:3], s[2:3] offset:-128
; GFX1210-SDAG-NEXT:    s_wait_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_umin_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_min_u64 v0, v[4:5], s[2:3] offset:-128
; GFX1210-GISEL-NEXT:    s_wait_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw umin ptr %gep1, i64 %data syncscope("workgroup") seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; cmpxchg
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_cmpxchg_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %cmp, i32 %data) {
; GFX1210-LABEL: flat_cmpxchg_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    v_mov_b32_e32 v3, v1
; GFX1210-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-NEXT:    flat_atomic_cmpswap_b32 v0, v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_SYS
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %cmpxchg = cmpxchg ptr %gep0, i32 %cmp, i32 %data seq_cst seq_cst
  %rtn = extractvalue { i32, i1 } %cmpxchg, 0
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_cmpxchg_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %cmp, i32 %data) {
; GFX1210-LABEL: flat_cmpxchg_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    v_mov_b32_e32 v3, v1
; GFX1210-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-NEXT:    flat_atomic_cmpswap_b32 v0, v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_SYS
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %cmpxchg = cmpxchg ptr %gep1, i32 %cmp, i32 %data seq_cst seq_cst
  %rtn = extractvalue { i32, i1 } %cmpxchg, 0
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_cmpxchg_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %cmp, i32 %data) {
; GFX1210-LABEL: flat_cmpxchg_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    v_mov_b32_e32 v3, v1
; GFX1210-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-NEXT:    flat_atomic_cmpswap_b32 v0, v[2:3], s[2:3] scope:SCOPE_SYS
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = cmpxchg ptr %gep0, i32 %cmp, i32 %data seq_cst seq_cst
  ret void
}

define amdgpu_ps void @flat_cmpxchg_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %cmp, i32 %data) {
; GFX1210-LABEL: flat_cmpxchg_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    v_mov_b32_e32 v3, v1
; GFX1210-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-NEXT:    flat_atomic_cmpswap_b32 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_SYS
; GFX1210-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = cmpxchg ptr %gep1, i32 %cmp, i32 %data seq_cst seq_cst
  ret void
}

define amdgpu_ps <2 x float> @flat_cmpxchg_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %cmp, i64 %data) {
; GFX1210-SDAG-LABEL: flat_cmpxchg_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v5, v4 :: v_dual_mov_b32 v4, v3
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v7, v2 :: v_dual_mov_b32 v6, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    flat_atomic_cmpswap_b64 v[0:1], v0, v[4:7], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_cmpxchg_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v8, v1 :: v_dual_mov_b32 v9, v2
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v6, v3 :: v_dual_mov_b32 v7, v4
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    flat_atomic_cmpswap_b64 v[0:1], v0, v[6:9], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %cmpxchg = cmpxchg ptr %gep0, i64 %cmp, i64 %data seq_cst seq_cst
  %rtn = extractvalue { i64, i1 } %cmpxchg, 0
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_cmpxchg_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %cmp, i64 %data) {
; GFX1210-SDAG-LABEL: flat_cmpxchg_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v5, v4 :: v_dual_mov_b32 v4, v3
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v7, v2 :: v_dual_mov_b32 v6, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    flat_atomic_cmpswap_b64 v[0:1], v0, v[4:7], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_cmpxchg_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v8, v1 :: v_dual_mov_b32 v9, v2
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v6, v3 :: v_dual_mov_b32 v7, v4
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    flat_atomic_cmpswap_b64 v[0:1], v0, v[6:9], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %cmpxchg = cmpxchg ptr %gep1, i64 %cmp, i64 %data seq_cst seq_cst
  %rtn = extractvalue { i64, i1 } %cmpxchg, 0
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_cmpxchg_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %cmp, i64 %data) {
; GFX1210-SDAG-LABEL: flat_cmpxchg_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v5, v4 :: v_dual_mov_b32 v4, v3
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v7, v2 :: v_dual_mov_b32 v6, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    flat_atomic_cmpswap_b64 v0, v[4:7], s[2:3] scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_cmpxchg_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v8, v1 :: v_dual_mov_b32 v9, v2
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v6, v3 :: v_dual_mov_b32 v7, v4
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    flat_atomic_cmpswap_b64 v0, v[6:9], s[2:3] scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = cmpxchg ptr %gep0, i64 %cmp, i64 %data seq_cst seq_cst
  ret void
}

define amdgpu_ps void @flat_cmpxchg_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %cmp, i64 %data) {
; GFX1210-SDAG-LABEL: flat_cmpxchg_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v5, v4 :: v_dual_mov_b32 v4, v3
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v7, v2 :: v_dual_mov_b32 v6, v1
; GFX1210-SDAG-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    flat_atomic_cmpswap_b64 v0, v[4:7], s[2:3] offset:-128 scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_cmpxchg_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v8, v1 :: v_dual_mov_b32 v9, v2
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v6, v3 :: v_dual_mov_b32 v7, v4
; GFX1210-GISEL-NEXT:    global_wb scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    flat_atomic_cmpswap_b64 v0, v[6:9], s[2:3] offset:-128 scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    s_wait_storecnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    global_inv scope:SCOPE_SYS
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = cmpxchg ptr %gep1, i64 %cmp, i64 %data seq_cst seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; amdgcn atomic inc
; --------------------------------------------------------------------------------

define amdgpu_ps float @flat_inc_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_inc_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_inc_u32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw uinc_wrap ptr %gep0, i32 %data syncscope("agent") monotonic
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_inc_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_inc_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_inc_u32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw uinc_wrap ptr %gep1, i32 %data syncscope("agent") monotonic
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_inc_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_inc_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_inc_u32 v0, v1, s[2:3] scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw uinc_wrap ptr %gep0, i32 %data syncscope("agent") monotonic
  ret void
}

define amdgpu_ps void @flat_inc_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_inc_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_inc_u32 v0, v1, s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw uinc_wrap ptr %gep1, i32 %data syncscope("agent") monotonic
  ret void
}

define amdgpu_ps <2 x float> @flat_inc_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_inc_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_inc_u64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_inc_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_inc_u64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw uinc_wrap ptr %gep0, i64 %data syncscope("agent") monotonic
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_inc_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_inc_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_inc_u64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_inc_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_inc_u64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw uinc_wrap ptr %gep1, i64 %data syncscope("agent") monotonic
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_inc_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_inc_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_inc_u64 v0, v[2:3], s[2:3] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_inc_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_inc_u64 v0, v[4:5], s[2:3] scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw uinc_wrap ptr %gep0, i64 %data syncscope("agent") monotonic
  ret void
}

define amdgpu_ps void @flat_inc_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_inc_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_inc_u64 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_inc_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_inc_u64 v0, v[4:5], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw uinc_wrap ptr %gep1, i64 %data syncscope("agent") monotonic
  ret void
}

; --------------------------------------------------------------------------------
; amdgcn atomic dec
; --------------------------------------------------------------------------------


define amdgpu_ps float @flat_dec_saddr_i32_rtn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_dec_saddr_i32_rtn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_dec_u32 v0, v0, v1, s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw udec_wrap ptr %gep0, i32 %data syncscope("agent") monotonic
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @flat_dec_saddr_i32_rtn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_dec_saddr_i32_rtn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_dec_u32 v0, v0, v1, s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-NEXT:    s_wait_xcnt 0x0
; GFX1210-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw udec_wrap ptr %gep1, i32 %data syncscope("agent") monotonic
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @flat_dec_saddr_i32_nortn(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_dec_saddr_i32_nortn:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_dec_u32 v0, v1, s[2:3] scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw udec_wrap ptr %gep0, i32 %data syncscope("agent") monotonic
  ret void
}

define amdgpu_ps void @flat_dec_saddr_i32_nortn_neg128(ptr inreg %sbase, i32 %voffset, i32 %data) {
; GFX1210-LABEL: flat_dec_saddr_i32_nortn_neg128:
; GFX1210:       ; %bb.0:
; GFX1210-NEXT:    flat_atomic_dec_u32 v0, v1, s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw udec_wrap ptr %gep1, i32 %data syncscope("agent") monotonic
  ret void
}

define amdgpu_ps <2 x float> @flat_dec_saddr_i64_rtn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_dec_saddr_i64_rtn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_dec_u64 v[0:1], v0, v[2:3], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_dec_saddr_i64_rtn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_dec_u64 v[0:1], v0, v[4:5], s[2:3] th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %rtn = atomicrmw udec_wrap ptr %gep0, i64 %data syncscope("agent") monotonic
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @flat_dec_saddr_i64_rtn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_dec_saddr_i64_rtn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_dec_u64 v[0:1], v0, v[2:3], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-SDAG-NEXT:    s_wait_xcnt 0x0
; GFX1210-SDAG-NEXT:    ; return to shader part epilog
;
; GFX1210-GISEL-LABEL: flat_dec_saddr_i64_rtn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_dec_u64 v[0:1], v0, v[4:5], s[2:3] offset:-128 th:TH_ATOMIC_RETURN scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX1210-GISEL-NEXT:    s_wait_xcnt 0x0
; GFX1210-GISEL-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %rtn = atomicrmw udec_wrap ptr %gep1, i64 %data syncscope("agent") monotonic
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @flat_dec_saddr_i64_nortn(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_dec_saddr_i64_nortn:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_dec_u64 v0, v[2:3], s[2:3] scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_dec_saddr_i64_nortn:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_dec_u64 v0, v[4:5], s[2:3] scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %unused = atomicrmw udec_wrap ptr %gep0, i64 %data syncscope("agent") monotonic
  ret void
}

define amdgpu_ps void @flat_dec_saddr_i64_nortn_neg128(ptr inreg %sbase, i32 %voffset, i64 %data) {
; GFX1210-SDAG-LABEL: flat_dec_saddr_i64_nortn_neg128:
; GFX1210-SDAG:       ; %bb.0:
; GFX1210-SDAG-NEXT:    v_dual_mov_b32 v3, v2 :: v_dual_mov_b32 v2, v1
; GFX1210-SDAG-NEXT:    flat_atomic_dec_u64 v0, v[2:3], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-SDAG-NEXT:    s_endpgm
;
; GFX1210-GISEL-LABEL: flat_dec_saddr_i64_nortn_neg128:
; GFX1210-GISEL:       ; %bb.0:
; GFX1210-GISEL-NEXT:    v_dual_mov_b32 v4, v1 :: v_dual_mov_b32 v5, v2
; GFX1210-GISEL-NEXT:    flat_atomic_dec_u64 v0, v[4:5], s[2:3] offset:-128 scope:SCOPE_DEV
; GFX1210-GISEL-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, ptr %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, ptr %gep0, i64 -128
  %unused = atomicrmw udec_wrap ptr %gep1, i64 %data syncscope("agent") monotonic
  ret void
}

attributes #0 = { argmemonly nounwind willreturn }
