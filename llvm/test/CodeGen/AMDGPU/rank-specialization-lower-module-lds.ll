; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -mtriple=amdgcn-amd-amdhsa -mcpu=gfx1300 -verify-machineinstrs -passes=amdgpu-lower-module-lds -S -o - %s | FileCheck --check-prefixes=CHECK,GV %s

target datalayout = "A5"

@weights = hidden local_unnamed_addr addrspace(3) global <9 x i32> undef, align 64
@col_center = hidden local_unnamed_addr addrspace(3) global <3 x i32> undef, align 16
@col_left = hidden local_unnamed_addr addrspace(3) global <3 x i32> undef, align 16
@col_right = hidden local_unnamed_addr addrspace(3) global <3 x i32> undef, align 16
@out = hidden local_unnamed_addr addrspace(3) global <8 x i16> undef, align 16

; The LDS GVs above get packed into a struct accessible from the specializations.
; GV:  %llvm.amdgcn.kernel.main.lds.t = type { <9 x i32>, <3 x i32>, <3 x i32>, <3 x i32>, <8 x i16> }
; GV:  @sem1 = internal addrspace(3) global target("amdgcn.semaphore", 1) poison, !absolute_symbol ![[SEMADDR1:[0-9]+]]
; GV:  @sem2 = internal addrspace(3) global target("amdgcn.semaphore", 2) poison, !absolute_symbol ![[SEMADDR2:[0-9]+]]
; GV:  @llvm.amdgcn.kernel.main.lds = internal addrspace(3) global %llvm.amdgcn.kernel.main.lds.t poison, align 64, !absolute_symbol ![[LDSSTRUCT:[0-9]+]]

@sem1 = internal addrspace(3) global target("amdgcn.semaphore", 1) poison
@sem2 = internal addrspace(3) global target("amdgcn.semaphore", 2) poison

define private amdgpu_kernel void @input(ptr addrspace(1) %inbuf, ptr addrspace(1) %wbuf, ptr addrspace(1) %outbuf) #0 #1 {
; CHECK-LABEL: define private amdgpu_kernel void @input(
; CHECK-SAME: ptr addrspace(1) [[INBUF:%.*]], ptr addrspace(1) [[WBUF:%.*]], ptr addrspace(1) [[OUTBUF:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[VEC30:%.*]] = load <3 x i32>, ptr addrspace(1) [[INBUF]], align 16
; CHECK-NEXT:    [[LD_P1:%.*]] = getelementptr <3 x i32>, ptr addrspace(1) [[INBUF]], i64 16
; CHECK-NEXT:    [[VEC31:%.*]] = load <3 x i32>, ptr addrspace(1) [[LD_P1]], align 16
; CHECK-NEXT:    [[LD_P2:%.*]] = getelementptr <3 x i32>, ptr addrspace(1) [[INBUF]], i64 32
; CHECK-NEXT:    [[VEC32:%.*]] = load <3 x i32>, ptr addrspace(1) [[LD_P2]], align 16
; CHECK-NEXT:    [[WEI30:%.*]] = load <3 x i32>, ptr addrspace(1) [[WBUF]], align 64
; CHECK-NEXT:    [[W_P1:%.*]] = getelementptr <3 x i32>, ptr addrspace(1) [[WBUF]], i64 16
; CHECK-NEXT:    [[WEI31:%.*]] = load <3 x i32>, ptr addrspace(1) [[W_P1]], align 16
; CHECK-NEXT:    [[W_P2:%.*]] = getelementptr <3 x i32>, ptr addrspace(1) [[WBUF]], i64 32
; CHECK-NEXT:    [[WEI32:%.*]] = load <3 x i32>, ptr addrspace(1) [[W_P2]], align 16
; CHECK-NEXT:    store <3 x i32> [[VEC30]], ptr addrspace(3) getelementptr inbounds ([[LLVM_AMDGCN_KERNEL_MAIN_LDS_T:%.*]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i32 0, i32 1), align 64
; CHECK-NEXT:    store <3 x i32> [[VEC31]], ptr addrspace(3) getelementptr inbounds ([[LLVM_AMDGCN_KERNEL_MAIN_LDS_T]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i32 0, i32 2), align 16
; CHECK-NEXT:    store <3 x i32> [[VEC32]], ptr addrspace(3) getelementptr inbounds ([[LLVM_AMDGCN_KERNEL_MAIN_LDS_T]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i32 0, i32 3), align 32
; CHECK-NEXT:    store <3 x i32> [[WEI30]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, align 64
; CHECK-NEXT:    [[WEI_P1:%.*]] = getelementptr <3 x i32>, ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i64 12
; CHECK-NEXT:    store <3 x i32> [[WEI31]], ptr addrspace(3) [[WEI_P1]], align 64
; CHECK-NEXT:    [[WEI_P2:%.*]] = getelementptr <3 x i32>, ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i64 24
; CHECK-NEXT:    store <3 x i32> [[WEI32]], ptr addrspace(3) [[WEI_P2]], align 64
; CHECK-NEXT:    call void @llvm.amdgcn.s.sema.signal(ptr addrspace(3) @sem1)
; CHECK-NEXT:    ret void
;
entry:
  %vec30 = load <3 x i32>, ptr addrspace(1) %inbuf, align 16
  %ld.p1 = getelementptr <3 x i32>, ptr addrspace(1) %inbuf, i64 16
  %vec31 = load <3 x i32>, ptr addrspace(1) %ld.p1, align 16
  %ld.p2 = getelementptr <3 x i32>, ptr addrspace(1) %inbuf, i64 32
  %vec32 = load <3 x i32>, ptr addrspace(1) %ld.p2, align 16

  %wei30 = load <3 x i32>, ptr addrspace(1) %wbuf, align 64
  %w.p1 = getelementptr <3 x i32>, ptr addrspace(1) %wbuf, i64 16
  %wei31 = load <3 x i32>, ptr addrspace(1) %w.p1, align 16
  %w.p2 = getelementptr <3 x i32>, ptr addrspace(1) %wbuf, i64 32
  %wei32 = load <3 x i32>, ptr addrspace(1) %w.p2, align 16

  store <3 x i32> %vec30, ptr addrspace(3) @col_center, align 16
  store <3 x i32> %vec31, ptr addrspace(3) @col_left, align 16
  store <3 x i32> %vec32, ptr addrspace(3) @col_right, align 16

  store <3 x i32> %wei30, ptr addrspace(3) @weights, align 64
  %wei.p1 = getelementptr <3 x i32>, ptr addrspace(3) @weights, i64 12
  store <3 x i32> %wei31, ptr addrspace(3) %wei.p1, align 64
  %wei.p2 = getelementptr <3 x i32>, ptr addrspace(3) @weights, i64 24
  store <3 x i32> %wei32, ptr addrspace(3) %wei.p2, align 64

  call void @llvm.amdgcn.s.sema.signal(ptr addrspace(3) @sem1)
  ret void
}

define private amdgpu_kernel void @compute(ptr addrspace(1) %inbuf, ptr addrspace(1) %wbuf, ptr addrspace(1) %outbuf) #0 #1 {
; CHECK-LABEL: define private amdgpu_kernel void @compute(
; CHECK-SAME: ptr addrspace(1) [[INBUF:%.*]], ptr addrspace(1) [[WBUF:%.*]], ptr addrspace(1) [[OUTBUF:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @llvm.amdgcn.s.sema.wait(ptr addrspace(3) @sem1)
; CHECK-NEXT:    [[VEC30:%.*]] = load <3 x i32>, ptr addrspace(3) getelementptr inbounds ([[LLVM_AMDGCN_KERNEL_MAIN_LDS_T:%.*]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i32 0, i32 1), align 64
; CHECK-NEXT:    [[VEC31:%.*]] = load <3 x i32>, ptr addrspace(3) getelementptr inbounds ([[LLVM_AMDGCN_KERNEL_MAIN_LDS_T]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i32 0, i32 2), align 16
; CHECK-NEXT:    [[VEC32:%.*]] = load <3 x i32>, ptr addrspace(3) getelementptr inbounds ([[LLVM_AMDGCN_KERNEL_MAIN_LDS_T]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i32 0, i32 3), align 32
; CHECK-NEXT:    [[WEI:%.*]] = load <9 x i32>, ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, align 64
; CHECK-NEXT:    [[TMP0:%.*]] = tail call contract <8 x half> @llvm.amdgcn.convolve.f16.fp8.fp8.3x3.v8f16.v8f16.v9i32.v3i32(<8 x half> zeroinitializer, <9 x i32> [[WEI]], <3 x i32> [[VEC30]], <3 x i32> [[VEC31]], <3 x i32> [[VEC32]], i32 42, i1 true)
; CHECK-NEXT:    store <8 x half> [[TMP0]], ptr addrspace(3) getelementptr inbounds ([[LLVM_AMDGCN_KERNEL_MAIN_LDS_T]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i32 0, i32 4), align 16, !tbaa [[TBAA3:![0-9]+]]
; CHECK-NEXT:    call void @llvm.amdgcn.s.sema.signal(ptr addrspace(3) @sem2)
; CHECK-NEXT:    ret void
;
entry:
  call void @llvm.amdgcn.s.sema.wait(ptr addrspace(3) @sem1)
  %vec30 = load <3 x i32>, ptr addrspace(3) @col_center, align 16
  %vec31 = load <3 x i32>, ptr addrspace(3) @col_left, align 16
  %vec32 = load <3 x i32>, ptr addrspace(3) @col_right, align 16
  %wei = load <9 x i32>, ptr addrspace(3) @weights, align 64
  %0 = tail call contract <8 x half> @llvm.amdgcn.convolve.f16.fp8.fp8.3x3.v8f16.v8f16.v9i32.v3i32(<8 x half> zeroinitializer, <9 x i32> %wei, <3 x i32> %vec30, <3 x i32> %vec31, <3 x i32> %vec32, i32 42, i1 true)
  store <8 x half> %0, ptr addrspace(3) @out, align 16, !tbaa !4
  call void @llvm.amdgcn.s.sema.signal(ptr addrspace(3) @sem2)
  ret void
}

define private amdgpu_kernel void @output(ptr addrspace(1) %inbuf, ptr addrspace(1) %wbuf, ptr addrspace(1) %outbuf) #0 #1 {
; CHECK-LABEL: define private amdgpu_kernel void @output(
; CHECK-SAME: ptr addrspace(1) [[INBUF:%.*]], ptr addrspace(1) [[WBUF:%.*]], ptr addrspace(1) [[OUTBUF:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @llvm.amdgcn.s.sema.wait(ptr addrspace(3) @sem2)
; CHECK-NEXT:    [[TMP0:%.*]] = load <8 x half>, ptr addrspace(3) getelementptr inbounds ([[LLVM_AMDGCN_KERNEL_MAIN_LDS_T:%.*]], ptr addrspace(3) @llvm.amdgcn.kernel.main.lds, i32 0, i32 4), align 16
; CHECK-NEXT:    store <8 x half> [[TMP0]], ptr addrspace(1) [[OUTBUF]], align 16
; CHECK-NEXT:    ret void
;
entry:
  call void @llvm.amdgcn.s.sema.wait(ptr addrspace(3) @sem2)
  %0 = load <8 x half>, ptr addrspace(3) @out, align 16
  store <8 x half> %0, ptr addrspace(1) %outbuf, align 16
  ret void
}

; Function Attrs: convergent mustprogress nofree norecurse nosync nounwind memory(readwrite, argmem: none, inaccessiblemem: none)
define amdgpu_kernel void @main(ptr addrspace(1) %inbuf, ptr addrspace(1) %wbuf, ptr addrspace(1) %outbuf) #0 !reqd_work_group_size !{i32 32, i32 12, i32 1} {
; CHECK-LABEL: define amdgpu_kernel void @main(
; CHECK-SAME: ptr addrspace(1) [[INBUF:%.*]], ptr addrspace(1) [[WBUF:%.*]], ptr addrspace(1) [[OUTBUF:%.*]]) #[[ATTR1:[0-9]+]] !reqd_work_group_size [[META6:![0-9]+]] {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    call void @llvm.donothing() [ "ExplicitUse"(ptr addrspace(3) @llvm.amdgcn.kernel.main.lds) ], !alias.scope [[META7:![0-9]+]], !noalias [[META10:![0-9]+]]
; CHECK-NEXT:    call void @llvm.amdgcn.wavegroup.rank.p0(i32 0, ptr @input)
; CHECK-NEXT:    call void @llvm.amdgcn.wavegroup.rank.p0(i32 1, ptr @compute)
; CHECK-NEXT:    call void @llvm.amdgcn.wavegroup.rank.p0(i32 2, ptr @output)
; CHECK-NEXT:    ret void
;
entry:
  call void @llvm.amdgcn.wavegroup.rank(i32 0, ptr @input)
  call void @llvm.amdgcn.wavegroup.rank(i32 1, ptr @compute)
  call void @llvm.amdgcn.wavegroup.rank(i32 2, ptr @output)
  ret void
}

; Function Attrs: convergent nounwind
declare !callback !38 void @llvm.amdgcn.wavegroup.rank.p0(i32 immarg, ptr) #2

attributes #0 = { mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: readwrite) "amdgpu-agpr-alloc"="0" "amdgpu-flat-work-group-size"="1,1024" "amdgpu-no-cluster-id-x" "amdgpu-no-cluster-id-y" "amdgpu-no-cluster-id-z" "amdgpu-no-completion-action" "amdgpu-no-default-queue" "amdgpu-no-dispatch-id" "amdgpu-no-dispatch-ptr" "amdgpu-no-flat-scratch-init" "amdgpu-no-heap-ptr" "amdgpu-no-hostcall-ptr" "amdgpu-no-implicitarg-ptr" "amdgpu-no-lds-kernel-id" "amdgpu-no-multigrid-sync-arg" "amdgpu-no-queue-ptr" "amdgpu-no-workgroup-id-x" "amdgpu-no-workgroup-id-y" "amdgpu-no-workgroup-id-z" "amdgpu-no-workitem-id-x" "amdgpu-no-workitem-id-y" "amdgpu-no-workitem-id-z" "amdgpu-wavegroup-enable" "amdgpu-waves-per-eu"="8,16" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx1300" "target-features"="+16-bit-insts,+ashr-pk-insts,+atomic-buffer-global-pk-add-f16-insts,+atomic-buffer-pk-add-bf16-inst,+atomic-ds-pk-add-16-insts,+atomic-fadd-rtn-insts,+atomic-flat-pk-add-16-insts,+atomic-global-pk-add-bf16-inst,+bf16-cvt-insts,+bf16-pk-insts,+bf16-trans-insts,+bitop3-insts,+ci-insts,+dl-insts,+dot7-insts,+dot8-insts,+dpp,+f16bf16-to-fp6bf6-cvt-scale-insts,+f32-to-f16bf16-cvt-sr-insts,+fp8-conversion-insts,+fp8e5m3-insts,+gfx10-3-insts,+gfx10-insts,+gfx11-insts,+gfx12-insts,+gfx1250-insts,+gfx1251-gemm-insts,+gfx13-insts,+gfx8-insts,+gfx9-insts,+parallel-bit-insts,+permlane16-swap,+prng-inst,+tanh-insts,+tensor-cvt-lut-insts,+transpose-load-f4f6-insts,+vmem-pref-insts,+wavefrontsize32" "uniform-work-group-size"="true" }
attributes #1 = { "amdgpu-wavegroup-rank-function" }
attributes #2 = { convergent nounwind }

; Function Attrs: convergent mustprogress nocallback nofree nosync nounwind willreturn memory(none)
declare <8 x half> @llvm.amdgcn.convolve.f16.fp8.fp8.3x3.v8f16.v8f16.v9i32.v3i32(<8 x half>, <9 x i32>, <3 x i32>, <3 x i32>, <3 x i32>, i32 immarg, i1 immarg) #1

!4 = !{!5, !5, i64 0}
!5 = !{!"omnipotent char", !6, i64 0}
!6 = !{!"Simple C++ TBAA"}
!38 = !{!39}
!39 = !{i64 1, i1 false}


; GV: ![[SEMADDR1]] = !{i64 8392976, i64 8392977}
; GV: ![[SEMADDR2]] = !{i64 8393232, i64 8393233}
; GV: ![[LDSSTRUCT]] = !{i64 0, i64 1}
; CHECK: [[TBAA3]] = !{[[META4:![0-9]+]], [[META4]], i64 0}
; CHECK: [[META4]] = !{!"omnipotent char", [[META5:![0-9]+]], i64 0}
; CHECK: [[META5]] = !{!"Simple C++ TBAA"}
; CHECK: [[META6]] = !{i32 32, i32 12, i32 1}
; CHECK: [[META7]] = !{[[META8:![0-9]+]]}
; CHECK: [[META8]] = distinct !{[[META8]], [[META9:![0-9]+]]}
; CHECK: [[META9]] = distinct !{[[META9]]}
; CHECK: [[META10]] = !{[[META11:![0-9]+]], [[META12:![0-9]+]], [[META13:![0-9]+]], [[META14:![0-9]+]]}
; CHECK: [[META11]] = distinct !{[[META11]], [[META9]]}
; CHECK: [[META12]] = distinct !{[[META12]], [[META9]]}
; CHECK: [[META13]] = distinct !{[[META13]], [[META9]]}
; CHECK: [[META14]] = distinct !{[[META14]], [[META9]]}
;.
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; GV: {{.*}}
