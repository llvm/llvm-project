; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -march=amdgcn -mcpu=gfx1100 -verify-machineinstrs < %s | FileCheck -check-prefixes=GCN,GFX11 %s

; TODO-GFX12: Codegen changes needed on GFX12 to handle the lack of immediate soffset.
; XUN: llc -march=amdgcn -mcpu=gfx1200 -verify-machineinstrs < %s | FileCheck -check-prefixes=GCN,GFX12 %s

define amdgpu_cs void @mixed_vmem_types(i32 inreg %globalTable, i32 inreg %perShaderTable, i32 inreg %descTable0, i32 inreg %descTable1, <3 x i32> inreg %WorkgroupId, i32 inreg %MultiDispatchInfo, <3 x i32> %LocalInvocationId) #0 {
; GCN-LABEL: mixed_vmem_types:
; GCN:       ; %bb.0: ; %.entry
; GCN-NEXT:    s_getpc_b64 s[4:5]
; GCN-NEXT:    s_mov_b32 s0, s3
; GCN-NEXT:    s_mov_b32 s1, s5
; GCN-NEXT:    s_mov_b32 s3, s5
; GCN-NEXT:    s_clause 0x2
; GCN-NEXT:    s_load_b128 s[28:31], s[0:1], 0x0
; GCN-NEXT:    s_load_b256 s[4:11], s[0:1], 0x10
; GCN-NEXT:    s_load_b128 s[44:47], s[0:1], 0x30
; GCN-NEXT:    s_clause 0x2
; GCN-NEXT:    s_load_b256 s[12:19], s[2:3], 0x40
; GCN-NEXT:    s_load_b256 s[20:27], s[2:3], 0x0
; GCN-NEXT:    s_load_b256 s[36:43], s[2:3], 0x20
; GCN-NEXT:    v_mov_b32_e32 v0, 0xbc00bc00
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GCN-NEXT:    image_sample_lz v1, v0, s[4:11], s[28:31] dmask:0x1 dim:SQ_RSRC_IMG_2D a16
; GCN-NEXT:    buffer_load_b32 v2, off, s[44:47], 0
; GCN-NEXT:    buffer_load_b32 v3, off, s[12:15], 0
; GCN-NEXT:    buffer_load_b32 v4, off, s[24:27], 0
; GCN-NEXT:    image_sample_lz v0, v0, s[36:43], s[20:23] dmask:0x1 dim:SQ_RSRC_IMG_2D a16
; GFX11-NEXT:    s_waitcnt vmcnt(4)
; GFX12-NEXT:    s_wait_samplecnt 0x1
; GCN-NEXT:    v_cmp_eq_f32_e32 vcc_lo, 1.0, v1
; GFX11-NEXT:    s_waitcnt vmcnt(3)
; GFX12-NEXT:    s_wait_loadcnt 0x2
; GCN-NEXT:    v_cmp_eq_u32_e64 s0, 0xac0, v2
; GFX11-NEXT:    s_waitcnt vmcnt(2)
; GFX12-NEXT:    s_wait_loadcnt 0x1
; GCN-NEXT:    v_cmp_eq_u32_e64 s1, 0xac0, v3
; GFX11-NEXT:    s_waitcnt vmcnt(1)
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GCN-NEXT:    v_cmp_eq_u32_e64 s2, 0xac0, v4
; GCN-NEXT:    s_and_b32 s0, s0, vcc_lo
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GCN-NEXT:    v_cmp_eq_f32_e32 vcc_lo, 0, v0
; GCN-NEXT:    s_and_b32 s0, s0, s1
; GCN-NEXT:    s_delay_alu instid0(SALU_CYCLE_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GCN-NEXT:    s_and_b32 s0, s0, s2
; GCN-NEXT:    s_and_b32 s0, s0, vcc_lo
; GCN-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GCN-NEXT:    v_cndmask_b32_e64 v0, 0, 1, s0
; GCN-NEXT:    buffer_store_b32 v0, off, s[16:19], 0
; GCN-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GCN-NEXT:    s_endpgm
.entry:
  %0 = call i64 @llvm.amdgcn.s.getpc()
  %extelt.offset = lshr i64 %0, 32
  %.i1 = trunc i64 %extelt.offset to i32
  %.upto0 = insertelement <2 x i32> poison, i32 %descTable1, i64 0
  %1 = insertelement <2 x i32> %.upto0, i32 %.i1, i64 1
  %2 = bitcast <2 x i32> %1 to i64
  %3 = inttoptr i64 %2 to i8 addrspace(4)*
  %.upto03 = insertelement <2 x i32> poison, i32 %descTable0, i64 0
  %4 = insertelement <2 x i32> %.upto03, i32 %.i1, i64 1
  %5 = bitcast <2 x i32> %4 to i64
  %6 = inttoptr i64 %5 to i8 addrspace(4)*
  %7 = getelementptr i8, i8 addrspace(4)* %6, i64 80
  %8 = bitcast i8 addrspace(4)* %7 to <4 x i32> addrspace(4)*
  %9 = load <4 x i32>, <4 x i32> addrspace(4)* %8, align 16
  %10 = getelementptr i8, i8 addrspace(4)* %3, i64 48
  %11 = bitcast i8 addrspace(4)* %10 to <4 x i32> addrspace(4)*
  %12 = load <4 x i32>, <4 x i32> addrspace(4)* %11, align 16
  %13 = getelementptr i8, i8 addrspace(4)* %6, i64 64
  %14 = bitcast i8 addrspace(4)* %13 to <4 x i32> addrspace(4)*
  %15 = load <4 x i32>, <4 x i32> addrspace(4)* %14, align 16
  %16 = getelementptr i8, i8 addrspace(4)* %6, i64 16
  %17 = bitcast i8 addrspace(4)* %16 to <4 x i32> addrspace(4)*
  %18 = load <4 x i32>, <4 x i32> addrspace(4)* %17, align 16
  %19 = getelementptr i8, i8 addrspace(4)* %6, i64 32
  %20 = bitcast i8 addrspace(4)* %19 to <8 x i32> addrspace(4)*
  %21 = load <8 x i32>, <8 x i32> addrspace(4)* %20, align 32
  %22 = bitcast i8 addrspace(4)* %6 to <4 x i32> addrspace(4)*
  %23 = load <4 x i32>, <4 x i32> addrspace(4)* %22, align 16
  %24 = call float @llvm.amdgcn.image.sample.lz.2d.f32.f16(i32 1, half 0xHBC00, half 0xHBC00, <8 x i32> %21, <4 x i32> %23, i1 false, i32 0, i32 0)
  %25 = fcmp oeq float %24, 0.000000e+00
  %26 = call i32 @llvm.amdgcn.raw.buffer.load.i32(<4 x i32> %18, i32 0, i32 0, i32 0)
  %.not = icmp eq i32 %26, 2752
  %27 = call i32 @llvm.amdgcn.raw.buffer.load.i32(<4 x i32> %15, i32 0, i32 0, i32 0)
  %.not1 = icmp eq i32 %27, 2752
  %28 = getelementptr i8, i8 addrspace(4)* %3, i64 16
  %29 = bitcast i8 addrspace(4)* %28 to <8 x i32> addrspace(4)*
  %30 = load <8 x i32>, <8 x i32> addrspace(4)* %29, align 32
  %31 = bitcast i8 addrspace(4)* %3 to <4 x i32> addrspace(4)*
  %32 = load <4 x i32>, <4 x i32> addrspace(4)* %31, align 16
  %33 = call float @llvm.amdgcn.image.sample.lz.2d.f32.f16(i32 1, half 0xHBC00, half 0xHBC00, <8 x i32> %30, <4 x i32> %32, i1 false, i32 0, i32 0)
  %34 = fcmp oeq float %33, 1.000000e+00
  %35 = call i32 @llvm.amdgcn.raw.buffer.load.i32(<4 x i32> %12, i32 0, i32 0, i32 0)
  %.not2 = icmp eq i32 %35, 2752
  %36 = select i1 %.not2, i1 %34, i1 false
  %37 = select i1 %36, i1 %.not1, i1 false
  %38 = select i1 %37, i1 %.not, i1 false
  %narrow2 = select i1 %38, i1 %25, i1 false
  %.4 = zext i1 %narrow2 to i32
  call void @llvm.amdgcn.raw.buffer.store.i32(i32 %.4, <4 x i32> %9, i32 0, i32 0, i32 0)
  ret void
}

declare <4 x float> @llvm.amdgcn.image.sample.l.2d.v4f32.f32(i32 immarg, float, float, float, <8 x i32>, <4 x i32>, i1 immarg, i32 immarg, i32 immarg) #1
declare i8 addrspace(7)* @lgc.late.launder.fat.pointer(<4 x i32>) #2
declare i64 @llvm.amdgcn.s.getpc() #3
declare <4 x float> @llvm.amdgcn.image.sample.lz.2d.v4f32.f32(i32 immarg, float, float, <8 x i32>, <4 x i32>, i1 immarg, i32 immarg, i32 immarg) #1
declare <4 x float> @llvm.amdgcn.image.sample.lz.2d.v4f32.f16(i32 immarg, half, half, <8 x i32>, <4 x i32>, i1 immarg, i32 immarg, i32 immarg) #1
declare float @llvm.amdgcn.image.sample.lz.2d.f32.f16(i32 immarg, half, half, <8 x i32>, <4 x i32>, i1 immarg, i32 immarg, i32 immarg) #1
declare i32 @llvm.amdgcn.raw.buffer.load.i32(<4 x i32>, i32, i32, i32 immarg) #1
declare void @llvm.amdgcn.raw.buffer.store.i32(i32, <4 x i32>, i32, i32, i32 immarg) #4

attributes #0 = { nounwind }
attributes #1 = { nounwind willreturn memory(read) }
attributes #2 = { nounwind memory(none) }
attributes #3 = { nounwind speculatable willreturn memory(none) }
attributes #4 = { nounwind willreturn memory(write) }
