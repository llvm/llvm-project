; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx1300 -verify-machineinstrs -o - %s | FileCheck %s

target datalayout = "A5"

@large_shared_vgpr = linkonce_odr hidden local_unnamed_addr addrspace(10) global [768 x i32] zeroinitializer, align 16

; Function Attrs: convergent mustprogress nofree norecurse nounwind
define protected amdgpu_kernel void @test_large_shared_vgpr(ptr addrspace(1) noundef readonly captures(none) %0, ptr addrspace(1) noundef writeonly captures(none) %1) local_unnamed_addr #11 !reqd_work_group_size !13 {
; CHECK-LABEL: test_large_shared_vgpr:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    s_getreg_b32 s3, hwreg(HW_REG_WAVE_GROUP_INFO, 16, 4)
; CHECK-NEXT:    s_delay_alu instid0(SALU_CYCLE_1) | instskip(SKIP_2) | instid1(SALU_CYCLE_1)
; CHECK-NEXT:    s_mul_i32 s4, s3, 3
; CHECK-NEXT:    s_mul_i32 s33, s3, s2
; CHECK-NEXT:    s_add_co_u32 s4, s4, 0x300
; CHECK-NEXT:    s_set_gpr_idx_u32 idx0, s4
; CHECK-NEXT:    ; sched_barrier mask(0x00000000)
; CHECK-NEXT:    s_bfe_u32 s2, ttmp6, 0x4000c
; CHECK-NEXT:    s_and_b32 s4, ttmp6, 15
; CHECK-NEXT:    s_add_co_i32 s2, s2, 1
; CHECK-NEXT:    s_getreg_b32 s5, hwreg(HW_REG_WAVE_GROUP_INFO, 0, 4)
; CHECK-NEXT:    s_mul_i32 s2, ttmp9, s2
; CHECK-NEXT:    s_bfe_u32 s3, ttmp8, 0x20019
; CHECK-NEXT:    s_add_co_i32 s4, s4, s2
; CHECK-NEXT:    s_cmp_eq_u32 s5, 0
; CHECK-NEXT:    v_mbcnt_lo_u32_b32 v0, -1, 0
; CHECK-NEXT:    s_cselect_b32 s2, ttmp9, s4
; CHECK-NEXT:    s_lshl_b32 s3, s3, 5
; CHECK-NEXT:    s_lshl_b32 s2, s2, 7
; CHECK-NEXT:    v_mov_b32_e32 v1, -1
; CHECK-NEXT:    v_or3_b32 v0, s2, s3, v0
; CHECK-NEXT:    s_mov_b32 s2, exec_lo
; CHECK-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; CHECK-NEXT:    v_cmpx_gt_u32_e32 0x300, v0
; CHECK-NEXT:    s_cbranch_execz .LBB0_4
; CHECK-NEXT:  ; %bb.1:
; CHECK-NEXT:    v_lshlrev_b32_e32 v2, 2, v0
; CHECK-NEXT:    s_mov_b32 s3, exec_lo
; CHECK-NEXT:  .LBB0_2: ; =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1)
; CHECK-NEXT:    v_readfirstlane_b32 s4, v2
; CHECK-NEXT:    v_cmp_eq_u32_e32 vcc_lo, s4, v2
; CHECK-NEXT:    s_and_saveexec_b32 vcc_lo, vcc_lo
; CHECK-NEXT:    s_lshr_b32 s4, s4, 2
; CHECK-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; CHECK-NEXT:    s_set_gpr_idx_u32 idx1, s4
; CHECK-NEXT:    s_set_vgpr_frames 1 ; vsrc0_idx=1 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    v_mov_b32_e32 v1, g1[0]
; CHECK-NEXT:    s_xor_b32 exec_lo, exec_lo, vcc_lo
; CHECK-NEXT:    s_set_vgpr_frames 0 ; vsrc0_idx=0 vsrc1_idx=0 vsrc2_idx=0 vdst_idx=0 vsrc0_msb=0 vsrc1_msb=0 vsrc2_msb=0 vdst_msb=0
; CHECK-NEXT:    s_cbranch_execnz .LBB0_2
; CHECK-NEXT:  ; %bb.3:
; CHECK-NEXT:    s_mov_b32 exec_lo, s3
; CHECK-NEXT:  .LBB0_4: ; %.sink.split
; CHECK-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; CHECK-NEXT:    s_or_b32 exec_lo, exec_lo, s2
; CHECK-NEXT:    s_load_b64 s[0:1], s[0:1], 0x8
; CHECK-NEXT:    s_wait_kmcnt 0x0
; CHECK-NEXT:    global_store_b32 v0, v1, s[0:1] scale_offset scope:SCOPE_SE
; CHECK-NEXT:    s_endpgm
entry:
  %2 = tail call i32 @llvm.amdgcn.workgroup.id.x()
  %3 = tail call i32 @llvm.amdgcn.wavegroup.id()
  %4 = tail call i32 @llvm.amdgcn.mbcnt.lo(i32 -1, i32 0)
  %5 = shl i32 %2, 7
  %6 = shl i32 %3, 5
  %7 = add i32 %5, %6
  %8 = add i32 %7, %4
  %9 = icmp ult i32 %8, 768
  br i1 %9, label %10, label %.sink.split

10:                                               ; preds = %entry
  %11 = getelementptr inbounds nuw [768 x i32], ptr addrspace(10) @large_shared_vgpr, i32 0, i32 %8
  %12 = load i32, ptr addrspace(10) %11, align 4
  br label %.sink.split

.sink.split:                                      ; preds = %10, %entry
  %.sink = phi i32 [ %12, %10 ], [ -1, %entry ]
  %13 = zext i32 %8 to i64
  %14 = getelementptr inbounds nuw i32, ptr addrspace(1) %1, i64 %13
  store i32 %.sink, ptr addrspace(1) %14, align 4
  ret void
}

attributes #11 = { convergent mustprogress nofree norecurse nounwind "amdgpu-agpr-alloc"="0" "amdgpu-flat-work-group-size"="256,256" "amdgpu-no-cluster-id-x" "amdgpu-no-cluster-id-y" "amdgpu-no-cluster-id-z" "amdgpu-no-completion-action" "amdgpu-no-default-queue" "amdgpu-no-dispatch-id" "amdgpu-no-dispatch-ptr" "amdgpu-no-flat-scratch-init" "amdgpu-no-heap-ptr" "amdgpu-no-hostcall-ptr" "amdgpu-no-implicitarg-ptr" "amdgpu-no-lds-kernel-id" "amdgpu-no-multigrid-sync-arg" "amdgpu-no-queue-ptr" "amdgpu-no-workgroup-id-x" "amdgpu-no-workgroup-id-y" "amdgpu-no-workgroup-id-z" "amdgpu-no-workitem-id-x" "amdgpu-no-workitem-id-y" "amdgpu-no-workitem-id-z" "amdgpu-wavegroup-enable" "amdgpu-waves-per-eu"="2,16" "approx-func-fp-math"="true" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx1301" "target-features"="+16-bit-insts,+ashr-pk-insts,+atomic-buffer-global-pk-add-f16-insts,+atomic-buffer-pk-add-bf16-inst,+atomic-ds-pk-add-16-insts,+atomic-fadd-rtn-insts,+atomic-flat-pk-add-16-insts,+atomic-global-pk-add-bf16-inst,+bf16-cvt-insts,+bf16-pk-insts,+bf16-trans-insts,+bitop3-insts,+ci-insts,+dl-insts,+dot7-insts,+dot8-insts,+dpp,+f16bf16-to-fp6bf6-cvt-scale-insts,+f32-to-f16bf16-cvt-sr-insts,+fp8-conversion-insts,+fp8e5m3-insts,+gfx10-3-insts,+gfx10-insts,+gfx11-insts,+gfx12-insts,+gfx1250-insts,+gfx1251-gemm-insts,+gfx13-insts,+gfx8-insts,+gfx9-insts,+parallel-bit-insts,+permlane16-swap,+prng-inst,+tanh-insts,+tensor-cvt-lut-insts,+transpose-load-f4f6-insts,+wavefrontsize32" "uniform-work-group-size"="true" "unsafe-fp-math"="true" }

!13 = !{i32 256, i32 1, i32 1}
