; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature
; RUN: opt -mtriple=amdgcn-amd-amdhsa -mcpu=gfx940 -amdgpu-attributor -amdgpu-lower-kernel-arguments -S < %s | FileCheck -check-prefix=NO-PRELOAD %s
; RUN: opt -mtriple=amdgcn-amd-amdhsa -mcpu=gfx940 -amdgpu-attributor -amdgpu-lower-kernel-arguments -amdgpu-kernarg-preload-count=2 -S < %s | FileCheck -check-prefix=PRELOAD-2 %s
; RUN: opt -mtriple=amdgcn-amd-amdhsa -mcpu=gfx940 -amdgpu-attributor -amdgpu-lower-kernel-arguments -amdgpu-kernarg-preload-count=100 -S < %s | FileCheck -check-prefix=PRELOAD-ALL %s

define amdgpu_kernel void @ptr1_ptr1_kernel(ptr addrspace(1) %in, ptr addrspace(1) %out) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_ptr1_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[IN:%.*]], ptr addrspace(1) [[OUT:%.*]]) #[[ATTR0:[0-9]+]] {
; NO-PRELOAD-NEXT:    [[PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0:![0-9]+]]
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_ptr1_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[OUT:%.*]]) #[[ATTR0:[0-9]+]] {
; PRELOAD-2-NEXT:    [[PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_ptr1_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[OUT:%.*]]) #[[ATTR0:[0-9]+]] {
; PRELOAD-ALL-NEXT:    [[PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %load = load i32, ptr addrspace(1) %in
  store i32 %load, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_ptr1_ptr1_ptr1_kernel(ptr addrspace(1) %in, ptr addrspace(1) %in1, ptr addrspace(1) %out, ptr addrspace(1) %out1) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[IN:%.*]], ptr addrspace(1) [[IN1:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 24
; NO-PRELOAD-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN_LOAD]], align 4
; NO-PRELOAD-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0:![0-9]+]]
; PRELOAD-2-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 24
; PRELOAD-2-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-2-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(1) inreg [[OUT1:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-ALL-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %load = load i32, ptr addrspace(1) %in
  %load1 = load i32, ptr addrspace(1) %in1
  store i32 %load, ptr addrspace(1) %out
  store i32 %load1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_kernel void @ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_kernel(ptr addrspace(1) %in, ptr addrspace(1) %in1, ptr addrspace(1) %in2, ptr addrspace(1) %in3, ptr addrspace(1) %out, ptr addrspace(1) %out1, ptr addrspace(1) %out2, ptr addrspace(1) %out3) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[IN:%.*]], ptr addrspace(1) [[IN1:%.*]], ptr addrspace(1) [[IN2:%.*]], ptr addrspace(1) [[IN3:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]], ptr addrspace(1) [[OUT2:%.*]], ptr addrspace(1) [[OUT3:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[IN2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN3_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 24
; NO-PRELOAD-NEXT:    [[IN3_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN3_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 32
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 40
; NO-PRELOAD-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 48
; NO-PRELOAD-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT3_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 56
; NO-PRELOAD-NEXT:    [[OUT3_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT3_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN_LOAD]], align 4
; NO-PRELOAD-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1_LOAD]], align 4
; NO-PRELOAD-NEXT:    [[LOAD2:%.*]] = load i32, ptr addrspace(1) [[IN2_LOAD]], align 4
; NO-PRELOAD-NEXT:    [[LOAD3:%.*]] = load i32, ptr addrspace(1) [[IN3_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD2]], ptr addrspace(1) [[OUT2_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD3]], ptr addrspace(1) [[OUT3_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) [[IN2:%.*]], ptr addrspace(1) [[IN3:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]], ptr addrspace(1) [[OUT2:%.*]], ptr addrspace(1) [[OUT3:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[IN2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[IN3_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 24
; PRELOAD-2-NEXT:    [[IN3_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN3_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 32
; PRELOAD-2-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 40
; PRELOAD-2-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 48
; PRELOAD-2-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT3_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 56
; PRELOAD-2-NEXT:    [[OUT3_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT3_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-2-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-2-NEXT:    [[LOAD2:%.*]] = load i32, ptr addrspace(1) [[IN2_LOAD]], align 4
; PRELOAD-2-NEXT:    [[LOAD3:%.*]] = load i32, ptr addrspace(1) [[IN3_LOAD]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD2]], ptr addrspace(1) [[OUT2_LOAD]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD3]], ptr addrspace(1) [[OUT3_LOAD]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_ptr1_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) inreg [[IN2:%.*]], ptr addrspace(1) inreg [[IN3:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(1) inreg [[OUT1:%.*]], ptr addrspace(1) inreg [[OUT2:%.*]], ptr addrspace(1) inreg [[OUT3:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[OUT3_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_PTR1_KERNEL_KERNARG_SEGMENT]], i64 56
; PRELOAD-ALL-NEXT:    [[OUT3_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT3_KERNARG_OFFSET]], align 8, !invariant.load [[META0:![0-9]+]]
; PRELOAD-ALL-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-ALL-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-ALL-NEXT:    [[LOAD2:%.*]] = load i32, ptr addrspace(1) [[IN2]], align 4
; PRELOAD-ALL-NEXT:    [[LOAD3:%.*]] = load i32, ptr addrspace(1) [[IN3]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD2]], ptr addrspace(1) [[OUT2]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD3]], ptr addrspace(1) [[OUT3_LOAD]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %load = load i32, ptr addrspace(1) %in
  %load1 = load i32, ptr addrspace(1) %in1
  %load2 = load i32, ptr addrspace(1) %in2
  %load3 = load i32, ptr addrspace(1) %in3
  store i32 %load, ptr addrspace(1) %out
  store i32 %load1, ptr addrspace(1) %out1
  store i32 %load2, ptr addrspace(1) %out2
  store i32 %load3, ptr addrspace(1) %out3
  ret void
}

define amdgpu_kernel void @ptr1_ptr1_ptr1_ptr1_inreg_offset_kernel(ptr addrspace(1) %in, ptr addrspace(1) %in1, ptr addrspace(1) %out, ptr addrspace(1) %out1) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_inreg_offset_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[IN:%.*]], ptr addrspace(1) [[IN1:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT]], i64 24
; NO-PRELOAD-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN_LOAD]], align 4
; NO-PRELOAD-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_inreg_offset_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT]], i64 24
; PRELOAD-2-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-2-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_inreg_offset_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(1) inreg [[OUT1:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-ALL-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %load = load i32, ptr addrspace(1) %in
  %load1 = load i32, ptr addrspace(1) %in1
  store i32 %load, ptr addrspace(1) %out
  store i32 %load1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_kernel void @ptr1_ptr1_ptr1_ptr1_inreg_offset_two_sequence_kernel(ptr addrspace(1) %in, ptr addrspace(1) %in1, ptr addrspace(1) %out, ptr addrspace(1) %out1) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_inreg_offset_two_sequence_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[IN:%.*]], ptr addrspace(1) [[IN1:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT]], i64 24
; NO-PRELOAD-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN_LOAD]], align 4
; NO-PRELOAD-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_inreg_offset_two_sequence_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT]], i64 24
; PRELOAD-2-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-2-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_ptr1_ptr1_ptr1_inreg_offset_two_sequence_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(1) inreg [[OUT1:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_PTR1_PTR1_PTR1_INREG_OFFSET_TWO_SEQUENCE_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-ALL-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %load = load i32, ptr addrspace(1) %in
  %load1 = load i32, ptr addrspace(1) %in1
  store i32 %load, ptr addrspace(1) %out
  store i32 %load1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_kernel void @i16_ptr1_ptr1_ptr1_ptr1_misaligned_kernel(i16 %arg0, ptr addrspace(1) %in, ptr addrspace(1) %in1, ptr addrspace(1) %out, ptr addrspace(1) %out1) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@i16_ptr1_ptr1_ptr1_ptr1_misaligned_kernel
; NO-PRELOAD-SAME: (i16 [[ARG0:%.*]], ptr addrspace(1) [[IN:%.*]], ptr addrspace(1) [[IN1:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET_ALIGN_DOWN]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[IN1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN1_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT]], i64 24
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT]], i64 32
; NO-PRELOAD-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN_LOAD]], align 4
; NO-PRELOAD-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1_LOAD]], align 4
; NO-PRELOAD-NEXT:    [[EXT:%.*]] = zext i16 [[TMP2]] to i32
; NO-PRELOAD-NEXT:    [[ADD:%.*]] = add i32 [[LOAD]], [[EXT]]
; NO-PRELOAD-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@i16_ptr1_ptr1_ptr1_ptr1_misaligned_kernel
; PRELOAD-2-SAME: (i16 inreg [[ARG0:%.*]], ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) [[IN1:%.*]], ptr addrspace(1) [[OUT:%.*]], ptr addrspace(1) [[OUT1:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[IN1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[IN1_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT]], i64 24
; PRELOAD-2-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT]], i64 32
; PRELOAD-2-NEXT:    [[OUT1_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT1_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-2-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1_LOAD]], align 4
; PRELOAD-2-NEXT:    [[EXT:%.*]] = zext i16 [[ARG0]] to i32
; PRELOAD-2-NEXT:    [[ADD:%.*]] = add i32 [[LOAD]], [[EXT]]
; PRELOAD-2-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; PRELOAD-2-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1_LOAD]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@i16_ptr1_ptr1_ptr1_ptr1_misaligned_kernel
; PRELOAD-ALL-SAME: (i16 inreg [[ARG0:%.*]], ptr addrspace(1) inreg [[IN:%.*]], ptr addrspace(1) inreg [[IN1:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(1) inreg [[OUT1:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[I16_PTR1_PTR1_PTR1_PTR1_MISALIGNED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[LOAD:%.*]] = load i32, ptr addrspace(1) [[IN]], align 4
; PRELOAD-ALL-NEXT:    [[LOAD1:%.*]] = load i32, ptr addrspace(1) [[IN1]], align 4
; PRELOAD-ALL-NEXT:    [[EXT:%.*]] = zext i16 [[ARG0]] to i32
; PRELOAD-ALL-NEXT:    [[ADD:%.*]] = add i32 [[LOAD]], [[EXT]]
; PRELOAD-ALL-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    store i32 [[LOAD1]], ptr addrspace(1) [[OUT1]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %load = load i32, ptr addrspace(1) %in
  %load1 = load i32, ptr addrspace(1) %in1
  %ext = zext i16 %arg0 to i32
  %add = add i32 %load, %ext
  store i32 %add, ptr addrspace(1) %out
  store i32 %load1, ptr addrspace(1) %out1
  ret void
}

define amdgpu_kernel void @i16_i16_ptr1_kernel(i16 %arg0, i16 %arg1, ptr addrspace(1) %out) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@i16_i16_ptr1_kernel
; NO-PRELOAD-SAME: (i16 [[ARG0:%.*]], i16 [[ARG1:%.*]], ptr addrspace(1) [[OUT:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[I16_I16_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET_ALIGN_DOWN]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[ARG1_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[TMP3:%.*]] = load i32, ptr addrspace(4) [[ARG1_KERNARG_OFFSET_ALIGN_DOWN]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP4:%.*]] = lshr i32 [[TMP3]], 16
; NO-PRELOAD-NEXT:    [[TMP5:%.*]] = trunc i32 [[TMP4]] to i16
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[EXT:%.*]] = zext i16 [[TMP2]] to i32
; NO-PRELOAD-NEXT:    [[EXT1:%.*]] = zext i16 [[TMP5]] to i32
; NO-PRELOAD-NEXT:    [[ADD:%.*]] = add i32 [[EXT]], [[EXT1]]
; NO-PRELOAD-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@i16_i16_ptr1_kernel
; PRELOAD-2-SAME: (i16 inreg [[ARG0:%.*]], i16 inreg [[ARG1:%.*]], ptr addrspace(1) [[OUT:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[I16_I16_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; PRELOAD-2-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[EXT:%.*]] = zext i16 [[ARG0]] to i32
; PRELOAD-2-NEXT:    [[EXT1:%.*]] = zext i16 [[ARG1]] to i32
; PRELOAD-2-NEXT:    [[ADD:%.*]] = add i32 [[EXT]], [[EXT1]]
; PRELOAD-2-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@i16_i16_ptr1_kernel
; PRELOAD-ALL-SAME: (i16 inreg [[ARG0:%.*]], i16 inreg [[ARG1:%.*]], ptr addrspace(1) inreg [[OUT:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[I16_I16_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[EXT:%.*]] = zext i16 [[ARG0]] to i32
; PRELOAD-ALL-NEXT:    [[EXT1:%.*]] = zext i16 [[ARG1]] to i32
; PRELOAD-ALL-NEXT:    [[ADD:%.*]] = add i32 [[EXT]], [[EXT1]]
; PRELOAD-ALL-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %ext = zext i16 %arg0 to i32
  %ext1 = zext i16 %arg1 to i32
  %add = add i32 %ext, %ext1
  store i32 %add, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_i8_kernel(ptr addrspace(1) %out, i8 %arg0) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i8_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i8 [[ARG0:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I8_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I8_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i8
; NO-PRELOAD-NEXT:    [[EXT:%.*]] = zext i8 [[TMP2]] to i32
; NO-PRELOAD-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i8_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i8 inreg [[ARG0:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[EXT:%.*]] = zext i8 [[ARG0]] to i32
; PRELOAD-2-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i8_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i8 inreg [[ARG0:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[EXT:%.*]] = zext i8 [[ARG0]] to i32
; PRELOAD-ALL-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %ext = zext i8 %arg0 to i32
  store i32 %ext, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_i8_zeroext_kernel(ptr addrspace(1) %out, i8 zeroext %arg0) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i8_zeroext_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i8 zeroext [[ARG0:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I8_ZEROEXT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I8_ZEROEXT_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I8_ZEROEXT_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i8
; NO-PRELOAD-NEXT:    [[EXT:%.*]] = zext i8 [[TMP2]] to i32
; NO-PRELOAD-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i8_zeroext_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i8 inreg zeroext [[ARG0:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I8_ZEROEXT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[EXT:%.*]] = zext i8 [[ARG0]] to i32
; PRELOAD-2-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i8_zeroext_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i8 inreg zeroext [[ARG0:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I8_ZEROEXT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[EXT:%.*]] = zext i8 [[ARG0]] to i32
; PRELOAD-ALL-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %ext = zext i8 %arg0 to i32
  store i32 %ext, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_i16_kernel(ptr addrspace(1) %out, i16 %arg0) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i16_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i16 [[ARG0:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[EXT:%.*]] = zext i16 [[TMP2]] to i32
; NO-PRELOAD-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i16_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[ARG0:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[EXT:%.*]] = zext i16 [[ARG0]] to i32
; PRELOAD-2-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i16_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[ARG0:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[EXT:%.*]] = zext i16 [[ARG0]] to i32
; PRELOAD-ALL-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %ext = zext i16 %arg0 to i32
  store i32 %ext, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_i32_kernel(ptr addrspace(1) %out, i32 %arg0) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i32_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i32 [[ARG0:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I32_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I32_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[ARG0_LOAD:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store i32 [[ARG0_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i32_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i32 inreg [[ARG0:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store i32 [[ARG0]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i32_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i32 inreg [[ARG0:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store i32 [[ARG0]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  store i32 %arg0, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @i32_ptr1_i32_kernel(i32 %arg0, ptr addrspace(1) %out, i32 %arg1) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@i32_ptr1_i32_kernel
; NO-PRELOAD-SAME: (i32 [[ARG0:%.*]], ptr addrspace(1) [[OUT:%.*]], i32 [[ARG1:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[I32_PTR1_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(20) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I32_PTR1_I32_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[ARG0_LOAD:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I32_PTR1_I32_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ARG1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I32_PTR1_I32_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[ARG1_LOAD:%.*]] = load i32, ptr addrspace(4) [[ARG1_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ADD:%.*]] = add i32 [[ARG0_LOAD]], [[ARG1_LOAD]]
; NO-PRELOAD-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@i32_ptr1_i32_kernel
; PRELOAD-2-SAME: (i32 inreg [[ARG0:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], i32 [[ARG1:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[I32_PTR1_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(20) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[ARG1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I32_PTR1_I32_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[ARG1_LOAD:%.*]] = load i32, ptr addrspace(4) [[ARG1_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[ADD:%.*]] = add i32 [[ARG0]], [[ARG1_LOAD]]
; PRELOAD-2-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@i32_ptr1_i32_kernel
; PRELOAD-ALL-SAME: (i32 inreg [[ARG0:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], i32 inreg [[ARG1:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[I32_PTR1_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(20) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[ADD:%.*]] = add i32 [[ARG0]], [[ARG1]]
; PRELOAD-ALL-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %add = add i32 %arg0, %arg1
  store i32 %add, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_i16_i16_kernel(ptr addrspace(1) %out, i16 %arg0, i16 %arg1) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i16_i16_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i16 [[ARG0:%.*]], i16 [[ARG1:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I16_I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[ARG1_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP3:%.*]] = load i32, ptr addrspace(4) [[ARG1_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP4:%.*]] = lshr i32 [[TMP3]], 16
; NO-PRELOAD-NEXT:    [[TMP5:%.*]] = trunc i32 [[TMP4]] to i16
; NO-PRELOAD-NEXT:    [[EXT:%.*]] = zext i16 [[TMP2]] to i32
; NO-PRELOAD-NEXT:    [[EXT1:%.*]] = zext i16 [[TMP5]] to i32
; NO-PRELOAD-NEXT:    [[ADD:%.*]] = add i32 [[EXT]], [[EXT1]]
; NO-PRELOAD-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i16_i16_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[ARG0:%.*]], i16 [[ARG1:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I16_I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[ARG1_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_KERNEL_KERNARG_SEGMENT]], i64 8
; PRELOAD-2-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[ARG1_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[TMP2:%.*]] = lshr i32 [[TMP1]], 16
; PRELOAD-2-NEXT:    [[TMP3:%.*]] = trunc i32 [[TMP2]] to i16
; PRELOAD-2-NEXT:    [[EXT:%.*]] = zext i16 [[ARG0]] to i32
; PRELOAD-2-NEXT:    [[EXT1:%.*]] = zext i16 [[TMP3]] to i32
; PRELOAD-2-NEXT:    [[ADD:%.*]] = add i32 [[EXT]], [[EXT1]]
; PRELOAD-2-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i16_i16_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[ARG0:%.*]], i16 inreg [[ARG1:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I16_I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[EXT:%.*]] = zext i16 [[ARG0]] to i32
; PRELOAD-ALL-NEXT:    [[EXT1:%.*]] = zext i16 [[ARG1]] to i32
; PRELOAD-ALL-NEXT:    [[ADD:%.*]] = add i32 [[EXT]], [[EXT1]]
; PRELOAD-ALL-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %ext = zext i16 %arg0 to i32
  %ext1 = zext i16 %arg1 to i32
  %add = add i32 %ext, %ext1
  store i32 %add, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_v2i8_kernel(ptr addrspace(1) %out, <2 x i8> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v2i8_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], <2 x i8> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V2I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V2I8_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V2I8_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = bitcast i16 [[TMP2]] to <2 x i8>
; NO-PRELOAD-NEXT:    store <2 x i8> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 2
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v2i8_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <2 x i8> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V2I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <2 x i8> [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v2i8_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <2 x i8> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V2I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <2 x i8> [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-ALL-NEXT:    ret void
;
  store <2 x i8> %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_byref_i32_i32_kernel(ptr addrspace(1) %out, ptr addrspace(4) byref(i32) align(256) %in.byref, i32 %after.offset) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_byref_i32_i32_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], ptr addrspace(4) byref(i32) align 256 [[IN_BYREF:%.*]], i32 [[AFTER_OFFSET:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 256 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_BYREF_BYVAL_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT]], i64 256
; NO-PRELOAD-NEXT:    [[AFTER_OFFSET_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT]], i64 260
; NO-PRELOAD-NEXT:    [[AFTER_OFFSET_LOAD:%.*]] = load i32, ptr addrspace(4) [[AFTER_OFFSET_KERNARG_OFFSET]], align 4, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN:%.*]] = load i32, ptr addrspace(4) [[IN_BYREF_BYVAL_KERNARG_OFFSET]], align 4
; NO-PRELOAD-NEXT:    store volatile i32 [[IN]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    store volatile i32 [[AFTER_OFFSET_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_byref_i32_i32_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(4) byref(i32) align 256 [[IN_BYREF:%.*]], i32 [[AFTER_OFFSET:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 256 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN_BYREF_BYVAL_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT]], i64 256
; PRELOAD-2-NEXT:    [[AFTER_OFFSET_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT]], i64 260
; PRELOAD-2-NEXT:    [[AFTER_OFFSET_LOAD:%.*]] = load i32, ptr addrspace(4) [[AFTER_OFFSET_KERNARG_OFFSET]], align 4, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[IN:%.*]] = load i32, ptr addrspace(4) [[IN_BYREF_BYVAL_KERNARG_OFFSET]], align 4
; PRELOAD-2-NEXT:    store volatile i32 [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    store volatile i32 [[AFTER_OFFSET_LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_byref_i32_i32_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(4) byref(i32) align 256 [[IN_BYREF:%.*]], i32 [[AFTER_OFFSET:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 256 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[IN_BYREF_BYVAL_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT]], i64 256
; PRELOAD-ALL-NEXT:    [[AFTER_OFFSET_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_KERNEL_KERNARG_SEGMENT]], i64 260
; PRELOAD-ALL-NEXT:    [[AFTER_OFFSET_LOAD:%.*]] = load i32, ptr addrspace(4) [[AFTER_OFFSET_KERNARG_OFFSET]], align 4, !invariant.load [[META0]]
; PRELOAD-ALL-NEXT:    [[IN:%.*]] = load i32, ptr addrspace(4) [[IN_BYREF_BYVAL_KERNARG_OFFSET]], align 4
; PRELOAD-ALL-NEXT:    store volatile i32 [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    store volatile i32 [[AFTER_OFFSET_LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %in = load i32, ptr addrspace(4) %in.byref
  store volatile i32 %in, ptr addrspace(1) %out, align 4
  store volatile i32 %after.offset, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_byref_i32_i32_staggered_kernel(ptr addrspace(1) %out, ptr addrspace(4) byref(i32) align(256) %in.byref, i32 %after.offset) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_byref_i32_i32_staggered_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], ptr addrspace(4) byref(i32) align 256 [[IN_BYREF:%.*]], i32 [[AFTER_OFFSET:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 256 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_BYREF_BYVAL_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 256
; NO-PRELOAD-NEXT:    [[AFTER_OFFSET_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 260
; NO-PRELOAD-NEXT:    [[AFTER_OFFSET_LOAD:%.*]] = load i32, ptr addrspace(4) [[AFTER_OFFSET_KERNARG_OFFSET]], align 4, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN:%.*]] = load i32, ptr addrspace(4) [[IN_BYREF_BYVAL_KERNARG_OFFSET]], align 4
; NO-PRELOAD-NEXT:    store volatile i32 [[IN]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    store volatile i32 [[AFTER_OFFSET_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_byref_i32_i32_staggered_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(4) byref(i32) align 256 [[IN_BYREF:%.*]], i32 [[AFTER_OFFSET:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 256 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN_BYREF_BYVAL_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 256
; PRELOAD-2-NEXT:    [[AFTER_OFFSET_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 260
; PRELOAD-2-NEXT:    [[AFTER_OFFSET_LOAD:%.*]] = load i32, ptr addrspace(4) [[AFTER_OFFSET_KERNARG_OFFSET]], align 4, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[IN:%.*]] = load i32, ptr addrspace(4) [[IN_BYREF_BYVAL_KERNARG_OFFSET]], align 4
; PRELOAD-2-NEXT:    store volatile i32 [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    store volatile i32 [[AFTER_OFFSET_LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_byref_i32_i32_staggered_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], ptr addrspace(4) byref(i32) align 256 [[IN_BYREF:%.*]], i32 [[AFTER_OFFSET:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 256 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[IN_BYREF_BYVAL_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 256
; PRELOAD-ALL-NEXT:    [[AFTER_OFFSET_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BYREF_I32_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 260
; PRELOAD-ALL-NEXT:    [[AFTER_OFFSET_LOAD:%.*]] = load i32, ptr addrspace(4) [[AFTER_OFFSET_KERNARG_OFFSET]], align 4, !invariant.load [[META0]]
; PRELOAD-ALL-NEXT:    [[IN:%.*]] = load i32, ptr addrspace(4) [[IN_BYREF_BYVAL_KERNARG_OFFSET]], align 4
; PRELOAD-ALL-NEXT:    store volatile i32 [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    store volatile i32 [[AFTER_OFFSET_LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %in = load i32, ptr addrspace(4) %in.byref
  store volatile i32 %in, ptr addrspace(1) %out, align 4
  store volatile i32 %after.offset, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_v8i32_kernel(ptr addrspace(1) nocapture %out, <8 x i32> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v8i32_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) nocapture [[OUT:%.*]], <8 x i32> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V8I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 32 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V8I32_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V8I32_KERNEL_KERNARG_SEGMENT]], i64 32
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load <8 x i32>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store <8 x i32> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v8i32_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <8 x i32> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V8I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 32 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V8I32_KERNEL_KERNARG_SEGMENT]], i64 32
; PRELOAD-2-NEXT:    [[IN_LOAD:%.*]] = load <8 x i32>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    store <8 x i32> [[IN_LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v8i32_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <8 x i32> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V8I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 32 dereferenceable(64) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V8I32_KERNEL_KERNARG_SEGMENT]], i64 32
; PRELOAD-ALL-NEXT:    [[IN_LOAD:%.*]] = load <8 x i32>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-ALL-NEXT:    store <8 x i32> [[IN_LOAD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  store <8 x i32> %in, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_v3i16_kernel(ptr addrspace(1) nocapture %out, <3 x i16> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v3i16_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) nocapture [[OUT:%.*]], <3 x i16> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V3I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V3I16_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V3I16_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load <4 x i16>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> poison, <3 x i32> <i32 0, i32 1, i32 2>
; NO-PRELOAD-NEXT:    store <3 x i16> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v3i16_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <3 x i16> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V3I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <3 x i16> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v3i16_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <3 x i16> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V3I16_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <3 x i16> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  store <3 x i16> %in, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_v3i32_kernel(ptr addrspace(1) nocapture %out, <3 x i32> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v3i32_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) nocapture [[OUT:%.*]], <3 x i32> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V3I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V3I32_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V3I32_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load <4 x i32>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = shufflevector <4 x i32> [[TMP1]], <4 x i32> poison, <3 x i32> <i32 0, i32 1, i32 2>
; NO-PRELOAD-NEXT:    store <3 x i32> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v3i32_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <3 x i32> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V3I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <3 x i32> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v3i32_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <3 x i32> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V3I32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <3 x i32> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  store <3 x i32> %in, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_v3f32_kernel(ptr addrspace(1) nocapture %out, <3 x float> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v3f32_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) nocapture [[OUT:%.*]], <3 x float> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V3F32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V3F32_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V3F32_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load <4 x float>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = shufflevector <4 x float> [[TMP1]], <4 x float> poison, <3 x i32> <i32 0, i32 1, i32 2>
; NO-PRELOAD-NEXT:    store <3 x float> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v3f32_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <3 x float> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V3F32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <3 x float> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v3f32_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <3 x float> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V3F32_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <3 x float> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  store <3 x float> %in, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_v5i8_kernel(ptr addrspace(1) nocapture %out, <5 x i8> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v5i8_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) nocapture [[OUT:%.*]], <5 x i8> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V5I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V5I8_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V5I8_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load <5 x i8>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store <5 x i8> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v5i8_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <5 x i8> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V5I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <5 x i8> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v5i8_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <5 x i8> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V5I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <5 x i8> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  store <5 x i8> %in, ptr addrspace(1) %out, align 4
  ret void
}

define amdgpu_kernel void @ptr1_v5f64_kernel(ptr addrspace(1) nocapture %out, <5 x double> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v5f64_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) nocapture [[OUT:%.*]], <5 x double> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V5F64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 64 dereferenceable(128) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V5F64_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V5F64_KERNEL_KERNARG_SEGMENT]], i64 64
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load <5 x double>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store <5 x double> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 8
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v5f64_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <5 x double> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V5F64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 64 dereferenceable(128) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V5F64_KERNEL_KERNARG_SEGMENT]], i64 64
; PRELOAD-2-NEXT:    [[IN_LOAD:%.*]] = load <5 x double>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    store <5 x double> [[IN_LOAD]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v5f64_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg nocapture [[OUT:%.*]], <5 x double> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V5F64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 64 dereferenceable(128) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V5F64_KERNEL_KERNARG_SEGMENT]], i64 64
; PRELOAD-ALL-NEXT:    [[IN_LOAD:%.*]] = load <5 x double>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-ALL-NEXT:    store <5 x double> [[IN_LOAD]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-ALL-NEXT:    ret void
;
  store <5 x double> %in, ptr addrspace(1) %out, align 8
  ret void
}

define amdgpu_kernel void @ptr1_v8i8_kernel(ptr addrspace(1) %out, <8 x i8> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v8i8_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], <8 x i8> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V8I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V8I8_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V8I8_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load <8 x i8>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store <8 x i8> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 8
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v8i8_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <8 x i8> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V8I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <8 x i8> [[IN]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v8i8_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <8 x i8> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V8I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <8 x i8> [[IN]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-ALL-NEXT:    ret void
;
  store <8 x i8> %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_i64_kernel(ptr addrspace(1) %out, i64 %a) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i64_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i64 [[A:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I64_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[A_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I64_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[A_LOAD:%.*]] = load i64, ptr addrspace(4) [[A_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store i64 [[A_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 8
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i64_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i64 inreg [[A:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store i64 [[A]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i64_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i64 inreg [[A:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store i64 [[A]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-ALL-NEXT:    ret void
;
  store i64 %a, ptr addrspace(1) %out, align 8
  ret void
}

define amdgpu_kernel void @ptr1_f64_kernel(ptr addrspace(1) %out, double %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_f64_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], double [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_F64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_F64_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_F64_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load double, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store double [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 8
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_f64_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], double inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_F64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store double [[IN]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_f64_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], double inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_F64_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store double [[IN]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-ALL-NEXT:    ret void
;
  store double %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_half_kernel(ptr addrspace(1) %out, half %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_half_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], half [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_HALF_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_HALF_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_HALF_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = bitcast i16 [[TMP2]] to half
; NO-PRELOAD-NEXT:    store half [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 2
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_half_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], half inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_HALF_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store half [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_half_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], half inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_HALF_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store half [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-ALL-NEXT:    ret void
;
  store half %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_bfloat_kernel(ptr addrspace(1) %out, bfloat %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_bfloat_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], bfloat [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = bitcast i16 [[TMP2]] to bfloat
; NO-PRELOAD-NEXT:    store bfloat [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 2
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_bfloat_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], bfloat inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store bfloat [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_bfloat_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], bfloat inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store bfloat [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-ALL-NEXT:    ret void
;
  store bfloat %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_v2bfloat_kernel(ptr addrspace(1) %out, <2 x bfloat> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v2bfloat_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], <2 x bfloat> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V2BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V2BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V2BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load <2 x bfloat>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store <2 x bfloat> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v2bfloat_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <2 x bfloat> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V2BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <2 x bfloat> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v2bfloat_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <2 x bfloat> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V2BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <2 x bfloat> [[IN]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  store <2 x bfloat> %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_v3bfloat_kernel(ptr addrspace(1) %out, <3 x bfloat> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v3bfloat_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], <3 x bfloat> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V3BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V3BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V3BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load <4 x bfloat>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = shufflevector <4 x bfloat> [[TMP1]], <4 x bfloat> poison, <3 x i32> <i32 0, i32 1, i32 2>
; NO-PRELOAD-NEXT:    store <3 x bfloat> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 8
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v3bfloat_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <3 x bfloat> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V3BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <3 x bfloat> [[IN]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v3bfloat_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <3 x bfloat> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V3BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <3 x bfloat> [[IN]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-ALL-NEXT:    ret void
;
  store <3 x bfloat> %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_v6bfloat_kernel(ptr addrspace(1) %out, <6 x bfloat> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v6bfloat_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], <6 x bfloat> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V6BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V6BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V6BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load <6 x bfloat>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store <6 x bfloat> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 16
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v6bfloat_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <6 x bfloat> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V6BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <6 x bfloat> [[IN]], ptr addrspace(1) [[OUT]], align 16
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v6bfloat_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <6 x bfloat> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V6BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <6 x bfloat> [[IN]], ptr addrspace(1) [[OUT]], align 16
; PRELOAD-ALL-NEXT:    ret void
;
  store <6 x bfloat> %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_half_v7bfloat_kernel(ptr addrspace(1) %out, half %in, <7 x bfloat> %in2, ptr addrspace(1) %out2) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_half_v7bfloat_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], half [[IN:%.*]], <7 x bfloat> [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = bitcast i16 [[TMP2]] to half
; NO-PRELOAD-NEXT:    [[IN2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[IN2_LOAD:%.*]] = load <7 x bfloat>, ptr addrspace(4) [[IN2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 32
; NO-PRELOAD-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store half [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 2
; NO-PRELOAD-NEXT:    store <7 x bfloat> [[IN2_LOAD]], ptr addrspace(1) [[OUT2_LOAD]], align 16
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_half_v7bfloat_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], half inreg [[IN:%.*]], <7 x bfloat> [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[IN2_LOAD:%.*]] = load <7 x bfloat>, ptr addrspace(4) [[IN2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT]], i64 32
; PRELOAD-2-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    store half [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-2-NEXT:    store <7 x bfloat> [[IN2_LOAD]], ptr addrspace(1) [[OUT2_LOAD]], align 16
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_half_v7bfloat_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], half inreg [[IN:%.*]], <7 x bfloat> inreg [[IN2:%.*]], ptr addrspace(1) inreg [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_HALF_V7BFLOAT_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store half [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-ALL-NEXT:    store <7 x bfloat> [[IN2]], ptr addrspace(1) [[OUT2]], align 16
; PRELOAD-ALL-NEXT:    ret void
;
  store half %in, ptr addrspace(1) %out
  store <7 x bfloat> %in2, ptr addrspace(1) %out2
  ret void
}

define amdgpu_kernel void @ptr1_i1_kernel(ptr addrspace(1) %out, i1 %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i1_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i1 [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i1
; NO-PRELOAD-NEXT:    store i1 [[TMP2]], ptr addrspace(1) [[OUT_LOAD]], align 1
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i1_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i1 inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store i1 [[IN]], ptr addrspace(1) [[OUT]], align 1
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i1_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i1 inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(12) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store i1 [[IN]], ptr addrspace(1) [[OUT]], align 1
; PRELOAD-ALL-NEXT:    ret void
;
  store i1 %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_fp128_kernel(ptr addrspace(1) %out, fp128 %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_fp128_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], fp128 [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_FP128_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_FP128_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_FP128_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load fp128, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store fp128 [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 16
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_fp128_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], fp128 inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_FP128_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store fp128 [[IN]], ptr addrspace(1) [[OUT]], align 16
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_fp128_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], fp128 inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_FP128_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store fp128 [[IN]], ptr addrspace(1) [[OUT]], align 16
; PRELOAD-ALL-NEXT:    ret void
;
  store fp128 %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_v7i8_kernel(ptr addrspace(1) %out, <7 x i8> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v7i8_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], <7 x i8> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V7I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V7I8_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V7I8_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load <7 x i8>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store <7 x i8> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 8
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v7i8_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <7 x i8> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V7I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <7 x i8> [[IN]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v7i8_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <7 x i8> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V7I8_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <7 x i8> [[IN]], ptr addrspace(1) [[OUT]], align 8
; PRELOAD-ALL-NEXT:    ret void
;
  store <7 x i8> %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_v7half_kernel(ptr addrspace(1) %out, <7 x half> %in) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_v7half_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], <7 x half> [[IN:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_V7HALF_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V7HALF_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_V7HALF_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[IN_LOAD:%.*]] = load <7 x half>, ptr addrspace(4) [[IN_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store <7 x half> [[IN_LOAD]], ptr addrspace(1) [[OUT_LOAD]], align 16
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_v7half_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <7 x half> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_V7HALF_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    store <7 x half> [[IN]], ptr addrspace(1) [[OUT]], align 16
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_v7half_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], <7 x half> inreg [[IN:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_V7HALF_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(32) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store <7 x half> [[IN]], ptr addrspace(1) [[OUT]], align 16
; PRELOAD-ALL-NEXT:    ret void
;
  store <7 x half> %in, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_i16_i32_ptr1_kernel(ptr addrspace(1) %out, i16 %in, i32 %in2, ptr addrspace(1) %out2) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i16_i32_ptr1_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i16 [[IN:%.*]], i32 [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 12
; NO-PRELOAD-NEXT:    [[IN2_LOAD:%.*]] = load i32, ptr addrspace(4) [[IN2_KERNARG_OFFSET]], align 4, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store i16 [[TMP2]], ptr addrspace(1) [[OUT_LOAD]], align 2
; NO-PRELOAD-NEXT:    store i32 [[IN2_LOAD]], ptr addrspace(1) [[OUT2_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i16_i32_ptr1_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[IN:%.*]], i32 [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 12
; PRELOAD-2-NEXT:    [[IN2_LOAD:%.*]] = load i32, ptr addrspace(4) [[IN2_KERNARG_OFFSET]], align 4, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    store i16 [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-2-NEXT:    store i32 [[IN2_LOAD]], ptr addrspace(1) [[OUT2_LOAD]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i16_i32_ptr1_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[IN:%.*]], i32 inreg [[IN2:%.*]], ptr addrspace(1) inreg [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I16_I32_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store i16 [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-ALL-NEXT:    store i32 [[IN2]], ptr addrspace(1) [[OUT2]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  store i16 %in, ptr addrspace(1) %out
  store i32 %in2, ptr addrspace(1) %out2
  ret void
}

define amdgpu_kernel void @ptr1_i16_v3i32_ptr1_kernel(ptr addrspace(1) %out, i16 %in, <3 x i32> %in2, ptr addrspace(1) %out2) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i16_v3i32_ptr1_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i16 [[IN:%.*]], <3 x i32> [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[TMP3:%.*]] = load <4 x i32>, ptr addrspace(4) [[IN2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN2_LOAD:%.*]] = shufflevector <4 x i32> [[TMP3]], <4 x i32> poison, <3 x i32> <i32 0, i32 1, i32 2>
; NO-PRELOAD-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 32
; NO-PRELOAD-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store i16 [[TMP2]], ptr addrspace(1) [[OUT_LOAD]], align 2
; NO-PRELOAD-NEXT:    store <3 x i32> [[IN2_LOAD]], ptr addrspace(1) [[OUT2_LOAD]], align 16
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i16_v3i32_ptr1_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[IN:%.*]], <3 x i32> [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[TMP1:%.*]] = load <4 x i32>, ptr addrspace(4) [[IN2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[IN2_LOAD:%.*]] = shufflevector <4 x i32> [[TMP1]], <4 x i32> poison, <3 x i32> <i32 0, i32 1, i32 2>
; PRELOAD-2-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT]], i64 32
; PRELOAD-2-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    store i16 [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-2-NEXT:    store <3 x i32> [[IN2_LOAD]], ptr addrspace(1) [[OUT2_LOAD]], align 16
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i16_v3i32_ptr1_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[IN:%.*]], <3 x i32> inreg [[IN2:%.*]], ptr addrspace(1) inreg [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I16_V3I32_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(40) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store i16 [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-ALL-NEXT:    store <3 x i32> [[IN2]], ptr addrspace(1) [[OUT2]], align 16
; PRELOAD-ALL-NEXT:    ret void
;
  store i16 %in, ptr addrspace(1) %out
  store <3 x i32> %in2, ptr addrspace(1) %out2
  ret void
}

define amdgpu_kernel void @ptr1_i16_i16_ptr1_kernel(ptr addrspace(1) %out, i16 %in, i16 %in2, ptr addrspace(1) %out2) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i16_i16_ptr1_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i16 [[IN:%.*]], i16 [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN2_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP3:%.*]] = load i32, ptr addrspace(4) [[IN2_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP4:%.*]] = lshr i32 [[TMP3]], 16
; NO-PRELOAD-NEXT:    [[TMP5:%.*]] = trunc i32 [[TMP4]] to i16
; NO-PRELOAD-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store i16 [[TMP2]], ptr addrspace(1) [[OUT_LOAD]], align 2
; NO-PRELOAD-NEXT:    store i16 [[TMP5]], ptr addrspace(1) [[OUT2_LOAD]], align 2
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i16_i16_ptr1_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[IN:%.*]], i16 [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN2_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; PRELOAD-2-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN2_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[TMP2:%.*]] = lshr i32 [[TMP1]], 16
; PRELOAD-2-NEXT:    [[TMP3:%.*]] = trunc i32 [[TMP2]] to i16
; PRELOAD-2-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    store i16 [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-2-NEXT:    store i16 [[TMP3]], ptr addrspace(1) [[OUT2_LOAD]], align 2
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i16_i16_ptr1_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[IN:%.*]], i16 inreg [[IN2:%.*]], ptr addrspace(1) inreg [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I16_I16_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store i16 [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-ALL-NEXT:    store i16 [[IN2]], ptr addrspace(1) [[OUT2]], align 2
; PRELOAD-ALL-NEXT:    ret void
;
  store i16 %in, ptr addrspace(1) %out
  store i16 %in2, ptr addrspace(1) %out2
  ret void
}

define amdgpu_kernel void @ptr1_i16_v2i8_ptr1_kernel(ptr addrspace(1) %out, i16 %in, <2 x i8> %in2, ptr addrspace(1) %out2) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i16_v2i8_ptr1_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i16 [[IN:%.*]], <2 x i8> [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[IN_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i16
; NO-PRELOAD-NEXT:    [[IN2_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP3:%.*]] = load i32, ptr addrspace(4) [[IN2_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP4:%.*]] = lshr i32 [[TMP3]], 16
; NO-PRELOAD-NEXT:    [[TMP5:%.*]] = trunc i32 [[TMP4]] to i16
; NO-PRELOAD-NEXT:    [[IN2_LOAD:%.*]] = bitcast i16 [[TMP5]] to <2 x i8>
; NO-PRELOAD-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    store i16 [[TMP2]], ptr addrspace(1) [[OUT_LOAD]], align 2
; NO-PRELOAD-NEXT:    store <2 x i8> [[IN2_LOAD]], ptr addrspace(1) [[OUT2_LOAD]], align 2
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i16_v2i8_ptr1_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[IN:%.*]], <2 x i8> [[IN2:%.*]], ptr addrspace(1) [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[IN2_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT]], i64 8
; PRELOAD-2-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[IN2_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[TMP2:%.*]] = lshr i32 [[TMP1]], 16
; PRELOAD-2-NEXT:    [[TMP3:%.*]] = trunc i32 [[TMP2]] to i16
; PRELOAD-2-NEXT:    [[IN2_LOAD:%.*]] = bitcast i16 [[TMP3]] to <2 x i8>
; PRELOAD-2-NEXT:    [[OUT2_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[OUT2_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT2_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    store i16 [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-2-NEXT:    store <2 x i8> [[IN2_LOAD]], ptr addrspace(1) [[OUT2_LOAD]], align 2
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i16_v2i8_ptr1_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i16 inreg [[IN:%.*]], <2 x i8> inreg [[IN2:%.*]], ptr addrspace(1) inreg [[OUT2:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I16_V2I8_PTR1_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(24) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    store i16 [[IN]], ptr addrspace(1) [[OUT]], align 2
; PRELOAD-ALL-NEXT:    store <2 x i8> [[IN2]], ptr addrspace(1) [[OUT2]], align 2
; PRELOAD-ALL-NEXT:    ret void
;
  store i16 %in, ptr addrspace(1) %out
  store <2 x i8> %in2, ptr addrspace(1) %out2
  ret void
}

define amdgpu_kernel void @i32_ptr1_i32_staggered_kernel(i32 %arg0, ptr addrspace(1) %out, i32 %arg1) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@i32_ptr1_i32_staggered_kernel
; NO-PRELOAD-SAME: (i32 [[ARG0:%.*]], ptr addrspace(1) [[OUT:%.*]], i32 [[ARG1:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[I32_PTR1_I32_STAGGERED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(20) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I32_PTR1_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[ARG0_LOAD:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I32_PTR1_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ARG1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I32_PTR1_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 16
; NO-PRELOAD-NEXT:    [[ARG1_LOAD:%.*]] = load i32, ptr addrspace(4) [[ARG1_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ADD:%.*]] = add i32 [[ARG0_LOAD]], [[ARG1_LOAD]]
; NO-PRELOAD-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@i32_ptr1_i32_staggered_kernel
; PRELOAD-2-SAME: (i32 inreg [[ARG0:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], i32 [[ARG1:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[I32_PTR1_I32_STAGGERED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(20) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[ARG1_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[I32_PTR1_I32_STAGGERED_KERNEL_KERNARG_SEGMENT]], i64 16
; PRELOAD-2-NEXT:    [[ARG1_LOAD:%.*]] = load i32, ptr addrspace(4) [[ARG1_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; PRELOAD-2-NEXT:    [[ADD:%.*]] = add i32 [[ARG0]], [[ARG1_LOAD]]
; PRELOAD-2-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@i32_ptr1_i32_staggered_kernel
; PRELOAD-ALL-SAME: (i32 inreg [[ARG0:%.*]], ptr addrspace(1) inreg [[OUT:%.*]], i32 inreg [[ARG1:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[I32_PTR1_I32_STAGGERED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(20) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[ADD:%.*]] = add i32 [[ARG0]], [[ARG1]]
; PRELOAD-ALL-NEXT:    store i32 [[ADD]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %add = add i32 %arg0, %arg1
  store i32 %add, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @ptr1_i8_i32_trailing_unused_kernel(ptr addrspace(1) %out, i8 %arg0, i32 %unused) {
; NO-PRELOAD-LABEL: define {{[^@]+}}@ptr1_i8_i32_trailing_unused_kernel
; NO-PRELOAD-SAME: (ptr addrspace(1) [[OUT:%.*]], i8 [[ARG0:%.*]], i32 [[UNUSED:%.*]]) #[[ATTR0]] {
; NO-PRELOAD-NEXT:    [[PTR1_I8_I32_TRAILING_UNUSED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; NO-PRELOAD-NEXT:    [[OUT_KERNARG_OFFSET:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I8_I32_TRAILING_UNUSED_KERNEL_KERNARG_SEGMENT]], i64 0
; NO-PRELOAD-NEXT:    [[OUT_LOAD:%.*]] = load ptr addrspace(1), ptr addrspace(4) [[OUT_KERNARG_OFFSET]], align 16, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[ARG0_KERNARG_OFFSET_ALIGN_DOWN:%.*]] = getelementptr inbounds i8, ptr addrspace(4) [[PTR1_I8_I32_TRAILING_UNUSED_KERNEL_KERNARG_SEGMENT]], i64 8
; NO-PRELOAD-NEXT:    [[TMP1:%.*]] = load i32, ptr addrspace(4) [[ARG0_KERNARG_OFFSET_ALIGN_DOWN]], align 8, !invariant.load [[META0]]
; NO-PRELOAD-NEXT:    [[TMP2:%.*]] = trunc i32 [[TMP1]] to i8
; NO-PRELOAD-NEXT:    [[EXT:%.*]] = zext i8 [[TMP2]] to i32
; NO-PRELOAD-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT_LOAD]], align 4
; NO-PRELOAD-NEXT:    ret void
;
; PRELOAD-2-LABEL: define {{[^@]+}}@ptr1_i8_i32_trailing_unused_kernel
; PRELOAD-2-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i8 inreg [[ARG0:%.*]], i32 [[UNUSED:%.*]]) #[[ATTR0]] {
; PRELOAD-2-NEXT:    [[PTR1_I8_I32_TRAILING_UNUSED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-2-NEXT:    [[EXT:%.*]] = zext i8 [[ARG0]] to i32
; PRELOAD-2-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-2-NEXT:    ret void
;
; PRELOAD-ALL-LABEL: define {{[^@]+}}@ptr1_i8_i32_trailing_unused_kernel
; PRELOAD-ALL-SAME: (ptr addrspace(1) inreg [[OUT:%.*]], i8 inreg [[ARG0:%.*]], i32 inreg [[UNUSED:%.*]]) #[[ATTR0]] {
; PRELOAD-ALL-NEXT:    [[PTR1_I8_I32_TRAILING_UNUSED_KERNEL_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(16) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; PRELOAD-ALL-NEXT:    [[EXT:%.*]] = zext i8 [[ARG0]] to i32
; PRELOAD-ALL-NEXT:    store i32 [[EXT]], ptr addrspace(1) [[OUT]], align 4
; PRELOAD-ALL-NEXT:    ret void
;
  %ext = zext i8 %arg0 to i32
  store i32 %ext, ptr addrspace(1) %out
  ret void
}
