; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc -global-isel=1 -mtriple=amdgcn-amd-amdpal -mcpu=gfx1200 < %s | FileCheck -check-prefix=GISEL-GFX12 %s
; RUN: llc -global-isel=0 -mtriple=amdgcn-amd-amdpal -mcpu=gfx1200 < %s | FileCheck -check-prefix=DAGISEL-GFX12 %s

declare amdgpu_cs_chain void @callee(<3 x i32> inreg, { i32, ptr addrspace(5), i32, i32 })
declare amdgpu_cs_chain_preserve void @callee_preserve(<3 x i32> inreg, { i32, ptr addrspace(5), i32, i32 })
declare void @llvm.amdgcn.cs.chain(ptr, i32, <3 x i32>, { i32, ptr addrspace(5), i32, i32 }, i32, ...) noreturn

define amdgpu_cs_chain void @dynamic_vgprs(i32 inreg %exec, <3 x i32> inreg %sgpr, { i32, ptr addrspace(5), i32, i32 } %vgpr, i32 inreg %num_vgpr) {
; GISEL-GFX12-LABEL: dynamic_vgprs:
; GISEL-GFX12:       ; %bb.0:
; GISEL-GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GISEL-GFX12-NEXT:    s_wait_expcnt 0x0
; GISEL-GFX12-NEXT:    s_wait_samplecnt 0x0
; GISEL-GFX12-NEXT:    s_wait_bvhcnt 0x0
; GISEL-GFX12-NEXT:    s_wait_kmcnt 0x0
; GISEL-GFX12-NEXT:    s_mov_b32 s5, s0
; GISEL-GFX12-NEXT:    s_mov_b32 s0, s1
; GISEL-GFX12-NEXT:    s_mov_b32 s1, s2
; GISEL-GFX12-NEXT:    s_mov_b32 s2, s3
; GISEL-GFX12-NEXT:    s_mov_b32 s6, callee@abs32@lo
; GISEL-GFX12-NEXT:    s_mov_b32 s7, callee@abs32@hi
; GISEL-GFX12-NEXT:    s_mov_b32 s8, retry_vgpr_alloc@abs32@lo
; GISEL-GFX12-NEXT:    s_mov_b32 s9, retry_vgpr_alloc@abs32@hi
; GISEL-GFX12-NEXT:    s_alloc_vgpr s4
; GISEL-GFX12-NEXT:    s_wait_alu 0xfffe
; GISEL-GFX12-NEXT:    s_cselect_b64 s[6:7], s[6:7], s[8:9]
; GISEL-GFX12-NEXT:    s_cselect_b32 exec_lo, s5, -1
; GISEL-GFX12-NEXT:    s_wait_alu 0xfffe
; GISEL-GFX12-NEXT:    s_setpc_b64 s[6:7]
;
; DAGISEL-GFX12-LABEL: dynamic_vgprs:
; DAGISEL-GFX12:       ; %bb.0:
; DAGISEL-GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; DAGISEL-GFX12-NEXT:    s_wait_expcnt 0x0
; DAGISEL-GFX12-NEXT:    s_wait_samplecnt 0x0
; DAGISEL-GFX12-NEXT:    s_wait_bvhcnt 0x0
; DAGISEL-GFX12-NEXT:    s_wait_kmcnt 0x0
; DAGISEL-GFX12-NEXT:    s_mov_b32 s5, s0
; DAGISEL-GFX12-NEXT:    s_mov_b32 s7, retry_vgpr_alloc@abs32@hi
; DAGISEL-GFX12-NEXT:    s_mov_b32 s6, retry_vgpr_alloc@abs32@lo
; DAGISEL-GFX12-NEXT:    s_mov_b32 s9, callee@abs32@hi
; DAGISEL-GFX12-NEXT:    s_mov_b32 s8, callee@abs32@lo
; DAGISEL-GFX12-NEXT:    s_mov_b32 s0, s1
; DAGISEL-GFX12-NEXT:    s_mov_b32 s1, s2
; DAGISEL-GFX12-NEXT:    s_mov_b32 s2, s3
; DAGISEL-GFX12-NEXT:    s_alloc_vgpr s4
; DAGISEL-GFX12-NEXT:    s_wait_alu 0xfffe
; DAGISEL-GFX12-NEXT:    s_cselect_b64 s[8:9], s[8:9], s[6:7]
; DAGISEL-GFX12-NEXT:    s_cselect_b32 exec_lo, s5, -1
; DAGISEL-GFX12-NEXT:    s_wait_alu 0xfffe
; DAGISEL-GFX12-NEXT:    s_setpc_b64 s[8:9]
  call void(ptr, i32, <3 x i32>, { i32, ptr addrspace(5), i32, i32 }, i32, ...) @llvm.amdgcn.cs.chain(ptr @callee, i32 %exec, <3 x i32> inreg %sgpr, { i32, ptr addrspace(5), i32, i32 } %vgpr, i32 1, i32 inreg %num_vgpr, i32 inreg -1, ptr @retry_vgpr_alloc)
  unreachable
}

define amdgpu_cs_chain void @constants(<3 x i32> inreg %sgpr, { i32, ptr addrspace(5), i32, i32 } %vgpr) {
; GISEL-GFX12-LABEL: constants:
; GISEL-GFX12:       ; %bb.0:
; GISEL-GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GISEL-GFX12-NEXT:    s_wait_expcnt 0x0
; GISEL-GFX12-NEXT:    s_wait_samplecnt 0x0
; GISEL-GFX12-NEXT:    s_wait_bvhcnt 0x0
; GISEL-GFX12-NEXT:    s_wait_kmcnt 0x0
; GISEL-GFX12-NEXT:    s_mov_b32 s4, callee@abs32@lo
; GISEL-GFX12-NEXT:    s_mov_b32 s5, callee@abs32@hi
; GISEL-GFX12-NEXT:    s_mov_b32 s6, retry_vgpr_alloc@abs32@lo
; GISEL-GFX12-NEXT:    s_mov_b32 s7, retry_vgpr_alloc@abs32@hi
; GISEL-GFX12-NEXT:    s_alloc_vgpr 64
; GISEL-GFX12-NEXT:    s_wait_alu 0xfffe
; GISEL-GFX12-NEXT:    s_cselect_b64 s[4:5], s[4:5], s[6:7]
; GISEL-GFX12-NEXT:    s_cselect_b32 exec_lo, 7, -1
; GISEL-GFX12-NEXT:    s_wait_alu 0xfffe
; GISEL-GFX12-NEXT:    s_setpc_b64 s[4:5]
;
; DAGISEL-GFX12-LABEL: constants:
; DAGISEL-GFX12:       ; %bb.0:
; DAGISEL-GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; DAGISEL-GFX12-NEXT:    s_wait_expcnt 0x0
; DAGISEL-GFX12-NEXT:    s_wait_samplecnt 0x0
; DAGISEL-GFX12-NEXT:    s_wait_bvhcnt 0x0
; DAGISEL-GFX12-NEXT:    s_wait_kmcnt 0x0
; DAGISEL-GFX12-NEXT:    s_mov_b32 s5, retry_vgpr_alloc@abs32@hi
; DAGISEL-GFX12-NEXT:    s_mov_b32 s4, retry_vgpr_alloc@abs32@lo
; DAGISEL-GFX12-NEXT:    s_mov_b32 s7, callee@abs32@hi
; DAGISEL-GFX12-NEXT:    s_mov_b32 s6, callee@abs32@lo
; DAGISEL-GFX12-NEXT:    s_alloc_vgpr 64
; DAGISEL-GFX12-NEXT:    s_wait_alu 0xfffe
; DAGISEL-GFX12-NEXT:    s_cselect_b64 s[6:7], s[6:7], s[4:5]
; DAGISEL-GFX12-NEXT:    s_cselect_b32 exec_lo, 7, -1
; DAGISEL-GFX12-NEXT:    s_wait_alu 0xfffe
; DAGISEL-GFX12-NEXT:    s_setpc_b64 s[6:7]
  call void(ptr, i32, <3 x i32>, { i32, ptr addrspace(5), i32, i32 }, i32, ...) @llvm.amdgcn.cs.chain(ptr @callee, i32 7, <3 x i32> inreg %sgpr, { i32, ptr addrspace(5), i32, i32 } %vgpr, i32 1, i32 inreg 64, i32 inreg -1, ptr @retry_vgpr_alloc)
  unreachable
}

declare amdgpu_cs_chain_preserve void @retry_vgpr_alloc(<3 x i32> inreg %sgpr)
