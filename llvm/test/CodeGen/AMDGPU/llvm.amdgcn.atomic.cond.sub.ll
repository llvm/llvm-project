; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -march=amdgcn -mcpu=gfx1200 -verify-machineinstrs < %s | FileCheck %s -check-prefix=GFX12

define float @raw_buffer_atomic_cond_sub_return(<4 x i32> inreg %rsrc, i32 inreg %data) #0 {
; GFX12-LABEL: raw_buffer_atomic_cond_sub_return:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB0_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, off, s[4:7], null th:TH_ATOMIC_RETURN
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB0_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v0, v4
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %orig = call i32 @llvm.amdgcn.raw.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 0)
  %r = bitcast i32 %orig to float
  ret float %r
}

define void @raw_buffer_atomic_cond_sub_no_return(<4 x i32> inreg %rsrc, i32 inreg %data) #0 {
; GFX12-LABEL: raw_buffer_atomic_cond_sub_no_return:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB1_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, off, s[4:7], null th:TH_ATOMIC_RETURN
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr4
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB1_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %unused = call i32 @llvm.amdgcn.raw.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 0)
  ret void
}

define void @raw_buffer_atomic_cond_sub_no_return_forced(<4 x i32> inreg %rsrc, i32 inreg %data) #1 {
; GFX12-LABEL: raw_buffer_atomic_cond_sub_no_return_forced:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB2_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, off, s[4:7], null
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr4
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB2_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %unused = call i32 @llvm.amdgcn.raw.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 0)
  ret void
}

define float @raw_buffer_atomic_cond_sub_imm_soff_return(<4 x i32> inreg %rsrc, i32 inreg %data) #0 {
; GFX12-LABEL: raw_buffer_atomic_cond_sub_imm_soff_return:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_mov_b32 s2, 4
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB3_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, off, s[4:7], s2 th:TH_ATOMIC_RETURN
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB3_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v0, v4
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %orig = call i32 @llvm.amdgcn.raw.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 4, i32 0)
  %r = bitcast i32 %orig to float
  ret float %r
}

define void @raw_buffer_atomic_cond_sub_imm_soff_no_return(<4 x i32> inreg %rsrc, i32 inreg %data) #0 {
; GFX12-LABEL: raw_buffer_atomic_cond_sub_imm_soff_no_return:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_mov_b32 s2, 4
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB4_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, off, s[4:7], s2 th:TH_ATOMIC_RETURN
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr4
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB4_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %unused = call i32 @llvm.amdgcn.raw.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 4, i32 0)
  ret void
}

define void @raw_buffer_atomic_cond_sub_imm_soff_no_return_forced(<4 x i32> inreg %rsrc, i32 inreg %data) #1 {
; GFX12-LABEL: raw_buffer_atomic_cond_sub_imm_soff_no_return_forced:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_mov_b32 s2, 4
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB5_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, off, s[4:7], s2
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr4
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB5_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %unused = call i32 @llvm.amdgcn.raw.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 4, i32 0)
  ret void
}

define float @struct_buffer_atomic_cond_sub_return(<4 x i32> inreg %rsrc, i32 inreg %data) #0 {
; GFX12-LABEL: struct_buffer_atomic_cond_sub_return:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v5, 0
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB6_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, v5, s[4:7], null idxen th:TH_ATOMIC_RETURN
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr5
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB6_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v0, v4
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %orig = call i32 @llvm.amdgcn.struct.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 0, i32 0)
  %r = bitcast i32 %orig to float
  ret float %r
}

define void @struct_buffer_atomic_cond_sub_no_return(<4 x i32> inreg %rsrc, i32 inreg %data) #0 {
; GFX12-LABEL: struct_buffer_atomic_cond_sub_no_return:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v5, 0
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB7_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, v5, s[4:7], null idxen th:TH_ATOMIC_RETURN
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr4
; GFX12-NEXT:    ; implicit-def: $vgpr5
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB7_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %unused = call i32 @llvm.amdgcn.struct.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 0, i32 0)
  ret void
}

define void @struct_buffer_atomic_cond_sub_no_return_forced(<4 x i32> inreg %rsrc, i32 inreg %data) #1 {
; GFX12-LABEL: struct_buffer_atomic_cond_sub_no_return_forced:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v5, 0
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB8_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, v5, s[4:7], null idxen
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr4
; GFX12-NEXT:    ; implicit-def: $vgpr5
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB8_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %unused = call i32 @llvm.amdgcn.struct.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 0, i32 0)
  ret void
}

define float @struct_buffer_atomic_cond_sub_imm_soff_return(<4 x i32> inreg %rsrc, i32 inreg %data) #0 {
; GFX12-LABEL: struct_buffer_atomic_cond_sub_imm_soff_return:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v5, 0
; GFX12-NEXT:    s_mov_b32 s2, 4
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB9_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, v5, s[4:7], s2 idxen th:TH_ATOMIC_RETURN
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr5
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB9_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v0, v4
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %orig = call i32 @llvm.amdgcn.struct.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 4, i32 0)
  %r = bitcast i32 %orig to float
  ret float %r
}

define void @struct_buffer_atomic_cond_sub_imm_soff_no_return(<4 x i32> inreg %rsrc, i32 inreg %data) #0 {
; GFX12-LABEL: struct_buffer_atomic_cond_sub_imm_soff_no_return:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v5, 0
; GFX12-NEXT:    s_mov_b32 s2, 4
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB10_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, v5, s[4:7], s2 idxen th:TH_ATOMIC_RETURN
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr4
; GFX12-NEXT:    ; implicit-def: $vgpr5
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB10_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %unused = call i32 @llvm.amdgcn.struct.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 4, i32 0)
  ret void
}

define void @struct_buffer_atomic_cond_sub_imm_soff_no_return_forced(<4 x i32> inreg %rsrc, i32 inreg %data) #1 {
; GFX12-LABEL: struct_buffer_atomic_cond_sub_imm_soff_no_return_forced:
; GFX12:       ; %bb.0: ; %main_body
; GFX12-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX12-NEXT:    s_wait_expcnt 0x0
; GFX12-NEXT:    s_wait_samplecnt 0x0
; GFX12-NEXT:    s_wait_bvhcnt 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    v_mov_b32_e32 v5, 0
; GFX12-NEXT:    s_mov_b32 s2, 4
; GFX12-NEXT:    s_mov_b32 s1, exec_lo
; GFX12-NEXT:  .LBB11_1: ; =>This Inner Loop Header: Depth=1
; GFX12-NEXT:    v_readfirstlane_b32 s4, v0
; GFX12-NEXT:    v_readfirstlane_b32 s5, v1
; GFX12-NEXT:    v_readfirstlane_b32 s6, v2
; GFX12-NEXT:    v_readfirstlane_b32 s7, v3
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_cmp_eq_u64_e32 vcc_lo, s[4:5], v[0:1]
; GFX12-NEXT:    v_cmp_eq_u64_e64 s0, s[6:7], v[2:3]
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(SALU_CYCLE_1)
; GFX12-NEXT:    s_and_b32 s0, vcc_lo, s0
; GFX12-NEXT:    s_and_saveexec_b32 s0, s0
; GFX12-NEXT:    buffer_atomic_cond_sub_u32 v4, v5, s[4:7], s2 idxen
; GFX12-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
; GFX12-NEXT:    ; implicit-def: $vgpr4
; GFX12-NEXT:    ; implicit-def: $vgpr5
; GFX12-NEXT:    s_xor_b32 exec_lo, exec_lo, s0
; GFX12-NEXT:    s_cbranch_execnz .LBB11_1
; GFX12-NEXT:  ; %bb.2:
; GFX12-NEXT:    s_mov_b32 exec_lo, s1
; GFX12-NEXT:    s_setpc_b64 s[30:31]
main_body:
  %unused = call i32 @llvm.amdgcn.struct.buffer.atomic.cond.sub.u32.i32(i32 %data, <4 x i32> %rsrc, i32 0, i32 0, i32 4, i32 0)
  ret void
}

declare i32 @llvm.amdgcn.raw.buffer.atomic.cond.sub.u32.i32(i32, <4 x i32>, i32, i32, i32) #0
declare i32 @llvm.amdgcn.struct.buffer.atomic.cond.sub.u32.i32(i32, <4 x i32>, i32, i32, i32, i32) #0

attributes #0 = { nounwind }
attributes #1 = { nounwind "target-features"="+atomic-csub-no-rtn-insts" }
