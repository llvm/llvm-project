; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -global-isel=0 -mtriple=amdgcn -mcpu=gfx1300 -verify-machineinstrs < %s | FileCheck %s --check-prefix=GFX13
; RUN: llc -global-isel=1 -mtriple=amdgcn -mcpu=gfx1300 -verify-machineinstrs < %s | FileCheck %s --check-prefix=GFX13

define amdgpu_kernel void @vbuffer_mtbuf_CFS128B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mtbuf_CFS128B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v3, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    tbuffer_load_format_xyz v[0:2], v0, s[0:3], s7 format:78 offen cfs:CFS_128B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b96 v3, v[0:2], s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call <3 x float> @llvm.amdgcn.raw.tbuffer.load.v3f32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 78, i32 128)
  store volatile <3 x float> %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vbuffer_mtbuf_CFS64B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mtbuf_CFS64B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v3, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    tbuffer_load_format_xyz v[0:2], v0, s[0:3], s7 format:78 offen cfs:CFS_64B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b96 v3, v[0:2], s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call <3 x float> @llvm.amdgcn.raw.tbuffer.load.v3f32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 78, i32 256)
  store volatile <3 x float> %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vbuffer_mtbuf_CFS32B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mtbuf_CFS32B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v3, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    tbuffer_load_format_xyz v[0:2], v0, s[0:3], s7 format:78 offen cfs:CFS_32B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b96 v3, v[0:2], s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call <3 x float> @llvm.amdgcn.raw.tbuffer.load.v3f32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 78, i32 384)
  store volatile <3 x float> %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vbuffer_mubuf_CFS128B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mubuf_CFS128B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    buffer_load_b32 v0, v0, s[0:3], s7 offen cfs:CFS_128B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1]
; GFX13-NEXT:    s_endpgm
  %val = call i32 @llvm.amdgcn.raw.buffer.load.i32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 128)
  store i32 %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vbuffer_mubuf_CFS64B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mubuf_CFS64B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    buffer_load_b32 v0, v0, s[0:3], s7 offen cfs:CFS_64B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1]
; GFX13-NEXT:    s_endpgm
  %val = call i32 @llvm.amdgcn.raw.buffer.load.i32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 256)
  store i32 %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vbuffer_mubuf_CFS32B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mubuf_CFS32B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    buffer_load_b32 v0, v0, s[0:3], s7 offen cfs:CFS_32B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1]
; GFX13-NEXT:    s_endpgm
  %val = call i32 @llvm.amdgcn.raw.buffer.load.i32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 384)
  store i32 %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vbuffer_mubuf_format_CFS128B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mubuf_format_CFS128B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    buffer_load_format_x v0, v0, s[0:3], s7 offen cfs:CFS_128B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call float @llvm.amdgcn.raw.buffer.load.format.f32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 128)
  store volatile float %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vbuffer_mubuf_format_CFS64B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mubuf_format_CFS64B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    buffer_load_format_x v0, v0, s[0:3], s7 offen cfs:CFS_64B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call float @llvm.amdgcn.raw.buffer.load.format.f32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 256)
  store volatile float %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vbuffer_mubuf_format_CFS32B(ptr addrspace(1) %out, <4 x i32> %src, i32 %offset, i32 %soffset) {
; GFX13-LABEL: vbuffer_mubuf_format_CFS32B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s6
; GFX13-NEXT:    buffer_load_format_x v0, v0, s[0:3], s7 offen cfs:CFS_32B
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call float @llvm.amdgcn.raw.buffer.load.format.f32(<4 x i32> %src, i32 %offset, i32 %soffset, i32 384)
  store volatile float %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @flat_CFS128B(ptr %addr) {
; GFX13-LABEL: flat_CFS128B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v0, s0 :: v_dual_mov_b32 v1, s1
; GFX13-NEXT:    flat_discard_b32 v[0:1] offset:32 scope:SCOPE_SE cfs:CFS_128B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i64, ptr addrspace(0) %addr, i32 4
  call void @llvm.amdgcn.discard.b32(ptr addrspace(0) %gep, i32 128);
  ret void
}

define amdgpu_kernel void @flat_CFS64B(ptr %addr) {
; GFX13-LABEL: flat_CFS64B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v0, s0 :: v_dual_mov_b32 v1, s1
; GFX13-NEXT:    flat_discard_b32 v[0:1] offset:32 scope:SCOPE_SE cfs:CFS_64B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i64, ptr addrspace(0) %addr, i32 4
  call void @llvm.amdgcn.discard.b32(ptr addrspace(0) %gep, i32 256);
  ret void
}

define amdgpu_kernel void @vflat_CFS32B(ptr %addr) {
; GFX13-LABEL: vflat_CFS32B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v0, s0 :: v_dual_mov_b32 v1, s1
; GFX13-NEXT:    flat_discard_b32 v[0:1] offset:32 scope:SCOPE_SE cfs:CFS_32B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i64, ptr addrspace(0) %addr, i32 4
  call void @llvm.amdgcn.discard.b32(ptr addrspace(0) %gep, i32 384);
  ret void
}

define amdgpu_kernel void @vglobal_CFS128B(ptr addrspace(1) %ptr) {
; GFX13-LABEL: vglobal_CFS128B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    v_mov_b32_e32 v0, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_prefetch_b8 v0, s[0:1] offset:512 cfs:CFS_128B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i32, ptr addrspace(1) %ptr, i32 128
  tail call void @llvm.amdgcn.global.prefetch(ptr addrspace(1) %gep, i32 128)
  ret void
}

define amdgpu_kernel void @vglobal_CFS64B(ptr addrspace(1) %ptr) {
; GFX13-LABEL: vglobal_CFS64B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    v_mov_b32_e32 v0, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_prefetch_b8 v0, s[0:1] offset:512 cfs:CFS_64B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i32, ptr addrspace(1) %ptr, i32 128
  tail call void @llvm.amdgcn.global.prefetch(ptr addrspace(1) %gep, i32 256)
  ret void
}

define amdgpu_kernel void @vglobal_CFS32B(ptr addrspace(1) %ptr) {
; GFX13-LABEL: vglobal_CFS32B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    v_mov_b32_e32 v0, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_prefetch_b8 v0, s[0:1] offset:512 cfs:CFS_32B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i32, ptr addrspace(1) %ptr, i32 128
  tail call void @llvm.amdgcn.global.prefetch(ptr addrspace(1) %gep, i32 384)
  ret void
}

define amdgpu_ps void @vscratch_CFS128B(ptr addrspace(5) %ptr) {
; GFX13-LABEL: vscratch_CFS128B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    scratch_discard_b32 v0, off offset:32 scope:SCOPE_SE cfs:CFS_128B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i64, ptr addrspace(5) %ptr, i32 4
  call void @llvm.amdgcn.discard.b32(ptr addrspace(5) %gep, i32 128);
  ret void
}

define amdgpu_ps void @vscratch_CFS64B(ptr addrspace(5) %ptr) {
; GFX13-LABEL: vscratch_CFS64B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    scratch_discard_b32 v0, off offset:32 scope:SCOPE_SE cfs:CFS_64B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i64, ptr addrspace(5) %ptr, i32 4
  call void @llvm.amdgcn.discard.b32(ptr addrspace(5) %gep, i32 256);
  ret void
}

define amdgpu_ps void @vscratch_CFS32B(ptr addrspace(5) %ptr) {
; GFX13-LABEL: vscratch_CFS32B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    scratch_discard_b32 v0, off offset:32 scope:SCOPE_SE cfs:CFS_32B
; GFX13-NEXT:    s_endpgm
  %gep = getelementptr i64, ptr addrspace(5) %ptr, i32 4
  call void @llvm.amdgcn.discard.b32(ptr addrspace(5) %gep, i32 384);
  ret void
}

define amdgpu_kernel void @vimage_CFS128B(ptr addrspace(1) %out, <8 x i32> inreg %src, i32 %s) {
; GFX13-LABEL: vimage_CFS128B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s0, s[4:5], 0x64
; GFX13-NEXT:    s_load_b256 s[8:15], s[4:5], 0x44
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s0
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    image_load v0, v0, s[8:15] dmask:0x1 dim:SQ_RSRC_IMG_1D cfs:CFS_128B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call float @llvm.amdgcn.image.load.1d.f32.i32(i32 1, i32 %s, <8 x i32> %src, i32 0, i32 128)
  store volatile float %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vimage_CFS64B(ptr addrspace(1) %out, <8 x i32> inreg %src, i32 %s) {
; GFX13-LABEL: vimage_CFS64B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s0, s[4:5], 0x64
; GFX13-NEXT:    s_load_b256 s[8:15], s[4:5], 0x44
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s0
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    image_load v0, v0, s[8:15] dmask:0x1 dim:SQ_RSRC_IMG_1D cfs:CFS_64B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call float @llvm.amdgcn.image.load.1d.f32.i32(i32 1, i32 %s, <8 x i32> %src, i32 0, i32 256)
  store volatile float %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vimage_CFS32B(ptr addrspace(1) %out, <8 x i32> inreg %src, i32 %s) {
; GFX13-LABEL: vimage_CFS32B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s0, s[4:5], 0x64
; GFX13-NEXT:    s_load_b256 s[8:15], s[4:5], 0x44
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s0
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    image_load v0, v0, s[8:15] dmask:0x1 dim:SQ_RSRC_IMG_1D cfs:CFS_32B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[0:1] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call float @llvm.amdgcn.image.load.1d.f32.i32(i32 1, i32 %s, <8 x i32> %src, i32 0, i32 384)
  store volatile float %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vsample_CFS128B(ptr addrspace(1) %out, i32 inreg %src, <4 x i32> inreg %samp, float %s, float %t) {
; GFX13-LABEL: vsample_CFS128B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x2
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b96 s[8:10], s[4:5], 0x24
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    v_mov_b32_e32 v4, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v0, s6 :: v_dual_mov_b32 v1, s7
; GFX13-NEXT:    image_gather4 v[0:3], [v0, v1], s10, s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D cfs:CFS_128B
; GFX13-NEXT:    s_wait_samplecnt 0x0
; GFX13-NEXT:    global_store_b128 v4, v[0:3], s[8:9] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call <4 x float> @llvm.amdgcn.image.gather4.2d.v4f32.f32(i32 1, float %s, float %t, i32 %src, <4 x i32> %samp, i1 0, i32 0, i32 128)
  store volatile <4 x float> %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vsample_CFS64B(ptr addrspace(1) %out, i32 inreg %src, <4 x i32> inreg %samp, float %s, float %t) {
; GFX13-LABEL: vsample_CFS64B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x2
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b96 s[8:10], s[4:5], 0x24
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    v_mov_b32_e32 v4, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v0, s6 :: v_dual_mov_b32 v1, s7
; GFX13-NEXT:    image_gather4 v[0:3], [v0, v1], s10, s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D cfs:CFS_64B
; GFX13-NEXT:    s_wait_samplecnt 0x0
; GFX13-NEXT:    global_store_b128 v4, v[0:3], s[8:9] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call <4 x float> @llvm.amdgcn.image.gather4.2d.v4f32.f32(i32 1, float %s, float %t, i32 %src, <4 x i32> %samp, i1 0, i32 0, i32 256)
  store volatile <4 x float> %val, ptr addrspace(1) %out
  ret void
}

define amdgpu_kernel void @vsample_CFS32B(ptr addrspace(1) %out, i32 inreg %src, <4 x i32> inreg %samp, float %s, float %t) {
; GFX13-LABEL: vsample_CFS32B:
; GFX13:       ; %bb.0:
; GFX13-NEXT:    s_clause 0x2
; GFX13-NEXT:    s_load_b64 s[6:7], s[4:5], 0x44
; GFX13-NEXT:    s_load_b96 s[8:10], s[4:5], 0x24
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x34
; GFX13-NEXT:    v_mov_b32_e32 v4, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v0, s6 :: v_dual_mov_b32 v1, s7
; GFX13-NEXT:    image_gather4 v[0:3], [v0, v1], s10, s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D cfs:CFS_32B
; GFX13-NEXT:    s_wait_samplecnt 0x0
; GFX13-NEXT:    global_store_b128 v4, v[0:3], s[8:9] scope:SCOPE_SYS
; GFX13-NEXT:    s_wait_storecnt 0x0
; GFX13-NEXT:    s_endpgm
  %val = call <4 x float> @llvm.amdgcn.image.gather4.2d.v4f32.f32(i32 1, float %s, float %t, i32 %src, <4 x i32> %samp, i1 0, i32 0, i32 384)
  store volatile <4 x float> %val, ptr addrspace(1) %out
  ret void
}
