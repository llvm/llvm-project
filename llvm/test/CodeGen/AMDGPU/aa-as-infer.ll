; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -mtriple=amdgcn-amd-amdhsa -passes=amdgpu-attributor -S %s -o - | FileCheck %s

@g1 = protected addrspace(1) externally_initialized global i32 0, align 4

define internal void @volatile_load_store_as_0(ptr %p) {
; CHECK-LABEL: define internal void @volatile_load_store_as_0(
; CHECK-SAME: ptr [[P:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:    [[VAL_0:%.*]] = load i32, ptr addrspace(1) @g1, align 4
; CHECK-NEXT:    [[VAL_1:%.*]] = load volatile i32, ptr [[P]], align 4
; CHECK-NEXT:    store i32 [[VAL_1]], ptr addrspace(1) @g1, align 4
; CHECK-NEXT:    store volatile i32 [[VAL_0]], ptr [[P]], align 4
; CHECK-NEXT:    ret void
;
  %val.0 = load i32, ptr addrspace(1) @g1, align 4
  %val.1 = load volatile i32, ptr %p, align 4
  store i32 %val.1, ptr addrspace(1) @g1, align 4
  store volatile i32 %val.0, ptr %p, align 4
  ret void
}

define void @call_volatile_load_store_as_0(ptr %p1, ptr %p2) {
; CHECK-LABEL: define void @call_volatile_load_store_as_0(
; CHECK-SAME: ptr [[P1:%.*]], ptr [[P2:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    call void @volatile_load_store_as_0(ptr [[P1]])
; CHECK-NEXT:    call void @volatile_load_store_as_0(ptr [[P2]])
; CHECK-NEXT:    ret void
;
  call void @volatile_load_store_as_0(ptr %p1)
  call void @volatile_load_store_as_0(ptr %p2)
  ret void
}

define internal void @volatile_load_store_as_1(ptr %p) {
; CHECK-LABEL: define internal void @volatile_load_store_as_1(
; CHECK-SAME: ptr [[P:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    [[VAL_0:%.*]] = load i32, ptr addrspace(1) @g1, align 4
; CHECK-NEXT:    [[VAL_1:%.*]] = load volatile i32, ptr [[P]], align 4
; CHECK-NEXT:    store i32 [[VAL_1]], ptr addrspace(1) @g1, align 4
; CHECK-NEXT:    store volatile i32 [[VAL_0]], ptr [[P]], align 4
; CHECK-NEXT:    ret void
;
  %val.0 = load i32, ptr addrspace(1) @g1, align 4
  %val.1 = load volatile i32, ptr %p, align 4
  store i32 %val.1, ptr addrspace(1) @g1, align 4
  store volatile i32 %val.0, ptr %p, align 4
  ret void
}

define void @call_volatile_load_store_as_1(ptr addrspace(1) %p1, ptr addrspace(1) %p2) {
; CHECK-LABEL: define void @call_volatile_load_store_as_1(
; CHECK-SAME: ptr addrspace(1) [[P1:%.*]], ptr addrspace(1) [[P2:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    [[P1_CAST:%.*]] = addrspacecast ptr addrspace(1) [[P1]] to ptr
; CHECK-NEXT:    [[P2_CAST:%.*]] = addrspacecast ptr addrspace(1) [[P2]] to ptr
; CHECK-NEXT:    call void @volatile_load_store_as_1(ptr [[P1_CAST]])
; CHECK-NEXT:    call void @volatile_load_store_as_1(ptr [[P2_CAST]])
; CHECK-NEXT:    ret void
;
  %p1.cast = addrspacecast ptr addrspace(1) %p1 to ptr
  %p2.cast = addrspacecast ptr addrspace(1) %p2 to ptr
  call void @volatile_load_store_as_1(ptr %p1.cast)
  call void @volatile_load_store_as_1(ptr %p2.cast)
  ret void
}

define internal void @volatile_load_store_as_4(ptr %p) {
  %val.0 = load i32, ptr addrspace(1) @g1, align 4
  %val.1 = load volatile i32, ptr %p, align 4
  store i32 %val.1, ptr addrspace(1) @g1, align 4
  store volatile i32 %val.0, ptr %p, align 4
  ret void
}

define void @call_volatile_load_store_as_4(ptr addrspace(4) %p1, ptr addrspace(4) %p2) {
; CHECK-LABEL: define void @call_volatile_load_store_as_4(
; CHECK-SAME: ptr addrspace(4) [[P1:%.*]], ptr addrspace(4) [[P2:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    [[P1_CAST:%.*]] = addrspacecast ptr addrspace(4) [[P1]] to ptr
; CHECK-NEXT:    [[P2_CAST:%.*]] = addrspacecast ptr addrspace(4) [[P2]] to ptr
; CHECK-NEXT:    call void @volatile_load_store_as_1(ptr [[P1_CAST]])
; CHECK-NEXT:    call void @volatile_load_store_as_1(ptr [[P2_CAST]])
; CHECK-NEXT:    ret void
;
  %p1.cast = addrspacecast ptr addrspace(4) %p1 to ptr
  %p2.cast = addrspacecast ptr addrspace(4) %p2 to ptr
  call void @volatile_load_store_as_1(ptr %p1.cast)
  call void @volatile_load_store_as_1(ptr %p2.cast)
  ret void
}
