# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 4
# RUN: llc -global-isel -mtriple=amdgcn-mesa-amdpal -mcpu=gfx1010 -run-pass=amdgpu-global-isel-divergence-lowering -verify-machineinstrs %s -o - | FileCheck -check-prefix=GFX10 %s

---
name: temporal_divergent_i32
legalized: true
tracksRegLiveness: true
body: |
  ; GFX10-LABEL: name: temporal_divergent_i32
  ; GFX10: bb.0:
  ; GFX10-NEXT:   successors: %bb.1(0x80000000)
  ; GFX10-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2
  ; GFX10-NEXT: {{  $}}
  ; GFX10-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $vgpr0
  ; GFX10-NEXT:   [[COPY1:%[0-9]+]]:_(s32) = COPY $vgpr1
  ; GFX10-NEXT:   [[COPY2:%[0-9]+]]:_(s32) = COPY $vgpr2
  ; GFX10-NEXT:   [[MV:%[0-9]+]]:_(p0) = G_MERGE_VALUES [[COPY1]](s32), [[COPY2]](s32)
  ; GFX10-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 -1
  ; GFX10-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
  ; GFX10-NEXT: {{  $}}
  ; GFX10-NEXT: bb.1:
  ; GFX10-NEXT:   successors: %bb.2(0x04000000), %bb.1(0x7c000000)
  ; GFX10-NEXT: {{  $}}
  ; GFX10-NEXT:   [[PHI:%[0-9]+]]:_(s32) = G_PHI %7(s32), %bb.1, [[C1]](s32), %bb.0
  ; GFX10-NEXT:   [[PHI1:%[0-9]+]]:_(s32) = G_PHI [[C]](s32), %bb.0, %9(s32), %bb.1
  ; GFX10-NEXT:   [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
  ; GFX10-NEXT:   [[ADD:%[0-9]+]]:_(s32) = G_ADD [[PHI1]], [[C2]]
  ; GFX10-NEXT:   [[COPY3:%[0-9]+]]:_(s32) = COPY [[ADD]](s32), implicit $exec_lo
  ; GFX10-NEXT:   [[UITOFP:%[0-9]+]]:_(s32) = G_UITOFP [[ADD]](s32)
  ; GFX10-NEXT:   [[FCMP:%[0-9]+]]:_(s1) = G_FCMP floatpred(ogt), [[UITOFP]](s32), [[COPY]]
  ; GFX10-NEXT:   [[INT:%[0-9]+]]:sreg_32_xm0_xexec(s32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), [[FCMP]](s1), [[PHI]](s32)
  ; GFX10-NEXT:   SI_LOOP [[INT]](s32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
  ; GFX10-NEXT:   G_BR %bb.2
  ; GFX10-NEXT: {{  $}}
  ; GFX10-NEXT: bb.2:
  ; GFX10-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[INT]](s32)
  ; GFX10-NEXT:   G_STORE [[COPY3]](s32), [[MV]](p0) :: (store (s32))
  ; GFX10-NEXT:   SI_RETURN
  bb.0:
    successors: %bb.1(0x80000000)
    liveins: $vgpr0, $vgpr1, $vgpr2

    %0:_(s32) = COPY $vgpr0
    %1:_(s32) = COPY $vgpr1
    %2:_(s32) = COPY $vgpr2
    %3:_(p0) = G_MERGE_VALUES %1(s32), %2(s32)
    %4:_(s32) = G_CONSTANT i32 -1
    %5:_(s32) = G_CONSTANT i32 0

  bb.1:
    successors: %bb.2(0x04000000), %bb.1(0x7c000000)

    %6:_(s32) = G_PHI %7(s32), %bb.1, %5(s32), %bb.0
    %8:_(s32) = G_PHI %4(s32), %bb.0, %9(s32), %bb.1
    %10:_(s32) = G_CONSTANT i32 1
    %9:_(s32) = G_ADD %8, %10
    %11:_(s32) = G_UITOFP %9(s32)
    %12:_(s1) = G_FCMP floatpred(ogt), %11(s32), %0
    %7:sreg_32_xm0_xexec(s32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), %12(s1), %6(s32)
    SI_LOOP %7(s32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
    G_BR %bb.2

  bb.2:
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), %7(s32)
    G_STORE %9(s32), %3(p0) :: (store (s32))
    SI_RETURN
...

---
name: temporal_divergent_i32_multiple_use
legalized: true
tracksRegLiveness: true
body: |
  ; GFX10-LABEL: name: temporal_divergent_i32_multiple_use
  ; GFX10: bb.0:
  ; GFX10-NEXT:   successors: %bb.1(0x80000000)
  ; GFX10-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4
  ; GFX10-NEXT: {{  $}}
  ; GFX10-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $vgpr0
  ; GFX10-NEXT:   [[COPY1:%[0-9]+]]:_(s32) = COPY $vgpr1
  ; GFX10-NEXT:   [[COPY2:%[0-9]+]]:_(s32) = COPY $vgpr2
  ; GFX10-NEXT:   [[MV:%[0-9]+]]:_(p0) = G_MERGE_VALUES [[COPY1]](s32), [[COPY2]](s32)
  ; GFX10-NEXT:   [[COPY3:%[0-9]+]]:_(s32) = COPY $vgpr3
  ; GFX10-NEXT:   [[COPY4:%[0-9]+]]:_(s32) = COPY $vgpr4
  ; GFX10-NEXT:   [[MV1:%[0-9]+]]:_(p0) = G_MERGE_VALUES [[COPY3]](s32), [[COPY4]](s32)
  ; GFX10-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 -1
  ; GFX10-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
  ; GFX10-NEXT: {{  $}}
  ; GFX10-NEXT: bb.1:
  ; GFX10-NEXT:   successors: %bb.2(0x04000000), %bb.1(0x7c000000)
  ; GFX10-NEXT: {{  $}}
  ; GFX10-NEXT:   [[PHI:%[0-9]+]]:_(s32) = G_PHI %10(s32), %bb.1, [[C1]](s32), %bb.0
  ; GFX10-NEXT:   [[PHI1:%[0-9]+]]:_(s32) = G_PHI [[C]](s32), %bb.0, %12(s32), %bb.1
  ; GFX10-NEXT:   [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
  ; GFX10-NEXT:   [[ADD:%[0-9]+]]:_(s32) = G_ADD [[PHI1]], [[C2]]
  ; GFX10-NEXT:   [[COPY5:%[0-9]+]]:_(s32) = COPY [[ADD]](s32), implicit $exec_lo
  ; GFX10-NEXT:   [[UITOFP:%[0-9]+]]:_(s32) = G_UITOFP [[ADD]](s32)
  ; GFX10-NEXT:   [[FCMP:%[0-9]+]]:_(s1) = G_FCMP floatpred(ogt), [[UITOFP]](s32), [[COPY]]
  ; GFX10-NEXT:   [[INT:%[0-9]+]]:sreg_32_xm0_xexec(s32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), [[FCMP]](s1), [[PHI]](s32)
  ; GFX10-NEXT:   SI_LOOP [[INT]](s32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
  ; GFX10-NEXT:   G_BR %bb.2
  ; GFX10-NEXT: {{  $}}
  ; GFX10-NEXT: bb.2:
  ; GFX10-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[INT]](s32)
  ; GFX10-NEXT:   G_STORE [[COPY5]](s32), [[MV]](p0) :: (store (s32))
  ; GFX10-NEXT:   G_STORE [[COPY5]](s32), [[MV1]](p0) :: (store (s32))
  ; GFX10-NEXT:   SI_RETURN
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4

    %0:_(s32) = COPY $vgpr0
    %1:_(s32) = COPY $vgpr1
    %2:_(s32) = COPY $vgpr2
    %3:_(p0) = G_MERGE_VALUES %1(s32), %2(s32)
    %4:_(s32) = COPY $vgpr3
    %5:_(s32) = COPY $vgpr4
    %6:_(p0) = G_MERGE_VALUES %4(s32), %5(s32)
    %7:_(s32) = G_CONSTANT i32 -1
    %8:_(s32) = G_CONSTANT i32 0

  bb.1:
    successors: %bb.2(0x04000000), %bb.1(0x7c000000)

    %9:_(s32) = G_PHI %10(s32), %bb.1, %8(s32), %bb.0
    %11:_(s32) = G_PHI %7(s32), %bb.0, %12(s32), %bb.1
    %13:_(s32) = G_CONSTANT i32 1
    %12:_(s32) = G_ADD %11, %13
    %14:_(s32) = G_UITOFP %12(s32)
    %15:_(s1) = G_FCMP floatpred(ogt), %14(s32), %0
    %10:sreg_32_xm0_xexec(s32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), %15(s1), %9(s32)
    SI_LOOP %10(s32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
    G_BR %bb.2

  bb.2:
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), %10(s32)
    G_STORE %12(s32), %3(p0) :: (store (s32))
    G_STORE %12(s32), %6(p0) :: (store (s32))
    SI_RETURN
...
