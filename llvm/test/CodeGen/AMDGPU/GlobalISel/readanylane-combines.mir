# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
# RUN: llc -mtriple=amdgcn -mcpu=gfx1010 -run-pass=amdgpu-regbanklegalize %s -verify-machineinstrs -o - | FileCheck %s

---
name: readanylane_to_virtual_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: readanylane_to_virtual_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:sgpr(s32) = COPY $sgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:sgpr(s32) = COPY $sgpr3
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY2]](s32), [[COPY3]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(s32) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (s32), addrspace 1)
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:vgpr(p1) = COPY [[MV1]](p1)
    ; CHECK-NEXT: G_STORE [[LOAD]](s32), [[COPY4]](p1) :: (store (s32), addrspace 1)
    ; CHECK-NEXT: S_ENDPGM 0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(s32) = COPY $sgpr2
    %4:sgpr(s32) = COPY $sgpr3
    %5:sgpr(p1) = G_MERGE_VALUES %3(s32), %4(s32)
    %6:sgpr(s32) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (s32), addrspace 1)
    G_STORE %6(s32), %5(p1) :: (store (s32), addrspace 1)
    S_ENDPGM 0
...

---
name: readanylane_to_physical_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1

    ; CHECK-LABEL: name: readanylane_to_physical_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(s32) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (s32), addrspace 1)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[LOAD]]
    ; CHECK-NEXT: $vgpr0 = COPY [[AMDGPU_READANYLANE]](s32)
    ; CHECK-NEXT: SI_RETURN_TO_EPILOG implicit $vgpr0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(s32) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (s32), addrspace 1)
    $vgpr0 = COPY %3(s32)
    SI_RETURN_TO_EPILOG implicit $vgpr0
...

---
name: readanylane_to_bitcast_to_virtual_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: readanylane_to_bitcast_to_virtual_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:sgpr(s32) = COPY $sgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:sgpr(s32) = COPY $sgpr3
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY2]](s32), [[COPY3]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(<2 x s16>) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (<2 x s16>), addrspace 1)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(<2 x s16>) = G_AMDGPU_READANYLANE [[LOAD]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:sgpr(s32) = G_BITCAST [[AMDGPU_READANYLANE]](<2 x s16>)
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:vgpr(s32) = COPY [[BITCAST]](s32)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:vgpr(p1) = COPY [[MV1]](p1)
    ; CHECK-NEXT: G_STORE [[COPY4]](s32), [[COPY5]](p1) :: (store (s32), addrspace 1)
    ; CHECK-NEXT: S_ENDPGM 0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(s32) = COPY $sgpr2
    %4:sgpr(s32) = COPY $sgpr3
    %5:sgpr(p1) = G_MERGE_VALUES %3(s32), %4(s32)
    %6:sgpr(<2 x s16>) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (<2 x s16>), addrspace 1)
    %7:sgpr(s32) = G_BITCAST %6(<2 x s16>)
    G_STORE %7(s32), %5(p1) :: (store (s32), addrspace 1)
    S_ENDPGM 0
...

---
name: readanylane_to_bitcast_to_physical_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: readanylane_to_bitcast_to_physical_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(<2 x s16>) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (<2 x s16>), addrspace 1)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(<2 x s16>) = G_AMDGPU_READANYLANE [[LOAD]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:sgpr(s32) = G_BITCAST [[AMDGPU_READANYLANE]](<2 x s16>)
    ; CHECK-NEXT: $vgpr0 = COPY [[BITCAST]](s32)
    ; CHECK-NEXT: SI_RETURN_TO_EPILOG implicit $vgpr0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(<2 x s16>) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (<2 x s16>), addrspace 1)
    %4:sgpr(s32) = G_BITCAST %3(<2 x s16>)
    $vgpr0 = COPY %4(s32)
    SI_RETURN_TO_EPILOG implicit $vgpr0
...

---
name: unmerge_readanylane_merge_to_virtual_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: unmerge_readanylane_merge_to_virtual_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:sgpr(s32) = COPY $sgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:sgpr(s32) = COPY $sgpr3
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY2]](s32), [[COPY3]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(s64) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (s64), addrspace 1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:vgpr(s32), [[UV1:%[0-9]+]]:vgpr(s32) = G_UNMERGE_VALUES [[LOAD]](s64)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV]]
    ; CHECK-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV1]]
    ; CHECK-NEXT: [[MV2:%[0-9]+]]:sgpr(s64) = G_MERGE_VALUES [[AMDGPU_READANYLANE]](s32), [[AMDGPU_READANYLANE1]](s32)
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:vgpr(s64) = COPY [[MV2]](s64)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:vgpr(p1) = COPY [[MV1]](p1)
    ; CHECK-NEXT: G_STORE [[COPY4]](s64), [[COPY5]](p1) :: (store (s64), addrspace 1)
    ; CHECK-NEXT: S_ENDPGM 0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(s32) = COPY $sgpr2
    %4:sgpr(s32) = COPY $sgpr3
    %5:sgpr(p1) = G_MERGE_VALUES %3(s32), %4(s32)
    %6:sgpr(s64) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (s64), addrspace 1)
    G_STORE %6(s64), %5(p1) :: (store (s64), addrspace 1)
    S_ENDPGM 0
...

---
name: unmerge_readanylane_merge_to_physical_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: unmerge_readanylane_merge_to_physical_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(s64) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (s64), addrspace 1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:vgpr(s32), [[UV1:%[0-9]+]]:vgpr(s32) = G_UNMERGE_VALUES [[LOAD]](s64)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV]]
    ; CHECK-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV1]]
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:sgpr(s64) = G_MERGE_VALUES [[AMDGPU_READANYLANE]](s32), [[AMDGPU_READANYLANE1]](s32)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[MV1]](s64)
    ; CHECK-NEXT: SI_RETURN_TO_EPILOG implicit $vgpr0_vgpr1
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(s64) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (s64), addrspace 1)
    $vgpr0_vgpr1 = COPY %3(s64)
    SI_RETURN_TO_EPILOG implicit $vgpr0_vgpr1
...

---
name: unmerge_readanylane_merge_bitcast_to_virtual_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: unmerge_readanylane_merge_bitcast_to_virtual_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:sgpr(s32) = COPY $sgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:sgpr(s32) = COPY $sgpr3
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY2]](s32), [[COPY3]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(<2 x s32>) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (<2 x s32>), addrspace 1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:vgpr(s32), [[UV1:%[0-9]+]]:vgpr(s32) = G_UNMERGE_VALUES [[LOAD]](<2 x s32>)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV]]
    ; CHECK-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV1]]
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:sgpr(<2 x s32>) = G_BUILD_VECTOR [[AMDGPU_READANYLANE]](s32), [[AMDGPU_READANYLANE1]](s32)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:sgpr(s64) = G_BITCAST [[BUILD_VECTOR]](<2 x s32>)
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:vgpr(s64) = COPY [[BITCAST]](s64)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:vgpr(p1) = COPY [[MV1]](p1)
    ; CHECK-NEXT: G_STORE [[COPY4]](s64), [[COPY5]](p1) :: (store (s64), addrspace 1)
    ; CHECK-NEXT: S_ENDPGM 0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(s32) = COPY $sgpr2
    %4:sgpr(s32) = COPY $sgpr3
    %5:sgpr(p1) = G_MERGE_VALUES %3(s32), %4(s32)
    %6:sgpr(<2 x s32>) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (<2 x s32>), addrspace 1)
    %7:sgpr(s64) = G_BITCAST %6(<2 x s32>)
    G_STORE %7(s64), %5(p1) :: (store (s64), addrspace 1)
    S_ENDPGM 0
...

---
name: unmerge_readanylane_merge_bitcast_to_physical_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: unmerge_readanylane_merge_bitcast_to_physical_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(<2 x s32>) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (<2 x s32>), addrspace 1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:vgpr(s32), [[UV1:%[0-9]+]]:vgpr(s32) = G_UNMERGE_VALUES [[LOAD]](<2 x s32>)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV]]
    ; CHECK-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV1]]
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:sgpr(<2 x s32>) = G_BUILD_VECTOR [[AMDGPU_READANYLANE]](s32), [[AMDGPU_READANYLANE1]](s32)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:sgpr(s64) = G_BITCAST [[BUILD_VECTOR]](<2 x s32>)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[BITCAST]](s64)
    ; CHECK-NEXT: SI_RETURN_TO_EPILOG implicit $vgpr0_vgpr1
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(<2 x s32>) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (<2 x s32>), addrspace 1)
    %4:sgpr(s64) = G_BITCAST %3(<2 x s32>)
    $vgpr0_vgpr1 = COPY %4(s64)
    SI_RETURN_TO_EPILOG implicit $vgpr0_vgpr1
...

---
name: unmerge_readanylane_merge_extract_to_virtual_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: unmerge_readanylane_merge_extract_to_virtual_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:sgpr(s32) = COPY $sgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:sgpr(s32) = COPY $sgpr3
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY2]](s32), [[COPY3]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(<2 x s32>) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (<2 x s32>), addrspace 1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:vgpr(s32), [[UV1:%[0-9]+]]:vgpr(s32) = G_UNMERGE_VALUES [[LOAD]](<2 x s32>)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV]]
    ; CHECK-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV1]]
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:sgpr(<2 x s32>) = G_BUILD_VECTOR [[AMDGPU_READANYLANE]](s32), [[AMDGPU_READANYLANE1]](s32)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:sgpr(s32), [[UV3:%[0-9]+]]:sgpr(s32) = G_UNMERGE_VALUES [[BUILD_VECTOR]](<2 x s32>)
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:vgpr(s32) = COPY [[UV3]](s32)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:vgpr(p1) = COPY [[MV1]](p1)
    ; CHECK-NEXT: G_STORE [[COPY4]](s32), [[COPY5]](p1) :: (store (s32), addrspace 1)
    ; CHECK-NEXT: S_ENDPGM 0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(s32) = COPY $sgpr2
    %4:sgpr(s32) = COPY $sgpr3
    %5:sgpr(p1) = G_MERGE_VALUES %3(s32), %4(s32)
    %6:sgpr(<2 x s32>) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (<2 x s32>), addrspace 1)
    %7:sgpr(s32), %8:sgpr(s32) = G_UNMERGE_VALUES %6(<2 x s32>)
    G_STORE %8(s32), %5(p1) :: (store (s32), addrspace 1)
    S_ENDPGM 0
...

---
name: unmerge_readanylane_merge_extract_to_physical_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: unmerge_readanylane_merge_extract_to_physical_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(<2 x s32>) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (<2 x s32>), addrspace 1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:vgpr(s32), [[UV1:%[0-9]+]]:vgpr(s32) = G_UNMERGE_VALUES [[LOAD]](<2 x s32>)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV]]
    ; CHECK-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(s32) = G_AMDGPU_READANYLANE [[UV1]]
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:sgpr(<2 x s32>) = G_BUILD_VECTOR [[AMDGPU_READANYLANE]](s32), [[AMDGPU_READANYLANE1]](s32)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:sgpr(s32), [[UV3:%[0-9]+]]:sgpr(s32) = G_UNMERGE_VALUES [[BUILD_VECTOR]](<2 x s32>)
    ; CHECK-NEXT: $vgpr0 = COPY [[UV3]](s32)
    ; CHECK-NEXT: SI_RETURN_TO_EPILOG implicit $vgpr0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(<2 x s32>) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (<2 x s32>), addrspace 1)
    %4:sgpr(s32), %5:sgpr(s32) = G_UNMERGE_VALUES %3(<2 x s32>)
    $vgpr0 = COPY %5(s32)
    SI_RETURN_TO_EPILOG implicit $vgpr0
...

---
name: unmerge_readanylane_merge_extract_bitcast_to_virtual_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: unmerge_readanylane_merge_extract_bitcast_to_virtual_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:sgpr(s32) = COPY $sgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:sgpr(s32) = COPY $sgpr3
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY2]](s32), [[COPY3]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(<4 x s16>) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (<4 x s16>), addrspace 1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:vgpr(<2 x s16>), [[UV1:%[0-9]+]]:vgpr(<2 x s16>) = G_UNMERGE_VALUES [[LOAD]](<4 x s16>)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(<2 x s16>) = G_AMDGPU_READANYLANE [[UV]]
    ; CHECK-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(<2 x s16>) = G_AMDGPU_READANYLANE [[UV1]]
    ; CHECK-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:sgpr(<4 x s16>) = G_CONCAT_VECTORS [[AMDGPU_READANYLANE]](<2 x s16>), [[AMDGPU_READANYLANE1]](<2 x s16>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:sgpr(<2 x s16>), [[UV3:%[0-9]+]]:sgpr(<2 x s16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<4 x s16>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:sgpr(s32) = G_BITCAST [[UV2]](<2 x s16>)
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:vgpr(s32) = COPY [[BITCAST]](s32)
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:vgpr(p1) = COPY [[MV1]](p1)
    ; CHECK-NEXT: G_STORE [[COPY4]](s32), [[COPY5]](p1) :: (store (s32), addrspace 1)
    ; CHECK-NEXT: S_ENDPGM 0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(s32) = COPY $sgpr2
    %4:sgpr(s32) = COPY $sgpr3
    %5:sgpr(p1) = G_MERGE_VALUES %3(s32), %4(s32)
    %6:sgpr(<4 x s16>) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (<4 x s16>), addrspace 1)
    %7:sgpr(<2 x s16>), %8:sgpr(<2 x s16>) = G_UNMERGE_VALUES %6(<4 x s16>)
    %9:sgpr(s32) = G_BITCAST %7(<2 x s16>)
    G_STORE %9(s32), %5(p1) :: (store (s32), addrspace 1)
    S_ENDPGM 0
...

---
name: unmerge_readanylane_merge_extract_bitcast_to_physical_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3

    ; CHECK-LABEL: name: unmerge_readanylane_merge_extract_bitcast_to_physical_vgpr
    ; CHECK: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:sgpr(s32) = COPY $sgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:sgpr(s32) = COPY $sgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:sgpr(p1) = G_MERGE_VALUES [[COPY]](s32), [[COPY1]](s32)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:vgpr(<4 x s16>) = G_LOAD [[MV]](p1) :: (volatile "amdgpu-noclobber" load (<4 x s16>), addrspace 1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:vgpr(<2 x s16>), [[UV1:%[0-9]+]]:vgpr(<2 x s16>) = G_UNMERGE_VALUES [[LOAD]](<4 x s16>)
    ; CHECK-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(<2 x s16>) = G_AMDGPU_READANYLANE [[UV]]
    ; CHECK-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(<2 x s16>) = G_AMDGPU_READANYLANE [[UV1]]
    ; CHECK-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:sgpr(<4 x s16>) = G_CONCAT_VECTORS [[AMDGPU_READANYLANE]](<2 x s16>), [[AMDGPU_READANYLANE1]](<2 x s16>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:sgpr(<2 x s16>), [[UV3:%[0-9]+]]:sgpr(<2 x s16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<4 x s16>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:sgpr(s32) = G_BITCAST [[UV2]](<2 x s16>)
    ; CHECK-NEXT: $vgpr0 = COPY [[BITCAST]](s32)
    ; CHECK-NEXT: SI_RETURN_TO_EPILOG implicit $vgpr0
    %0:sgpr(s32) = COPY $sgpr0
    %1:sgpr(s32) = COPY $sgpr1
    %2:sgpr(p1) = G_MERGE_VALUES %0(s32), %1(s32)
    %3:sgpr(<4 x s16>) = G_LOAD %2(p1) :: (volatile "amdgpu-noclobber" load (<4 x s16>), addrspace 1)
    %4:sgpr(<2 x s16>), %5:sgpr(<2 x s16>) = G_UNMERGE_VALUES %3(<4 x s16>)
    %6:sgpr(s32) = G_BITCAST %4(<2 x s16>)
    $vgpr0 = COPY %6(s32)
    SI_RETURN_TO_EPILOG implicit $vgpr0
...

