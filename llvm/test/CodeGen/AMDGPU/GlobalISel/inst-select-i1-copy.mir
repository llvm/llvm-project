# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=amdgcn -mcpu=gfx900 -run-pass=instruction-select -verify-machineinstrs -global-isel %s -o - | FileCheck %s -check-prefixes=WAVE64
# RUN: llc -mtriple=amdgcn -mcpu=gfx1010 -run-pass=instruction-select -verify-machineinstrs -global-isel %s -o - | FileCheck %s -check-prefixes=WAVE32

---
name: i1_vcc_to_vcc_copy
legalized: true
regBankSelected: true
tracksRegLiveness: true

body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4

    ; WAVE64-LABEL: name: i1_vcc_to_vcc_copy
    ; WAVE64: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4
    ; WAVE64-NEXT: {{  $}}
    ; WAVE64-NEXT: [[COPY:%[0-9]+]]:vgpr_32 = COPY $vgpr0
    ; WAVE64-NEXT: [[COPY1:%[0-9]+]]:vgpr_32 = COPY $vgpr1
    ; WAVE64-NEXT: [[COPY2:%[0-9]+]]:vgpr_32 = COPY $vgpr2
    ; WAVE64-NEXT: [[COPY3:%[0-9]+]]:vgpr_32 = COPY $vgpr3
    ; WAVE64-NEXT: [[COPY4:%[0-9]+]]:vgpr_32 = COPY $vgpr4
    ; WAVE64-NEXT: [[DEF:%[0-9]+]]:sreg_32 = IMPLICIT_DEF
    ; WAVE64-NEXT: [[S_MOV_B32_:%[0-9]+]]:sreg_32 = S_MOV_B32 2
    ; WAVE64-NEXT: [[COPY5:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_]]
    ; WAVE64-NEXT: [[V_CMP_EQ_U32_e64_:%[0-9]+]]:sreg_64_xexec = V_CMP_EQ_U32_e64 [[COPY]], [[COPY5]], implicit $exec
    ; WAVE64-NEXT: [[V_CNDMASK_B32_e64_:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, [[COPY2]], 0, [[COPY1]], [[V_CMP_EQ_U32_e64_]], implicit $exec
    ; WAVE64-NEXT: [[V_CNDMASK_B32_e64_1:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, [[COPY4]], 0, [[COPY3]], [[V_CMP_EQ_U32_e64_]], implicit $exec
    ; WAVE64-NEXT: [[COPY6:%[0-9]+]]:vgpr_32 = COPY [[DEF]]
    ; WAVE64-NEXT: [[COPY7:%[0-9]+]]:vgpr_32 = COPY [[DEF]]
    ; WAVE64-NEXT: EXP_DONE 0, [[V_CNDMASK_B32_e64_]], [[V_CNDMASK_B32_e64_1]], [[COPY6]], [[COPY7]], -1, 0, 15, implicit $exec
    ; WAVE64-NEXT: S_ENDPGM 0
    ;
    ; WAVE32-LABEL: name: i1_vcc_to_vcc_copy
    ; WAVE32: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4
    ; WAVE32-NEXT: {{  $}}
    ; WAVE32-NEXT: [[COPY:%[0-9]+]]:vgpr_32 = COPY $vgpr0
    ; WAVE32-NEXT: [[COPY1:%[0-9]+]]:vgpr_32 = COPY $vgpr1
    ; WAVE32-NEXT: [[COPY2:%[0-9]+]]:vgpr_32 = COPY $vgpr2
    ; WAVE32-NEXT: [[COPY3:%[0-9]+]]:vgpr_32 = COPY $vgpr3
    ; WAVE32-NEXT: [[COPY4:%[0-9]+]]:vgpr_32 = COPY $vgpr4
    ; WAVE32-NEXT: [[DEF:%[0-9]+]]:sreg_32 = IMPLICIT_DEF
    ; WAVE32-NEXT: [[S_MOV_B32_:%[0-9]+]]:sreg_32 = S_MOV_B32 2
    ; WAVE32-NEXT: [[COPY5:%[0-9]+]]:vgpr_32 = COPY [[S_MOV_B32_]]
    ; WAVE32-NEXT: [[V_CMP_EQ_U32_e64_:%[0-9]+]]:sreg_32_xm0_xexec = V_CMP_EQ_U32_e64 [[COPY]], [[COPY5]], implicit $exec
    ; WAVE32-NEXT: [[V_CNDMASK_B32_e64_:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, [[COPY2]], 0, [[COPY1]], [[V_CMP_EQ_U32_e64_]], implicit $exec
    ; WAVE32-NEXT: [[V_CNDMASK_B32_e64_1:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, [[COPY4]], 0, [[COPY3]], [[V_CMP_EQ_U32_e64_]], implicit $exec
    ; WAVE32-NEXT: [[COPY6:%[0-9]+]]:vgpr_32 = COPY [[DEF]]
    ; WAVE32-NEXT: [[COPY7:%[0-9]+]]:vgpr_32 = COPY [[DEF]]
    ; WAVE32-NEXT: EXP_DONE 0, [[V_CNDMASK_B32_e64_]], [[V_CNDMASK_B32_e64_1]], [[COPY6]], [[COPY7]], -1, 0, 15, implicit $exec
    ; WAVE32-NEXT: S_ENDPGM 0
    %0:vgpr(i32) = COPY $vgpr0
    %1:vgpr(i32) = COPY $vgpr1
    %2:vgpr(i32) = COPY $vgpr2
    %3:vgpr(i32) = COPY $vgpr3
    %4:vgpr(i32) = COPY $vgpr4
    %5:sgpr(i32) = G_IMPLICIT_DEF
    %6:sgpr(i32) = G_CONSTANT i32 2
    %7:vgpr(i32) = COPY %6(i32)
    %8:vcc(i1) = G_ICMP intpred(eq), %0(i32), %7
    %9:vgpr(i32) = G_SELECT %8(i1), %1, %2
    %10:vgpr(i32) = G_SELECT %8(i1), %3, %4
    %11:vgpr(i32) = COPY %5(i32)
    %12:vgpr(i32) = COPY %5(i32)
    %13:vgpr(f32) = G_BITCAST %9(i32)
    %14:vgpr(f32) = G_BITCAST %10(i32)
    %15:vgpr(f32) = G_BITCAST %11(i32)
    %16:vgpr(f32) = G_BITCAST %12(i32)
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.exp), 0, 15, %13(f32), %14(f32), %15(f32), %16(f32), -1, -1
    S_ENDPGM 0
...

---
name: i1_sgpr_to_vcc_copy
legalized: true
regBankSelected: true
tracksRegLiveness: true

body: |
  bb.0:
    liveins: $sgpr0, $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; WAVE64-LABEL: name: i1_sgpr_to_vcc_copy
    ; WAVE64: liveins: $sgpr0, $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; WAVE64-NEXT: {{  $}}
    ; WAVE64-NEXT: [[COPY:%[0-9]+]]:sreg_32 = COPY $sgpr0
    ; WAVE64-NEXT: [[COPY1:%[0-9]+]]:vgpr_32 = COPY $vgpr0
    ; WAVE64-NEXT: [[COPY2:%[0-9]+]]:vgpr_32 = COPY $vgpr1
    ; WAVE64-NEXT: [[COPY3:%[0-9]+]]:vgpr_32 = COPY $vgpr2
    ; WAVE64-NEXT: [[COPY4:%[0-9]+]]:vgpr_32 = COPY $vgpr3
    ; WAVE64-NEXT: [[DEF:%[0-9]+]]:sreg_32 = IMPLICIT_DEF
    ; WAVE64-NEXT: [[S_MOV_B32_:%[0-9]+]]:sreg_32 = S_MOV_B32 2
    ; WAVE64-NEXT: S_CMP_EQ_U32 [[COPY]], [[S_MOV_B32_]], implicit-def $scc
    ; WAVE64-NEXT: [[COPY5:%[0-9]+]]:sreg_32 = COPY $scc
    ; WAVE64-NEXT: [[S_AND_B32_:%[0-9]+]]:sreg_32 = S_AND_B32 1, [[COPY5]], implicit-def dead $scc
    ; WAVE64-NEXT: [[V_CMP_NE_U32_e64_:%[0-9]+]]:sreg_64_xexec = V_CMP_NE_U32_e64 0, [[S_AND_B32_]], implicit $exec
    ; WAVE64-NEXT: [[V_CNDMASK_B32_e64_:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, [[COPY2]], 0, [[COPY1]], [[V_CMP_NE_U32_e64_]], implicit $exec
    ; WAVE64-NEXT: [[S_AND_B32_1:%[0-9]+]]:sreg_32 = S_AND_B32 1, [[COPY5]], implicit-def dead $scc
    ; WAVE64-NEXT: [[V_CMP_NE_U32_e64_1:%[0-9]+]]:sreg_64_xexec = V_CMP_NE_U32_e64 0, [[S_AND_B32_1]], implicit $exec
    ; WAVE64-NEXT: [[V_CNDMASK_B32_e64_1:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, [[COPY4]], 0, [[COPY3]], [[V_CMP_NE_U32_e64_1]], implicit $exec
    ; WAVE64-NEXT: [[COPY6:%[0-9]+]]:vgpr_32 = COPY [[DEF]]
    ; WAVE64-NEXT: [[COPY7:%[0-9]+]]:vgpr_32 = COPY [[DEF]]
    ; WAVE64-NEXT: EXP_DONE 0, [[V_CNDMASK_B32_e64_]], [[V_CNDMASK_B32_e64_1]], [[COPY6]], [[COPY7]], -1, 0, 15, implicit $exec
    ; WAVE64-NEXT: S_ENDPGM 0
    ;
    ; WAVE32-LABEL: name: i1_sgpr_to_vcc_copy
    ; WAVE32: liveins: $sgpr0, $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; WAVE32-NEXT: {{  $}}
    ; WAVE32-NEXT: [[COPY:%[0-9]+]]:sreg_32 = COPY $sgpr0
    ; WAVE32-NEXT: [[COPY1:%[0-9]+]]:vgpr_32 = COPY $vgpr0
    ; WAVE32-NEXT: [[COPY2:%[0-9]+]]:vgpr_32 = COPY $vgpr1
    ; WAVE32-NEXT: [[COPY3:%[0-9]+]]:vgpr_32 = COPY $vgpr2
    ; WAVE32-NEXT: [[COPY4:%[0-9]+]]:vgpr_32 = COPY $vgpr3
    ; WAVE32-NEXT: [[DEF:%[0-9]+]]:sreg_32 = IMPLICIT_DEF
    ; WAVE32-NEXT: [[S_MOV_B32_:%[0-9]+]]:sreg_32 = S_MOV_B32 2
    ; WAVE32-NEXT: S_CMP_EQ_U32 [[COPY]], [[S_MOV_B32_]], implicit-def $scc
    ; WAVE32-NEXT: [[COPY5:%[0-9]+]]:sreg_32 = COPY $scc
    ; WAVE32-NEXT: [[S_AND_B32_:%[0-9]+]]:sreg_32 = S_AND_B32 1, [[COPY5]], implicit-def dead $scc
    ; WAVE32-NEXT: [[V_CMP_NE_U32_e64_:%[0-9]+]]:sreg_32_xm0_xexec = V_CMP_NE_U32_e64 0, [[S_AND_B32_]], implicit $exec
    ; WAVE32-NEXT: [[V_CNDMASK_B32_e64_:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, [[COPY2]], 0, [[COPY1]], [[V_CMP_NE_U32_e64_]], implicit $exec
    ; WAVE32-NEXT: [[S_AND_B32_1:%[0-9]+]]:sreg_32 = S_AND_B32 1, [[COPY5]], implicit-def dead $scc
    ; WAVE32-NEXT: [[V_CMP_NE_U32_e64_1:%[0-9]+]]:sreg_32_xm0_xexec = V_CMP_NE_U32_e64 0, [[S_AND_B32_1]], implicit $exec
    ; WAVE32-NEXT: [[V_CNDMASK_B32_e64_1:%[0-9]+]]:vgpr_32 = V_CNDMASK_B32_e64 0, [[COPY4]], 0, [[COPY3]], [[V_CMP_NE_U32_e64_1]], implicit $exec
    ; WAVE32-NEXT: [[COPY6:%[0-9]+]]:vgpr_32 = COPY [[DEF]]
    ; WAVE32-NEXT: [[COPY7:%[0-9]+]]:vgpr_32 = COPY [[DEF]]
    ; WAVE32-NEXT: EXP_DONE 0, [[V_CNDMASK_B32_e64_]], [[V_CNDMASK_B32_e64_1]], [[COPY6]], [[COPY7]], -1, 0, 15, implicit $exec
    ; WAVE32-NEXT: S_ENDPGM 0
    %0:sgpr(i32) = COPY $sgpr0
    %1:vgpr(i32) = COPY $vgpr0
    %2:vgpr(i32) = COPY $vgpr1
    %3:vgpr(i32) = COPY $vgpr2
    %4:vgpr(i32) = COPY $vgpr3
    %5:sgpr(i32) = G_IMPLICIT_DEF
    %6:sgpr(i32) = G_CONSTANT i32 2
    %7:sgpr(i32) = G_ICMP intpred(eq), %0(i32), %6
    %8:sgpr(i1) = G_TRUNC %7(i32)
    %9:vcc(i1) = COPY %8(i1)
    %10:vgpr(i32) = G_SELECT %9(i1), %1, %2
    %11:vcc(i1) = COPY %8(i1)
    %12:vgpr(i32) = G_SELECT %11(i1), %3, %4
    %13:vgpr(i32) = COPY %5(i32)
    %14:vgpr(i32) = COPY %5(i32)
    %15:vgpr(f32) = G_BITCAST %10(i32)
    %16:vgpr(f32) = G_BITCAST %12(i32)
    %17:vgpr(f32) = G_BITCAST %13(i32)
    %18:vgpr(f32) = G_BITCAST %14(i32)
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.exp), 0, 15, %15(f32), %16(f32), %17(f32), %18(f32), -1, -1
    S_ENDPGM 0
...
