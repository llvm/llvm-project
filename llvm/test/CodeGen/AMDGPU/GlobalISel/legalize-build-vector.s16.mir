# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=hawaii -O0 -run-pass=legalizer %s -o - | FileCheck -check-prefix=GFX78 %s
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=fiji -O0 -run-pass=legalizer %s -o - | FileCheck -check-prefix=GFX78 %s
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx900 -O0 -run-pass=legalizer %s -o - | FileCheck -check-prefix=GFX9 %s
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx1010 -O0 -run-pass=legalizer %s -o - | FileCheck -check-prefix=GFX9 %s
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx1100 -O0 -run-pass=legalizer %s -o - | FileCheck -check-prefix=GFX9 %s

---
name: build_vector_v2s16
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1

    ; GFX78-LABEL: name: build_vector_v2s16
    ; GFX78: liveins: $vgpr0, $vgpr1
    ; GFX78-NEXT: {{  $}}
    ; GFX78-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX78-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX78-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; GFX78-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX78-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; GFX78-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; GFX78-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; GFX78-NEXT: S_NOP 0, implicit [[BITCAST]](<2 x i16>)
    ;
    ; GFX9-LABEL: name: build_vector_v2s16
    ; GFX9: liveins: $vgpr0, $vgpr1
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC]](i16), [[TRUNC1]](i16)
    ; GFX9-NEXT: S_NOP 0, implicit [[BUILD_VECTOR]](<2 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i16) = G_TRUNC %0(i32)
    %3:_(i16) = G_TRUNC %1(i32)
    %4:_(<2 x i16>) = G_BUILD_VECTOR %2(i16), %3(i16)
    S_NOP 0, implicit %4(<2 x i16>)
...

---
name: build_vector_v3s16
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2

    ; GFX78-LABEL: name: build_vector_v3s16
    ; GFX78: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX78-NEXT: {{  $}}
    ; GFX78-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX78-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX78-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX78-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; GFX78-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX78-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; GFX78-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; GFX78-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; GFX78-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; GFX78-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; GFX78-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; GFX78-NEXT: [[AND4:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[AND5:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[AND5]], [[C1]](i32)
    ; GFX78-NEXT: [[OR2:%[0-9]+]]:_(i32) = G_OR [[AND4]], [[SHL2]]
    ; GFX78-NEXT: [[BITCAST2:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR2]](i32)
    ; GFX78-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST]](<2 x i16>), [[BITCAST1]](<2 x i16>), [[BITCAST2]](<2 x i16>)
    ; GFX78-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<6 x i16>)
    ;
    ; GFX9-LABEL: name: build_vector_v3s16
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC]](i16), [[TRUNC1]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC2]](i16), [[TRUNC]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC1]](i16), [[TRUNC2]](i16)
    ; GFX9-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BUILD_VECTOR]](<2 x i16>), [[BUILD_VECTOR1]](<2 x i16>), [[BUILD_VECTOR2]](<2 x i16>)
    ; GFX9-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<6 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i16) = G_TRUNC %0(i32)
    %4:_(i16) = G_TRUNC %1(i32)
    %5:_(i16) = G_TRUNC %2(i32)
    %6:_(<3 x i16>) = G_BUILD_VECTOR %3(i16), %4(i16), %5(i16)
    %7:_(<6 x i16>) = G_CONCAT_VECTORS %6(<3 x i16>), %6(<3 x i16>)
    S_NOP 0, implicit %7(<6 x i16>)
...

---
name: build_vector_v4s16
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; GFX78-LABEL: name: build_vector_v4s16
    ; GFX78: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX78-NEXT: {{  $}}
    ; GFX78-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX78-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX78-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX78-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX78-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; GFX78-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX78-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; GFX78-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; GFX78-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; GFX78-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[COPY3]], [[C]]
    ; GFX78-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; GFX78-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; GFX78-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; GFX78-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[BITCAST]](<2 x i16>), [[BITCAST1]](<2 x i16>)
    ; GFX78-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<4 x i16>)
    ;
    ; GFX9-LABEL: name: build_vector_v4s16
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[COPY3]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC]](i16), [[TRUNC1]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC2]](i16), [[TRUNC3]](i16)
    ; GFX9-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[BUILD_VECTOR]](<2 x i16>), [[BUILD_VECTOR1]](<2 x i16>)
    ; GFX9-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<4 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i16) = G_TRUNC %0(i32)
    %5:_(i16) = G_TRUNC %1(i32)
    %6:_(i16) = G_TRUNC %2(i32)
    %7:_(i16) = G_TRUNC %3(i32)
    %8:_(<4 x i16>) = G_BUILD_VECTOR %4(i16), %5(i16), %6(i16), %7(i16)
    S_NOP 0, implicit %8(<4 x i16>)
...

---
name: build_vector_v5s16
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4

    ; GFX78-LABEL: name: build_vector_v5s16
    ; GFX78: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4
    ; GFX78-NEXT: {{  $}}
    ; GFX78-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX78-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX78-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX78-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX78-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX78-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; GFX78-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX78-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; GFX78-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; GFX78-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; GFX78-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[COPY3]], [[C]]
    ; GFX78-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; GFX78-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; GFX78-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; GFX78-NEXT: [[AND4:%[0-9]+]]:_(i32) = G_AND [[COPY4]], [[C]]
    ; GFX78-NEXT: [[AND5:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[AND5]], [[C1]](i32)
    ; GFX78-NEXT: [[OR2:%[0-9]+]]:_(i32) = G_OR [[AND4]], [[SHL2]]
    ; GFX78-NEXT: [[BITCAST2:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR2]](i32)
    ; GFX78-NEXT: [[AND6:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[AND7:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[SHL3:%[0-9]+]]:_(i32) = G_SHL [[AND7]], [[C1]](i32)
    ; GFX78-NEXT: [[OR3:%[0-9]+]]:_(i32) = G_OR [[AND6]], [[SHL3]]
    ; GFX78-NEXT: [[BITCAST3:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR3]](i32)
    ; GFX78-NEXT: [[AND8:%[0-9]+]]:_(i32) = G_AND [[COPY3]], [[C]]
    ; GFX78-NEXT: [[AND9:%[0-9]+]]:_(i32) = G_AND [[COPY4]], [[C]]
    ; GFX78-NEXT: [[SHL4:%[0-9]+]]:_(i32) = G_SHL [[AND9]], [[C1]](i32)
    ; GFX78-NEXT: [[OR4:%[0-9]+]]:_(i32) = G_OR [[AND8]], [[SHL4]]
    ; GFX78-NEXT: [[BITCAST4:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR4]](i32)
    ; GFX78-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<10 x i16>) = G_CONCAT_VECTORS [[BITCAST]](<2 x i16>), [[BITCAST1]](<2 x i16>), [[BITCAST2]](<2 x i16>), [[BITCAST3]](<2 x i16>), [[BITCAST4]](<2 x i16>)
    ; GFX78-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<10 x i16>)
    ;
    ; GFX9-LABEL: name: build_vector_v5s16
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[COPY3]](i32)
    ; GFX9-NEXT: [[TRUNC4:%[0-9]+]]:_(i16) = G_TRUNC [[COPY4]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC]](i16), [[TRUNC1]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC2]](i16), [[TRUNC3]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC4]](i16), [[TRUNC]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR3:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC1]](i16), [[TRUNC2]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR4:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC3]](i16), [[TRUNC4]](i16)
    ; GFX9-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<10 x i16>) = G_CONCAT_VECTORS [[BUILD_VECTOR]](<2 x i16>), [[BUILD_VECTOR1]](<2 x i16>), [[BUILD_VECTOR2]](<2 x i16>), [[BUILD_VECTOR3]](<2 x i16>), [[BUILD_VECTOR4]](<2 x i16>)
    ; GFX9-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<10 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i16) = G_TRUNC %0(i32)
    %6:_(i16) = G_TRUNC %1(i32)
    %7:_(i16) = G_TRUNC %2(i32)
    %8:_(i16) = G_TRUNC %3(i32)
    %9:_(i16) = G_TRUNC %4(i32)
    %10:_(<5 x i16>) = G_BUILD_VECTOR %5(i16), %6(i16), %7(i16), %8(i16), %9(i16)
    %11:_(<10 x i16>) = G_CONCAT_VECTORS %10(<5 x i16>), %10(<5 x i16>)
    S_NOP 0, implicit %11(<10 x i16>)
...

---
name: build_vector_v7s16
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6

    ; GFX78-LABEL: name: build_vector_v7s16
    ; GFX78: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6
    ; GFX78-NEXT: {{  $}}
    ; GFX78-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX78-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX78-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX78-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX78-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX78-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX78-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX78-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; GFX78-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX78-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; GFX78-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; GFX78-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; GFX78-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[COPY3]], [[C]]
    ; GFX78-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; GFX78-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; GFX78-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; GFX78-NEXT: [[AND4:%[0-9]+]]:_(i32) = G_AND [[COPY4]], [[C]]
    ; GFX78-NEXT: [[AND5:%[0-9]+]]:_(i32) = G_AND [[COPY5]], [[C]]
    ; GFX78-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[AND5]], [[C1]](i32)
    ; GFX78-NEXT: [[OR2:%[0-9]+]]:_(i32) = G_OR [[AND4]], [[SHL2]]
    ; GFX78-NEXT: [[BITCAST2:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR2]](i32)
    ; GFX78-NEXT: [[AND6:%[0-9]+]]:_(i32) = G_AND [[COPY6]], [[C]]
    ; GFX78-NEXT: [[AND7:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[SHL3:%[0-9]+]]:_(i32) = G_SHL [[AND7]], [[C1]](i32)
    ; GFX78-NEXT: [[OR3:%[0-9]+]]:_(i32) = G_OR [[AND6]], [[SHL3]]
    ; GFX78-NEXT: [[BITCAST3:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR3]](i32)
    ; GFX78-NEXT: [[AND8:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[AND9:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[SHL4:%[0-9]+]]:_(i32) = G_SHL [[AND9]], [[C1]](i32)
    ; GFX78-NEXT: [[OR4:%[0-9]+]]:_(i32) = G_OR [[AND8]], [[SHL4]]
    ; GFX78-NEXT: [[BITCAST4:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR4]](i32)
    ; GFX78-NEXT: [[AND10:%[0-9]+]]:_(i32) = G_AND [[COPY3]], [[C]]
    ; GFX78-NEXT: [[AND11:%[0-9]+]]:_(i32) = G_AND [[COPY4]], [[C]]
    ; GFX78-NEXT: [[SHL5:%[0-9]+]]:_(i32) = G_SHL [[AND11]], [[C1]](i32)
    ; GFX78-NEXT: [[OR5:%[0-9]+]]:_(i32) = G_OR [[AND10]], [[SHL5]]
    ; GFX78-NEXT: [[BITCAST5:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR5]](i32)
    ; GFX78-NEXT: [[AND12:%[0-9]+]]:_(i32) = G_AND [[COPY5]], [[C]]
    ; GFX78-NEXT: [[AND13:%[0-9]+]]:_(i32) = G_AND [[COPY6]], [[C]]
    ; GFX78-NEXT: [[SHL6:%[0-9]+]]:_(i32) = G_SHL [[AND13]], [[C1]](i32)
    ; GFX78-NEXT: [[OR6:%[0-9]+]]:_(i32) = G_OR [[AND12]], [[SHL6]]
    ; GFX78-NEXT: [[BITCAST6:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR6]](i32)
    ; GFX78-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<14 x i16>) = G_CONCAT_VECTORS [[BITCAST]](<2 x i16>), [[BITCAST1]](<2 x i16>), [[BITCAST2]](<2 x i16>), [[BITCAST3]](<2 x i16>), [[BITCAST4]](<2 x i16>), [[BITCAST5]](<2 x i16>), [[BITCAST6]](<2 x i16>)
    ; GFX78-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<14 x i16>)
    ;
    ; GFX9-LABEL: name: build_vector_v7s16
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[COPY3]](i32)
    ; GFX9-NEXT: [[TRUNC4:%[0-9]+]]:_(i16) = G_TRUNC [[COPY4]](i32)
    ; GFX9-NEXT: [[TRUNC5:%[0-9]+]]:_(i16) = G_TRUNC [[COPY5]](i32)
    ; GFX9-NEXT: [[TRUNC6:%[0-9]+]]:_(i16) = G_TRUNC [[COPY6]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC]](i16), [[TRUNC1]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC2]](i16), [[TRUNC3]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC4]](i16), [[TRUNC5]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR3:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC6]](i16), [[TRUNC]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR4:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC1]](i16), [[TRUNC2]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR5:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC3]](i16), [[TRUNC4]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR6:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC5]](i16), [[TRUNC6]](i16)
    ; GFX9-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<14 x i16>) = G_CONCAT_VECTORS [[BUILD_VECTOR]](<2 x i16>), [[BUILD_VECTOR1]](<2 x i16>), [[BUILD_VECTOR2]](<2 x i16>), [[BUILD_VECTOR3]](<2 x i16>), [[BUILD_VECTOR4]](<2 x i16>), [[BUILD_VECTOR5]](<2 x i16>), [[BUILD_VECTOR6]](<2 x i16>)
    ; GFX9-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<14 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i32) = COPY $vgpr5
    %6:_(i32) = COPY $vgpr6
    %7:_(i16) = G_TRUNC %0(i32)
    %8:_(i16) = G_TRUNC %1(i32)
    %9:_(i16) = G_TRUNC %2(i32)
    %10:_(i16) = G_TRUNC %3(i32)
    %11:_(i16) = G_TRUNC %4(i32)
    %12:_(i16) = G_TRUNC %5(i32)
    %13:_(i16) = G_TRUNC %6(i32)
    %14:_(<7 x i16>) = G_BUILD_VECTOR %7(i16), %8(i16), %9(i16), %10(i16), %11(i16), %12(i16), %13(i16)
    %15:_(<14 x i16>) = G_CONCAT_VECTORS %14(<7 x i16>), %14(<7 x i16>)
    S_NOP 0, implicit %15(<14 x i16>)
...

---
name: build_vector_v8s16
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7

    ; GFX78-LABEL: name: build_vector_v8s16
    ; GFX78: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7
    ; GFX78-NEXT: {{  $}}
    ; GFX78-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX78-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX78-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX78-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX78-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX78-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX78-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX78-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX78-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; GFX78-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX78-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; GFX78-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; GFX78-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; GFX78-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[COPY3]], [[C]]
    ; GFX78-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; GFX78-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; GFX78-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; GFX78-NEXT: [[AND4:%[0-9]+]]:_(i32) = G_AND [[COPY4]], [[C]]
    ; GFX78-NEXT: [[AND5:%[0-9]+]]:_(i32) = G_AND [[COPY5]], [[C]]
    ; GFX78-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[AND5]], [[C1]](i32)
    ; GFX78-NEXT: [[OR2:%[0-9]+]]:_(i32) = G_OR [[AND4]], [[SHL2]]
    ; GFX78-NEXT: [[BITCAST2:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR2]](i32)
    ; GFX78-NEXT: [[AND6:%[0-9]+]]:_(i32) = G_AND [[COPY6]], [[C]]
    ; GFX78-NEXT: [[AND7:%[0-9]+]]:_(i32) = G_AND [[COPY7]], [[C]]
    ; GFX78-NEXT: [[SHL3:%[0-9]+]]:_(i32) = G_SHL [[AND7]], [[C1]](i32)
    ; GFX78-NEXT: [[OR3:%[0-9]+]]:_(i32) = G_OR [[AND6]], [[SHL3]]
    ; GFX78-NEXT: [[BITCAST3:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR3]](i32)
    ; GFX78-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<8 x i16>) = G_CONCAT_VECTORS [[BITCAST]](<2 x i16>), [[BITCAST1]](<2 x i16>), [[BITCAST2]](<2 x i16>), [[BITCAST3]](<2 x i16>)
    ; GFX78-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<8 x i16>)
    ;
    ; GFX9-LABEL: name: build_vector_v8s16
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[COPY3]](i32)
    ; GFX9-NEXT: [[TRUNC4:%[0-9]+]]:_(i16) = G_TRUNC [[COPY4]](i32)
    ; GFX9-NEXT: [[TRUNC5:%[0-9]+]]:_(i16) = G_TRUNC [[COPY5]](i32)
    ; GFX9-NEXT: [[TRUNC6:%[0-9]+]]:_(i16) = G_TRUNC [[COPY6]](i32)
    ; GFX9-NEXT: [[TRUNC7:%[0-9]+]]:_(i16) = G_TRUNC [[COPY7]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC]](i16), [[TRUNC1]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC2]](i16), [[TRUNC3]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC4]](i16), [[TRUNC5]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR3:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC6]](i16), [[TRUNC7]](i16)
    ; GFX9-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<8 x i16>) = G_CONCAT_VECTORS [[BUILD_VECTOR]](<2 x i16>), [[BUILD_VECTOR1]](<2 x i16>), [[BUILD_VECTOR2]](<2 x i16>), [[BUILD_VECTOR3]](<2 x i16>)
    ; GFX9-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<8 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i32) = COPY $vgpr5
    %6:_(i32) = COPY $vgpr6
    %7:_(i32) = COPY $vgpr7
    %8:_(i16) = G_TRUNC %0(i32)
    %9:_(i16) = G_TRUNC %1(i32)
    %10:_(i16) = G_TRUNC %2(i32)
    %11:_(i16) = G_TRUNC %3(i32)
    %12:_(i16) = G_TRUNC %4(i32)
    %13:_(i16) = G_TRUNC %5(i32)
    %14:_(i16) = G_TRUNC %6(i32)
    %15:_(i16) = G_TRUNC %7(i32)
    %16:_(<8 x i16>) = G_BUILD_VECTOR %8(i16), %9(i16), %10(i16), %11(i16), %12(i16), %13(i16), %14(i16), %15(i16)
    S_NOP 0, implicit %16(<8 x i16>)
...

---
name: build_vector_v16s16
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15

    ; GFX78-LABEL: name: build_vector_v16s16
    ; GFX78: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15
    ; GFX78-NEXT: {{  $}}
    ; GFX78-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX78-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX78-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX78-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX78-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX78-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX78-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX78-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX78-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX78-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX78-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX78-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX78-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX78-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX78-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX78-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX78-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; GFX78-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY]], [[C]]
    ; GFX78-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; GFX78-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX78-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; GFX78-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; GFX78-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; GFX78-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[COPY2]], [[C]]
    ; GFX78-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[COPY3]], [[C]]
    ; GFX78-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; GFX78-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; GFX78-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; GFX78-NEXT: [[AND4:%[0-9]+]]:_(i32) = G_AND [[COPY4]], [[C]]
    ; GFX78-NEXT: [[AND5:%[0-9]+]]:_(i32) = G_AND [[COPY5]], [[C]]
    ; GFX78-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[AND5]], [[C1]](i32)
    ; GFX78-NEXT: [[OR2:%[0-9]+]]:_(i32) = G_OR [[AND4]], [[SHL2]]
    ; GFX78-NEXT: [[BITCAST2:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR2]](i32)
    ; GFX78-NEXT: [[AND6:%[0-9]+]]:_(i32) = G_AND [[COPY6]], [[C]]
    ; GFX78-NEXT: [[AND7:%[0-9]+]]:_(i32) = G_AND [[COPY7]], [[C]]
    ; GFX78-NEXT: [[SHL3:%[0-9]+]]:_(i32) = G_SHL [[AND7]], [[C1]](i32)
    ; GFX78-NEXT: [[OR3:%[0-9]+]]:_(i32) = G_OR [[AND6]], [[SHL3]]
    ; GFX78-NEXT: [[BITCAST3:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR3]](i32)
    ; GFX78-NEXT: [[AND8:%[0-9]+]]:_(i32) = G_AND [[COPY8]], [[C]]
    ; GFX78-NEXT: [[AND9:%[0-9]+]]:_(i32) = G_AND [[COPY9]], [[C]]
    ; GFX78-NEXT: [[SHL4:%[0-9]+]]:_(i32) = G_SHL [[AND9]], [[C1]](i32)
    ; GFX78-NEXT: [[OR4:%[0-9]+]]:_(i32) = G_OR [[AND8]], [[SHL4]]
    ; GFX78-NEXT: [[BITCAST4:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR4]](i32)
    ; GFX78-NEXT: [[AND10:%[0-9]+]]:_(i32) = G_AND [[COPY10]], [[C]]
    ; GFX78-NEXT: [[AND11:%[0-9]+]]:_(i32) = G_AND [[COPY11]], [[C]]
    ; GFX78-NEXT: [[SHL5:%[0-9]+]]:_(i32) = G_SHL [[AND11]], [[C1]](i32)
    ; GFX78-NEXT: [[OR5:%[0-9]+]]:_(i32) = G_OR [[AND10]], [[SHL5]]
    ; GFX78-NEXT: [[BITCAST5:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR5]](i32)
    ; GFX78-NEXT: [[AND12:%[0-9]+]]:_(i32) = G_AND [[COPY12]], [[C]]
    ; GFX78-NEXT: [[AND13:%[0-9]+]]:_(i32) = G_AND [[COPY13]], [[C]]
    ; GFX78-NEXT: [[SHL6:%[0-9]+]]:_(i32) = G_SHL [[AND13]], [[C1]](i32)
    ; GFX78-NEXT: [[OR6:%[0-9]+]]:_(i32) = G_OR [[AND12]], [[SHL6]]
    ; GFX78-NEXT: [[BITCAST6:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR6]](i32)
    ; GFX78-NEXT: [[AND14:%[0-9]+]]:_(i32) = G_AND [[COPY14]], [[C]]
    ; GFX78-NEXT: [[AND15:%[0-9]+]]:_(i32) = G_AND [[COPY15]], [[C]]
    ; GFX78-NEXT: [[SHL7:%[0-9]+]]:_(i32) = G_SHL [[AND15]], [[C1]](i32)
    ; GFX78-NEXT: [[OR7:%[0-9]+]]:_(i32) = G_OR [[AND14]], [[SHL7]]
    ; GFX78-NEXT: [[BITCAST7:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR7]](i32)
    ; GFX78-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<16 x i16>) = G_CONCAT_VECTORS [[BITCAST]](<2 x i16>), [[BITCAST1]](<2 x i16>), [[BITCAST2]](<2 x i16>), [[BITCAST3]](<2 x i16>), [[BITCAST4]](<2 x i16>), [[BITCAST5]](<2 x i16>), [[BITCAST6]](<2 x i16>), [[BITCAST7]](<2 x i16>)
    ; GFX78-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<16 x i16>)
    ;
    ; GFX9-LABEL: name: build_vector_v16s16
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[COPY3]](i32)
    ; GFX9-NEXT: [[TRUNC4:%[0-9]+]]:_(i16) = G_TRUNC [[COPY4]](i32)
    ; GFX9-NEXT: [[TRUNC5:%[0-9]+]]:_(i16) = G_TRUNC [[COPY5]](i32)
    ; GFX9-NEXT: [[TRUNC6:%[0-9]+]]:_(i16) = G_TRUNC [[COPY6]](i32)
    ; GFX9-NEXT: [[TRUNC7:%[0-9]+]]:_(i16) = G_TRUNC [[COPY7]](i32)
    ; GFX9-NEXT: [[TRUNC8:%[0-9]+]]:_(i16) = G_TRUNC [[COPY8]](i32)
    ; GFX9-NEXT: [[TRUNC9:%[0-9]+]]:_(i16) = G_TRUNC [[COPY9]](i32)
    ; GFX9-NEXT: [[TRUNC10:%[0-9]+]]:_(i16) = G_TRUNC [[COPY10]](i32)
    ; GFX9-NEXT: [[TRUNC11:%[0-9]+]]:_(i16) = G_TRUNC [[COPY11]](i32)
    ; GFX9-NEXT: [[TRUNC12:%[0-9]+]]:_(i16) = G_TRUNC [[COPY12]](i32)
    ; GFX9-NEXT: [[TRUNC13:%[0-9]+]]:_(i16) = G_TRUNC [[COPY13]](i32)
    ; GFX9-NEXT: [[TRUNC14:%[0-9]+]]:_(i16) = G_TRUNC [[COPY14]](i32)
    ; GFX9-NEXT: [[TRUNC15:%[0-9]+]]:_(i16) = G_TRUNC [[COPY15]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC]](i16), [[TRUNC1]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC2]](i16), [[TRUNC3]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC4]](i16), [[TRUNC5]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR3:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC6]](i16), [[TRUNC7]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR4:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC8]](i16), [[TRUNC9]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR5:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC10]](i16), [[TRUNC11]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR6:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC12]](i16), [[TRUNC13]](i16)
    ; GFX9-NEXT: [[BUILD_VECTOR7:%[0-9]+]]:_(<2 x i16>) = G_BUILD_VECTOR [[TRUNC14]](i16), [[TRUNC15]](i16)
    ; GFX9-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<16 x i16>) = G_CONCAT_VECTORS [[BUILD_VECTOR]](<2 x i16>), [[BUILD_VECTOR1]](<2 x i16>), [[BUILD_VECTOR2]](<2 x i16>), [[BUILD_VECTOR3]](<2 x i16>), [[BUILD_VECTOR4]](<2 x i16>), [[BUILD_VECTOR5]](<2 x i16>), [[BUILD_VECTOR6]](<2 x i16>), [[BUILD_VECTOR7]](<2 x i16>)
    ; GFX9-NEXT: S_NOP 0, implicit [[CONCAT_VECTORS]](<16 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i32) = COPY $vgpr5
    %6:_(i32) = COPY $vgpr6
    %7:_(i32) = COPY $vgpr7
    %8:_(i32) = COPY $vgpr8
    %9:_(i32) = COPY $vgpr9
    %10:_(i32) = COPY $vgpr10
    %11:_(i32) = COPY $vgpr11
    %12:_(i32) = COPY $vgpr12
    %13:_(i32) = COPY $vgpr13
    %14:_(i32) = COPY $vgpr14
    %15:_(i32) = COPY $vgpr15
    %16:_(i16) = G_TRUNC %0(i32)
    %17:_(i16) = G_TRUNC %1(i32)
    %18:_(i16) = G_TRUNC %2(i32)
    %19:_(i16) = G_TRUNC %3(i32)
    %20:_(i16) = G_TRUNC %4(i32)
    %21:_(i16) = G_TRUNC %5(i32)
    %22:_(i16) = G_TRUNC %6(i32)
    %23:_(i16) = G_TRUNC %7(i32)
    %24:_(i16) = G_TRUNC %8(i32)
    %25:_(i16) = G_TRUNC %9(i32)
    %26:_(i16) = G_TRUNC %10(i32)
    %27:_(i16) = G_TRUNC %11(i32)
    %28:_(i16) = G_TRUNC %12(i32)
    %29:_(i16) = G_TRUNC %13(i32)
    %30:_(i16) = G_TRUNC %14(i32)
    %31:_(i16) = G_TRUNC %15(i32)
    %32:_(<16 x i16>) = G_BUILD_VECTOR %16(i16), %17(i16), %18(i16), %19(i16), %20(i16), %21(i16), %22(i16), %23(i16), %24(i16), %25(i16), %26(i16), %27(i16), %28(i16), %29(i16), %30(i16), %31(i16)
    S_NOP 0, implicit %32(<16 x i16>)
...
