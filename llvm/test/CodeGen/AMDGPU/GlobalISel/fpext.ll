; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -global-isel -new-reg-bank-select -mtriple=amdgcn-amd-amdpal -mattr=-real-true16 -mcpu=gfx1100 -o - %s | FileCheck -check-prefixes=GFX11,GFX11-FAKE16 %s
; RUN: llc -global-isel -new-reg-bank-select -mtriple=amdgcn-amd-amdpal -mattr=+real-true16 -mcpu=gfx1100 -o - %s | FileCheck -check-prefixes=GFX11,GFX11-TRUE16 %s
; RUN: llc -global-isel -new-reg-bank-select -mtriple=amdgcn-amd-amdpal -mattr=-real-true16 -mcpu=gfx1200 -o - %s | FileCheck -check-prefixes=GFX12,GFX12-FAKE16 %s
; RUN: llc -global-isel -new-reg-bank-select -mtriple=amdgcn-amd-amdpal -mattr=+real-true16 -mcpu=gfx1200 -o - %s | FileCheck -check-prefixes=GFX12,GFX12-TRUE16 %s

define amdgpu_ps float @fpext_f16_to_f32_uniform(half inreg %a) {
; GFX11-LABEL: fpext_f16_to_f32_uniform:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_cvt_f32_f16_e32 v0, s0
; GFX11-NEXT:    ; return to shader part epilog
;
; GFX12-LABEL: fpext_f16_to_f32_uniform:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    s_cvt_f32_f16 s0, s0
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_3)
; GFX12-NEXT:    v_mov_b32_e32 v0, s0
; GFX12-NEXT:    ; return to shader part epilog
  %result = fpext half %a to float
  ret float %result
}

define amdgpu_ps float @fpext_f16_to_f32_div(half %a) {
; GFX11-FAKE16-LABEL: fpext_f16_to_f32_div:
; GFX11-FAKE16:       ; %bb.0:
; GFX11-FAKE16-NEXT:    v_cvt_f32_f16_e32 v0, v0
; GFX11-FAKE16-NEXT:    ; return to shader part epilog
;
; GFX11-TRUE16-LABEL: fpext_f16_to_f32_div:
; GFX11-TRUE16:       ; %bb.0:
; GFX11-TRUE16-NEXT:    v_cvt_f32_f16_e32 v0, v0.l
; GFX11-TRUE16-NEXT:    ; return to shader part epilog
;
; GFX12-FAKE16-LABEL: fpext_f16_to_f32_div:
; GFX12-FAKE16:       ; %bb.0:
; GFX12-FAKE16-NEXT:    v_cvt_f32_f16_e32 v0, v0
; GFX12-FAKE16-NEXT:    ; return to shader part epilog
;
; GFX12-TRUE16-LABEL: fpext_f16_to_f32_div:
; GFX12-TRUE16:       ; %bb.0:
; GFX12-TRUE16-NEXT:    v_cvt_f32_f16_e32 v0, v0.l
; GFX12-TRUE16-NEXT:    ; return to shader part epilog
  %result = fpext half %a to float
  ret float %result
}

define amdgpu_ps void @fpext_f32_to_f64_uniform(float inreg %a, ptr addrspace(1) %ptr) {
; GFX11-LABEL: fpext_f32_to_f64_uniform:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_cvt_f64_f32_e32 v[2:3], s0
; GFX11-NEXT:    global_store_b64 v[0:1], v[2:3], off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: fpext_f32_to_f64_uniform:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_cvt_f64_f32_e32 v[2:3], s0
; GFX12-NEXT:    global_store_b64 v[0:1], v[2:3], off
; GFX12-NEXT:    s_endpgm
  %result = fpext float %a to double
  store double %result, ptr addrspace(1) %ptr
  ret void
}

define amdgpu_ps void @fpext_f32_to_f64_div(float %a, ptr addrspace(1) %ptr) {
; GFX11-LABEL: fpext_f32_to_f64_div:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_cvt_f64_f32_e32 v[3:4], v0
; GFX11-NEXT:    global_store_b64 v[1:2], v[3:4], off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: fpext_f32_to_f64_div:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_cvt_f64_f32_e32 v[3:4], v0
; GFX12-NEXT:    global_store_b64 v[1:2], v[3:4], off
; GFX12-NEXT:    s_endpgm
  %result = fpext float %a to double
  store double %result, ptr addrspace(1) %ptr
  ret void
}

define amdgpu_ps void @fpext_f16_to_f64_uniform(half inreg %a, ptr addrspace(1) %ptr) {
; GFX11-LABEL: fpext_f16_to_f64_uniform:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_cvt_f32_f16_e32 v2, s0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cvt_f64_f32_e32 v[2:3], v2
; GFX11-NEXT:    global_store_b64 v[0:1], v[2:3], off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: fpext_f16_to_f64_uniform:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    s_cvt_f32_f16 s0, s0
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_3)
; GFX12-NEXT:    v_cvt_f64_f32_e32 v[2:3], s0
; GFX12-NEXT:    global_store_b64 v[0:1], v[2:3], off
; GFX12-NEXT:    s_endpgm
  %result = fpext half %a to double
  store double %result, ptr addrspace(1) %ptr
  ret void
}

define amdgpu_ps void @fpext_f16_to_f64_div(half %a, ptr addrspace(1) %ptr) {
; GFX11-FAKE16-LABEL: fpext_f16_to_f64_div:
; GFX11-FAKE16:       ; %bb.0:
; GFX11-FAKE16-NEXT:    v_cvt_f32_f16_e32 v0, v0
; GFX11-FAKE16-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-FAKE16-NEXT:    v_cvt_f64_f32_e32 v[3:4], v0
; GFX11-FAKE16-NEXT:    global_store_b64 v[1:2], v[3:4], off
; GFX11-FAKE16-NEXT:    s_endpgm
;
; GFX11-TRUE16-LABEL: fpext_f16_to_f64_div:
; GFX11-TRUE16:       ; %bb.0:
; GFX11-TRUE16-NEXT:    v_cvt_f32_f16_e32 v0, v0.l
; GFX11-TRUE16-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-TRUE16-NEXT:    v_cvt_f64_f32_e32 v[3:4], v0
; GFX11-TRUE16-NEXT:    global_store_b64 v[1:2], v[3:4], off
; GFX11-TRUE16-NEXT:    s_endpgm
;
; GFX12-FAKE16-LABEL: fpext_f16_to_f64_div:
; GFX12-FAKE16:       ; %bb.0:
; GFX12-FAKE16-NEXT:    v_cvt_f32_f16_e32 v0, v0
; GFX12-FAKE16-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX12-FAKE16-NEXT:    v_cvt_f64_f32_e32 v[3:4], v0
; GFX12-FAKE16-NEXT:    global_store_b64 v[1:2], v[3:4], off
; GFX12-FAKE16-NEXT:    s_endpgm
;
; GFX12-TRUE16-LABEL: fpext_f16_to_f64_div:
; GFX12-TRUE16:       ; %bb.0:
; GFX12-TRUE16-NEXT:    v_cvt_f32_f16_e32 v0, v0.l
; GFX12-TRUE16-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX12-TRUE16-NEXT:    v_cvt_f64_f32_e32 v[3:4], v0
; GFX12-TRUE16-NEXT:    global_store_b64 v[1:2], v[3:4], off
; GFX12-TRUE16-NEXT:    s_endpgm
  %result = fpext half %a to double
  store double %result, ptr addrspace(1) %ptr
  ret void
}

define amdgpu_ps <2 x float> @fpext_v2f16_to_v2f32_uniform(<2 x half> inreg %a) {
; GFX11-LABEL: fpext_v2f16_to_v2f32_uniform:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_lshr_b32 s1, s0, 16
; GFX11-NEXT:    v_cvt_f32_f16_e32 v0, s0
; GFX11-NEXT:    v_cvt_f32_f16_e32 v1, s1
; GFX11-NEXT:    ; return to shader part epilog
;
; GFX12-LABEL: fpext_v2f16_to_v2f32_uniform:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    s_cvt_f32_f16 s1, s0
; GFX12-NEXT:    s_cvt_hi_f32_f16 s0, s0
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_3)
; GFX12-NEXT:    v_dual_mov_b32 v0, s1 :: v_dual_mov_b32 v1, s0
; GFX12-NEXT:    ; return to shader part epilog
  %result = fpext <2 x half> %a to <2 x float>
  ret <2 x float> %result
}

define amdgpu_ps <2 x float> @fpext_v2f16_to_v2f32_div(<2 x half> %a) {
; GFX11-FAKE16-LABEL: fpext_v2f16_to_v2f32_div:
; GFX11-FAKE16:       ; %bb.0:
; GFX11-FAKE16-NEXT:    v_lshrrev_b32_e32 v1, 16, v0
; GFX11-FAKE16-NEXT:    v_cvt_f32_f16_e32 v0, v0
; GFX11-FAKE16-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; GFX11-FAKE16-NEXT:    v_cvt_f32_f16_e32 v1, v1
; GFX11-FAKE16-NEXT:    ; return to shader part epilog
;
; GFX11-TRUE16-LABEL: fpext_v2f16_to_v2f32_div:
; GFX11-TRUE16:       ; %bb.0:
; GFX11-TRUE16-NEXT:    v_cvt_f32_f16_e32 v2, v0.l
; GFX11-TRUE16-NEXT:    v_cvt_f32_f16_e32 v1, v0.h
; GFX11-TRUE16-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; GFX11-TRUE16-NEXT:    v_mov_b32_e32 v0, v2
; GFX11-TRUE16-NEXT:    ; return to shader part epilog
;
; GFX12-FAKE16-LABEL: fpext_v2f16_to_v2f32_div:
; GFX12-FAKE16:       ; %bb.0:
; GFX12-FAKE16-NEXT:    v_lshrrev_b32_e32 v1, 16, v0
; GFX12-FAKE16-NEXT:    v_cvt_f32_f16_e32 v0, v0
; GFX12-FAKE16-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; GFX12-FAKE16-NEXT:    v_cvt_f32_f16_e32 v1, v1
; GFX12-FAKE16-NEXT:    ; return to shader part epilog
;
; GFX12-TRUE16-LABEL: fpext_v2f16_to_v2f32_div:
; GFX12-TRUE16:       ; %bb.0:
; GFX12-TRUE16-NEXT:    v_cvt_f32_f16_e32 v2, v0.l
; GFX12-TRUE16-NEXT:    v_cvt_f32_f16_e32 v1, v0.h
; GFX12-TRUE16-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; GFX12-TRUE16-NEXT:    v_mov_b32_e32 v0, v2
; GFX12-TRUE16-NEXT:    ; return to shader part epilog
  %result = fpext <2 x half> %a to <2 x float>
  ret <2 x float> %result
}

define amdgpu_ps void @fpext_v2f32_to_v2f64_uniform(<2 x float> inreg %a, ptr addrspace(1) %ptr) {
; GFX11-LABEL: fpext_v2f32_to_v2f64_uniform:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_cvt_f64_f32_e32 v[4:5], s1
; GFX11-NEXT:    v_cvt_f64_f32_e32 v[2:3], s0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_2) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX11-NEXT:    v_readfirstlane_b32 s3, v5
; GFX11-NEXT:    v_readfirstlane_b32 s0, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(SKIP_1) | instid1(VALU_DEP_3)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v3
; GFX11-NEXT:    v_readfirstlane_b32 s2, v4
; GFX11-NEXT:    v_dual_mov_b32 v5, s3 :: v_dual_mov_b32 v2, s0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; GFX11-NEXT:    v_dual_mov_b32 v3, s1 :: v_dual_mov_b32 v4, s2
; GFX11-NEXT:    global_store_b128 v[0:1], v[2:5], off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: fpext_v2f32_to_v2f64_uniform:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_cvt_f64_f32_e32 v[4:5], s1
; GFX12-NEXT:    v_cvt_f64_f32_e32 v[2:3], s0
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_2) | instskip(NEXT) | instid1(VALU_DEP_2)
; GFX12-NEXT:    v_readfirstlane_b32 s3, v5
; GFX12-NEXT:    v_readfirstlane_b32 s0, v2
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(SKIP_2) | instid1(VALU_DEP_3)
; GFX12-NEXT:    v_readfirstlane_b32 s1, v3
; GFX12-NEXT:    v_readfirstlane_b32 s2, v4
; GFX12-NEXT:    s_wait_alu depctr_va_sdst(0)
; GFX12-NEXT:    v_dual_mov_b32 v5, s3 :: v_dual_mov_b32 v2, s0
; GFX12-NEXT:    s_delay_alu instid0(VALU_DEP_2)
; GFX12-NEXT:    v_dual_mov_b32 v3, s1 :: v_dual_mov_b32 v4, s2
; GFX12-NEXT:    global_store_b128 v[0:1], v[2:5], off
; GFX12-NEXT:    s_endpgm
  %result = fpext <2 x float> %a to <2 x double>
  store <2 x double> %result, ptr addrspace(1) %ptr
  ret void
}

define amdgpu_ps void @fpext_v2f32_to_v2f64_div(<2 x float> %a, ptr addrspace(1) %ptr) {
; GFX11-LABEL: fpext_v2f32_to_v2f64_div:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_cvt_f64_f32_e32 v[4:5], v0
; GFX11-NEXT:    v_cvt_f64_f32_e32 v[6:7], v1
; GFX11-NEXT:    global_store_b128 v[2:3], v[4:7], off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: fpext_v2f32_to_v2f64_div:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_cvt_f64_f32_e32 v[4:5], v0
; GFX12-NEXT:    v_cvt_f64_f32_e32 v[6:7], v1
; GFX12-NEXT:    global_store_b128 v[2:3], v[4:7], off
; GFX12-NEXT:    s_endpgm
  %result = fpext <2 x float> %a to <2 x double>
  store <2 x double> %result, ptr addrspace(1) %ptr
  ret void
}
