# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=amdgcn-mesa-mesa3d -mcpu=fiji -run-pass=legalizer %s -o - | FileCheck %s

---
name: extract_vector_elt_0_v2i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1
    ; CHECK-LABEL: name: extract_vector_elt_0_v2i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i32) = G_EXTRACT_VECTOR_ELT %0(<2 x i32>), %1(i32)
    $vgpr0 = COPY %2(i32)
...
---
name: extract_vector_elt_1_v2i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1
    ; CHECK-LABEL: name: extract_vector_elt_1_v2i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 1
    %2:_(i32) = G_EXTRACT_VECTOR_ELT %0(<2 x i32>), %1(i32)
    $vgpr0 = COPY %2(i32)
...
---
name: extract_vector_elt_2_v2i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1
    ; CHECK-LABEL: name: extract_vector_elt_2_v2i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 1
    %2:_(i32) = G_EXTRACT_VECTOR_ELT %0(<2 x i32>), %1(i32)
    $vgpr0 = COPY %2(i32)
...
---
name: extract_vector_elt_0_v3i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2
    ; CHECK-LABEL: name: extract_vector_elt_0_v3i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<3 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i32) = G_EXTRACT_VECTOR_ELT %0(<3 x i32>), %1(i32)
    $vgpr0 = COPY %2(i32)
...
---
name: extract_vector_elt_0_v4i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-LABEL: name: extract_vector_elt_0_v4i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<4 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i32) = G_EXTRACT_VECTOR_ELT %0(<4 x i32>), %1(i32)
    $vgpr0 = COPY %2(i32)
...

---
name: extract_vector_elt_0_v5i32

body: |
  bb.0:
    liveins: $vgpr0
    ; CHECK-LABEL: name: extract_vector_elt_0_v5i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[COPY]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<5 x i32>) = G_BUILD_VECTOR %0(i32), %0(i32), %0(i32), %0(i32), %0(i32)
    %2:_(i32) = G_CONSTANT i32 0
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %1(<5 x i32>), %2(i32)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_0_v6i32

body: |
  bb.0:
    liveins: $vgpr0
    ; CHECK-LABEL: name: extract_vector_elt_0_v6i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[COPY]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<6 x i32>) = G_BUILD_VECTOR %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32)
    %2:_(i32) = G_CONSTANT i32 0
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %1(<6 x i32>), %2(i32)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_0_v7i32

body: |
  bb.0:
    liveins: $vgpr0
    ; CHECK-LABEL: name: extract_vector_elt_0_v7i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[COPY]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<7 x i32>) = G_BUILD_VECTOR %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32)
    %2:_(i32) = G_CONSTANT i32 0
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %1(<7 x i32>), %2(i32)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_0_v8i32

body: |
  bb.0:
    liveins: $vgpr0
    ; CHECK-LABEL: name: extract_vector_elt_0_v8i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[COPY]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<8 x i32>) = G_BUILD_VECTOR %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32)
    %2:_(i32) = G_CONSTANT i32 0
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %1(<8 x i32>), %2(i32)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_0_v16i32

body: |
  bb.0:
    liveins: $vgpr0
    ; CHECK-LABEL: name: extract_vector_elt_0_v16i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[COPY]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<16 x i32>) = G_BUILD_VECTOR %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32), %0(i32)
    %2:_(i32) = G_CONSTANT i32 0
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %1(<16 x i32>), %2(i32)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_var_v2i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1, $vgpr2
    ; CHECK-LABEL: name: extract_vector_elt_var_v2i32
    ; CHECK: liveins: $vgpr0_vgpr1, $vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[COPY]](<2 x i32>), [[COPY1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[EVEC]](i32)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(i32) = COPY $vgpr2
    %2:_(i32) = G_EXTRACT_VECTOR_ELT %0(<2 x i32>), %1(i32)
    $vgpr0 = COPY %2(i32)
...

---
name: extract_vector_elt_var_v8i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-LABEL: name: extract_vector_elt_var_v8i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<8 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[COPY]](<8 x i32>), [[COPY1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[EVEC]](i32)
    %0:_(<8 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(i32) = COPY $vgpr2
    %2:_(i32) = G_EXTRACT_VECTOR_ELT %0(<8 x i32>), %1(i32)
    $vgpr0 = COPY %2(i32)
...


---
name: extract_vector_elt_0_v2i8_i32

body: |
  bb.0:

    ; CHECK-LABEL: name: extract_vector_elt_0_v2i8_i32
    ; CHECK: [[DEF:%[0-9]+]]:_(<2 x i32>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[DEF]](<2 x i32>)
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY]](i32)
    %0:_(<2 x i8>) = G_IMPLICIT_DEF
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i8) = G_EXTRACT_VECTOR_ELT %0(<2 x i8>), %1(i32)
    %3:_(i32) = G_ANYEXT %2(i8)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_0_v2i16_i32

body: |
  bb.0:

    ; CHECK-LABEL: name: extract_vector_elt_0_v2i16_i32
    ; CHECK: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[DEF]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(<2 x i16>) = G_IMPLICIT_DEF
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i16) = G_EXTRACT_VECTOR_ELT %0(<2 x i16>), %1(i32)
    %3:_(i32) = G_ANYEXT %2(i16)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_0_v2i1_i32

body: |
  bb.0:

    ; CHECK-LABEL: name: extract_vector_elt_0_v2i1_i32
    ; CHECK: [[DEF:%[0-9]+]]:_(<2 x i32>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[DEF]](<2 x i32>)
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY]](i32)
    %0:_(<2 x i1>) = G_IMPLICIT_DEF
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i1) = G_EXTRACT_VECTOR_ELT %0(<2 x i1>), %1(i32)
    %3:_(i32) = G_ANYEXT %2(i1)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_0_v2i1_i1

body: |
  bb.0:

    ; CHECK-LABEL: name: extract_vector_elt_0_v2i1_i1
    ; CHECK: [[DEF:%[0-9]+]]:_(<2 x i32>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[DEF]](<2 x i32>)
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY]](i32)
    %0:_(<2 x i1>) = G_IMPLICIT_DEF
    %1:_(i1) = G_CONSTANT i1 false
    %2:_(i32) = G_ZEXT %1(i1)
    %3:_(i1) = G_EXTRACT_VECTOR_ELT %0(<2 x i1>), %2(i32)
    %4:_(i32) = G_ANYEXT %3(i1)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v2s8_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0, $vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v2s8_varidx_i32
    ; CHECK: liveins: $vgpr0, $vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[LSHR]](i32)
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[BUILD_VECTOR]](<2 x i32>), [[COPY1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[EVEC]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i16) = G_TRUNC %0(i32)
    %3:_(<2 x i8>) = G_BITCAST %2(i16)
    %4:_(i8) = G_EXTRACT_VECTOR_ELT %3(<2 x i8>), %1(i32)
    %5:_(i32) = G_ANYEXT %4(i8)
    $vgpr0 = COPY %5(i32)
...

---
name: extract_vector_elt_v2s8_constidx_0_i32

body: |
  bb.0:
    liveins: $vgpr0

    ; CHECK-LABEL: name: extract_vector_elt_v2s8_constidx_0_i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i16) = G_TRUNC %0(i32)
    %3:_(<2 x i8>) = G_BITCAST %2(i16)
    %4:_(i32) = G_CONSTANT i32 0
    %5:_(i8) = G_EXTRACT_VECTOR_ELT %3(<2 x i8>), %4(i32)
    %6:_(i32) = G_ANYEXT %5(i8)
    $vgpr0 = COPY %6(i32)
...

---
name: extract_vector_elt_v2s8_constidx_1_i32

body: |
  bb.0:
    liveins: $vgpr0

    ; CHECK-LABEL: name: extract_vector_elt_v2s8_constidx_1_i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i16) = G_TRUNC %0(i32)
    %3:_(<2 x i8>) = G_BITCAST %2(i16)
    %4:_(i32) = G_CONSTANT i32 1
    %5:_(i8) = G_EXTRACT_VECTOR_ELT %3(<2 x i8>), %4(i32)
    %6:_(i32) = G_ANYEXT %5(i8)
    $vgpr0 = COPY %6(i32)
...

---
name: extract_vector_elt_v4s4_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0, $vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v4s4_varidx_i32
    ; CHECK: liveins: $vgpr0, $vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 4
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C1]](i32)
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(i32) = G_CONSTANT i32 12
    ; CHECK-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C2]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[LSHR]](i32), [[LSHR1]](i32), [[LSHR2]](i32)
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[BUILD_VECTOR]](<4 x i32>), [[COPY1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[EVEC]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i16) = G_TRUNC %0(i32)
    %3:_(<4 x i4>) = G_BITCAST %2(i16)
    %4:_(i4) = G_EXTRACT_VECTOR_ELT %3(<4 x i4>), %1(i32)
    %5:_(i32) = G_ANYEXT %4(i4)
    $vgpr0 = COPY %5(i32)
...

---
name: extract_vector_elt_v3s8_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2, $vgpr3

    ; CHECK-LABEL: name: extract_vector_elt_v3s8_varidx_i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2, $vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[COPY]](<3 x i32>), [[COPY1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[EVEC]](i32)
    %0:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(i32) = COPY $vgpr3
    %2:_(<3 x i8>) = G_TRUNC %0(<3 x i32>)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<3 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v4s8_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0, $vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v4s8_varidx_i32
    ; CHECK: liveins: $vgpr0, $vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 3
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND]], [[C]](i32)
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[SHL]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(<4 x i8>) = G_BITCAST %0(i32)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<4 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v4s8_constidx_0_i32

body: |
  bb.0:
    liveins: $vgpr0

    ; CHECK-LABEL: name: extract_vector_elt_v4s8_constidx_0_i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<4 x i8>) = G_BITCAST %0(i32)
    %2:_(i32) = G_CONSTANT i32 0
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %1(<4 x i8>), %2(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v4s8_constidx_1_i32

body: |
  bb.0:
    liveins: $vgpr0

    ; CHECK-LABEL: name: extract_vector_elt_v4s8_constidx_1_i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<4 x i8>) = G_BITCAST %0(i32)
    %2:_(i32) = G_CONSTANT i32 1
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %1(<4 x i8>), %2(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v4s8_constidx_2_i32

body: |
  bb.0:
    liveins: $vgpr0

    ; CHECK-LABEL: name: extract_vector_elt_v4s8_constidx_2_i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<4 x i8>) = G_BITCAST %0(i32)
    %2:_(i32) = G_CONSTANT i32 2
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %1(<4 x i8>), %2(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v4s8_constidx_3_i32

body: |
  bb.0:
    liveins: $vgpr0

    ; CHECK-LABEL: name: extract_vector_elt_v4s8_constidx_3_i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 24
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(<4 x i8>) = G_BITCAST %0(i32)
    %2:_(i32) = G_CONSTANT i32 3
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %1(<4 x i8>), %2(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...



---
name: extract_vector_elt_v8s8_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1, $vgpr2

    ; CHECK-LABEL: name: extract_vector_elt_v8s8_varidx_i32
    ; CHECK: liveins: $vgpr0_vgpr1, $vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[UV]](i32), [[UV1]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 2
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[BUILD_VECTOR]](<2 x i32>), [[LSHR]](i32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 3
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C1]]
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND]], [[C1]](i32)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[EVEC]], [[SHL]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR1]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i32) = COPY $vgpr2
    %2:_(<8 x i8>) = G_BITCAST %0(i64)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<8 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...


---
name: extract_vector_elt_v8s8_constidx_0_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v8s8_constidx_0_i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(<8 x i8>) = G_BITCAST %0(i64)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<8 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v8s8_constidx_1_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v8s8_constidx_1_i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 1
    %2:_(<8 x i8>) = G_BITCAST %0(i64)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<8 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v8s8_constidx_3_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v8s8_constidx_3_i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 24
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 3
    %2:_(<8 x i8>) = G_BITCAST %0(i64)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<8 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v8s8_constidx_4_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v8s8_constidx_4_i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV1]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 4
    %2:_(<8 x i8>) = G_BITCAST %0(i64)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<8 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v8s8_constidx_5_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v8s8_constidx_5_i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV1]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 5
    %2:_(<8 x i8>) = G_BITCAST %0(i64)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<8 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v8s8_constidx_7_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v8s8_constidx_7_i32
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV1]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 24
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i32) = G_CONSTANT i32 7
    %2:_(<8 x i8>) = G_BITCAST %0(i64)
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %2(<8 x i8>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v2s16_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0, $vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v2s16_varidx_i32
    ; CHECK: liveins: $vgpr0, $vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[COPY]](<2 x i16>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 4
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND]], [[C1]](i32)
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[SHL]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(<2 x i16>) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i16) = G_EXTRACT_VECTOR_ELT %0(<2 x i16>), %1(i32)
    %3:_(i32) = G_ANYEXT %2(i16)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_v2s16_idx0_i32

body: |
  bb.0:
    liveins: $vgpr0

    ; CHECK-LABEL: name: extract_vector_elt_v2s16_idx0_i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[COPY]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(<2 x i16>) = COPY $vgpr0
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i16) = G_EXTRACT_VECTOR_ELT %0(<2 x i16>), %1(i32)
    %3:_(i32) = G_ANYEXT %2(i16)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_v2s16_idx1_i32

body: |
  bb.0:
    liveins: $vgpr0

    ; CHECK-LABEL: name: extract_vector_elt_v2s16_idx1_i32
    ; CHECK: liveins: $vgpr0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[COPY]](<2 x i16>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(<2 x i16>) = COPY $vgpr0
    %1:_(i32) = G_CONSTANT i32 1
    %2:_(i16) = G_EXTRACT_VECTOR_ELT %0(<2 x i16>), %1(i32)
    %3:_(i32) = G_ANYEXT %2(i16)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_v3s16_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2, $vgpr3

    ; CHECK-LABEL: name: extract_vector_elt_v3s16_varidx_i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2, $vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[COPY]](<3 x i32>), [[COPY1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[EVEC]](i32)
    %0:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(i32) = COPY $vgpr3
    %2:_(<3 x i16>) = G_TRUNC %0(<3 x i32>)
    %3:_(i16) = G_EXTRACT_VECTOR_ELT %2(<3 x i16>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i16)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v3s16_idx0_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2

    ; CHECK-LABEL: name: extract_vector_elt_v3s16_idx0_i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<3 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(<3 x i16>) = G_TRUNC %0(<3 x i32>)
    %3:_(i16) = G_EXTRACT_VECTOR_ELT %2(<3 x i16>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i16)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v3s16_idx1_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2

    ; CHECK-LABEL: name: extract_vector_elt_v3s16_idx1_i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<3 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(i32) = G_CONSTANT i32 1
    %2:_(<3 x i16>) = G_TRUNC %0(<3 x i32>)
    %3:_(i16) = G_EXTRACT_VECTOR_ELT %2(<3 x i16>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i16)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v3s16_idx2_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2

    ; CHECK-LABEL: name: extract_vector_elt_v3s16_idx2_i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<3 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV2]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(i32) = G_CONSTANT i32 2
    %2:_(<3 x i16>) = G_TRUNC %0(<3 x i32>)
    %3:_(i16) = G_EXTRACT_VECTOR_ELT %2(<3 x i16>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i16)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v4s16_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1, $vgpr2

    ; CHECK-LABEL: name: extract_vector_elt_v4s16_varidx_i32
    ; CHECK: liveins: $vgpr0_vgpr1, $vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i16>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i32>) = G_BITCAST [[COPY]](<4 x i16>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[BITCAST]](<2 x i32>), [[LSHR]](i32)
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 4
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND]], [[C1]](i32)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[EVEC]], [[SHL]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR1]](i32)
    %0:_(<4 x i16>) = COPY $vgpr0_vgpr1
    %1:_(i32) = COPY $vgpr2
    %2:_(i16) = G_EXTRACT_VECTOR_ELT %0(<4 x i16>), %1(i32)
    %3:_(i32) = G_ANYEXT %2(i16)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_v2s128_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7, $vgpr8

    ; CHECK-LABEL: name: extract_vector_elt_v2s128_varidx_i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7, $vgpr8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i128>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[COPY]](<2 x i128>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 2
    ; CHECK-NEXT: [[MUL:%[0-9]+]]:_(i32) = G_MUL [[COPY1]], [[C]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[ADD:%[0-9]+]]:_(i32) = G_ADD [[MUL]], [[C1]]
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i64) = G_EXTRACT_VECTOR_ELT [[BITCAST]](<4 x i64>), [[ADD]](i32)
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(i32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[ADD1:%[0-9]+]]:_(i32) = G_ADD [[MUL]], [[C2]]
    ; CHECK-NEXT: [[EVEC1:%[0-9]+]]:_(i64) = G_EXTRACT_VECTOR_ELT [[BITCAST]](<4 x i64>), [[ADD1]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i64>) = G_BUILD_VECTOR [[EVEC]](i64), [[EVEC1]](i64)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i128) = G_BITCAST [[BUILD_VECTOR]](<2 x i64>)
    ; CHECK-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[BITCAST1]](i128)
    %0:_(<2 x i128>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(i32) = COPY $vgpr8
    %2:_(i128) = G_EXTRACT_VECTOR_ELT %0(<2 x i128>), %1(i32)
    $vgpr0_vgpr1_vgpr2_vgpr3 = COPY %2(i128)
...

---
name: extract_vector_elt_v2i32_varidx_i64

body: |
  bb.0:
    liveins: $vgpr0_vgpr1, $vgpr2_vgpr3

    ; CHECK-LABEL: name: extract_vector_elt_v2i32_varidx_i64
    ; CHECK: liveins: $vgpr0_vgpr1, $vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i64) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i32) = G_TRUNC [[COPY1]](i64)
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[COPY]](<2 x i32>), [[TRUNC]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[EVEC]](i32)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(i64) = COPY $vgpr2_vgpr3
    %2:_(i32) = G_TRUNC %1(i64)
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %0(<2 x i32>), %2(i32)
    $vgpr0 = COPY %3(i32)
...
---
name: extract_vector_elt_0_v2i64

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3

    ; CHECK-LABEL: name: extract_vector_elt_0_v2i64
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i64), [[UV1:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY]](<2 x i64>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i64) = COPY [[UV]](i64)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[COPY1]](i64)
    %0:_(<2 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i64) = G_EXTRACT_VECTOR_ELT %0(<2 x i64>), %1(i32)
    $vgpr0_vgpr1 = COPY %2(i64)
...

---
name: extract_vector_elt_0_v8i64

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3

    ; CHECK-LABEL: name: extract_vector_elt_0_v8i64
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(<8 x i64>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i64), [[UV1:%[0-9]+]]:_(i64), [[UV2:%[0-9]+]]:_(i64), [[UV3:%[0-9]+]]:_(i64), [[UV4:%[0-9]+]]:_(i64), [[UV5:%[0-9]+]]:_(i64), [[UV6:%[0-9]+]]:_(i64), [[UV7:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[DEF]](<8 x i64>)
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY [[UV]](i64)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[COPY]](i64)
    %0:_(<8 x i64>) = G_IMPLICIT_DEF
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i64) = G_EXTRACT_VECTOR_ELT %0(<8 x i64>), %1(i32)
    $vgpr0_vgpr1 = COPY %2(i64)
...

---
name: extract_vector_elt_0_v16i64

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3

    ; CHECK-LABEL: name: extract_vector_elt_0_v16i64
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(<16 x i64>) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i64), [[UV1:%[0-9]+]]:_(i64), [[UV2:%[0-9]+]]:_(i64), [[UV3:%[0-9]+]]:_(i64), [[UV4:%[0-9]+]]:_(i64), [[UV5:%[0-9]+]]:_(i64), [[UV6:%[0-9]+]]:_(i64), [[UV7:%[0-9]+]]:_(i64), [[UV8:%[0-9]+]]:_(i64), [[UV9:%[0-9]+]]:_(i64), [[UV10:%[0-9]+]]:_(i64), [[UV11:%[0-9]+]]:_(i64), [[UV12:%[0-9]+]]:_(i64), [[UV13:%[0-9]+]]:_(i64), [[UV14:%[0-9]+]]:_(i64), [[UV15:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[DEF]](<16 x i64>)
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY [[UV]](i64)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[COPY]](i64)
    %0:_(<16 x i64>) = G_IMPLICIT_DEF
    %1:_(i32) = G_CONSTANT i32 0
    %2:_(i64) = G_EXTRACT_VECTOR_ELT %0(<16 x i64>), %1(i32)
    $vgpr0_vgpr1 = COPY %2(i64)
...

# Make sure we look through casts looking for a constant index.
---
name: extract_vector_elt_look_through_trunc_0_v4i32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-LABEL: name: extract_vector_elt_look_through_trunc_0_v4i32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<4 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY1]](i32)
    %0:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(i64) = G_CONSTANT i64 0
    %2:_(i32) = G_TRUNC %1(i64)
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %0(<4 x i32>), %2(i32)
    $vgpr0 = COPY %3(i32)
...

---
name: extract_vector_elt_7_v64s32

body: |
  bb.0:
    liveins: $sgpr0_sgpr1

    ; CHECK-LABEL: name: extract_vector_elt_7_v64s32
    ; CHECK: liveins: $sgpr0_sgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p1) = COPY $sgpr0_sgpr1
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:_(<16 x i32>) = G_LOAD [[COPY]](p1) :: (load (<16 x i32>), align 4, addrspace 4)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32), [[UV8:%[0-9]+]]:_(i32), [[UV9:%[0-9]+]]:_(i32), [[UV10:%[0-9]+]]:_(i32), [[UV11:%[0-9]+]]:_(i32), [[UV12:%[0-9]+]]:_(i32), [[UV13:%[0-9]+]]:_(i32), [[UV14:%[0-9]+]]:_(i32), [[UV15:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<16 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV7]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[COPY1]](i32)
    %0:_(p1) = COPY $sgpr0_sgpr1
    %1:_(i32) = G_CONSTANT i32 7
    %2:_(<64 x i32>) = G_LOAD %0(p1) :: (load (<64 x i32>), align 4, addrspace 4)
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %2(<64 x i32>), %1(i32)
    S_ENDPGM 0, implicit %3(i32)
...

---
name: extract_vector_elt_33_v64s32

body: |
  bb.0:
    liveins: $sgpr0_sgpr1

    ; CHECK-LABEL: name: extract_vector_elt_33_v64s32
    ; CHECK: liveins: $sgpr0_sgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p1) = COPY $sgpr0_sgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i64) = G_CONSTANT i64 128
    ; CHECK-NEXT: [[PTR_ADD:%[0-9]+]]:_(p1) = G_PTR_ADD [[COPY]], [[C]](i64)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:_(<16 x i32>) = G_LOAD [[PTR_ADD]](p1) :: (load (<16 x i32>) from unknown-address + 128, align 4, addrspace 4)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32), [[UV8:%[0-9]+]]:_(i32), [[UV9:%[0-9]+]]:_(i32), [[UV10:%[0-9]+]]:_(i32), [[UV11:%[0-9]+]]:_(i32), [[UV12:%[0-9]+]]:_(i32), [[UV13:%[0-9]+]]:_(i32), [[UV14:%[0-9]+]]:_(i32), [[UV15:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<16 x i32>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY [[UV1]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[COPY1]](i32)
    %0:_(p1) = COPY $sgpr0_sgpr1
    %1:_(i32) = G_CONSTANT i32 33
    %2:_(<64 x i32>) = G_LOAD %0(p1) :: (load (<64 x i32>), align 4, addrspace 4)
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %2(<64 x i32>), %1(i32)
    S_ENDPGM 0, implicit %3(i32)
...

# Test handling of out of bounds indexes
---
name: extract_vector_elt_64_65_v64s32

body: |
  bb.0:
    liveins: $sgpr0_sgpr1

    ; CHECK-LABEL: name: extract_vector_elt_64_65_v64s32
    ; CHECK: liveins: $sgpr0_sgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(i32) = G_IMPLICIT_DEF
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY [[DEF]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[COPY]](i32), implicit [[DEF]](i32)
    %0:_(p1) = COPY $sgpr0_sgpr1
    %1:_(i32) = G_CONSTANT i32 64
    %2:_(<64 x i32>) = G_LOAD %0(p1) :: (load (<64 x i32>), align 4, addrspace 4)
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %2(<64 x i32>), %1(i32)
    %4:_(i32) = G_CONSTANT i32 65
    %5:_(i32) = G_EXTRACT_VECTOR_ELT %2(<64 x i32>), %4(i32)
    S_ENDPGM 0, implicit %3(i32), implicit %5(i32)
...

---
name: extract_vector_elt_33_v64p3

body: |
  bb.0:
    liveins: $sgpr0_sgpr1

    ; CHECK-LABEL: name: extract_vector_elt_33_v64p3
    ; CHECK: liveins: $sgpr0_sgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p1) = COPY $sgpr0_sgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i64) = G_CONSTANT i64 128
    ; CHECK-NEXT: [[PTR_ADD:%[0-9]+]]:_(p1) = G_PTR_ADD [[COPY]], [[C]](i64)
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:_(<16 x i32>) = G_LOAD [[PTR_ADD]](p1) :: (load (<16 x i32>) from unknown-address + 128, align 4, addrspace 4)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<16 x p3>) = G_BITCAST [[LOAD]](<16 x i32>)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(p3), [[UV1:%[0-9]+]]:_(p3), [[UV2:%[0-9]+]]:_(p3), [[UV3:%[0-9]+]]:_(p3), [[UV4:%[0-9]+]]:_(p3), [[UV5:%[0-9]+]]:_(p3), [[UV6:%[0-9]+]]:_(p3), [[UV7:%[0-9]+]]:_(p3), [[UV8:%[0-9]+]]:_(p3), [[UV9:%[0-9]+]]:_(p3), [[UV10:%[0-9]+]]:_(p3), [[UV11:%[0-9]+]]:_(p3), [[UV12:%[0-9]+]]:_(p3), [[UV13:%[0-9]+]]:_(p3), [[UV14:%[0-9]+]]:_(p3), [[UV15:%[0-9]+]]:_(p3) = G_UNMERGE_VALUES [[BITCAST]](<16 x p3>)
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(p3) = COPY [[UV1]](p3)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[COPY1]](p3)
    %0:_(p1) = COPY $sgpr0_sgpr1
    %1:_(i32) = G_CONSTANT i32 33
    %2:_(<64 x p3>) = G_LOAD %0(p1) :: (load (<64 x p3>), align 4, addrspace 4)
    %3:_(p3) = G_EXTRACT_VECTOR_ELT %2(<64 x p3>), %1(i32)
    S_ENDPGM 0, implicit %3(p3)
...

---
name: extract_vector_elt_varidx_v64s32

body: |
  bb.0:
    liveins: $sgpr0_sgpr1, $sgpr2

    ; CHECK-LABEL: name: extract_vector_elt_varidx_v64s32
    ; CHECK: liveins: $sgpr0_sgpr1, $sgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p1) = COPY $sgpr0_sgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $sgpr2
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:_(<16 x i32>) = G_LOAD [[COPY]](p1) :: (load (<16 x i32>), align 4, addrspace 4)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i64) = G_CONSTANT i64 64
    ; CHECK-NEXT: [[PTR_ADD:%[0-9]+]]:_(p1) = G_PTR_ADD [[COPY]], [[C]](i64)
    ; CHECK-NEXT: [[LOAD1:%[0-9]+]]:_(<16 x i32>) = G_LOAD [[PTR_ADD]](p1) :: (load (<16 x i32>) from unknown-address + 64, align 4, addrspace 4)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i64) = G_CONSTANT i64 128
    ; CHECK-NEXT: [[PTR_ADD1:%[0-9]+]]:_(p1) = G_PTR_ADD [[COPY]], [[C1]](i64)
    ; CHECK-NEXT: [[LOAD2:%[0-9]+]]:_(<16 x i32>) = G_LOAD [[PTR_ADD1]](p1) :: (load (<16 x i32>) from unknown-address + 128, align 4, addrspace 4)
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(i64) = G_CONSTANT i64 192
    ; CHECK-NEXT: [[PTR_ADD2:%[0-9]+]]:_(p1) = G_PTR_ADD [[COPY]], [[C2]](i64)
    ; CHECK-NEXT: [[LOAD3:%[0-9]+]]:_(<16 x i32>) = G_LOAD [[PTR_ADD2]](p1) :: (load (<16 x i32>) from unknown-address + 192, align 4, addrspace 4)
    ; CHECK-NEXT: [[FRAME_INDEX:%[0-9]+]]:_(p5) = G_FRAME_INDEX %stack.0
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32), [[UV8:%[0-9]+]]:_(i32), [[UV9:%[0-9]+]]:_(i32), [[UV10:%[0-9]+]]:_(i32), [[UV11:%[0-9]+]]:_(i32), [[UV12:%[0-9]+]]:_(i32), [[UV13:%[0-9]+]]:_(i32), [[UV14:%[0-9]+]]:_(i32), [[UV15:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<16 x i32>)
    ; CHECK-NEXT: [[UV16:%[0-9]+]]:_(i32), [[UV17:%[0-9]+]]:_(i32), [[UV18:%[0-9]+]]:_(i32), [[UV19:%[0-9]+]]:_(i32), [[UV20:%[0-9]+]]:_(i32), [[UV21:%[0-9]+]]:_(i32), [[UV22:%[0-9]+]]:_(i32), [[UV23:%[0-9]+]]:_(i32), [[UV24:%[0-9]+]]:_(i32), [[UV25:%[0-9]+]]:_(i32), [[UV26:%[0-9]+]]:_(i32), [[UV27:%[0-9]+]]:_(i32), [[UV28:%[0-9]+]]:_(i32), [[UV29:%[0-9]+]]:_(i32), [[UV30:%[0-9]+]]:_(i32), [[UV31:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD1]](<16 x i32>)
    ; CHECK-NEXT: [[UV32:%[0-9]+]]:_(i32), [[UV33:%[0-9]+]]:_(i32), [[UV34:%[0-9]+]]:_(i32), [[UV35:%[0-9]+]]:_(i32), [[UV36:%[0-9]+]]:_(i32), [[UV37:%[0-9]+]]:_(i32), [[UV38:%[0-9]+]]:_(i32), [[UV39:%[0-9]+]]:_(i32), [[UV40:%[0-9]+]]:_(i32), [[UV41:%[0-9]+]]:_(i32), [[UV42:%[0-9]+]]:_(i32), [[UV43:%[0-9]+]]:_(i32), [[UV44:%[0-9]+]]:_(i32), [[UV45:%[0-9]+]]:_(i32), [[UV46:%[0-9]+]]:_(i32), [[UV47:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD2]](<16 x i32>)
    ; CHECK-NEXT: [[UV48:%[0-9]+]]:_(i32), [[UV49:%[0-9]+]]:_(i32), [[UV50:%[0-9]+]]:_(i32), [[UV51:%[0-9]+]]:_(i32), [[UV52:%[0-9]+]]:_(i32), [[UV53:%[0-9]+]]:_(i32), [[UV54:%[0-9]+]]:_(i32), [[UV55:%[0-9]+]]:_(i32), [[UV56:%[0-9]+]]:_(i32), [[UV57:%[0-9]+]]:_(i32), [[UV58:%[0-9]+]]:_(i32), [[UV59:%[0-9]+]]:_(i32), [[UV60:%[0-9]+]]:_(i32), [[UV61:%[0-9]+]]:_(i32), [[UV62:%[0-9]+]]:_(i32), [[UV63:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD3]](<16 x i32>)
    ; CHECK-NEXT: G_STORE [[UV]](i32), [[FRAME_INDEX]](p5) :: (store (i32) into %stack.0, align 256, addrspace 5)
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(i32) = G_CONSTANT i32 4
    ; CHECK-NEXT: [[PTR_ADD3:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C3]](i32)
    ; CHECK-NEXT: G_STORE [[UV1]](i32), [[PTR_ADD3]](p5) :: (store (i32) into %stack.0 + 4, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C4:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[PTR_ADD4:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C4]](i32)
    ; CHECK-NEXT: G_STORE [[UV2]](i32), [[PTR_ADD4]](p5) :: (store (i32) into %stack.0 + 8, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C5:%[0-9]+]]:_(i32) = G_CONSTANT i32 12
    ; CHECK-NEXT: [[PTR_ADD5:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C5]](i32)
    ; CHECK-NEXT: G_STORE [[UV3]](i32), [[PTR_ADD5]](p5) :: (store (i32) into %stack.0 + 12, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C6:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[PTR_ADD6:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C6]](i32)
    ; CHECK-NEXT: G_STORE [[UV4]](i32), [[PTR_ADD6]](p5) :: (store (i32) into %stack.0 + 16, align 16, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C7:%[0-9]+]]:_(i32) = G_CONSTANT i32 20
    ; CHECK-NEXT: [[PTR_ADD7:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C7]](i32)
    ; CHECK-NEXT: G_STORE [[UV5]](i32), [[PTR_ADD7]](p5) :: (store (i32) into %stack.0 + 20, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C8:%[0-9]+]]:_(i32) = G_CONSTANT i32 24
    ; CHECK-NEXT: [[PTR_ADD8:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C8]](i32)
    ; CHECK-NEXT: G_STORE [[UV6]](i32), [[PTR_ADD8]](p5) :: (store (i32) into %stack.0 + 24, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C9:%[0-9]+]]:_(i32) = G_CONSTANT i32 28
    ; CHECK-NEXT: [[PTR_ADD9:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C9]](i32)
    ; CHECK-NEXT: G_STORE [[UV7]](i32), [[PTR_ADD9]](p5) :: (store (i32) into %stack.0 + 28, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C10:%[0-9]+]]:_(i32) = G_CONSTANT i32 32
    ; CHECK-NEXT: [[PTR_ADD10:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C10]](i32)
    ; CHECK-NEXT: G_STORE [[UV8]](i32), [[PTR_ADD10]](p5) :: (store (i32) into %stack.0 + 32, align 32, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C11:%[0-9]+]]:_(i32) = G_CONSTANT i32 36
    ; CHECK-NEXT: [[PTR_ADD11:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C11]](i32)
    ; CHECK-NEXT: G_STORE [[UV9]](i32), [[PTR_ADD11]](p5) :: (store (i32) into %stack.0 + 36, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C12:%[0-9]+]]:_(i32) = G_CONSTANT i32 40
    ; CHECK-NEXT: [[PTR_ADD12:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C12]](i32)
    ; CHECK-NEXT: G_STORE [[UV10]](i32), [[PTR_ADD12]](p5) :: (store (i32) into %stack.0 + 40, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C13:%[0-9]+]]:_(i32) = G_CONSTANT i32 44
    ; CHECK-NEXT: [[PTR_ADD13:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C13]](i32)
    ; CHECK-NEXT: G_STORE [[UV11]](i32), [[PTR_ADD13]](p5) :: (store (i32) into %stack.0 + 44, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C14:%[0-9]+]]:_(i32) = G_CONSTANT i32 48
    ; CHECK-NEXT: [[PTR_ADD14:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C14]](i32)
    ; CHECK-NEXT: G_STORE [[UV12]](i32), [[PTR_ADD14]](p5) :: (store (i32) into %stack.0 + 48, align 16, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C15:%[0-9]+]]:_(i32) = G_CONSTANT i32 52
    ; CHECK-NEXT: [[PTR_ADD15:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C15]](i32)
    ; CHECK-NEXT: G_STORE [[UV13]](i32), [[PTR_ADD15]](p5) :: (store (i32) into %stack.0 + 52, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C16:%[0-9]+]]:_(i32) = G_CONSTANT i32 56
    ; CHECK-NEXT: [[PTR_ADD16:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C16]](i32)
    ; CHECK-NEXT: G_STORE [[UV14]](i32), [[PTR_ADD16]](p5) :: (store (i32) into %stack.0 + 56, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C17:%[0-9]+]]:_(i32) = G_CONSTANT i32 60
    ; CHECK-NEXT: [[PTR_ADD17:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C17]](i32)
    ; CHECK-NEXT: G_STORE [[UV15]](i32), [[PTR_ADD17]](p5) :: (store (i32) into %stack.0 + 60, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C18:%[0-9]+]]:_(i32) = G_CONSTANT i32 64
    ; CHECK-NEXT: [[PTR_ADD18:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C18]](i32)
    ; CHECK-NEXT: G_STORE [[UV16]](i32), [[PTR_ADD18]](p5) :: (store (i32) into %stack.0 + 64, align 64, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C19:%[0-9]+]]:_(i32) = G_CONSTANT i32 68
    ; CHECK-NEXT: [[PTR_ADD19:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C19]](i32)
    ; CHECK-NEXT: G_STORE [[UV17]](i32), [[PTR_ADD19]](p5) :: (store (i32) into %stack.0 + 68, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C20:%[0-9]+]]:_(i32) = G_CONSTANT i32 72
    ; CHECK-NEXT: [[PTR_ADD20:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C20]](i32)
    ; CHECK-NEXT: G_STORE [[UV18]](i32), [[PTR_ADD20]](p5) :: (store (i32) into %stack.0 + 72, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C21:%[0-9]+]]:_(i32) = G_CONSTANT i32 76
    ; CHECK-NEXT: [[PTR_ADD21:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C21]](i32)
    ; CHECK-NEXT: G_STORE [[UV19]](i32), [[PTR_ADD21]](p5) :: (store (i32) into %stack.0 + 76, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C22:%[0-9]+]]:_(i32) = G_CONSTANT i32 80
    ; CHECK-NEXT: [[PTR_ADD22:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C22]](i32)
    ; CHECK-NEXT: G_STORE [[UV20]](i32), [[PTR_ADD22]](p5) :: (store (i32) into %stack.0 + 80, align 16, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C23:%[0-9]+]]:_(i32) = G_CONSTANT i32 84
    ; CHECK-NEXT: [[PTR_ADD23:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C23]](i32)
    ; CHECK-NEXT: G_STORE [[UV21]](i32), [[PTR_ADD23]](p5) :: (store (i32) into %stack.0 + 84, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C24:%[0-9]+]]:_(i32) = G_CONSTANT i32 88
    ; CHECK-NEXT: [[PTR_ADD24:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C24]](i32)
    ; CHECK-NEXT: G_STORE [[UV22]](i32), [[PTR_ADD24]](p5) :: (store (i32) into %stack.0 + 88, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C25:%[0-9]+]]:_(i32) = G_CONSTANT i32 92
    ; CHECK-NEXT: [[PTR_ADD25:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C25]](i32)
    ; CHECK-NEXT: G_STORE [[UV23]](i32), [[PTR_ADD25]](p5) :: (store (i32) into %stack.0 + 92, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C26:%[0-9]+]]:_(i32) = G_CONSTANT i32 96
    ; CHECK-NEXT: [[PTR_ADD26:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C26]](i32)
    ; CHECK-NEXT: G_STORE [[UV24]](i32), [[PTR_ADD26]](p5) :: (store (i32) into %stack.0 + 96, align 32, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C27:%[0-9]+]]:_(i32) = G_CONSTANT i32 100
    ; CHECK-NEXT: [[PTR_ADD27:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C27]](i32)
    ; CHECK-NEXT: G_STORE [[UV25]](i32), [[PTR_ADD27]](p5) :: (store (i32) into %stack.0 + 100, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C28:%[0-9]+]]:_(i32) = G_CONSTANT i32 104
    ; CHECK-NEXT: [[PTR_ADD28:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C28]](i32)
    ; CHECK-NEXT: G_STORE [[UV26]](i32), [[PTR_ADD28]](p5) :: (store (i32) into %stack.0 + 104, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C29:%[0-9]+]]:_(i32) = G_CONSTANT i32 108
    ; CHECK-NEXT: [[PTR_ADD29:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C29]](i32)
    ; CHECK-NEXT: G_STORE [[UV27]](i32), [[PTR_ADD29]](p5) :: (store (i32) into %stack.0 + 108, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C30:%[0-9]+]]:_(i32) = G_CONSTANT i32 112
    ; CHECK-NEXT: [[PTR_ADD30:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C30]](i32)
    ; CHECK-NEXT: G_STORE [[UV28]](i32), [[PTR_ADD30]](p5) :: (store (i32) into %stack.0 + 112, align 16, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C31:%[0-9]+]]:_(i32) = G_CONSTANT i32 116
    ; CHECK-NEXT: [[PTR_ADD31:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C31]](i32)
    ; CHECK-NEXT: G_STORE [[UV29]](i32), [[PTR_ADD31]](p5) :: (store (i32) into %stack.0 + 116, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C32:%[0-9]+]]:_(i32) = G_CONSTANT i32 120
    ; CHECK-NEXT: [[PTR_ADD32:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C32]](i32)
    ; CHECK-NEXT: G_STORE [[UV30]](i32), [[PTR_ADD32]](p5) :: (store (i32) into %stack.0 + 120, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C33:%[0-9]+]]:_(i32) = G_CONSTANT i32 124
    ; CHECK-NEXT: [[PTR_ADD33:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C33]](i32)
    ; CHECK-NEXT: G_STORE [[UV31]](i32), [[PTR_ADD33]](p5) :: (store (i32) into %stack.0 + 124, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C34:%[0-9]+]]:_(i32) = G_CONSTANT i32 128
    ; CHECK-NEXT: [[PTR_ADD34:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C34]](i32)
    ; CHECK-NEXT: G_STORE [[UV32]](i32), [[PTR_ADD34]](p5) :: (store (i32) into %stack.0 + 128, align 128, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C35:%[0-9]+]]:_(i32) = G_CONSTANT i32 132
    ; CHECK-NEXT: [[PTR_ADD35:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C35]](i32)
    ; CHECK-NEXT: G_STORE [[UV33]](i32), [[PTR_ADD35]](p5) :: (store (i32) into %stack.0 + 132, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C36:%[0-9]+]]:_(i32) = G_CONSTANT i32 136
    ; CHECK-NEXT: [[PTR_ADD36:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C36]](i32)
    ; CHECK-NEXT: G_STORE [[UV34]](i32), [[PTR_ADD36]](p5) :: (store (i32) into %stack.0 + 136, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C37:%[0-9]+]]:_(i32) = G_CONSTANT i32 140
    ; CHECK-NEXT: [[PTR_ADD37:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C37]](i32)
    ; CHECK-NEXT: G_STORE [[UV35]](i32), [[PTR_ADD37]](p5) :: (store (i32) into %stack.0 + 140, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C38:%[0-9]+]]:_(i32) = G_CONSTANT i32 144
    ; CHECK-NEXT: [[PTR_ADD38:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C38]](i32)
    ; CHECK-NEXT: G_STORE [[UV36]](i32), [[PTR_ADD38]](p5) :: (store (i32) into %stack.0 + 144, align 16, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C39:%[0-9]+]]:_(i32) = G_CONSTANT i32 148
    ; CHECK-NEXT: [[PTR_ADD39:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C39]](i32)
    ; CHECK-NEXT: G_STORE [[UV37]](i32), [[PTR_ADD39]](p5) :: (store (i32) into %stack.0 + 148, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C40:%[0-9]+]]:_(i32) = G_CONSTANT i32 152
    ; CHECK-NEXT: [[PTR_ADD40:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C40]](i32)
    ; CHECK-NEXT: G_STORE [[UV38]](i32), [[PTR_ADD40]](p5) :: (store (i32) into %stack.0 + 152, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C41:%[0-9]+]]:_(i32) = G_CONSTANT i32 156
    ; CHECK-NEXT: [[PTR_ADD41:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C41]](i32)
    ; CHECK-NEXT: G_STORE [[UV39]](i32), [[PTR_ADD41]](p5) :: (store (i32) into %stack.0 + 156, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C42:%[0-9]+]]:_(i32) = G_CONSTANT i32 160
    ; CHECK-NEXT: [[PTR_ADD42:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C42]](i32)
    ; CHECK-NEXT: G_STORE [[UV40]](i32), [[PTR_ADD42]](p5) :: (store (i32) into %stack.0 + 160, align 32, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C43:%[0-9]+]]:_(i32) = G_CONSTANT i32 164
    ; CHECK-NEXT: [[PTR_ADD43:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C43]](i32)
    ; CHECK-NEXT: G_STORE [[UV41]](i32), [[PTR_ADD43]](p5) :: (store (i32) into %stack.0 + 164, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C44:%[0-9]+]]:_(i32) = G_CONSTANT i32 168
    ; CHECK-NEXT: [[PTR_ADD44:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C44]](i32)
    ; CHECK-NEXT: G_STORE [[UV42]](i32), [[PTR_ADD44]](p5) :: (store (i32) into %stack.0 + 168, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C45:%[0-9]+]]:_(i32) = G_CONSTANT i32 172
    ; CHECK-NEXT: [[PTR_ADD45:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C45]](i32)
    ; CHECK-NEXT: G_STORE [[UV43]](i32), [[PTR_ADD45]](p5) :: (store (i32) into %stack.0 + 172, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C46:%[0-9]+]]:_(i32) = G_CONSTANT i32 176
    ; CHECK-NEXT: [[PTR_ADD46:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C46]](i32)
    ; CHECK-NEXT: G_STORE [[UV44]](i32), [[PTR_ADD46]](p5) :: (store (i32) into %stack.0 + 176, align 16, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C47:%[0-9]+]]:_(i32) = G_CONSTANT i32 180
    ; CHECK-NEXT: [[PTR_ADD47:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C47]](i32)
    ; CHECK-NEXT: G_STORE [[UV45]](i32), [[PTR_ADD47]](p5) :: (store (i32) into %stack.0 + 180, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C48:%[0-9]+]]:_(i32) = G_CONSTANT i32 184
    ; CHECK-NEXT: [[PTR_ADD48:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C48]](i32)
    ; CHECK-NEXT: G_STORE [[UV46]](i32), [[PTR_ADD48]](p5) :: (store (i32) into %stack.0 + 184, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C49:%[0-9]+]]:_(i32) = G_CONSTANT i32 188
    ; CHECK-NEXT: [[PTR_ADD49:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C49]](i32)
    ; CHECK-NEXT: G_STORE [[UV47]](i32), [[PTR_ADD49]](p5) :: (store (i32) into %stack.0 + 188, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C50:%[0-9]+]]:_(i32) = G_CONSTANT i32 192
    ; CHECK-NEXT: [[PTR_ADD50:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C50]](i32)
    ; CHECK-NEXT: G_STORE [[UV48]](i32), [[PTR_ADD50]](p5) :: (store (i32) into %stack.0 + 192, align 64, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C51:%[0-9]+]]:_(i32) = G_CONSTANT i32 196
    ; CHECK-NEXT: [[PTR_ADD51:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C51]](i32)
    ; CHECK-NEXT: G_STORE [[UV49]](i32), [[PTR_ADD51]](p5) :: (store (i32) into %stack.0 + 196, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C52:%[0-9]+]]:_(i32) = G_CONSTANT i32 200
    ; CHECK-NEXT: [[PTR_ADD52:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C52]](i32)
    ; CHECK-NEXT: G_STORE [[UV50]](i32), [[PTR_ADD52]](p5) :: (store (i32) into %stack.0 + 200, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C53:%[0-9]+]]:_(i32) = G_CONSTANT i32 204
    ; CHECK-NEXT: [[PTR_ADD53:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C53]](i32)
    ; CHECK-NEXT: G_STORE [[UV51]](i32), [[PTR_ADD53]](p5) :: (store (i32) into %stack.0 + 204, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C54:%[0-9]+]]:_(i32) = G_CONSTANT i32 208
    ; CHECK-NEXT: [[PTR_ADD54:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C54]](i32)
    ; CHECK-NEXT: G_STORE [[UV52]](i32), [[PTR_ADD54]](p5) :: (store (i32) into %stack.0 + 208, align 16, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C55:%[0-9]+]]:_(i32) = G_CONSTANT i32 212
    ; CHECK-NEXT: [[PTR_ADD55:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C55]](i32)
    ; CHECK-NEXT: G_STORE [[UV53]](i32), [[PTR_ADD55]](p5) :: (store (i32) into %stack.0 + 212, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C56:%[0-9]+]]:_(i32) = G_CONSTANT i32 216
    ; CHECK-NEXT: [[PTR_ADD56:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C56]](i32)
    ; CHECK-NEXT: G_STORE [[UV54]](i32), [[PTR_ADD56]](p5) :: (store (i32) into %stack.0 + 216, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C57:%[0-9]+]]:_(i32) = G_CONSTANT i32 220
    ; CHECK-NEXT: [[PTR_ADD57:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C57]](i32)
    ; CHECK-NEXT: G_STORE [[UV55]](i32), [[PTR_ADD57]](p5) :: (store (i32) into %stack.0 + 220, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C58:%[0-9]+]]:_(i32) = G_CONSTANT i32 224
    ; CHECK-NEXT: [[PTR_ADD58:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C58]](i32)
    ; CHECK-NEXT: G_STORE [[UV56]](i32), [[PTR_ADD58]](p5) :: (store (i32) into %stack.0 + 224, align 32, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C59:%[0-9]+]]:_(i32) = G_CONSTANT i32 228
    ; CHECK-NEXT: [[PTR_ADD59:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C59]](i32)
    ; CHECK-NEXT: G_STORE [[UV57]](i32), [[PTR_ADD59]](p5) :: (store (i32) into %stack.0 + 228, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C60:%[0-9]+]]:_(i32) = G_CONSTANT i32 232
    ; CHECK-NEXT: [[PTR_ADD60:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C60]](i32)
    ; CHECK-NEXT: G_STORE [[UV58]](i32), [[PTR_ADD60]](p5) :: (store (i32) into %stack.0 + 232, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C61:%[0-9]+]]:_(i32) = G_CONSTANT i32 236
    ; CHECK-NEXT: [[PTR_ADD61:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C61]](i32)
    ; CHECK-NEXT: G_STORE [[UV59]](i32), [[PTR_ADD61]](p5) :: (store (i32) into %stack.0 + 236, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C62:%[0-9]+]]:_(i32) = G_CONSTANT i32 240
    ; CHECK-NEXT: [[PTR_ADD62:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C62]](i32)
    ; CHECK-NEXT: G_STORE [[UV60]](i32), [[PTR_ADD62]](p5) :: (store (i32) into %stack.0 + 240, align 16, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C63:%[0-9]+]]:_(i32) = G_CONSTANT i32 244
    ; CHECK-NEXT: [[PTR_ADD63:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C63]](i32)
    ; CHECK-NEXT: G_STORE [[UV61]](i32), [[PTR_ADD63]](p5) :: (store (i32) into %stack.0 + 244, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C64:%[0-9]+]]:_(i32) = G_CONSTANT i32 248
    ; CHECK-NEXT: [[PTR_ADD64:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C64]](i32)
    ; CHECK-NEXT: G_STORE [[UV62]](i32), [[PTR_ADD64]](p5) :: (store (i32) into %stack.0 + 248, align 8, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C65:%[0-9]+]]:_(i32) = G_CONSTANT i32 252
    ; CHECK-NEXT: [[PTR_ADD65:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[C65]](i32)
    ; CHECK-NEXT: G_STORE [[UV63]](i32), [[PTR_ADD65]](p5) :: (store (i32) into %stack.0 + 252, basealign 256, addrspace 5)
    ; CHECK-NEXT: [[C66:%[0-9]+]]:_(i32) = G_CONSTANT i32 63
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C66]]
    ; CHECK-NEXT: [[MUL:%[0-9]+]]:_(i32) = G_MUL [[AND]], [[C3]]
    ; CHECK-NEXT: [[PTR_ADD66:%[0-9]+]]:_(p5) = G_PTR_ADD [[FRAME_INDEX]], [[MUL]](i32)
    ; CHECK-NEXT: [[LOAD4:%[0-9]+]]:_(i32) = G_LOAD [[PTR_ADD66]](p5) :: (load (i32), addrspace 5)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[LOAD4]](i32)
    %0:_(p1) = COPY $sgpr0_sgpr1
    %1:_(i32) = COPY $sgpr2
    %2:_(<64 x i32>) = G_LOAD %0(p1) :: (load (<64 x i32>), align 4, addrspace 4)
    %3:_(i32) = G_EXTRACT_VECTOR_ELT %2(<64 x i32>), %1(i32)
    S_ENDPGM 0, implicit %3(i32)
...

---
name: extract_vector_elt_v32s1_varidx_i32

body: |
  bb.0:
    liveins: $vgpr0, $vgpr1

    ; CHECK-LABEL: name: extract_vector_elt_v32s1_varidx_i32
    ; CHECK: liveins: $vgpr0, $vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 31
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 0
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND]], [[C1]](i32)
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[SHL]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(<32 x i1>) = G_BITCAST %0(i32)
    %3:_(i1) = G_EXTRACT_VECTOR_ELT %2(<32 x i1>), %1(i32)
    %4:_(i32) = G_ANYEXT %3(i1)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v12s8_varidx_s32

body: |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2, $vgpr3
    ; CHECK-LABEL: name: extract_vector_elt_v12s8_varidx_s32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2, $vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 2
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[COPY]](<3 x i32>), [[LSHR]](i32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 3
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY1]], [[C1]]
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND]], [[C1]](i32)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[EVEC]], [[SHL]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[LSHR1]](i32)
    %0:_(<3 x i32>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(<12 x i8>) = G_BITCAST %0(<3 x i32>)
    %2:_(i32) = COPY $vgpr3
    %3:_(i8) = G_EXTRACT_VECTOR_ELT %1(<12 x i8>), %2(i32)
    %4:_(i32) = G_ANYEXT %3(i8)
    $vgpr0 = COPY %4(i32)
...

---
name: extract_vector_elt_v3s8_varidx_s32

body: |
  bb.0:
    liveins: $vgpr0, $vgpr1
    ; CHECK-LABEL: name: extract_vector_elt_v3s8_varidx_s32
    ; CHECK: liveins: $vgpr0, $vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C1]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[LSHR]](i32), [[LSHR1]](i32)
    ; CHECK-NEXT: [[EVEC:%[0-9]+]]:_(i32) = G_EXTRACT_VECTOR_ELT [[BUILD_VECTOR]](<3 x i32>), [[COPY1]](i32)
    ; CHECK-NEXT: $vgpr0 = COPY [[EVEC]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i24) = G_TRUNC %0(i32)
    %3:_(<3 x i8>) = G_BITCAST %2(i24)
    %4:_(i8) = G_EXTRACT_VECTOR_ELT %3(<3 x i8>), %1(i32)
    %5:_(i32) = G_ANYEXT %4(i8)
    $vgpr0 = COPY %5(i32)
...
