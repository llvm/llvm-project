# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
# RUN: llc -mtriple=amdgcn -mcpu=gfx1010 -run-pass=regbankselect %s -verify-machineinstrs -o - | FileCheck %s -check-prefixes=OLD_RBS
# RUN: llc -mtriple=amdgcn -mcpu=gfx1010 -run-pass="amdgpu-regbankselect,amdgpu-regbanklegalize" %s -verify-machineinstrs -o - | FileCheck %s -check-prefixes=NEW_RBS

---
name: uniform_in_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1

    ; OLD_RBS-LABEL: name: uniform_in_vgpr
    ; OLD_RBS: liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; OLD_RBS-NEXT: [[BITCAST:%[0-9]+]]:sgpr(f32) = G_BITCAST [[COPY]](i32)
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(f32) = COPY [[BITCAST]](f32)
    ; OLD_RBS-NEXT: [[FPTOUI:%[0-9]+]]:vgpr(i32) = G_FPTOUI [[COPY4]](f32)
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY [[COPY1]](i32)
    ; OLD_RBS-NEXT: [[ADD:%[0-9]+]]:vgpr(i32) = G_ADD [[FPTOUI]], [[COPY5]]
    ; OLD_RBS-NEXT: G_STORE [[ADD]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: uniform_in_vgpr
    ; NEW_RBS: liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; NEW_RBS-NEXT: [[BITCAST:%[0-9]+]]:sgpr(f32) = G_BITCAST [[COPY]](i32)
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(f32) = COPY [[BITCAST]](f32)
    ; NEW_RBS-NEXT: [[FPTOUI:%[0-9]+]]:vgpr(i32) = G_FPTOUI [[COPY4]](f32)
    ; NEW_RBS-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(i32) = G_AMDGPU_READANYLANE [[FPTOUI]]
    ; NEW_RBS-NEXT: [[ADD:%[0-9]+]]:sgpr(i32) = G_ADD [[AMDGPU_READANYLANE]], [[COPY1]]
    ; NEW_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY [[ADD]](i32)
    ; NEW_RBS-NEXT: G_STORE [[COPY5]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $sgpr1
    %2:_(i32) = COPY $vgpr0
    %3:_(i32) = COPY $vgpr1
    %4:_(p1) = G_MERGE_VALUES %2(i32), %3(i32)
    %5:_(f32) = G_BITCAST %0(i32)
    %6:_(i32) = G_FPTOUI %5(f32)
    %7:_(i32) = G_ADD %6, %1
    G_STORE %7(i32), %4(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: back_to_back_uniform_in_vgpr
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $vgpr0, $vgpr1

    ; OLD_RBS-LABEL: name: back_to_back_uniform_in_vgpr
    ; OLD_RBS: liveins: $sgpr0, $sgpr1, $sgpr2, $vgpr0, $vgpr1
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr2
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY3]](i32), [[COPY4]](i32)
    ; OLD_RBS-NEXT: [[BITCAST:%[0-9]+]]:sgpr(f32) = G_BITCAST [[COPY]](i32)
    ; OLD_RBS-NEXT: [[BITCAST1:%[0-9]+]]:sgpr(f32) = G_BITCAST [[COPY1]](i32)
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(f32) = COPY [[BITCAST]](f32)
    ; OLD_RBS-NEXT: [[COPY6:%[0-9]+]]:vgpr(f32) = COPY [[BITCAST1]](f32)
    ; OLD_RBS-NEXT: [[FADD:%[0-9]+]]:vgpr(f32) = G_FADD [[COPY5]], [[COPY6]]
    ; OLD_RBS-NEXT: [[FPTOUI:%[0-9]+]]:vgpr(i32) = G_FPTOUI [[FADD]](f32)
    ; OLD_RBS-NEXT: [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[COPY2]](i32)
    ; OLD_RBS-NEXT: [[ADD:%[0-9]+]]:vgpr(i32) = G_ADD [[FPTOUI]], [[COPY7]]
    ; OLD_RBS-NEXT: G_STORE [[ADD]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: back_to_back_uniform_in_vgpr
    ; NEW_RBS: liveins: $sgpr0, $sgpr1, $sgpr2, $vgpr0, $vgpr1
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr2
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY3]](i32), [[COPY4]](i32)
    ; NEW_RBS-NEXT: [[BITCAST:%[0-9]+]]:sgpr(f32) = G_BITCAST [[COPY]](i32)
    ; NEW_RBS-NEXT: [[BITCAST1:%[0-9]+]]:sgpr(f32) = G_BITCAST [[COPY1]](i32)
    ; NEW_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(f32) = COPY [[BITCAST]](f32)
    ; NEW_RBS-NEXT: [[COPY6:%[0-9]+]]:vgpr(f32) = COPY [[BITCAST1]](f32)
    ; NEW_RBS-NEXT: [[FADD:%[0-9]+]]:vgpr(f32) = G_FADD [[COPY5]], [[COPY6]]
    ; NEW_RBS-NEXT: [[FPTOUI:%[0-9]+]]:vgpr(i32) = G_FPTOUI [[FADD]](f32)
    ; NEW_RBS-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(i32) = G_AMDGPU_READANYLANE [[FPTOUI]]
    ; NEW_RBS-NEXT: [[ADD:%[0-9]+]]:sgpr(i32) = G_ADD [[AMDGPU_READANYLANE]], [[COPY2]]
    ; NEW_RBS-NEXT: [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[ADD]](i32)
    ; NEW_RBS-NEXT: G_STORE [[COPY7]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $sgpr1
    %2:_(i32) = COPY $sgpr2
    %3:_(i32) = COPY $vgpr0
    %4:_(i32) = COPY $vgpr1
    %5:_(p1) = G_MERGE_VALUES %3(i32), %4(i32)
    %6:_(f32) = G_BITCAST %0(i32)
    %7:_(f32) = G_BITCAST %1(i32)
    %8:_(f32) = G_FADD %6, %7
    %9:_(i32) = G_FPTOUI %8(f32)
    %10:_(i32) = G_ADD %9, %2
    G_STORE %10(i32), %5(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: buffer_load_uniform
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3, $sgpr4, $vgpr0, $vgpr1

    ; OLD_RBS-LABEL: name: buffer_load_uniform
    ; OLD_RBS: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3, $sgpr4, $vgpr0, $vgpr1
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr2
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:sgpr(i32) = COPY $sgpr3
    ; OLD_RBS-NEXT: [[BUILD_VECTOR:%[0-9]+]]:sgpr(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:sgpr(i32) = COPY $sgpr4
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY6:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY5]](i32), [[COPY6]](i32)
    ; OLD_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
    ; OLD_RBS-NEXT: [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[C]](i32)
    ; OLD_RBS-NEXT: [[COPY8:%[0-9]+]]:vgpr(i32) = COPY [[COPY4]](i32)
    ; OLD_RBS-NEXT: [[AMDGPU_BUFFER_LOAD:%[0-9]+]]:vgpr(<4 x i32>) = G_AMDGPU_BUFFER_LOAD [[BUILD_VECTOR]](<4 x i32>), [[COPY7]](i32), [[COPY8]], [[C]], 0, 0, 0 :: (dereferenceable load (<4 x i32>), align 1, addrspace 8)
    ; OLD_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
    ; OLD_RBS-NEXT: [[UV:%[0-9]+]]:vgpr(i32), [[UV1:%[0-9]+]]:vgpr(i32), [[UV2:%[0-9]+]]:vgpr(i32), [[UV3:%[0-9]+]]:vgpr(i32) = G_UNMERGE_VALUES [[AMDGPU_BUFFER_LOAD]](<4 x i32>)
    ; OLD_RBS-NEXT: [[COPY9:%[0-9]+]]:vgpr(i32) = COPY [[C1]](i32)
    ; OLD_RBS-NEXT: [[ADD:%[0-9]+]]:vgpr(i32) = G_ADD [[UV1]], [[COPY9]]
    ; OLD_RBS-NEXT: G_STORE [[ADD]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: buffer_load_uniform
    ; NEW_RBS: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3, $sgpr4, $vgpr0, $vgpr1
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr2
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:sgpr(i32) = COPY $sgpr3
    ; NEW_RBS-NEXT: [[BUILD_VECTOR:%[0-9]+]]:sgpr(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:sgpr(i32) = COPY $sgpr4
    ; NEW_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY6:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY5]](i32), [[COPY6]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
    ; NEW_RBS-NEXT: [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[C]](i32)
    ; NEW_RBS-NEXT: [[COPY8:%[0-9]+]]:vgpr(i32) = COPY [[COPY4]](i32)
    ; NEW_RBS-NEXT: [[AMDGPU_BUFFER_LOAD:%[0-9]+]]:vgpr(<4 x i32>) = G_AMDGPU_BUFFER_LOAD [[BUILD_VECTOR]](<4 x i32>), [[COPY7]](i32), [[COPY8]], [[C]], 0, 0, 0 :: (dereferenceable load (<4 x i32>), align 1, addrspace 8)
    ; NEW_RBS-NEXT: [[UV:%[0-9]+]]:vgpr(i32), [[UV1:%[0-9]+]]:vgpr(i32), [[UV2:%[0-9]+]]:vgpr(i32), [[UV3:%[0-9]+]]:vgpr(i32) = G_UNMERGE_VALUES [[AMDGPU_BUFFER_LOAD]](<4 x i32>)
    ; NEW_RBS-NEXT: [[AMDGPU_READANYLANE:%[0-9]+]]:sgpr(i32) = G_AMDGPU_READANYLANE [[UV]]
    ; NEW_RBS-NEXT: [[AMDGPU_READANYLANE1:%[0-9]+]]:sgpr(i32) = G_AMDGPU_READANYLANE [[UV1]]
    ; NEW_RBS-NEXT: [[AMDGPU_READANYLANE2:%[0-9]+]]:sgpr(i32) = G_AMDGPU_READANYLANE [[UV2]]
    ; NEW_RBS-NEXT: [[AMDGPU_READANYLANE3:%[0-9]+]]:sgpr(i32) = G_AMDGPU_READANYLANE [[UV3]]
    ; NEW_RBS-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:sgpr(<4 x i32>) = G_BUILD_VECTOR [[AMDGPU_READANYLANE]](i32), [[AMDGPU_READANYLANE1]](i32), [[AMDGPU_READANYLANE2]](i32), [[AMDGPU_READANYLANE3]](i32)
    ; NEW_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
    ; NEW_RBS-NEXT: [[UV4:%[0-9]+]]:sgpr(i32), [[UV5:%[0-9]+]]:sgpr(i32), [[UV6:%[0-9]+]]:sgpr(i32), [[UV7:%[0-9]+]]:sgpr(i32) = G_UNMERGE_VALUES [[BUILD_VECTOR1]](<4 x i32>)
    ; NEW_RBS-NEXT: [[ADD:%[0-9]+]]:sgpr(i32) = G_ADD [[UV5]], [[C1]]
    ; NEW_RBS-NEXT: [[COPY9:%[0-9]+]]:vgpr(i32) = COPY [[ADD]](i32)
    ; NEW_RBS-NEXT: G_STORE [[COPY9]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $sgpr1
    %2:_(i32) = COPY $sgpr2
    %3:_(i32) = COPY $sgpr3
    %4:_(<4 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32), %3(i32)
    %5:_(i32) = COPY $sgpr4
    %6:_(i32) = COPY $vgpr0
    %7:_(i32) = COPY $vgpr1
    %8:_(p1) = G_MERGE_VALUES %6(i32), %7(i32)
    %9:_(i32) = G_CONSTANT i32 0
    %10:_(<4 x i32>) = G_AMDGPU_BUFFER_LOAD %4(<4 x i32>), %9(i32), %5, %9, 0, 0, 0 :: (dereferenceable load (<4 x i32>), align 1, addrspace 8)
    %11:_(i32) = G_CONSTANT i32 1
    %12:_(i32), %13:_(i32), %14:_(i32), %15:_(i32) = G_UNMERGE_VALUES %10(<4 x i32>)
    %16:_(i32) = G_ADD %13, %11
    G_STORE %16(i32), %8(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: buffer_load_divergent
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3, $vgpr0, $vgpr1, $vgpr2

    ; OLD_RBS-LABEL: name: buffer_load_divergent
    ; OLD_RBS: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3, $vgpr0, $vgpr1, $vgpr2
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr2
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:sgpr(i32) = COPY $sgpr3
    ; OLD_RBS-NEXT: [[BUILD_VECTOR:%[0-9]+]]:sgpr(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[COPY6:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY5]](i32), [[COPY6]](i32)
    ; OLD_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
    ; OLD_RBS-NEXT: [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[C]](i32)
    ; OLD_RBS-NEXT: [[AMDGPU_BUFFER_LOAD:%[0-9]+]]:vgpr(<4 x i32>) = G_AMDGPU_BUFFER_LOAD [[BUILD_VECTOR]](<4 x i32>), [[COPY7]](i32), [[COPY4]], [[C]], 0, 0, 0 :: (dereferenceable load (<4 x i32>), align 1, addrspace 8)
    ; OLD_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
    ; OLD_RBS-NEXT: [[UV:%[0-9]+]]:vgpr(i32), [[UV1:%[0-9]+]]:vgpr(i32), [[UV2:%[0-9]+]]:vgpr(i32), [[UV3:%[0-9]+]]:vgpr(i32) = G_UNMERGE_VALUES [[AMDGPU_BUFFER_LOAD]](<4 x i32>)
    ; OLD_RBS-NEXT: [[COPY8:%[0-9]+]]:vgpr(i32) = COPY [[C1]](i32)
    ; OLD_RBS-NEXT: [[ADD:%[0-9]+]]:vgpr(i32) = G_ADD [[UV1]], [[COPY8]]
    ; OLD_RBS-NEXT: G_STORE [[ADD]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: buffer_load_divergent
    ; NEW_RBS: liveins: $sgpr0, $sgpr1, $sgpr2, $sgpr3, $vgpr0, $vgpr1, $vgpr2
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr2
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:sgpr(i32) = COPY $sgpr3
    ; NEW_RBS-NEXT: [[BUILD_VECTOR:%[0-9]+]]:sgpr(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[COPY6:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY5]](i32), [[COPY6]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
    ; NEW_RBS-NEXT: [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[C]](i32)
    ; NEW_RBS-NEXT: [[AMDGPU_BUFFER_LOAD:%[0-9]+]]:vgpr(<4 x i32>) = G_AMDGPU_BUFFER_LOAD [[BUILD_VECTOR]](<4 x i32>), [[COPY7]](i32), [[COPY4]], [[C]], 0, 0, 0 :: (dereferenceable load (<4 x i32>), align 1, addrspace 8)
    ; NEW_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
    ; NEW_RBS-NEXT: [[UV:%[0-9]+]]:vgpr(i32), [[UV1:%[0-9]+]]:vgpr(i32), [[UV2:%[0-9]+]]:vgpr(i32), [[UV3:%[0-9]+]]:vgpr(i32) = G_UNMERGE_VALUES [[AMDGPU_BUFFER_LOAD]](<4 x i32>)
    ; NEW_RBS-NEXT: [[COPY8:%[0-9]+]]:vgpr(i32) = COPY [[C1]](i32)
    ; NEW_RBS-NEXT: [[ADD:%[0-9]+]]:vgpr(i32) = G_ADD [[UV1]], [[COPY8]]
    ; NEW_RBS-NEXT: G_STORE [[ADD]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $sgpr1
    %2:_(i32) = COPY $sgpr2
    %3:_(i32) = COPY $sgpr3
    %4:_(<4 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32), %3(i32)
    %5:_(i32) = COPY $vgpr0
    %6:_(i32) = COPY $vgpr1
    %7:_(i32) = COPY $vgpr2
    %8:_(p1) = G_MERGE_VALUES %6(i32), %7(i32)
    %9:_(i32) = G_CONSTANT i32 0
    %10:_(<4 x i32>) = G_AMDGPU_BUFFER_LOAD %4(<4 x i32>), %9(i32), %5, %9, 0, 0, 0 :: (dereferenceable load (<4 x i32>), align 1, addrspace 8)
    %11:_(i32) = G_CONSTANT i32 1
    %12:_(i32), %13:_(i32), %14:_(i32), %15:_(i32) = G_UNMERGE_VALUES %10(<4 x i32>)
    %16:_(i32) = G_ADD %13, %11
    G_STORE %16(i32), %8(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: vgpr_and_i64
legalized: true
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5

    ; OLD_RBS-LABEL: name: vgpr_and_i64
    ; OLD_RBS: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
    ; OLD_RBS-NEXT: [[MV1:%[0-9]+]]:vgpr(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr4
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY $vgpr5
    ; OLD_RBS-NEXT: [[MV2:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; OLD_RBS-NEXT: [[UV:%[0-9]+]]:vgpr(i32), [[UV1:%[0-9]+]]:vgpr(i32) = G_UNMERGE_VALUES [[MV]](i64)
    ; OLD_RBS-NEXT: [[UV2:%[0-9]+]]:vgpr(i32), [[UV3:%[0-9]+]]:vgpr(i32) = G_UNMERGE_VALUES [[MV1]](i64)
    ; OLD_RBS-NEXT: [[AND:%[0-9]+]]:vgpr(i32) = G_AND [[UV]], [[UV2]]
    ; OLD_RBS-NEXT: [[AND1:%[0-9]+]]:vgpr(i32) = G_AND [[UV1]], [[UV3]]
    ; OLD_RBS-NEXT: [[MV3:%[0-9]+]]:vgpr(i64) = G_MERGE_VALUES [[AND]](i32), [[AND1]](i32)
    ; OLD_RBS-NEXT: G_STORE [[MV3]](i64), [[MV2]](p1) :: (store (i64), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: vgpr_and_i64
    ; NEW_RBS: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
    ; NEW_RBS-NEXT: [[MV1:%[0-9]+]]:vgpr(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr4
    ; NEW_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY $vgpr5
    ; NEW_RBS-NEXT: [[MV2:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; NEW_RBS-NEXT: [[UV:%[0-9]+]]:vgpr(i32), [[UV1:%[0-9]+]]:vgpr(i32) = G_UNMERGE_VALUES [[MV]](i64)
    ; NEW_RBS-NEXT: [[UV2:%[0-9]+]]:vgpr(i32), [[UV3:%[0-9]+]]:vgpr(i32) = G_UNMERGE_VALUES [[MV1]](i64)
    ; NEW_RBS-NEXT: [[AND:%[0-9]+]]:vgpr(i32) = G_AND [[UV]], [[UV2]]
    ; NEW_RBS-NEXT: [[AND1:%[0-9]+]]:vgpr(i32) = G_AND [[UV1]], [[UV3]]
    ; NEW_RBS-NEXT: [[MV3:%[0-9]+]]:vgpr(i64) = G_MERGE_VALUES [[AND]](i32), [[AND1]](i32)
    ; NEW_RBS-NEXT: G_STORE [[MV3]](i64), [[MV2]](p1) :: (store (i64), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i64) = G_MERGE_VALUES %0(i32), %1(i32)
    %3:_(i32) = COPY $vgpr2
    %4:_(i32) = COPY $vgpr3
    %5:_(i64) = G_MERGE_VALUES %3(i32), %4(i32)
    %6:_(i32) = COPY $vgpr4
    %7:_(i32) = COPY $vgpr5
    %8:_(p1) = G_MERGE_VALUES %6(i32), %7(i32)
    %9:_(i64) = G_AND %2, %5
    G_STORE %9(i64), %8(p1) :: (store (i64), addrspace 1)
    S_ENDPGM 0
...

---
name: abs_sgpr_i16
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $vgpr0, $vgpr1

    ; OLD_RBS-LABEL: name: abs_sgpr_i16
    ; OLD_RBS: liveins: $sgpr0, $vgpr0, $vgpr1
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[TRUNC:%[0-9]+]]:sgpr(i16) = G_TRUNC [[COPY]](i32)
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
    ; OLD_RBS-NEXT: [[SEXT:%[0-9]+]]:sgpr(i32) = G_SEXT [[TRUNC]](i16)
    ; OLD_RBS-NEXT: [[ABS:%[0-9]+]]:sgpr(i32) = G_ABS [[SEXT]]
    ; OLD_RBS-NEXT: [[TRUNC1:%[0-9]+]]:sgpr(i16) = G_TRUNC [[ABS]](i32)
    ; OLD_RBS-NEXT: [[ANYEXT:%[0-9]+]]:sgpr(i32) = G_ANYEXT [[TRUNC1]](i16)
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[ANYEXT]](i32)
    ; OLD_RBS-NEXT: G_STORE [[COPY3]](i32), [[MV]](p1) :: (store (i16), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: abs_sgpr_i16
    ; NEW_RBS: liveins: $sgpr0, $vgpr0, $vgpr1
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[TRUNC:%[0-9]+]]:sgpr(i16) = G_TRUNC [[COPY]](i32)
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
    ; NEW_RBS-NEXT: [[SEXT:%[0-9]+]]:sgpr(i32) = G_SEXT [[TRUNC]](i16)
    ; NEW_RBS-NEXT: [[ABS:%[0-9]+]]:sgpr(i32) = G_ABS [[SEXT]]
    ; NEW_RBS-NEXT: [[TRUNC1:%[0-9]+]]:sgpr(i16) = G_TRUNC [[ABS]](i32)
    ; NEW_RBS-NEXT: [[ANYEXT:%[0-9]+]]:sgpr(i32) = G_ANYEXT [[TRUNC1]](i16)
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[ANYEXT]](i32)
    ; NEW_RBS-NEXT: G_STORE [[COPY3]](i32), [[MV]](p1) :: (store (i16), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i16) = G_TRUNC %0(i32)
    %2:_(i32) = COPY $vgpr0
    %3:_(i32) = COPY $vgpr1
    %4:_(p1) = G_MERGE_VALUES %2(i32), %3(i32)
    %5:_(i16) = G_ABS %1
    %6:_(i32) = G_ANYEXT %5(i16)
    G_STORE %6(i32), %4(p1) :: (store (i16), addrspace 1)
    S_ENDPGM 0
...

---
name: uniform_i1_phi
legalized: true
tracksRegLiveness: true
body: |
  ; OLD_RBS-LABEL: name: uniform_i1_phi
  ; OLD_RBS: bb.0:
  ; OLD_RBS-NEXT:   successors: %bb.1(0x30000000), %bb.2(0x50000000)
  ; OLD_RBS-NEXT:   liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
  ; OLD_RBS-NEXT:   [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
  ; OLD_RBS-NEXT:   [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
  ; OLD_RBS-NEXT:   [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
  ; OLD_RBS-NEXT:   [[COPY3:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
  ; OLD_RBS-NEXT:   [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 6
  ; OLD_RBS-NEXT:   [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(uge), [[COPY2]](i32), [[C]]
  ; OLD_RBS-NEXT:   [[TRUNC:%[0-9]+]]:sgpr(i1) = G_TRUNC [[ICMP]](i32)
  ; OLD_RBS-NEXT:   [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; OLD_RBS-NEXT:   [[ICMP1:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(ne), [[COPY3]](i32), [[C1]]
  ; OLD_RBS-NEXT:   [[TRUNC1:%[0-9]+]]:sgpr(i1) = G_TRUNC [[ICMP1]](i32)
  ; OLD_RBS-NEXT:   [[ZEXT:%[0-9]+]]:sgpr(i32) = G_ZEXT [[TRUNC1]](i1)
  ; OLD_RBS-NEXT:   [[ANYEXT:%[0-9]+]]:sgpr(i32) = G_ANYEXT [[TRUNC]](i1)
  ; OLD_RBS-NEXT:   G_BRCOND [[ZEXT]](i32), %bb.2
  ; OLD_RBS-NEXT:   G_BR %bb.1
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.1:
  ; OLD_RBS-NEXT:   successors: %bb.2(0x80000000)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; OLD_RBS-NEXT:   [[ICMP2:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(ult), [[COPY2]](i32), [[C2]]
  ; OLD_RBS-NEXT:   [[TRUNC2:%[0-9]+]]:sgpr(i1) = G_TRUNC [[ICMP2]](i32)
  ; OLD_RBS-NEXT:   [[ANYEXT1:%[0-9]+]]:sgpr(i32) = G_ANYEXT [[TRUNC2]](i1)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.2:
  ; OLD_RBS-NEXT:   [[PHI:%[0-9]+]]:sgpr(i32) = G_PHI [[ANYEXT]](i32), %bb.0, [[ANYEXT1]](i32), %bb.1
  ; OLD_RBS-NEXT:   [[TRUNC3:%[0-9]+]]:sgpr(i1) = G_TRUNC [[PHI]](i32)
  ; OLD_RBS-NEXT:   [[SEXT:%[0-9]+]]:sgpr(i32) = G_SEXT [[TRUNC3]](i1)
  ; OLD_RBS-NEXT:   [[C3:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 2
  ; OLD_RBS-NEXT:   [[ADD:%[0-9]+]]:sgpr(i32) = G_ADD [[SEXT]], [[C3]]
  ; OLD_RBS-NEXT:   [[COPY4:%[0-9]+]]:vgpr(i32) = COPY [[ADD]](i32)
  ; OLD_RBS-NEXT:   G_STORE [[COPY4]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
  ; OLD_RBS-NEXT:   S_ENDPGM 0
  ;
  ; NEW_RBS-LABEL: name: uniform_i1_phi
  ; NEW_RBS: bb.0:
  ; NEW_RBS-NEXT:   successors: %bb.1(0x30000000), %bb.2(0x50000000)
  ; NEW_RBS-NEXT:   liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
  ; NEW_RBS-NEXT:   [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
  ; NEW_RBS-NEXT:   [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
  ; NEW_RBS-NEXT:   [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
  ; NEW_RBS-NEXT:   [[COPY3:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
  ; NEW_RBS-NEXT:   [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 6
  ; NEW_RBS-NEXT:   [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(uge), [[COPY2]](i32), [[C]]
  ; NEW_RBS-NEXT:   [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; NEW_RBS-NEXT:   [[ICMP1:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(ne), [[COPY3]](i32), [[C1]]
  ; NEW_RBS-NEXT:   [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; NEW_RBS-NEXT:   [[AND:%[0-9]+]]:sgpr(i32) = G_AND [[ICMP1]], [[C2]]
  ; NEW_RBS-NEXT:   G_BRCOND [[AND]](i32), %bb.2
  ; NEW_RBS-NEXT:   G_BR %bb.1
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.1:
  ; NEW_RBS-NEXT:   successors: %bb.2(0x80000000)
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[C3:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; NEW_RBS-NEXT:   [[ICMP2:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(ult), [[COPY2]](i32), [[C3]]
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.2:
  ; NEW_RBS-NEXT:   [[PHI:%[0-9]+]]:sgpr(i32) = G_PHI [[ICMP]](i32), %bb.0, [[ICMP2]](i32), %bb.1
  ; NEW_RBS-NEXT:   [[C4:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; NEW_RBS-NEXT:   [[AND1:%[0-9]+]]:sgpr(i32) = G_AND [[PHI]], [[C4]]
  ; NEW_RBS-NEXT:   [[C5:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 -1
  ; NEW_RBS-NEXT:   [[C6:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; NEW_RBS-NEXT:   [[SELECT:%[0-9]+]]:sgpr(i32) = G_SELECT [[AND1]](i32), [[C5]], [[C6]]
  ; NEW_RBS-NEXT:   [[C7:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 2
  ; NEW_RBS-NEXT:   [[ADD:%[0-9]+]]:sgpr(i32) = G_ADD [[SELECT]], [[C7]]
  ; NEW_RBS-NEXT:   [[COPY4:%[0-9]+]]:vgpr(i32) = COPY [[ADD]](i32)
  ; NEW_RBS-NEXT:   G_STORE [[COPY4]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
  ; NEW_RBS-NEXT:   S_ENDPGM 0
  bb.0:
    successors: %bb.1(0x30000000), %bb.2(0x50000000)
    liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1

    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(p1) = G_MERGE_VALUES %0(i32), %1(i32)
    %3:_(i32) = COPY $sgpr0
    %4:_(i32) = COPY $sgpr1
    %5:_(i32) = G_CONSTANT i32 6
    %6:_(i1) = G_ICMP intpred(uge), %3(i32), %5
    %7:_(i32) = G_CONSTANT i32 0
    %8:_(i1) = G_ICMP intpred(ne), %4(i32), %7
    G_BRCOND %8(i1), %bb.2
    G_BR %bb.1

  bb.1:
    successors: %bb.2(0x80000000)

    %9:_(i32) = G_CONSTANT i32 1
    %10:_(i1) = G_ICMP intpred(ult), %3(i32), %9

  bb.2:
    %11:_(i1) = G_PHI %6(i1), %bb.0, %10(i1), %bb.1
    %12:_(i32) = G_SEXT %11(i1)
    %13:_(i32) = G_CONSTANT i32 2
    %14:_(i32) = G_ADD %12, %13
    G_STORE %14(i32), %2(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0




...

---
name: vcc_to_scc
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $sgpr2, $vgpr0, $vgpr1

    ; OLD_RBS-LABEL: name: vcc_to_scc
    ; OLD_RBS: liveins: $sgpr0, $sgpr1, $sgpr2, $vgpr0, $vgpr1
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr2
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY3]](i32), [[COPY4]](i32)
    ; OLD_RBS-NEXT: [[C:%[0-9]+]]:sgpr(f32) = G_FCONSTANT float 0.000000e+00
    ; OLD_RBS-NEXT: [[BITCAST:%[0-9]+]]:sgpr(f32) = G_BITCAST [[COPY]](i32)
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(f32) = COPY [[BITCAST]](f32)
    ; OLD_RBS-NEXT: [[COPY6:%[0-9]+]]:vgpr(f32) = COPY [[C]](f32)
    ; OLD_RBS-NEXT: [[FCMP:%[0-9]+]]:vcc(i1) = G_FCMP floatpred(oeq), [[COPY5]](f32), [[COPY6]]
    ; OLD_RBS-NEXT: [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[COPY1]](i32)
    ; OLD_RBS-NEXT: [[COPY8:%[0-9]+]]:vgpr(i32) = COPY [[COPY2]](i32)
    ; OLD_RBS-NEXT: [[SELECT:%[0-9]+]]:vgpr(i32) = G_SELECT [[FCMP]](i1), [[COPY7]], [[COPY8]]
    ; OLD_RBS-NEXT: G_STORE [[SELECT]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: vcc_to_scc
    ; NEW_RBS: liveins: $sgpr0, $sgpr1, $sgpr2, $vgpr0, $vgpr1
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:sgpr(i32) = COPY $sgpr2
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY3]](i32), [[COPY4]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:sgpr(f32) = G_FCONSTANT float 0.000000e+00
    ; NEW_RBS-NEXT: [[BITCAST:%[0-9]+]]:sgpr(f32) = G_BITCAST [[COPY]](i32)
    ; NEW_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(f32) = COPY [[BITCAST]](f32)
    ; NEW_RBS-NEXT: [[COPY6:%[0-9]+]]:vgpr(f32) = COPY [[C]](f32)
    ; NEW_RBS-NEXT: [[FCMP:%[0-9]+]]:vcc(i1) = G_FCMP floatpred(oeq), [[COPY5]](f32), [[COPY6]]
    ; NEW_RBS-NEXT: [[AMDGPU_COPY_SCC_VCC:%[0-9]+]]:sgpr(i32) = G_AMDGPU_COPY_SCC_VCC [[FCMP]](i1)
    ; NEW_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
    ; NEW_RBS-NEXT: [[AND:%[0-9]+]]:sgpr(i32) = G_AND [[AMDGPU_COPY_SCC_VCC]], [[C1]]
    ; NEW_RBS-NEXT: [[SELECT:%[0-9]+]]:sgpr(i32) = G_SELECT [[AND]](i32), [[COPY1]], [[COPY2]]
    ; NEW_RBS-NEXT: [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[SELECT]](i32)
    ; NEW_RBS-NEXT: G_STORE [[COPY7]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $sgpr1
    %2:_(i32) = COPY $sgpr2
    %3:_(i32) = COPY $vgpr0
    %4:_(i32) = COPY $vgpr1
    %5:_(p1) = G_MERGE_VALUES %3(i32), %4(i32)
    %6:_(f32) = G_FCONSTANT float 0.000000e+00
    %7:_(f32) = G_BITCAST %0(i32)
    %8:_(i1) = G_FCMP floatpred(oeq), %7(f32), %6
    %9:_(i32) = G_SELECT %8(i1), %1, %2
    G_STORE %9(i32), %5(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: scc_to_vcc
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; OLD_RBS-LABEL: name: scc_to_vcc
    ; OLD_RBS: liveins: $sgpr0, $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY3]](i32), [[COPY4]](i32)
    ; OLD_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
    ; OLD_RBS-NEXT: [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(eq), [[COPY]](i32), [[C]]
    ; OLD_RBS-NEXT: [[TRUNC:%[0-9]+]]:sgpr(i1) = G_TRUNC [[ICMP]](i32)
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vcc(i1) = COPY [[TRUNC]](i1)
    ; OLD_RBS-NEXT: [[SELECT:%[0-9]+]]:vgpr(i32) = G_SELECT [[COPY5]](i1), [[COPY1]], [[COPY2]]
    ; OLD_RBS-NEXT: G_STORE [[SELECT]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: scc_to_vcc
    ; NEW_RBS: liveins: $sgpr0, $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY3]](i32), [[COPY4]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
    ; NEW_RBS-NEXT: [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(eq), [[COPY]](i32), [[C]]
    ; NEW_RBS-NEXT: [[AMDGPU_COPY_VCC_SCC:%[0-9]+]]:vcc(i1) = G_AMDGPU_COPY_VCC_SCC [[ICMP]](i32)
    ; NEW_RBS-NEXT: [[SELECT:%[0-9]+]]:vgpr(i32) = G_SELECT [[AMDGPU_COPY_VCC_SCC]](i1), [[COPY1]], [[COPY2]]
    ; NEW_RBS-NEXT: G_STORE [[SELECT]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $vgpr0
    %2:_(i32) = COPY $vgpr1
    %3:_(i32) = COPY $vgpr2
    %4:_(i32) = COPY $vgpr3
    %5:_(p1) = G_MERGE_VALUES %3(i32), %4(i32)
    %6:_(i32) = G_CONSTANT i32 0
    %7:_(i1) = G_ICMP intpred(eq), %0(i32), %6
    %8:_(i32) = G_SELECT %7(i1), %1, %2
    G_STORE %8(i32), %5(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: vgpr_to_vcc_trunc
legalized: true
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4

    ; OLD_RBS-LABEL: name: vgpr_to_vcc_trunc
    ; OLD_RBS: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr4
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY3]](i32), [[COPY4]](i32)
    ; OLD_RBS-NEXT: [[TRUNC:%[0-9]+]]:vgpr(i1) = G_TRUNC [[COPY]](i32)
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vcc(i1) = COPY [[TRUNC]](i1)
    ; OLD_RBS-NEXT: [[SELECT:%[0-9]+]]:vgpr(i32) = G_SELECT [[COPY5]](i1), [[COPY1]], [[COPY2]]
    ; OLD_RBS-NEXT: G_STORE [[SELECT]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: vgpr_to_vcc_trunc
    ; NEW_RBS: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr4
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY3]](i32), [[COPY4]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:vgpr(i32) = G_CONSTANT i32 1
    ; NEW_RBS-NEXT: [[AND:%[0-9]+]]:vgpr(i32) = G_AND [[COPY]], [[C]]
    ; NEW_RBS-NEXT: [[C1:%[0-9]+]]:vgpr(i32) = G_CONSTANT i32 0
    ; NEW_RBS-NEXT: [[ICMP:%[0-9]+]]:vcc(i1) = G_ICMP intpred(ne), [[AND]](i32), [[C1]]
    ; NEW_RBS-NEXT: [[SELECT:%[0-9]+]]:vgpr(i32) = G_SELECT [[ICMP]](i1), [[COPY1]], [[COPY2]]
    ; NEW_RBS-NEXT: G_STORE [[SELECT]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(p1) = G_MERGE_VALUES %3(i32), %4(i32)
    %6:_(i1) = G_TRUNC %0(i32)
    %7:_(i32) = G_SELECT %6(i1), %1, %2
    G_STORE %7(i32), %5(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: zext
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $vgpr0, $vgpr1

    ; OLD_RBS-LABEL: name: zext
    ; OLD_RBS: liveins: $sgpr0, $vgpr0, $vgpr1
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
    ; OLD_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
    ; OLD_RBS-NEXT: [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(eq), [[COPY]](i32), [[C]]
    ; OLD_RBS-NEXT: [[TRUNC:%[0-9]+]]:sgpr(i1) = G_TRUNC [[ICMP]](i32)
    ; OLD_RBS-NEXT: [[ZEXT:%[0-9]+]]:sgpr(i32) = G_ZEXT [[TRUNC]](i1)
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[ZEXT]](i32)
    ; OLD_RBS-NEXT: G_STORE [[COPY3]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: zext
    ; NEW_RBS: liveins: $sgpr0, $vgpr0, $vgpr1
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
    ; NEW_RBS-NEXT: [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(eq), [[COPY]](i32), [[C]]
    ; NEW_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
    ; NEW_RBS-NEXT: [[AND:%[0-9]+]]:sgpr(i32) = G_AND [[ICMP]], [[C1]]
    ; NEW_RBS-NEXT: [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
    ; NEW_RBS-NEXT: [[SELECT:%[0-9]+]]:sgpr(i32) = G_SELECT [[AND]](i32), [[C1]], [[C2]]
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[SELECT]](i32)
    ; NEW_RBS-NEXT: G_STORE [[COPY3]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $vgpr0
    %2:_(i32) = COPY $vgpr1
    %3:_(p1) = G_MERGE_VALUES %1(i32), %2(i32)
    %4:_(i32) = G_CONSTANT i32 10
    %5:_(i1) = G_ICMP intpred(eq), %0(i32), %4
    %6:_(i32) = G_ZEXT %5(i1)
    G_STORE %6(i32), %3(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: sext
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $vgpr0, $vgpr1

    ; OLD_RBS-LABEL: name: sext
    ; OLD_RBS: liveins: $sgpr0, $vgpr0, $vgpr1
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
    ; OLD_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
    ; OLD_RBS-NEXT: [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(eq), [[COPY]](i32), [[C]]
    ; OLD_RBS-NEXT: [[TRUNC:%[0-9]+]]:sgpr(i1) = G_TRUNC [[ICMP]](i32)
    ; OLD_RBS-NEXT: [[SEXT:%[0-9]+]]:sgpr(i32) = G_SEXT [[TRUNC]](i1)
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[SEXT]](i32)
    ; OLD_RBS-NEXT: G_STORE [[COPY3]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: sext
    ; NEW_RBS: liveins: $sgpr0, $vgpr0, $vgpr1
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
    ; NEW_RBS-NEXT: [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(eq), [[COPY]](i32), [[C]]
    ; NEW_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
    ; NEW_RBS-NEXT: [[AND:%[0-9]+]]:sgpr(i32) = G_AND [[ICMP]], [[C1]]
    ; NEW_RBS-NEXT: [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 -1
    ; NEW_RBS-NEXT: [[C3:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
    ; NEW_RBS-NEXT: [[SELECT:%[0-9]+]]:sgpr(i32) = G_SELECT [[AND]](i32), [[C2]], [[C3]]
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[SELECT]](i32)
    ; NEW_RBS-NEXT: G_STORE [[COPY3]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $vgpr0
    %2:_(i32) = COPY $vgpr1
    %3:_(p1) = G_MERGE_VALUES %1(i32), %2(i32)
    %4:_(i32) = G_CONSTANT i32 10
    %5:_(i1) = G_ICMP intpred(eq), %0(i32), %4
    %6:_(i32) = G_SEXT %5(i1)
    G_STORE %6(i32), %3(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: and_i1_vcc
legalized: true
body: |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; OLD_RBS-LABEL: name: and_i1_vcc
    ; OLD_RBS: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; OLD_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY [[C]](i32)
    ; OLD_RBS-NEXT: [[ICMP:%[0-9]+]]:vcc(i1) = G_ICMP intpred(uge), [[COPY]](i32), [[COPY4]]
    ; OLD_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 20
    ; OLD_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY [[C1]](i32)
    ; OLD_RBS-NEXT: [[ICMP1:%[0-9]+]]:vcc(i1) = G_ICMP intpred(uge), [[COPY1]](i32), [[COPY5]]
    ; OLD_RBS-NEXT: [[AND:%[0-9]+]]:vcc(i1) = G_AND [[ICMP]], [[ICMP1]]
    ; OLD_RBS-NEXT: [[SELECT:%[0-9]+]]:vgpr(i32) = G_SELECT [[AND]](i1), [[COPY]], [[COPY1]]
    ; OLD_RBS-NEXT: G_STORE [[SELECT]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: and_i1_vcc
    ; NEW_RBS: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY [[C]](i32)
    ; NEW_RBS-NEXT: [[ICMP:%[0-9]+]]:vcc(i1) = G_ICMP intpred(uge), [[COPY]](i32), [[COPY4]]
    ; NEW_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 20
    ; NEW_RBS-NEXT: [[COPY5:%[0-9]+]]:vgpr(i32) = COPY [[C1]](i32)
    ; NEW_RBS-NEXT: [[ICMP1:%[0-9]+]]:vcc(i1) = G_ICMP intpred(uge), [[COPY1]](i32), [[COPY5]]
    ; NEW_RBS-NEXT: [[AND:%[0-9]+]]:vcc(i1) = G_AND [[ICMP]], [[ICMP1]]
    ; NEW_RBS-NEXT: [[SELECT:%[0-9]+]]:vgpr(i32) = G_SELECT [[AND]](i1), [[COPY]], [[COPY1]]
    ; NEW_RBS-NEXT: G_STORE [[SELECT]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(p1) = G_MERGE_VALUES %2(i32), %3(i32)
    %5:_(i32) = G_CONSTANT i32 10
    %6:_(i1) = G_ICMP intpred(uge), %0(i32), %5
    %7:_(i32) = G_CONSTANT i32 20
    %8:_(i1) = G_ICMP intpred(uge), %1(i32), %7
    %9:_(i1) = G_AND %6, %8
    %10:_(i32) = G_SELECT %9(i1), %0, %1
    G_STORE %10(i32), %4(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: and_i1_scc
legalized: true
body: |
  bb.0:
    liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1

    ; OLD_RBS-LABEL: name: and_i1_scc
    ; OLD_RBS: liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1
    ; OLD_RBS-NEXT: {{  $}}
    ; OLD_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; OLD_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; OLD_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; OLD_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; OLD_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; OLD_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
    ; OLD_RBS-NEXT: [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(uge), [[COPY]](i32), [[C]]
    ; OLD_RBS-NEXT: [[TRUNC:%[0-9]+]]:sgpr(i1) = G_TRUNC [[ICMP]](i32)
    ; OLD_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 20
    ; OLD_RBS-NEXT: [[ICMP1:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(uge), [[COPY1]](i32), [[C1]]
    ; OLD_RBS-NEXT: [[TRUNC1:%[0-9]+]]:sgpr(i1) = G_TRUNC [[ICMP1]](i32)
    ; OLD_RBS-NEXT: [[ANYEXT:%[0-9]+]]:sgpr(i32) = G_ANYEXT [[TRUNC]](i1)
    ; OLD_RBS-NEXT: [[ANYEXT1:%[0-9]+]]:sgpr(i32) = G_ANYEXT [[TRUNC1]](i1)
    ; OLD_RBS-NEXT: [[AND:%[0-9]+]]:sgpr(i32) = G_AND [[ANYEXT]], [[ANYEXT1]]
    ; OLD_RBS-NEXT: [[TRUNC2:%[0-9]+]]:sgpr(i1) = G_TRUNC [[AND]](i32)
    ; OLD_RBS-NEXT: [[ZEXT:%[0-9]+]]:sgpr(i32) = G_ZEXT [[TRUNC2]](i1)
    ; OLD_RBS-NEXT: [[SELECT:%[0-9]+]]:sgpr(i32) = G_SELECT [[ZEXT]](i32), [[COPY]], [[COPY1]]
    ; OLD_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY [[SELECT]](i32)
    ; OLD_RBS-NEXT: G_STORE [[COPY4]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; OLD_RBS-NEXT: S_ENDPGM 0
    ;
    ; NEW_RBS-LABEL: name: and_i1_scc
    ; NEW_RBS: liveins: $sgpr0, $sgpr1, $vgpr0, $vgpr1
    ; NEW_RBS-NEXT: {{  $}}
    ; NEW_RBS-NEXT: [[COPY:%[0-9]+]]:sgpr(i32) = COPY $sgpr0
    ; NEW_RBS-NEXT: [[COPY1:%[0-9]+]]:sgpr(i32) = COPY $sgpr1
    ; NEW_RBS-NEXT: [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
    ; NEW_RBS-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
    ; NEW_RBS-NEXT: [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; NEW_RBS-NEXT: [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
    ; NEW_RBS-NEXT: [[ICMP:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(uge), [[COPY]](i32), [[C]]
    ; NEW_RBS-NEXT: [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 20
    ; NEW_RBS-NEXT: [[ICMP1:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(uge), [[COPY1]](i32), [[C1]]
    ; NEW_RBS-NEXT: [[AND:%[0-9]+]]:sgpr(i32) = G_AND [[ICMP]], [[ICMP1]]
    ; NEW_RBS-NEXT: [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
    ; NEW_RBS-NEXT: [[AND1:%[0-9]+]]:sgpr(i32) = G_AND [[AND]], [[C2]]
    ; NEW_RBS-NEXT: [[SELECT:%[0-9]+]]:sgpr(i32) = G_SELECT [[AND1]](i32), [[COPY]], [[COPY1]]
    ; NEW_RBS-NEXT: [[COPY4:%[0-9]+]]:vgpr(i32) = COPY [[SELECT]](i32)
    ; NEW_RBS-NEXT: G_STORE [[COPY4]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
    ; NEW_RBS-NEXT: S_ENDPGM 0
    %0:_(i32) = COPY $sgpr0
    %1:_(i32) = COPY $sgpr1
    %2:_(i32) = COPY $vgpr0
    %3:_(i32) = COPY $vgpr1
    %4:_(p1) = G_MERGE_VALUES %2(i32), %3(i32)
    %5:_(i32) = G_CONSTANT i32 10
    %6:_(i1) = G_ICMP intpred(uge), %0(i32), %5
    %7:_(i32) = G_CONSTANT i32 20
    %8:_(i1) = G_ICMP intpred(uge), %1(i32), %7
    %9:_(i1) = G_AND %6, %8
    %10:_(i32) = G_SELECT %9(i1), %0, %1
    G_STORE %10(i32), %4(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: divergent_phi_with_uniform_inputs
legalized: true
tracksRegLiveness: true
body: |
  ; OLD_RBS-LABEL: name: divergent_phi_with_uniform_inputs
  ; OLD_RBS: bb.0:
  ; OLD_RBS-NEXT:   successors: %bb.1(0x40000000), %bb.2(0x40000000)
  ; OLD_RBS-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
  ; OLD_RBS-NEXT:   [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
  ; OLD_RBS-NEXT:   [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
  ; OLD_RBS-NEXT:   [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
  ; OLD_RBS-NEXT:   [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; OLD_RBS-NEXT:   [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[C]](i32)
  ; OLD_RBS-NEXT:   [[ICMP:%[0-9]+]]:sreg_32_xm0_xexec(i1) = G_ICMP intpred(eq), [[COPY]](i32), [[COPY3]]
  ; OLD_RBS-NEXT:   [[SI_IF:%[0-9]+]]:sreg_32_xm0_xexec(i32) = SI_IF [[ICMP]](i1), %bb.2, implicit-def $exec, implicit-def $scc, implicit $exec
  ; OLD_RBS-NEXT:   G_BR %bb.1
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.1:
  ; OLD_RBS-NEXT:   successors: %bb.2(0x80000000)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.2:
  ; OLD_RBS-NEXT:   [[PHI:%[0-9]+]]:sgpr(i32) = G_PHI [[C]](i32), %bb.0, [[C1]](i32), %bb.1
  ; OLD_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[SI_IF]](i32)
  ; OLD_RBS-NEXT:   [[COPY4:%[0-9]+]]:vgpr(i32) = COPY [[PHI]](i32)
  ; OLD_RBS-NEXT:   G_STORE [[COPY4]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
  ; OLD_RBS-NEXT:   S_ENDPGM 0
  ;
  ; NEW_RBS-LABEL: name: divergent_phi_with_uniform_inputs
  ; NEW_RBS: bb.0:
  ; NEW_RBS-NEXT:   successors: %bb.1(0x40000000), %bb.2(0x40000000)
  ; NEW_RBS-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
  ; NEW_RBS-NEXT:   [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
  ; NEW_RBS-NEXT:   [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
  ; NEW_RBS-NEXT:   [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
  ; NEW_RBS-NEXT:   [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; NEW_RBS-NEXT:   [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[C]](i32)
  ; NEW_RBS-NEXT:   [[ICMP:%[0-9]+]]:vcc(i1) = G_ICMP intpred(eq), [[COPY]](i32), [[COPY3]]
  ; NEW_RBS-NEXT:   [[COPY4:%[0-9]+]]:sreg_32_xm0_xexec(i1) = COPY [[ICMP]](i1)
  ; NEW_RBS-NEXT:   [[SI_IF:%[0-9]+]]:sreg_32_xm0_xexec(i32) = SI_IF [[COPY4]](i1), %bb.2, implicit-def $exec, implicit-def $scc, implicit $exec
  ; NEW_RBS-NEXT:   G_BR %bb.1
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.1:
  ; NEW_RBS-NEXT:   successors: %bb.2(0x80000000)
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.2:
  ; NEW_RBS-NEXT:   [[PHI:%[0-9]+]]:vgpr(i32) = G_PHI [[C]](i32), %bb.0, [[C1]](i32), %bb.1
  ; NEW_RBS-NEXT:   [[COPY5:%[0-9]+]]:sgpr(i32) = COPY [[SI_IF]](i32)
  ; NEW_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[COPY5]](i32)
  ; NEW_RBS-NEXT:   G_STORE [[PHI]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
  ; NEW_RBS-NEXT:   S_ENDPGM 0
  bb.0:
    successors: %bb.1(0x40000000), %bb.2(0x40000000)
    liveins: $vgpr0, $vgpr1, $vgpr2

    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(p1) = G_MERGE_VALUES %1(i32), %2(i32)
    %4:_(i32) = G_CONSTANT i32 0
    %5:sreg_32_xm0_xexec(i1) = G_ICMP intpred(eq), %0(i32), %4
    %6:sreg_32_xm0_xexec(i32) = SI_IF %5(i1), %bb.2, implicit-def $exec, implicit-def $scc, implicit $exec
    G_BR %bb.1

  bb.1:
    successors: %bb.2(0x80000000)

    %7:_(i32) = G_CONSTANT i32 1

  bb.2:
    %8:_(i32) = G_PHI %4(i32), %bb.0, %7(i32), %bb.1
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), %6(i32)
    G_STORE %8(i32), %3(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: divergent_because_of_temporal_divergent_use
legalized: true
tracksRegLiveness: true
body: |
  ; OLD_RBS-LABEL: name: divergent_because_of_temporal_divergent_use
  ; OLD_RBS: bb.0:
  ; OLD_RBS-NEXT:   successors: %bb.1(0x80000000)
  ; OLD_RBS-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
  ; OLD_RBS-NEXT:   [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
  ; OLD_RBS-NEXT:   [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
  ; OLD_RBS-NEXT:   [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
  ; OLD_RBS-NEXT:   [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 -1
  ; OLD_RBS-NEXT:   [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.1:
  ; OLD_RBS-NEXT:   successors: %bb.2(0x04000000), %bb.1(0x7c000000)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[PHI:%[0-9]+]]:sgpr(i32) = G_PHI %7(i32), %bb.1, [[C1]](i32), %bb.0
  ; OLD_RBS-NEXT:   [[PHI1:%[0-9]+]]:vgpr(i32) = G_PHI [[C]](i32), %bb.0, %9(i32), %bb.1
  ; OLD_RBS-NEXT:   [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; OLD_RBS-NEXT:   [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[C2]](i32)
  ; OLD_RBS-NEXT:   [[ADD:%[0-9]+]]:vgpr(i32) = G_ADD [[PHI1]], [[COPY3]]
  ; OLD_RBS-NEXT:   [[UITOFP:%[0-9]+]]:vgpr(f32) = G_UITOFP [[ADD]](i32)
  ; OLD_RBS-NEXT:   [[BITCAST:%[0-9]+]]:vgpr(f32) = G_BITCAST [[COPY]](i32)
  ; OLD_RBS-NEXT:   [[FCMP:%[0-9]+]]:vcc(i1) = G_FCMP floatpred(ogt), [[UITOFP]](f32), [[BITCAST]]
  ; OLD_RBS-NEXT:   [[INT:%[0-9]+]]:sreg_32_xm0_xexec(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), [[FCMP]](i1), [[PHI]](i32)
  ; OLD_RBS-NEXT:   SI_LOOP [[INT]](i32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
  ; OLD_RBS-NEXT:   G_BR %bb.2
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.2:
  ; OLD_RBS-NEXT:   [[PHI2:%[0-9]+]]:vgpr(i32) = G_PHI [[ADD]](i32), %bb.1
  ; OLD_RBS-NEXT:   [[PHI3:%[0-9]+]]:sgpr(i32) = G_PHI [[INT]](i32), %bb.1
  ; OLD_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[PHI3]](i32)
  ; OLD_RBS-NEXT:   [[C3:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
  ; OLD_RBS-NEXT:   [[COPY4:%[0-9]+]]:vgpr(i32) = COPY [[C3]](i32)
  ; OLD_RBS-NEXT:   [[MUL:%[0-9]+]]:vgpr(i32) = G_MUL [[PHI2]], [[COPY4]]
  ; OLD_RBS-NEXT:   G_STORE [[MUL]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
  ; OLD_RBS-NEXT:   S_ENDPGM 0
  ;
  ; NEW_RBS-LABEL: name: divergent_because_of_temporal_divergent_use
  ; NEW_RBS: bb.0:
  ; NEW_RBS-NEXT:   successors: %bb.1(0x80000000)
  ; NEW_RBS-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
  ; NEW_RBS-NEXT:   [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
  ; NEW_RBS-NEXT:   [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
  ; NEW_RBS-NEXT:   [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY1]](i32), [[COPY2]](i32)
  ; NEW_RBS-NEXT:   [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 -1
  ; NEW_RBS-NEXT:   [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.1:
  ; NEW_RBS-NEXT:   successors: %bb.2(0x04000000), %bb.1(0x7c000000)
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[PHI:%[0-9]+]]:sgpr(i32) = G_PHI %18(i32), %bb.1, [[C1]](i32), %bb.0
  ; NEW_RBS-NEXT:   [[PHI1:%[0-9]+]]:sgpr(i32) = G_PHI [[C]](i32), %bb.0, %9(i32), %bb.1
  ; NEW_RBS-NEXT:   [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; NEW_RBS-NEXT:   [[ADD:%[0-9]+]]:sgpr(i32) = G_ADD [[PHI1]], [[C2]]
  ; NEW_RBS-NEXT:   [[COPY3:%[0-9]+]]:vgpr(i32) = COPY [[ADD]](i32)
  ; NEW_RBS-NEXT:   [[UITOFP:%[0-9]+]]:vgpr(f32) = G_UITOFP [[COPY3]](i32)
  ; NEW_RBS-NEXT:   [[BITCAST:%[0-9]+]]:vgpr(f32) = G_BITCAST [[COPY]](i32)
  ; NEW_RBS-NEXT:   [[FCMP:%[0-9]+]]:vcc(i1) = G_FCMP floatpred(ogt), [[UITOFP]](f32), [[BITCAST]]
  ; NEW_RBS-NEXT:   [[INT:%[0-9]+]]:sgpr(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), [[FCMP]](i1), [[PHI]](i32)
  ; NEW_RBS-NEXT:   [[COPY4:%[0-9]+]]:sreg_32_xm0_xexec(i32) = COPY [[INT]](i32)
  ; NEW_RBS-NEXT:   SI_LOOP [[COPY4]](i32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
  ; NEW_RBS-NEXT:   G_BR %bb.2
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.2:
  ; NEW_RBS-NEXT:   [[PHI2:%[0-9]+]]:vgpr(i32) = G_PHI [[ADD]](i32), %bb.1
  ; NEW_RBS-NEXT:   [[PHI3:%[0-9]+]]:sgpr(i32) = G_PHI [[INT]](i32), %bb.1
  ; NEW_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[PHI3]](i32)
  ; NEW_RBS-NEXT:   [[C3:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 10
  ; NEW_RBS-NEXT:   [[COPY5:%[0-9]+]]:vgpr(i32) = COPY [[C3]](i32)
  ; NEW_RBS-NEXT:   [[MUL:%[0-9]+]]:vgpr(i32) = G_MUL [[PHI2]], [[COPY5]]
  ; NEW_RBS-NEXT:   G_STORE [[MUL]](i32), [[MV]](p1) :: (store (i32), addrspace 1)
  ; NEW_RBS-NEXT:   S_ENDPGM 0
  bb.0:
    successors: %bb.1(0x80000000)
    liveins: $vgpr0, $vgpr1, $vgpr2

    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(p1) = G_MERGE_VALUES %1(i32), %2(i32)
    %4:_(i32) = G_CONSTANT i32 -1
    %5:_(i32) = G_CONSTANT i32 0

  bb.1:
    successors: %bb.2(0x04000000), %bb.1(0x7c000000)

    %6:_(i32) = G_PHI %7(i32), %bb.1, %5(i32), %bb.0
    %8:_(i32) = G_PHI %4(i32), %bb.0, %9(i32), %bb.1
    %10:_(i32) = G_CONSTANT i32 1
    %9:_(i32) = G_ADD %8, %10
    %11:_(f32) = G_UITOFP %9(i32)
    %17:_(f32) = G_BITCAST %0(i32)
    %12:_(i1) = G_FCMP floatpred(ogt), %11(f32), %17
    %7:sreg_32_xm0_xexec(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), %12(i1), %6(i32)
    SI_LOOP %7(i32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
    G_BR %bb.2

  bb.2:
    %13:_(i32) = G_PHI %9(i32), %bb.1
    %14:_(i32) = G_PHI %7(i32), %bb.1
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), %14(i32)
    %15:_(i32) = G_CONSTANT i32 10
    %16:_(i32) = G_MUL %13, %15
    G_STORE %16(i32), %3(p1) :: (store (i32), addrspace 1)
    S_ENDPGM 0
...

---
name: loop_with_2breaks
legalized: true
tracksRegLiveness: true
body: |
  ; OLD_RBS-LABEL: name: loop_with_2breaks
  ; OLD_RBS: bb.0:
  ; OLD_RBS-NEXT:   successors: %bb.1(0x80000000)
  ; OLD_RBS-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
  ; OLD_RBS-NEXT:   [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
  ; OLD_RBS-NEXT:   [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
  ; OLD_RBS-NEXT:   [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
  ; OLD_RBS-NEXT:   [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
  ; OLD_RBS-NEXT:   [[MV1:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
  ; OLD_RBS-NEXT:   [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr4
  ; OLD_RBS-NEXT:   [[COPY5:%[0-9]+]]:vgpr(i32) = COPY $vgpr5
  ; OLD_RBS-NEXT:   [[MV2:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
  ; OLD_RBS-NEXT:   [[DEF:%[0-9]+]]:sgpr(i32) = G_IMPLICIT_DEF
  ; OLD_RBS-NEXT:   [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; OLD_RBS-NEXT:   [[DEF1:%[0-9]+]]:sreg_32(i1) = IMPLICIT_DEF
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.1:
  ; OLD_RBS-NEXT:   successors: %bb.2(0x40000000), %bb.3(0x40000000)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[PHI:%[0-9]+]]:sreg_32(i1) = PHI [[DEF1]](i1), %bb.0, %13(i1), %bb.3
  ; OLD_RBS-NEXT:   [[PHI1:%[0-9]+]]:sgpr(i32) = G_PHI %15(i32), %bb.3, [[C]](i32), %bb.0
  ; OLD_RBS-NEXT:   [[PHI2:%[0-9]+]]:vgpr(i32) = G_PHI [[C]](i32), %bb.0, %17(i32), %bb.3
  ; OLD_RBS-NEXT:   [[COPY6:%[0-9]+]]:sreg_32(i1) = COPY [[PHI]](i1)
  ; OLD_RBS-NEXT:   [[COPY7:%[0-9]+]]:vgpr(i32) = COPY [[PHI2]](i32)
  ; OLD_RBS-NEXT:   [[C1:%[0-9]+]]:vgpr(i32) = G_CONSTANT i32 31
  ; OLD_RBS-NEXT:   [[ASHR:%[0-9]+]]:vgpr(i32) = G_ASHR [[COPY7]], [[C1]](i32)
  ; OLD_RBS-NEXT:   [[MV3:%[0-9]+]]:vgpr(i64) = G_MERGE_VALUES [[COPY7]](i32), [[ASHR]](i32)
  ; OLD_RBS-NEXT:   [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 2
  ; OLD_RBS-NEXT:   [[COPY8:%[0-9]+]]:vgpr(i32) = COPY [[C2]](i32)
  ; OLD_RBS-NEXT:   [[SHL:%[0-9]+]]:vgpr(i64) = G_SHL [[MV3]], [[COPY8]](i32)
  ; OLD_RBS-NEXT:   [[PTR_ADD:%[0-9]+]]:vgpr(p1) = G_PTR_ADD [[MV1]], [[SHL]](i64)
  ; OLD_RBS-NEXT:   [[LOAD:%[0-9]+]]:vgpr(i32) = G_LOAD [[PTR_ADD]](p1) :: (load (i32), addrspace 1)
  ; OLD_RBS-NEXT:   [[C3:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; OLD_RBS-NEXT:   [[COPY9:%[0-9]+]]:vgpr(i32) = COPY [[C3]](i32)
  ; OLD_RBS-NEXT:   [[ICMP:%[0-9]+]]:sreg_32_xm0_xexec(i1) = G_ICMP intpred(ne), [[LOAD]](i32), [[COPY9]]
  ; OLD_RBS-NEXT:   [[C4:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; OLD_RBS-NEXT:   [[TRUNC:%[0-9]+]]:sgpr(i1) = G_TRUNC [[C4]](i32)
  ; OLD_RBS-NEXT:   [[COPY10:%[0-9]+]]:sreg_32(i1) = COPY [[TRUNC]](i1)
  ; OLD_RBS-NEXT:   [[S_ANDN2_B32_:%[0-9]+]]:sreg_32(i1) = S_ANDN2_B32 [[COPY6]](i1), $exec_lo, implicit-def $scc
  ; OLD_RBS-NEXT:   [[S_AND_B32_:%[0-9]+]]:sreg_32(i1) = S_AND_B32 $exec_lo, [[COPY10]](i1), implicit-def $scc
  ; OLD_RBS-NEXT:   [[S_OR_B32_:%[0-9]+]]:sreg_32(i1) = S_OR_B32 [[S_ANDN2_B32_]](i1), [[S_AND_B32_]](i1), implicit-def $scc
  ; OLD_RBS-NEXT:   [[COPY11:%[0-9]+]]:sreg_32(i1) = COPY [[S_OR_B32_]](i1)
  ; OLD_RBS-NEXT:   [[SI_IF:%[0-9]+]]:sreg_32_xm0_xexec(i32) = SI_IF [[ICMP]](i1), %bb.3, implicit-def $exec, implicit-def $scc, implicit $exec
  ; OLD_RBS-NEXT:   G_BR %bb.2
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.2:
  ; OLD_RBS-NEXT:   successors: %bb.4(0x40000000), %bb.5(0x40000000)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[C5:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 2
  ; OLD_RBS-NEXT:   [[COPY12:%[0-9]+]]:vgpr(i32) = COPY [[C5]](i32)
  ; OLD_RBS-NEXT:   [[SHL1:%[0-9]+]]:vgpr(i64) = G_SHL [[MV3]], [[COPY12]](i32)
  ; OLD_RBS-NEXT:   [[PTR_ADD1:%[0-9]+]]:vgpr(p1) = G_PTR_ADD [[MV2]], [[SHL1]](i64)
  ; OLD_RBS-NEXT:   [[LOAD1:%[0-9]+]]:vgpr(i32) = G_LOAD [[PTR_ADD1]](p1) :: (load (i32), addrspace 1)
  ; OLD_RBS-NEXT:   [[C6:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; OLD_RBS-NEXT:   [[COPY13:%[0-9]+]]:vgpr(i32) = COPY [[C6]](i32)
  ; OLD_RBS-NEXT:   [[ICMP1:%[0-9]+]]:sreg_32_xm0_xexec(i1) = G_ICMP intpred(ne), [[LOAD1]](i32), [[COPY13]]
  ; OLD_RBS-NEXT:   [[C7:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; OLD_RBS-NEXT:   [[TRUNC1:%[0-9]+]]:sgpr(i1) = G_TRUNC [[C7]](i32)
  ; OLD_RBS-NEXT:   [[COPY14:%[0-9]+]]:sreg_32(i1) = COPY [[TRUNC1]](i1)
  ; OLD_RBS-NEXT:   [[COPY15:%[0-9]+]]:sreg_32(i1) = COPY [[COPY14]](i1)
  ; OLD_RBS-NEXT:   [[SI_IF1:%[0-9]+]]:sreg_32_xm0_xexec(i32) = SI_IF [[ICMP1]](i1), %bb.5, implicit-def $exec, implicit-def $scc, implicit $exec
  ; OLD_RBS-NEXT:   G_BR %bb.4
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.3:
  ; OLD_RBS-NEXT:   successors: %bb.6(0x04000000), %bb.1(0x7c000000)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[PHI3:%[0-9]+]]:sreg_32(i1) = PHI [[S_OR_B32_]](i1), %bb.1, %43(i1), %bb.5
  ; OLD_RBS-NEXT:   [[PHI4:%[0-9]+]]:vgpr(i32) = G_PHI %44(i32), %bb.5, [[DEF]](i32), %bb.1
  ; OLD_RBS-NEXT:   [[COPY16:%[0-9]+]]:sreg_32(i1) = COPY [[PHI3]](i1)
  ; OLD_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[SI_IF]](i32)
  ; OLD_RBS-NEXT:   [[INT:%[0-9]+]]:sreg_32_xm0_xexec(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), [[COPY16]](i1), [[PHI1]](i32)
  ; OLD_RBS-NEXT:   SI_LOOP [[INT]](i32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
  ; OLD_RBS-NEXT:   G_BR %bb.6
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.4:
  ; OLD_RBS-NEXT:   successors: %bb.5(0x80000000)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[C8:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 2
  ; OLD_RBS-NEXT:   [[COPY17:%[0-9]+]]:vgpr(i32) = COPY [[C8]](i32)
  ; OLD_RBS-NEXT:   [[SHL2:%[0-9]+]]:vgpr(i64) = G_SHL [[MV3]], [[COPY17]](i32)
  ; OLD_RBS-NEXT:   [[PTR_ADD2:%[0-9]+]]:vgpr(p1) = G_PTR_ADD [[MV]], [[SHL2]](i64)
  ; OLD_RBS-NEXT:   [[LOAD2:%[0-9]+]]:vgpr(i32) = G_LOAD [[PTR_ADD2]](p1) :: (load (i32), addrspace 1)
  ; OLD_RBS-NEXT:   [[C9:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; OLD_RBS-NEXT:   [[COPY18:%[0-9]+]]:vgpr(i32) = COPY [[C9]](i32)
  ; OLD_RBS-NEXT:   [[ADD:%[0-9]+]]:vgpr(i32) = G_ADD [[LOAD2]], [[COPY18]]
  ; OLD_RBS-NEXT:   G_STORE [[ADD]](i32), [[PTR_ADD2]](p1) :: (store (i32), addrspace 1)
  ; OLD_RBS-NEXT:   [[COPY19:%[0-9]+]]:vgpr(i32) = COPY [[C9]](i32)
  ; OLD_RBS-NEXT:   [[ADD1:%[0-9]+]]:vgpr(i32) = G_ADD [[PHI2]], [[COPY19]]
  ; OLD_RBS-NEXT:   [[C10:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 100
  ; OLD_RBS-NEXT:   [[COPY20:%[0-9]+]]:vgpr(i32) = COPY [[C10]](i32)
  ; OLD_RBS-NEXT:   [[ICMP2:%[0-9]+]]:vcc(i1) = G_ICMP intpred(ult), [[PHI2]](i32), [[COPY20]]
  ; OLD_RBS-NEXT:   [[COPY21:%[0-9]+]]:sreg_32(i1) = COPY [[ICMP2]](i1)
  ; OLD_RBS-NEXT:   [[S_ANDN2_B32_1:%[0-9]+]]:sreg_32(i1) = S_ANDN2_B32 [[COPY15]](i1), $exec_lo, implicit-def $scc
  ; OLD_RBS-NEXT:   [[S_AND_B32_1:%[0-9]+]]:sreg_32(i1) = S_AND_B32 $exec_lo, [[COPY21]](i1), implicit-def $scc
  ; OLD_RBS-NEXT:   [[S_OR_B32_1:%[0-9]+]]:sreg_32(i1) = S_OR_B32 [[S_ANDN2_B32_1]](i1), [[S_AND_B32_1]](i1), implicit-def $scc
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.5:
  ; OLD_RBS-NEXT:   successors: %bb.3(0x80000000)
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT:   [[PHI5:%[0-9]+]]:sreg_32(i1) = PHI [[COPY14]](i1), %bb.2, [[S_OR_B32_1]](i1), %bb.4
  ; OLD_RBS-NEXT:   [[PHI6:%[0-9]+]]:vgpr(i32) = G_PHI [[ADD1]](i32), %bb.4, [[DEF]](i32), %bb.2
  ; OLD_RBS-NEXT:   [[COPY22:%[0-9]+]]:sreg_32(i1) = COPY [[PHI5]](i1)
  ; OLD_RBS-NEXT:   [[COPY23:%[0-9]+]]:sreg_32(i1) = COPY [[COPY22]](i1)
  ; OLD_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[SI_IF1]](i32)
  ; OLD_RBS-NEXT:   [[S_ANDN2_B32_2:%[0-9]+]]:sreg_32(i1) = S_ANDN2_B32 [[COPY11]](i1), $exec_lo, implicit-def $scc
  ; OLD_RBS-NEXT:   [[S_AND_B32_2:%[0-9]+]]:sreg_32(i1) = S_AND_B32 $exec_lo, [[COPY23]](i1), implicit-def $scc
  ; OLD_RBS-NEXT:   [[S_OR_B32_2:%[0-9]+]]:sreg_32(i1) = S_OR_B32 [[S_ANDN2_B32_2]](i1), [[S_AND_B32_2]](i1), implicit-def $scc
  ; OLD_RBS-NEXT:   G_BR %bb.3
  ; OLD_RBS-NEXT: {{  $}}
  ; OLD_RBS-NEXT: bb.6:
  ; OLD_RBS-NEXT:   [[PHI7:%[0-9]+]]:sgpr(i32) = G_PHI [[INT]](i32), %bb.3
  ; OLD_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[PHI7]](i32)
  ; OLD_RBS-NEXT:   S_ENDPGM 0
  ;
  ; NEW_RBS-LABEL: name: loop_with_2breaks
  ; NEW_RBS: bb.0:
  ; NEW_RBS-NEXT:   successors: %bb.1(0x80000000)
  ; NEW_RBS-NEXT:   liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[COPY:%[0-9]+]]:vgpr(i32) = COPY $vgpr0
  ; NEW_RBS-NEXT:   [[COPY1:%[0-9]+]]:vgpr(i32) = COPY $vgpr1
  ; NEW_RBS-NEXT:   [[MV:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
  ; NEW_RBS-NEXT:   [[COPY2:%[0-9]+]]:vgpr(i32) = COPY $vgpr2
  ; NEW_RBS-NEXT:   [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr3
  ; NEW_RBS-NEXT:   [[MV1:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
  ; NEW_RBS-NEXT:   [[COPY4:%[0-9]+]]:vgpr(i32) = COPY $vgpr4
  ; NEW_RBS-NEXT:   [[COPY5:%[0-9]+]]:vgpr(i32) = COPY $vgpr5
  ; NEW_RBS-NEXT:   [[MV2:%[0-9]+]]:vgpr(p1) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
  ; NEW_RBS-NEXT:   [[DEF:%[0-9]+]]:sgpr(i32) = G_IMPLICIT_DEF
  ; NEW_RBS-NEXT:   [[C:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; NEW_RBS-NEXT:   [[DEF1:%[0-9]+]]:sreg_32(i1) = IMPLICIT_DEF
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.1:
  ; NEW_RBS-NEXT:   successors: %bb.2(0x40000000), %bb.3(0x40000000)
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[PHI:%[0-9]+]]:sreg_32(i1) = PHI [[DEF1]](i1), %bb.0, %13(i1), %bb.3
  ; NEW_RBS-NEXT:   [[PHI1:%[0-9]+]]:sgpr(i32) = G_PHI %68(i32), %bb.3, [[C]](i32), %bb.0
  ; NEW_RBS-NEXT:   [[PHI2:%[0-9]+]]:sgpr(i32) = G_PHI [[C]](i32), %bb.0, %17(i32), %bb.3
  ; NEW_RBS-NEXT:   [[COPY6:%[0-9]+]]:sreg_32(i1) = COPY [[PHI]](i1)
  ; NEW_RBS-NEXT:   [[C1:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 31
  ; NEW_RBS-NEXT:   [[ASHR:%[0-9]+]]:sgpr(i32) = G_ASHR [[PHI2]], [[C1]](i32)
  ; NEW_RBS-NEXT:   [[MV3:%[0-9]+]]:sgpr(i64) = G_MERGE_VALUES [[PHI2]](i32), [[ASHR]](i32)
  ; NEW_RBS-NEXT:   [[C2:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 2
  ; NEW_RBS-NEXT:   [[SHL:%[0-9]+]]:sgpr(i64) = G_SHL [[MV3]], [[C2]](i32)
  ; NEW_RBS-NEXT:   [[COPY7:%[0-9]+]]:vgpr(i64) = COPY [[SHL]](i64)
  ; NEW_RBS-NEXT:   [[PTR_ADD:%[0-9]+]]:vgpr(p1) = G_PTR_ADD [[MV1]], [[COPY7]](i64)
  ; NEW_RBS-NEXT:   [[LOAD:%[0-9]+]]:vgpr(i32) = G_LOAD [[PTR_ADD]](p1) :: (load (i32), addrspace 1)
  ; NEW_RBS-NEXT:   [[C3:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; NEW_RBS-NEXT:   [[COPY8:%[0-9]+]]:vgpr(i32) = COPY [[C3]](i32)
  ; NEW_RBS-NEXT:   [[ICMP:%[0-9]+]]:vcc(i1) = G_ICMP intpred(ne), [[LOAD]](i32), [[COPY8]]
  ; NEW_RBS-NEXT:   [[COPY9:%[0-9]+]]:sreg_32_xm0_xexec(i1) = COPY [[ICMP]](i1)
  ; NEW_RBS-NEXT:   [[C4:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; NEW_RBS-NEXT:   [[AMDGPU_COPY_VCC_SCC:%[0-9]+]]:sreg_32(i1) = G_AMDGPU_COPY_VCC_SCC [[C4]](i32)
  ; NEW_RBS-NEXT:   [[S_ANDN2_B32_:%[0-9]+]]:sreg_32(i1) = S_ANDN2_B32 [[COPY6]](i1), $exec_lo, implicit-def $scc
  ; NEW_RBS-NEXT:   [[S_AND_B32_:%[0-9]+]]:sreg_32(i1) = S_AND_B32 $exec_lo, [[AMDGPU_COPY_VCC_SCC]](i1), implicit-def $scc
  ; NEW_RBS-NEXT:   [[S_OR_B32_:%[0-9]+]]:sreg_32(i1) = S_OR_B32 [[S_ANDN2_B32_]](i1), [[S_AND_B32_]](i1), implicit-def $scc
  ; NEW_RBS-NEXT:   [[COPY10:%[0-9]+]]:sreg_32(i1) = COPY [[S_OR_B32_]](i1)
  ; NEW_RBS-NEXT:   [[SI_IF:%[0-9]+]]:sreg_32_xm0_xexec(i32) = SI_IF [[COPY9]](i1), %bb.3, implicit-def $exec, implicit-def $scc, implicit $exec
  ; NEW_RBS-NEXT:   G_BR %bb.2
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.2:
  ; NEW_RBS-NEXT:   successors: %bb.4(0x40000000), %bb.5(0x40000000)
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[C5:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 2
  ; NEW_RBS-NEXT:   [[SHL1:%[0-9]+]]:sgpr(i64) = G_SHL [[MV3]], [[C5]](i32)
  ; NEW_RBS-NEXT:   [[COPY11:%[0-9]+]]:vgpr(i64) = COPY [[SHL1]](i64)
  ; NEW_RBS-NEXT:   [[PTR_ADD1:%[0-9]+]]:vgpr(p1) = G_PTR_ADD [[MV2]], [[COPY11]](i64)
  ; NEW_RBS-NEXT:   [[LOAD1:%[0-9]+]]:vgpr(i32) = G_LOAD [[PTR_ADD1]](p1) :: (load (i32), addrspace 1)
  ; NEW_RBS-NEXT:   [[C6:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 0
  ; NEW_RBS-NEXT:   [[COPY12:%[0-9]+]]:vgpr(i32) = COPY [[C6]](i32)
  ; NEW_RBS-NEXT:   [[ICMP1:%[0-9]+]]:vcc(i1) = G_ICMP intpred(ne), [[LOAD1]](i32), [[COPY12]]
  ; NEW_RBS-NEXT:   [[COPY13:%[0-9]+]]:sreg_32_xm0_xexec(i1) = COPY [[ICMP1]](i1)
  ; NEW_RBS-NEXT:   [[C7:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; NEW_RBS-NEXT:   [[AMDGPU_COPY_VCC_SCC1:%[0-9]+]]:sreg_32(i1) = G_AMDGPU_COPY_VCC_SCC [[C7]](i32)
  ; NEW_RBS-NEXT:   [[COPY14:%[0-9]+]]:sreg_32(i1) = COPY [[AMDGPU_COPY_VCC_SCC1]](i1)
  ; NEW_RBS-NEXT:   [[SI_IF1:%[0-9]+]]:sreg_32_xm0_xexec(i32) = SI_IF [[COPY13]](i1), %bb.5, implicit-def $exec, implicit-def $scc, implicit $exec
  ; NEW_RBS-NEXT:   G_BR %bb.4
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.3:
  ; NEW_RBS-NEXT:   successors: %bb.6(0x04000000), %bb.1(0x7c000000)
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[PHI3:%[0-9]+]]:sreg_32(i1) = PHI [[S_OR_B32_]](i1), %bb.1, %43(i1), %bb.5
  ; NEW_RBS-NEXT:   [[PHI4:%[0-9]+]]:sgpr(i32) = G_PHI %44(i32), %bb.5, [[DEF]](i32), %bb.1
  ; NEW_RBS-NEXT:   [[COPY15:%[0-9]+]]:sreg_32(i1) = COPY [[PHI3]](i1)
  ; NEW_RBS-NEXT:   [[COPY16:%[0-9]+]]:sgpr(i32) = COPY [[SI_IF]](i32)
  ; NEW_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[COPY16]](i32)
  ; NEW_RBS-NEXT:   [[COPY17:%[0-9]+]]:vcc(i1) = COPY [[COPY15]](i1)
  ; NEW_RBS-NEXT:   [[INT:%[0-9]+]]:sgpr(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), [[COPY17]](i1), [[PHI1]](i32)
  ; NEW_RBS-NEXT:   [[COPY18:%[0-9]+]]:sreg_32_xm0_xexec(i32) = COPY [[INT]](i32)
  ; NEW_RBS-NEXT:   SI_LOOP [[COPY18]](i32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
  ; NEW_RBS-NEXT:   G_BR %bb.6
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.4:
  ; NEW_RBS-NEXT:   successors: %bb.5(0x80000000)
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[C8:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 2
  ; NEW_RBS-NEXT:   [[SHL2:%[0-9]+]]:sgpr(i64) = G_SHL [[MV3]], [[C8]](i32)
  ; NEW_RBS-NEXT:   [[COPY19:%[0-9]+]]:vgpr(i64) = COPY [[SHL2]](i64)
  ; NEW_RBS-NEXT:   [[PTR_ADD2:%[0-9]+]]:vgpr(p1) = G_PTR_ADD [[MV]], [[COPY19]](i64)
  ; NEW_RBS-NEXT:   [[LOAD2:%[0-9]+]]:vgpr(i32) = G_LOAD [[PTR_ADD2]](p1) :: (load (i32), addrspace 1)
  ; NEW_RBS-NEXT:   [[C9:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 1
  ; NEW_RBS-NEXT:   [[COPY20:%[0-9]+]]:vgpr(i32) = COPY [[C9]](i32)
  ; NEW_RBS-NEXT:   [[ADD:%[0-9]+]]:vgpr(i32) = G_ADD [[LOAD2]], [[COPY20]]
  ; NEW_RBS-NEXT:   G_STORE [[ADD]](i32), [[PTR_ADD2]](p1) :: (store (i32), addrspace 1)
  ; NEW_RBS-NEXT:   [[ADD1:%[0-9]+]]:sgpr(i32) = G_ADD [[PHI2]], [[C9]]
  ; NEW_RBS-NEXT:   [[C10:%[0-9]+]]:sgpr(i32) = G_CONSTANT i32 100
  ; NEW_RBS-NEXT:   [[ICMP2:%[0-9]+]]:sgpr(i32) = G_ICMP intpred(ult), [[PHI2]](i32), [[C10]]
  ; NEW_RBS-NEXT:   [[AND:%[0-9]+]]:sgpr(i32) = G_AND [[ICMP2]], [[C9]]
  ; NEW_RBS-NEXT:   [[AMDGPU_COPY_VCC_SCC2:%[0-9]+]]:sreg_32(i1) = G_AMDGPU_COPY_VCC_SCC [[AND]](i32)
  ; NEW_RBS-NEXT:   [[S_ANDN2_B32_1:%[0-9]+]]:sreg_32(i1) = S_ANDN2_B32 [[COPY14]](i1), $exec_lo, implicit-def $scc
  ; NEW_RBS-NEXT:   [[S_AND_B32_1:%[0-9]+]]:sreg_32(i1) = S_AND_B32 $exec_lo, [[AMDGPU_COPY_VCC_SCC2]](i1), implicit-def $scc
  ; NEW_RBS-NEXT:   [[S_OR_B32_1:%[0-9]+]]:sreg_32(i1) = S_OR_B32 [[S_ANDN2_B32_1]](i1), [[S_AND_B32_1]](i1), implicit-def $scc
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.5:
  ; NEW_RBS-NEXT:   successors: %bb.3(0x80000000)
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT:   [[PHI5:%[0-9]+]]:sreg_32(i1) = PHI [[AMDGPU_COPY_VCC_SCC1]](i1), %bb.2, [[S_OR_B32_1]](i1), %bb.4
  ; NEW_RBS-NEXT:   [[PHI6:%[0-9]+]]:sgpr(i32) = G_PHI [[ADD1]](i32), %bb.4, [[DEF]](i32), %bb.2
  ; NEW_RBS-NEXT:   [[COPY21:%[0-9]+]]:sreg_32(i1) = COPY [[PHI5]](i1)
  ; NEW_RBS-NEXT:   [[COPY22:%[0-9]+]]:sreg_32(i1) = COPY [[COPY21]](i1)
  ; NEW_RBS-NEXT:   [[COPY23:%[0-9]+]]:sgpr(i32) = COPY [[SI_IF1]](i32)
  ; NEW_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[COPY23]](i32)
  ; NEW_RBS-NEXT:   [[S_ANDN2_B32_2:%[0-9]+]]:sreg_32(i1) = S_ANDN2_B32 [[COPY10]](i1), $exec_lo, implicit-def $scc
  ; NEW_RBS-NEXT:   [[S_AND_B32_2:%[0-9]+]]:sreg_32(i1) = S_AND_B32 $exec_lo, [[COPY22]](i1), implicit-def $scc
  ; NEW_RBS-NEXT:   [[S_OR_B32_2:%[0-9]+]]:sreg_32(i1) = S_OR_B32 [[S_ANDN2_B32_2]](i1), [[S_AND_B32_2]](i1), implicit-def $scc
  ; NEW_RBS-NEXT:   G_BR %bb.3
  ; NEW_RBS-NEXT: {{  $}}
  ; NEW_RBS-NEXT: bb.6:
  ; NEW_RBS-NEXT:   [[PHI7:%[0-9]+]]:sgpr(i32) = G_PHI [[INT]](i32), %bb.3
  ; NEW_RBS-NEXT:   G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), [[PHI7]](i32)
  ; NEW_RBS-NEXT:   S_ENDPGM 0
  bb.0:
    successors: %bb.1(0x80000000)
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5

    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(p1) = G_MERGE_VALUES %0(i32), %1(i32)
    %3:_(i32) = COPY $vgpr2
    %4:_(i32) = COPY $vgpr3
    %5:_(p1) = G_MERGE_VALUES %3(i32), %4(i32)
    %6:_(i32) = COPY $vgpr4
    %7:_(i32) = COPY $vgpr5
    %8:_(p1) = G_MERGE_VALUES %6(i32), %7(i32)
    %9:_(i32) = G_IMPLICIT_DEF
    %10:_(i32) = G_CONSTANT i32 0
    %11:sreg_32(i1) = IMPLICIT_DEF

  bb.1:
    successors: %bb.2(0x40000000), %bb.3(0x40000000)

    %12:sreg_32(i1) = PHI %11(i1), %bb.0, %13(i1), %bb.3
    %14:_(i32) = G_PHI %15(i32), %bb.3, %10(i32), %bb.0
    %16:_(i32) = G_PHI %10(i32), %bb.0, %17(i32), %bb.3
    %18:sreg_32(i1) = COPY %12(i1)
    %19:_(i64) = G_SEXT %16(i32)
    %20:_(i32) = G_CONSTANT i32 2
    %21:_(i64) = G_SHL %19, %20(i32)
    %22:_(p1) = G_PTR_ADD %5, %21(i64)
    %23:_(i32) = G_LOAD %22(p1) :: (load (i32), addrspace 1)
    %24:_(i32) = G_CONSTANT i32 0
    %25:sreg_32_xm0_xexec(i1) = G_ICMP intpred(ne), %23(i32), %24
    %26:_(i1) = G_CONSTANT i1 true
    %27:sreg_32(i1) = COPY %26(i1)
    %28:sreg_32(i1) = S_ANDN2_B32 %18(i1), $exec_lo, implicit-def $scc
    %29:sreg_32(i1) = S_AND_B32 $exec_lo, %27(i1), implicit-def $scc
    %30:sreg_32(i1) = S_OR_B32 %28(i1), %29(i1), implicit-def $scc
    %31:sreg_32(i1) = COPY %30(i1)
    %32:sreg_32_xm0_xexec(i32) = SI_IF %25(i1), %bb.3, implicit-def $exec, implicit-def $scc, implicit $exec
    G_BR %bb.2

  bb.2:
    successors: %bb.4(0x40000000), %bb.5(0x40000000)

    %33:_(i32) = G_CONSTANT i32 2
    %34:_(i64) = G_SHL %19, %33(i32)
    %35:_(p1) = G_PTR_ADD %8, %34(i64)
    %36:_(i32) = G_LOAD %35(p1) :: (load (i32), addrspace 1)
    %37:_(i32) = G_CONSTANT i32 0
    %38:sreg_32_xm0_xexec(i1) = G_ICMP intpred(ne), %36(i32), %37
    %39:_(i1) = G_CONSTANT i1 true
    %40:sreg_32(i1) = COPY %39(i1)
    %41:sreg_32(i1) = COPY %40(i1)
    %42:sreg_32_xm0_xexec(i32) = SI_IF %38(i1), %bb.5, implicit-def $exec, implicit-def $scc, implicit $exec
    G_BR %bb.4

  bb.3:
    successors: %bb.6(0x04000000), %bb.1(0x7c000000)

    %13:sreg_32(i1) = PHI %30(i1), %bb.1, %43(i1), %bb.5
    %17:_(i32) = G_PHI %44(i32), %bb.5, %9(i32), %bb.1
    %45:sreg_32(i1) = COPY %13(i1)
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), %32(i32)
    %15:sreg_32_xm0_xexec(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.if.break), %45(i1), %14(i32)
    SI_LOOP %15(i32), %bb.1, implicit-def $exec, implicit-def $scc, implicit $exec
    G_BR %bb.6

  bb.4:
    successors: %bb.5(0x80000000)

    %46:_(i32) = G_CONSTANT i32 2
    %47:_(i64) = G_SHL %19, %46(i32)
    %48:_(p1) = G_PTR_ADD %2, %47(i64)
    %49:_(i32) = G_LOAD %48(p1) :: (load (i32), addrspace 1)
    %50:_(i32) = G_CONSTANT i32 1
    %51:_(i32) = G_ADD %49, %50
    G_STORE %51(i32), %48(p1) :: (store (i32), addrspace 1)
    %52:_(i32) = G_ADD %16, %50
    %53:_(i32) = G_CONSTANT i32 100
    %54:_(i1) = G_ICMP intpred(ult), %16(i32), %53
    %55:sreg_32(i1) = COPY %54(i1)
    %56:sreg_32(i1) = S_ANDN2_B32 %41(i1), $exec_lo, implicit-def $scc
    %57:sreg_32(i1) = S_AND_B32 $exec_lo, %55(i1), implicit-def $scc
    %58:sreg_32(i1) = S_OR_B32 %56(i1), %57(i1), implicit-def $scc

  bb.5:
    successors: %bb.3(0x80000000)

    %59:sreg_32(i1) = PHI %40(i1), %bb.2, %58(i1), %bb.4
    %44:_(i32) = G_PHI %52(i32), %bb.4, %9(i32), %bb.2
    %60:sreg_32(i1) = COPY %59(i1)
    %61:sreg_32(i1) = COPY %60(i1)
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), %42(i32)
    %62:sreg_32(i1) = S_ANDN2_B32 %31(i1), $exec_lo, implicit-def $scc
    %63:sreg_32(i1) = S_AND_B32 $exec_lo, %61(i1), implicit-def $scc
    %43:sreg_32(i1) = S_OR_B32 %62(i1), %63(i1), implicit-def $scc
    G_BR %bb.3

  bb.6:
    %64:_(i32) = G_PHI %15(i32), %bb.3
    G_INTRINSIC_W_SIDE_EFFECTS intrinsic(@llvm.amdgcn.end.cf), %64(i32)
    S_ENDPGM 0
...
