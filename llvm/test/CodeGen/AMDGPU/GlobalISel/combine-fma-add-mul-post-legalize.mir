# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -global-isel -mtriple=amdgcn -mcpu=gfx900 -run-pass=amdgpu-postlegalizer-combiner %s -o - | FileCheck -check-prefix=GFX9 %s
# RUN: llc -global-isel -mtriple=amdgcn -mcpu=gfx900 -run-pass=amdgpu-postlegalizer-combiner -fp-contract=fast %s -o - | FileCheck -check-prefix=GFX9-CONTRACT %s
# RUN: llc -global-isel -mtriple=amdgcn -mcpu=gfx900 -run-pass=amdgpu-postlegalizer-combiner --denormal-fp-math=preserve-sign %s -o - | FileCheck -check-prefix=GFX9-DENORM %s
# RUN: llc -global-isel -mtriple=amdgcn -mcpu=gfx900 -run-pass=amdgpu-postlegalizer-combiner -enable-unsafe-fp-math %s -o - | FileCheck -check-prefix=GFX9-UNSAFE %s
# RUN: llc -global-isel -mtriple=amdgcn -mcpu=gfx1010 -run-pass=amdgpu-postlegalizer-combiner %s -o - | FileCheck -check-prefix=GFX10 %s
# RUN: llc -global-isel -mtriple=amdgcn -mcpu=gfx1010 -run-pass=amdgpu-postlegalizer-combiner -fp-contract=fast %s -o - | FileCheck -check-prefix=GFX10-CONTRACT %s
# RUN: llc -global-isel -mtriple=amdgcn -mcpu=gfx1010 -run-pass=amdgpu-postlegalizer-combiner --denormal-fp-math=preserve-sign %s -o - | FileCheck -check-prefix=GFX10-DENORM %s
# RUN: llc -global-isel -mtriple=amdgcn -mcpu=gfx1010 -run-pass=amdgpu-postlegalizer-combiner -enable-unsafe-fp-math %s -o - | FileCheck -check-prefix=GFX10-UNSAFE %s

---
name:            test_f32_add_mul
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2

    ; GFX9-LABEL: name: test_f32_add_mul
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX9-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-CONTRACT-LABEL: name: test_f32_add_mul
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX9-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-DENORM-LABEL: name: test_f32_add_mul
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-UNSAFE-LABEL: name: test_f32_add_mul
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX9-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-LABEL: name: test_f32_add_mul
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX10-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-CONTRACT-LABEL: name: test_f32_add_mul
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX10-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-DENORM-LABEL: name: test_f32_add_mul
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-UNSAFE-LABEL: name: test_f32_add_mul
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX10-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(f32) = G_BITCAST %0(i32)
    %4:_(f32) = G_BITCAST %1(i32)
    %5:_(f32) = G_FMUL %3, %4
    %6:_(f32) = G_BITCAST %2(i32)
    %7:_(f32) = G_FADD %5, %6
    %8:_(i32) = G_BITCAST %7(f32)
    $vgpr0 = COPY %8(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
...

---
name:            test_f32_add_mul_rhs
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2

    ; GFX9-LABEL: name: test_f32_add_mul_rhs
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX9-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-CONTRACT-LABEL: name: test_f32_add_mul_rhs
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX9-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-DENORM-LABEL: name: test_f32_add_mul_rhs
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-UNSAFE-LABEL: name: test_f32_add_mul_rhs
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX9-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-LABEL: name: test_f32_add_mul_rhs
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX10-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-CONTRACT-LABEL: name: test_f32_add_mul_rhs
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX10-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-DENORM-LABEL: name: test_f32_add_mul_rhs
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-UNSAFE-LABEL: name: test_f32_add_mul_rhs
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[COPY2]](i32)
    ; GFX10-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(f32) = G_BITCAST %0(i32)
    %4:_(f32) = G_BITCAST %1(i32)
    %5:_(f32) = G_FMUL %3, %4
    %6:_(f32) = G_BITCAST %2(i32)
    %7:_(f32) = G_FADD %6, %5
    %8:_(i32) = G_BITCAST %7(f32)
    $vgpr0 = COPY %8(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
...

---
name: test_add_mul_multiple_defs_z
body: |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; GFX9-LABEL: name: test_add_mul_multiple_defs_z
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX9-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX9-CONTRACT-LABEL: name: test_add_mul_multiple_defs_z
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX9-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX9-DENORM-LABEL: name: test_add_mul_multiple_defs_z
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX9-UNSAFE-LABEL: name: test_add_mul_multiple_defs_z
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX9-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX10-LABEL: name: test_add_mul_multiple_defs_z
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX10-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX10-CONTRACT-LABEL: name: test_add_mul_multiple_defs_z
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX10-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX10-DENORM-LABEL: name: test_add_mul_multiple_defs_z
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX10-UNSAFE-LABEL: name: test_add_mul_multiple_defs_z
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX10-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(p1) = G_MERGE_VALUES %2(i32), %3(i32)
    %5:_(f32) = G_BITCAST %0(i32)
    %6:_(f32) = G_BITCAST %1(i32)
    %7:_(f32) = G_FMUL %5, %6
    %8:_(<2 x i32>) = G_LOAD %4(p1) :: (load (<2 x i32>), addrspace 1)
    %9:_(i32), %10:_(i32) = G_UNMERGE_VALUES %8(<2 x i32>)
    %11:_(i32) = COPY %10(i32)
    %12:_(f32) = G_BITCAST %11(i32)
    %13:_(f32) = G_FADD %7, %12
    %14:_(i32) = G_BITCAST %13(f32)
    $vgpr0 = COPY %14(i32)
...

---
name: test_add_mul_rhs_multiple_defs_z
body: |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; GFX9-LABEL: name: test_add_mul_rhs_multiple_defs_z
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX9-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX9-CONTRACT-LABEL: name: test_add_mul_rhs_multiple_defs_z
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX9-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX9-DENORM-LABEL: name: test_add_mul_rhs_multiple_defs_z
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX9-UNSAFE-LABEL: name: test_add_mul_rhs_multiple_defs_z
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX9-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX10-LABEL: name: test_add_mul_rhs_multiple_defs_z
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX10-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX10-CONTRACT-LABEL: name: test_add_mul_rhs_multiple_defs_z
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX10-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX10-DENORM-LABEL: name: test_add_mul_rhs_multiple_defs_z
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f32) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f32) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FADD]](f32)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    ;
    ; GFX10-UNSAFE-LABEL: name: test_add_mul_rhs_multiple_defs_z
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(p1) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f32) = G_BITCAST [[COPY]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f32) = G_BITCAST [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[LOAD:%[0-9]+]]:_(<2 x i32>) = G_LOAD [[MV]](p1) :: (load (<2 x i32>), addrspace 1)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[LOAD]](<2 x i32>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f32) = G_BITCAST [[UV1]](i32)
    ; GFX10-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[FMA]](f32)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[BITCAST3]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(p1) = G_MERGE_VALUES %2(i32), %3(i32)
    %5:_(f32) = G_BITCAST %0(i32)
    %6:_(f32) = G_BITCAST %1(i32)
    %7:_(f32) = G_FMUL %5, %6
    %8:_(<2 x i32>) = G_LOAD %4(p1) :: (load (<2 x i32>), addrspace 1)
    %9:_(i32), %10:_(i32) = G_UNMERGE_VALUES %8(<2 x i32>)
    %11:_(i32) = COPY %10(i32)
    %12:_(f32) = G_BITCAST %11(i32)
    %13:_(f32) = G_FADD %12, %7
    %14:_(i32) = G_BITCAST %13(f32)
    $vgpr0 = COPY %14(i32)
...

---
name:            test_half_add_mul
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2

    ; GFX9-LABEL: name: test_half_add_mul
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(f16) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(f16) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FADD]](f16)
    ; GFX9-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX9-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-CONTRACT-LABEL: name: test_half_add_mul
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX9-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f16) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FMA]](f16)
    ; GFX9-CONTRACT-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-DENORM-LABEL: name: test_half_add_mul
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f16) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f16) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FADD]](f16)
    ; GFX9-DENORM-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-UNSAFE-LABEL: name: test_half_add_mul
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX9-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f16) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FMA]](f16)
    ; GFX9-UNSAFE-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-LABEL: name: test_half_add_mul
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(f16) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(f16) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FADD]](f16)
    ; GFX10-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX10-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-CONTRACT-LABEL: name: test_half_add_mul
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX10-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f16) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FMA]](f16)
    ; GFX10-CONTRACT-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-DENORM-LABEL: name: test_half_add_mul
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f16) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f16) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FADD]](f16)
    ; GFX10-DENORM-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-UNSAFE-LABEL: name: test_half_add_mul
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX10-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f16) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FMA]](f16)
    ; GFX10-UNSAFE-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    %0:_(i32) = COPY $vgpr0
    %1:_(i16) = G_TRUNC %0(i32)
    %2:_(i32) = COPY $vgpr1
    %3:_(i16) = G_TRUNC %2(i32)
    %4:_(i32) = COPY $vgpr2
    %5:_(i16) = G_TRUNC %4(i32)
    %6:_(f16) = G_BITCAST %1(i16)
    %7:_(f16) = G_BITCAST %3(i16)
    %8:_(f16) = G_FMUL %6, %7
    %9:_(f16) = G_BITCAST %5(i16)
    %10:_(f16) = G_FADD %8, %9
    %11:_(i16) = G_BITCAST %10(f16)
    %12:_(i32) = G_ANYEXT %11(i16)
    $vgpr0 = COPY %12(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
...

---
name:            test_half_add_mul_rhs
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2

    ; GFX9-LABEL: name: test_half_add_mul_rhs
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(f16) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(f16) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FADD]](f16)
    ; GFX9-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX9-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-CONTRACT-LABEL: name: test_half_add_mul_rhs
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX9-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f16) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FMA]](f16)
    ; GFX9-CONTRACT-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-DENORM-LABEL: name: test_half_add_mul_rhs
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f16) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f16) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FADD]](f16)
    ; GFX9-DENORM-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX9-UNSAFE-LABEL: name: test_half_add_mul_rhs
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX9-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f16) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FMA]](f16)
    ; GFX9-UNSAFE-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-LABEL: name: test_half_add_mul_rhs
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(f16) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(f16) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FADD]](f16)
    ; GFX10-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX10-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-CONTRACT-LABEL: name: test_half_add_mul_rhs
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX10-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f16) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FMA]](f16)
    ; GFX10-CONTRACT-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-DENORM-LABEL: name: test_half_add_mul_rhs
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f16) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f16) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FADD]](f16)
    ; GFX10-DENORM-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    ;
    ; GFX10-UNSAFE-LABEL: name: test_half_add_mul_rhs
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX10-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f16) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i16) = G_BITCAST [[FMA]](f16)
    ; GFX10-UNSAFE-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST3]](i16)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
    %0:_(i32) = COPY $vgpr0
    %1:_(i16) = G_TRUNC %0(i32)
    %2:_(i32) = COPY $vgpr1
    %3:_(i16) = G_TRUNC %2(i32)
    %4:_(i32) = COPY $vgpr2
    %5:_(i16) = G_TRUNC %4(i32)
    %6:_(f16) = G_BITCAST %1(i16)
    %7:_(f16) = G_BITCAST %3(i16)
    %8:_(f16) = G_FMUL %6, %7
    %9:_(f16) = G_BITCAST %5(i16)
    %10:_(f16) = G_FADD %9, %8
    %11:_(i16) = G_BITCAST %10(f16)
    %12:_(i32) = G_ANYEXT %11(i16)
    $vgpr0 = COPY %12(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0
...

---
name:            test_double_add_mul
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5

    ; GFX9-LABEL: name: test_double_add_mul
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(f64) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(f64) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FADD]](f64)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX9-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-CONTRACT-LABEL: name: test_double_add_mul
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-CONTRACT-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX9-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f64) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FMA]](f64)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-DENORM-LABEL: name: test_double_add_mul
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-DENORM-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f64) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f64) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FADD]](f64)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-UNSAFE-LABEL: name: test_double_add_mul
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-UNSAFE-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX9-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f64) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FMA]](f64)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-LABEL: name: test_double_add_mul
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(f64) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(f64) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FADD]](f64)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX10-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-CONTRACT-LABEL: name: test_double_add_mul
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-CONTRACT-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX10-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f64) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FMA]](f64)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-DENORM-LABEL: name: test_double_add_mul
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-DENORM-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f64) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f64) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FADD]](f64)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-UNSAFE-LABEL: name: test_double_add_mul
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-UNSAFE-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX10-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f64) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FMA]](f64)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i64) = G_MERGE_VALUES %0(i32), %1(i32)
    %3:_(i32) = COPY $vgpr2
    %4:_(i32) = COPY $vgpr3
    %5:_(i64) = G_MERGE_VALUES %3(i32), %4(i32)
    %6:_(i32) = COPY $vgpr4
    %7:_(i32) = COPY $vgpr5
    %8:_(i64) = G_MERGE_VALUES %6(i32), %7(i32)
    %9:_(f64) = G_BITCAST %2(i64)
    %10:_(f64) = G_BITCAST %5(i64)
    %11:_(f64) = G_FMUL %9, %10
    %12:_(f64) = G_BITCAST %8(i64)
    %13:_(f64) = G_FADD %11, %12
    %14:_(i64) = G_BITCAST %13(f64)
    %15:_(i32), %16:_(i32) = G_UNMERGE_VALUES %14(i64)
    $vgpr0 = COPY %15(i32)
    $vgpr1 = COPY %16(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
...

---
name:            test_double_add_mul_rhs
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5

    ; GFX9-LABEL: name: test_double_add_mul_rhs
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(f64) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(f64) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FADD]](f64)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX9-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-CONTRACT-LABEL: name: test_double_add_mul_rhs
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-CONTRACT-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX9-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f64) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FMA]](f64)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-DENORM-LABEL: name: test_double_add_mul_rhs
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-DENORM-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f64) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f64) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FADD]](f64)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-UNSAFE-LABEL: name: test_double_add_mul_rhs
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-UNSAFE-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX9-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f64) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FMA]](f64)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-LABEL: name: test_double_add_mul_rhs
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(f64) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(f64) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FADD]](f64)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX10-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-CONTRACT-LABEL: name: test_double_add_mul_rhs
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-CONTRACT-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX10-CONTRACT-NEXT: [[FMA:%[0-9]+]]:_(f64) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FMA]](f64)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-DENORM-LABEL: name: test_double_add_mul_rhs
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-DENORM-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(f64) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(f64) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FADD]](f64)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-UNSAFE-LABEL: name: test_double_add_mul_rhs
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-UNSAFE-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(f64) = G_BITCAST [[MV]](i64)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(f64) = G_BITCAST [[MV1]](i64)
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(f64) = G_BITCAST [[MV2]](i64)
    ; GFX10-UNSAFE-NEXT: [[FMA:%[0-9]+]]:_(f64) = G_FMA [[BITCAST]], [[BITCAST1]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(i64) = G_BITCAST [[FMA]](f64)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](i64)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i64) = G_MERGE_VALUES %0(i32), %1(i32)
    %3:_(i32) = COPY $vgpr2
    %4:_(i32) = COPY $vgpr3
    %5:_(i64) = G_MERGE_VALUES %3(i32), %4(i32)
    %6:_(i32) = COPY $vgpr4
    %7:_(i32) = COPY $vgpr5
    %8:_(i64) = G_MERGE_VALUES %6(i32), %7(i32)
    %9:_(f64) = G_BITCAST %2(i64)
    %10:_(f64) = G_BITCAST %5(i64)
    %11:_(f64) = G_FMUL %9, %10
    %12:_(f64) = G_BITCAST %8(i64)
    %13:_(f64) = G_FADD %12, %11
    %14:_(i64) = G_BITCAST %13(f64)
    %15:_(i32), %16:_(i32) = G_UNMERGE_VALUES %14(i64)
    $vgpr0 = COPY %15(i32)
    $vgpr1 = COPY %16(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
...

---
name:            test_4xfloat_add_mul
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10

    ; GFX9-LABEL: name: test_4xfloat_add_mul
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32), [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32), [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR]](<4 x i32>)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i32>)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i32>)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(<4 x f32>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i32>) = G_BITCAST [[FADD]](<4 x f32>)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i32>)
    ; GFX9-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    ;
    ; GFX9-CONTRACT-LABEL: name: test_4xfloat_add_mul
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-CONTRACT-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-CONTRACT-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32), [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-CONTRACT-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-CONTRACT-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-CONTRACT-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32), [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR]](<4 x i32>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i32>)
    ; GFX9-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i32>)
    ; GFX9-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<4 x f32>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i32>) = G_BITCAST [[FADD]](<4 x f32>)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i32>)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    ;
    ; GFX9-DENORM-LABEL: name: test_4xfloat_add_mul
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-DENORM-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-DENORM-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32), [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-DENORM-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-DENORM-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-DENORM-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-DENORM-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32), [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR]](<4 x i32>)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i32>)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i32>)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<4 x f32>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i32>) = G_BITCAST [[FADD]](<4 x f32>)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i32>)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-DENORM-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-DENORM-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    ;
    ; GFX9-UNSAFE-LABEL: name: test_4xfloat_add_mul
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-UNSAFE-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-UNSAFE-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32), [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-UNSAFE-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-UNSAFE-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-UNSAFE-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32), [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR]](<4 x i32>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i32>)
    ; GFX9-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i32>)
    ; GFX9-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<4 x f32>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i32>) = G_BITCAST [[FADD]](<4 x f32>)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i32>)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    ;
    ; GFX10-LABEL: name: test_4xfloat_add_mul
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32), [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32), [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR]](<4 x i32>)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i32>)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i32>)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(<4 x f32>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i32>) = G_BITCAST [[FADD]](<4 x f32>)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i32>)
    ; GFX10-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    ;
    ; GFX10-CONTRACT-LABEL: name: test_4xfloat_add_mul
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-CONTRACT-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-CONTRACT-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32), [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-CONTRACT-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-CONTRACT-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-CONTRACT-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32), [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR]](<4 x i32>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i32>)
    ; GFX10-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i32>)
    ; GFX10-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<4 x f32>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i32>) = G_BITCAST [[FADD]](<4 x f32>)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i32>)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    ;
    ; GFX10-DENORM-LABEL: name: test_4xfloat_add_mul
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-DENORM-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-DENORM-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32), [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-DENORM-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-DENORM-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-DENORM-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-DENORM-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32), [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR]](<4 x i32>)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i32>)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i32>)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<4 x f32>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i32>) = G_BITCAST [[FADD]](<4 x f32>)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i32>)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-DENORM-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-DENORM-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    ;
    ; GFX10-UNSAFE-LABEL: name: test_4xfloat_add_mul
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-UNSAFE-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-UNSAFE-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32), [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-UNSAFE-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-UNSAFE-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-UNSAFE-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32), [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR]](<4 x i32>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i32>)
    ; GFX10-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i32>)
    ; GFX10-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<4 x f32>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i32>) = G_BITCAST [[FADD]](<4 x f32>)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i32>)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(<4 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32), %3(i32)
    %5:_(i32) = COPY $vgpr4
    %6:_(i32) = COPY $vgpr5
    %7:_(i32) = COPY $vgpr6
    %8:_(i32) = COPY $vgpr7
    %9:_(<4 x i32>) = G_BUILD_VECTOR %5(i32), %6(i32), %7(i32), %8(i32)
    %10:_(i32) = COPY $vgpr8
    %11:_(i32) = COPY $vgpr9
    %12:_(i32) = COPY $vgpr10
    %13:_(i32) = COPY $vgpr11
    %14:_(<4 x i32>) = G_BUILD_VECTOR %10(i32), %11(i32), %12(i32), %13(i32)
    %15:_(<4 x f32>) = G_BITCAST %4(<4 x i32>)
    %16:_(<4 x f32>) = G_BITCAST %9(<4 x i32>)
    %17:_(<4 x f32>) = G_FMUL %15, %16
    %18:_(<4 x f32>) = G_BITCAST %14(<4 x i32>)
    %19:_(<4 x f32>) = G_FADD %17, %18
    %20:_(<4 x i32>) = G_BITCAST %19(<4 x f32>)
    %21:_(i32), %22:_(i32), %23:_(i32), %24:_(i32) = G_UNMERGE_VALUES %20(<4 x i32>)
    $vgpr0 = COPY %21(i32)
    $vgpr1 = COPY %22(i32)
    $vgpr2 = COPY %23(i32)
    $vgpr3 = COPY %24(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
...

---
name:            test_3xfloat_add_mul_rhs
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8

    ; GFX9-LABEL: name: test_3xfloat_add_mul_rhs
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32), [[COPY8]](i32)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR]](<3 x i32>)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i32>)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i32>)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(<3 x f32>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i32>) = G_BITCAST [[FADD]](<3 x f32>)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i32>)
    ; GFX9-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    ;
    ; GFX9-CONTRACT-LABEL: name: test_3xfloat_add_mul_rhs
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-CONTRACT-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-CONTRACT-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-CONTRACT-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32), [[COPY8]](i32)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR]](<3 x i32>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i32>)
    ; GFX9-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i32>)
    ; GFX9-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<3 x f32>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i32>) = G_BITCAST [[FADD]](<3 x f32>)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i32>)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    ;
    ; GFX9-DENORM-LABEL: name: test_3xfloat_add_mul_rhs
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-DENORM-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-DENORM-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-DENORM-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32), [[COPY8]](i32)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR]](<3 x i32>)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i32>)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i32>)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<3 x f32>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i32>) = G_BITCAST [[FADD]](<3 x f32>)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i32>)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-DENORM-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    ;
    ; GFX9-UNSAFE-LABEL: name: test_3xfloat_add_mul_rhs
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-UNSAFE-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-UNSAFE-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-UNSAFE-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32), [[COPY8]](i32)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR]](<3 x i32>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i32>)
    ; GFX9-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i32>)
    ; GFX9-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<3 x f32>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i32>) = G_BITCAST [[FADD]](<3 x f32>)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i32>)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    ;
    ; GFX10-LABEL: name: test_3xfloat_add_mul_rhs
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32), [[COPY8]](i32)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR]](<3 x i32>)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i32>)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i32>)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(<3 x f32>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i32>) = G_BITCAST [[FADD]](<3 x f32>)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i32>)
    ; GFX10-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    ;
    ; GFX10-CONTRACT-LABEL: name: test_3xfloat_add_mul_rhs
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-CONTRACT-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-CONTRACT-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-CONTRACT-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32), [[COPY8]](i32)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR]](<3 x i32>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i32>)
    ; GFX10-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i32>)
    ; GFX10-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<3 x f32>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i32>) = G_BITCAST [[FADD]](<3 x f32>)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i32>)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    ;
    ; GFX10-DENORM-LABEL: name: test_3xfloat_add_mul_rhs
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-DENORM-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-DENORM-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-DENORM-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32), [[COPY8]](i32)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR]](<3 x i32>)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i32>)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i32>)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<3 x f32>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i32>) = G_BITCAST [[FADD]](<3 x f32>)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i32>)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-DENORM-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    ;
    ; GFX10-UNSAFE-LABEL: name: test_3xfloat_add_mul_rhs
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-UNSAFE-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-UNSAFE-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-UNSAFE-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32), [[COPY8]](i32)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR]](<3 x i32>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i32>)
    ; GFX10-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f32>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f32>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i32>)
    ; GFX10-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<3 x f32>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i32>) = G_BITCAST [[FADD]](<3 x f32>)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i32>)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(<3 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32)
    %4:_(i32) = COPY $vgpr3
    %5:_(i32) = COPY $vgpr4
    %6:_(i32) = COPY $vgpr5
    %7:_(<3 x i32>) = G_BUILD_VECTOR %4(i32), %5(i32), %6(i32)
    %8:_(i32) = COPY $vgpr6
    %9:_(i32) = COPY $vgpr7
    %10:_(i32) = COPY $vgpr8
    %11:_(<3 x i32>) = G_BUILD_VECTOR %8(i32), %9(i32), %10(i32)
    %12:_(<3 x f32>) = G_BITCAST %3(<3 x i32>)
    %13:_(<3 x f32>) = G_BITCAST %7(<3 x i32>)
    %14:_(<3 x f32>) = G_FMUL %12, %13
    %15:_(<3 x f32>) = G_BITCAST %11(<3 x i32>)
    %16:_(<3 x f32>) = G_FADD %15, %14
    %17:_(<3 x i32>) = G_BITCAST %16(<3 x f32>)
    %18:_(i32), %19:_(i32), %20:_(i32) = G_UNMERGE_VALUES %17(<3 x i32>)
    $vgpr0 = COPY %18(i32)
    $vgpr1 = COPY %19(i32)
    $vgpr2 = COPY %20(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
...

---
name:            test_4xhalf_add_mul
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5

    ; GFX9-LABEL: name: test_4xhalf_add_mul
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX9-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>)
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX9-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>)
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX9-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS]](<4 x i16>)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS1]](<4 x i16>)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS2]](<4 x i16>)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(<4 x f16>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i16>) = G_BITCAST [[FADD]](<4 x f16>)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i16>)
    ; GFX9-NEXT: $vgpr0 = COPY [[UV]](<2 x i16>)
    ; GFX9-NEXT: $vgpr1 = COPY [[UV1]](<2 x i16>)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-CONTRACT-LABEL: name: test_4xhalf_add_mul
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX9-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX9-CONTRACT-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS]](<4 x i16>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS1]](<4 x i16>)
    ; GFX9-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS2]](<4 x i16>)
    ; GFX9-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<4 x f16>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i16>) = G_BITCAST [[FADD]](<4 x f16>)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i16>)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-DENORM-LABEL: name: test_4xhalf_add_mul
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>)
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>)
    ; GFX9-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX9-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX9-DENORM-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS]](<4 x i16>)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS1]](<4 x i16>)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS2]](<4 x i16>)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<4 x f16>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i16>) = G_BITCAST [[FADD]](<4 x f16>)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i16>)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[UV]](<2 x i16>)
    ; GFX9-DENORM-NEXT: $vgpr1 = COPY [[UV1]](<2 x i16>)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-UNSAFE-LABEL: name: test_4xhalf_add_mul
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX9-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX9-UNSAFE-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS]](<4 x i16>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS1]](<4 x i16>)
    ; GFX9-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS2]](<4 x i16>)
    ; GFX9-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<4 x f16>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i16>) = G_BITCAST [[FADD]](<4 x f16>)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i16>)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-LABEL: name: test_4xhalf_add_mul
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX10-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>)
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX10-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>)
    ; GFX10-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX10-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX10-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS]](<4 x i16>)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS1]](<4 x i16>)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS2]](<4 x i16>)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(<4 x f16>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i16>) = G_BITCAST [[FADD]](<4 x f16>)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i16>)
    ; GFX10-NEXT: $vgpr0 = COPY [[UV]](<2 x i16>)
    ; GFX10-NEXT: $vgpr1 = COPY [[UV1]](<2 x i16>)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-CONTRACT-LABEL: name: test_4xhalf_add_mul
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX10-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX10-CONTRACT-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS]](<4 x i16>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS1]](<4 x i16>)
    ; GFX10-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS2]](<4 x i16>)
    ; GFX10-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<4 x f16>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i16>) = G_BITCAST [[FADD]](<4 x f16>)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i16>)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-DENORM-LABEL: name: test_4xhalf_add_mul
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>)
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>)
    ; GFX10-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX10-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX10-DENORM-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS]](<4 x i16>)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS1]](<4 x i16>)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS2]](<4 x i16>)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<4 x f16>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i16>) = G_BITCAST [[FADD]](<4 x f16>)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i16>)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[UV]](<2 x i16>)
    ; GFX10-DENORM-NEXT: $vgpr1 = COPY [[UV1]](<2 x i16>)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-UNSAFE-LABEL: name: test_4xhalf_add_mul
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX10-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX10-UNSAFE-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS]](<4 x i16>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS1]](<4 x i16>)
    ; GFX10-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f16>) = G_BITCAST [[CONCAT_VECTORS2]](<4 x i16>)
    ; GFX10-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<4 x f16>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i16>) = G_BITCAST [[FADD]](<4 x f16>)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i16>)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    %0:_(<2 x i16>) = COPY $vgpr0
    %1:_(<2 x i16>) = COPY $vgpr1
    %2:_(<4 x i16>) = G_CONCAT_VECTORS %0(<2 x i16>), %1(<2 x i16>)
    %3:_(<2 x i16>) = COPY $vgpr2
    %4:_(<2 x i16>) = COPY $vgpr3
    %5:_(<4 x i16>) = G_CONCAT_VECTORS %3(<2 x i16>), %4(<2 x i16>)
    %6:_(<2 x i16>) = COPY $vgpr4
    %7:_(<2 x i16>) = COPY $vgpr5
    %8:_(<4 x i16>) = G_CONCAT_VECTORS %6(<2 x i16>), %7(<2 x i16>)
    %9:_(<4 x f16>) = G_BITCAST %2(<4 x i16>)
    %10:_(<4 x f16>) = G_BITCAST %5(<4 x i16>)
    %11:_(<4 x f16>) = G_FMUL %9, %10
    %12:_(<4 x f16>) = G_BITCAST %8(<4 x i16>)
    %13:_(<4 x f16>) = G_FADD %11, %12
    %14:_(<4 x i16>) = G_BITCAST %13(<4 x f16>)
    %15:_(<2 x i16>), %16:_(<2 x i16>) = G_UNMERGE_VALUES %14(<4 x i16>)
    $vgpr0 = COPY %15(<2 x i16>)
    $vgpr1 = COPY %16(<2 x i16>)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
...

---
name:            test_3xhalf_add_mul_rhs
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5

    ; GFX9-LABEL: name: test_3xhalf_add_mul_rhs
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX9-NEXT: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; GFX9-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(<3 x i16>), [[UV1:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<6 x i16>)
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX9-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-NEXT: [[UV2:%[0-9]+]]:_(<3 x i16>), [[UV3:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS1]](<6 x i16>)
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX9-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-NEXT: [[UV4:%[0-9]+]]:_(<3 x i16>), [[UV5:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS2]](<6 x i16>)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV]](<3 x i16>)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV2]](<3 x i16>)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV4]](<3 x i16>)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(<3 x f16>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-NEXT: [[DEF1:%[0-9]+]]:_(<3 x i16>) = G_IMPLICIT_DEF
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i16>) = G_BITCAST [[FADD]](<3 x f16>)
    ; GFX9-NEXT: [[CONCAT_VECTORS3:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST3]](<3 x i16>), [[DEF1]](<3 x i16>)
    ; GFX9-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>), [[UV8:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS3]](<6 x i16>)
    ; GFX9-NEXT: $vgpr0 = COPY [[UV6]](<2 x i16>)
    ; GFX9-NEXT: $vgpr1 = COPY [[UV7]](<2 x i16>)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-CONTRACT-LABEL: name: test_3xhalf_add_mul_rhs
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; GFX9-CONTRACT-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(<3 x i16>), [[UV1:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<6 x i16>)
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: [[UV2:%[0-9]+]]:_(<3 x i16>), [[UV3:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS1]](<6 x i16>)
    ; GFX9-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX9-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX9-CONTRACT-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: [[UV4:%[0-9]+]]:_(<3 x i16>), [[UV5:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS2]](<6 x i16>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV]](<3 x i16>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV2]](<3 x i16>)
    ; GFX9-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV4]](<3 x i16>)
    ; GFX9-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<3 x f16>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-CONTRACT-NEXT: [[DEF1:%[0-9]+]]:_(<3 x i16>) = G_IMPLICIT_DEF
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i16>) = G_BITCAST [[FADD]](<3 x f16>)
    ; GFX9-CONTRACT-NEXT: [[CONCAT_VECTORS3:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST3]](<3 x i16>), [[DEF1]](<3 x i16>)
    ; GFX9-CONTRACT-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>), [[UV8:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS3]](<6 x i16>)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[UV6]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: $vgpr1 = COPY [[UV7]](<2 x i16>)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-DENORM-LABEL: name: test_3xhalf_add_mul_rhs
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; GFX9-DENORM-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(<3 x i16>), [[UV1:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<6 x i16>)
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-DENORM-NEXT: [[UV2:%[0-9]+]]:_(<3 x i16>), [[UV3:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS1]](<6 x i16>)
    ; GFX9-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX9-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX9-DENORM-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-DENORM-NEXT: [[UV4:%[0-9]+]]:_(<3 x i16>), [[UV5:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS2]](<6 x i16>)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV]](<3 x i16>)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV2]](<3 x i16>)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV4]](<3 x i16>)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<3 x f16>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-DENORM-NEXT: [[DEF1:%[0-9]+]]:_(<3 x i16>) = G_IMPLICIT_DEF
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i16>) = G_BITCAST [[FADD]](<3 x f16>)
    ; GFX9-DENORM-NEXT: [[CONCAT_VECTORS3:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST3]](<3 x i16>), [[DEF1]](<3 x i16>)
    ; GFX9-DENORM-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>), [[UV8:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS3]](<6 x i16>)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[UV6]](<2 x i16>)
    ; GFX9-DENORM-NEXT: $vgpr1 = COPY [[UV7]](<2 x i16>)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX9-UNSAFE-LABEL: name: test_3xhalf_add_mul_rhs
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; GFX9-UNSAFE-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(<3 x i16>), [[UV1:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<6 x i16>)
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: [[UV2:%[0-9]+]]:_(<3 x i16>), [[UV3:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS1]](<6 x i16>)
    ; GFX9-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX9-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX9-UNSAFE-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: [[UV4:%[0-9]+]]:_(<3 x i16>), [[UV5:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS2]](<6 x i16>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV]](<3 x i16>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV2]](<3 x i16>)
    ; GFX9-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV4]](<3 x i16>)
    ; GFX9-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<3 x f16>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-UNSAFE-NEXT: [[DEF1:%[0-9]+]]:_(<3 x i16>) = G_IMPLICIT_DEF
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i16>) = G_BITCAST [[FADD]](<3 x f16>)
    ; GFX9-UNSAFE-NEXT: [[CONCAT_VECTORS3:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST3]](<3 x i16>), [[DEF1]](<3 x i16>)
    ; GFX9-UNSAFE-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>), [[UV8:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS3]](<6 x i16>)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[UV6]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: $vgpr1 = COPY [[UV7]](<2 x i16>)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-LABEL: name: test_3xhalf_add_mul_rhs
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX10-NEXT: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; GFX10-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(<3 x i16>), [[UV1:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<6 x i16>)
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX10-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-NEXT: [[UV2:%[0-9]+]]:_(<3 x i16>), [[UV3:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS1]](<6 x i16>)
    ; GFX10-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX10-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX10-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-NEXT: [[UV4:%[0-9]+]]:_(<3 x i16>), [[UV5:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS2]](<6 x i16>)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV]](<3 x i16>)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV2]](<3 x i16>)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV4]](<3 x i16>)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(<3 x f16>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-NEXT: [[DEF1:%[0-9]+]]:_(<3 x i16>) = G_IMPLICIT_DEF
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i16>) = G_BITCAST [[FADD]](<3 x f16>)
    ; GFX10-NEXT: [[CONCAT_VECTORS3:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST3]](<3 x i16>), [[DEF1]](<3 x i16>)
    ; GFX10-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>), [[UV8:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS3]](<6 x i16>)
    ; GFX10-NEXT: $vgpr0 = COPY [[UV6]](<2 x i16>)
    ; GFX10-NEXT: $vgpr1 = COPY [[UV7]](<2 x i16>)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-CONTRACT-LABEL: name: test_3xhalf_add_mul_rhs
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; GFX10-CONTRACT-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(<3 x i16>), [[UV1:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<6 x i16>)
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: [[UV2:%[0-9]+]]:_(<3 x i16>), [[UV3:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS1]](<6 x i16>)
    ; GFX10-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX10-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX10-CONTRACT-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: [[UV4:%[0-9]+]]:_(<3 x i16>), [[UV5:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS2]](<6 x i16>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV]](<3 x i16>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV2]](<3 x i16>)
    ; GFX10-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV4]](<3 x i16>)
    ; GFX10-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<3 x f16>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-CONTRACT-NEXT: [[DEF1:%[0-9]+]]:_(<3 x i16>) = G_IMPLICIT_DEF
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i16>) = G_BITCAST [[FADD]](<3 x f16>)
    ; GFX10-CONTRACT-NEXT: [[CONCAT_VECTORS3:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST3]](<3 x i16>), [[DEF1]](<3 x i16>)
    ; GFX10-CONTRACT-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>), [[UV8:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS3]](<6 x i16>)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[UV6]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: $vgpr1 = COPY [[UV7]](<2 x i16>)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-DENORM-LABEL: name: test_3xhalf_add_mul_rhs
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; GFX10-DENORM-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(<3 x i16>), [[UV1:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<6 x i16>)
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-DENORM-NEXT: [[UV2:%[0-9]+]]:_(<3 x i16>), [[UV3:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS1]](<6 x i16>)
    ; GFX10-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX10-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX10-DENORM-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-DENORM-NEXT: [[UV4:%[0-9]+]]:_(<3 x i16>), [[UV5:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS2]](<6 x i16>)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV]](<3 x i16>)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV2]](<3 x i16>)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV4]](<3 x i16>)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<3 x f16>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-DENORM-NEXT: [[DEF1:%[0-9]+]]:_(<3 x i16>) = G_IMPLICIT_DEF
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i16>) = G_BITCAST [[FADD]](<3 x f16>)
    ; GFX10-DENORM-NEXT: [[CONCAT_VECTORS3:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST3]](<3 x i16>), [[DEF1]](<3 x i16>)
    ; GFX10-DENORM-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>), [[UV8:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS3]](<6 x i16>)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[UV6]](<2 x i16>)
    ; GFX10-DENORM-NEXT: $vgpr1 = COPY [[UV7]](<2 x i16>)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    ;
    ; GFX10-UNSAFE-LABEL: name: test_3xhalf_add_mul_rhs
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[DEF:%[0-9]+]]:_(<2 x i16>) = G_IMPLICIT_DEF
    ; GFX10-UNSAFE-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY]](<2 x i16>), [[COPY1]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(<3 x i16>), [[UV1:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<6 x i16>)
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY2]](<2 x i16>), [[COPY3]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: [[UV2:%[0-9]+]]:_(<3 x i16>), [[UV3:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS1]](<6 x i16>)
    ; GFX10-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr4
    ; GFX10-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr5
    ; GFX10-UNSAFE-NEXT: [[CONCAT_VECTORS2:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[COPY4]](<2 x i16>), [[COPY5]](<2 x i16>), [[DEF]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: [[UV4:%[0-9]+]]:_(<3 x i16>), [[UV5:%[0-9]+]]:_(<3 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS2]](<6 x i16>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV]](<3 x i16>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV2]](<3 x i16>)
    ; GFX10-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f16>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f16>) = G_BITCAST [[UV4]](<3 x i16>)
    ; GFX10-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<3 x f16>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-UNSAFE-NEXT: [[DEF1:%[0-9]+]]:_(<3 x i16>) = G_IMPLICIT_DEF
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i16>) = G_BITCAST [[FADD]](<3 x f16>)
    ; GFX10-UNSAFE-NEXT: [[CONCAT_VECTORS3:%[0-9]+]]:_(<6 x i16>) = G_CONCAT_VECTORS [[BITCAST3]](<3 x i16>), [[DEF1]](<3 x i16>)
    ; GFX10-UNSAFE-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>), [[UV8:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[CONCAT_VECTORS3]](<6 x i16>)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[UV6]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: $vgpr1 = COPY [[UV7]](<2 x i16>)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
    %0:_(<2 x i16>) = COPY $vgpr0
    %1:_(<2 x i16>) = COPY $vgpr1
    %2:_(<2 x i16>) = G_IMPLICIT_DEF
    %3:_(<6 x i16>) = G_CONCAT_VECTORS %0(<2 x i16>), %1(<2 x i16>), %2(<2 x i16>)
    %4:_(<3 x i16>), %5:_(<3 x i16>) = G_UNMERGE_VALUES %3(<6 x i16>)
    %6:_(<2 x i16>) = COPY $vgpr2
    %7:_(<2 x i16>) = COPY $vgpr3
    %8:_(<6 x i16>) = G_CONCAT_VECTORS %6(<2 x i16>), %7(<2 x i16>), %2(<2 x i16>)
    %9:_(<3 x i16>), %10:_(<3 x i16>) = G_UNMERGE_VALUES %8(<6 x i16>)
    %11:_(<2 x i16>) = COPY $vgpr4
    %12:_(<2 x i16>) = COPY $vgpr5
    %13:_(<6 x i16>) = G_CONCAT_VECTORS %11(<2 x i16>), %12(<2 x i16>), %2(<2 x i16>)
    %14:_(<3 x i16>), %15:_(<3 x i16>) = G_UNMERGE_VALUES %13(<6 x i16>)
    %16:_(<3 x f16>) = G_BITCAST %4(<3 x i16>)
    %17:_(<3 x f16>) = G_BITCAST %9(<3 x i16>)
    %18:_(<3 x f16>) = G_FMUL %16, %17
    %19:_(<3 x f16>) = G_BITCAST %14(<3 x i16>)
    %20:_(<3 x f16>) = G_FADD %19, %18
    %21:_(<3 x i16>) = G_IMPLICIT_DEF
    %22:_(<3 x i16>) = G_BITCAST %20(<3 x f16>)
    %23:_(<6 x i16>) = G_CONCAT_VECTORS %22(<3 x i16>), %21(<3 x i16>)
    %24:_(<2 x i16>), %25:_(<2 x i16>), %26:_(<2 x i16>) = G_UNMERGE_VALUES %23(<6 x i16>)
    $vgpr0 = COPY %24(<2 x i16>)
    $vgpr1 = COPY %25(<2 x i16>)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1
...

---
name:            test_4xdouble_add_mul
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23

    ; GFX9-LABEL: name: test_4xdouble_add_mul
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64), [[MV3]](i64)
    ; GFX9-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX9-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX9-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV4]](i64), [[MV5]](i64), [[MV6]](i64), [[MV7]](i64)
    ; GFX9-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX9-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX9-NEXT: [[COPY18:%[0-9]+]]:_(i32) = COPY $vgpr18
    ; GFX9-NEXT: [[COPY19:%[0-9]+]]:_(i32) = COPY $vgpr19
    ; GFX9-NEXT: [[COPY20:%[0-9]+]]:_(i32) = COPY $vgpr20
    ; GFX9-NEXT: [[COPY21:%[0-9]+]]:_(i32) = COPY $vgpr21
    ; GFX9-NEXT: [[COPY22:%[0-9]+]]:_(i32) = COPY $vgpr22
    ; GFX9-NEXT: [[COPY23:%[0-9]+]]:_(i32) = COPY $vgpr23
    ; GFX9-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX9-NEXT: [[MV9:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY18]](i32), [[COPY19]](i32)
    ; GFX9-NEXT: [[MV10:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY20]](i32), [[COPY21]](i32)
    ; GFX9-NEXT: [[MV11:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY22]](i32), [[COPY23]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV8]](i64), [[MV9]](i64), [[MV10]](i64), [[MV11]](i64)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR]](<4 x i64>)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i64>)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i64>)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(<4 x f64>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[FADD]](<4 x f64>)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i64>)
    ; GFX9-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX9-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX9-NEXT: $vgpr6 = COPY [[UV6]](i32)
    ; GFX9-NEXT: $vgpr7 = COPY [[UV7]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
    ;
    ; GFX9-CONTRACT-LABEL: name: test_4xdouble_add_mul
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-CONTRACT-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-CONTRACT-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64), [[MV3]](i64)
    ; GFX9-CONTRACT-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-CONTRACT-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-CONTRACT-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-CONTRACT-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-CONTRACT-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-CONTRACT-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-CONTRACT-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-CONTRACT-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-CONTRACT-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV4]](i64), [[MV5]](i64), [[MV6]](i64), [[MV7]](i64)
    ; GFX9-CONTRACT-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX9-CONTRACT-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX9-CONTRACT-NEXT: [[COPY18:%[0-9]+]]:_(i32) = COPY $vgpr18
    ; GFX9-CONTRACT-NEXT: [[COPY19:%[0-9]+]]:_(i32) = COPY $vgpr19
    ; GFX9-CONTRACT-NEXT: [[COPY20:%[0-9]+]]:_(i32) = COPY $vgpr20
    ; GFX9-CONTRACT-NEXT: [[COPY21:%[0-9]+]]:_(i32) = COPY $vgpr21
    ; GFX9-CONTRACT-NEXT: [[COPY22:%[0-9]+]]:_(i32) = COPY $vgpr22
    ; GFX9-CONTRACT-NEXT: [[COPY23:%[0-9]+]]:_(i32) = COPY $vgpr23
    ; GFX9-CONTRACT-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV9:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY18]](i32), [[COPY19]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV10:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY20]](i32), [[COPY21]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV11:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY22]](i32), [[COPY23]](i32)
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV8]](i64), [[MV9]](i64), [[MV10]](i64), [[MV11]](i64)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR]](<4 x i64>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i64>)
    ; GFX9-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i64>)
    ; GFX9-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<4 x f64>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[FADD]](<4 x f64>)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i64>)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr6 = COPY [[UV6]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr7 = COPY [[UV7]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
    ;
    ; GFX9-DENORM-LABEL: name: test_4xdouble_add_mul
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-DENORM-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-DENORM-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-DENORM-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-DENORM-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-DENORM-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64), [[MV3]](i64)
    ; GFX9-DENORM-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-DENORM-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-DENORM-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-DENORM-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-DENORM-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-DENORM-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-DENORM-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-DENORM-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-DENORM-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX9-DENORM-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-DENORM-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX9-DENORM-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV4]](i64), [[MV5]](i64), [[MV6]](i64), [[MV7]](i64)
    ; GFX9-DENORM-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX9-DENORM-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX9-DENORM-NEXT: [[COPY18:%[0-9]+]]:_(i32) = COPY $vgpr18
    ; GFX9-DENORM-NEXT: [[COPY19:%[0-9]+]]:_(i32) = COPY $vgpr19
    ; GFX9-DENORM-NEXT: [[COPY20:%[0-9]+]]:_(i32) = COPY $vgpr20
    ; GFX9-DENORM-NEXT: [[COPY21:%[0-9]+]]:_(i32) = COPY $vgpr21
    ; GFX9-DENORM-NEXT: [[COPY22:%[0-9]+]]:_(i32) = COPY $vgpr22
    ; GFX9-DENORM-NEXT: [[COPY23:%[0-9]+]]:_(i32) = COPY $vgpr23
    ; GFX9-DENORM-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX9-DENORM-NEXT: [[MV9:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY18]](i32), [[COPY19]](i32)
    ; GFX9-DENORM-NEXT: [[MV10:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY20]](i32), [[COPY21]](i32)
    ; GFX9-DENORM-NEXT: [[MV11:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY22]](i32), [[COPY23]](i32)
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV8]](i64), [[MV9]](i64), [[MV10]](i64), [[MV11]](i64)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR]](<4 x i64>)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i64>)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i64>)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<4 x f64>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[FADD]](<4 x f64>)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i64>)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-DENORM-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-DENORM-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-DENORM-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX9-DENORM-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX9-DENORM-NEXT: $vgpr6 = COPY [[UV6]](i32)
    ; GFX9-DENORM-NEXT: $vgpr7 = COPY [[UV7]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
    ;
    ; GFX9-UNSAFE-LABEL: name: test_4xdouble_add_mul
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-UNSAFE-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-UNSAFE-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64), [[MV3]](i64)
    ; GFX9-UNSAFE-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-UNSAFE-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-UNSAFE-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-UNSAFE-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-UNSAFE-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-UNSAFE-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-UNSAFE-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-UNSAFE-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-UNSAFE-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV4]](i64), [[MV5]](i64), [[MV6]](i64), [[MV7]](i64)
    ; GFX9-UNSAFE-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX9-UNSAFE-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX9-UNSAFE-NEXT: [[COPY18:%[0-9]+]]:_(i32) = COPY $vgpr18
    ; GFX9-UNSAFE-NEXT: [[COPY19:%[0-9]+]]:_(i32) = COPY $vgpr19
    ; GFX9-UNSAFE-NEXT: [[COPY20:%[0-9]+]]:_(i32) = COPY $vgpr20
    ; GFX9-UNSAFE-NEXT: [[COPY21:%[0-9]+]]:_(i32) = COPY $vgpr21
    ; GFX9-UNSAFE-NEXT: [[COPY22:%[0-9]+]]:_(i32) = COPY $vgpr22
    ; GFX9-UNSAFE-NEXT: [[COPY23:%[0-9]+]]:_(i32) = COPY $vgpr23
    ; GFX9-UNSAFE-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV9:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY18]](i32), [[COPY19]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV10:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY20]](i32), [[COPY21]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV11:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY22]](i32), [[COPY23]](i32)
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV8]](i64), [[MV9]](i64), [[MV10]](i64), [[MV11]](i64)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR]](<4 x i64>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i64>)
    ; GFX9-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i64>)
    ; GFX9-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<4 x f64>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[FADD]](<4 x f64>)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i64>)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr6 = COPY [[UV6]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr7 = COPY [[UV7]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
    ;
    ; GFX10-LABEL: name: test_4xdouble_add_mul
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64), [[MV3]](i64)
    ; GFX10-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX10-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX10-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX10-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX10-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX10-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX10-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX10-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV4]](i64), [[MV5]](i64), [[MV6]](i64), [[MV7]](i64)
    ; GFX10-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX10-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX10-NEXT: [[COPY18:%[0-9]+]]:_(i32) = COPY $vgpr18
    ; GFX10-NEXT: [[COPY19:%[0-9]+]]:_(i32) = COPY $vgpr19
    ; GFX10-NEXT: [[COPY20:%[0-9]+]]:_(i32) = COPY $vgpr20
    ; GFX10-NEXT: [[COPY21:%[0-9]+]]:_(i32) = COPY $vgpr21
    ; GFX10-NEXT: [[COPY22:%[0-9]+]]:_(i32) = COPY $vgpr22
    ; GFX10-NEXT: [[COPY23:%[0-9]+]]:_(i32) = COPY $vgpr23
    ; GFX10-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX10-NEXT: [[MV9:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY18]](i32), [[COPY19]](i32)
    ; GFX10-NEXT: [[MV10:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY20]](i32), [[COPY21]](i32)
    ; GFX10-NEXT: [[MV11:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY22]](i32), [[COPY23]](i32)
    ; GFX10-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV8]](i64), [[MV9]](i64), [[MV10]](i64), [[MV11]](i64)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR]](<4 x i64>)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i64>)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i64>)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(<4 x f64>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[FADD]](<4 x f64>)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i64>)
    ; GFX10-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX10-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX10-NEXT: $vgpr6 = COPY [[UV6]](i32)
    ; GFX10-NEXT: $vgpr7 = COPY [[UV7]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
    ;
    ; GFX10-CONTRACT-LABEL: name: test_4xdouble_add_mul
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-CONTRACT-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-CONTRACT-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64), [[MV3]](i64)
    ; GFX10-CONTRACT-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-CONTRACT-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-CONTRACT-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-CONTRACT-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-CONTRACT-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX10-CONTRACT-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX10-CONTRACT-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX10-CONTRACT-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX10-CONTRACT-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV4]](i64), [[MV5]](i64), [[MV6]](i64), [[MV7]](i64)
    ; GFX10-CONTRACT-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX10-CONTRACT-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX10-CONTRACT-NEXT: [[COPY18:%[0-9]+]]:_(i32) = COPY $vgpr18
    ; GFX10-CONTRACT-NEXT: [[COPY19:%[0-9]+]]:_(i32) = COPY $vgpr19
    ; GFX10-CONTRACT-NEXT: [[COPY20:%[0-9]+]]:_(i32) = COPY $vgpr20
    ; GFX10-CONTRACT-NEXT: [[COPY21:%[0-9]+]]:_(i32) = COPY $vgpr21
    ; GFX10-CONTRACT-NEXT: [[COPY22:%[0-9]+]]:_(i32) = COPY $vgpr22
    ; GFX10-CONTRACT-NEXT: [[COPY23:%[0-9]+]]:_(i32) = COPY $vgpr23
    ; GFX10-CONTRACT-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV9:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY18]](i32), [[COPY19]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV10:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY20]](i32), [[COPY21]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV11:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY22]](i32), [[COPY23]](i32)
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV8]](i64), [[MV9]](i64), [[MV10]](i64), [[MV11]](i64)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR]](<4 x i64>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i64>)
    ; GFX10-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i64>)
    ; GFX10-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<4 x f64>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[FADD]](<4 x f64>)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i64>)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr6 = COPY [[UV6]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr7 = COPY [[UV7]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
    ;
    ; GFX10-DENORM-LABEL: name: test_4xdouble_add_mul
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-DENORM-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-DENORM-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-DENORM-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-DENORM-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-DENORM-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64), [[MV3]](i64)
    ; GFX10-DENORM-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-DENORM-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-DENORM-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-DENORM-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-DENORM-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX10-DENORM-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX10-DENORM-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX10-DENORM-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX10-DENORM-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX10-DENORM-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-DENORM-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX10-DENORM-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV4]](i64), [[MV5]](i64), [[MV6]](i64), [[MV7]](i64)
    ; GFX10-DENORM-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX10-DENORM-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX10-DENORM-NEXT: [[COPY18:%[0-9]+]]:_(i32) = COPY $vgpr18
    ; GFX10-DENORM-NEXT: [[COPY19:%[0-9]+]]:_(i32) = COPY $vgpr19
    ; GFX10-DENORM-NEXT: [[COPY20:%[0-9]+]]:_(i32) = COPY $vgpr20
    ; GFX10-DENORM-NEXT: [[COPY21:%[0-9]+]]:_(i32) = COPY $vgpr21
    ; GFX10-DENORM-NEXT: [[COPY22:%[0-9]+]]:_(i32) = COPY $vgpr22
    ; GFX10-DENORM-NEXT: [[COPY23:%[0-9]+]]:_(i32) = COPY $vgpr23
    ; GFX10-DENORM-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX10-DENORM-NEXT: [[MV9:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY18]](i32), [[COPY19]](i32)
    ; GFX10-DENORM-NEXT: [[MV10:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY20]](i32), [[COPY21]](i32)
    ; GFX10-DENORM-NEXT: [[MV11:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY22]](i32), [[COPY23]](i32)
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV8]](i64), [[MV9]](i64), [[MV10]](i64), [[MV11]](i64)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR]](<4 x i64>)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i64>)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i64>)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<4 x f64>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[FADD]](<4 x f64>)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i64>)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-DENORM-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-DENORM-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-DENORM-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX10-DENORM-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX10-DENORM-NEXT: $vgpr6 = COPY [[UV6]](i32)
    ; GFX10-DENORM-NEXT: $vgpr7 = COPY [[UV7]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
    ;
    ; GFX10-UNSAFE-LABEL: name: test_4xdouble_add_mul
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17, $vgpr18, $vgpr19, $vgpr20, $vgpr21, $vgpr22, $vgpr23
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-UNSAFE-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-UNSAFE-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64), [[MV3]](i64)
    ; GFX10-UNSAFE-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-UNSAFE-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-UNSAFE-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-UNSAFE-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-UNSAFE-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX10-UNSAFE-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX10-UNSAFE-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX10-UNSAFE-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX10-UNSAFE-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV4]](i64), [[MV5]](i64), [[MV6]](i64), [[MV7]](i64)
    ; GFX10-UNSAFE-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX10-UNSAFE-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX10-UNSAFE-NEXT: [[COPY18:%[0-9]+]]:_(i32) = COPY $vgpr18
    ; GFX10-UNSAFE-NEXT: [[COPY19:%[0-9]+]]:_(i32) = COPY $vgpr19
    ; GFX10-UNSAFE-NEXT: [[COPY20:%[0-9]+]]:_(i32) = COPY $vgpr20
    ; GFX10-UNSAFE-NEXT: [[COPY21:%[0-9]+]]:_(i32) = COPY $vgpr21
    ; GFX10-UNSAFE-NEXT: [[COPY22:%[0-9]+]]:_(i32) = COPY $vgpr22
    ; GFX10-UNSAFE-NEXT: [[COPY23:%[0-9]+]]:_(i32) = COPY $vgpr23
    ; GFX10-UNSAFE-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV9:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY18]](i32), [[COPY19]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV10:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY20]](i32), [[COPY21]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV11:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY22]](i32), [[COPY23]](i32)
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<4 x i64>) = G_BUILD_VECTOR [[MV8]](i64), [[MV9]](i64), [[MV10]](i64), [[MV11]](i64)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR]](<4 x i64>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<4 x i64>)
    ; GFX10-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<4 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<4 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<4 x i64>)
    ; GFX10-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<4 x f64>) = G_FADD [[FMUL]], [[BITCAST2]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<4 x i64>) = G_BITCAST [[FADD]](<4 x f64>)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<4 x i64>)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr6 = COPY [[UV6]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr7 = COPY [[UV7]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i32) = COPY $vgpr5
    %6:_(i32) = COPY $vgpr6
    %7:_(i32) = COPY $vgpr7
    %8:_(i64) = G_MERGE_VALUES %0(i32), %1(i32)
    %9:_(i64) = G_MERGE_VALUES %2(i32), %3(i32)
    %10:_(i64) = G_MERGE_VALUES %4(i32), %5(i32)
    %11:_(i64) = G_MERGE_VALUES %6(i32), %7(i32)
    %12:_(<4 x i64>) = G_BUILD_VECTOR %8(i64), %9(i64), %10(i64), %11(i64)
    %13:_(i32) = COPY $vgpr8
    %14:_(i32) = COPY $vgpr9
    %15:_(i32) = COPY $vgpr10
    %16:_(i32) = COPY $vgpr11
    %17:_(i32) = COPY $vgpr12
    %18:_(i32) = COPY $vgpr13
    %19:_(i32) = COPY $vgpr14
    %20:_(i32) = COPY $vgpr15
    %21:_(i64) = G_MERGE_VALUES %13(i32), %14(i32)
    %22:_(i64) = G_MERGE_VALUES %15(i32), %16(i32)
    %23:_(i64) = G_MERGE_VALUES %17(i32), %18(i32)
    %24:_(i64) = G_MERGE_VALUES %19(i32), %20(i32)
    %25:_(<4 x i64>) = G_BUILD_VECTOR %21(i64), %22(i64), %23(i64), %24(i64)
    %26:_(i32) = COPY $vgpr16
    %27:_(i32) = COPY $vgpr17
    %28:_(i32) = COPY $vgpr18
    %29:_(i32) = COPY $vgpr19
    %30:_(i32) = COPY $vgpr20
    %31:_(i32) = COPY $vgpr21
    %32:_(i32) = COPY $vgpr22
    %33:_(i32) = COPY $vgpr23
    %34:_(i64) = G_MERGE_VALUES %26(i32), %27(i32)
    %35:_(i64) = G_MERGE_VALUES %28(i32), %29(i32)
    %36:_(i64) = G_MERGE_VALUES %30(i32), %31(i32)
    %37:_(i64) = G_MERGE_VALUES %32(i32), %33(i32)
    %38:_(<4 x i64>) = G_BUILD_VECTOR %34(i64), %35(i64), %36(i64), %37(i64)
    %39:_(<4 x f64>) = G_BITCAST %12(<4 x i64>)
    %40:_(<4 x f64>) = G_BITCAST %25(<4 x i64>)
    %41:_(<4 x f64>) = G_FMUL %39, %40
    %42:_(<4 x f64>) = G_BITCAST %38(<4 x i64>)
    %43:_(<4 x f64>) = G_FADD %41, %42
    %44:_(<4 x i64>) = G_BITCAST %43(<4 x f64>)
    %45:_(i32), %46:_(i32), %47:_(i32), %48:_(i32), %49:_(i32), %50:_(i32), %51:_(i32), %52:_(i32) = G_UNMERGE_VALUES %44(<4 x i64>)
    $vgpr0 = COPY %45(i32)
    $vgpr1 = COPY %46(i32)
    $vgpr2 = COPY %47(i32)
    $vgpr3 = COPY %48(i32)
    $vgpr4 = COPY %49(i32)
    $vgpr5 = COPY %50(i32)
    $vgpr6 = COPY %51(i32)
    $vgpr7 = COPY %52(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5, implicit $vgpr6, implicit $vgpr7
...

---
name:            test_3xdouble_add_mul_rhs
body:             |
  bb.1.entry:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17

    ; GFX9-LABEL: name: test_3xdouble_add_mul_rhs
    ; GFX9: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17
    ; GFX9-NEXT: {{  $}}
    ; GFX9-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64)
    ; GFX9-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX9-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV3]](i64), [[MV4]](i64), [[MV5]](i64)
    ; GFX9-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX9-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX9-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX9-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX9-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX9-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV6]](i64), [[MV7]](i64), [[MV8]](i64)
    ; GFX9-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR]](<3 x i64>)
    ; GFX9-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i64>)
    ; GFX9-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i64>)
    ; GFX9-NEXT: [[FADD:%[0-9]+]]:_(<3 x f64>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i64>) = G_BITCAST [[FADD]](<3 x f64>)
    ; GFX9-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i64>)
    ; GFX9-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX9-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX9-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    ;
    ; GFX9-CONTRACT-LABEL: name: test_3xdouble_add_mul_rhs
    ; GFX9-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17
    ; GFX9-CONTRACT-NEXT: {{  $}}
    ; GFX9-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64)
    ; GFX9-CONTRACT-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-CONTRACT-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-CONTRACT-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-CONTRACT-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-CONTRACT-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-CONTRACT-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-CONTRACT-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV3]](i64), [[MV4]](i64), [[MV5]](i64)
    ; GFX9-CONTRACT-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-CONTRACT-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-CONTRACT-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-CONTRACT-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-CONTRACT-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX9-CONTRACT-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX9-CONTRACT-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX9-CONTRACT-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX9-CONTRACT-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV6]](i64), [[MV7]](i64), [[MV8]](i64)
    ; GFX9-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR]](<3 x i64>)
    ; GFX9-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i64>)
    ; GFX9-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i64>)
    ; GFX9-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<3 x f64>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i64>) = G_BITCAST [[FADD]](<3 x f64>)
    ; GFX9-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i64>)
    ; GFX9-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX9-CONTRACT-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX9-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    ;
    ; GFX9-DENORM-LABEL: name: test_3xdouble_add_mul_rhs
    ; GFX9-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17
    ; GFX9-DENORM-NEXT: {{  $}}
    ; GFX9-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-DENORM-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-DENORM-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-DENORM-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64)
    ; GFX9-DENORM-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-DENORM-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-DENORM-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-DENORM-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-DENORM-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-DENORM-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-DENORM-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-DENORM-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX9-DENORM-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV3]](i64), [[MV4]](i64), [[MV5]](i64)
    ; GFX9-DENORM-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-DENORM-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-DENORM-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-DENORM-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-DENORM-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX9-DENORM-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX9-DENORM-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX9-DENORM-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX9-DENORM-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX9-DENORM-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV6]](i64), [[MV7]](i64), [[MV8]](i64)
    ; GFX9-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR]](<3 x i64>)
    ; GFX9-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i64>)
    ; GFX9-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i64>)
    ; GFX9-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<3 x f64>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i64>) = G_BITCAST [[FADD]](<3 x f64>)
    ; GFX9-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i64>)
    ; GFX9-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-DENORM-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-DENORM-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-DENORM-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX9-DENORM-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX9-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    ;
    ; GFX9-UNSAFE-LABEL: name: test_3xdouble_add_mul_rhs
    ; GFX9-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17
    ; GFX9-UNSAFE-NEXT: {{  $}}
    ; GFX9-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX9-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX9-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX9-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX9-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX9-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX9-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64)
    ; GFX9-UNSAFE-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX9-UNSAFE-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX9-UNSAFE-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX9-UNSAFE-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX9-UNSAFE-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX9-UNSAFE-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX9-UNSAFE-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV3]](i64), [[MV4]](i64), [[MV5]](i64)
    ; GFX9-UNSAFE-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX9-UNSAFE-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX9-UNSAFE-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX9-UNSAFE-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX9-UNSAFE-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX9-UNSAFE-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX9-UNSAFE-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX9-UNSAFE-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX9-UNSAFE-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV6]](i64), [[MV7]](i64), [[MV8]](i64)
    ; GFX9-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR]](<3 x i64>)
    ; GFX9-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i64>)
    ; GFX9-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i64>)
    ; GFX9-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<3 x f64>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX9-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i64>) = G_BITCAST [[FADD]](<3 x f64>)
    ; GFX9-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i64>)
    ; GFX9-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX9-UNSAFE-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX9-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    ;
    ; GFX10-LABEL: name: test_3xdouble_add_mul_rhs
    ; GFX10: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17
    ; GFX10-NEXT: {{  $}}
    ; GFX10-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64)
    ; GFX10-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX10-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV3]](i64), [[MV4]](i64), [[MV5]](i64)
    ; GFX10-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX10-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX10-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX10-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX10-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX10-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX10-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX10-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX10-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX10-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV6]](i64), [[MV7]](i64), [[MV8]](i64)
    ; GFX10-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR]](<3 x i64>)
    ; GFX10-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i64>)
    ; GFX10-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i64>)
    ; GFX10-NEXT: [[FADD:%[0-9]+]]:_(<3 x f64>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i64>) = G_BITCAST [[FADD]](<3 x f64>)
    ; GFX10-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i64>)
    ; GFX10-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX10-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX10-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    ;
    ; GFX10-CONTRACT-LABEL: name: test_3xdouble_add_mul_rhs
    ; GFX10-CONTRACT: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17
    ; GFX10-CONTRACT-NEXT: {{  $}}
    ; GFX10-CONTRACT-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-CONTRACT-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-CONTRACT-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-CONTRACT-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-CONTRACT-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-CONTRACT-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-CONTRACT-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64)
    ; GFX10-CONTRACT-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-CONTRACT-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-CONTRACT-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-CONTRACT-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-CONTRACT-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-CONTRACT-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-CONTRACT-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV3]](i64), [[MV4]](i64), [[MV5]](i64)
    ; GFX10-CONTRACT-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX10-CONTRACT-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX10-CONTRACT-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX10-CONTRACT-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX10-CONTRACT-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX10-CONTRACT-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX10-CONTRACT-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX10-CONTRACT-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX10-CONTRACT-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV6]](i64), [[MV7]](i64), [[MV8]](i64)
    ; GFX10-CONTRACT-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR]](<3 x i64>)
    ; GFX10-CONTRACT-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i64>)
    ; GFX10-CONTRACT-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i64>)
    ; GFX10-CONTRACT-NEXT: [[FADD:%[0-9]+]]:_(<3 x f64>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-CONTRACT-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i64>) = G_BITCAST [[FADD]](<3 x f64>)
    ; GFX10-CONTRACT-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i64>)
    ; GFX10-CONTRACT-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX10-CONTRACT-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX10-CONTRACT-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    ;
    ; GFX10-DENORM-LABEL: name: test_3xdouble_add_mul_rhs
    ; GFX10-DENORM: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17
    ; GFX10-DENORM-NEXT: {{  $}}
    ; GFX10-DENORM-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-DENORM-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-DENORM-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-DENORM-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-DENORM-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-DENORM-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-DENORM-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-DENORM-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-DENORM-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64)
    ; GFX10-DENORM-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-DENORM-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-DENORM-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-DENORM-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-DENORM-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-DENORM-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-DENORM-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-DENORM-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX10-DENORM-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV3]](i64), [[MV4]](i64), [[MV5]](i64)
    ; GFX10-DENORM-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX10-DENORM-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX10-DENORM-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX10-DENORM-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX10-DENORM-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX10-DENORM-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX10-DENORM-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX10-DENORM-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX10-DENORM-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX10-DENORM-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV6]](i64), [[MV7]](i64), [[MV8]](i64)
    ; GFX10-DENORM-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR]](<3 x i64>)
    ; GFX10-DENORM-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i64>)
    ; GFX10-DENORM-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-DENORM-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i64>)
    ; GFX10-DENORM-NEXT: [[FADD:%[0-9]+]]:_(<3 x f64>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-DENORM-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i64>) = G_BITCAST [[FADD]](<3 x f64>)
    ; GFX10-DENORM-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i64>)
    ; GFX10-DENORM-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-DENORM-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-DENORM-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-DENORM-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-DENORM-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX10-DENORM-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX10-DENORM-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    ;
    ; GFX10-UNSAFE-LABEL: name: test_3xdouble_add_mul_rhs
    ; GFX10-UNSAFE: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15, $vgpr16, $vgpr17
    ; GFX10-UNSAFE-NEXT: {{  $}}
    ; GFX10-UNSAFE-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX10-UNSAFE-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX10-UNSAFE-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX10-UNSAFE-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX10-UNSAFE-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX10-UNSAFE-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX10-UNSAFE-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY2]](i32), [[COPY3]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV2:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY4]](i32), [[COPY5]](i32)
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV]](i64), [[MV1]](i64), [[MV2]](i64)
    ; GFX10-UNSAFE-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX10-UNSAFE-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX10-UNSAFE-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX10-UNSAFE-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX10-UNSAFE-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX10-UNSAFE-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX10-UNSAFE-NEXT: [[MV3:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY6]](i32), [[COPY7]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV4:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY8]](i32), [[COPY9]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV5:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY10]](i32), [[COPY11]](i32)
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV3]](i64), [[MV4]](i64), [[MV5]](i64)
    ; GFX10-UNSAFE-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; GFX10-UNSAFE-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; GFX10-UNSAFE-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; GFX10-UNSAFE-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; GFX10-UNSAFE-NEXT: [[COPY16:%[0-9]+]]:_(i32) = COPY $vgpr16
    ; GFX10-UNSAFE-NEXT: [[COPY17:%[0-9]+]]:_(i32) = COPY $vgpr17
    ; GFX10-UNSAFE-NEXT: [[MV6:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY12]](i32), [[COPY13]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV7:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY14]](i32), [[COPY15]](i32)
    ; GFX10-UNSAFE-NEXT: [[MV8:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY16]](i32), [[COPY17]](i32)
    ; GFX10-UNSAFE-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i64>) = G_BUILD_VECTOR [[MV6]](i64), [[MV7]](i64), [[MV8]](i64)
    ; GFX10-UNSAFE-NEXT: [[BITCAST:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR]](<3 x i64>)
    ; GFX10-UNSAFE-NEXT: [[BITCAST1:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR1]](<3 x i64>)
    ; GFX10-UNSAFE-NEXT: [[FMUL:%[0-9]+]]:_(<3 x f64>) = G_FMUL [[BITCAST]], [[BITCAST1]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST2:%[0-9]+]]:_(<3 x f64>) = G_BITCAST [[BUILD_VECTOR2]](<3 x i64>)
    ; GFX10-UNSAFE-NEXT: [[FADD:%[0-9]+]]:_(<3 x f64>) = G_FADD [[BITCAST2]], [[FMUL]]
    ; GFX10-UNSAFE-NEXT: [[BITCAST3:%[0-9]+]]:_(<3 x i64>) = G_BITCAST [[FADD]](<3 x f64>)
    ; GFX10-UNSAFE-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32), [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST3]](<3 x i64>)
    ; GFX10-UNSAFE-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; GFX10-UNSAFE-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; GFX10-UNSAFE-NEXT: S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i32) = COPY $vgpr5
    %6:_(i64) = G_MERGE_VALUES %0(i32), %1(i32)
    %7:_(i64) = G_MERGE_VALUES %2(i32), %3(i32)
    %8:_(i64) = G_MERGE_VALUES %4(i32), %5(i32)
    %9:_(<3 x i64>) = G_BUILD_VECTOR %6(i64), %7(i64), %8(i64)
    %10:_(i32) = COPY $vgpr6
    %11:_(i32) = COPY $vgpr7
    %12:_(i32) = COPY $vgpr8
    %13:_(i32) = COPY $vgpr9
    %14:_(i32) = COPY $vgpr10
    %15:_(i32) = COPY $vgpr11
    %16:_(i64) = G_MERGE_VALUES %10(i32), %11(i32)
    %17:_(i64) = G_MERGE_VALUES %12(i32), %13(i32)
    %18:_(i64) = G_MERGE_VALUES %14(i32), %15(i32)
    %19:_(<3 x i64>) = G_BUILD_VECTOR %16(i64), %17(i64), %18(i64)
    %20:_(i32) = COPY $vgpr12
    %21:_(i32) = COPY $vgpr13
    %22:_(i32) = COPY $vgpr14
    %23:_(i32) = COPY $vgpr15
    %24:_(i32) = COPY $vgpr16
    %25:_(i32) = COPY $vgpr17
    %26:_(i64) = G_MERGE_VALUES %20(i32), %21(i32)
    %27:_(i64) = G_MERGE_VALUES %22(i32), %23(i32)
    %28:_(i64) = G_MERGE_VALUES %24(i32), %25(i32)
    %29:_(<3 x i64>) = G_BUILD_VECTOR %26(i64), %27(i64), %28(i64)
    %30:_(<3 x f64>) = G_BITCAST %9(<3 x i64>)
    %31:_(<3 x f64>) = G_BITCAST %19(<3 x i64>)
    %32:_(<3 x f64>) = G_FMUL %30, %31
    %33:_(<3 x f64>) = G_BITCAST %29(<3 x i64>)
    %34:_(<3 x f64>) = G_FADD %33, %32
    %35:_(<3 x i64>) = G_BITCAST %34(<3 x f64>)
    %36:_(i32), %37:_(i32), %38:_(i32), %39:_(i32), %40:_(i32), %41:_(i32) = G_UNMERGE_VALUES %35(<3 x i64>)
    $vgpr0 = COPY %36(i32)
    $vgpr1 = COPY %37(i32)
    $vgpr2 = COPY %38(i32)
    $vgpr3 = COPY %39(i32)
    $vgpr4 = COPY %40(i32)
    $vgpr5 = COPY %41(i32)
    S_SETPC_B64_return $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
...
