# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx900 -run-pass=legalizer -o - %s | FileCheck %s

# The G_UNMERGE_VALUES of the G_SEXT of G_BUILD_VECTOR will introduce
# a new G_SEXT for each of the scalars. The sext of %and[4-7] already
# exist, so the CSE MIR builder in the artifact combiner would re-use
# those instructions and introduce dead copies which were never
# deleted, and also kept the illegal %sext[4-7] alive which would fail
# legalization.

---
name: artifact_combiner_sext_already_exists
tracksRegLiveness: true
body:             |
  bb.0:
    ; CHECK-LABEL: name: artifact_combiner_sext_already_exists
    ; CHECK: %undef:_(p4) = G_IMPLICIT_DEF
    ; CHECK-NEXT: %load:_(i32) = G_LOAD %undef(p4) :: (dereferenceable invariant load (i8), align 16, addrspace 4)
    ; CHECK-NEXT: %unmerge3_0:_(i1) = G_TRUNC %load(i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR %load, [[C]](i32)
    ; CHECK-NEXT: %unmerge3_1:_(i1) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 2
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR %load, [[C1]](i32)
    ; CHECK-NEXT: %unmerge3_2:_(i1) = G_TRUNC [[LSHR1]](i32)
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(i32) = G_CONSTANT i32 3
    ; CHECK-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR %load, [[C2]](i32)
    ; CHECK-NEXT: %unmerge3_3:_(i1) = G_TRUNC [[LSHR2]](i32)
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(i32) = G_CONSTANT i32 4
    ; CHECK-NEXT: [[LSHR3:%[0-9]+]]:_(i32) = G_LSHR %load, [[C3]](i32)
    ; CHECK-NEXT: %unmerge3_4:_(i1) = G_TRUNC [[LSHR3]](i32)
    ; CHECK-NEXT: [[C4:%[0-9]+]]:_(i32) = G_CONSTANT i32 5
    ; CHECK-NEXT: [[LSHR4:%[0-9]+]]:_(i32) = G_LSHR %load, [[C4]](i32)
    ; CHECK-NEXT: %unmerge3_5:_(i1) = G_TRUNC [[LSHR4]](i32)
    ; CHECK-NEXT: [[C5:%[0-9]+]]:_(i32) = G_CONSTANT i32 6
    ; CHECK-NEXT: [[LSHR5:%[0-9]+]]:_(i32) = G_LSHR %load, [[C5]](i32)
    ; CHECK-NEXT: %unmerge3_6:_(i1) = G_TRUNC [[LSHR5]](i32)
    ; CHECK-NEXT: [[C6:%[0-9]+]]:_(i32) = G_CONSTANT i32 7
    ; CHECK-NEXT: [[LSHR6:%[0-9]+]]:_(i32) = G_LSHR %load, [[C6]](i32)
    ; CHECK-NEXT: %unmerge3_7:_(i1) = G_TRUNC [[LSHR6]](i32)
    ; CHECK-NEXT: [[C7:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[C8:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[C9:%[0-9]+]]:_(i32) = G_CONSTANT i32 24
    ; CHECK-NEXT: %negone:_(i1) = G_CONSTANT i1 true
    ; CHECK-NEXT: %and0:_(i1) = G_XOR %unmerge3_0, %negone
    ; CHECK-NEXT: %and1:_(i1) = G_XOR %unmerge3_1, %negone
    ; CHECK-NEXT: %and2:_(i1) = G_XOR %unmerge3_2, %negone
    ; CHECK-NEXT: %and3:_(i1) = G_XOR %unmerge3_3, %negone
    ; CHECK-NEXT: %and4:_(i1) = G_XOR %unmerge3_4, %negone
    ; CHECK-NEXT: %and5:_(i1) = G_XOR %unmerge3_5, %negone
    ; CHECK-NEXT: %and6:_(i1) = G_XOR %unmerge3_6, %negone
    ; CHECK-NEXT: %and7:_(i1) = G_XOR %unmerge3_7, %negone
    ; CHECK-NEXT: [[SEXT:%[0-9]+]]:_(i32) = G_SEXT %and0(i1)
    ; CHECK-NEXT: [[C10:%[0-9]+]]:_(i32) = G_CONSTANT i32 255
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[SEXT]], [[C10]]
    ; CHECK-NEXT: [[SEXT1:%[0-9]+]]:_(i32) = G_SEXT %and1(i1)
    ; CHECK-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[SEXT1]], [[C10]]
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C7]](i32)
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; CHECK-NEXT: [[SEXT2:%[0-9]+]]:_(i32) = G_SEXT %and2(i1)
    ; CHECK-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[SEXT2]], [[C10]]
    ; CHECK-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND2]], [[C8]](i32)
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[OR]], [[SHL1]]
    ; CHECK-NEXT: [[SEXT3:%[0-9]+]]:_(i32) = G_SEXT %and3(i1)
    ; CHECK-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[SEXT3]], [[C10]]
    ; CHECK-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C9]](i32)
    ; CHECK-NEXT: %merge0:_(i32) = G_OR [[OR1]], [[SHL2]]
    ; CHECK-NEXT: [[SEXT4:%[0-9]+]]:_(i32) = G_SEXT %and4(i1)
    ; CHECK-NEXT: [[AND4:%[0-9]+]]:_(i32) = G_AND [[SEXT4]], [[C10]]
    ; CHECK-NEXT: [[SEXT5:%[0-9]+]]:_(i32) = G_SEXT %and5(i1)
    ; CHECK-NEXT: [[AND5:%[0-9]+]]:_(i32) = G_AND [[SEXT5]], [[C10]]
    ; CHECK-NEXT: [[SHL3:%[0-9]+]]:_(i32) = G_SHL [[AND5]], [[C7]](i32)
    ; CHECK-NEXT: [[OR2:%[0-9]+]]:_(i32) = G_OR [[AND4]], [[SHL3]]
    ; CHECK-NEXT: [[SEXT6:%[0-9]+]]:_(i32) = G_SEXT %and6(i1)
    ; CHECK-NEXT: [[AND6:%[0-9]+]]:_(i32) = G_AND [[SEXT6]], [[C10]]
    ; CHECK-NEXT: [[SHL4:%[0-9]+]]:_(i32) = G_SHL [[AND6]], [[C8]](i32)
    ; CHECK-NEXT: [[OR3:%[0-9]+]]:_(i32) = G_OR [[OR2]], [[SHL4]]
    ; CHECK-NEXT: [[SEXT7:%[0-9]+]]:_(i32) = G_SEXT %and7(i1)
    ; CHECK-NEXT: [[AND7:%[0-9]+]]:_(i32) = G_AND [[SEXT7]], [[C10]]
    ; CHECK-NEXT: [[SHL5:%[0-9]+]]:_(i32) = G_SHL [[AND7]], [[C9]](i32)
    ; CHECK-NEXT: %merge1:_(i32) = G_OR [[OR3]], [[SHL5]]
    ; CHECK-NEXT: %bv:_(<2 x i32>) = G_BUILD_VECTOR %merge0(i32), %merge1(i32)
    ; CHECK-NEXT: %null:_(p1) = G_CONSTANT i64 0
    ; CHECK-NEXT: G_STORE %bv(<2 x i32>), %null(p1) :: (store (<2 x i32>), addrspace 1)
    ; CHECK-NEXT: S_ENDPGM 0
    %undef:_(p4) = G_IMPLICIT_DEF
    %load:_(i32) = G_LOAD %undef(p4) :: (dereferenceable invariant load (i8), align 16, addrspace 4)
    %trunc:_(i8) = G_TRUNC %load(i32)
    %unmerge3_0:_(i1), %unmerge3_1:_(i1), %unmerge3_2:_(i1), %unmerge3_3:_(i1), %unmerge3_4:_(i1), %unmerge3_5:_(i1), %unmerge3_6:_(i1), %unmerge3_7:_(i1) = G_UNMERGE_VALUES %trunc(i8)
    %negone:_(i1) = G_CONSTANT i1 true
    %and0:_(i1) = G_XOR %unmerge3_0, %negone
    %and1:_(i1) = G_XOR %unmerge3_1, %negone
    %and2:_(i1) = G_XOR %unmerge3_2, %negone
    %and3:_(i1) = G_XOR %unmerge3_3, %negone
    %and4:_(i1) = G_XOR %unmerge3_4, %negone
    %and5:_(i1) = G_XOR %unmerge3_5, %negone
    %and6:_(i1) = G_XOR %unmerge3_6, %negone
    %and7:_(i1) = G_XOR %unmerge3_7, %negone
    %boolvec:_(<8 x i1>) = G_BUILD_VECTOR %and0(i1), %and1(i1), %and2(i1), %and3(i1), %and4(i1), %and5(i1), %and6(i1), %and7(i1)
    %sext:_(<8 x i8>) = G_SEXT %boolvec(<8 x i1>)
    %sext_lo:_(<4 x i8>), %sext_hi:_(<4 x i8>) = G_UNMERGE_VALUES %sext(<8 x i8>)
    %sext0:_(i8), %sext1:_(i8), %sext2:_(i8), %sext3:_(i8) = G_UNMERGE_VALUES %sext_lo(<4 x i8>)
    %merge0:_(i32) = G_MERGE_VALUES %sext0(i8), %sext1(i8), %sext2(i8), %sext3(i8)
    %sext4:_(i8) = G_SEXT %and4(i1)
    %sext5:_(i8) = G_SEXT %and5(i1)
    %sext6:_(i8) = G_SEXT %and6(i1)
    %sext7:_(i8) = G_SEXT %and7(i1)
    %merge1:_(i32) = G_MERGE_VALUES %sext4(i8), %sext5(i8), %sext6(i8), %sext7(i8)
    %bv:_(<2 x i32>) = G_BUILD_VECTOR %merge0(i32), %merge1(i32)
    %null:_(p1) = G_CONSTANT i64 0
    G_STORE %bv(<2 x i32>), %null(p1) :: (store (<2 x i32>), addrspace 1)
    S_ENDPGM 0

...
