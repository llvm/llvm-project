# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -O0 -mtriple=amdgcn-mesa-mesa3d -mcpu=tahiti -run-pass=legalizer -o - %s  | FileCheck %s

---
name: test_unmerge_values_s1_trunc_v2s1_of_build_vector_v2s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s1_trunc_v2s1_of_build_vector_v2s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV]](i32), [[UV2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV1]](i32), [[UV3]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i32) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[SEXT_INREG:%[0-9]+]]:_(i32) = G_SEXT_INREG [[ANYEXT]], 1
    ; CHECK-NEXT: [[SEXT_INREG1:%[0-9]+]]:_(i32) = G_SEXT_INREG [[ANYEXT1]], 1
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[SEXT_INREG]](i32), [[SEXT_INREG1]](i32)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[BUILD_VECTOR]](<2 x i32>)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %2:_(i32), %3:_(i32) = G_UNMERGE_VALUES %0(<2 x i32>)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %1(<2 x i32>)
    %6:_(i1) = G_ICMP intpred(ne), %2(i32), %4
    %7:_(i1) = G_ICMP intpred(ne), %3(i32), %5
    %8:_(i32) = G_ANYEXT %6(i1)
    %9:_(i32) = G_ANYEXT %7(i1)
    %10:_(<2 x i32>) = G_BUILD_VECTOR %8(i32), %9(i32)
    %11:_(<2 x i1>) = G_TRUNC %10(<2 x i32>)
    %12:_(i1), %13:_(i1) = G_UNMERGE_VALUES %11(<2 x i1>)
    %14:_(i32) = G_SEXT %12(i1)
    %15:_(i32) = G_SEXT %13(i1)
    %16:_(<2 x i32>) = G_BUILD_VECTOR %14(i32), %15(i32)
    $vgpr0_vgpr1 = COPY %16(<2 x i32>)

...

# Requires looking thorugh extra copies between the build_vector,
# trunc and unmerge.
---
name: test_unmerge_values_s1_trunc_v2s1_of_build_vector_v2s32_extra_copies
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s1_trunc_v2s1_of_build_vector_v2s32_extra_copies
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV]](i32), [[UV2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV1]](i32), [[UV3]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i32) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[SEXT_INREG:%[0-9]+]]:_(i32) = G_SEXT_INREG [[ANYEXT]], 1
    ; CHECK-NEXT: [[SEXT_INREG1:%[0-9]+]]:_(i32) = G_SEXT_INREG [[ANYEXT1]], 1
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[SEXT_INREG]](i32), [[SEXT_INREG1]](i32)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[BUILD_VECTOR]](<2 x i32>)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %2:_(i32), %3:_(i32) = G_UNMERGE_VALUES %0(<2 x i32>)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %1(<2 x i32>)
    %6:_(i1) = G_ICMP intpred(ne), %2(i32), %4
    %7:_(i1) = G_ICMP intpred(ne), %3(i32), %5
    %8:_(i32) = G_ANYEXT %6(i1)
    %9:_(i32) = G_ANYEXT %7(i1)
    %10:_(<2 x i32>) = G_BUILD_VECTOR %8(i32), %9(i32)
    %11:_(<2 x i32>) = COPY %10(<2 x i32>)
    %12:_(<2 x i1>) = G_TRUNC %11(<2 x i32>)
    %13:_(<2 x i1>) = COPY %12(<2 x i1>)
    %14:_(i1), %15:_(i1) = G_UNMERGE_VALUES %13(<2 x i1>)
    %16:_(i32) = G_SEXT %14(i1)
    %17:_(i32) = G_SEXT %15(i1)
    %18:_(<2 x i32>) = G_BUILD_VECTOR %16(i32), %17(i32)
    $vgpr0_vgpr1 = COPY %18(<2 x i32>)

...

---
name: test_unmerge_values_s32_sext_v2s32_of_build_vector_v2s16
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s32_sext_v2s32_of_build_vector_v2s16
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV]](i32), [[UV2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV1]](i32), [[UV3]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i16) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i16) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[SEXT:%[0-9]+]]:_(i32) = G_SEXT [[ANYEXT]](i16)
    ; CHECK-NEXT: [[SEXT1:%[0-9]+]]:_(i32) = G_SEXT [[ANYEXT1]](i16)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[SEXT]](i32), [[SEXT1]](i32)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[BUILD_VECTOR]](<2 x i32>)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %2:_(i32), %3:_(i32) = G_UNMERGE_VALUES %0(<2 x i32>)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %1(<2 x i32>)
    %6:_(i1) = G_ICMP intpred(ne), %2(i32), %4
    %7:_(i1) = G_ICMP intpred(ne), %3(i32), %5
    %8:_(i16) = G_ANYEXT %6(i1)
    %9:_(i16) = G_ANYEXT %7(i1)
    %10:_(<2 x i16>) = G_BUILD_VECTOR %8(i16), %9(i16)
    %11:_(<2 x i32>) = G_SEXT %10(<2 x i16>)
    %12:_(i32), %13:_(i32) = G_UNMERGE_VALUES %11(<2 x i32>)
    %14:_(<2 x i32>) = G_BUILD_VECTOR %12(i32), %13(i32)
    $vgpr0_vgpr1 = COPY %14(<2 x i32>)

...

---
name: test_unmerge_values_s32_zext_v2s32_of_build_vector_v2s16
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s32_zext_v2s32_of_build_vector_v2s16
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV]](i32), [[UV2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV1]](i32), [[UV3]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i16) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i16) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(i32) = G_ZEXT [[ANYEXT]](i16)
    ; CHECK-NEXT: [[ZEXT1:%[0-9]+]]:_(i32) = G_ZEXT [[ANYEXT1]](i16)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[ZEXT]](i32), [[ZEXT1]](i32)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[BUILD_VECTOR]](<2 x i32>)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %2:_(i32), %3:_(i32) = G_UNMERGE_VALUES %0(<2 x i32>)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %1(<2 x i32>)
    %6:_(i1) = G_ICMP intpred(ne), %2(i32), %4
    %7:_(i1) = G_ICMP intpred(ne), %3(i32), %5
    %8:_(i16) = G_ANYEXT %6(i1)
    %9:_(i16) = G_ANYEXT %7(i1)
    %10:_(<2 x i16>) = G_BUILD_VECTOR %8(i16), %9(i16)
    %11:_(<2 x i32>) = G_ZEXT %10(<2 x i16>)
    %12:_(i32), %13:_(i32) = G_UNMERGE_VALUES %11(<2 x i32>)
    %14:_(<2 x i32>) = G_BUILD_VECTOR %12(i32), %13(i32)
    $vgpr0_vgpr1 = COPY %14(<2 x i32>)

...

---
name: test_unmerge_values_s32_anyext_v2s32_of_build_vector_v2s16
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s32_anyext_v2s32_of_build_vector_v2s16
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV]](i32), [[UV2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV1]](i32), [[UV3]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i32) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[ANYEXT]](i32), [[ANYEXT1]](i32)
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[BUILD_VECTOR]](<2 x i32>)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %2:_(i32), %3:_(i32) = G_UNMERGE_VALUES %0(<2 x i32>)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %1(<2 x i32>)
    %6:_(i1) = G_ICMP intpred(ne), %2(i32), %4
    %7:_(i1) = G_ICMP intpred(ne), %3(i32), %5
    %8:_(i16) = G_ANYEXT %6(i1)
    %9:_(i16) = G_ANYEXT %7(i1)
    %10:_(<2 x i16>) = G_BUILD_VECTOR %8(i16), %9(i16)
    %11:_(<2 x i32>) = G_ANYEXT %10(<2 x i16>)
    %12:_(i32), %13:_(i32) = G_UNMERGE_VALUES %11(<2 x i32>)
    %14:_(<2 x i32>) = G_BUILD_VECTOR %12(i32), %13(i32)
    $vgpr0_vgpr1 = COPY %14(<2 x i32>)

...

---
name: test_unmerge_values_v2s16_zext_v4s32_of_build_vector_v4s16

body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_v2s16_zext_v4s32_of_build_vector_v4s16
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV]](i32), [[UV2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(ne), [[UV1]](i32), [[UV3]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i16) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i16) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(i32) = G_ZEXT [[ANYEXT]](i16)
    ; CHECK-NEXT: [[ZEXT1:%[0-9]+]]:_(i32) = G_ZEXT [[ANYEXT1]](i16)
    ; CHECK-NEXT: [[ZEXT2:%[0-9]+]]:_(i32) = G_ZEXT [[ANYEXT]](i16)
    ; CHECK-NEXT: [[ZEXT3:%[0-9]+]]:_(i32) = G_ZEXT [[ANYEXT1]](i16)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[ZEXT]](i32), [[ZEXT1]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[ZEXT2]](i32), [[ZEXT3]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BUILD_VECTOR]](<2 x i32>), implicit [[BUILD_VECTOR1]](<2 x i32>)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %2:_(i32), %3:_(i32) = G_UNMERGE_VALUES %0(<2 x i32>)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %1(<2 x i32>)
    %6:_(i1) = G_ICMP intpred(ne), %2(i32), %4
    %7:_(i1) = G_ICMP intpred(ne), %3(i32), %5
    %8:_(i16) = G_ANYEXT %6(i1)
    %9:_(i16) = G_ANYEXT %7(i1)
    %10:_(<4 x i16>) = G_BUILD_VECTOR %8(i16), %9(i16), %8(i16), %9(i16)
    %11:_(<4 x i32>) = G_ZEXT %10(<4 x i16>)
    %12:_(<2 x i32>), %13:_(<2 x i32>) = G_UNMERGE_VALUES %11(<4 x i32>)
    S_ENDPGM 0, implicit %12(<2 x i32>), implicit %13(<2 x i32>)

...

---
name: test_unmerge_values_s1_trunc_v4s1_of_concat_vectors_v4s32_v2s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s1_trunc_v4s1_of_concat_vectors_v4s32_v2s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[SEXT_INREG:%[0-9]+]]:_(i32) = G_SEXT_INREG [[UV]], 1
    ; CHECK-NEXT: [[SEXT_INREG1:%[0-9]+]]:_(i32) = G_SEXT_INREG [[UV1]], 1
    ; CHECK-NEXT: [[SEXT_INREG2:%[0-9]+]]:_(i32) = G_SEXT_INREG [[UV2]], 1
    ; CHECK-NEXT: [[SEXT_INREG3:%[0-9]+]]:_(i32) = G_SEXT_INREG [[UV3]], 1
    ; CHECK-NEXT: $vgpr0 = COPY [[SEXT_INREG]](i32)
    ; CHECK-NEXT: $vgpr1 = COPY [[SEXT_INREG1]](i32)
    ; CHECK-NEXT: $vgpr2 = COPY [[SEXT_INREG2]](i32)
    ; CHECK-NEXT: $vgpr3 = COPY [[SEXT_INREG3]](i32)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr2_vgpr3
    %2:_(<4 x i32>) = G_CONCAT_VECTORS %0(<2 x i32>), %1(<2 x i32>)
    %3:_(<4 x i1>) = G_TRUNC %2(<4 x i32>)
    %4:_(i1), %5:_(i1), %6:_(i1), %7:_(i1) = G_UNMERGE_VALUES %3(<4 x i1>)
    %8:_(i32) = G_SEXT %4(i1)
    %9:_(i32) = G_SEXT %5(i1)
    %10:_(i32) = G_SEXT %6(i1)
    %11:_(i32) = G_SEXT %7(i1)
    $vgpr0 = COPY %8(i32)
    $vgpr1 = COPY %9(i32)
    $vgpr2 = COPY %10(i32)
    $vgpr3 = COPY %11(i32)
...

---
name: test_unmerge_values_s16_of_concat_vectors_v2s16_v2s16
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s16_of_concat_vectors_v2s16_v2s16
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[COPY]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[COPY1]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST1]](i32)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST1]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR1]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i16), implicit [[TRUNC1]](i16), implicit [[TRUNC2]](i16), implicit [[TRUNC3]](i16)
    %0:_(<2 x i16>) = COPY $vgpr0
    %1:_(<2 x i16>) = COPY $vgpr1
    %2:_(<4 x i16>) = G_CONCAT_VECTORS %0(<2 x i16>), %1(<2 x i16>)
    %3:_(i16), %4:_(i16), %5:_(i16), %6:_(i16) = G_UNMERGE_VALUES %2(<4 x i16>)
    S_ENDPGM 0, implicit %3(i16), implicit %4(i16), implicit %5(i16), implicit %6(i16)
...

---
name: test_unmerge_values_s32_of_concat_vectors_v2s32_v2s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s32_of_concat_vectors_v2s32_v2s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr1_vgpr2
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[UV]](i32), implicit [[UV1]](i32), implicit [[UV2]](i32), implicit [[UV3]](i32)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr1_vgpr2
    %2:_(<4 x i32>) = G_CONCAT_VECTORS %0(<2 x i32>), %1(<2 x i32>)
    %3:_(i32), %4:_(i32), %5:_(i32), %6:_(i32) = G_UNMERGE_VALUES %2(<4 x i32>)
    S_ENDPGM 0, implicit %3(i32), implicit %4(i32), implicit %5(i32), implicit %6(i32)
...

---
name: test_unmerge_values_s32_of_concat_vectors_v2s64_v2s64
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s32_of_concat_vectors_v2s64_v2s64
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i64>) = COPY $vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i64>)
    ; CHECK-NEXT: [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32), [[UV6:%[0-9]+]]:_(i32), [[UV7:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i64>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[UV]](i32), implicit [[UV1]](i32), implicit [[UV2]](i32), implicit [[UV3]](i32), implicit [[UV4]](i32), implicit [[UV5]](i32), implicit [[UV6]](i32), implicit [[UV7]](i32)
    %0:_(<2 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(<2 x i64>) = COPY $vgpr4_vgpr5_vgpr6_vgpr7
    %2:_(<4 x i64>) = G_CONCAT_VECTORS %0(<2 x i64>), %1(<2 x i64>)
    %3:_(i32), %4:_(i32), %5:_(i32), %6:_(i32), %7:_(i32), %8:_(i32), %9:_(i32), %10:_(i32) = G_UNMERGE_VALUES %2(<4 x i64>)
    S_ENDPGM 0, implicit %3(i32), implicit %4(i32), implicit %5(i32), implicit %6(i32), implicit %7(i32), implicit %8(i32), implicit %9(i32), implicit %10(i32)
...

---
name: test_unmerge_values_s32_of_trunc_concat_vectors_v2s64_v2s64
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s32_of_trunc_concat_vectors_v2s64_v2s64
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i64>) = COPY $vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i64), [[UV1:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY]](<2 x i64>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i64), [[UV3:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY1]](<2 x i64>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i32) = G_TRUNC [[UV]](i64)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i32) = G_TRUNC [[UV1]](i64)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i32) = G_TRUNC [[UV2]](i64)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i32) = G_TRUNC [[UV3]](i64)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i32), implicit [[TRUNC1]](i32), implicit [[TRUNC2]](i32), implicit [[TRUNC3]](i32)
    %0:_(<2 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(<2 x i64>) = COPY $vgpr4_vgpr5_vgpr6_vgpr7
    %2:_(<4 x i64>) = G_CONCAT_VECTORS %0(<2 x i64>), %1(<2 x i64>)
    %3:_(<4 x i32>) = G_TRUNC %2(<4 x i64>)
    %4:_(i32), %5:_(i32), %6:_(i32), %7:_(i32) = G_UNMERGE_VALUES %3(<4 x i32>)
    S_ENDPGM 0, implicit %4(i32), implicit %5(i32), implicit %6(i32), implicit %7(i32)
...

---
name: test_unmerge_values_s64_of_sext_concat_vectors_v2s32_v2s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s64_of_sext_concat_vectors_v2s32_v2s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[SEXT:%[0-9]+]]:_(i64) = G_SEXT [[UV]](i32)
    ; CHECK-NEXT: [[SEXT1:%[0-9]+]]:_(i64) = G_SEXT [[UV1]](i32)
    ; CHECK-NEXT: [[SEXT2:%[0-9]+]]:_(i64) = G_SEXT [[UV2]](i32)
    ; CHECK-NEXT: [[SEXT3:%[0-9]+]]:_(i64) = G_SEXT [[UV3]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[SEXT]](i64), implicit [[SEXT1]](i64), implicit [[SEXT2]](i64), implicit [[SEXT3]](i64)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr2_vgpr3
    %2:_(<4 x i32>) = G_CONCAT_VECTORS %0(<2 x i32>), %1(<2 x i32>)
    %3:_(<4 x i64>) = G_SEXT %2(<4 x i32>)
    %4:_(i64), %5:_(i64), %6:_(i64), %7:_(i64) = G_UNMERGE_VALUES %3(<4 x i64>)
    S_ENDPGM 0, implicit %4(i64), implicit %5(i64), implicit %6(i64), implicit %7(i64)
...

---
name: test_unmerge_values_s64_of_zext_concat_vectors_v2s32_v2s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s64_of_zext_concat_vectors_v2s32_v2s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(i64) = G_ZEXT [[UV]](i32)
    ; CHECK-NEXT: [[ZEXT1:%[0-9]+]]:_(i64) = G_ZEXT [[UV1]](i32)
    ; CHECK-NEXT: [[ZEXT2:%[0-9]+]]:_(i64) = G_ZEXT [[UV2]](i32)
    ; CHECK-NEXT: [[ZEXT3:%[0-9]+]]:_(i64) = G_ZEXT [[UV3]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[ZEXT]](i64), implicit [[ZEXT1]](i64), implicit [[ZEXT2]](i64), implicit [[ZEXT3]](i64)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr2_vgpr3
    %2:_(<4 x i32>) = G_CONCAT_VECTORS %0(<2 x i32>), %1(<2 x i32>)
    %3:_(<4 x i64>) = G_ZEXT %2(<4 x i32>)
    %4:_(i64), %5:_(i64), %6:_(i64), %7:_(i64) = G_UNMERGE_VALUES %3(<4 x i64>)
    S_ENDPGM 0, implicit %4(i64), implicit %5(i64), implicit %6(i64), implicit %7(i64)
...

---
name: test_unmerge_values_s64_of_anyext_concat_vectors_v2s32_v2s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s64_of_anyext_concat_vectors_v2s32_v2s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i64) = G_ANYEXT [[UV]](i32)
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i64) = G_ANYEXT [[UV1]](i32)
    ; CHECK-NEXT: [[ANYEXT2:%[0-9]+]]:_(i64) = G_ANYEXT [[UV2]](i32)
    ; CHECK-NEXT: [[ANYEXT3:%[0-9]+]]:_(i64) = G_ANYEXT [[UV3]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[ANYEXT]](i64), implicit [[ANYEXT1]](i64), implicit [[ANYEXT2]](i64), implicit [[ANYEXT3]](i64)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr2_vgpr3
    %2:_(<4 x i32>) = G_CONCAT_VECTORS %0(<2 x i32>), %1(<2 x i32>)
    %3:_(<4 x i64>) = G_ANYEXT %2(<4 x i32>)
    %4:_(i64), %5:_(i64), %6:_(i64), %7:_(i64) = G_UNMERGE_VALUES %3(<4 x i64>)
    S_ENDPGM 0, implicit %4(i64), implicit %5(i64), implicit %6(i64), implicit %7(i64)
...

---
name: test_unmerge_values_s8_of_trunc_v4s16_concat_vectors_v2s32_v2s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s8_of_trunc_v4s16_concat_vectors_v2s32_v2s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[TRUNC]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i8) = G_TRUNC [[BITCAST]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 8
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i8) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C1]](i32)
    ; CHECK-NEXT: [[TRUNC4:%[0-9]+]]:_(i8) = G_TRUNC [[LSHR1]](i32)
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(i32) = G_CONSTANT i32 24
    ; CHECK-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C2]](i32)
    ; CHECK-NEXT: [[TRUNC5:%[0-9]+]]:_(i8) = G_TRUNC [[LSHR2]](i32)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[TRUNC1]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC6:%[0-9]+]]:_(i8) = G_TRUNC [[BITCAST1]](i32)
    ; CHECK-NEXT: [[LSHR3:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST1]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC7:%[0-9]+]]:_(i8) = G_TRUNC [[LSHR3]](i32)
    ; CHECK-NEXT: [[LSHR4:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST1]], [[C1]](i32)
    ; CHECK-NEXT: [[TRUNC8:%[0-9]+]]:_(i8) = G_TRUNC [[LSHR4]](i32)
    ; CHECK-NEXT: [[LSHR5:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST1]], [[C2]](i32)
    ; CHECK-NEXT: [[TRUNC9:%[0-9]+]]:_(i8) = G_TRUNC [[LSHR5]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC2]](i8), implicit [[TRUNC3]](i8), implicit [[TRUNC4]](i8), implicit [[TRUNC5]](i8), implicit [[TRUNC6]](i8), implicit [[TRUNC7]](i8), implicit [[TRUNC8]](i8), implicit [[TRUNC9]](i8)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr2_vgpr3
    %2:_(<4 x i32>) = G_CONCAT_VECTORS %0(<2 x i32>), %1(<2 x i32>)
    %3:_(<4 x i16>) = G_TRUNC %2(<4 x i32>)
    %4:_(i8), %5:_(i8), %6:_(i8), %7:_(i8), %8:_(i8), %9:_(i8), %10:_(i8), %11:_(i8) = G_UNMERGE_VALUES %3(<4 x i16>)
    S_ENDPGM 0, implicit %4(i8), implicit %5(i8), implicit %6(i8), implicit %7(i8), implicit %8(i8), implicit %9(i8), implicit %10(i8), implicit %11(i8)
...

---
name: test_unmerge_values_s16_of_anyext_v4s64_concat_vectors_v2s32_v2s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s16_of_anyext_v4s64_concat_vectors_v2s32_v2s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i64) = G_ANYEXT [[UV]](i32)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[ANYEXT]](i64)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[UV]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[UV]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[UV3]](i32)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[UV3]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR1]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i16), implicit [[TRUNC1]](i16), implicit [[TRUNC2]](i16), implicit [[TRUNC3]](i16)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr2_vgpr3
    %2:_(<4 x i32>) = G_CONCAT_VECTORS %0(<2 x i32>), %1(<2 x i32>)
    %3:_(<4 x i64>) = G_ANYEXT %2(<4 x i32>)
    %4:_(i16), %5:_(i16), %6:_(i16), %7:_(i16), %8:_(i16), %9:_(i16), %10:_(i16), %11:_(i16), %12:_(i16), %13:_(i16), %14:_(i16), %15:_(i16), %16:_(i16), %17:_(i16), %18:_(i16), %19:_(i16) = G_UNMERGE_VALUES %3(<4 x i64>)
    S_ENDPGM 0, implicit %4(i16), implicit %5(i16), implicit %6(i16), implicit %7(i16)
...

# FIXME: Handle this
---
name: test_unmerge_values_s32_of_concat_vectors_v4s32_v4s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s32_of_concat_vectors_v4s32_v4s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr4_vgpr5
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(<2 x i32>) = COPY $vgpr6_vgpr7
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[COPY]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[COPY1]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[COPY2]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[COPY3]](<2 x i32>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[TRUNC]](<2 x i16>)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[TRUNC1]](<2 x i16>)
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(i32) = G_BITCAST [[TRUNC2]](<2 x i16>)
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[TRUNC3]](<2 x i16>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BITCAST]](i32), implicit [[BITCAST1]](i32), implicit [[BITCAST2]](i32), implicit [[BITCAST3]](i32)
    %0:_(<2 x i32>) = COPY $vgpr0_vgpr1
    %1:_(<2 x i32>) = COPY $vgpr2_vgpr3
    %2:_(<2 x i32>) = COPY $vgpr4_vgpr5
    %3:_(<2 x i32>) = COPY $vgpr6_vgpr7
    %4:_(<8 x i32>) = G_CONCAT_VECTORS %0(<2 x i32>), %1(<2 x i32>), %2(<2 x i32>), %3(<2 x i32>)
    %5:_(<8 x i16>) = G_TRUNC %4(<8 x i32>)
    %6:_(i32), %7:_(i32), %8:_(i32), %9:_(i32) = G_UNMERGE_VALUES %5(<8 x i16>)
    S_ENDPGM 0, implicit %6(i32), implicit %7(i32), implicit %8(i32), implicit %9(i32)
...

---
name: test_unmerge_values_s64_of_build_vector_v4s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s64_of_build_vector_v4s32
    ; CHECK: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY2]](i32), [[COPY3]](i32)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR1]](<2 x i32>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[TRUNC]](<2 x i16>)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[TRUNC1]](<2 x i16>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BITCAST]](i32), implicit [[BITCAST1]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(<4 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32), %3(i32)
    %5:_(<4 x i16>) = G_TRUNC %4(<4 x i32>)
    %6:_(i32), %7:_(i32) = G_UNMERGE_VALUES %5(<4 x i16>)
    S_ENDPGM 0, implicit %6(i32), implicit %7(i32)
...

# To properly simplify that one, we would need to insert bitcast
# after the G_ZEXT.
# i.e.,
# s64 = zext <2 x s16> <-- invalid
# vs.
# <2 x s32> = zext <2 x s16>
# s64 = bitcast <2 x s32> <-- we are missing the code to do that
---
name: test_unmerge_values_s128_of_zext_of_concat_vectors
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s128_of_zext_of_concat_vectors
    ; CHECK: [[COPY:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<2 x i16>) = COPY $vgpr1
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[COPY]](<2 x i16>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[COPY1]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST1]], [[C]](i32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[BITCAST]], [[C1]]
    ; CHECK-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[BITCAST1]], [[C1]]
    ; CHECK-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[AND]](i32), [[LSHR]](i32)
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[AND1]](i32), [[LSHR1]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[MV]](i64), implicit [[MV1]](i64)
    %0:_(<2 x i16>) = COPY $vgpr0
    %1:_(<2 x i16>) = COPY $vgpr1
    %2:_(<4 x i16>) = G_CONCAT_VECTORS %0(<2 x i16>), %1(<2 x i16>)
    %3:_(<4 x i32>) = G_ZEXT %2(<4 x i16>)
    %4:_(i64), %5:_(i64) = G_UNMERGE_VALUES %3(<4 x i32>)
    S_ENDPGM 0, implicit %4(i64), implicit %5(i64)
...

---

name: test_unmerge_values_v3s32_of_v12s32_concat_vectors_v4s32
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_v3s32_of_v12s32_concat_vectors_v4s32
    ; CHECK: [[COPY:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr8_vgpr9_vgpr10_vgpr11
    ; CHECK-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<12 x i32>) = G_CONCAT_VECTORS [[COPY]](<4 x i32>), [[COPY1]](<4 x i32>), [[COPY2]](<4 x i32>)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<3 x i32>), [[UV1:%[0-9]+]]:_(<3 x i32>), [[UV2:%[0-9]+]]:_(<3 x i32>), [[UV3:%[0-9]+]]:_(<3 x i32>) = G_UNMERGE_VALUES [[CONCAT_VECTORS]](<12 x i32>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[UV]](<3 x i32>), implicit [[UV1]](<3 x i32>), implicit [[UV2]](<3 x i32>), implicit [[UV3]](<3 x i32>)
    %0:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(<4 x i32>) = COPY $vgpr4_vgpr5_vgpr6_vgpr7
    %2:_(<4 x i32>) = COPY $vgpr8_vgpr9_vgpr10_vgpr11
    %3:_(<12 x i32>) = G_CONCAT_VECTORS %0(<4 x i32>), %1(<4 x i32>), %2(<4 x i32>)
    %4:_(<3 x i32>), %5:_(<3 x i32>), %6:_(<3 x i32>), %7:_(<3 x i32>) = G_UNMERGE_VALUES %3(<12 x i32>)
    S_ENDPGM 0, implicit %4(<3 x i32>), implicit %5(<3 x i32>), implicit %6(<3 x i32>), implicit %7(<3 x i32>)
...

---
name: test_unmerge_values_v3s16_of_v12s16_concat_vectors_v4s16
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_v3s16_of_v12s16_concat_vectors_v4s16
    ; CHECK: [[COPY:%[0-9]+]]:_(<4 x i16>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(<4 x i16>) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(<4 x i16>) = COPY $vgpr4_vgpr5
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY]](<4 x i16>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[UV]](<2 x i16>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[UV1]](<2 x i16>)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[BITCAST]](i32), [[LSHR]](i32), [[BITCAST1]](i32)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(<2 x i16>), [[UV3:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY]](<4 x i16>)
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(i32) = G_BITCAST [[UV3]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST2]], [[C]](i32)
    ; CHECK-NEXT: [[UV4:%[0-9]+]]:_(<2 x i16>), [[UV5:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY1]](<4 x i16>)
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[UV4]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST3]], [[C]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[LSHR1]](i32), [[BITCAST3]](i32), [[LSHR2]](i32)
    ; CHECK-NEXT: [[UV6:%[0-9]+]]:_(<2 x i16>), [[UV7:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY1]](<4 x i16>)
    ; CHECK-NEXT: [[BITCAST4:%[0-9]+]]:_(i32) = G_BITCAST [[UV7]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR3:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST4]], [[C]](i32)
    ; CHECK-NEXT: [[UV8:%[0-9]+]]:_(<2 x i16>), [[UV9:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY2]](<4 x i16>)
    ; CHECK-NEXT: [[BITCAST5:%[0-9]+]]:_(i32) = G_BITCAST [[UV8]](<2 x i16>)
    ; CHECK-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[BITCAST4]](i32), [[LSHR3]](i32), [[BITCAST5]](i32)
    ; CHECK-NEXT: [[UV10:%[0-9]+]]:_(<2 x i16>), [[UV11:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY2]](<4 x i16>)
    ; CHECK-NEXT: [[BITCAST6:%[0-9]+]]:_(i32) = G_BITCAST [[UV10]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR4:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST6]], [[C]](i32)
    ; CHECK-NEXT: [[BITCAST7:%[0-9]+]]:_(i32) = G_BITCAST [[UV11]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR5:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST7]], [[C]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR3:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[LSHR4]](i32), [[BITCAST7]](i32), [[LSHR5]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BUILD_VECTOR]](<3 x i32>), implicit [[BUILD_VECTOR1]](<3 x i32>), implicit [[BUILD_VECTOR2]](<3 x i32>), implicit [[BUILD_VECTOR3]](<3 x i32>)
    %0:_(<4 x i16>) = COPY $vgpr0_vgpr1
    %1:_(<4 x i16>) = COPY $vgpr2_vgpr3
    %2:_(<4 x i16>) = COPY $vgpr4_vgpr5
    %3:_(<12 x i16>) = G_CONCAT_VECTORS %0(<4 x i16>), %1(<4 x i16>), %2(<4 x i16>)
    %4:_(<3 x i16>), %5:_(<3 x i16>), %6:_(<3 x i16>), %7:_(<3 x i16>) = G_UNMERGE_VALUES %3(<12 x i16>)
    %8:_(<3 x i32>) = G_ANYEXT %4(<3 x i16>)
    %9:_(<3 x i32>) = G_ANYEXT %5(<3 x i16>)
    %10:_(<3 x i32>) = G_ANYEXT %6(<3 x i16>)
    %11:_(<3 x i32>) = G_ANYEXT %7(<3 x i16>)
    S_ENDPGM 0, implicit %8(<3 x i32>), implicit %9(<3 x i32>), implicit %10(<3 x i32>), implicit %11(<3 x i32>)
...

---
name:            unmerge_v2s16_from_v4s16_sext_v4s8_concat_vectors_v2s8
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; CHECK-LABEL: name: unmerge_v2s16_from_v4s16_sext_v4s8_concat_vectors_v2s8
    ; CHECK: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[SEXT_INREG:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY]], 8
    ; CHECK-NEXT: [[SEXT_INREG1:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY1]], 8
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG]], [[C]]
    ; CHECK-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG1]], [[C]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; CHECK-NEXT: [[SEXT_INREG2:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY2]], 8
    ; CHECK-NEXT: [[SEXT_INREG3:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY3]], 8
    ; CHECK-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG2]], [[C]]
    ; CHECK-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG3]], [[C]]
    ; CHECK-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BITCAST]](<2 x i16>), implicit [[BITCAST1]](<2 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i8) = G_TRUNC %0(i32)
    %5:_(i8) = G_TRUNC %1(i32)
    %6:_(i8) = G_TRUNC %2(i32)
    %7:_(i8) = G_TRUNC %3(i32)
    %8:_(<2 x i8>) = G_BUILD_VECTOR %4(i8), %5(i8)
    %9:_(<2 x i8>) = G_BUILD_VECTOR %6(i8), %7(i8)
    %10:_(<4 x i8>) = G_CONCAT_VECTORS %8(<2 x i8>), %9(<2 x i8>)
    %11:_(<4 x i16>) = G_SEXT %10(<4 x i8>)
    %12:_(<2 x i16>), %13:_(<2 x i16>) = G_UNMERGE_VALUES %11(<4 x i16>)
    S_ENDPGM 0, implicit %12(<2 x i16>), implicit %13(<2 x i16>)
...

---
name:            unmerge_v2s16_from_v8s16_sext_v8s8_concat_vectors_v4s8
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7

    ; CHECK-LABEL: name: unmerge_v2s16_from_v8s16_sext_v8s8_concat_vectors_v4s8
    ; CHECK: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; CHECK-NEXT: [[SEXT_INREG:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY]], 8
    ; CHECK-NEXT: [[SEXT_INREG1:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY1]], 8
    ; CHECK-NEXT: [[SEXT_INREG2:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY2]], 8
    ; CHECK-NEXT: [[SEXT_INREG3:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY3]], 8
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG]], [[C]]
    ; CHECK-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG1]], [[C]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; CHECK-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG2]], [[C]]
    ; CHECK-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG3]], [[C]]
    ; CHECK-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; CHECK-NEXT: [[SEXT_INREG4:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY4]], 8
    ; CHECK-NEXT: [[SEXT_INREG5:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY5]], 8
    ; CHECK-NEXT: [[SEXT_INREG6:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY6]], 8
    ; CHECK-NEXT: [[SEXT_INREG7:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY7]], 8
    ; CHECK-NEXT: [[AND4:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG4]], [[C]]
    ; CHECK-NEXT: [[AND5:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG5]], [[C]]
    ; CHECK-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[AND5]], [[C1]](i32)
    ; CHECK-NEXT: [[OR2:%[0-9]+]]:_(i32) = G_OR [[AND4]], [[SHL2]]
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR2]](i32)
    ; CHECK-NEXT: [[AND6:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG6]], [[C]]
    ; CHECK-NEXT: [[AND7:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG7]], [[C]]
    ; CHECK-NEXT: [[SHL3:%[0-9]+]]:_(i32) = G_SHL [[AND7]], [[C1]](i32)
    ; CHECK-NEXT: [[OR3:%[0-9]+]]:_(i32) = G_OR [[AND6]], [[SHL3]]
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR3]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BITCAST]](<2 x i16>), implicit [[BITCAST1]](<2 x i16>), implicit [[BITCAST2]](<2 x i16>), implicit [[BITCAST3]](<2 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i32) = COPY $vgpr5
    %6:_(i32) = COPY $vgpr6
    %7:_(i32) = COPY $vgpr7
    %8:_(i8) = G_TRUNC %0(i32)
    %9:_(i8) = G_TRUNC %1(i32)
    %10:_(i8) = G_TRUNC %2(i32)
    %11:_(i8) = G_TRUNC %3(i32)
    %12:_(i8) = G_TRUNC %4(i32)
    %13:_(i8) = G_TRUNC %5(i32)
    %14:_(i8) = G_TRUNC %6(i32)
    %15:_(i8) = G_TRUNC %7(i32)
    %16:_(<4 x i8>) = G_BUILD_VECTOR %8(i8), %9(i8), %10(i8), %11(i8)
    %17:_(<4 x i8>) = G_BUILD_VECTOR %12(i8), %13(i8), %14(i8), %15(i8)
    %18:_(<8 x i8>) = G_CONCAT_VECTORS %16(<4 x i8>), %17(<4 x i8>)
    %19:_(<8 x i16>) = G_SEXT %18(<8 x i8>)
    %20:_(<2 x i16>), %21:_(<2 x i16>), %22:_(<2 x i16>), %23:_(<2 x i16>) = G_UNMERGE_VALUES %19(<8 x i16>)
    S_ENDPGM 0, implicit %20(<2 x i16>), implicit %21(<2 x i16>), implicit %22(<2 x i16>), implicit %23(<2 x i16>)
...

---
name:            unmerge_v2s16_from_v16s16_sext_v16s8_concat_vectors_v8s8
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15

    ; CHECK-LABEL: name: unmerge_v2s16_from_v16s16_sext_v16s8_concat_vectors_v8s8
    ; CHECK: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11, $vgpr12, $vgpr13, $vgpr14, $vgpr15
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; CHECK-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; CHECK-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; CHECK-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; CHECK-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; CHECK-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; CHECK-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; CHECK-NEXT: [[COPY12:%[0-9]+]]:_(i32) = COPY $vgpr12
    ; CHECK-NEXT: [[COPY13:%[0-9]+]]:_(i32) = COPY $vgpr13
    ; CHECK-NEXT: [[COPY14:%[0-9]+]]:_(i32) = COPY $vgpr14
    ; CHECK-NEXT: [[COPY15:%[0-9]+]]:_(i32) = COPY $vgpr15
    ; CHECK-NEXT: [[SEXT_INREG:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY]], 8
    ; CHECK-NEXT: [[SEXT_INREG1:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY1]], 8
    ; CHECK-NEXT: [[SEXT_INREG2:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY2]], 8
    ; CHECK-NEXT: [[SEXT_INREG3:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY3]], 8
    ; CHECK-NEXT: [[SEXT_INREG4:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY4]], 8
    ; CHECK-NEXT: [[SEXT_INREG5:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY5]], 8
    ; CHECK-NEXT: [[SEXT_INREG6:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY6]], 8
    ; CHECK-NEXT: [[SEXT_INREG7:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY7]], 8
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG]], [[C]]
    ; CHECK-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG1]], [[C]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; CHECK-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG2]], [[C]]
    ; CHECK-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG3]], [[C]]
    ; CHECK-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; CHECK-NEXT: [[AND4:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG4]], [[C]]
    ; CHECK-NEXT: [[AND5:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG5]], [[C]]
    ; CHECK-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[AND5]], [[C1]](i32)
    ; CHECK-NEXT: [[OR2:%[0-9]+]]:_(i32) = G_OR [[AND4]], [[SHL2]]
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR2]](i32)
    ; CHECK-NEXT: [[AND6:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG6]], [[C]]
    ; CHECK-NEXT: [[AND7:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG7]], [[C]]
    ; CHECK-NEXT: [[SHL3:%[0-9]+]]:_(i32) = G_SHL [[AND7]], [[C1]](i32)
    ; CHECK-NEXT: [[OR3:%[0-9]+]]:_(i32) = G_OR [[AND6]], [[SHL3]]
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR3]](i32)
    ; CHECK-NEXT: [[SEXT_INREG8:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY8]], 8
    ; CHECK-NEXT: [[SEXT_INREG9:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY9]], 8
    ; CHECK-NEXT: [[SEXT_INREG10:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY10]], 8
    ; CHECK-NEXT: [[SEXT_INREG11:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY11]], 8
    ; CHECK-NEXT: [[SEXT_INREG12:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY12]], 8
    ; CHECK-NEXT: [[SEXT_INREG13:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY13]], 8
    ; CHECK-NEXT: [[SEXT_INREG14:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY14]], 8
    ; CHECK-NEXT: [[SEXT_INREG15:%[0-9]+]]:_(i32) = G_SEXT_INREG [[COPY15]], 8
    ; CHECK-NEXT: [[AND8:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG8]], [[C]]
    ; CHECK-NEXT: [[AND9:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG9]], [[C]]
    ; CHECK-NEXT: [[SHL4:%[0-9]+]]:_(i32) = G_SHL [[AND9]], [[C1]](i32)
    ; CHECK-NEXT: [[OR4:%[0-9]+]]:_(i32) = G_OR [[AND8]], [[SHL4]]
    ; CHECK-NEXT: [[BITCAST4:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR4]](i32)
    ; CHECK-NEXT: [[AND10:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG10]], [[C]]
    ; CHECK-NEXT: [[AND11:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG11]], [[C]]
    ; CHECK-NEXT: [[SHL5:%[0-9]+]]:_(i32) = G_SHL [[AND11]], [[C1]](i32)
    ; CHECK-NEXT: [[OR5:%[0-9]+]]:_(i32) = G_OR [[AND10]], [[SHL5]]
    ; CHECK-NEXT: [[BITCAST5:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR5]](i32)
    ; CHECK-NEXT: [[AND12:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG12]], [[C]]
    ; CHECK-NEXT: [[AND13:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG13]], [[C]]
    ; CHECK-NEXT: [[SHL6:%[0-9]+]]:_(i32) = G_SHL [[AND13]], [[C1]](i32)
    ; CHECK-NEXT: [[OR6:%[0-9]+]]:_(i32) = G_OR [[AND12]], [[SHL6]]
    ; CHECK-NEXT: [[BITCAST6:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR6]](i32)
    ; CHECK-NEXT: [[AND14:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG14]], [[C]]
    ; CHECK-NEXT: [[AND15:%[0-9]+]]:_(i32) = G_AND [[SEXT_INREG15]], [[C]]
    ; CHECK-NEXT: [[SHL7:%[0-9]+]]:_(i32) = G_SHL [[AND15]], [[C1]](i32)
    ; CHECK-NEXT: [[OR7:%[0-9]+]]:_(i32) = G_OR [[AND14]], [[SHL7]]
    ; CHECK-NEXT: [[BITCAST7:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR7]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BITCAST]](<2 x i16>), implicit [[BITCAST1]](<2 x i16>), implicit [[BITCAST2]](<2 x i16>), implicit [[BITCAST3]](<2 x i16>), implicit [[BITCAST4]](<2 x i16>), implicit [[BITCAST5]](<2 x i16>), implicit [[BITCAST6]](<2 x i16>), implicit [[BITCAST7]](<2 x i16>)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i32) = COPY $vgpr5
    %6:_(i32) = COPY $vgpr6
    %7:_(i32) = COPY $vgpr7
    %8:_(i32) = COPY $vgpr8
    %9:_(i32) = COPY $vgpr9
    %10:_(i32) = COPY $vgpr10
    %11:_(i32) = COPY $vgpr11
    %12:_(i32) = COPY $vgpr12
    %13:_(i32) = COPY $vgpr13
    %14:_(i32) = COPY $vgpr14
    %15:_(i32) = COPY $vgpr15
    %16:_(i8) = G_TRUNC %0(i32)
    %17:_(i8) = G_TRUNC %1(i32)
    %18:_(i8) = G_TRUNC %2(i32)
    %19:_(i8) = G_TRUNC %3(i32)
    %20:_(i8) = G_TRUNC %4(i32)
    %21:_(i8) = G_TRUNC %5(i32)
    %22:_(i8) = G_TRUNC %6(i32)
    %23:_(i8) = G_TRUNC %7(i32)
    %24:_(i8) = G_TRUNC %8(i32)
    %25:_(i8) = G_TRUNC %9(i32)
    %26:_(i8) = G_TRUNC %10(i32)
    %27:_(i8) = G_TRUNC %11(i32)
    %28:_(i8) = G_TRUNC %12(i32)
    %29:_(i8) = G_TRUNC %13(i32)
    %30:_(i8) = G_TRUNC %14(i32)
    %31:_(i8) = G_TRUNC %15(i32)
    %32:_(<8 x i8>) = G_BUILD_VECTOR %16(i8), %17(i8), %18(i8), %19(i8), %20(i8), %21(i8), %22(i8), %23(i8)
    %33:_(<8 x i8>) = G_BUILD_VECTOR %24(i8), %25(i8), %26(i8), %27(i8), %28(i8), %29(i8), %30(i8), %31(i8)
    %34:_(<16 x i8>) = G_CONCAT_VECTORS %32(<8 x i8>), %33(<8 x i8>)
    %35:_(<16 x i16>) = G_SEXT %34(<16 x i8>)
    %36:_(<2 x i16>), %37:_(<2 x i16>), %38:_(<2 x i16>), %39:_(<2 x i16>), %40:_(<2 x i16>), %41:_(<2 x i16>), %42:_(<2 x i16>), %43:_(<2 x i16>) = G_UNMERGE_VALUES %35(<16 x i16>)
    S_ENDPGM 0, implicit %36(<2 x i16>), implicit %37(<2 x i16>), implicit %38(<2 x i16>), implicit %39(<2 x i16>), implicit %40(<2 x i16>), implicit %41(<2 x i16>), implicit %42(<2 x i16>), implicit %43(<2 x i16>)
...

---
name: test_unmerge_values_s32_trunc_s96_of_merge_values_s192_s64
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $vgpr4_vgpr5
    ; CHECK-LABEL: name: test_unmerge_values_s32_trunc_s96_of_merge_values_s192_s64
    ; CHECK: liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $vgpr4_vgpr5
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i64) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](i64)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[UV]](i32), implicit [[UV1]](i32), implicit [[UV2]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i64) = COPY $vgpr2_vgpr3
    %2:_(i64) = COPY $vgpr4_vgpr5
    %3:_(i192) = G_MERGE_VALUES %0(i64), %1(i64), %2(i64)
    %4:_(i96) = G_TRUNC %3(i192)
    %5:_(i32), %6:_(i32), %7:_(i32) = G_UNMERGE_VALUES %4(i96)
    S_ENDPGM 0, implicit %5(i32), implicit %6(i32), implicit %7(i32)

...

---
name: test_unmerge_values_s16_trunc_s96_of_merge_values_s192_s64
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $vgpr4_vgpr5
    ; CHECK-LABEL: name: test_unmerge_values_s16_trunc_s96_of_merge_values_s192_s64
    ; CHECK: liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $vgpr4_vgpr5
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i64) = COPY $vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[UV]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[UV]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[UV1]](i32)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[UV1]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR1]](i32)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY1]](i64)
    ; CHECK-NEXT: [[TRUNC4:%[0-9]+]]:_(i16) = G_TRUNC [[UV2]](i32)
    ; CHECK-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR [[UV2]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC5:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR2]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i16), implicit [[TRUNC1]](i16), implicit [[TRUNC2]](i16), implicit [[TRUNC3]](i16), implicit [[TRUNC4]](i16), implicit [[TRUNC5]](i16)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i64) = COPY $vgpr2_vgpr3
    %2:_(i64) = COPY $vgpr4_vgpr5
    %3:_(i192) = G_MERGE_VALUES %0(i64), %1(i64), %2(i64)
    %4:_(i96) = G_TRUNC %3(i192)
    %5:_(i16), %6:_(i16), %7:_(i16), %8:_(i16), %9:_(i16), %10:_(i16) = G_UNMERGE_VALUES %4(i96)
    S_ENDPGM 0, implicit %5(i16), implicit %6(i16), implicit %7(i16), implicit %8(i16), implicit %9(i16), implicit %10(i16)

...

---
name: test_unmerge_values_s16_trunc_s96_of_merge_values_s192_s32
body:             |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; CHECK-LABEL: name: test_unmerge_values_s16_trunc_s96_of_merge_values_s192_s32
    ; CHECK: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; CHECK-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; CHECK-NEXT: [[MV:%[0-9]+]]:_(i192) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32), [[COPY3]](i32), [[COPY4]](i32), [[COPY5]](i32)
    ; CHECK-NEXT: [[MV1:%[0-9]+]]:_(i96) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32), [[COPY2]](i32)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[COPY]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[COPY1]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR1]](i32)
    ; CHECK-NEXT: [[TRUNC4:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; CHECK-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR [[COPY2]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC5:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR2]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[MV]](i192), implicit [[MV1]](i96), implicit [[TRUNC]](i16), implicit [[TRUNC1]](i16), implicit [[TRUNC2]](i16), implicit [[TRUNC3]](i16), implicit [[TRUNC4]](i16), implicit [[TRUNC5]](i16)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(i32) = COPY $vgpr5
    %6:_(i192) = G_MERGE_VALUES %0(i32), %1(i32), %2(i32), %3(i32), %4(i32), %5(i32)
    %7:_(i96) = G_TRUNC %6(i192)
    %8:_(i16), %9:_(i16), %10:_(i16), %11:_(i16), %12:_(i16), %13:_(i16) = G_UNMERGE_VALUES %7(i96)
    S_ENDPGM 0, implicit %6(i192), implicit %7(i96), implicit %8(i16), implicit %9(i16), implicit %10(i16), implicit %11(i16), implicit %12(i16), implicit %13(i16)

...

---
name: test_unmerge_values_s64_anyext_s128_of_merge_values_s64
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s64_anyext_s128_of_merge_values_s64
    ; CHECK: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[MV:%[0-9]+]]:_(i64) = G_MERGE_VALUES [[COPY]](i32), [[COPY1]](i32)
    ; CHECK-NEXT: [[DEF:%[0-9]+]]:_(i64) = G_IMPLICIT_DEF
    ; CHECK-NEXT: $vgpr0_vgpr1 = COPY [[MV]](i64)
    ; CHECK-NEXT: $vgpr2_vgpr3 = COPY [[DEF]](i64)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i64) = G_MERGE_VALUES %0(i32), %1(i32)
    %3:_(i128) = G_ANYEXT %2(i64)
    %4:_(i64), %5:_(i64) = G_UNMERGE_VALUES %3(i128)
    $vgpr0_vgpr1 = COPY %4(i64)
    $vgpr2_vgpr3 = COPY %5(i64)

...

---
name: test_unmerge_values_s32_trunc_s64_of_merge_values_s128
body:             |
  bb.0:
    ; CHECK-LABEL: name: test_unmerge_values_s32_trunc_s64_of_merge_values_s128
    ; CHECK: [[COPY:%[0-9]+]]:_(i64) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](i64)
    ; CHECK-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr1 = COPY [[UV1]](i32)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i64) = COPY $vgpr2_vgpr3
    %2:_(i128) = G_MERGE_VALUES %0(i64), %1(i64)
    %3:_(i64) = G_TRUNC %2(i128)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %3(i64)
    $vgpr0 = COPY %4(i32)
    $vgpr1 = COPY %5(i32)
...

---
name: test_unmerge_values_s8_v4s8_trunc_v4s32
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3

    ; CHECK-LABEL: name: test_unmerge_values_s8_v4s8_trunc_v4s32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<4 x i32>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i8) = G_TRUNC [[UV]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i8) = G_TRUNC [[UV1]](i32)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i8) = G_TRUNC [[UV2]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i8) = G_TRUNC [[UV3]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i8), implicit [[TRUNC1]](i8), implicit [[TRUNC2]](i8), implicit [[TRUNC3]](i8)
    %0:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(<4 x i8>) = G_TRUNC %0(<4 x i32>)
    %2:_(i8), %3:_(i8), %4:_(i8), %5:_(i8) = G_UNMERGE_VALUES %1(<4 x i8>)
    S_ENDPGM 0, implicit %2(i8), implicit %3(i8), implicit %4(i8), implicit %5(i8)

...

---
name: test_unmerge_values_v2s8_v4s8_trunc_v4s32
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3

    ; CHECK-LABEL: name: test_unmerge_values_v2s8_v4s8_trunc_v4s32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i32>), [[UV1:%[0-9]+]]:_(<2 x i32>) = G_UNMERGE_VALUES [[COPY]](<4 x i32>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV1]](<2 x i32>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](<2 x i16>), implicit [[TRUNC1]](<2 x i16>)
    %0:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(<4 x i8>) = G_TRUNC %0(<4 x i32>)
    %2:_(<2 x i8>), %3:_(<2 x i8>) = G_UNMERGE_VALUES %1(<4 x i8>)
    %4:_(<2 x i16>) = G_ANYEXT %2(<2 x i8>)
    %5:_(<2 x i16>) = G_ANYEXT %3(<2 x i8>)
    S_ENDPGM 0, implicit %4(<2 x i16>), implicit %5(<2 x i16>)

...

---
name: test_unmerge_values_v4s8_v8s8_trunc_v8s32
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7

    ; CHECK-LABEL: name: test_unmerge_values_v4s8_v8s8_trunc_v8s32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<8 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<4 x i32>), [[UV1:%[0-9]+]]:_(<4 x i32>) = G_UNMERGE_VALUES [[COPY]](<8 x i32>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(<4 x i8>) = G_TRUNC [[UV]](<4 x i32>)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(<4 x i8>) = G_TRUNC [[UV1]](<4 x i32>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](<4 x i8>), implicit [[TRUNC1]](<4 x i8>)
    %0:_(<8 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(<8 x i8>) = G_TRUNC %0(<8 x i32>)
    %2:_(<4 x i8>), %3:_(<4 x i8>) = G_UNMERGE_VALUES %1(<8 x i8>)
    S_ENDPGM 0, implicit %2(<4 x i8>), implicit %3(<4 x i8>)

...

---

name: test_unmerge_values_s16_v4s16_trunc_v4s32
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3

    ; CHECK-LABEL: name: test_unmerge_values_s16_v4s16_trunc_v4s32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32), [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[COPY]](<4 x i32>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[UV]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[UV1]](i32)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[UV2]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[UV3]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i16), implicit [[TRUNC1]](i16), implicit [[TRUNC2]](i16), implicit [[TRUNC3]](i16)
    %0:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(<4 x i16>) = G_TRUNC %0(<4 x i32>)
    %2:_(i16), %3:_(i16), %4:_(i16), %5:_(i16) = G_UNMERGE_VALUES %1(<4 x i16>)
    S_ENDPGM 0, implicit %2(i16), implicit %3(i16), implicit %4(i16), implicit %5(i16)

...

---
name: test_unmerge_values_v2s16_v4s16_trunc_v4s32
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3

    ; CHECK-LABEL: name: test_unmerge_values_v2s16_v4s16_trunc_v4s32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i32>), [[UV1:%[0-9]+]]:_(<2 x i32>) = G_UNMERGE_VALUES [[COPY]](<4 x i32>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV1]](<2 x i32>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](<2 x i16>), implicit [[TRUNC1]](<2 x i16>)
    %0:_(<4 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3
    %1:_(<4 x i16>) = G_TRUNC %0(<4 x i32>)
    %2:_(<2 x i16>), %3:_(<2 x i16>) = G_UNMERGE_VALUES %1(<4 x i16>)
    S_ENDPGM 0, implicit %2(<2 x i16>), implicit %3(<2 x i16>)

...

---
name: test_unmerge_values_v2s16_v8s16_trunc_v8s32
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7

    ; CHECK-LABEL: name: test_unmerge_values_v2s16_v8s16_trunc_v8s32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<8 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i32>), [[UV1:%[0-9]+]]:_(<2 x i32>), [[UV2:%[0-9]+]]:_(<2 x i32>), [[UV3:%[0-9]+]]:_(<2 x i32>) = G_UNMERGE_VALUES [[COPY]](<8 x i32>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV1]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV2]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV3]](<2 x i32>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](<2 x i16>), implicit [[TRUNC1]](<2 x i16>), implicit [[TRUNC2]](<2 x i16>), implicit [[TRUNC3]](<2 x i16>)
    %0:_(<8 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(<8 x i16>) = G_TRUNC %0(<8 x i32>)
    %2:_(<2 x i16>), %3:_(<2 x i16>), %4:_(<2 x i16>), %5:_(<2 x i16>) = G_UNMERGE_VALUES %1(<8 x i16>)
    S_ENDPGM 0, implicit %2(<2 x i16>), implicit %3(<2 x i16>), implicit %4(<2 x i16>), implicit %5(<2 x i16>)

...

---
name: test_unmerge_values_v4s16_v8s16_trunc_v8s32
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7

    ; CHECK-LABEL: name: test_unmerge_values_v4s16_v8s16_trunc_v8s32
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<8 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i32>), [[UV1:%[0-9]+]]:_(<2 x i32>), [[UV2:%[0-9]+]]:_(<2 x i32>), [[UV3:%[0-9]+]]:_(<2 x i32>) = G_UNMERGE_VALUES [[COPY]](<8 x i32>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV1]](<2 x i32>)
    ; CHECK-NEXT: [[CONCAT_VECTORS:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[TRUNC]](<2 x i16>), [[TRUNC1]](<2 x i16>)
    ; CHECK-NEXT: [[UV4:%[0-9]+]]:_(<2 x i32>), [[UV5:%[0-9]+]]:_(<2 x i32>), [[UV6:%[0-9]+]]:_(<2 x i32>), [[UV7:%[0-9]+]]:_(<2 x i32>) = G_UNMERGE_VALUES [[COPY]](<8 x i32>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV6]](<2 x i32>)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[UV7]](<2 x i32>)
    ; CHECK-NEXT: [[CONCAT_VECTORS1:%[0-9]+]]:_(<4 x i16>) = G_CONCAT_VECTORS [[TRUNC2]](<2 x i16>), [[TRUNC3]](<2 x i16>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[CONCAT_VECTORS]](<4 x i16>), implicit [[CONCAT_VECTORS1]](<4 x i16>)
    %0:_(<8 x i32>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(<8 x i16>) = G_TRUNC %0(<8 x i32>)
    %2:_(<4 x i16>), %3:_(<4 x i16>) = G_UNMERGE_VALUES %1(<8 x i16>)
    S_ENDPGM 0, implicit %2(<4 x i16>), implicit %3(<4 x i16>)

...

---
name: test_unmerge_values_s8_v4s8_trunc_v4s16
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1

    ; CHECK-LABEL: name: test_unmerge_values_s8_v4s8_trunc_v4s16
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i16>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY]](<4 x i16>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[UV]](<2 x i16>)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[UV1]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST1]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i8) = G_TRUNC [[BITCAST]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i8) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i8) = G_TRUNC [[BITCAST1]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i8) = G_TRUNC [[LSHR1]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i8), implicit [[TRUNC1]](i8), implicit [[TRUNC2]](i8), implicit [[TRUNC3]](i8)
    %0:_(<4 x i16>) = COPY $vgpr0_vgpr1
    %1:_(<4 x i8>) = G_TRUNC %0(<4 x i16>)
    %2:_(i8), %3:_(i8), %4:_(i8), %5:_(i8) = G_UNMERGE_VALUES %1(<4 x i8>)
    S_ENDPGM 0, implicit %2(i8), implicit %3(i8), implicit %4(i8), implicit %5(i8)

...

---
name: test_unmerge_values_v2s8_v4s8_trunc_v4s16
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1

    ; CHECK-LABEL: name: test_unmerge_values_v2s8_v4s8_trunc_v4s16
    ; CHECK: liveins: $vgpr0_vgpr1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i16>) = COPY $vgpr0_vgpr1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY]](<4 x i16>)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[UV]](<2 x i16>), implicit [[UV1]](<2 x i16>)
    %0:_(<4 x i16>) = COPY $vgpr0_vgpr1
    %1:_(<4 x i8>) = G_TRUNC %0(<4 x i16>)
    %2:_(<2 x i8>), %3:_(<2 x i8>) = G_UNMERGE_VALUES %1(<4 x i8>)
    %4:_(<2 x i16>) = G_ANYEXT %2(<2 x i8>)
    %5:_(<2 x i16>) = G_ANYEXT %3(<2 x i8>)
    S_ENDPGM 0, implicit %4(<2 x i16>), implicit %5(<2 x i16>)

...

---
name: test_unmerge_values_s32_v4s32_trunc_v4s64
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7

    ; CHECK-LABEL: name: test_unmerge_values_s32_v4s32_trunc_v4s64
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i64), [[UV1:%[0-9]+]]:_(i64), [[UV2:%[0-9]+]]:_(i64), [[UV3:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY]](<4 x i64>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i32) = G_TRUNC [[UV]](i64)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i32) = G_TRUNC [[UV1]](i64)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i32) = G_TRUNC [[UV2]](i64)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i32) = G_TRUNC [[UV3]](i64)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i32), implicit [[TRUNC1]](i32), implicit [[TRUNC2]](i32), implicit [[TRUNC3]](i32)
    %0:_(<4 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(<4 x i32>) = G_TRUNC %0(<4 x i64>)
    %2:_(i32), %3:_(i32), %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %1(<4 x i32>)
    S_ENDPGM 0, implicit %2(i32), implicit %3(i32), implicit %4(i32), implicit %5(i32)

...

---
name: test_unmerge_values_v2s32_v4s32_trunc_v4s64
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7

    ; CHECK-LABEL: name: test_unmerge_values_v2s32_v4s32_trunc_v4s64
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i64), [[UV1:%[0-9]+]]:_(i64), [[UV2:%[0-9]+]]:_(i64), [[UV3:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY]](<4 x i64>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i32) = G_TRUNC [[UV]](i64)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i32) = G_TRUNC [[UV1]](i64)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[TRUNC]](i32), [[TRUNC1]](i32)
    ; CHECK-NEXT: [[UV4:%[0-9]+]]:_(i64), [[UV5:%[0-9]+]]:_(i64), [[UV6:%[0-9]+]]:_(i64), [[UV7:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY]](<4 x i64>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i32) = G_TRUNC [[UV6]](i64)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i32) = G_TRUNC [[UV7]](i64)
    ; CHECK-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[TRUNC2]](i32), [[TRUNC3]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BUILD_VECTOR]](<2 x i32>), implicit [[BUILD_VECTOR1]](<2 x i32>)
    %0:_(<4 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(<4 x i32>) = G_TRUNC %0(<4 x i64>)
    %2:_(<2 x i32>), %3:_(<2 x i32>) = G_UNMERGE_VALUES %1(<4 x i32>)
    S_ENDPGM 0, implicit %2(<2 x i32>), implicit %3(<2 x i32>)

...

---
name: test_unmerge_values_s16_v4s16_trunc_v4s64
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7

    ; CHECK-LABEL: name: test_unmerge_values_s16_v4s16_trunc_v4s64
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i64), [[UV1:%[0-9]+]]:_(i64), [[UV2:%[0-9]+]]:_(i64), [[UV3:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY]](<4 x i64>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[UV]](i64)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[UV1]](i64)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[UV2]](i64)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[UV3]](i64)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i16), implicit [[TRUNC1]](i16), implicit [[TRUNC2]](i16), implicit [[TRUNC3]](i16)
    %0:_(<4 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(<4 x i16>) = G_TRUNC %0(<4 x i64>)
    %2:_(i16), %3:_(i16), %4:_(i16), %5:_(i16) = G_UNMERGE_VALUES %1(<4 x i16>)
    S_ENDPGM 0, implicit %2(i16), implicit %3(i16), implicit %4(i16), implicit %5(i16)

...

---
name: test_unmerge_values_v2s16_v4s16_trunc_v4s64
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7

    ; CHECK-LABEL: name: test_unmerge_values_v2s16_v4s16_trunc_v4s64
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i64), [[UV1:%[0-9]+]]:_(i64), [[UV2:%[0-9]+]]:_(i64), [[UV3:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY]](<4 x i64>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i32) = G_TRUNC [[UV]](i64)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[TRUNC]], [[C]]
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i32) = G_TRUNC [[UV1]](i64)
    ; CHECK-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[TRUNC1]], [[C]]
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[AND1]], [[C1]](i32)
    ; CHECK-NEXT: [[OR:%[0-9]+]]:_(i32) = G_OR [[AND]], [[SHL]]
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR]](i32)
    ; CHECK-NEXT: [[UV4:%[0-9]+]]:_(i64), [[UV5:%[0-9]+]]:_(i64), [[UV6:%[0-9]+]]:_(i64), [[UV7:%[0-9]+]]:_(i64) = G_UNMERGE_VALUES [[COPY]](<4 x i64>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i32) = G_TRUNC [[UV6]](i64)
    ; CHECK-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[TRUNC2]], [[C]]
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i32) = G_TRUNC [[UV7]](i64)
    ; CHECK-NEXT: [[AND3:%[0-9]+]]:_(i32) = G_AND [[TRUNC3]], [[C]]
    ; CHECK-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[AND3]], [[C1]](i32)
    ; CHECK-NEXT: [[OR1:%[0-9]+]]:_(i32) = G_OR [[AND2]], [[SHL1]]
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[OR1]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[BITCAST]](<2 x i16>), implicit [[BITCAST1]](<2 x i16>)
    %0:_(<4 x i64>) = COPY $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7
    %1:_(<4 x i16>) = G_TRUNC %0(<4 x i64>)
    %2:_(<2 x i16>), %3:_(<2 x i16>) = G_UNMERGE_VALUES %1(<4 x i16>)
    S_ENDPGM 0, implicit %2(<2 x i16>), implicit %3(<2 x i16>)

...

---
name: test_unmerge_values_s16_from_v3s16_from_v6s16
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2

    ; CHECK-LABEL: name: test_unmerge_values_s16_from_v3s16_from_v6s16
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<6 x i16>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>), [[UV2:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY]](<6 x i16>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[UV]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[UV1]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST1]](i32)
    ; CHECK-NEXT: [[UV3:%[0-9]+]]:_(<2 x i16>), [[UV4:%[0-9]+]]:_(<2 x i16>), [[UV5:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY]](<6 x i16>)
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(i32) = G_BITCAST [[UV4]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST2]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR1]](i32)
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[UV5]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC4:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST3]](i32)
    ; CHECK-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST3]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC5:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR2]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i16), implicit [[TRUNC1]](i16), implicit [[TRUNC2]](i16), implicit [[TRUNC3]](i16), implicit [[TRUNC4]](i16), implicit [[TRUNC5]](i16)
    %0:_(<6 x i16>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(<3 x i16>), %2:_(<3 x i16>) = G_UNMERGE_VALUES %0(<6 x i16>)
    %3:_(i16), %4:_(i16), %5:_(i16) = G_UNMERGE_VALUES %1(<3 x i16>)
    %6:_(i16), %7:_(i16), %8:_(i16) = G_UNMERGE_VALUES %2(<3 x i16>)
    S_ENDPGM 0, implicit %3(i16), implicit %4(i16), implicit %5(i16), implicit %6(i16), implicit %7(i16), implicit %8(i16)

...

---
name: test_unmerge_values_s16_from_v3s16_from_v6s16_other_def_use
body:             |
  bb.0:
    liveins: $vgpr0_vgpr1_vgpr2

    ; CHECK-LABEL: name: test_unmerge_values_s16_from_v3s16_from_v6s16_other_def_use
    ; CHECK: liveins: $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<6 x i16>) = COPY $vgpr0_vgpr1_vgpr2
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(<2 x i16>), [[UV1:%[0-9]+]]:_(<2 x i16>), [[UV2:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY]](<6 x i16>)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[UV]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST]](i32)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; CHECK-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; CHECK-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR]](i32)
    ; CHECK-NEXT: [[BITCAST1:%[0-9]+]]:_(i32) = G_BITCAST [[UV1]](<2 x i16>)
    ; CHECK-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST1]](i32)
    ; CHECK-NEXT: [[UV3:%[0-9]+]]:_(<2 x i16>), [[UV4:%[0-9]+]]:_(<2 x i16>), [[UV5:%[0-9]+]]:_(<2 x i16>) = G_UNMERGE_VALUES [[COPY]](<6 x i16>)
    ; CHECK-NEXT: [[BITCAST2:%[0-9]+]]:_(i32) = G_BITCAST [[UV4]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST2]], [[C]](i32)
    ; CHECK-NEXT: [[BITCAST3:%[0-9]+]]:_(i32) = G_BITCAST [[UV5]](<2 x i16>)
    ; CHECK-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST3]], [[C]](i32)
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<3 x i32>) = G_BUILD_VECTOR [[LSHR1]](i32), [[BITCAST3]](i32), [[LSHR2]](i32)
    ; CHECK-NEXT: S_ENDPGM 0, implicit [[TRUNC]](i16), implicit [[TRUNC1]](i16), implicit [[TRUNC2]](i16), implicit [[BUILD_VECTOR]](<3 x i32>)
    %0:_(<6 x i16>) = COPY $vgpr0_vgpr1_vgpr2
    %1:_(<3 x i16>), %2:_(<3 x i16>) = G_UNMERGE_VALUES %0(<6 x i16>)
    %3:_(i16), %4:_(i16), %5:_(i16) = G_UNMERGE_VALUES %1(<3 x i16>)
    %6:_(<3 x i32>) = G_ANYEXT %2(<3 x i16>)
    S_ENDPGM 0, implicit %3(i16), implicit %4(i16), implicit %5(i16), implicit %6(<3 x i32>)

...

---
name: test_unmerge_values_s32_from_sext_v2s64_from_v2s1
body:             |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2

    ; CHECK-LABEL: name: test_unmerge_values_s32_from_sext_v2s64_from_v2s1
    ; CHECK: liveins: $vgpr0, $vgpr1, $vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY]](i32), [[COPY2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY1]](i32), [[COPY2]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[SEXT_INREG:%[0-9]+]]:_(i64) = G_SEXT_INREG [[ANYEXT]], 1
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[SEXT_INREG1:%[0-9]+]]:_(i64) = G_SEXT_INREG [[ANYEXT1]], 1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[SEXT_INREG]](i64)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[SEXT_INREG1]](i64)
    ; CHECK-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; CHECK-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; CHECK-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; CHECK-NEXT: S_SETPC_B64_return undef $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i1) = G_ICMP intpred(eq), %0(i32), %2
    %4:_(i1) = G_ICMP intpred(eq), %1(i32), %2
    %5:_(<2 x i1>) = G_BUILD_VECTOR %3(i1), %4(i1)
    %6:_(<2 x i64>) = G_SEXT %5(<2 x i1>)
    %7:_(i32), %8:_(i32), %9:_(i32), %10:_(i32) = G_UNMERGE_VALUES %6(<2 x i64>)
    $vgpr0 = COPY %7(i32)
    $vgpr1 = COPY %8(i32)
    $vgpr2 = COPY %9(i32)
    $vgpr3 = COPY %10(i32)
    S_SETPC_B64_return undef $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3

...

---
name: test_unmerge_values_s32_from_zext_v2s64_from_v2s1
body:             |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2

    ; CHECK-LABEL: name: test_unmerge_values_s32_from_zext_v2s64_from_v2s1
    ; CHECK: liveins: $vgpr0, $vgpr1, $vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY]](i32), [[COPY2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY1]](i32), [[COPY2]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(i64) = G_CONSTANT i64 1
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(i64) = G_AND [[ANYEXT]], [[C]]
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[AND1:%[0-9]+]]:_(i64) = G_AND [[ANYEXT1]], [[C]]
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[AND]](i64)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[AND1]](i64)
    ; CHECK-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; CHECK-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; CHECK-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; CHECK-NEXT: S_SETPC_B64_return undef $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i1) = G_ICMP intpred(eq), %0(i32), %2
    %4:_(i1) = G_ICMP intpred(eq), %1(i32), %2
    %5:_(<2 x i1>) = G_BUILD_VECTOR %3(i1), %4(i1)
    %6:_(<2 x i64>) = G_ZEXT %5(<2 x i1>)
    %7:_(i32), %8:_(i32), %9:_(i32), %10:_(i32) = G_UNMERGE_VALUES %6(<2 x i64>)
    $vgpr0 = COPY %7(i32)
    $vgpr1 = COPY %8(i32)
    $vgpr2 = COPY %9(i32)
    $vgpr3 = COPY %10(i32)
    S_SETPC_B64_return undef $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3

...

---
name: test_unmerge_values_s32_from_anyext_v2s64_from_v2s1
body:             |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2

    ; CHECK-LABEL: name: test_unmerge_values_s32_from_anyext_v2s64_from_v2s1
    ; CHECK: liveins: $vgpr0, $vgpr1, $vgpr2
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY]](i32), [[COPY2]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY1]](i32), [[COPY2]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i32) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[ANYEXT2:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[ANYEXT3:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[ANYEXT2]](i64)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[ANYEXT3]](i64)
    ; CHECK-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; CHECK-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; CHECK-NEXT: $vgpr2 = COPY [[ANYEXT1]](i32)
    ; CHECK-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; CHECK-NEXT: S_SETPC_B64_return undef $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i1) = G_ICMP intpred(eq), %0(i32), %2
    %4:_(i1) = G_ICMP intpred(eq), %1(i32), %2
    %5:_(<2 x i1>) = G_BUILD_VECTOR %3(i1), %4(i1)
    %6:_(<2 x i64>) = G_ANYEXT %5(<2 x i1>)
    %7:_(i32), %8:_(i32), %9:_(i32), %10:_(i32) = G_UNMERGE_VALUES %6(<2 x i64>)
    $vgpr0 = COPY %7(i32)
    $vgpr1 = COPY %8(i32)
    $vgpr2 = COPY %9(i32)
    $vgpr3 = COPY %10(i32)
    S_SETPC_B64_return undef $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3

...

---
name: test_unmerge_values_s32_from_sext_v3s64_from_v3s1
body:             |
  bb.0:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; CHECK-LABEL: name: test_unmerge_values_s32_from_sext_v3s64_from_v3s1
    ; CHECK: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; CHECK-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY]](i32), [[COPY3]]
    ; CHECK-NEXT: [[ICMP1:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY1]](i32), [[COPY3]]
    ; CHECK-NEXT: [[ICMP2:%[0-9]+]]:_(i1) = G_ICMP intpred(eq), [[COPY2]](i32), [[COPY3]]
    ; CHECK-NEXT: [[ANYEXT:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP]](i1)
    ; CHECK-NEXT: [[SEXT_INREG:%[0-9]+]]:_(i64) = G_SEXT_INREG [[ANYEXT]], 1
    ; CHECK-NEXT: [[ANYEXT1:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP1]](i1)
    ; CHECK-NEXT: [[SEXT_INREG1:%[0-9]+]]:_(i64) = G_SEXT_INREG [[ANYEXT1]], 1
    ; CHECK-NEXT: [[ANYEXT2:%[0-9]+]]:_(i64) = G_ANYEXT [[ICMP2]](i1)
    ; CHECK-NEXT: [[SEXT_INREG2:%[0-9]+]]:_(i64) = G_SEXT_INREG [[ANYEXT2]], 1
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[SEXT_INREG]](i64)
    ; CHECK-NEXT: [[UV2:%[0-9]+]]:_(i32), [[UV3:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[SEXT_INREG1]](i64)
    ; CHECK-NEXT: [[UV4:%[0-9]+]]:_(i32), [[UV5:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[SEXT_INREG2]](i64)
    ; CHECK-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr1 = COPY [[UV1]](i32)
    ; CHECK-NEXT: $vgpr2 = COPY [[UV2]](i32)
    ; CHECK-NEXT: $vgpr3 = COPY [[UV3]](i32)
    ; CHECK-NEXT: $vgpr4 = COPY [[UV4]](i32)
    ; CHECK-NEXT: $vgpr5 = COPY [[UV5]](i32)
    ; CHECK-NEXT: S_SETPC_B64_return undef $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i1) = G_ICMP intpred(eq), %0(i32), %3
    %5:_(i1) = G_ICMP intpred(eq), %1(i32), %3
    %6:_(i1) = G_ICMP intpred(eq), %2(i32), %3
    %7:_(<3 x i1>) = G_BUILD_VECTOR %4(i1), %5(i1), %6(i1)
    %8:_(<3 x i64>) = G_SEXT %7(<3 x i1>)
    %9:_(i32), %10:_(i32), %11:_(i32), %12:_(i32), %13:_(i32), %14:_(i32) = G_UNMERGE_VALUES %8(<3 x i64>)
    $vgpr0 = COPY %9(i32)
    $vgpr1 = COPY %10(i32)
    $vgpr2 = COPY %11(i32)
    $vgpr3 = COPY %12(i32)
    $vgpr4 = COPY %13(i32)
    $vgpr5 = COPY %14(i32)
    S_SETPC_B64_return undef $sgpr30_sgpr31, implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4, implicit $vgpr5

...

---
name: test_unmerge_values_look_through_scalar_to_vector_bitcast
body: |
  bb.0:

    ; CHECK-LABEL: name: test_unmerge_values_look_through_scalar_to_vector_bitcast
    ; CHECK: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: $vgpr0 = COPY [[COPY]](i32)
    ; CHECK-NEXT: $vgpr1 = COPY [[COPY1]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i64) = G_MERGE_VALUES %0(i32), %1(i32)
    %3:_(<2 x i32>) = G_BITCAST %2(i64)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %3(<2 x i32>)
    $vgpr0 = COPY %4(i32)
    $vgpr1 = COPY %5(i32)
...

---
name: test_unmerge_values_look_through_vector_to_scalar_bitcast
body: |
  bb.0:

    ; CHECK-LABEL: name: test_unmerge_values_look_through_vector_to_scalar_bitcast
    ; CHECK: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32)
    ; CHECK-NEXT: [[BITCAST:%[0-9]+]]:_(i64) = G_BITCAST [[BUILD_VECTOR]](<2 x i32>)
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(i32), [[UV1:%[0-9]+]]:_(i32) = G_UNMERGE_VALUES [[BITCAST]](i64)
    ; CHECK-NEXT: $vgpr0 = COPY [[UV]](i32)
    ; CHECK-NEXT: $vgpr1 = COPY [[UV1]](i32)
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(<2 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32)
    %3:_(i64) = G_BITCAST %2(<2 x i32>)
    %4:_(i32), %5:_(i32) = G_UNMERGE_VALUES %3(i64)
    $vgpr0 = COPY %4(i32)
    $vgpr1 = COPY %5(i32)
...
