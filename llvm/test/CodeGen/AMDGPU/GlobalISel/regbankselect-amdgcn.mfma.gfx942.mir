# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=amdgcn -mcpu=gfx942 -run-pass=regbankselect -regbankselect-fast -verify-machineinstrs %s -o - | FileCheck %s -check-prefix=FAST
# RUN: llc -mtriple=amdgcn -mcpu=gfx942 -run-pass=regbankselect -regbankselect-greedy -verify-machineinstrs %s -o - | FileCheck %s -check-prefix=GREEDY

---
name: mfma_i32_16x16x32_i8_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr1_vgpr2, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3

    ; FAST-LABEL: name: mfma_i32_16x16x32_i8_vva
    ; FAST: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i64) = COPY $vgpr2_vgpr3
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.i32.16x16x32.i8), [[COPY]](i64), [[COPY1]](i64), [[COPY2]](<4 x i32>), 0, 0, 0
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[INTRINSIC_CONVERGENT]](<4 x i32>)
    ;
    ; GREEDY-LABEL: name: mfma_i32_16x16x32_i8_vva
    ; GREEDY: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i64) = COPY $vgpr2_vgpr3
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.i32.16x16x32.i8), [[COPY]](i64), [[COPY1]](i64), [[COPY2]](<4 x i32>), 0, 0, 0
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[INTRINSIC_CONVERGENT]](<4 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i64) = COPY $vgpr2_vgpr3
    %2:_(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    %3:_(<4 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.i32.16x16x32.i8), %0(i64), %1(i64), %2(<4 x i32>), 0, 0, 0
    $vgpr0_vgpr1_vgpr2_vgpr3 = COPY %3(<4 x i32>)
...

---
name: mfma_i32_32x32x16_i8_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15

    ; FAST-LABEL: name: mfma_i32_32x32x16_i8_vva
    ; FAST: liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i64) = COPY $vgpr2_vgpr3
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.i32.32x32x16.i8), [[COPY]](i64), [[COPY1]](i64), [[COPY2]](<16 x i32>), 0, 0, 0
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[INTRINSIC_CONVERGENT]](<16 x i32>)
    ;
    ; GREEDY-LABEL: name: mfma_i32_32x32x16_i8_vva
    ; GREEDY: liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i64) = COPY $vgpr2_vgpr3
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.i32.32x32x16.i8), [[COPY]](i64), [[COPY1]](i64), [[COPY2]](<16 x i32>), 0, 0, 0
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[INTRINSIC_CONVERGENT]](<16 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i64) = COPY $vgpr2_vgpr3
    %2:_(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    %3:_(<16 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.i32.32x32x16.i8), %0(i64), %1(i64), %2(<16 x i32>), 0, 0, 0
    $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY %3(<16 x i32>)
...

---
name: mfma_f32_16x16x8_xf32_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr1_vgpr2, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3

    ; FAST-LABEL: name: mfma_f32_16x16x8_xf32_vva
    ; FAST: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i64) = COPY $vgpr2_vgpr3
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; FAST-NEXT: [[BITCAST:%[0-9]+]]:vgpr(f64) = G_BITCAST [[COPY]](i64)
    ; FAST-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(f64) = G_BITCAST [[COPY1]](i64)
    ; FAST-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<4 x f32>) = G_BITCAST [[COPY2]](<4 x i32>)
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.f32.16x16x8.xf32), [[BITCAST]](f64), [[BITCAST1]](f64), [[BITCAST2]](<4 x f32>), 0, 0, 0
    ; FAST-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<4 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<4 x f32>)
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[BITCAST3]](<4 x i32>)
    ;
    ; GREEDY-LABEL: name: mfma_f32_16x16x8_xf32_vva
    ; GREEDY: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i64) = COPY $vgpr2_vgpr3
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; GREEDY-NEXT: [[BITCAST:%[0-9]+]]:vgpr(f64) = G_BITCAST [[COPY]](i64)
    ; GREEDY-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(f64) = G_BITCAST [[COPY1]](i64)
    ; GREEDY-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<4 x f32>) = G_BITCAST [[COPY2]](<4 x i32>)
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.f32.16x16x8.xf32), [[BITCAST]](f64), [[BITCAST1]](f64), [[BITCAST2]](<4 x f32>), 0, 0, 0
    ; GREEDY-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<4 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<4 x f32>)
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[BITCAST3]](<4 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i64) = COPY $vgpr2_vgpr3
    %2:_(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    %3:_(f64) = G_BITCAST %0(i64)
    %4:_(f64) = G_BITCAST %1(i64)
    %5:_(<4 x f32>) = G_BITCAST %2(<4 x i32>)
    %6:_(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.f32.16x16x8.xf32), %3(f64), %4(f64), %5(<4 x f32>), 0, 0, 0
    %7:_(<4 x i32>) = G_BITCAST %6(<4 x f32>)
    $vgpr0_vgpr1_vgpr2_vgpr3 = COPY %7(<4 x i32>)
...

---
name: mfma_f32_32x32x4_xf32_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15

    ; FAST-LABEL: name: mfma_f32_32x32x4_xf32_vva
    ; FAST: liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i64) = COPY $vgpr2_vgpr3
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; FAST-NEXT: [[BITCAST:%[0-9]+]]:vgpr(f64) = G_BITCAST [[COPY]](i64)
    ; FAST-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(f64) = G_BITCAST [[COPY1]](i64)
    ; FAST-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<16 x f32>) = G_BITCAST [[COPY2]](<16 x i32>)
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.f32.32x32x4.xf32), [[BITCAST]](f64), [[BITCAST1]](f64), [[BITCAST2]](<16 x f32>), 0, 0, 0
    ; FAST-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<16 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<16 x f32>)
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[BITCAST3]](<16 x i32>)
    ;
    ; GREEDY-LABEL: name: mfma_f32_32x32x4_xf32_vva
    ; GREEDY: liveins: $vgpr0_vgpr1, $vgpr2_vgpr3, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i64) = COPY $vgpr2_vgpr3
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; GREEDY-NEXT: [[BITCAST:%[0-9]+]]:vgpr(f64) = G_BITCAST [[COPY]](i64)
    ; GREEDY-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(f64) = G_BITCAST [[COPY1]](i64)
    ; GREEDY-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<16 x f32>) = G_BITCAST [[COPY2]](<16 x i32>)
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.f32.32x32x4.xf32), [[BITCAST]](f64), [[BITCAST1]](f64), [[BITCAST2]](<16 x f32>), 0, 0, 0
    ; GREEDY-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<16 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<16 x f32>)
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[BITCAST3]](<16 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i64) = COPY $vgpr2_vgpr3
    %2:_(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    %3:_(f64) = G_BITCAST %0(i64)
    %4:_(f64) = G_BITCAST %1(i64)
    %5:_(<16 x f32>) = G_BITCAST %2(<16 x i32>)
    %6:_(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.mfma.f32.32x32x4.xf32), %3(f64), %4(f64), %5(<16 x f32>), 0, 0, 0
    %7:_(<16 x i32>) = G_BITCAST %6(<16 x f32>)
    $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY %7(<16 x i32>)
...

---
name: smfmac_f32_16x16x32_f16_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20

    ; FAST-LABEL: name: smfmac_f32_16x16x32_f16_vva
    ; FAST: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; FAST-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; FAST-NEXT: [[BITCAST:%[0-9]+]]:vgpr(<4 x f16>) = G_BITCAST [[COPY]](i64)
    ; FAST-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(<8 x f16>) = G_BITCAST [[COPY1]](i128)
    ; FAST-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<4 x f32>) = G_BITCAST [[COPY2]](<4 x i32>)
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.16x16x32.f16), [[BITCAST]](<4 x f16>), [[BITCAST1]](<8 x f16>), [[BITCAST2]](<4 x f32>), [[COPY3]](i32), 0, 0
    ; FAST-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<4 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<4 x f32>)
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[BITCAST3]](<4 x i32>)
    ;
    ; GREEDY-LABEL: name: smfmac_f32_16x16x32_f16_vva
    ; GREEDY: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; GREEDY-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; GREEDY-NEXT: [[BITCAST:%[0-9]+]]:vgpr(<4 x f16>) = G_BITCAST [[COPY]](i64)
    ; GREEDY-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(<8 x f16>) = G_BITCAST [[COPY1]](i128)
    ; GREEDY-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<4 x f32>) = G_BITCAST [[COPY2]](<4 x i32>)
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.16x16x32.f16), [[BITCAST]](<4 x f16>), [[BITCAST1]](<8 x f16>), [[BITCAST2]](<4 x f32>), [[COPY3]](i32), 0, 0
    ; GREEDY-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<4 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<4 x f32>)
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[BITCAST3]](<4 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    %2:_(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    %3:_(i32) = COPY $vgpr20
    %4:_(<4 x f16>) = G_BITCAST %0(i64)
    %5:_(<8 x f16>) = G_BITCAST %1(i128)
    %6:_(<4 x f32>) = G_BITCAST %2(<4 x i32>)
    %7:_(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.16x16x32.f16), %4(<4 x f16>), %5(<8 x f16>), %6(<4 x f32>), %3(i32), 0, 0
    %8:_(<4 x i32>) = G_BITCAST %7(<4 x f32>)
    $vgpr0_vgpr1_vgpr2_vgpr3 = COPY %8(<4 x i32>)
...

---
name: smfmac_f32_32x32x16_f16_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20

    ; FAST-LABEL: name: smfmac_f32_32x32x16_f16_vva
    ; FAST: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; FAST-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; FAST-NEXT: [[BITCAST:%[0-9]+]]:vgpr(<4 x f16>) = G_BITCAST [[COPY]](i64)
    ; FAST-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(<8 x f16>) = G_BITCAST [[COPY1]](i128)
    ; FAST-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<16 x f32>) = G_BITCAST [[COPY2]](<16 x i32>)
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.32x32x16.f16), [[BITCAST]](<4 x f16>), [[BITCAST1]](<8 x f16>), [[BITCAST2]](<16 x f32>), [[COPY3]](i32), 0, 0
    ; FAST-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<16 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<16 x f32>)
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[BITCAST3]](<16 x i32>)
    ;
    ; GREEDY-LABEL: name: smfmac_f32_32x32x16_f16_vva
    ; GREEDY: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; GREEDY-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; GREEDY-NEXT: [[BITCAST:%[0-9]+]]:vgpr(<4 x f16>) = G_BITCAST [[COPY]](i64)
    ; GREEDY-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(<8 x f16>) = G_BITCAST [[COPY1]](i128)
    ; GREEDY-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<16 x f32>) = G_BITCAST [[COPY2]](<16 x i32>)
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.32x32x16.f16), [[BITCAST]](<4 x f16>), [[BITCAST1]](<8 x f16>), [[BITCAST2]](<16 x f32>), [[COPY3]](i32), 0, 0
    ; GREEDY-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<16 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<16 x f32>)
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[BITCAST3]](<16 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    %2:_(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    %3:_(i32) = COPY $vgpr20
    %4:_(<4 x f16>) = G_BITCAST %0(i64)
    %5:_(<8 x f16>) = G_BITCAST %1(i128)
    %6:_(<16 x f32>) = G_BITCAST %2(<16 x i32>)
    %7:_(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.32x32x16.f16), %4(<4 x f16>), %5(<8 x f16>), %6(<16 x f32>), %3(i32), 0, 0
    %8:_(<16 x i32>) = G_BITCAST %7(<16 x f32>)
    $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY %8(<16 x i32>)
...

---
name: smfmac_f32_16x16x32_bf16_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20

    ; FAST-LABEL: name: smfmac_f32_16x16x32_bf16_vva
    ; FAST: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; FAST-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; FAST-NEXT: [[BITCAST:%[0-9]+]]:vgpr(<4 x bf16>) = G_BITCAST [[COPY]](i64)
    ; FAST-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(<8 x bf16>) = G_BITCAST [[COPY1]](i128)
    ; FAST-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<4 x f32>) = G_BITCAST [[COPY2]](<4 x i32>)
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.16x16x32.bf16), [[BITCAST]](<4 x bf16>), [[BITCAST1]](<8 x bf16>), [[BITCAST2]](<4 x f32>), [[COPY3]](i32), 0, 0
    ; FAST-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<4 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<4 x f32>)
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[BITCAST3]](<4 x i32>)
    ;
    ; GREEDY-LABEL: name: smfmac_f32_16x16x32_bf16_vva
    ; GREEDY: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; GREEDY-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; GREEDY-NEXT: [[BITCAST:%[0-9]+]]:vgpr(<4 x bf16>) = G_BITCAST [[COPY]](i64)
    ; GREEDY-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(<8 x bf16>) = G_BITCAST [[COPY1]](i128)
    ; GREEDY-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<4 x f32>) = G_BITCAST [[COPY2]](<4 x i32>)
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.16x16x32.bf16), [[BITCAST]](<4 x bf16>), [[BITCAST1]](<8 x bf16>), [[BITCAST2]](<4 x f32>), [[COPY3]](i32), 0, 0
    ; GREEDY-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<4 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<4 x f32>)
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[BITCAST3]](<4 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    %2:_(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    %3:_(i32) = COPY $vgpr20
    %4:_(<4 x bf16>) = G_BITCAST %0(i64)
    %5:_(<8 x bf16>) = G_BITCAST %1(i128)
    %6:_(<4 x f32>) = G_BITCAST %2(<4 x i32>)
    %7:_(<4 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.16x16x32.bf16), %4(<4 x bf16>), %5(<8 x bf16>), %6(<4 x f32>), %3(i32), 0, 0
    %8:_(<4 x i32>) = G_BITCAST %7(<4 x f32>)
    $vgpr0_vgpr1_vgpr2_vgpr3 = COPY %8(<4 x i32>)
...

---
name: smfmac_f32_32x32x16_bf16_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20

    ; FAST-LABEL: name: smfmac_f32_32x32x16_bf16_vva
    ; FAST: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; FAST-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; FAST-NEXT: [[BITCAST:%[0-9]+]]:vgpr(<4 x bf16>) = G_BITCAST [[COPY]](i64)
    ; FAST-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(<8 x bf16>) = G_BITCAST [[COPY1]](i128)
    ; FAST-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<16 x f32>) = G_BITCAST [[COPY2]](<16 x i32>)
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.32x32x16.bf16), [[BITCAST]](<4 x bf16>), [[BITCAST1]](<8 x bf16>), [[BITCAST2]](<16 x f32>), [[COPY3]](i32), 0, 0
    ; FAST-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<16 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<16 x f32>)
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[BITCAST3]](<16 x i32>)
    ;
    ; GREEDY-LABEL: name: smfmac_f32_32x32x16_bf16_vva
    ; GREEDY: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; GREEDY-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; GREEDY-NEXT: [[BITCAST:%[0-9]+]]:vgpr(<4 x bf16>) = G_BITCAST [[COPY]](i64)
    ; GREEDY-NEXT: [[BITCAST1:%[0-9]+]]:vgpr(<8 x bf16>) = G_BITCAST [[COPY1]](i128)
    ; GREEDY-NEXT: [[BITCAST2:%[0-9]+]]:agpr(<16 x f32>) = G_BITCAST [[COPY2]](<16 x i32>)
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.32x32x16.bf16), [[BITCAST]](<4 x bf16>), [[BITCAST1]](<8 x bf16>), [[BITCAST2]](<16 x f32>), [[COPY3]](i32), 0, 0
    ; GREEDY-NEXT: [[BITCAST3:%[0-9]+]]:agpr(<16 x i32>) = G_BITCAST [[INTRINSIC_CONVERGENT]](<16 x f32>)
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[BITCAST3]](<16 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    %2:_(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    %3:_(i32) = COPY $vgpr20
    %4:_(<4 x bf16>) = G_BITCAST %0(i64)
    %5:_(<8 x bf16>) = G_BITCAST %1(i128)
    %6:_(<16 x f32>) = G_BITCAST %2(<16 x i32>)
    %7:_(<16 x f32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.f32.32x32x16.bf16), %4(<4 x bf16>), %5(<8 x bf16>), %6(<16 x f32>), %3(i32), 0, 0
    %8:_(<16 x i32>) = G_BITCAST %7(<16 x f32>)
    $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY %8(<16 x i32>)
...

---
name: smfmac_i32_16x16x64_i8_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20

    ; FAST-LABEL: name: smfmac_i32_16x16x64_i8_vva
    ; FAST: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; FAST-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.i32.16x16x64.i8), [[COPY]](i64), [[COPY1]](i128), [[COPY2]](<4 x i32>), [[COPY3]](i32), 0, 0
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[INTRINSIC_CONVERGENT]](<4 x i32>)
    ;
    ; GREEDY-LABEL: name: smfmac_i32_16x16x64_i8_vva
    ; GREEDY: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3, $vgpr20
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    ; GREEDY-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<4 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.i32.16x16x64.i8), [[COPY]](i64), [[COPY1]](i128), [[COPY2]](<4 x i32>), [[COPY3]](i32), 0, 0
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3 = COPY [[INTRINSIC_CONVERGENT]](<4 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    %2:_(<4 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3
    %3:_(i32) = COPY $vgpr20
    %4:_(<4 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.i32.16x16x64.i8), %0(i64), %1(i128), %2(<4 x i32>), %3(i32), 0, 0
    $vgpr0_vgpr1_vgpr2_vgpr3 = COPY %4(<4 x i32>)
...

---
name: smfmac_i32_32x32x32_i8_vva
legalized: true
tracksRegLiveness: true
body: |
  bb.0:
    liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20

    ; FAST-LABEL: name: smfmac_i32_32x32x32_i8_vva
    ; FAST: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20
    ; FAST-NEXT: {{  $}}
    ; FAST-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; FAST-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; FAST-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; FAST-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; FAST-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.i32.32x32x32.i8), [[COPY]](i64), [[COPY1]](i128), [[COPY2]](<16 x i32>), [[COPY3]](i32), 0, 0
    ; FAST-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[INTRINSIC_CONVERGENT]](<16 x i32>)
    ;
    ; GREEDY-LABEL: name: smfmac_i32_32x32x32_i8_vva
    ; GREEDY: liveins: $vgpr1_vgpr2, $vgpr2_vgpr3_vgpr4_vgpr5, $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15, $vgpr20
    ; GREEDY-NEXT: {{  $}}
    ; GREEDY-NEXT: [[COPY:%[0-9]+]]:vgpr(i64) = COPY $vgpr0_vgpr1
    ; GREEDY-NEXT: [[COPY1:%[0-9]+]]:vgpr(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    ; GREEDY-NEXT: [[COPY2:%[0-9]+]]:agpr(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    ; GREEDY-NEXT: [[COPY3:%[0-9]+]]:vgpr(i32) = COPY $vgpr20
    ; GREEDY-NEXT: [[INTRINSIC_CONVERGENT:%[0-9]+]]:agpr(<16 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.i32.32x32x32.i8), [[COPY]](i64), [[COPY1]](i128), [[COPY2]](<16 x i32>), [[COPY3]](i32), 0, 0
    ; GREEDY-NEXT: $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY [[INTRINSIC_CONVERGENT]](<16 x i32>)
    %0:_(i64) = COPY $vgpr0_vgpr1
    %1:_(i128) = COPY $vgpr2_vgpr3_vgpr4_vgpr5
    %2:_(<16 x i32>) = COPY $agpr0_agpr1_agpr2_agpr3_agpr4_agpr5_agpr6_agpr7_agpr8_agpr9_agpr10_agpr11_agpr12_agpr13_agpr14_agpr15
    %3:_(i32) = COPY $vgpr20
    %4:_(<16 x i32>) = G_INTRINSIC_CONVERGENT intrinsic(@llvm.amdgcn.smfmac.i32.32x32x32.i8), %0(i64), %1(i128), %2(<16 x i32>), %3(i32), 0, 0
    $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11_vgpr12_vgpr13_vgpr14_vgpr15 = COPY %4(<16 x i32>)
...
