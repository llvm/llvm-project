# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=amdgcn-mesa-mesa3d -mcpu=hawaii -run-pass=legalizer -verify-machineinstrs -o - %s | FileCheck -check-prefix=GFX7 %s

--- |

  define <2 x i16> @and_v2i16(<2 x i16> %a, <2 x i16> %b) #0 {
    %and = and <2 x i16> %a, %b
    ret <2 x i16> %and
  }

  define <3 x i16> @add_v3i16(<3 x i16> %a, <3 x i16> %b) #0 {
    %add = add <3 x i16> %a, %b
    ret <3 x i16> %add
  }

  define <3 x i16> @shl_v3i16(<3 x i16> %a, <3 x i16> %b) #0 {
    %shl = shl <3 x i16> %a, %b
    ret <3 x i16> %shl
  }

  define <4 x half> @fma_v4f16(<4 x half> %a, <4 x half> %b, <4 x half> %c) {
    %fma = call <4 x half> @llvm.fma.v4f16(<4 x half> %a, <4 x half> %b, <4 x half> %c)
    ret <4 x half> %fma
  }

  define amdgpu_ps <5 x half> @maxnum_v5i16(<5 x half> %a, <5 x half> %b) {
    %fma = call <5 x half> @llvm.maxnum.v5f16(<5 x half> %a, <5 x half> %b)
    ret <5 x half> %fma
  }

  declare <4 x half> @llvm.fma.v4f16(<4 x half>, <4 x half>, <4 x half>)
  declare <5 x half> @llvm.maxnum.v5f16(<5 x half>, <5 x half>)
...

---
name: and_v2i16
body: |
  bb.1:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3

    ; GFX7-LABEL: name: and_v2i16
    ; GFX7: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3
    ; GFX7-NEXT: {{  $}}
    ; GFX7-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX7-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX7-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32)
    ; GFX7-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR]](<2 x i32>)
    ; GFX7-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX7-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX7-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY2]](i32), [[COPY3]](i32)
    ; GFX7-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR1]](<2 x i32>)
    ; GFX7-NEXT: [[AND:%[0-9]+]]:_(<2 x i16>) = G_AND [[TRUNC]], [[TRUNC1]]
    ; GFX7-NEXT: [[BITCAST:%[0-9]+]]:_(i32) = G_BITCAST [[AND]](<2 x i16>)
    ; GFX7-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX7-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST]], [[C]](i32)
    ; GFX7-NEXT: $vgpr0 = COPY [[BITCAST]](i32)
    ; GFX7-NEXT: $vgpr1 = COPY [[LSHR]](i32)
    ; GFX7-NEXT: SI_RETURN implicit $vgpr0, implicit $vgpr1
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(<2 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32)
    %3:_(<2 x i16>) = G_TRUNC %2(<2 x i32>)
    %4:_(i32) = COPY $vgpr2
    %5:_(i32) = COPY $vgpr3
    %6:_(<2 x i32>) = G_BUILD_VECTOR %4(i32), %5(i32)
    %7:_(<2 x i16>) = G_TRUNC %6(<2 x i32>)
    %8:_(<2 x i16>) = G_AND %3, %7
    %9:_(i16), %10:_(i16) = G_UNMERGE_VALUES %8(<2 x i16>)
    %11:_(i32) = G_ANYEXT %9(i16)
    %12:_(i32) = G_ANYEXT %10(i16)
    $vgpr0 = COPY %11(i32)
    $vgpr1 = COPY %12(i32)
    SI_RETURN implicit $vgpr0, implicit $vgpr1

...

---
name: add_v3i16
body: |
  bb.1:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5

    ; GFX7-LABEL: name: add_v3i16
    ; GFX7: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX7-NEXT: {{  $}}
    ; GFX7-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX7-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX7-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX7-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX7-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX7-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX7-NEXT: [[ADD:%[0-9]+]]:_(i32) = G_ADD [[COPY]], [[COPY3]]
    ; GFX7-NEXT: [[ADD1:%[0-9]+]]:_(i32) = G_ADD [[COPY1]], [[COPY4]]
    ; GFX7-NEXT: [[ADD2:%[0-9]+]]:_(i32) = G_ADD [[COPY2]], [[COPY5]]
    ; GFX7-NEXT: $vgpr0 = COPY [[ADD]](i32)
    ; GFX7-NEXT: $vgpr1 = COPY [[ADD1]](i32)
    ; GFX7-NEXT: $vgpr2 = COPY [[ADD2]](i32)
    ; GFX7-NEXT: SI_RETURN implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(<3 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32)
    %4:_(<3 x i16>) = G_TRUNC %3(<3 x i32>)
    %5:_(i32) = COPY $vgpr3
    %6:_(i32) = COPY $vgpr4
    %7:_(i32) = COPY $vgpr5
    %8:_(<3 x i32>) = G_BUILD_VECTOR %5(i32), %6(i32), %7(i32)
    %9:_(<3 x i16>) = G_TRUNC %8(<3 x i32>)
    %10:_(<3 x i16>) = G_ADD %4, %9
    %11:_(i16), %12:_(i16), %13:_(i16) = G_UNMERGE_VALUES %10(<3 x i16>)
    %14:_(i32) = G_ANYEXT %11(i16)
    %15:_(i32) = G_ANYEXT %12(i16)
    %16:_(i32) = G_ANYEXT %13(i16)
    $vgpr0 = COPY %14(i32)
    $vgpr1 = COPY %15(i32)
    $vgpr2 = COPY %16(i32)
    SI_RETURN implicit $vgpr0, implicit $vgpr1, implicit $vgpr2

...

---
name: shl_v3i16
body: |
  bb.1:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5

    ; GFX7-LABEL: name: shl_v3i16
    ; GFX7: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5
    ; GFX7-NEXT: {{  $}}
    ; GFX7-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX7-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX7-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX7-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX7-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX7-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX7-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 65535
    ; GFX7-NEXT: [[AND:%[0-9]+]]:_(i32) = G_AND [[COPY3]], [[C]]
    ; GFX7-NEXT: [[SHL:%[0-9]+]]:_(i32) = G_SHL [[COPY]], [[AND]](i32)
    ; GFX7-NEXT: [[AND1:%[0-9]+]]:_(i32) = G_AND [[COPY4]], [[C]]
    ; GFX7-NEXT: [[SHL1:%[0-9]+]]:_(i32) = G_SHL [[COPY1]], [[AND1]](i32)
    ; GFX7-NEXT: [[AND2:%[0-9]+]]:_(i32) = G_AND [[COPY5]], [[C]]
    ; GFX7-NEXT: [[SHL2:%[0-9]+]]:_(i32) = G_SHL [[COPY2]], [[AND2]](i32)
    ; GFX7-NEXT: $vgpr0 = COPY [[SHL]](i32)
    ; GFX7-NEXT: $vgpr1 = COPY [[SHL1]](i32)
    ; GFX7-NEXT: $vgpr2 = COPY [[SHL2]](i32)
    ; GFX7-NEXT: SI_RETURN implicit $vgpr0, implicit $vgpr1, implicit $vgpr2
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(<3 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32)
    %4:_(<3 x i16>) = G_TRUNC %3(<3 x i32>)
    %5:_(i32) = COPY $vgpr3
    %6:_(i32) = COPY $vgpr4
    %7:_(i32) = COPY $vgpr5
    %8:_(<3 x i32>) = G_BUILD_VECTOR %5(i32), %6(i32), %7(i32)
    %9:_(<3 x i16>) = G_TRUNC %8(<3 x i32>)
    %10:_(<3 x i16>) = G_SHL %4, %9(<3 x i16>)
    %11:_(i16), %12:_(i16), %13:_(i16) = G_UNMERGE_VALUES %10(<3 x i16>)
    %14:_(i32) = G_ANYEXT %11(i16)
    %15:_(i32) = G_ANYEXT %12(i16)
    %16:_(i32) = G_ANYEXT %13(i16)
    $vgpr0 = COPY %14(i32)
    $vgpr1 = COPY %15(i32)
    $vgpr2 = COPY %16(i32)
    SI_RETURN implicit $vgpr0, implicit $vgpr1, implicit $vgpr2

...

---
name: fma_v4f16
body: |
  bb.1:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11

    ; GFX7-LABEL: name: fma_v4f16
    ; GFX7: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9, $vgpr10, $vgpr11
    ; GFX7-NEXT: {{  $}}
    ; GFX7-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX7-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX7-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX7-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX7-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY]](i32), [[COPY1]](i32)
    ; GFX7-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY2]](i32), [[COPY3]](i32)
    ; GFX7-NEXT: [[TRUNC:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR]](<2 x i32>)
    ; GFX7-NEXT: [[TRUNC1:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR1]](<2 x i32>)
    ; GFX7-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX7-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX7-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX7-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX7-NEXT: [[BUILD_VECTOR2:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY4]](i32), [[COPY5]](i32)
    ; GFX7-NEXT: [[BUILD_VECTOR3:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY6]](i32), [[COPY7]](i32)
    ; GFX7-NEXT: [[TRUNC2:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR2]](<2 x i32>)
    ; GFX7-NEXT: [[TRUNC3:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR3]](<2 x i32>)
    ; GFX7-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX7-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX7-NEXT: [[COPY10:%[0-9]+]]:_(i32) = COPY $vgpr10
    ; GFX7-NEXT: [[COPY11:%[0-9]+]]:_(i32) = COPY $vgpr11
    ; GFX7-NEXT: [[BUILD_VECTOR4:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY8]](i32), [[COPY9]](i32)
    ; GFX7-NEXT: [[BUILD_VECTOR5:%[0-9]+]]:_(<2 x i32>) = G_BUILD_VECTOR [[COPY10]](i32), [[COPY11]](i32)
    ; GFX7-NEXT: [[TRUNC4:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR4]](<2 x i32>)
    ; GFX7-NEXT: [[TRUNC5:%[0-9]+]]:_(<2 x i16>) = G_TRUNC [[BUILD_VECTOR5]](<2 x i32>)
    ; GFX7-NEXT: [[BITCAST:%[0-9]+]]:_(<2 x f16>) = G_BITCAST [[TRUNC]](<2 x i16>)
    ; GFX7-NEXT: [[BITCAST1:%[0-9]+]]:_(<2 x f16>) = G_BITCAST [[TRUNC1]](<2 x i16>)
    ; GFX7-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST %87(i16)
    ; GFX7-NEXT: [[BITCAST3:%[0-9]+]]:_(f16) = G_BITCAST %93(i16)
    ; GFX7-NEXT: [[BITCAST4:%[0-9]+]]:_(f16) = G_BITCAST %88(i16)
    ; GFX7-NEXT: [[BITCAST5:%[0-9]+]]:_(f16) = G_BITCAST %94(i16)
    ; GFX7-NEXT: [[BITCAST6:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[BITCAST1]](<2 x f16>)
    ; GFX7-NEXT: [[BITCAST7:%[0-9]+]]:_(i32) = G_BITCAST [[BITCAST6]](<2 x i16>)
    ; GFX7-NEXT: [[TRUNC6:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST7]](i32)
    ; GFX7-NEXT: [[C:%[0-9]+]]:_(i32) = G_CONSTANT i32 16
    ; GFX7-NEXT: [[LSHR:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST7]], [[C]](i32)
    ; GFX7-NEXT: [[TRUNC7:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR]](i32)
    ; GFX7-NEXT: [[BITCAST8:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[BITCAST]](<2 x f16>)
    ; GFX7-NEXT: [[BITCAST9:%[0-9]+]]:_(i32) = G_BITCAST [[BITCAST8]](<2 x i16>)
    ; GFX7-NEXT: [[TRUNC8:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST9]](i32)
    ; GFX7-NEXT: [[LSHR1:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST9]], [[C]](i32)
    ; GFX7-NEXT: [[TRUNC9:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR1]](i32)
    ; GFX7-NEXT: [[BITCAST10:%[0-9]+]]:_(<2 x f16>) = G_BITCAST [[TRUNC2]](<2 x i16>)
    ; GFX7-NEXT: [[BITCAST11:%[0-9]+]]:_(<2 x f16>) = G_BITCAST [[TRUNC3]](<2 x i16>)
    ; GFX7-NEXT: [[BITCAST12:%[0-9]+]]:_(f16) = G_BITCAST %98(i16)
    ; GFX7-NEXT: [[BITCAST13:%[0-9]+]]:_(f16) = G_BITCAST %103(i16)
    ; GFX7-NEXT: [[BITCAST14:%[0-9]+]]:_(f16) = G_BITCAST %99(i16)
    ; GFX7-NEXT: [[BITCAST15:%[0-9]+]]:_(f16) = G_BITCAST %104(i16)
    ; GFX7-NEXT: [[BITCAST16:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[BITCAST11]](<2 x f16>)
    ; GFX7-NEXT: [[BITCAST17:%[0-9]+]]:_(i32) = G_BITCAST [[BITCAST16]](<2 x i16>)
    ; GFX7-NEXT: [[TRUNC10:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST17]](i32)
    ; GFX7-NEXT: [[LSHR2:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST17]], [[C]](i32)
    ; GFX7-NEXT: [[TRUNC11:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR2]](i32)
    ; GFX7-NEXT: [[BITCAST18:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[BITCAST10]](<2 x f16>)
    ; GFX7-NEXT: [[BITCAST19:%[0-9]+]]:_(i32) = G_BITCAST [[BITCAST18]](<2 x i16>)
    ; GFX7-NEXT: [[TRUNC12:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST19]](i32)
    ; GFX7-NEXT: [[LSHR3:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST19]], [[C]](i32)
    ; GFX7-NEXT: [[TRUNC13:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR3]](i32)
    ; GFX7-NEXT: [[BITCAST20:%[0-9]+]]:_(<2 x f16>) = G_BITCAST [[TRUNC4]](<2 x i16>)
    ; GFX7-NEXT: [[BITCAST21:%[0-9]+]]:_(<2 x f16>) = G_BITCAST [[TRUNC5]](<2 x i16>)
    ; GFX7-NEXT: [[BITCAST22:%[0-9]+]]:_(f16) = G_BITCAST %108(i16)
    ; GFX7-NEXT: [[BITCAST23:%[0-9]+]]:_(f16) = G_BITCAST %113(i16)
    ; GFX7-NEXT: [[BITCAST24:%[0-9]+]]:_(f16) = G_BITCAST %109(i16)
    ; GFX7-NEXT: [[BITCAST25:%[0-9]+]]:_(f16) = G_BITCAST %114(i16)
    ; GFX7-NEXT: [[BITCAST26:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[BITCAST21]](<2 x f16>)
    ; GFX7-NEXT: [[BITCAST27:%[0-9]+]]:_(i32) = G_BITCAST [[BITCAST26]](<2 x i16>)
    ; GFX7-NEXT: [[TRUNC14:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST27]](i32)
    ; GFX7-NEXT: [[LSHR4:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST27]], [[C]](i32)
    ; GFX7-NEXT: [[TRUNC15:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR4]](i32)
    ; GFX7-NEXT: [[BITCAST28:%[0-9]+]]:_(<2 x i16>) = G_BITCAST [[BITCAST20]](<2 x f16>)
    ; GFX7-NEXT: [[BITCAST29:%[0-9]+]]:_(i32) = G_BITCAST [[BITCAST28]](<2 x i16>)
    ; GFX7-NEXT: [[TRUNC16:%[0-9]+]]:_(i16) = G_TRUNC [[BITCAST29]](i32)
    ; GFX7-NEXT: [[LSHR5:%[0-9]+]]:_(i32) = G_LSHR [[BITCAST29]], [[C]](i32)
    ; GFX7-NEXT: [[TRUNC17:%[0-9]+]]:_(i16) = G_TRUNC [[LSHR5]](i32)
    ; GFX7-NEXT: [[FPEXT:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST2]](f16)
    ; GFX7-NEXT: [[FPEXT1:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST12]](f16)
    ; GFX7-NEXT: [[FPEXT2:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST22]](f16)
    ; GFX7-NEXT: [[FMA:%[0-9]+]]:_(f32) = G_FMA [[FPEXT]], [[FPEXT1]], [[FPEXT2]]
    ; GFX7-NEXT: [[FPTRUNC:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMA]](f32)
    ; GFX7-NEXT: [[FPEXT3:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST4]](f16)
    ; GFX7-NEXT: [[FPEXT4:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST14]](f16)
    ; GFX7-NEXT: [[FPEXT5:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST24]](f16)
    ; GFX7-NEXT: [[FMA1:%[0-9]+]]:_(f32) = G_FMA [[FPEXT3]], [[FPEXT4]], [[FPEXT5]]
    ; GFX7-NEXT: [[FPTRUNC1:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMA1]](f32)
    ; GFX7-NEXT: [[FPEXT6:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST3]](f16)
    ; GFX7-NEXT: [[FPEXT7:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST13]](f16)
    ; GFX7-NEXT: [[FPEXT8:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST23]](f16)
    ; GFX7-NEXT: [[FMA2:%[0-9]+]]:_(f32) = G_FMA [[FPEXT6]], [[FPEXT7]], [[FPEXT8]]
    ; GFX7-NEXT: [[FPTRUNC2:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMA2]](f32)
    ; GFX7-NEXT: [[FPEXT9:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST5]](f16)
    ; GFX7-NEXT: [[FPEXT10:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST15]](f16)
    ; GFX7-NEXT: [[FPEXT11:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST25]](f16)
    ; GFX7-NEXT: [[FMA3:%[0-9]+]]:_(f32) = G_FMA [[FPEXT9]], [[FPEXT10]], [[FPEXT11]]
    ; GFX7-NEXT: [[FPTRUNC3:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMA3]](f32)
    ; GFX7-NEXT: [[BITCAST30:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC]](f16)
    ; GFX7-NEXT: [[BITCAST31:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC1]](f16)
    ; GFX7-NEXT: [[BITCAST32:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC2]](f16)
    ; GFX7-NEXT: [[BITCAST33:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC3]](f16)
    ; GFX7-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST30]](i16)
    ; GFX7-NEXT: [[ANYEXT1:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST31]](i16)
    ; GFX7-NEXT: [[ANYEXT2:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST32]](i16)
    ; GFX7-NEXT: [[ANYEXT3:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST33]](i16)
    ; GFX7-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX7-NEXT: $vgpr1 = COPY [[ANYEXT1]](i32)
    ; GFX7-NEXT: $vgpr2 = COPY [[ANYEXT2]](i32)
    ; GFX7-NEXT: $vgpr3 = COPY [[ANYEXT3]](i32)
    ; GFX7-NEXT: SI_RETURN implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(<4 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32), %3(i32)
    %5:_(<4 x i16>) = G_TRUNC %4(<4 x i32>)
    %6:_(i32) = COPY $vgpr4
    %7:_(i32) = COPY $vgpr5
    %8:_(i32) = COPY $vgpr6
    %9:_(i32) = COPY $vgpr7
    %10:_(<4 x i32>) = G_BUILD_VECTOR %6(i32), %7(i32), %8(i32), %9(i32)
    %11:_(<4 x i16>) = G_TRUNC %10(<4 x i32>)
    %12:_(i32) = COPY $vgpr8
    %13:_(i32) = COPY $vgpr9
    %14:_(i32) = COPY $vgpr10
    %15:_(i32) = COPY $vgpr11
    %16:_(<4 x i32>) = G_BUILD_VECTOR %12(i32), %13(i32), %14(i32), %15(i32)
    %17:_(<4 x i16>) = G_TRUNC %16(<4 x i32>)
    %18:_(<4 x f16>) = G_BITCAST %5(<4 x i16>)
    %19:_(<4 x f16>) = G_BITCAST %11(<4 x i16>)
    %20:_(<4 x f16>) = G_BITCAST %17(<4 x i16>)
    %21:_(<4 x f16>) = G_FMA %18, %19, %20
    %22:_(<4 x i16>) = G_BITCAST %21(<4 x f16>)
    %23:_(i16), %24:_(i16), %25:_(i16), %26:_(i16) = G_UNMERGE_VALUES %22(<4 x i16>)
    %27:_(i32) = G_ANYEXT %23(i16)
    %28:_(i32) = G_ANYEXT %24(i16)
    %29:_(i32) = G_ANYEXT %25(i16)
    %30:_(i32) = G_ANYEXT %26(i16)
    $vgpr0 = COPY %27(i32)
    $vgpr1 = COPY %28(i32)
    $vgpr2 = COPY %29(i32)
    $vgpr3 = COPY %30(i32)
    SI_RETURN implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3
...

---
name: maxnum_v5i16
body: |
  bb.1:
    liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9

    ; GFX7-LABEL: name: maxnum_v5i16
    ; GFX7: liveins: $vgpr0, $vgpr1, $vgpr2, $vgpr3, $vgpr4, $vgpr5, $vgpr6, $vgpr7, $vgpr8, $vgpr9
    ; GFX7-NEXT: {{  $}}
    ; GFX7-NEXT: [[COPY:%[0-9]+]]:_(i32) = COPY $vgpr0
    ; GFX7-NEXT: [[COPY1:%[0-9]+]]:_(i32) = COPY $vgpr1
    ; GFX7-NEXT: [[COPY2:%[0-9]+]]:_(i32) = COPY $vgpr2
    ; GFX7-NEXT: [[COPY3:%[0-9]+]]:_(i32) = COPY $vgpr3
    ; GFX7-NEXT: [[COPY4:%[0-9]+]]:_(i32) = COPY $vgpr4
    ; GFX7-NEXT: [[COPY5:%[0-9]+]]:_(i32) = COPY $vgpr5
    ; GFX7-NEXT: [[COPY6:%[0-9]+]]:_(i32) = COPY $vgpr6
    ; GFX7-NEXT: [[COPY7:%[0-9]+]]:_(i32) = COPY $vgpr7
    ; GFX7-NEXT: [[COPY8:%[0-9]+]]:_(i32) = COPY $vgpr8
    ; GFX7-NEXT: [[COPY9:%[0-9]+]]:_(i32) = COPY $vgpr9
    ; GFX7-NEXT: [[TRUNC:%[0-9]+]]:_(i16) = G_TRUNC [[COPY]](i32)
    ; GFX7-NEXT: [[TRUNC1:%[0-9]+]]:_(i16) = G_TRUNC [[COPY1]](i32)
    ; GFX7-NEXT: [[TRUNC2:%[0-9]+]]:_(i16) = G_TRUNC [[COPY2]](i32)
    ; GFX7-NEXT: [[TRUNC3:%[0-9]+]]:_(i16) = G_TRUNC [[COPY3]](i32)
    ; GFX7-NEXT: [[TRUNC4:%[0-9]+]]:_(i16) = G_TRUNC [[COPY4]](i32)
    ; GFX7-NEXT: [[BITCAST:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC]](i16)
    ; GFX7-NEXT: [[BITCAST1:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC1]](i16)
    ; GFX7-NEXT: [[BITCAST2:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC2]](i16)
    ; GFX7-NEXT: [[BITCAST3:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC3]](i16)
    ; GFX7-NEXT: [[BITCAST4:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC4]](i16)
    ; GFX7-NEXT: [[TRUNC5:%[0-9]+]]:_(i16) = G_TRUNC [[COPY5]](i32)
    ; GFX7-NEXT: [[TRUNC6:%[0-9]+]]:_(i16) = G_TRUNC [[COPY6]](i32)
    ; GFX7-NEXT: [[TRUNC7:%[0-9]+]]:_(i16) = G_TRUNC [[COPY7]](i32)
    ; GFX7-NEXT: [[TRUNC8:%[0-9]+]]:_(i16) = G_TRUNC [[COPY8]](i32)
    ; GFX7-NEXT: [[TRUNC9:%[0-9]+]]:_(i16) = G_TRUNC [[COPY9]](i32)
    ; GFX7-NEXT: [[BITCAST5:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC5]](i16)
    ; GFX7-NEXT: [[BITCAST6:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC6]](i16)
    ; GFX7-NEXT: [[BITCAST7:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC7]](i16)
    ; GFX7-NEXT: [[BITCAST8:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC8]](i16)
    ; GFX7-NEXT: [[BITCAST9:%[0-9]+]]:_(f16) = G_BITCAST [[TRUNC9]](i16)
    ; GFX7-NEXT: [[FPEXT:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST]](f16)
    ; GFX7-NEXT: [[FPEXT1:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST5]](f16)
    ; GFX7-NEXT: [[FMAXNUM_IEEE:%[0-9]+]]:_(f32) = G_FMAXNUM_IEEE [[FPEXT]], [[FPEXT1]]
    ; GFX7-NEXT: [[FPTRUNC:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMAXNUM_IEEE]](f32)
    ; GFX7-NEXT: [[FPEXT2:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST1]](f16)
    ; GFX7-NEXT: [[FPEXT3:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST6]](f16)
    ; GFX7-NEXT: [[FMAXNUM_IEEE1:%[0-9]+]]:_(f32) = G_FMAXNUM_IEEE [[FPEXT2]], [[FPEXT3]]
    ; GFX7-NEXT: [[FPTRUNC1:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMAXNUM_IEEE1]](f32)
    ; GFX7-NEXT: [[FPEXT4:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST2]](f16)
    ; GFX7-NEXT: [[FPEXT5:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST7]](f16)
    ; GFX7-NEXT: [[FMAXNUM_IEEE2:%[0-9]+]]:_(f32) = G_FMAXNUM_IEEE [[FPEXT4]], [[FPEXT5]]
    ; GFX7-NEXT: [[FPTRUNC2:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMAXNUM_IEEE2]](f32)
    ; GFX7-NEXT: [[FPEXT6:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST3]](f16)
    ; GFX7-NEXT: [[FPEXT7:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST8]](f16)
    ; GFX7-NEXT: [[FMAXNUM_IEEE3:%[0-9]+]]:_(f32) = G_FMAXNUM_IEEE [[FPEXT6]], [[FPEXT7]]
    ; GFX7-NEXT: [[FPTRUNC3:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMAXNUM_IEEE3]](f32)
    ; GFX7-NEXT: [[FPEXT8:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST4]](f16)
    ; GFX7-NEXT: [[FPEXT9:%[0-9]+]]:_(f32) = G_FPEXT [[BITCAST9]](f16)
    ; GFX7-NEXT: [[FMAXNUM_IEEE4:%[0-9]+]]:_(f32) = G_FMAXNUM_IEEE [[FPEXT8]], [[FPEXT9]]
    ; GFX7-NEXT: [[FPTRUNC4:%[0-9]+]]:_(f16) = G_FPTRUNC [[FMAXNUM_IEEE4]](f32)
    ; GFX7-NEXT: [[BITCAST10:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC]](f16)
    ; GFX7-NEXT: [[BITCAST11:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC1]](f16)
    ; GFX7-NEXT: [[BITCAST12:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC2]](f16)
    ; GFX7-NEXT: [[BITCAST13:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC3]](f16)
    ; GFX7-NEXT: [[BITCAST14:%[0-9]+]]:_(i16) = G_BITCAST [[FPTRUNC4]](f16)
    ; GFX7-NEXT: [[ANYEXT:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST10]](i16)
    ; GFX7-NEXT: [[ANYEXT1:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST11]](i16)
    ; GFX7-NEXT: [[ANYEXT2:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST12]](i16)
    ; GFX7-NEXT: [[ANYEXT3:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST13]](i16)
    ; GFX7-NEXT: [[ANYEXT4:%[0-9]+]]:_(i32) = G_ANYEXT [[BITCAST14]](i16)
    ; GFX7-NEXT: $vgpr0 = COPY [[ANYEXT]](i32)
    ; GFX7-NEXT: $vgpr1 = COPY [[ANYEXT1]](i32)
    ; GFX7-NEXT: $vgpr2 = COPY [[ANYEXT2]](i32)
    ; GFX7-NEXT: $vgpr3 = COPY [[ANYEXT3]](i32)
    ; GFX7-NEXT: $vgpr4 = COPY [[ANYEXT4]](i32)
    ; GFX7-NEXT: SI_RETURN_TO_EPILOG implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4
    %0:_(i32) = COPY $vgpr0
    %1:_(i32) = COPY $vgpr1
    %2:_(i32) = COPY $vgpr2
    %3:_(i32) = COPY $vgpr3
    %4:_(i32) = COPY $vgpr4
    %5:_(<5 x i32>) = G_BUILD_VECTOR %0(i32), %1(i32), %2(i32), %3(i32), %4(i32)
    %6:_(<5 x i16>) = G_TRUNC %5(<5 x i32>)
    %7:_(i32) = COPY $vgpr5
    %8:_(i32) = COPY $vgpr6
    %9:_(i32) = COPY $vgpr7
    %10:_(i32) = COPY $vgpr8
    %11:_(i32) = COPY $vgpr9
    %12:_(<5 x i32>) = G_BUILD_VECTOR %7(i32), %8(i32), %9(i32), %10(i32), %11(i32)
    %13:_(<5 x i16>) = G_TRUNC %12(<5 x i32>)
    %14:_(<5 x f16>) = G_BITCAST %6(<5 x i16>)
    %15:_(<5 x f16>) = G_BITCAST %13(<5 x i16>)
    %16:_(<5 x f16>) = G_FMAXNUM %14, %15
    %17:_(<5 x i16>) = G_BITCAST %16(<5 x f16>)
    %18:_(i16), %19:_(i16), %20:_(i16), %21:_(i16), %22:_(i16) = G_UNMERGE_VALUES %17(<5 x i16>)
    %23:_(i32) = G_ANYEXT %18(i16)
    %24:_(i32) = G_ANYEXT %19(i16)
    %25:_(i32) = G_ANYEXT %20(i16)
    %26:_(i32) = G_ANYEXT %21(i16)
    %27:_(i32) = G_ANYEXT %22(i16)
    $vgpr0 = COPY %23(i32)
    $vgpr1 = COPY %24(i32)
    $vgpr2 = COPY %25(i32)
    $vgpr3 = COPY %26(i32)
    $vgpr4 = COPY %27(i32)
    SI_RETURN_TO_EPILOG implicit $vgpr0, implicit $vgpr1, implicit $vgpr2, implicit $vgpr3, implicit $vgpr4
...
