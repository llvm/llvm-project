; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -global-isel -new-reg-bank-select -mtriple=amdgcn-amd-amdpal -mcpu=gfx1100 -mattr=+unaligned-access-mode < %s | FileCheck --check-prefix=GFX11 %s
; RUN: llc -global-isel -new-reg-bank-select -mtriple=amdgcn-amd-amdpal -mcpu=gfx1200 -mattr=+unaligned-access-mode < %s | FileCheck --check-prefix=GFX12 %s

define amdgpu_ps void @sextload_and_zextload_P1_i8_not_uniform_mmo_gfx12(ptr addrspace(1) inreg %ptra, ptr addrspace(1) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: sextload_and_zextload_P1_i8_not_uniform_mmo_gfx12:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    global_load_i8 v3, v2, s[0:1] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    global_load_u8 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_and_zextload_P1_i8_not_uniform_mmo_gfx12:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    global_load_i8 v3, v2, s[0:1] scope:SCOPE_SYS
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    global_load_u8 v2, v2, s[2:3] scope:SCOPE_SYS
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s0, v3
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load volatile i8, ptr addrspace(1) %ptra
  %a32 = sext i8 %a to i32
  %b = load volatile i8, ptr addrspace(1) %ptrb
  %b32 = zext i8 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @sextload_P1_i8_not_align4_or_not_uniform_mmo_gfx11(ptr addrspace(1) inreg %ptra, ptr addrspace(1) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: sextload_P1_i8_not_align4_or_not_uniform_mmo_gfx11:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_i8 v3, v2, s[0:1]
; GFX11-NEXT:    global_load_i8 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_P1_i8_not_align4_or_not_uniform_mmo_gfx11:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    s_load_i8 s0, s[0:1], 0x0
; GFX12-NEXT:    global_load_i8 v2, v2, s[2:3] scope:SCOPE_SYS
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i8, ptr addrspace(1) %ptra
  %a32 = sext i8 %a to i32
  %b = load volatile i8, ptr addrspace(1) %ptrb, align 4
  %b32 = sext i8 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @zextload_P1_i8_not_align4_or_not_uniform_mmo_gfx11(ptr addrspace(1) inreg %ptra, ptr addrspace(1) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: zextload_P1_i8_not_align4_or_not_uniform_mmo_gfx11:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_u8 v3, v2, s[0:1]
; GFX11-NEXT:    global_load_u8 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: zextload_P1_i8_not_align4_or_not_uniform_mmo_gfx11:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    s_load_u8 s0, s[0:1], 0x0
; GFX12-NEXT:    global_load_u8 v2, v2, s[2:3] scope:SCOPE_SYS
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i8, ptr addrspace(1) %ptra
  %a32 = zext i8 %a to i32
  %b = load volatile i8, ptr addrspace(1) %ptrb, align 4
  %b32 = zext i8 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @sextload_P1_i16_not_natural_align_or_not_uniform_mmo_gfx12(ptr addrspace(1) inreg %ptra, ptr addrspace(1) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: sextload_P1_i16_not_natural_align_or_not_uniform_mmo_gfx12:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_i16 v3, v2, s[0:1]
; GFX11-NEXT:    global_load_i16 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_P1_i16_not_natural_align_or_not_uniform_mmo_gfx12:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    s_clause 0x1
; GFX12-NEXT:    global_load_i16 v3, v2, s[0:1]
; GFX12-NEXT:    global_load_i16 v2, v2, s[2:3] scope:SCOPE_SYS
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s0, v3
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i16, ptr addrspace(1) %ptra, align 1
  %a32 = sext i16 %a to i32
  %b = load volatile i16, ptr addrspace(1) %ptrb
  %b32 = sext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @sextload_P1_i16_not_align4_or_not_uniform_mmo_gfx11(ptr addrspace(1) inreg %ptra, ptr addrspace(1) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: sextload_P1_i16_not_align4_or_not_uniform_mmo_gfx11:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_i16 v3, v2, s[0:1]
; GFX11-NEXT:    global_load_i16 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_P1_i16_not_align4_or_not_uniform_mmo_gfx11:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    s_load_i16 s0, s[0:1], 0x0
; GFX12-NEXT:    global_load_i16 v2, v2, s[2:3] scope:SCOPE_SYS
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i16, ptr addrspace(1) %ptra
  %a32 = sext i16 %a to i32
  %b = load volatile i16, ptr addrspace(1) %ptrb, align 4
  %b32 = sext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @zextload_P1_i16_not_natural_align_or_not_uniform_mmo_gfx12(ptr addrspace(1) inreg %ptra, ptr addrspace(1) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: zextload_P1_i16_not_natural_align_or_not_uniform_mmo_gfx12:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_u16 v3, v2, s[0:1]
; GFX11-NEXT:    global_load_u16 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: zextload_P1_i16_not_natural_align_or_not_uniform_mmo_gfx12:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    s_clause 0x1
; GFX12-NEXT:    global_load_u16 v3, v2, s[0:1]
; GFX12-NEXT:    global_load_u16 v2, v2, s[2:3] scope:SCOPE_SYS
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s0, v3
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i16, ptr addrspace(1) %ptra, align 1
  %a32 = zext i16 %a to i32
  %b = load volatile i16, ptr addrspace(1) %ptrb
  %b32 = zext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @zextload_P1_i16_not_align4_or_not_uniform_mmo_gfx11(ptr addrspace(1) inreg %ptra, ptr addrspace(1) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: zextload_P1_i16_not_align4_or_not_uniform_mmo_gfx11:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_u16 v3, v2, s[0:1]
; GFX11-NEXT:    global_load_u16 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: zextload_P1_i16_not_align4_or_not_uniform_mmo_gfx11:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    s_load_u16 s0, s[0:1], 0x0
; GFX12-NEXT:    global_load_u16 v2, v2, s[2:3] scope:SCOPE_SYS
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i16, ptr addrspace(1) %ptra
  %a32 = zext i16 %a to i32
  %b = load volatile i16, ptr addrspace(1) %ptrb, align 4
  %b32 = zext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}



define amdgpu_ps void @sextload_and_zextload_P3_i8(ptr addrspace(3) inreg %ptra, ptr addrspace(3) inreg %ptrb, ptr addrspace(3) %out) {
; GFX11-LABEL: sextload_and_zextload_P3_i8:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_dual_mov_b32 v1, s0 :: v_dual_mov_b32 v2, s1
; GFX11-NEXT:    ds_load_i8 v1, v1
; GFX11-NEXT:    ds_load_u8 v2, v2
; GFX11-NEXT:    s_waitcnt lgkmcnt(1)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v1
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v1, s0
; GFX11-NEXT:    ds_store_b32 v0, v1
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_and_zextload_P3_i8:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_dual_mov_b32 v1, s0 :: v_dual_mov_b32 v2, s1
; GFX12-NEXT:    ds_load_i8 v1, v1
; GFX12-NEXT:    ds_load_u8 v2, v2
; GFX12-NEXT:    s_wait_dscnt 0x1
; GFX12-NEXT:    v_readfirstlane_b32 s0, v1
; GFX12-NEXT:    s_wait_dscnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_wait_alu 0xfffe
; GFX12-NEXT:    v_mov_b32_e32 v1, s0
; GFX12-NEXT:    ds_store_b32 v0, v1
; GFX12-NEXT:    s_endpgm
  %a = load volatile i8, ptr addrspace(3) %ptra
  %a32 = sext i8 %a to i32
  %b = load volatile i8, ptr addrspace(3) %ptrb
  %b32 = zext i8 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(3) %out
  ret void
}

define amdgpu_ps void @sextload_and_zextload_P3_i16(ptr addrspace(3) inreg %ptra, ptr addrspace(3) inreg %ptrb, ptr addrspace(3) %out) {
; GFX11-LABEL: sextload_and_zextload_P3_i16:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_dual_mov_b32 v1, s0 :: v_dual_mov_b32 v2, s1
; GFX11-NEXT:    ds_load_i16 v1, v1
; GFX11-NEXT:    ds_load_u16 v2, v2
; GFX11-NEXT:    s_waitcnt lgkmcnt(1)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v1
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v1, s0
; GFX11-NEXT:    ds_store_b32 v0, v1
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_and_zextload_P3_i16:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_dual_mov_b32 v1, s0 :: v_dual_mov_b32 v2, s1
; GFX12-NEXT:    ds_load_i16 v1, v1
; GFX12-NEXT:    ds_load_u16 v2, v2
; GFX12-NEXT:    s_wait_dscnt 0x1
; GFX12-NEXT:    v_readfirstlane_b32 s0, v1
; GFX12-NEXT:    s_wait_dscnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_wait_alu 0xfffe
; GFX12-NEXT:    v_mov_b32_e32 v1, s0
; GFX12-NEXT:    ds_store_b32 v0, v1
; GFX12-NEXT:    s_endpgm
  %a = load volatile i16, ptr addrspace(3) %ptra
  %a32 = sext i16 %a to i32
  %b = load volatile i16, ptr addrspace(3) %ptrb
  %b32 = zext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(3) %out
  ret void
}



define amdgpu_ps void @sextload_and_zextload_P4_i8_not_uniform_mmo_gfx12(ptr addrspace(4) inreg %ptra, ptr addrspace(4) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: sextload_and_zextload_P4_i8_not_uniform_mmo_gfx12:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_i8 v3, v2, s[0:1] glc dlc
; GFX11-NEXT:    global_load_u8 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(1)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_and_zextload_P4_i8_not_uniform_mmo_gfx12:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    s_load_i8 s0, s[0:1], 0x0
; GFX12-NEXT:    s_load_u8 s1, s[2:3], 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load volatile i8, ptr addrspace(4) %ptra
  %a32 = sext i8 %a to i32
  %b = load volatile i8, ptr addrspace(4) %ptrb
  %b32 = zext i8 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @sextload_P4_i8_not_align4_or_not_uniform_mmo_gfx11(ptr addrspace(4) inreg %ptra, ptr addrspace(4) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: sextload_P4_i8_not_align4_or_not_uniform_mmo_gfx11:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    global_load_i8 v2, v2, s[0:1]
; GFX11-NEXT:    s_load_b32 s0, s[2:3], 0x0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    s_sext_i32_i8 s0, s0
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s1, s0
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_P4_i8_not_align4_or_not_uniform_mmo_gfx11:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    s_load_i8 s0, s[0:1], 0x0
; GFX12-NEXT:    s_load_i8 s1, s[2:3], 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i8, ptr addrspace(4) %ptra
  %a32 = sext i8 %a to i32
  %b = load volatile i8, ptr addrspace(4) %ptrb, align 4
  %b32 = sext i8 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @zextload_P4_i8_not_align4_or_not_uniform_mmo_gfx11(ptr addrspace(4) inreg %ptra, ptr addrspace(4) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: zextload_P4_i8_not_align4_or_not_uniform_mmo_gfx11:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    global_load_u8 v2, v2, s[0:1]
; GFX11-NEXT:    s_load_b32 s0, s[2:3], 0x0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    s_and_b32 s0, s0, 0xff
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s1, s0
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: zextload_P4_i8_not_align4_or_not_uniform_mmo_gfx11:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    s_load_u8 s0, s[0:1], 0x0
; GFX12-NEXT:    s_load_u8 s1, s[2:3], 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i8, ptr addrspace(4) %ptra
  %a32 = zext i8 %a to i32
  %b = load volatile i8, ptr addrspace(4) %ptrb, align 4
  %b32 = zext i8 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @sextload_P4_i16_not_natural_align_or_not_uniform_mmo_gfx12(ptr addrspace(4) inreg %ptra, ptr addrspace(4) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: sextload_P4_i16_not_natural_align_or_not_uniform_mmo_gfx12:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_i16 v3, v2, s[0:1]
; GFX11-NEXT:    global_load_i16 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(1)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_P4_i16_not_natural_align_or_not_uniform_mmo_gfx12:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    global_load_i16 v2, v2, s[0:1]
; GFX12-NEXT:    s_load_i16 s0, s[2:3], 0x0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s1, s0
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i16, ptr addrspace(4) %ptra, align 1
  %a32 = sext i16 %a to i32
  %b = load volatile i16, ptr addrspace(4) %ptrb
  %b32 = sext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @sextload_P4_i16_not_align4_or_not_uniform_mmo_gfx11(ptr addrspace(4) inreg %ptra, ptr addrspace(4) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: sextload_P4_i16_not_align4_or_not_uniform_mmo_gfx11:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    global_load_i16 v2, v2, s[0:1]
; GFX11-NEXT:    s_load_b32 s0, s[2:3], 0x0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    s_sext_i32_i16 s0, s0
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s1, s0
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: sextload_P4_i16_not_align4_or_not_uniform_mmo_gfx11:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    s_load_i16 s0, s[0:1], 0x0
; GFX12-NEXT:    s_load_i16 s1, s[2:3], 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i16, ptr addrspace(4) %ptra
  %a32 = sext i16 %a to i32
  %b = load volatile i16, ptr addrspace(4) %ptrb, align 4
  %b32 = sext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @zextload_P4_i16_not_natural_align_or_not_uniform_mmo_gfx12(ptr addrspace(4) inreg %ptra, ptr addrspace(4) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: zextload_P4_i16_not_natural_align_or_not_uniform_mmo_gfx12:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    s_clause 0x1
; GFX11-NEXT:    global_load_u16 v3, v2, s[0:1]
; GFX11-NEXT:    global_load_u16 v2, v2, s[2:3] glc dlc
; GFX11-NEXT:    s_waitcnt vmcnt(1)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v3
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s0, s1
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: zextload_P4_i16_not_natural_align_or_not_uniform_mmo_gfx12:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    v_mov_b32_e32 v2, 0
; GFX12-NEXT:    global_load_u16 v2, v2, s[0:1]
; GFX12-NEXT:    s_load_u16 s0, s[2:3], 0x0
; GFX12-NEXT:    s_wait_loadcnt 0x0
; GFX12-NEXT:    v_readfirstlane_b32 s1, v2
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s1, s0
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i16, ptr addrspace(4) %ptra, align 1
  %a32 = zext i16 %a to i32
  %b = load volatile i16, ptr addrspace(4) %ptrb
  %b32 = zext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @zextload_P4_i16_not_align4_or_not_uniform_mmo_gfx11(ptr addrspace(4) inreg %ptra, ptr addrspace(4) inreg %ptrb, ptr addrspace(1) %out) {
; GFX11-LABEL: zextload_P4_i16_not_align4_or_not_uniform_mmo_gfx11:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    global_load_u16 v2, v2, s[0:1]
; GFX11-NEXT:    s_load_b32 s0, s[2:3], 0x0
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    s_and_b32 s0, s0, 0xffff
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s1, v2
; GFX11-NEXT:    s_add_i32 s0, s1, s0
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    v_mov_b32_e32 v2, s0
; GFX11-NEXT:    global_store_b32 v[0:1], v2, off
; GFX11-NEXT:    s_endpgm
;
; GFX12-LABEL: zextload_P4_i16_not_align4_or_not_uniform_mmo_gfx11:
; GFX12:       ; %bb.0:
; GFX12-NEXT:    s_load_u16 s0, s[0:1], 0x0
; GFX12-NEXT:    s_load_u16 s1, s[2:3], 0x0
; GFX12-NEXT:    s_wait_kmcnt 0x0
; GFX12-NEXT:    s_add_co_i32 s0, s0, s1
; GFX12-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX12-NEXT:    v_mov_b32_e32 v2, s0
; GFX12-NEXT:    global_store_b32 v[0:1], v2, off
; GFX12-NEXT:    s_endpgm
  %a = load i16, ptr addrspace(4) %ptra
  %a32 = zext i16 %a to i32
  %b = load volatile i16, ptr addrspace(4) %ptrb, align 4
  %b32 = zext i16 %b to i32
  %res = add i32 %a32, %b32
  store i32 %res, ptr addrspace(1) %out
  ret void
}
