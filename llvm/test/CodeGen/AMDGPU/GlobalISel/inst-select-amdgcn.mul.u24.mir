# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=amdgcn -mcpu=tahiti -run-pass=instruction-select -verify-machineinstrs %s -o -  | FileCheck -check-prefix=GCN %s

---
name: mul_u24_vsv
legalized: true
regBankSelected: true
tracksRegLiveness: true

body: |
  bb.0:
    liveins: $sgpr0, $vgpr0
    ; GCN-LABEL: name: mul_u24_vsv
    ; GCN: liveins: $sgpr0, $vgpr0
    ; GCN-NEXT: {{  $}}
    ; GCN-NEXT: [[COPY:%[0-9]+]]:sreg_32 = COPY $sgpr0
    ; GCN-NEXT: [[COPY1:%[0-9]+]]:vgpr_32 = COPY $vgpr0
    ; GCN-NEXT: [[V_MUL_U32_U24_e64_:%[0-9]+]]:vgpr_32 = V_MUL_U32_U24_e64 [[COPY]], [[COPY1]], 0, implicit $exec
    ; GCN-NEXT: S_ENDPGM 0, implicit [[V_MUL_U32_U24_e64_]]
    %0:sgpr(i32) = COPY $sgpr0
    %1:vgpr(i32) = COPY $vgpr0
    %2:vgpr(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.mul.u24), %0(i32), %1(i32)
    S_ENDPGM 0, implicit %2(i32)
...

---
name: mul_u24_vvs
legalized: true
regBankSelected: true
tracksRegLiveness: true

body: |
  bb.0:
    liveins: $sgpr0, $vgpr0
    ; GCN-LABEL: name: mul_u24_vvs
    ; GCN: liveins: $sgpr0, $vgpr0
    ; GCN-NEXT: {{  $}}
    ; GCN-NEXT: [[COPY:%[0-9]+]]:vgpr_32 = COPY $vgpr0
    ; GCN-NEXT: [[COPY1:%[0-9]+]]:sreg_32 = COPY $sgpr0
    ; GCN-NEXT: [[V_MUL_U32_U24_e64_:%[0-9]+]]:vgpr_32 = V_MUL_U32_U24_e64 [[COPY]], [[COPY1]], 0, implicit $exec
    ; GCN-NEXT: S_ENDPGM 0, implicit [[V_MUL_U32_U24_e64_]]
    %0:vgpr(i32) = COPY $vgpr0
    %1:sgpr(i32) = COPY $sgpr0
    %2:vgpr(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.mul.u24), %0(i32), %1(i32)
    S_ENDPGM 0, implicit %2(i32)
...

---
name: mul_u24_vvv
legalized: true
regBankSelected: true
tracksRegLiveness: true

body: |
  bb.0:
    liveins: $vgpr0, $vgpr1
    ; GCN-LABEL: name: mul_u24_vvv
    ; GCN: liveins: $vgpr0, $vgpr1
    ; GCN-NEXT: {{  $}}
    ; GCN-NEXT: [[COPY:%[0-9]+]]:vgpr_32 = COPY $vgpr0
    ; GCN-NEXT: [[COPY1:%[0-9]+]]:vgpr_32 = COPY $vgpr1
    ; GCN-NEXT: [[V_MUL_U32_U24_e64_:%[0-9]+]]:vgpr_32 = V_MUL_U32_U24_e64 [[COPY]], [[COPY1]], 0, implicit $exec
    ; GCN-NEXT: S_ENDPGM 0, implicit [[V_MUL_U32_U24_e64_]]
    %0:vgpr(i32) = COPY $vgpr0
    %1:vgpr(i32) = COPY $vgpr1
    %2:vgpr(i32) = G_INTRINSIC intrinsic(@llvm.amdgcn.mul.u24), %0(i32), %1(i32)
    S_ENDPGM 0, implicit %2(i32)
...
