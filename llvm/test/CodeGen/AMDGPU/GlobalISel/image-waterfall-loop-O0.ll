; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -global-isel -O0 -mtriple=amdgcn-amd-amdhsa -mcpu=gfx1031 -verify-machineinstrs -o - %s | FileCheck %s

; Make sure the waterfall loop does not fail the verifier after regalloc fast
define <4 x float> @waterfall_loop(<8 x i32> %vgpr_srd) {
; CHECK-LABEL: waterfall_loop:
; CHECK:       ; %bb.0: ; %bb
; CHECK-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; CHECK-NEXT:    s_waitcnt_vscnt null, 0x0
; CHECK-NEXT:    s_or_saveexec_b32 s4, -1
; CHECK-NEXT:    buffer_store_dword v15, off, s[0:3], s32 offset:76 ; 4-byte Folded Spill
; CHECK-NEXT:    s_mov_b32 exec_lo, s4
; CHECK-NEXT:    v_mov_b32_e32 v14, v1
; CHECK-NEXT:    v_mov_b32_e32 v13, v2
; CHECK-NEXT:    v_mov_b32_e32 v12, v3
; CHECK-NEXT:    v_mov_b32_e32 v11, v4
; CHECK-NEXT:    v_mov_b32_e32 v10, v5
; CHECK-NEXT:    v_mov_b32_e32 v9, v6
; CHECK-NEXT:    v_mov_b32_e32 v8, v7
; CHECK-NEXT:    ; kill: def $vgpr0 killed $vgpr0 def $vgpr0_vgpr1_vgpr2_vgpr3_vgpr4_vgpr5_vgpr6_vgpr7 killed $exec
; CHECK-NEXT:    v_mov_b32_e32 v1, v14
; CHECK-NEXT:    v_mov_b32_e32 v2, v13
; CHECK-NEXT:    v_mov_b32_e32 v3, v12
; CHECK-NEXT:    v_mov_b32_e32 v4, v11
; CHECK-NEXT:    v_mov_b32_e32 v5, v10
; CHECK-NEXT:    v_mov_b32_e32 v6, v9
; CHECK-NEXT:    v_mov_b32_e32 v7, v8
; CHECK-NEXT:    buffer_store_dword v0, off, s[0:3], s32 offset:40 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v1, off, s[0:3], s32 offset:44 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v2, off, s[0:3], s32 offset:48 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v3, off, s[0:3], s32 offset:52 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v4, off, s[0:3], s32 offset:56 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v5, off, s[0:3], s32 offset:60 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v6, off, s[0:3], s32 offset:64 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v7, off, s[0:3], s32 offset:68 ; 4-byte Folded Spill
; CHECK-NEXT:    s_mov_b32 s8, 0
; CHECK-NEXT:    s_mov_b32 s4, s8
; CHECK-NEXT:    s_mov_b32 s5, s8
; CHECK-NEXT:    s_mov_b32 s6, s8
; CHECK-NEXT:    s_mov_b32 s7, s8
; CHECK-NEXT:    v_writelane_b32 v15, s4, 0
; CHECK-NEXT:    v_writelane_b32 v15, s5, 1
; CHECK-NEXT:    v_writelane_b32 v15, s6, 2
; CHECK-NEXT:    v_writelane_b32 v15, s7, 3
; CHECK-NEXT:    s_mov_b32 s6, 0
; CHECK-NEXT:    s_mov_b32 s4, s6
; CHECK-NEXT:    s_mov_b32 s5, s6
; CHECK-NEXT:    v_mov_b32_e32 v9, s5
; CHECK-NEXT:    v_mov_b32_e32 v8, s4
; CHECK-NEXT:    buffer_store_dword v8, off, s[0:3], s32 offset:32 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v9, off, s[0:3], s32 offset:36 ; 4-byte Folded Spill
; CHECK-NEXT:    v_mov_b32_e32 v9, v1
; CHECK-NEXT:    v_mov_b32_e32 v8, v0
; CHECK-NEXT:    buffer_store_dword v8, off, s[0:3], s32 offset:24 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v9, off, s[0:3], s32 offset:28 ; 4-byte Folded Spill
; CHECK-NEXT:    v_mov_b32_e32 v9, v3
; CHECK-NEXT:    v_mov_b32_e32 v8, v2
; CHECK-NEXT:    buffer_store_dword v8, off, s[0:3], s32 offset:16 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v9, off, s[0:3], s32 offset:20 ; 4-byte Folded Spill
; CHECK-NEXT:    v_mov_b32_e32 v9, v5
; CHECK-NEXT:    v_mov_b32_e32 v8, v4
; CHECK-NEXT:    buffer_store_dword v8, off, s[0:3], s32 offset:8 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v9, off, s[0:3], s32 offset:12 ; 4-byte Folded Spill
; CHECK-NEXT:    v_mov_b32_e32 v0, v6
; CHECK-NEXT:    v_mov_b32_e32 v1, v7
; CHECK-NEXT:    buffer_store_dword v0, off, s[0:3], s32 ; 4-byte Folded Spill
; CHECK-NEXT:    buffer_store_dword v1, off, s[0:3], s32 offset:4 ; 4-byte Folded Spill
; CHECK-NEXT:    s_mov_b32 s4, exec_lo
; CHECK-NEXT:    v_writelane_b32 v15, s4, 4
; CHECK-NEXT:  .LBB0_1: ; =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    buffer_load_dword v0, off, s[0:3], s32 ; 4-byte Folded Reload
; CHECK-NEXT:    buffer_load_dword v1, off, s[0:3], s32 offset:4 ; 4-byte Folded Reload
; CHECK-NEXT:    buffer_load_dword v2, off, s[0:3], s32 offset:8 ; 4-byte Folded Reload
; CHECK-NEXT:    buffer_load_dword v3, off, s[0:3], s32 offset:12 ; 4-byte Folded Reload
; CHECK-NEXT:    buffer_load_dword v4, off, s[0:3], s32 offset:16 ; 4-byte Folded Reload
; CHECK-NEXT:    buffer_load_dword v5, off, s[0:3], s32 offset:20 ; 4-byte Folded Reload
; CHECK-NEXT:    buffer_load_dword v6, off, s[0:3], s32 offset:24 ; 4-byte Folded Reload
; CHECK-NEXT:    buffer_load_dword v7, off, s[0:3], s32 offset:28 ; 4-byte Folded Reload
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    v_readfirstlane_b32 s8, v6
; CHECK-NEXT:    v_readfirstlane_b32 s19, v7
; CHECK-NEXT:    s_mov_b32 s4, s8
; CHECK-NEXT:    s_mov_b32 s5, s19
; CHECK-NEXT:    v_cmp_eq_u64_e64 s5, s[4:5], v[6:7]
; CHECK-NEXT:    v_readfirstlane_b32 s18, v4
; CHECK-NEXT:    v_readfirstlane_b32 s17, v5
; CHECK-NEXT:    s_mov_b32 s6, s18
; CHECK-NEXT:    s_mov_b32 s7, s17
; CHECK-NEXT:    v_cmp_eq_u64_e64 s4, s[6:7], v[4:5]
; CHECK-NEXT:    s_and_b32 s5, s4, s5
; CHECK-NEXT:    v_readfirstlane_b32 s16, v2
; CHECK-NEXT:    v_readfirstlane_b32 s7, v3
; CHECK-NEXT:    s_mov_b32 s10, s16
; CHECK-NEXT:    s_mov_b32 s11, s7
; CHECK-NEXT:    v_cmp_eq_u64_e64 s4, s[10:11], v[2:3]
; CHECK-NEXT:    s_and_b32 s9, s4, s5
; CHECK-NEXT:    v_readfirstlane_b32 s6, v0
; CHECK-NEXT:    v_readfirstlane_b32 s5, v1
; CHECK-NEXT:    s_mov_b32 s10, s6
; CHECK-NEXT:    s_mov_b32 s11, s5
; CHECK-NEXT:    v_cmp_eq_u64_e64 s4, s[10:11], v[0:1]
; CHECK-NEXT:    s_and_b32 s4, s4, s9
; CHECK-NEXT:    ; kill: def $sgpr8 killed $sgpr8 def $sgpr8_sgpr9_sgpr10_sgpr11_sgpr12_sgpr13_sgpr14_sgpr15
; CHECK-NEXT:    s_mov_b32 s9, s19
; CHECK-NEXT:    s_mov_b32 s10, s18
; CHECK-NEXT:    s_mov_b32 s11, s17
; CHECK-NEXT:    s_mov_b32 s12, s16
; CHECK-NEXT:    s_mov_b32 s13, s7
; CHECK-NEXT:    s_mov_b32 s14, s6
; CHECK-NEXT:    s_mov_b32 s15, s5
; CHECK-NEXT:    v_writelane_b32 v15, s8, 5
; CHECK-NEXT:    v_writelane_b32 v15, s9, 6
; CHECK-NEXT:    v_writelane_b32 v15, s10, 7
; CHECK-NEXT:    v_writelane_b32 v15, s11, 8
; CHECK-NEXT:    v_writelane_b32 v15, s12, 9
; CHECK-NEXT:    v_writelane_b32 v15, s13, 10
; CHECK-NEXT:    v_writelane_b32 v15, s14, 11
; CHECK-NEXT:    v_writelane_b32 v15, s15, 12
; CHECK-NEXT:    s_and_saveexec_b32 s4, s4
; CHECK-NEXT:    v_writelane_b32 v15, s4, 13
; CHECK-NEXT:  ; %bb.2: ; in Loop: Header=BB0_1 Depth=1
; CHECK-NEXT:    v_readlane_b32 s4, v15, 13
; CHECK-NEXT:    buffer_load_dword v0, off, s[0:3], s32 offset:32 ; 4-byte Folded Reload
; CHECK-NEXT:    buffer_load_dword v1, off, s[0:3], s32 offset:36 ; 4-byte Folded Reload
; CHECK-NEXT:    v_readlane_b32 s8, v15, 5
; CHECK-NEXT:    v_readlane_b32 s9, v15, 6
; CHECK-NEXT:    v_readlane_b32 s10, v15, 7
; CHECK-NEXT:    v_readlane_b32 s11, v15, 8
; CHECK-NEXT:    v_readlane_b32 s12, v15, 9
; CHECK-NEXT:    v_readlane_b32 s13, v15, 10
; CHECK-NEXT:    v_readlane_b32 s14, v15, 11
; CHECK-NEXT:    v_readlane_b32 s15, v15, 12
; CHECK-NEXT:    v_readlane_b32 s16, v15, 0
; CHECK-NEXT:    v_readlane_b32 s17, v15, 1
; CHECK-NEXT:    v_readlane_b32 s18, v15, 2
; CHECK-NEXT:    v_readlane_b32 s19, v15, 3
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    image_sample v0, v[0:1], s[8:15], s[16:19] dmask:0x1 dim:SQ_RSRC_IMG_2D
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    buffer_store_dword v0, off, s[0:3], s32 offset:72 ; 4-byte Folded Spill
; CHECK-NEXT:    s_xor_b32 exec_lo, exec_lo, s4
; CHECK-NEXT:    s_cbranch_execnz .LBB0_1
; CHECK-NEXT:  ; %bb.3:
; CHECK-NEXT:    v_readlane_b32 s4, v15, 4
; CHECK-NEXT:    s_mov_b32 exec_lo, s4
; CHECK-NEXT:  ; %bb.4:
; CHECK-NEXT:    buffer_load_dword v0, off, s[0:3], s32 offset:72 ; 4-byte Folded Reload
; CHECK-NEXT:    ; implicit-def: $sgpr4
; CHECK-NEXT:    v_mov_b32_e32 v1, s4
; CHECK-NEXT:    v_mov_b32_e32 v2, s4
; CHECK-NEXT:    v_mov_b32_e32 v3, s4
; CHECK-NEXT:    s_or_saveexec_b32 s4, -1
; CHECK-NEXT:    buffer_load_dword v15, off, s[0:3], s32 offset:76 ; 4-byte Folded Reload
; CHECK-NEXT:    s_mov_b32 exec_lo, s4
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    s_waitcnt_vscnt null, 0x0
; CHECK-NEXT:    s_setpc_b64 s[30:31]
bb:
  %ret = tail call <4 x float> @llvm.amdgcn.image.sample.2d.v4f32.f32(i32 1, float 0.000000e+00, float 0.000000e+00, <8 x i32> %vgpr_srd, <4 x i32> zeroinitializer, i1 false, i32 0, i32 0)
  ret <4 x float> %ret
}

declare <4 x float> @llvm.amdgcn.image.sample.2d.v4f32.f32(i32 immarg, float, float, <8 x i32>, <4 x i32>, i1 immarg, i32 immarg, i32 immarg) #0

attributes #0 = { nounwind readonly willreturn }
