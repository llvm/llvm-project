; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc -march=amdgcn -mcpu=gfx1250 -verify-machineinstrs < %s | FileCheck %s --check-prefix=GFX1250
; RUN: llc -march=amdgcn -mcpu=gfx1250 -global-isel -verify-machineinstrs < %s | FileCheck %s --check-prefix=GISEL

define amdgpu_ps void @test_wmma_f32_16x16x4_f32(<2 x float> %A, <2 x float> %B, <8 x float> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f32_16x16x4_f32:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f32_16x16x4_f32 v[4:11], v[0:1], v[2:3], v[4:11]
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[12:13], v[8:11], off offset:16
; GFX1250-NEXT:    global_store_b128 v[12:13], v[4:7], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f32_16x16x4_f32:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f32_16x16x4_f32 v[4:11], v[0:1], v[2:3], v[4:11]
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[12:13], v[4:7], off
; GISEL-NEXT:    global_store_b128 v[12:13], v[8:11], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.f32.16x16x4.f32.v8f32.v2f32(i1 0, <2 x float> %A, i1 0, <2 x float> %B, i16 0, <8 x float> %C)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f32_16x16x32_bf16(<16 x bfloat> %A, <16 x bfloat> %B, <8 x float> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f32_16x16x32_bf16:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f32_16x16x32_bf16 v[16:23], v[0:7], v[8:15], v[16:23]
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GFX1250-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f32_16x16x32_bf16:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_dual_lshrrev_b32 v26, 16, v0 :: v_dual_lshrrev_b32 v27, 16, v1
; GISEL-NEXT:    v_dual_lshrrev_b32 v28, 16, v2 :: v_dual_lshrrev_b32 v29, 16, v3
; GISEL-NEXT:    v_dual_lshrrev_b32 v30, 16, v4 :: v_dual_lshrrev_b32 v31, 16, v5
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(SKIP_4) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v26 :: v_dual_lshlrev_b32 v27, 16, v27
; GISEL-NEXT:    v_and_b32_e32 v0, 0xffff, v0
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v28, 16, v28 :: v_dual_lshrrev_b32 v32, 16, v6
; GISEL-NEXT:    v_and_b32_e32 v2, 0xffff, v2
; GISEL-NEXT:    v_dual_lshrrev_b32 v33, 16, v7 :: v_dual_bitop2_b32 v0, v26, v0 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshlrev_b32 v27, 16, v30 :: v_dual_bitop2_b32 v1, v27, v1 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v29 :: v_dual_bitop2_b32 v2, v28, v2 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v3, 0xffff, v3
; GISEL-NEXT:    v_and_b32_e32 v4, 0xffff, v4
; GISEL-NEXT:    v_dual_lshlrev_b32 v28, 16, v31 :: v_dual_lshlrev_b32 v29, 16, v32
; GISEL-NEXT:    v_and_b32_e32 v5, 0xffff, v5
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_4) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v30, 16, v33 :: v_dual_bitop2_b32 v3, v26, v3 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v7, 0xffff, v7
; GISEL-NEXT:    v_and_b32_e32 v6, 0xffff, v6
; GISEL-NEXT:    v_dual_lshrrev_b32 v27, 16, v9 :: v_dual_bitop2_b32 v4, v27, v4 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v26, 16, v8 :: v_dual_bitop2_b32 v5, v28, v5 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v28, 16, v10 :: v_dual_bitop2_b32 v7, v30, v7 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_1) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshrrev_b32 v29, 16, v11 :: v_dual_bitop2_b32 v6, v29, v6 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v30, 16, v12 :: v_dual_lshrrev_b32 v31, 16, v13
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v26 :: v_dual_lshlrev_b32 v27, 16, v27
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v8
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v9
; GISEL-NEXT:    v_dual_lshlrev_b32 v28, 16, v28 :: v_dual_lshrrev_b32 v32, 16, v14
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v10
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshrrev_b32 v33, 16, v15 :: v_dual_bitop2_b32 v8, v26, v8 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v27, 16, v30 :: v_dual_bitop2_b32 v9, v27, v9 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v29 :: v_dual_bitop2_b32 v10, v28, v10 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v11, 0xffff, v11
; GISEL-NEXT:    v_and_b32_e32 v12, 0xffff, v12
; GISEL-NEXT:    v_dual_lshlrev_b32 v28, 16, v31 :: v_dual_lshlrev_b32 v29, 16, v32
; GISEL-NEXT:    v_and_b32_e32 v13, 0xffff, v13
; GISEL-NEXT:    v_and_b32_e32 v14, 0xffff, v14
; GISEL-NEXT:    v_dual_lshlrev_b32 v30, 16, v33 :: v_dual_bitop2_b32 v11, v26, v11 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v15, 0xffff, v15
; GISEL-NEXT:    v_or_b32_e32 v12, v27, v12
; GISEL-NEXT:    v_or_b32_e32 v13, v28, v13
; GISEL-NEXT:    v_or_b32_e32 v14, v29, v14
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_1)
; GISEL-NEXT:    v_or_b32_e32 v15, v30, v15
; GISEL-NEXT:    v_wmma_f32_16x16x32_bf16 v[16:23], v[0:7], v[8:15], v[16:23]
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GISEL-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.f32.16x16x32.bf16.v8f32.v16bf16(i1 0, <16 x bfloat> %A, i1 0, <16 x bfloat> %B, i16 0, <8 x float> %C)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_bf16_16x16x32_bf16(<16 x bfloat> %A, <16 x bfloat> %B, <8 x bfloat> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_bf16_16x16x32_bf16:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_bf16_16x16x32_bf16 v[16:19], v[0:7], v[8:15], v[16:19]
; GFX1250-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_bf16_16x16x32_bf16:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_dual_lshrrev_b32 v22, 16, v0 :: v_dual_lshrrev_b32 v23, 16, v1
; GISEL-NEXT:    v_dual_lshrrev_b32 v24, 16, v2 :: v_dual_lshrrev_b32 v25, 16, v3
; GISEL-NEXT:    v_dual_lshrrev_b32 v26, 16, v4 :: v_dual_lshrrev_b32 v27, 16, v5
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(SKIP_4) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v22, 16, v22 :: v_dual_lshlrev_b32 v23, 16, v23
; GISEL-NEXT:    v_and_b32_e32 v0, 0xffff, v0
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v24, 16, v24 :: v_dual_lshrrev_b32 v28, 16, v6
; GISEL-NEXT:    v_and_b32_e32 v2, 0xffff, v2
; GISEL-NEXT:    v_dual_lshrrev_b32 v29, 16, v7 :: v_dual_bitop2_b32 v0, v22, v0 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshlrev_b32 v23, 16, v26 :: v_dual_bitop2_b32 v1, v23, v1 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v22, 16, v25 :: v_dual_bitop2_b32 v2, v24, v2 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v3, 0xffff, v3
; GISEL-NEXT:    v_and_b32_e32 v4, 0xffff, v4
; GISEL-NEXT:    v_dual_lshlrev_b32 v24, 16, v27 :: v_dual_lshlrev_b32 v25, 16, v28
; GISEL-NEXT:    v_and_b32_e32 v5, 0xffff, v5
; GISEL-NEXT:    v_and_b32_e32 v6, 0xffff, v6
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v29 :: v_dual_bitop2_b32 v3, v22, v3 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v7, 0xffff, v7
; GISEL-NEXT:    v_dual_lshrrev_b32 v23, 16, v9 :: v_dual_bitop2_b32 v4, v23, v4 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v22, 16, v8 :: v_dual_bitop2_b32 v5, v24, v5 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v25, 16, v11 :: v_dual_bitop2_b32 v6, v25, v6 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshrrev_b32 v24, 16, v10 :: v_dual_bitop2_b32 v7, v26, v7 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v26, 16, v12 :: v_dual_lshlrev_b32 v22, 16, v22
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v8
; GISEL-NEXT:    v_dual_lshlrev_b32 v23, 16, v23 :: v_dual_lshrrev_b32 v27, 16, v13
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v9
; GISEL-NEXT:    v_dual_lshrrev_b32 v28, 16, v14 :: v_dual_lshrrev_b32 v29, 16, v15
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_or_b32_e32 v8, v22, v8
; GISEL-NEXT:    v_dual_lshlrev_b32 v22, 16, v24 :: v_dual_bitop2_b32 v9, v23, v9 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v10
; GISEL-NEXT:    v_lshlrev_b32_e32 v23, 16, v25
; GISEL-NEXT:    v_and_b32_e32 v11, 0xffff, v11
; GISEL-NEXT:    v_dual_lshlrev_b32 v24, 16, v26 :: v_dual_lshlrev_b32 v25, 16, v27
; GISEL-NEXT:    v_and_b32_e32 v12, 0xffff, v12
; GISEL-NEXT:    v_and_b32_e32 v13, 0xffff, v13
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v28 :: v_dual_bitop2_b32 v10, v22, v10 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v14, 0xffff, v14
; GISEL-NEXT:    v_dual_lshlrev_b32 v22, 16, v29 :: v_dual_bitop2_b32 v11, v23, v11 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v24, 16, v17 :: v_dual_bitop2_b32 v12, v24, v12 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v23, 16, v16 :: v_dual_bitop2_b32 v13, v25, v13 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_2) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshrrev_b32 v26, 16, v19 :: v_dual_bitop2_b32 v14, v26, v14 bitop3:0x54
; GISEL-NEXT:    v_lshrrev_b32_e32 v25, 16, v18
; GISEL-NEXT:    v_and_b32_e32 v15, 0xffff, v15
; GISEL-NEXT:    v_lshlrev_b32_e32 v23, 16, v23
; GISEL-NEXT:    v_and_b32_e32 v16, 0xffff, v16
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v24, 16, v24 :: v_dual_lshlrev_b32 v25, 16, v25
; GISEL-NEXT:    v_and_b32_e32 v17, 0xffff, v17
; GISEL-NEXT:    v_and_b32_e32 v18, 0xffff, v18
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v26 :: v_dual_bitop2_b32 v15, v22, v15 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v19, 0xffff, v19
; GISEL-NEXT:    v_or_b32_e32 v16, v23, v16
; GISEL-NEXT:    v_or_b32_e32 v17, v24, v17
; GISEL-NEXT:    v_or_b32_e32 v18, v25, v18
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_1)
; GISEL-NEXT:    v_or_b32_e32 v19, v26, v19
; GISEL-NEXT:    v_wmma_bf16_16x16x32_bf16 v[16:19], v[0:7], v[8:15], v[16:19]
; GISEL-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x bfloat> @llvm.amdgcn.wmma.bf16.16x16x32.bf16.v8bf16.v16bf16(i1 0, <16 x bfloat> %A, i1 0, <16 x bfloat> %B, i16 0, <8 x bfloat> %C)
  store <8 x bfloat> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_bf16f32_16x16x32_bf16(<16 x bfloat> %A, <16 x bfloat> %B, <8 x float> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_bf16f32_16x16x32_bf16:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_bf16f32_16x16x32_bf16 v[26:29], v[0:7], v[8:15], v[16:23]
; GFX1250-NEXT:    global_store_b128 v[24:25], v[26:29], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_bf16f32_16x16x32_bf16:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_dual_lshrrev_b32 v26, 16, v0 :: v_dual_lshrrev_b32 v27, 16, v1
; GISEL-NEXT:    v_dual_lshrrev_b32 v28, 16, v2 :: v_dual_lshrrev_b32 v29, 16, v3
; GISEL-NEXT:    v_dual_lshrrev_b32 v30, 16, v4 :: v_dual_lshrrev_b32 v31, 16, v5
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(SKIP_4) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v26 :: v_dual_lshlrev_b32 v27, 16, v27
; GISEL-NEXT:    v_and_b32_e32 v0, 0xffff, v0
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v28, 16, v28 :: v_dual_lshrrev_b32 v32, 16, v6
; GISEL-NEXT:    v_and_b32_e32 v2, 0xffff, v2
; GISEL-NEXT:    v_dual_lshrrev_b32 v33, 16, v7 :: v_dual_bitop2_b32 v0, v26, v0 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshlrev_b32 v27, 16, v30 :: v_dual_bitop2_b32 v1, v27, v1 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v29 :: v_dual_bitop2_b32 v2, v28, v2 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v3, 0xffff, v3
; GISEL-NEXT:    v_and_b32_e32 v4, 0xffff, v4
; GISEL-NEXT:    v_dual_lshlrev_b32 v28, 16, v31 :: v_dual_lshlrev_b32 v29, 16, v32
; GISEL-NEXT:    v_and_b32_e32 v5, 0xffff, v5
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_4) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v30, 16, v33 :: v_dual_bitop2_b32 v3, v26, v3 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v7, 0xffff, v7
; GISEL-NEXT:    v_and_b32_e32 v6, 0xffff, v6
; GISEL-NEXT:    v_dual_lshrrev_b32 v27, 16, v9 :: v_dual_bitop2_b32 v4, v27, v4 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v26, 16, v8 :: v_dual_bitop2_b32 v5, v28, v5 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v28, 16, v10 :: v_dual_bitop2_b32 v7, v30, v7 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_1) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshrrev_b32 v29, 16, v11 :: v_dual_bitop2_b32 v6, v29, v6 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v30, 16, v12 :: v_dual_lshrrev_b32 v31, 16, v13
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v26 :: v_dual_lshlrev_b32 v27, 16, v27
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v8
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v9
; GISEL-NEXT:    v_dual_lshlrev_b32 v28, 16, v28 :: v_dual_lshrrev_b32 v32, 16, v14
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v10
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshrrev_b32 v33, 16, v15 :: v_dual_bitop2_b32 v8, v26, v8 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v27, 16, v30 :: v_dual_bitop2_b32 v9, v27, v9 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshlrev_b32 v26, 16, v29 :: v_dual_bitop2_b32 v10, v28, v10 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v11, 0xffff, v11
; GISEL-NEXT:    v_and_b32_e32 v12, 0xffff, v12
; GISEL-NEXT:    v_dual_lshlrev_b32 v28, 16, v31 :: v_dual_lshlrev_b32 v29, 16, v32
; GISEL-NEXT:    v_and_b32_e32 v13, 0xffff, v13
; GISEL-NEXT:    v_and_b32_e32 v14, 0xffff, v14
; GISEL-NEXT:    v_dual_lshlrev_b32 v30, 16, v33 :: v_dual_bitop2_b32 v11, v26, v11 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v15, 0xffff, v15
; GISEL-NEXT:    v_or_b32_e32 v12, v27, v12
; GISEL-NEXT:    v_or_b32_e32 v13, v28, v13
; GISEL-NEXT:    v_or_b32_e32 v14, v29, v14
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_1)
; GISEL-NEXT:    v_or_b32_e32 v15, v30, v15
; GISEL-NEXT:    v_wmma_bf16f32_16x16x32_bf16 v[26:29], v[0:7], v[8:15], v[16:23]
; GISEL-NEXT:    global_store_b128 v[24:25], v[26:29], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x bfloat> @llvm.amdgcn.wmma.bf16f32.16x16x32.bf16.v8bf16.v16bf16(i1 0, <16 x bfloat> %A, i1 0, <16 x bfloat> %B, i16 0, <8 x float> %C)
  store <8 x bfloat> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f32_16x16x64_fp8_fp8(<8 x i32> %A, <8 x i32> %B, <8 x float> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f32_16x16x64_fp8_fp8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f32_16x16x64_fp8_fp8 v[16:23], v[0:7], v[8:15], v[16:23]
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GFX1250-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f32_16x16x64_fp8_fp8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f32_16x16x64_fp8_fp8 v[16:23], v[0:7], v[8:15], v[16:23]
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GISEL-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.f32.16x16x64.fp8.fp8.v8f32.v8i32(<8 x i32> %A, <8 x i32> %B, i16 0, <8 x float> %C)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f32_16x16x64_fp8_bf8(<8 x i32> %A, <8 x i32> %B, <8 x float> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f32_16x16x64_fp8_bf8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f32_16x16x64_fp8_bf8 v[16:23], v[0:7], v[8:15], v[16:23]
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GFX1250-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f32_16x16x64_fp8_bf8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f32_16x16x64_fp8_bf8 v[16:23], v[0:7], v[8:15], v[16:23]
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GISEL-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.f32.16x16x64.fp8.bf8.v8f32.v8i32(<8 x i32> %A, <8 x i32> %B, i16 0, <8 x float> %C)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f32_16x16x64_bf8_fp8(<8 x i32> %A, <8 x i32> %B, <8 x float> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f32_16x16x64_bf8_fp8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f32_16x16x64_bf8_fp8 v[16:23], v[0:7], v[8:15], v[16:23]
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GFX1250-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f32_16x16x64_bf8_fp8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f32_16x16x64_bf8_fp8 v[16:23], v[0:7], v[8:15], v[16:23]
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GISEL-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.f32.16x16x64.bf8.fp8.v8f32.v8i32(<8 x i32> %A, <8 x i32> %B, i16 0, <8 x float> %C)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f32_16x16x64_bf8_bf8(<8 x i32> %A, <8 x i32> %B, <8 x float> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f32_16x16x64_bf8_bf8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f32_16x16x64_bf8_bf8 v[16:23], v[0:7], v[8:15], v[16:23]
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GFX1250-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f32_16x16x64_bf8_bf8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f32_16x16x64_bf8_bf8 v[16:23], v[0:7], v[8:15], v[16:23]
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GISEL-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.f32.16x16x64.bf8.bf8.v8f32.v8i32(<8 x i32> %A, <8 x i32> %B, i16 0, <8 x float> %C)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f16_16x16x64_fp8_fp8(<8 x i32> %A, <8 x i32> %B, <8 x half> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f16_16x16x64_fp8_fp8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f16_16x16x64_fp8_fp8 v[16:19], v[0:7], v[8:15], v[16:19]
; GFX1250-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f16_16x16x64_fp8_fp8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f16_16x16x64_fp8_fp8 v[16:19], v[0:7], v[8:15], v[16:19]
; GISEL-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x half> @llvm.amdgcn.wmma.f16.16x16x64.fp8.fp8.v8f16.v8i32(<8 x i32> %A, <8 x i32> %B, i16 0, <8 x half> %C)
  store <8 x half> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f16_16x16x64_fp8_bf8(<8 x i32> %A, <8 x i32> %B, <8 x half> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f16_16x16x64_fp8_bf8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f16_16x16x64_fp8_bf8 v[16:19], v[0:7], v[8:15], v[16:19]
; GFX1250-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f16_16x16x64_fp8_bf8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f16_16x16x64_fp8_bf8 v[16:19], v[0:7], v[8:15], v[16:19]
; GISEL-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x half> @llvm.amdgcn.wmma.f16.16x16x64.fp8.bf8.v8f16.v8i32(<8 x i32> %A, <8 x i32> %B, i16 0, <8 x half> %C)
  store <8 x half> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f16_16x16x64_bf8_fp8(<8 x i32> %A, <8 x i32> %B, <8 x half> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f16_16x16x64_bf8_fp8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f16_16x16x64_bf8_fp8 v[16:19], v[0:7], v[8:15], v[16:19]
; GFX1250-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f16_16x16x64_bf8_fp8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f16_16x16x64_bf8_fp8 v[16:19], v[0:7], v[8:15], v[16:19]
; GISEL-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x half> @llvm.amdgcn.wmma.f16.16x16x64.bf8.fp8.v8f16.v8i32(<8 x i32> %A, <8 x i32> %B, i16 0, <8 x half> %C)
  store <8 x half> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f16_16x16x64_bf8_bf8(<8 x i32> %A, <8 x i32> %B, <8 x half> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f16_16x16x64_bf8_bf8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f16_16x16x64_bf8_bf8 v[16:19], v[0:7], v[8:15], v[16:19]
; GFX1250-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f16_16x16x64_bf8_bf8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f16_16x16x64_bf8_bf8 v[16:19], v[0:7], v[8:15], v[16:19]
; GISEL-NEXT:    global_store_b128 v[20:21], v[16:19], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x half> @llvm.amdgcn.wmma.f16.16x16x64.bf8.bf8.v8f16.v8i32(<8 x i32> %A, <8 x i32> %B, i16 0, <8 x half> %C)
  store <8 x half> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_i32_16x16x64_iu8(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_i32_16x16x64_iu8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_i32_16x16x64_iu8 v[16:23], v[0:7], v[8:15], v[16:23]
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GFX1250-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_i32_16x16x64_iu8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_i32_16x16x64_iu8 v[16:23], v[0:7], v[8:15], v[16:23]
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GISEL-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.wmma.i32.16x16x64.iu8.v8i32.v8i32(i1 0, <8 x i32> %A, i1 0, <8 x i32> %B, <8 x i32> %C)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_i32_16x16x128_iu4(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_i32_16x16x128_iu4:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_i32_16x16x128_iu4 v[16:23], v[0:7], v[8:15], v[16:23]
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GFX1250-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_i32_16x16x128_iu4:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_i32_16x16x128_iu4 v[16:23], v[0:7], v[8:15], v[16:23]
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[24:25], v[16:19], off
; GISEL-NEXT:    global_store_b128 v[24:25], v[20:23], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.wmma.i32.16x16x128.iu4.v8i32.v8i32(i1 0, <8 x i32> %A, i1 0, <8 x i32> %B, <8 x i32> %C)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_f32_16x16x128_f8f6f4(<16 x i32> %A, <16 x i32> %B, <8 x float> %C, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_f32_16x16x128_f8f6f4:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39] matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GFX1250-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_f32_16x16x128_f8f6f4:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39] matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GISEL-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.f32.16x16x128.f8f6f4.v8f32.v16i32(i32 1, <16 x i32> %A, i32 2, <16 x i32> %B, i16 0, <8 x float> %C)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_scale_f32_16x16x128_f8f6f4(<16 x i32> %A, <16 x i32> %B, <8 x float> %C, i32 %scale_src0, i32 %scale_src1, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_scale_f32_16x16x128_f8f6f4:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_scale_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], v40, v41 matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_a_scale:MATRIX_SCALE_ROW1 matrix_b_scale:MATRIX_SCALE_ROW1
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[42:43], v[36:39], off offset:16
; GFX1250-NEXT:    global_store_b128 v[42:43], v[32:35], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_scale_f32_16x16x128_f8f6f4:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_scale_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], v40, v41 matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_a_scale:MATRIX_SCALE_ROW1 matrix_b_scale:MATRIX_SCALE_ROW1
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[42:43], v[32:35], off
; GISEL-NEXT:    global_store_b128 v[42:43], v[36:39], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.scale.f32.16x16x128.f8f6f4.v8f32.v16i32(i32 1, <16 x i32> %A, i32 2, <16 x i32> %B, i16 0, <8 x float> %C, i32 1, i32 %scale_src0, i32 1, i32 %scale_src1, i1 false, i1 false)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_scale_f32_16x16x128_f8f6f4_ss(<16 x i32> %A, <16 x i32> %B, <8 x float> %C, i32 inreg %scale_src0, i32 inreg %scale_src1, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_scale_f32_16x16x128_f8f6f4_ss:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_scale_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], s0, s1 matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_b_scale:MATRIX_SCALE_ROW1 matrix_a_reuse
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GFX1250-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_scale_f32_16x16x128_f8f6f4_ss:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_scale_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], s0, s1 matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_b_scale:MATRIX_SCALE_ROW1 matrix_a_reuse
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GISEL-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.scale.f32.16x16x128.f8f6f4.v8f32.v16i32(i32 1, <16 x i32> %A, i32 2, <16 x i32> %B, i16 0, <8 x float> %C, i32 2, i32 %scale_src0, i32 1, i32 %scale_src1, i1 true, i1 false)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_scale_f32_16x16x128_f8f6f4_si_scale(<16 x i32> %A, <16 x i32> %B, <8 x float> %C, i32 inreg %scale_src0, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_scale_f32_16x16x128_f8f6f4_si_scale:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_mov_b32_e32 v42, 0x64
; GFX1250-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX1250-NEXT:    v_wmma_scale_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], s0, v42 matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_a_scale:MATRIX_SCALE_ROW1 matrix_b_reuse
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GFX1250-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_scale_f32_16x16x128_f8f6f4_si_scale:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_mov_b32_e32 v42, 0x64
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GISEL-NEXT:    v_wmma_scale_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], s0, v42 matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_a_scale:MATRIX_SCALE_ROW1 matrix_b_reuse
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GISEL-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.scale.f32.16x16x128.f8f6f4.v8f32.v16i32(i32 1, <16 x i32> %A, i32 2, <16 x i32> %B, i16 0, <8 x float> %C, i32 3, i32 %scale_src0, i32 0, i32 100, i1 false, i1 true)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_scale16_f32_16x16x128_f8f6f4(<16 x i32> %A, <16 x i32> %B, <8 x float> %C, i64 %scale_src0, i64 %scale_src1, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_scale16_f32_16x16x128_f8f6f4:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_scale16_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], v[40:41], v[42:43] matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_a_scale:MATRIX_SCALE_ROW1 matrix_b_scale:MATRIX_SCALE_ROW1
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[44:45], v[36:39], off offset:16
; GFX1250-NEXT:    global_store_b128 v[44:45], v[32:35], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_scale16_f32_16x16x128_f8f6f4:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_scale16_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], v[40:41], v[42:43] matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_a_scale:MATRIX_SCALE_ROW1 matrix_b_scale:MATRIX_SCALE_ROW1
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[44:45], v[32:35], off
; GISEL-NEXT:    global_store_b128 v[44:45], v[36:39], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.scale16.f32.16x16x128.f8f6f4.v8f32.v16i32(i32 1, <16 x i32> %A, i32 2, <16 x i32> %B, i16 0, <8 x float> %C, i32 1, i64 %scale_src0, i32 1, i64 %scale_src1, i1 false, i1 false)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_scale16_f32_16x16x128_f8f6f4_ss(<16 x i32> %A, <16 x i32> %B, <8 x float> %C, i64 inreg %scale_src0, i64 inreg %scale_src1, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_scale16_f32_16x16x128_f8f6f4_ss:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_wmma_scale16_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], s[0:1], s[2:3] matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_b_scale:MATRIX_SCALE_ROW1 matrix_a_reuse
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GFX1250-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_scale16_f32_16x16x128_f8f6f4_ss:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_wmma_scale16_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], s[0:1], s[2:3] matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_b_scale:MATRIX_SCALE_ROW1 matrix_a_reuse
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GISEL-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.scale16.f32.16x16x128.f8f6f4.v8f32.v16i32(i32 1, <16 x i32> %A, i32 2, <16 x i32> %B, i16 0, <8 x float> %C, i32 2, i64 %scale_src0, i32 1, i64 %scale_src1, i1 true, i1 false)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_wmma_scale16_f32_16x16x128_f8f6f4_si_scale(<16 x i32> %A, <16 x i32> %B, <8 x float> %C, i64 inreg %scale_src0, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_wmma_scale16_f32_16x16x128_f8f6f4_si_scale:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_mov_b64_e32 v[42:43], 0x64
; GFX1250-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX1250-NEXT:    v_wmma_scale16_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], s[0:1], v[42:43] matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_a_scale:MATRIX_SCALE_ROW1 matrix_b_reuse
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GFX1250-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_wmma_scale16_f32_16x16x128_f8f6f4_si_scale:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_mov_b64_e32 v[42:43], 0x64
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GISEL-NEXT:    v_wmma_scale16_f32_16x16x128_f8f6f4 v[32:39], v[0:15], v[16:31], v[32:39], s[0:1], v[42:43] matrix_a_fmt:MATRIX_FMT_BF8 matrix_b_fmt:MATRIX_FMT_FP6 matrix_a_scale:MATRIX_SCALE_ROW1 matrix_b_reuse
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[40:41], v[32:35], off
; GISEL-NEXT:    global_store_b128 v[40:41], v[36:39], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.wmma.scale16.f32.16x16x128.f8f6f4.v8f32.v16i32(i32 1, <16 x i32> %A, i32 2, <16 x i32> %B, i16 0, <8 x float> %C, i32 3, i64 %scale_src0, i32 0, i64 100, i1 false, i1 true)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f32_16x16x64_bf16(<16 x bfloat> %A, <32 x bfloat> %B, <8 x float> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f32_16x16x64_bf16:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f32_16x16x64_bf16 v[24:31], v[0:7], v[8:23], v32
; GFX1250-NEXT:    v_dual_mov_b32 v35, v34 :: v_dual_mov_b32 v34, v33
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[34:35], v[28:31], off offset:16
; GFX1250-NEXT:    global_store_b128 v[34:35], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f32_16x16x64_bf16:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_dual_mov_b32 v42, v33 :: v_dual_mov_b32 v43, v34
; GISEL-NEXT:    v_dual_lshrrev_b32 v33, 16, v0 :: v_dual_lshrrev_b32 v34, 16, v1
; GISEL-NEXT:    v_dual_lshrrev_b32 v35, 16, v2 :: v_dual_lshrrev_b32 v37, 16, v3
; GISEL-NEXT:    v_dual_lshrrev_b32 v38, 16, v4 :: v_dual_lshrrev_b32 v39, 16, v5
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(SKIP_4) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v33, 16, v33 :: v_dual_lshlrev_b32 v36, 16, v34
; GISEL-NEXT:    v_and_b32_e32 v0, 0xffff, v0
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v40, 16, v35 :: v_dual_lshrrev_b32 v41, 16, v6
; GISEL-NEXT:    v_and_b32_e32 v2, 0xffff, v2
; GISEL-NEXT:    v_dual_lshrrev_b32 v44, 16, v7 :: v_dual_bitop2_b32 v34, v33, v0 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_or_b32_e32 v35, v36, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v0, 16, v37 :: v_dual_bitop2_b32 v36, v40, v2 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v3
; GISEL-NEXT:    v_lshlrev_b32_e32 v2, 16, v38
; GISEL-NEXT:    v_and_b32_e32 v3, 0xffff, v4
; GISEL-NEXT:    v_dual_lshlrev_b32 v4, 16, v39 :: v_dual_lshlrev_b32 v33, 16, v41
; GISEL-NEXT:    v_and_b32_e32 v5, 0xffff, v5
; GISEL-NEXT:    v_and_b32_e32 v6, 0xffff, v6
; GISEL-NEXT:    v_dual_lshlrev_b32 v41, 16, v44 :: v_dual_bitop2_b32 v37, v0, v1 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v7, 0xffff, v7
; GISEL-NEXT:    v_dual_lshrrev_b32 v0, 16, v8 :: v_dual_bitop2_b32 v38, v2, v3 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v2, 16, v10 :: v_dual_bitop2_b32 v39, v4, v5 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v1, 16, v9 :: v_dual_bitop2_b32 v40, v33, v6 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_1) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshrrev_b32 v4, 16, v12 :: v_dual_bitop2_b32 v41, v41, v7 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v3, 16, v11 :: v_dual_lshrrev_b32 v5, 16, v13
; GISEL-NEXT:    v_dual_lshlrev_b32 v0, 16, v0 :: v_dual_lshlrev_b32 v1, 16, v1
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v8
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v9
; GISEL-NEXT:    v_lshlrev_b32_e32 v2, 16, v2
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v10
; GISEL-NEXT:    v_dual_lshrrev_b32 v6, 16, v14 :: v_dual_lshrrev_b32 v7, 16, v15
; GISEL-NEXT:    v_dual_lshrrev_b32 v33, 16, v16 :: v_dual_lshrrev_b32 v44, 16, v17
; GISEL-NEXT:    v_dual_lshrrev_b32 v45, 16, v18 :: v_dual_bitop2_b32 v0, v0, v8 bitop3:0x54
; GISEL-NEXT:    v_or_b32_e32 v1, v1, v9
; GISEL-NEXT:    v_dual_lshrrev_b32 v48, 16, v21 :: v_dual_bitop2_b32 v2, v2, v10 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v3, 16, v3 :: v_dual_lshlrev_b32 v4, 16, v4
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v11
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v12
; GISEL-NEXT:    v_dual_lshlrev_b32 v5, 16, v5 :: v_dual_lshrrev_b32 v11, 16, v22
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v13
; GISEL-NEXT:    v_dual_lshrrev_b32 v46, 16, v19 :: v_dual_lshrrev_b32 v47, 16, v20
; GISEL-NEXT:    v_dual_lshrrev_b32 v12, 16, v23 :: v_dual_bitop2_b32 v3, v3, v8 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v6, 16, v6 :: v_dual_bitop2_b32 v4, v4, v9 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v7, 16, v7 :: v_dual_bitop2_b32 v5, v5, v10 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v14
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v15
; GISEL-NEXT:    v_dual_lshlrev_b32 v10, 16, v33 :: v_dual_lshlrev_b32 v14, 16, v44
; GISEL-NEXT:    v_and_b32_e32 v13, 0xffff, v16
; GISEL-NEXT:    v_and_b32_e32 v15, 0xffff, v17
; GISEL-NEXT:    v_dual_lshlrev_b32 v16, 16, v45 :: v_dual_bitop2_b32 v6, v6, v8 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v17, 0xffff, v18
; GISEL-NEXT:    v_or_b32_e32 v7, v7, v9
; GISEL-NEXT:    v_or_b32_e32 v8, v10, v13
; GISEL-NEXT:    v_dual_lshlrev_b32 v13, 16, v46 :: v_dual_bitop2_b32 v9, v14, v15 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4)
; GISEL-NEXT:    v_or_b32_e32 v10, v16, v17
; GISEL-NEXT:    v_and_b32_e32 v14, 0xffff, v19
; GISEL-NEXT:    v_lshlrev_b32_e32 v19, 16, v11
; GISEL-NEXT:    v_lshlrev_b32_e32 v15, 16, v47
; GISEL-NEXT:    v_and_b32_e32 v16, 0xffff, v20
; GISEL-NEXT:    v_lshlrev_b32_e32 v17, 16, v48
; GISEL-NEXT:    v_and_b32_e32 v18, 0xffff, v21
; GISEL-NEXT:    v_and_b32_e32 v20, 0xffff, v22
; GISEL-NEXT:    v_dual_lshlrev_b32 v21, 16, v12 :: v_dual_bitop2_b32 v11, v13, v14 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v22, 0xffff, v23
; GISEL-NEXT:    v_or_b32_e32 v12, v15, v16
; GISEL-NEXT:    v_or_b32_e32 v13, v17, v18
; GISEL-NEXT:    v_or_b32_e32 v14, v19, v20
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_1)
; GISEL-NEXT:    v_or_b32_e32 v15, v21, v22
; GISEL-NEXT:    v_swmmac_f32_16x16x64_bf16 v[24:31], v[34:41], v[0:15], v32
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[42:43], v[24:27], off
; GISEL-NEXT:    global_store_b128 v[42:43], v[28:31], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmmac.f32.16x16x64.bf16.v8f32.v16bf16.v32bf16.i16(i1 0, <16 x bfloat> %A, i1 0, <32 x bfloat> %B, <8 x float> %C, i16 %Index)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_bf16_16x16x64_bf16(<16 x bfloat> %A, <32 x bfloat> %B, <8 x bfloat> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_bf16_16x16x64_bf16:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_bf16_16x16x64_bf16 v[24:27], v[0:7], v[8:23], v28
; GFX1250-NEXT:    v_dual_mov_b32 v31, v30 :: v_dual_mov_b32 v30, v29
; GFX1250-NEXT:    global_store_b128 v[30:31], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_bf16_16x16x64_bf16:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_dual_mov_b32 v38, v29 :: v_dual_mov_b32 v39, v30
; GISEL-NEXT:    v_dual_lshrrev_b32 v29, 16, v0 :: v_dual_lshrrev_b32 v30, 16, v1
; GISEL-NEXT:    v_dual_lshrrev_b32 v31, 16, v2 :: v_dual_lshrrev_b32 v33, 16, v3
; GISEL-NEXT:    v_dual_lshrrev_b32 v34, 16, v4 :: v_dual_lshrrev_b32 v35, 16, v5
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(SKIP_4) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v29, 16, v29 :: v_dual_lshlrev_b32 v32, 16, v30
; GISEL-NEXT:    v_and_b32_e32 v0, 0xffff, v0
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v36, 16, v31 :: v_dual_lshrrev_b32 v37, 16, v6
; GISEL-NEXT:    v_and_b32_e32 v2, 0xffff, v2
; GISEL-NEXT:    v_dual_lshrrev_b32 v40, 16, v7 :: v_dual_bitop2_b32 v30, v29, v0 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_or_b32_e32 v31, v32, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v0, 16, v33 :: v_dual_bitop2_b32 v32, v36, v2 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v3
; GISEL-NEXT:    v_lshlrev_b32_e32 v2, 16, v34
; GISEL-NEXT:    v_and_b32_e32 v3, 0xffff, v4
; GISEL-NEXT:    v_dual_lshlrev_b32 v4, 16, v35 :: v_dual_lshlrev_b32 v29, 16, v37
; GISEL-NEXT:    v_and_b32_e32 v5, 0xffff, v5
; GISEL-NEXT:    v_and_b32_e32 v6, 0xffff, v6
; GISEL-NEXT:    v_dual_lshlrev_b32 v37, 16, v40 :: v_dual_bitop2_b32 v33, v0, v1 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v7, 0xffff, v7
; GISEL-NEXT:    v_dual_lshrrev_b32 v0, 16, v8 :: v_dual_bitop2_b32 v34, v2, v3 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v2, 16, v10 :: v_dual_bitop2_b32 v35, v4, v5 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v1, 16, v9 :: v_dual_bitop2_b32 v36, v29, v6 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshrrev_b32 v4, 16, v12 :: v_dual_bitop2_b32 v37, v37, v7 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v3, 16, v11 :: v_dual_lshrrev_b32 v5, 16, v13
; GISEL-NEXT:    v_dual_lshrrev_b32 v41, 16, v18 :: v_dual_lshlrev_b32 v0, 16, v0
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v8
; GISEL-NEXT:    v_dual_lshrrev_b32 v6, 16, v14 :: v_dual_lshrrev_b32 v7, 16, v15
; GISEL-NEXT:    v_dual_lshrrev_b32 v29, 16, v16 :: v_dual_lshrrev_b32 v40, 16, v17
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshlrev_b32 v1, 16, v1 :: v_dual_bitop2_b32 v0, v0, v8 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v9
; GISEL-NEXT:    v_dual_lshlrev_b32 v2, 16, v2 :: v_dual_lshlrev_b32 v3, 16, v3
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v10
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v11
; GISEL-NEXT:    v_dual_lshlrev_b32 v4, 16, v4 :: v_dual_lshrrev_b32 v46, 16, v23
; GISEL-NEXT:    v_and_b32_e32 v11, 0xffff, v12
; GISEL-NEXT:    v_dual_lshrrev_b32 v42, 16, v19 :: v_dual_lshrrev_b32 v43, 16, v20
; GISEL-NEXT:    v_dual_lshrrev_b32 v44, 16, v21 :: v_dual_lshrrev_b32 v45, 16, v22
; GISEL-NEXT:    v_dual_lshlrev_b32 v5, 16, v5 :: v_dual_bitop2_b32 v1, v1, v8 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v6, 16, v6 :: v_dual_bitop2_b32 v2, v2, v9 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v7, 16, v7 :: v_dual_bitop2_b32 v3, v3, v10 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v11, 16, v29 :: v_dual_bitop2_b32 v4, v4, v11 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v13
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v14
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v15
; GISEL-NEXT:    v_and_b32_e32 v12, 0xffff, v16
; GISEL-NEXT:    v_lshlrev_b32_e32 v13, 16, v40
; GISEL-NEXT:    v_and_b32_e32 v14, 0xffff, v17
; GISEL-NEXT:    v_or_b32_e32 v6, v6, v9
; GISEL-NEXT:    v_or_b32_e32 v5, v5, v8
; GISEL-NEXT:    v_or_b32_e32 v7, v7, v10
; GISEL-NEXT:    v_dual_lshlrev_b32 v12, 16, v42 :: v_dual_bitop2_b32 v8, v11, v12 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v16, 16, v44 :: v_dual_bitop2_b32 v9, v13, v14 bitop3:0x54
; GISEL-NEXT:    v_lshlrev_b32_e32 v10, 16, v41
; GISEL-NEXT:    v_and_b32_e32 v11, 0xffff, v18
; GISEL-NEXT:    v_and_b32_e32 v13, 0xffff, v19
; GISEL-NEXT:    v_lshlrev_b32_e32 v14, 16, v43
; GISEL-NEXT:    v_and_b32_e32 v15, 0xffff, v20
; GISEL-NEXT:    v_and_b32_e32 v17, 0xffff, v21
; GISEL-NEXT:    v_dual_lshlrev_b32 v18, 16, v45 :: v_dual_bitop2_b32 v10, v10, v11 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v19, 0xffff, v22
; GISEL-NEXT:    v_or_b32_e32 v11, v12, v13
; GISEL-NEXT:    v_or_b32_e32 v12, v14, v15
; GISEL-NEXT:    v_dual_lshrrev_b32 v16, 16, v24 :: v_dual_bitop2_b32 v13, v16, v17 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_1) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshrrev_b32 v18, 16, v25 :: v_dual_bitop2_b32 v14, v18, v19 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v19, 16, v26 :: v_dual_lshrrev_b32 v20, 16, v27
; GISEL-NEXT:    v_dual_lshlrev_b32 v16, 16, v16 :: v_dual_lshlrev_b32 v15, 16, v46
; GISEL-NEXT:    v_and_b32_e32 v17, 0xffff, v23
; GISEL-NEXT:    v_and_b32_e32 v21, 0xffff, v24
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v18, 16, v18 :: v_dual_lshlrev_b32 v19, 16, v19
; GISEL-NEXT:    v_and_b32_e32 v22, 0xffff, v25
; GISEL-NEXT:    v_and_b32_e32 v23, 0xffff, v26
; GISEL-NEXT:    v_dual_lshlrev_b32 v20, 16, v20 :: v_dual_bitop2_b32 v15, v15, v17 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v24, 0xffff, v27
; GISEL-NEXT:    v_or_b32_e32 v16, v16, v21
; GISEL-NEXT:    v_or_b32_e32 v17, v18, v22
; GISEL-NEXT:    v_or_b32_e32 v18, v19, v23
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_1)
; GISEL-NEXT:    v_or_b32_e32 v19, v20, v24
; GISEL-NEXT:    v_swmmac_bf16_16x16x64_bf16 v[16:19], v[30:37], v[0:15], v28
; GISEL-NEXT:    global_store_b128 v[38:39], v[16:19], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x bfloat> @llvm.amdgcn.swmmac.bf16.16x16x64.bf16.v8bf16.v16bf16.v32bf16.i16(i1 0, <16 x bfloat> %A, i1 0, <32 x bfloat> %B, <8 x bfloat> %C, i16 %Index)
  store <8 x bfloat> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_bf16f32_16x16x64_bf16(<16 x bfloat> %A, <32 x bfloat> %B, <8 x float> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_bf16f32_16x16x64_bf16:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_bf16f32_16x16x64_bf16 v[24:31], v[0:7], v[8:23], v32
; GFX1250-NEXT:    v_dual_mov_b32 v35, v34 :: v_dual_mov_b32 v34, v33
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[34:35], v[28:31], off offset:16
; GFX1250-NEXT:    global_store_b128 v[34:35], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_bf16f32_16x16x64_bf16:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_dual_mov_b32 v42, v33 :: v_dual_mov_b32 v43, v34
; GISEL-NEXT:    v_dual_lshrrev_b32 v33, 16, v0 :: v_dual_lshrrev_b32 v34, 16, v1
; GISEL-NEXT:    v_dual_lshrrev_b32 v35, 16, v2 :: v_dual_lshrrev_b32 v37, 16, v3
; GISEL-NEXT:    v_dual_lshrrev_b32 v38, 16, v4 :: v_dual_lshrrev_b32 v39, 16, v5
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(SKIP_4) | instid1(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v33, 16, v33 :: v_dual_lshlrev_b32 v36, 16, v34
; GISEL-NEXT:    v_and_b32_e32 v0, 0xffff, v0
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v40, 16, v35 :: v_dual_lshrrev_b32 v41, 16, v6
; GISEL-NEXT:    v_and_b32_e32 v2, 0xffff, v2
; GISEL-NEXT:    v_dual_lshrrev_b32 v44, 16, v7 :: v_dual_bitop2_b32 v34, v33, v0 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_or_b32_e32 v35, v36, v1
; GISEL-NEXT:    v_dual_lshlrev_b32 v0, 16, v37 :: v_dual_bitop2_b32 v36, v40, v2 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v1, 0xffff, v3
; GISEL-NEXT:    v_lshlrev_b32_e32 v2, 16, v38
; GISEL-NEXT:    v_and_b32_e32 v3, 0xffff, v4
; GISEL-NEXT:    v_dual_lshlrev_b32 v4, 16, v39 :: v_dual_lshlrev_b32 v33, 16, v41
; GISEL-NEXT:    v_and_b32_e32 v5, 0xffff, v5
; GISEL-NEXT:    v_and_b32_e32 v6, 0xffff, v6
; GISEL-NEXT:    v_dual_lshlrev_b32 v41, 16, v44 :: v_dual_bitop2_b32 v37, v0, v1 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v7, 0xffff, v7
; GISEL-NEXT:    v_dual_lshrrev_b32 v0, 16, v8 :: v_dual_bitop2_b32 v38, v2, v3 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v2, 16, v10 :: v_dual_bitop2_b32 v39, v4, v5 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v1, 16, v9 :: v_dual_bitop2_b32 v40, v33, v6 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(SKIP_1) | instid1(VALU_DEP_3)
; GISEL-NEXT:    v_dual_lshrrev_b32 v4, 16, v12 :: v_dual_bitop2_b32 v41, v41, v7 bitop3:0x54
; GISEL-NEXT:    v_dual_lshrrev_b32 v3, 16, v11 :: v_dual_lshrrev_b32 v5, 16, v13
; GISEL-NEXT:    v_dual_lshlrev_b32 v0, 16, v0 :: v_dual_lshlrev_b32 v1, 16, v1
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v8
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v9
; GISEL-NEXT:    v_lshlrev_b32_e32 v2, 16, v2
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v10
; GISEL-NEXT:    v_dual_lshrrev_b32 v6, 16, v14 :: v_dual_lshrrev_b32 v7, 16, v15
; GISEL-NEXT:    v_dual_lshrrev_b32 v33, 16, v16 :: v_dual_lshrrev_b32 v44, 16, v17
; GISEL-NEXT:    v_dual_lshrrev_b32 v45, 16, v18 :: v_dual_bitop2_b32 v0, v0, v8 bitop3:0x54
; GISEL-NEXT:    v_or_b32_e32 v1, v1, v9
; GISEL-NEXT:    v_dual_lshrrev_b32 v48, 16, v21 :: v_dual_bitop2_b32 v2, v2, v10 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v3, 16, v3 :: v_dual_lshlrev_b32 v4, 16, v4
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v11
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v12
; GISEL-NEXT:    v_dual_lshlrev_b32 v5, 16, v5 :: v_dual_lshrrev_b32 v11, 16, v22
; GISEL-NEXT:    v_and_b32_e32 v10, 0xffff, v13
; GISEL-NEXT:    v_dual_lshrrev_b32 v46, 16, v19 :: v_dual_lshrrev_b32 v47, 16, v20
; GISEL-NEXT:    v_dual_lshrrev_b32 v12, 16, v23 :: v_dual_bitop2_b32 v3, v3, v8 bitop3:0x54
; GISEL-NEXT:    v_dual_lshlrev_b32 v6, 16, v6 :: v_dual_bitop2_b32 v4, v4, v9 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4)
; GISEL-NEXT:    v_dual_lshlrev_b32 v7, 16, v7 :: v_dual_bitop2_b32 v5, v5, v10 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v8, 0xffff, v14
; GISEL-NEXT:    v_and_b32_e32 v9, 0xffff, v15
; GISEL-NEXT:    v_dual_lshlrev_b32 v10, 16, v33 :: v_dual_lshlrev_b32 v14, 16, v44
; GISEL-NEXT:    v_and_b32_e32 v13, 0xffff, v16
; GISEL-NEXT:    v_and_b32_e32 v15, 0xffff, v17
; GISEL-NEXT:    v_dual_lshlrev_b32 v16, 16, v45 :: v_dual_bitop2_b32 v6, v6, v8 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v17, 0xffff, v18
; GISEL-NEXT:    v_or_b32_e32 v7, v7, v9
; GISEL-NEXT:    v_or_b32_e32 v8, v10, v13
; GISEL-NEXT:    v_dual_lshlrev_b32 v13, 16, v46 :: v_dual_bitop2_b32 v9, v14, v15 bitop3:0x54
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4)
; GISEL-NEXT:    v_or_b32_e32 v10, v16, v17
; GISEL-NEXT:    v_and_b32_e32 v14, 0xffff, v19
; GISEL-NEXT:    v_lshlrev_b32_e32 v19, 16, v11
; GISEL-NEXT:    v_lshlrev_b32_e32 v15, 16, v47
; GISEL-NEXT:    v_and_b32_e32 v16, 0xffff, v20
; GISEL-NEXT:    v_lshlrev_b32_e32 v17, 16, v48
; GISEL-NEXT:    v_and_b32_e32 v18, 0xffff, v21
; GISEL-NEXT:    v_and_b32_e32 v20, 0xffff, v22
; GISEL-NEXT:    v_dual_lshlrev_b32 v21, 16, v12 :: v_dual_bitop2_b32 v11, v13, v14 bitop3:0x54
; GISEL-NEXT:    v_and_b32_e32 v22, 0xffff, v23
; GISEL-NEXT:    v_or_b32_e32 v12, v15, v16
; GISEL-NEXT:    v_or_b32_e32 v13, v17, v18
; GISEL-NEXT:    v_or_b32_e32 v14, v19, v20
; GISEL-NEXT:    s_delay_alu instid0(VALU_DEP_4) | instskip(NEXT) | instid1(VALU_DEP_1)
; GISEL-NEXT:    v_or_b32_e32 v15, v21, v22
; GISEL-NEXT:    v_swmmac_bf16f32_16x16x64_bf16 v[24:31], v[34:41], v[0:15], v32
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[42:43], v[24:27], off
; GISEL-NEXT:    global_store_b128 v[42:43], v[28:31], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmmac.bf16f32.16x16x64.bf16.v8f32.v16bf16.v32bf16.i16(i1 0, <16 x bfloat> %A, i1 0, <32 x bfloat> %B, <8 x float> %C, i16 %Index)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f32_16x16x128_fp8_fp8(<8 x i32> %A, <16 x i32> %B, <8 x float> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f32_16x16x128_fp8_fp8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f32_16x16x128_fp8_fp8 v[24:31], v[0:7], v[8:23], v32
; GFX1250-NEXT:    v_dual_mov_b32 v35, v34 :: v_dual_mov_b32 v34, v33
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[34:35], v[28:31], off offset:16
; GFX1250-NEXT:    global_store_b128 v[34:35], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f32_16x16x128_fp8_fp8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_f32_16x16x128_fp8_fp8 v[24:31], v[0:7], v[8:23], v32
; GISEL-NEXT:    v_dual_mov_b32 v36, v33 :: v_dual_mov_b32 v37, v34
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[36:37], v[24:27], off
; GISEL-NEXT:    global_store_b128 v[36:37], v[28:31], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmmac.f32.16x16x128.fp8.fp8.v8f32.v8i32.v16i32.i16(<8 x i32> %A, <16 x i32> %B, <8 x float> %C, i16 %Index)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f32_16x16x128_fp8_bf8(<8 x i32> %A, <16 x i32> %B, <8 x float> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f32_16x16x128_fp8_bf8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f32_16x16x128_fp8_bf8 v[24:31], v[0:7], v[8:23], v32
; GFX1250-NEXT:    v_dual_mov_b32 v35, v34 :: v_dual_mov_b32 v34, v33
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[34:35], v[28:31], off offset:16
; GFX1250-NEXT:    global_store_b128 v[34:35], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f32_16x16x128_fp8_bf8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_f32_16x16x128_fp8_bf8 v[24:31], v[0:7], v[8:23], v32
; GISEL-NEXT:    v_dual_mov_b32 v36, v33 :: v_dual_mov_b32 v37, v34
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[36:37], v[24:27], off
; GISEL-NEXT:    global_store_b128 v[36:37], v[28:31], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmmac.f32.16x16x128.fp8.bf8.v8f32.v8i32.v16i32.i16(<8 x i32> %A, <16 x i32> %B, <8 x float> %C, i16 %Index)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f32_16x16x128_bf8_fp8(<8 x i32> %A, <16 x i32> %B, <8 x float> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f32_16x16x128_bf8_fp8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f32_16x16x128_bf8_fp8 v[24:31], v[0:7], v[8:23], v32
; GFX1250-NEXT:    v_dual_mov_b32 v35, v34 :: v_dual_mov_b32 v34, v33
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[34:35], v[28:31], off offset:16
; GFX1250-NEXT:    global_store_b128 v[34:35], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f32_16x16x128_bf8_fp8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_f32_16x16x128_bf8_fp8 v[24:31], v[0:7], v[8:23], v32
; GISEL-NEXT:    v_dual_mov_b32 v36, v33 :: v_dual_mov_b32 v37, v34
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[36:37], v[24:27], off
; GISEL-NEXT:    global_store_b128 v[36:37], v[28:31], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmmac.f32.16x16x128.bf8.fp8.v8f32.v8i32.v16i32.i16(<8 x i32> %A, <16 x i32> %B, <8 x float> %C, i16 %Index)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f32_16x16x128_bf8_bf8(<8 x i32> %A, <16 x i32> %B, <8 x float> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f32_16x16x128_bf8_bf8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f32_16x16x128_bf8_bf8 v[24:31], v[0:7], v[8:23], v32
; GFX1250-NEXT:    v_dual_mov_b32 v35, v34 :: v_dual_mov_b32 v34, v33
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[34:35], v[28:31], off offset:16
; GFX1250-NEXT:    global_store_b128 v[34:35], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f32_16x16x128_bf8_bf8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_f32_16x16x128_bf8_bf8 v[24:31], v[0:7], v[8:23], v32
; GISEL-NEXT:    v_dual_mov_b32 v36, v33 :: v_dual_mov_b32 v37, v34
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[36:37], v[24:27], off
; GISEL-NEXT:    global_store_b128 v[36:37], v[28:31], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x float> @llvm.amdgcn.swmmac.f32.16x16x128.bf8.bf8.v8f32.v8i32.v16i32.i16(<8 x i32> %A, <16 x i32> %B, <8 x float> %C, i16 %Index)
  store <8 x float> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f16_16x16x128_fp8_fp8(<8 x i32> %A, <16 x i32> %B, <8 x half> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f16_16x16x128_fp8_fp8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f16_16x16x128_fp8_fp8 v[24:27], v[0:7], v[8:23], v28
; GFX1250-NEXT:    v_dual_mov_b32 v31, v30 :: v_dual_mov_b32 v30, v29
; GFX1250-NEXT:    global_store_b128 v[30:31], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f16_16x16x128_fp8_fp8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_f16_16x16x128_fp8_fp8 v[24:27], v[0:7], v[8:23], v28
; GISEL-NEXT:    v_dual_mov_b32 v32, v29 :: v_dual_mov_b32 v33, v30
; GISEL-NEXT:    global_store_b128 v[32:33], v[24:27], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x half> @llvm.amdgcn.swmmac.f16.16x16x128.fp8.fp8.v8f16.v8i32.v16i32.i16(<8 x i32> %A, <16 x i32> %B, <8 x half> %C, i16 %Index)
  store <8 x half> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f16_16x16x128_fp8_bf8(<8 x i32> %A, <16 x i32> %B, <8 x half> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f16_16x16x128_fp8_bf8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f16_16x16x128_fp8_bf8 v[24:27], v[0:7], v[8:23], v28
; GFX1250-NEXT:    v_dual_mov_b32 v31, v30 :: v_dual_mov_b32 v30, v29
; GFX1250-NEXT:    global_store_b128 v[30:31], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f16_16x16x128_fp8_bf8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_f16_16x16x128_fp8_bf8 v[24:27], v[0:7], v[8:23], v28
; GISEL-NEXT:    v_dual_mov_b32 v32, v29 :: v_dual_mov_b32 v33, v30
; GISEL-NEXT:    global_store_b128 v[32:33], v[24:27], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x half> @llvm.amdgcn.swmmac.f16.16x16x128.fp8.bf8.v8f16.v8i32.v16i32.i16(<8 x i32> %A, <16 x i32> %B, <8 x half> %C, i16 %Index)
  store <8 x half> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f16_16x16x128_bf8_fp8(<8 x i32> %A, <16 x i32> %B, <8 x half> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f16_16x16x128_bf8_fp8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f16_16x16x128_bf8_fp8 v[24:27], v[0:7], v[8:23], v28
; GFX1250-NEXT:    v_dual_mov_b32 v31, v30 :: v_dual_mov_b32 v30, v29
; GFX1250-NEXT:    global_store_b128 v[30:31], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f16_16x16x128_bf8_fp8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_f16_16x16x128_bf8_fp8 v[24:27], v[0:7], v[8:23], v28
; GISEL-NEXT:    v_dual_mov_b32 v32, v29 :: v_dual_mov_b32 v33, v30
; GISEL-NEXT:    global_store_b128 v[32:33], v[24:27], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x half> @llvm.amdgcn.swmmac.f16.16x16x128.bf8.fp8.v8f16.v8i32.v16i32.i16(<8 x i32> %A, <16 x i32> %B, <8 x half> %C, i16 %Index)
  store <8 x half> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_f16_16x16x128_bf8_bf8(<8 x i32> %A, <16 x i32> %B, <8 x half> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_f16_16x16x128_bf8_bf8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_f16_16x16x128_bf8_bf8 v[24:27], v[0:7], v[8:23], v28
; GFX1250-NEXT:    v_dual_mov_b32 v31, v30 :: v_dual_mov_b32 v30, v29
; GFX1250-NEXT:    global_store_b128 v[30:31], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_f16_16x16x128_bf8_bf8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_f16_16x16x128_bf8_bf8 v[24:27], v[0:7], v[8:23], v28
; GISEL-NEXT:    v_dual_mov_b32 v32, v29 :: v_dual_mov_b32 v33, v30
; GISEL-NEXT:    global_store_b128 v[32:33], v[24:27], off
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x half> @llvm.amdgcn.swmmac.f16.16x16x128.bf8.bf8.v8f16.v8i32.v16i32.i16(<8 x i32> %A, <16 x i32> %B, <8 x half> %C, i16 %Index)
  store <8 x half> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_i32_16x16x128_iu8(<8 x i32> %A, <16 x i32> %B, <8 x i32> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_i32_16x16x128_iu8:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_i32_16x16x128_iu8 v[24:31], v[0:7], v[8:23], v32
; GFX1250-NEXT:    v_dual_mov_b32 v35, v34 :: v_dual_mov_b32 v34, v33
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[34:35], v[28:31], off offset:16
; GFX1250-NEXT:    global_store_b128 v[34:35], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_i32_16x16x128_iu8:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_i32_16x16x128_iu8 v[24:31], v[0:7], v[8:23], v32
; GISEL-NEXT:    v_dual_mov_b32 v36, v33 :: v_dual_mov_b32 v37, v34
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[36:37], v[24:27], off
; GISEL-NEXT:    global_store_b128 v[36:37], v[28:31], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.swmmac.i32.16x16x128.iu8.v8i32.v8i32.v16i32.i16(i1 0, <8 x i32> %A, i1 0, <16 x i32> %B, <8 x i32> %C, i16 %Index)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}

define amdgpu_ps void @test_swmmac_i32_16x16x256_iu4(<8 x i32> %A, <16 x i32> %B, <8 x i32> %C, i16 %Index, ptr addrspace(1) %out) {
; GFX1250-LABEL: test_swmmac_i32_16x16x256_iu4:
; GFX1250:       ; %bb.0: ; %bb
; GFX1250-NEXT:    v_swmmac_i32_16x16x256_iu4 v[24:31], v[0:7], v[8:23], v32
; GFX1250-NEXT:    v_dual_mov_b32 v35, v34 :: v_dual_mov_b32 v34, v33
; GFX1250-NEXT:    s_clause 0x1
; GFX1250-NEXT:    global_store_b128 v[34:35], v[28:31], off offset:16
; GFX1250-NEXT:    global_store_b128 v[34:35], v[24:27], off
; GFX1250-NEXT:    s_endpgm
;
; GISEL-LABEL: test_swmmac_i32_16x16x256_iu4:
; GISEL:       ; %bb.0: ; %bb
; GISEL-NEXT:    v_swmmac_i32_16x16x256_iu4 v[24:31], v[0:7], v[8:23], v32
; GISEL-NEXT:    v_dual_mov_b32 v36, v33 :: v_dual_mov_b32 v37, v34
; GISEL-NEXT:    s_clause 0x1
; GISEL-NEXT:    global_store_b128 v[36:37], v[24:27], off
; GISEL-NEXT:    global_store_b128 v[36:37], v[28:31], off offset:16
; GISEL-NEXT:    s_endpgm
bb:
  %res = call <8 x i32> @llvm.amdgcn.swmmac.i32.16x16x256.iu4.v8i32.v8i32.v16i32.i16(i1 0, <8 x i32> %A, i1 0, <16 x i32> %B, <8 x i32> %C, i16 %Index)
  store <8 x i32> %res, ptr addrspace(1) %out
  ret void
}

declare <8 x float> @llvm.amdgcn.wmma.f32.16x16x4.f32.v8f32.v2f32(i1, <2 x float>, i1, <2 x float>, i16, <8 x float>)
declare <8 x float> @llvm.amdgcn.wmma.f32.16x16x32.bf16.v8f32.v16bf16(i1, <16 x bfloat>, i1, <16 x bfloat>, i16, <8 x float>)
declare <8 x bfloat> @llvm.amdgcn.wmma.bf16.16x16x32.bf16.v8bf16.v16bf16(i1, <16 x bfloat>, i1, <16 x bfloat>, i16, <8 x bfloat>)
declare <8 x bfloat> @llvm.amdgcn.wmma.bf16f32.16x16x32.bf16.v8bf16.v16bf16(i1, <16 x bfloat>, i1, <16 x bfloat>, i16, <8 x float>)
declare <8 x float> @llvm.amdgcn.wmma.f32.16x16x64.fp8.fp8.v8f32.v8i32(<8 x i32>, <8 x i32>, i16, <8 x float>)
declare <8 x float> @llvm.amdgcn.wmma.f32.16x16x64.fp8.bf8.v8f32.v8i32(<8 x i32>, <8 x i32>, i16, <8 x float>)
declare <8 x float> @llvm.amdgcn.wmma.f32.16x16x64.bf8.fp8.v8f32.v8i32(<8 x i32>, <8 x i32>, i16, <8 x float>)
declare <8 x float> @llvm.amdgcn.wmma.f32.16x16x64.bf8.bf8.v8f32.v8i32(<8 x i32>, <8 x i32>, i16, <8 x float>)
declare <8 x half> @llvm.amdgcn.wmma.f16.16x16x64.fp8.fp8.v8f16.v8i32(<8 x i32>, <8 x i32>, i16, <8 x half>)
declare <8 x half> @llvm.amdgcn.wmma.f16.16x16x64.fp8.bf8.v8f16.v8i32(<8 x i32>, <8 x i32>, i16, <8 x half>)
declare <8 x half> @llvm.amdgcn.wmma.f16.16x16x64.bf8.fp8.v8f16.v8i32(<8 x i32>, <8 x i32>, i16, <8 x half>)
declare <8 x half> @llvm.amdgcn.wmma.f16.16x16x64.bf8.bf8.v8f16.v8i32(<8 x i32>, <8 x i32>, i16, <8 x half>)
declare <8 x i32> @llvm.amdgcn.wmma.i32.16x16x64.iu8.v8i32.v8i32(i1 immarg, <8 x i32>, i1 immarg, <8 x i32>, <8 x i32>)
declare <8 x i32> @llvm.amdgcn.wmma.i32.16x16x128.iu4.v8i32.v8i32(i1 immarg, <8 x i32>, i1 immarg, <8 x i32>, <8 x i32>)
declare <8 x float> @llvm.amdgcn.wmma.f32.16x16x128.f8f6f4.v8f32.v16i32(i32, <16 x i32>, i32, <16 x i32>, i16, <8 x float>)
declare <8 x float> @llvm.amdgcn.wmma.scale.f32.16x16x128.f8f6f4.v8f32.v16i32(i32, <16 x i32>, i32, <16 x i32>, i16, <8 x float>, i32, i32, i32, i32, i1, i1)
declare <8 x float> @llvm.amdgcn.wmma.scale16.f32.16x16x128.f8f6f4.v8f32.v16i32(i32, <16 x i32>, i32, <16 x i32>, i16, <8 x float>, i32, i64, i32, i64, i1, i1)

declare <8 x float> @llvm.amdgcn.swmmac.f32.16x16x64.bf16.v8f32.v16bf16.v32bf16.i16(i1, <16 x bfloat>, i1, <32 x bfloat>, <8 x float>, i16)
declare <8 x bfloat> @llvm.amdgcn.swmmac.bf16.16x16x64.bf16.v8bf16.v16bf16.v32bf16.i16(i1, <16 x bfloat>, i1, <32 x bfloat>, <8 x bfloat>, i16)
declare <8 x float> @llvm.amdgcn.swmmac.bf16f32.16x16x64.bf16.v8f32.v16bf16.v32bf16.i16(i1, <16 x bfloat>, i1, <32 x bfloat>, <8 x float>, i16)
declare <8 x float> @llvm.amdgcn.swmmac.f32.16x16x128.fp8.fp8.v8f32.v8i32.v16i32.i16(<8 x i32>, <16 x i32>, <8 x float>, i16)
declare <8 x float> @llvm.amdgcn.swmmac.f32.16x16x128.fp8.bf8.v8f32.v8i32.v16i32.i16(<8 x i32>, <16 x i32>, <8 x float>, i16)
declare <8 x float> @llvm.amdgcn.swmmac.f32.16x16x128.bf8.fp8.v8f32.v8i32.v16i32.i16(<8 x i32>, <16 x i32>, <8 x float>, i16)
declare <8 x float> @llvm.amdgcn.swmmac.f32.16x16x128.bf8.bf8.v8f32.v8i32.v16i32.i16(<8 x i32>, <16 x i32>, <8 x float>, i16)
declare <8 x half> @llvm.amdgcn.swmmac.f16.16x16x128.fp8.fp8.v8f16.v8i32.v16i32.i16(<8 x i32>, <16 x i32>, <8 x half>, i16)
declare <8 x half> @llvm.amdgcn.swmmac.f16.16x16x128.fp8.bf8.v8f16.v8i32.v16i32.i16(<8 x i32>, <16 x i32>, <8 x half>, i16)
declare <8 x half> @llvm.amdgcn.swmmac.f16.16x16x128.bf8.fp8.v8f16.v8i32.v16i32.i16(<8 x i32>, <16 x i32>, <8 x half>, i16)
declare <8 x half> @llvm.amdgcn.swmmac.f16.16x16x128.bf8.bf8.v8f16.v8i32.v16i32.i16(<8 x i32>, <16 x i32>, <8 x half>, i16)
declare <8 x i32> @llvm.amdgcn.swmmac.i32.16x16x128.iu8.v8i32.v8i32.v16i32.i16(i1 immarg, <8 x i32>, i1 immarg, <16 x i32>, <8 x i32>, i16 %Index)
declare <8 x i32> @llvm.amdgcn.swmmac.i32.16x16x256.iu4.v8i32.v8i32.v16i32.i16(i1 immarg, <8 x i32>, i1 immarg, <16 x i32>, <8 x i32>, i16 %Index)
