; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=amdgcn -mcpu=gfx1300 -verify-machineinstrs < %s | FileCheck --check-prefix=GFX13 %s

define amdgpu_kernel void @flat_load_store_cfs_128B(ptr %in, ptr %out) {
; GFX13-LABEL: flat_load_store_cfs_128B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    v_mov_b32_e32 v0, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    flat_load_b32 v1, v0, s[0:1] cfs:CFS_128B
; GFX13-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX13-NEXT:    flat_store_b32 v0, v1, s[2:3] scope:SCOPE_SE cfs:CFS_128B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr %in, align 4, !amdgpu.cfs !{i32 1}
  store i32 %val, ptr %out, !amdgpu.cfs !{i32 1}
  ret void
}

define amdgpu_kernel void @flat_load_store_cfs_64B(ptr %in, ptr %out) {
; GFX13-LABEL: flat_load_store_cfs_64B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    v_mov_b32_e32 v0, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    flat_load_b32 v1, v0, s[0:1] cfs:CFS_64B
; GFX13-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX13-NEXT:    flat_store_b32 v0, v1, s[2:3] scope:SCOPE_SE cfs:CFS_64B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr %in, align 4, !amdgpu.cfs !{i32 2}
  store i32 %val, ptr %out, !amdgpu.cfs !{i32 2}
  ret void
}

define amdgpu_kernel void @flat_load_store_cfs_32B(ptr %in, ptr %out) {
; GFX13-LABEL: flat_load_store_cfs_32B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    v_mov_b32_e32 v0, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    flat_load_b32 v1, v0, s[0:1] cfs:CFS_32B
; GFX13-NEXT:    s_wait_loadcnt_dscnt 0x0
; GFX13-NEXT:    flat_store_b32 v0, v1, s[2:3] scope:SCOPE_SE cfs:CFS_32B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr %in, align 4, !amdgpu.cfs !{i32 3}
  store i32 %val, ptr %out, !amdgpu.cfs !{i32 3}
  ret void
}

define amdgpu_kernel void @global_load_store_cfs_128B(ptr addrspace(1) %in, ptr addrspace(1) %out) {
; GFX13-LABEL: global_load_store_cfs_128B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    v_and_b32_e32 v0, 0x3ff, v0
; GFX13-NEXT:    v_mov_b32_e32 v1, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_load_b32 v0, v0, s[0:1] scale_offset cfs:CFS_128B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[2:3] scope:SCOPE_SE cfs:CFS_128B
; GFX13-NEXT:    s_endpgm
entry:
  %tid = call i32 @llvm.amdgcn.workitem.id.x()
  %val.gep = getelementptr inbounds i32, ptr addrspace(1) %in, i32 %tid
  %val = load i32, ptr addrspace(1) %val.gep, align 4, !amdgpu.cfs !{i32 1}
  store i32 %val, ptr addrspace(1) %out, !amdgpu.cfs !{i32 1}
  ret void
}

define amdgpu_kernel void @global_load_store_cfs_64B(ptr addrspace(1) %in, ptr addrspace(1) %out) {
; GFX13-LABEL: global_load_store_cfs_64B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    v_and_b32_e32 v0, 0x3ff, v0
; GFX13-NEXT:    v_mov_b32_e32 v1, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_load_b32 v0, v0, s[0:1] scale_offset cfs:CFS_64B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[2:3] scope:SCOPE_SE cfs:CFS_64B
; GFX13-NEXT:    s_endpgm
entry:
  %tid = call i32 @llvm.amdgcn.workitem.id.x()
  %val.gep = getelementptr inbounds i32, ptr addrspace(1) %in, i32 %tid
  %val = load i32, ptr addrspace(1) %val.gep, align 4, !amdgpu.cfs !{i32 2}
  store i32 %val, ptr addrspace(1) %out, !amdgpu.cfs !{i32 2}
  ret void
}

define amdgpu_kernel void @global_load_store_cfs_32B(ptr addrspace(1) %in, ptr addrspace(1) %out) {
; GFX13-LABEL: global_load_store_cfs_32B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    v_and_b32_e32 v0, 0x3ff, v0
; GFX13-NEXT:    v_mov_b32_e32 v1, 0
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    global_load_b32 v0, v0, s[0:1] scale_offset cfs:CFS_32B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    global_store_b32 v1, v0, s[2:3] scope:SCOPE_SE cfs:CFS_32B
; GFX13-NEXT:    s_endpgm
entry:
  %tid = call i32 @llvm.amdgcn.workitem.id.x()
  %val.gep = getelementptr inbounds i32, ptr addrspace(1) %in, i32 %tid
  %val = load i32, ptr addrspace(1) %val.gep, align 4, !amdgpu.cfs !{i32 3}
  store i32 %val, ptr addrspace(1) %out, !amdgpu.cfs !{i32 3}
  ret void
}

define amdgpu_kernel void @scratch_load_store_cfs_128B(ptr addrspace(5) %in, ptr addrspace(5) %out) {
; GFX13-LABEL: scratch_load_store_cfs_128B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    scratch_load_b32 v0, off, s0 cfs:CFS_128B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    scratch_store_b32 off, v0, s1 scope:SCOPE_SE cfs:CFS_128B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr addrspace(5) %in, align 4, !amdgpu.cfs !{i32 1}
  store i32 %val, ptr addrspace(5) %out, !amdgpu.cfs !{i32 1}
  ret void
}

define amdgpu_kernel void @scratch_load_store_cfs_64B(ptr addrspace(5) %in, ptr addrspace(5) %out) {
; GFX13-LABEL: scratch_load_store_cfs_64B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    scratch_load_b32 v0, off, s0 cfs:CFS_64B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    scratch_store_b32 off, v0, s1 scope:SCOPE_SE cfs:CFS_64B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr addrspace(5) %in, align 4, !amdgpu.cfs !{i32 2}
  store i32 %val, ptr addrspace(5) %out, !amdgpu.cfs !{i32 2}
  ret void
}

define amdgpu_kernel void @scratch_load_store_cfs_32B(ptr addrspace(5) %in, ptr addrspace(5) %out) {
; GFX13-LABEL: scratch_load_store_cfs_32B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_load_b64 s[0:1], s[4:5], 0x24
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    scratch_load_b32 v0, off, s0 cfs:CFS_32B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    scratch_store_b32 off, v0, s1 scope:SCOPE_SE cfs:CFS_32B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr addrspace(5) %in, align 4, !amdgpu.cfs !{i32 3}
  store i32 %val, ptr addrspace(5) %out, !amdgpu.cfs !{i32 3}
  ret void
}

define amdgpu_kernel void @buffer_load_store_cfs_128B(ptr addrspace(7) %in, ptr addrspace(7) %out) {
; GFX13-LABEL: buffer_load_store_cfs_128B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    s_load_b32 s13, s[4:5], 0x34
; GFX13-NEXT:    s_mov_b32 s12, 0
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_mov_b32 s7, s12
; GFX13-NEXT:    s_mov_b32 s9, s12
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    s_mov_b32 s6, s3
; GFX13-NEXT:    v_mov_b32_e32 v0, s0
; GFX13-NEXT:    s_mov_b32 s8, s1
; GFX13-NEXT:    s_or_b64 s[10:11], s[6:7], s[12:13]
; GFX13-NEXT:    s_mov_b32 s13, s2
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_or_b64 s[8:9], s[8:9], s[12:13]
; GFX13-NEXT:    buffer_load_b32 v0, v0, s[8:11], null offen cfs:CFS_128B
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s13, s[4:5], 0x54
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x44
; GFX13-NEXT:    s_mov_b32 s5, s12
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_mov_b32_e32 v1, s0
; GFX13-NEXT:    s_mov_b32 s4, s3
; GFX13-NEXT:    s_mov_b32 s3, s12
; GFX13-NEXT:    s_or_b64 s[6:7], s[4:5], s[12:13]
; GFX13-NEXT:    s_mov_b32 s13, s2
; GFX13-NEXT:    s_mov_b32 s2, s1
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_or_b64 s[4:5], s[2:3], s[12:13]
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    buffer_store_b32 v0, v1, s[4:7], null offen scope:SCOPE_SE cfs:CFS_128B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr addrspace(7) %in, !amdgpu.cfs !{i32 1}
  store i32 %val, ptr addrspace(7) %out, !amdgpu.cfs !{i32 1}
  ret void
}

define amdgpu_kernel void @buffer_load_store_cfs_64B(ptr addrspace(7) %in, ptr addrspace(7) %out) {
; GFX13-LABEL: buffer_load_store_cfs_64B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    s_load_b32 s13, s[4:5], 0x34
; GFX13-NEXT:    s_mov_b32 s12, 0
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_mov_b32 s7, s12
; GFX13-NEXT:    s_mov_b32 s9, s12
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    s_mov_b32 s6, s3
; GFX13-NEXT:    v_mov_b32_e32 v0, s0
; GFX13-NEXT:    s_mov_b32 s8, s1
; GFX13-NEXT:    s_or_b64 s[10:11], s[6:7], s[12:13]
; GFX13-NEXT:    s_mov_b32 s13, s2
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_or_b64 s[8:9], s[8:9], s[12:13]
; GFX13-NEXT:    buffer_load_b32 v0, v0, s[8:11], null offen cfs:CFS_64B
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s13, s[4:5], 0x54
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x44
; GFX13-NEXT:    s_mov_b32 s5, s12
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_mov_b32_e32 v1, s0
; GFX13-NEXT:    s_mov_b32 s4, s3
; GFX13-NEXT:    s_mov_b32 s3, s12
; GFX13-NEXT:    s_or_b64 s[6:7], s[4:5], s[12:13]
; GFX13-NEXT:    s_mov_b32 s13, s2
; GFX13-NEXT:    s_mov_b32 s2, s1
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_or_b64 s[4:5], s[2:3], s[12:13]
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    buffer_store_b32 v0, v1, s[4:7], null offen scope:SCOPE_SE cfs:CFS_64B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr addrspace(7) %in, !amdgpu.cfs !{i32 2}
  store i32 %val, ptr addrspace(7) %out, !amdgpu.cfs !{i32 2}
  ret void
}

define amdgpu_kernel void @buffer_load_store_cfs_32B(ptr addrspace(7) %in, ptr addrspace(7) %out) {
; GFX13-LABEL: buffer_load_store_cfs_32B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x24
; GFX13-NEXT:    s_load_b32 s13, s[4:5], 0x34
; GFX13-NEXT:    s_mov_b32 s12, 0
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_mov_b32 s7, s12
; GFX13-NEXT:    s_mov_b32 s9, s12
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    s_mov_b32 s6, s3
; GFX13-NEXT:    v_mov_b32_e32 v0, s0
; GFX13-NEXT:    s_mov_b32 s8, s1
; GFX13-NEXT:    s_or_b64 s[10:11], s[6:7], s[12:13]
; GFX13-NEXT:    s_mov_b32 s13, s2
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_or_b64 s[8:9], s[8:9], s[12:13]
; GFX13-NEXT:    buffer_load_b32 v0, v0, s[8:11], null offen cfs:CFS_32B
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s13, s[4:5], 0x54
; GFX13-NEXT:    s_load_b128 s[0:3], s[4:5], 0x44
; GFX13-NEXT:    s_mov_b32 s5, s12
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_mov_b32_e32 v1, s0
; GFX13-NEXT:    s_mov_b32 s4, s3
; GFX13-NEXT:    s_mov_b32 s3, s12
; GFX13-NEXT:    s_or_b64 s[6:7], s[4:5], s[12:13]
; GFX13-NEXT:    s_mov_b32 s13, s2
; GFX13-NEXT:    s_mov_b32 s2, s1
; GFX13-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX13-NEXT:    s_or_b64 s[4:5], s[2:3], s[12:13]
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    buffer_store_b32 v0, v1, s[4:7], null offen scope:SCOPE_SE cfs:CFS_32B
; GFX13-NEXT:    s_endpgm
entry:
  %val = load i32, ptr addrspace(7) %in, !amdgpu.cfs !{i32 3}
  store i32 %val, ptr addrspace(7) %out, !amdgpu.cfs !{i32 3}
  ret void
}

define amdgpu_kernel void @image_load_store_cfs_128B(ptr addrspace(1) %out, <8 x i32> inreg %src, i32 %s) {
; GFX13-LABEL: image_load_store_cfs_128B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s8, s[4:5], 0x64
; GFX13-NEXT:    s_load_b256 s[0:7], s[4:5], 0x44
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s8
; GFX13-NEXT:    image_load v0, v0, s[0:7] dmask:0x1 dim:SQ_RSRC_IMG_1D cfs:CFS_128B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    image_store v0, v1, s[0:7] dmask:0x1 dim:SQ_RSRC_IMG_1D scope:SCOPE_SE cfs:CFS_128B
; GFX13-NEXT:    s_endpgm
entry:
  %val = call float @llvm.amdgcn.image.load.1d.f32.i32(i32 1, i32 %s, <8 x i32> %src, i32 0, i32 0), !amdgpu.cfs !{i32 1}
  call void @llvm.amdgcn.image.store.1d.f32.i32(float %val, i32 1, i32 0, <8 x i32> %src, i32 0, i32 0), !amdgpu.cfs !{i32 1}
  ret void
}

define amdgpu_kernel void @image_load_store_cfs_64B(ptr addrspace(1) %out, <8 x i32> inreg %src, i32 %s) {
; GFX13-LABEL: image_load_store_cfs_64B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s8, s[4:5], 0x64
; GFX13-NEXT:    s_load_b256 s[0:7], s[4:5], 0x44
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s8
; GFX13-NEXT:    image_load v0, v0, s[0:7] dmask:0x1 dim:SQ_RSRC_IMG_1D cfs:CFS_64B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    image_store v0, v1, s[0:7] dmask:0x1 dim:SQ_RSRC_IMG_1D scope:SCOPE_SE cfs:CFS_64B
; GFX13-NEXT:    s_endpgm
entry:
  %val = call float @llvm.amdgcn.image.load.1d.f32.i32(i32 1, i32 %s, <8 x i32> %src, i32 0, i32 0), !amdgpu.cfs !{i32 2}
  call void @llvm.amdgcn.image.store.1d.f32.i32(float %val, i32 1, i32 0, <8 x i32> %src, i32 0, i32 0), !amdgpu.cfs !{i32 2}
  ret void
}

define amdgpu_kernel void @image_load_store_cfs_32B(ptr addrspace(1) %out, <8 x i32> inreg %src, i32 %s) {
; GFX13-LABEL: image_load_store_cfs_32B:
; GFX13:       ; %bb.0: ; %entry
; GFX13-NEXT:    s_clause 0x1
; GFX13-NEXT:    s_load_b32 s8, s[4:5], 0x64
; GFX13-NEXT:    s_load_b256 s[0:7], s[4:5], 0x44
; GFX13-NEXT:    s_wait_kmcnt 0x0
; GFX13-NEXT:    v_dual_mov_b32 v1, 0 :: v_dual_mov_b32 v0, s8
; GFX13-NEXT:    image_load v0, v0, s[0:7] dmask:0x1 dim:SQ_RSRC_IMG_1D cfs:CFS_32B
; GFX13-NEXT:    s_wait_loadcnt 0x0
; GFX13-NEXT:    image_store v0, v1, s[0:7] dmask:0x1 dim:SQ_RSRC_IMG_1D scope:SCOPE_SE cfs:CFS_32B
; GFX13-NEXT:    s_endpgm
entry:
  %val = call float @llvm.amdgcn.image.load.1d.f32.i32(i32 1, i32 %s, <8 x i32> %src, i32 0, i32 0), !amdgpu.cfs !{i32 3}
  call void @llvm.amdgcn.image.store.1d.f32.i32(float %val, i32 1, i32 0, <8 x i32> %src, i32 0, i32 0), !amdgpu.cfs !{i32 3}
  ret void
}
