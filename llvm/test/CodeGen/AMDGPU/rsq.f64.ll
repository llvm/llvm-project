; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 2
; RUN: llc -global-isel=0 -march=amdgcn -mcpu=tahiti < %s | FileCheck -check-prefixes=GCN,SDAG,SI-SDAG %s
; RUN: llc -global-isel=1 -march=amdgcn -mcpu=tahiti < %s | FileCheck -check-prefixes=GCN,GISEL,SI-GISEL %s

; RUN: llc -global-isel=0 -march=amdgcn -mcpu=fiji < %s | FileCheck -check-prefixes=GCN,SDAG,VI-SDAG %s
; RUN: llc -global-isel=1 -march=amdgcn -mcpu=fiji < %s | FileCheck -check-prefixes=GCN,GISEL,VI-GISEL %s

declare i32 @llvm.amdgcn.workitem.id.x()
declare i32 @llvm.amdgcn.readfirstlane(i32)
declare double @llvm.sqrt.f64(double)
declare <2 x double> @llvm.sqrt.v2f64(<2 x double>)
declare double @llvm.amdgcn.sqrt.f64(double)
declare double @llvm.fabs.f64(double)

define amdgpu_ps <2 x i32> @s_rsq_f64(double inreg %x) {
; SI-SDAG-LABEL: s_rsq_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s2, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[0:1], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[0:1], s2, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[0:1], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; SI-SDAG-NEXT:    ; return to shader part epilog
;
; SI-GISEL-LABEL: s_rsq_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[0:1], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[0:1], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[0:1]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; SI-GISEL-NEXT:    ; return to shader part epilog
;
; VI-SDAG-LABEL: s_rsq_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; VI-SDAG-NEXT:    ; return to shader part epilog
;
; VI-GISEL-LABEL: s_rsq_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; VI-GISEL-NEXT:    ; return to shader part epilog
  %rsq = call contract double @llvm.sqrt.f64(double %x)
  %result = fdiv contract double 1.0, %rsq
  %cast = bitcast double %result to <2 x i32>
  %cast.0 = extractelement <2 x i32> %cast, i32 0
  %cast.1 = extractelement <2 x i32> %cast, i32 1
  %lane.0 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.0)
  %lane.1 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.1)
  %insert.0 = insertelement <2 x i32> poison, i32 %lane.0, i32 0
  %insert.1 = insertelement <2 x i32> %insert.0, i32 %lane.1, i32 1
  ret <2 x i32> %insert.1
}

define amdgpu_ps <2 x i32> @s_rsq_f64_fabs(double inreg %x) {
; SI-SDAG-LABEL: s_rsq_f64_fabs:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    v_sqrt_f64_e64 v[0:1], |s[0:1]|
; SI-SDAG-NEXT:    s_mov_b32 s2, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[0:1], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[0:1], s2, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[0:1], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; SI-SDAG-NEXT:    ; return to shader part epilog
;
; SI-GISEL-LABEL: s_rsq_f64_fabs:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    v_sqrt_f64_e64 v[0:1], |s[0:1]|
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[0:1], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[0:1], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[0:1]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; SI-GISEL-NEXT:    ; return to shader part epilog
;
; VI-SDAG-LABEL: s_rsq_f64_fabs:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    v_sqrt_f64_e64 v[0:1], |s[0:1]|
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; VI-SDAG-NEXT:    ; return to shader part epilog
;
; VI-GISEL-LABEL: s_rsq_f64_fabs:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    v_sqrt_f64_e64 v[0:1], |s[0:1]|
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; VI-GISEL-NEXT:    ; return to shader part epilog
  %fabs.x = call double @llvm.fabs.f64(double %x)
  %rsq = call contract double @llvm.sqrt.f64(double %fabs.x)
  %result = fdiv contract double 1.0, %rsq
  %cast = bitcast double %result to <2 x i32>
  %cast.0 = extractelement <2 x i32> %cast, i32 0
  %cast.1 = extractelement <2 x i32> %cast, i32 1
  %lane.0 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.0)
  %lane.1 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.1)
  %insert.0 = insertelement <2 x i32> poison, i32 %lane.0, i32 0
  %insert.1 = insertelement <2 x i32> %insert.0, i32 %lane.1, i32 1
  ret <2 x i32> %insert.1
}

define amdgpu_ps <2 x i32> @s_neg_rsq_f64(double inreg %x) {
; SI-SDAG-LABEL: s_neg_rsq_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s2, 0xbff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], -1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[0:1], -1.0, v[0:1], -1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[0:1], s2, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[0:1], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; SI-SDAG-NEXT:    ; return to shader part epilog
;
; SI-GISEL-LABEL: s_neg_rsq_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0xbff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[0:1], -1.0, v[0:1], -1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[0:1], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[0:1]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; SI-GISEL-NEXT:    ; return to shader part epilog
;
; VI-SDAG-LABEL: s_neg_rsq_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], -1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; VI-SDAG-NEXT:    ; return to shader part epilog
;
; VI-GISEL-LABEL: s_neg_rsq_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], -1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; VI-GISEL-NEXT:    ; return to shader part epilog
  %rsq = call contract double @llvm.sqrt.f64(double %x)
  %result = fdiv contract double -1.0, %rsq
  %cast = bitcast double %result to <2 x i32>
  %cast.0 = extractelement <2 x i32> %cast, i32 0
  %cast.1 = extractelement <2 x i32> %cast, i32 1
  %lane.0 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.0)
  %lane.1 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.1)
  %insert.0 = insertelement <2 x i32> poison, i32 %lane.0, i32 0
  %insert.1 = insertelement <2 x i32> %insert.0, i32 %lane.1, i32 1
  ret <2 x i32> %insert.1
}

define amdgpu_ps <2 x i32> @s_neg_rsq_neg_f64(double inreg %x) {
; SI-SDAG-LABEL: s_neg_rsq_neg_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    v_sqrt_f64_e64 v[0:1], -s[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s2, 0xbff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], -1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[0:1], -1.0, v[0:1], -1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[0:1], s2, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[0:1], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; SI-SDAG-NEXT:    ; return to shader part epilog
;
; SI-GISEL-LABEL: s_neg_rsq_neg_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    v_sqrt_f64_e64 v[0:1], -s[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0xbff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[0:1], -1.0, v[0:1], -1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[0:1], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[0:1]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; SI-GISEL-NEXT:    ; return to shader part epilog
;
; VI-SDAG-LABEL: s_neg_rsq_neg_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    v_sqrt_f64_e64 v[0:1], -s[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], -1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; VI-SDAG-NEXT:    ; return to shader part epilog
;
; VI-GISEL-LABEL: s_neg_rsq_neg_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    v_sqrt_f64_e64 v[0:1], -s[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], -1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; VI-GISEL-NEXT:    ; return to shader part epilog
  %x.neg = fneg double %x
  %rsq = call contract double @llvm.sqrt.f64(double %x.neg)
  %result = fdiv contract double -1.0, %rsq
  %cast = bitcast double %result to <2 x i32>
  %cast.0 = extractelement <2 x i32> %cast, i32 0
  %cast.1 = extractelement <2 x i32> %cast, i32 1
  %lane.0 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.0)
  %lane.1 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.1)
  %insert.0 = insertelement <2 x i32> poison, i32 %lane.0, i32 0
  %insert.1 = insertelement <2 x i32> %insert.0, i32 %lane.1, i32 1
  ret <2 x i32> %insert.1
}

define double @v_rsq_f64(double %x) {
; SI-SDAG-LABEL: v_rsq_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64_fabs(double %x) {
; SI-SDAG-LABEL: v_rsq_f64_fabs:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e64 v[0:1], |v[0:1]|
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_f64_fabs:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e64 v[0:1], |v[0:1]|
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_f64_fabs:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e64 v[0:1], |v[0:1]|
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_f64_fabs:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e64 v[0:1], |v[0:1]|
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %fabs.x = call double @llvm.fabs.f64(double %x)
  %sqrt = call contract double @llvm.sqrt.f64(double %fabs.x)
  %rsq = fdiv contract double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64_missing_contract0(double %x) {
; SI-SDAG-LABEL: v_rsq_f64_missing_contract0:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_f64_missing_contract0:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_f64_missing_contract0:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_f64_missing_contract0:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64_missing_contract1(double %x) {
; SI-SDAG-LABEL: v_rsq_f64_missing_contract1:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_f64_missing_contract1:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_f64_missing_contract1:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_f64_missing_contract1:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.sqrt.f64(double %x)
  %rsq = fdiv double 1.0, %sqrt
  ret double %rsq
}

define double @v_neg_rsq_f64(double %x) {
; SI-SDAG-LABEL: v_neg_rsq_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0xbff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], -1.0, v[0:1], -1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_neg_rsq_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0xbff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], -1.0, v[0:1], -1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_neg_rsq_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_neg_rsq_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract double -1.0, %sqrt
  ret double %rsq
}

define <2 x double> @v_rsq_v2f64(<2 x double> %x) {
; SI-SDAG-LABEL: v_rsq_v2f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[2:3], v[2:3], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[12:13], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_div_scale_f64 v[18:19], s[4:5], 1.0, v[2:3], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v5
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[10:11], v[8:9]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v13
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[14:15], v[6:7]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-SDAG-NEXT:    v_mul_f64 v[16:17], v[12:13], v[6:7]
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[16:17], v[12:13]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[16:17]
; SI-SDAG-NEXT:    v_mul_f64 v[12:13], v[18:19], v[10:11]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v3, v9
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[8:9], v[12:13], v[18:19]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v19
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], 1.0
; SI-SDAG-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[12:13]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_v2f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_mov_b32_e32 v20, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[2:3], v[2:3], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_div_scale_f64 v[12:13], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[18:19], s[4:5], 1.0, v[2:3], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v20, v13
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[10:11], v[8:9]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v5
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[14:15], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-GISEL-NEXT:    v_mul_f64 v[16:17], v[12:13], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[16:17], v[12:13]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[10:11], v[14:15], v[10:11]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[6:7], v[12:13], v[6:7], v[16:17]
; SI-GISEL-NEXT:    v_mul_f64 v[10:11], v[18:19], v[4:5]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v20, v19
; SI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[8:9], v[10:11], v[18:19]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v3, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[6:7], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[12:13], v[4:5], v[10:11]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[2:3], v[4:5], v[2:3], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_v2f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], v[2:3], v[2:3], 1.0
; VI-SDAG-NEXT:    v_div_scale_f64 v[16:17], s[4:5], 1.0, v[2:3], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[10:11], v[6:7]
; VI-SDAG-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[8:9], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[6:7], v[10:11], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], v[8:9], v[12:13], v[8:9]
; VI-SDAG-NEXT:    v_div_scale_f64 v[12:13], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; VI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[8:9], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[18:19], -v[6:7], v[10:11], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], v[8:9], v[14:15], v[8:9]
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[18:19], v[10:11]
; VI-SDAG-NEXT:    v_mul_f64 v[14:15], v[12:13], v[8:9]
; VI-SDAG-NEXT:    v_mul_f64 v[18:19], v[16:17], v[10:11]
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[14:15], v[12:13]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[18:19], v[16:17]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[8:9], v[14:15]
; VI-SDAG-NEXT:    s_mov_b64 vcc, s[4:5]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[18:19]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], 1.0
; VI-SDAG-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_v2f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], s[4:5], v[2:3], v[2:3], 1.0
; VI-GISEL-NEXT:    v_div_scale_f64 v[16:17], s[4:5], 1.0, v[2:3], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[10:11], v[6:7]
; VI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], v[8:9], v[12:13], v[8:9]
; VI-GISEL-NEXT:    v_div_scale_f64 v[12:13], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; VI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[18:19], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], v[8:9], v[14:15], v[8:9]
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[18:19], v[10:11]
; VI-GISEL-NEXT:    v_mul_f64 v[14:15], v[12:13], v[8:9]
; VI-GISEL-NEXT:    v_mul_f64 v[18:19], v[16:17], v[10:11]
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[14:15], v[12:13]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[18:19], v[16:17]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[8:9], v[14:15]
; VI-GISEL-NEXT:    s_mov_b64 vcc, s[4:5]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[18:19]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], 1.0
; VI-GISEL-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call <2 x double> @llvm.sqrt.v2f64(<2 x double> %x)
  %rsq = fdiv <2 x double> <double 1.0, double 1.0>, %sqrt
  ret <2 x double> %rsq
}

define <2 x double> @v_neg_rsq_v2f64(<2 x double> %x) {
; SI-SDAG-LABEL: v_neg_rsq_v2f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0xbff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; SI-SDAG-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[2:3], v[2:3], -1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[12:13], s[4:5], -1.0, v[0:1], -1.0
; SI-SDAG-NEXT:    v_div_scale_f64 v[18:19], s[4:5], -1.0, v[2:3], -1.0
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v5
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[10:11], v[8:9]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v13
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[14:15], v[6:7]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-SDAG-NEXT:    v_mul_f64 v[16:17], v[12:13], v[6:7]
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[16:17], v[12:13]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[16:17]
; SI-SDAG-NEXT:    v_mul_f64 v[12:13], v[18:19], v[10:11]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v3, v9
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[8:9], v[12:13], v[18:19]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v19
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], -1.0
; SI-SDAG-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[12:13]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], -1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_neg_rsq_v2f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_mov_b32_e32 v20, 0xbff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[2:3], v[2:3], -1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_div_scale_f64 v[12:13], s[4:5], -1.0, v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[18:19], s[4:5], -1.0, v[2:3], -1.0
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v20, v13
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[10:11], v[8:9]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v5
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[14:15], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-GISEL-NEXT:    v_mul_f64 v[16:17], v[12:13], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[16:17], v[12:13]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[10:11], v[14:15], v[10:11]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[6:7], v[12:13], v[6:7], v[16:17]
; SI-GISEL-NEXT:    v_mul_f64 v[10:11], v[18:19], v[4:5]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v20, v19
; SI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[8:9], v[10:11], v[18:19]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v3, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[6:7], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[12:13], v[4:5], v[10:11]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[2:3], v[4:5], v[2:3], -1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_neg_rsq_v2f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], v[2:3], v[2:3], -1.0
; VI-SDAG-NEXT:    v_div_scale_f64 v[16:17], s[4:5], -1.0, v[2:3], -1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[10:11], v[6:7]
; VI-SDAG-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[8:9], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[6:7], v[10:11], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], v[8:9], v[12:13], v[8:9]
; VI-SDAG-NEXT:    v_div_scale_f64 v[12:13], vcc, -1.0, v[0:1], -1.0
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; VI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[8:9], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[18:19], -v[6:7], v[10:11], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], v[8:9], v[14:15], v[8:9]
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[18:19], v[10:11]
; VI-SDAG-NEXT:    v_mul_f64 v[14:15], v[12:13], v[8:9]
; VI-SDAG-NEXT:    v_mul_f64 v[18:19], v[16:17], v[10:11]
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[14:15], v[12:13]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[18:19], v[16:17]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[8:9], v[14:15]
; VI-SDAG-NEXT:    s_mov_b64 vcc, s[4:5]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[18:19]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], -1.0
; VI-SDAG-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], -1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_neg_rsq_v2f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], s[4:5], v[2:3], v[2:3], -1.0
; VI-GISEL-NEXT:    v_div_scale_f64 v[16:17], s[4:5], -1.0, v[2:3], -1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[10:11], v[6:7]
; VI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], v[8:9], v[12:13], v[8:9]
; VI-GISEL-NEXT:    v_div_scale_f64 v[12:13], vcc, -1.0, v[0:1], -1.0
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; VI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[18:19], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], v[8:9], v[14:15], v[8:9]
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[18:19], v[10:11]
; VI-GISEL-NEXT:    v_mul_f64 v[14:15], v[12:13], v[8:9]
; VI-GISEL-NEXT:    v_mul_f64 v[18:19], v[16:17], v[10:11]
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[14:15], v[12:13]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[18:19], v[16:17]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[8:9], v[14:15]
; VI-GISEL-NEXT:    s_mov_b64 vcc, s[4:5]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[18:19]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], -1.0
; VI-GISEL-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], -1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call <2 x double> @llvm.sqrt.v2f64(<2 x double> %x)
  %rsq = fdiv <2 x double> <double -1.0, double -1.0>, %sqrt
  ret <2 x double> %rsq
}

define <2 x double> @v_neg_rsq_v2f64_poisonelt(<2 x double> %x) {
; SI-SDAG-LABEL: v_neg_rsq_v2f64_poisonelt:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0xbff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], -1.0, v[0:1], -1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-SDAG-NEXT:    v_mov_b32_e32 v2, 0
; SI-SDAG-NEXT:    v_mov_b32_e32 v3, 0x7ff80000
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_neg_rsq_v2f64_poisonelt:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_mov_b32_e32 v16, 0xbff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[2:3], v[2:3], s[4:5]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_div_scale_f64 v[12:13], s[4:5], -1.0, v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[18:19], s[4:5], s[4:5], v[2:3], s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v16, v13
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[10:11], v[8:9]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v5
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[14:15], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-GISEL-NEXT:    v_mul_f64 v[16:17], v[12:13], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[16:17], v[12:13]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[10:11], v[14:15], v[10:11]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[6:7], v[12:13], v[6:7], v[16:17]
; SI-GISEL-NEXT:    v_mul_f64 v[10:11], v[18:19], v[4:5]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, s4, v19
; SI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[8:9], v[10:11], v[18:19]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v3, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[6:7], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[12:13], v[4:5], v[10:11]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[2:3], v[4:5], v[2:3], s[4:5]
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_neg_rsq_v2f64_poisonelt:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-SDAG-NEXT:    v_mov_b32_e32 v2, 0
; VI-SDAG-NEXT:    v_mov_b32_e32 v3, 0x7ff80000
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_neg_rsq_v2f64_poisonelt:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], s[4:5], v[2:3], v[2:3], s[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[16:17], s[4:5], s[4:5], v[2:3], s[4:5]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[10:11], v[6:7]
; VI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], v[8:9], v[12:13], v[8:9]
; VI-GISEL-NEXT:    v_div_scale_f64 v[12:13], vcc, -1.0, v[0:1], -1.0
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; VI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[18:19], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], v[8:9], v[14:15], v[8:9]
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[18:19], v[10:11]
; VI-GISEL-NEXT:    v_mul_f64 v[14:15], v[12:13], v[8:9]
; VI-GISEL-NEXT:    v_mul_f64 v[18:19], v[16:17], v[10:11]
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[14:15], v[12:13]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[18:19], v[16:17]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[8:9], v[14:15]
; VI-GISEL-NEXT:    s_mov_b64 vcc, s[4:5]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[18:19]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], -1.0
; VI-GISEL-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], s[4:5]
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call <2 x double> @llvm.sqrt.v2f64(<2 x double> %x)
  %rsq = fdiv <2 x double> <double -1.0, double poison>, %sqrt
  ret <2 x double> %rsq
}

define <2 x double> @v_neg_pos_rsq_v2f64(<2 x double> %x) {
; SI-SDAG-LABEL: v_neg_pos_rsq_v2f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0xbff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; SI-SDAG-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[2:3], v[2:3], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[12:13], s[4:5], -1.0, v[0:1], -1.0
; SI-SDAG-NEXT:    v_div_scale_f64 v[18:19], s[4:5], 1.0, v[2:3], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v5
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[10:11], v[8:9]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v13
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[14:15], v[6:7]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-SDAG-NEXT:    v_mul_f64 v[16:17], v[12:13], v[6:7]
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[16:17], v[12:13]
; SI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-SDAG-NEXT:    s_mov_b32 s4, 0x3ff00000
; SI-SDAG-NEXT:    v_mul_f64 v[12:13], v[18:19], v[10:11]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[16:17]
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[8:9], v[12:13], v[18:19]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v3, v9
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s4, v19
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], -1.0
; SI-SDAG-NEXT:    s_nop 0
; SI-SDAG-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[12:13]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_neg_pos_rsq_v2f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_mov_b32_e32 v16, 0xbff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[2:3], v[2:3], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_div_scale_f64 v[12:13], s[4:5], -1.0, v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[18:19], s[4:5], 1.0, v[2:3], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v16, v13
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[10:11], v[8:9]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v5
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[14:15], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-GISEL-NEXT:    v_mul_f64 v[16:17], v[12:13], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; SI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[16:17], v[12:13]
; SI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[8:9], v[10:11], 1.0
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[10:11], v[14:15], v[10:11]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[6:7], v[12:13], v[6:7], v[16:17]
; SI-GISEL-NEXT:    v_mul_f64 v[10:11], v[18:19], v[4:5]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v3, v9
; SI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[8:9], v[10:11], v[18:19]
; SI-GISEL-NEXT:    v_mov_b32_e32 v8, 0x3ff00000
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v8, v19
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[6:7], v[0:1], -1.0
; SI-GISEL-NEXT:    s_nop 1
; SI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[12:13], v[4:5], v[10:11]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[2:3], v[4:5], v[2:3], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_neg_pos_rsq_v2f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], v[2:3], v[2:3], 1.0
; VI-SDAG-NEXT:    v_div_scale_f64 v[16:17], s[4:5], 1.0, v[2:3], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[10:11], v[6:7]
; VI-SDAG-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[8:9], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[6:7], v[10:11], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], v[8:9], v[12:13], v[8:9]
; VI-SDAG-NEXT:    v_div_scale_f64 v[12:13], vcc, -1.0, v[0:1], -1.0
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; VI-SDAG-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[8:9], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[18:19], -v[6:7], v[10:11], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], v[8:9], v[14:15], v[8:9]
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], v[10:11], v[18:19], v[10:11]
; VI-SDAG-NEXT:    v_mul_f64 v[14:15], v[12:13], v[8:9]
; VI-SDAG-NEXT:    v_mul_f64 v[18:19], v[16:17], v[10:11]
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[14:15], v[12:13]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[18:19], v[16:17]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[8:9], v[14:15]
; VI-SDAG-NEXT:    s_mov_b64 vcc, s[4:5]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[18:19]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], -1.0
; VI-SDAG-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_neg_pos_rsq_v2f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[0:1], v[0:1], -1.0
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], s[4:5], v[2:3], v[2:3], 1.0
; VI-GISEL-NEXT:    v_div_scale_f64 v[16:17], s[4:5], 1.0, v[2:3], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[10:11], v[6:7]
; VI-GISEL-NEXT:    v_fma_f64 v[12:13], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], v[8:9], v[12:13], v[8:9]
; VI-GISEL-NEXT:    v_div_scale_f64 v[12:13], vcc, -1.0, v[0:1], -1.0
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[14:15], v[10:11]
; VI-GISEL-NEXT:    v_fma_f64 v[14:15], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[18:19], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], v[8:9], v[14:15], v[8:9]
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], v[10:11], v[18:19], v[10:11]
; VI-GISEL-NEXT:    v_mul_f64 v[14:15], v[12:13], v[8:9]
; VI-GISEL-NEXT:    v_mul_f64 v[18:19], v[16:17], v[10:11]
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[14:15], v[12:13]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[18:19], v[16:17]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[8:9], v[14:15]
; VI-GISEL-NEXT:    s_mov_b64 vcc, s[4:5]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[6:7], v[6:7], v[10:11], v[18:19]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[0:1], -1.0
; VI-GISEL-NEXT:    v_div_fixup_f64 v[2:3], v[6:7], v[2:3], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call <2 x double> @llvm.sqrt.v2f64(<2 x double> %x)
  %rsq = fdiv <2 x double> <double -1.0, double 1.0>, %sqrt
  ret <2 x double> %rsq
}

define double @v_rsq_f64_fneg_fabs(double %x) {
; SI-SDAG-LABEL: v_rsq_f64_fneg_fabs:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e64 v[0:1], -|v[0:1]|
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_f64_fneg_fabs:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e64 v[0:1], -|v[0:1]|
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_f64_fneg_fabs:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e64 v[0:1], -|v[0:1]|
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_f64_fneg_fabs:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e64 v[0:1], -|v[0:1]|
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %fabs = call double @llvm.fabs.f64(double %x)
  %fneg.fabs = fneg double %fabs
  %sqrt = call contract double @llvm.sqrt.f64(double %fneg.fabs)
  %rsq = fdiv contract double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64__afn_sqrt(double %x) {
; SI-SDAG-LABEL: v_rsq_f64__afn_sqrt:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_f64__afn_sqrt:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_f64__afn_sqrt:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_f64__afn_sqrt:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract afn double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64__afn_fdiv(double %x) {
; SDAG-LABEL: v_rsq_f64__afn_fdiv:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[2:3]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; GISEL-LABEL: v_rsq_f64__afn_fdiv:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_mul_f64 v[4:5], 1.0, v[0:1]
; GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[4:5], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[2:3], v[0:1], v[4:5]
; GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract afn double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64__afn(double %x) {
; SDAG-LABEL: v_rsq_f64__afn:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[2:3]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; GISEL-LABEL: v_rsq_f64__afn:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_mul_f64 v[4:5], 1.0, v[0:1]
; GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[4:5], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[2:3], v[0:1], v[4:5]
; GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract afn double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract afn double 1.0, %sqrt
  ret double %rsq
}

define double @v_neg_rsq_f64__afn(double %x) {
; SDAG-LABEL: v_neg_rsq_f64__afn:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_mul_f64 v[4:5], v[2:3], -1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[4:5], -1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[4:5]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; GISEL-LABEL: v_neg_rsq_f64__afn:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_mul_f64 v[4:5], -1.0, v[0:1]
; GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[4:5], -1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[2:3], v[0:1], v[4:5]
; GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract afn double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract afn double -1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64__afn_ninf(double %x) {
; SDAG-LABEL: v_rsq_f64__afn_ninf:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[2:3]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; GISEL-LABEL: v_rsq_f64__afn_ninf:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_mul_f64 v[4:5], 1.0, v[0:1]
; GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[4:5], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[2:3], v[0:1], v[4:5]
; GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract afn ninf double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract afn ninf double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64__afn_nnan(double %x) {
; SDAG-LABEL: v_rsq_f64__afn_nnan:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[2:3]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; GISEL-LABEL: v_rsq_f64__afn_nnan:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_mul_f64 v[4:5], 1.0, v[0:1]
; GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[4:5], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[2:3], v[0:1], v[4:5]
; GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract afn nnan double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract afn nnan double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64__afn_nnan_ninf(double %x) {
; SDAG-LABEL: v_rsq_f64__afn_nnan_ninf:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[2:3]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; GISEL-LABEL: v_rsq_f64__afn_nnan_ninf:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_mul_f64 v[4:5], 1.0, v[0:1]
; GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[4:5], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[2:3], v[0:1], v[4:5]
; GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract afn nnan ninf double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract afn nnan ninf double 1.0, %sqrt
  ret double %rsq
}

define double @v_neg_rsq_f64__afn_nnan_ninf(double %x) {
; SDAG-LABEL: v_neg_rsq_f64__afn_nnan_ninf:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_mul_f64 v[4:5], v[2:3], -1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[4:5], -1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[4:5]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; GISEL-LABEL: v_neg_rsq_f64__afn_nnan_ninf:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_mul_f64 v[4:5], -1.0, v[0:1]
; GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[4:5], -1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[2:3], v[0:1], v[4:5]
; GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract afn nnan ninf double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract afn nnan ninf double -1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_f64__nnan_ninf(double %x) {
; SI-SDAG-LABEL: v_rsq_f64__nnan_ninf:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_f64__nnan_ninf:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_f64__nnan_ninf:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_f64__nnan_ninf:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract nnan ninf double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract nnan ninf double 1.0, %sqrt
  ret double %rsq
}

define <2 x double> @v_rsq_v2f64__afn_nnan_ninf(<2 x double> %x) {
; SDAG-LABEL: v_rsq_v2f64__afn_nnan_ninf:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[8:9], -v[0:1], v[4:5], 1.0
; SDAG-NEXT:    v_fma_f64 v[10:11], -v[2:3], v[6:7], 1.0
; SDAG-NEXT:    v_fma_f64 v[4:5], v[8:9], v[4:5], v[4:5]
; SDAG-NEXT:    v_fma_f64 v[6:7], v[10:11], v[6:7], v[6:7]
; SDAG-NEXT:    v_fma_f64 v[8:9], -v[0:1], v[4:5], 1.0
; SDAG-NEXT:    v_fma_f64 v[10:11], -v[2:3], v[6:7], 1.0
; SDAG-NEXT:    v_fma_f64 v[4:5], v[8:9], v[4:5], v[4:5]
; SDAG-NEXT:    v_fma_f64 v[6:7], v[10:11], v[6:7], v[6:7]
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[4:5], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], 1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[4:5], v[4:5]
; SDAG-NEXT:    v_fma_f64 v[2:3], v[2:3], v[6:7], v[6:7]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_v2f64__afn_nnan_ninf:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[4:5], v[0:1]
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[6:7], v[2:3]
; SI-GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_rsq_f64_e32 v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[0:1], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[6:7], v[2:3], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[0:1], v[8:9], v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], v[10:11], v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[0:1], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[6:7], v[2:3], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[0:1], v[8:9], v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], v[10:11], v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_mul_f64 v[8:9], 1.0, v[0:1]
; SI-GISEL-NEXT:    v_mul_f64 v[10:11], 1.0, v[2:3]
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[8:9], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[10:11], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[8:9]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], v[6:7], v[2:3], v[10:11]
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_v2f64__afn_nnan_ninf:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[4:5], v[0:1]
; VI-GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[6:7], v[2:3]
; VI-GISEL-NEXT:    v_rsq_f64_e32 v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[6:7], v[2:3], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[0:1], v[8:9], v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], v[10:11], v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[6:7], v[2:3], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[0:1], v[8:9], v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], v[10:11], v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], 1.0, v[0:1]
; VI-GISEL-NEXT:    v_mul_f64 v[10:11], 1.0, v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[8:9], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[6:7], v[10:11], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[8:9]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], v[6:7], v[2:3], v[10:11]
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract afn nnan ninf <2 x double> @llvm.sqrt.v2f64(<2 x double> %x)
  %rsq = fdiv contract afn nnan ninf <2 x double> <double 1.0, double 1.0>, %sqrt
  ret <2 x double> %rsq
}

define amdgpu_ps <2 x i32> @s_rsq_f64_unsafe(double inreg %x) #0 {
; SDAG-LABEL: s_rsq_f64_unsafe:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[2:3]
; SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; SDAG-NEXT:    ; return to shader part epilog
;
; GISEL-LABEL: s_rsq_f64_unsafe:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[2:3], s[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; GISEL-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; GISEL-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; GISEL-NEXT:    v_mul_f64 v[4:5], 1.0, v[2:3]
; GISEL-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[4:5], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[4:5]
; GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; GISEL-NEXT:    ; return to shader part epilog
  %rsq = call contract double @llvm.sqrt.f64(double %x)
  %result = fdiv contract double 1.0, %rsq
  %cast = bitcast double %result to <2 x i32>
  %cast.0 = extractelement <2 x i32> %cast, i32 0
  %cast.1 = extractelement <2 x i32> %cast, i32 1
  %lane.0 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.0)
  %lane.1 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.1)
  %insert.0 = insertelement <2 x i32> poison, i32 %lane.0, i32 0
  %insert.1 = insertelement <2 x i32> %insert.0, i32 %lane.1, i32 1
  ret <2 x i32> %insert.1
}

define double @v_rsq_f64_unsafe(double %x) #0 {
; SDAG-LABEL: v_rsq_f64_unsafe:
; SDAG:       ; %bb.0:
; SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SDAG-NEXT:    v_rcp_f64_e32 v[2:3], v[0:1]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[4:5], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[2:3], v[4:5], v[2:3], v[2:3]
; SDAG-NEXT:    v_fma_f64 v[0:1], -v[0:1], v[2:3], 1.0
; SDAG-NEXT:    v_fma_f64 v[0:1], v[0:1], v[2:3], v[2:3]
; SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; GISEL-LABEL: v_rsq_f64_unsafe:
; GISEL:       ; %bb.0:
; GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[0:1]
; GISEL-NEXT:    v_rsq_f64_e32 v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_fma_f64 v[4:5], -v[2:3], v[0:1], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[4:5], v[0:1], v[0:1]
; GISEL-NEXT:    v_mul_f64 v[4:5], 1.0, v[0:1]
; GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[4:5], 1.0
; GISEL-NEXT:    v_fma_f64 v[0:1], v[2:3], v[0:1], v[4:5]
; GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call double @llvm.sqrt.f64(double %x)
  %rsq = fdiv double 1.0, %sqrt
  ret double %rsq
}

define double @v_rsq_amdgcn_sqrt_f64(double %x) {
; SI-SDAG-LABEL: v_rsq_amdgcn_sqrt_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_rsq_amdgcn_sqrt_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_rsq_amdgcn_sqrt_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_rsq_amdgcn_sqrt_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.amdgcn.sqrt.f64(double %x)
  %rsq = fdiv contract double 1.0, %sqrt
  ret double %rsq
}

define double @v_neg_rsq_amdgcn_sqrt_f64(double %x) {
; SI-SDAG-LABEL: v_neg_rsq_amdgcn_sqrt_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0xbff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], -1.0, v[0:1], -1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s6, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_neg_rsq_amdgcn_sqrt_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0xbff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], -1.0, v[0:1], -1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_neg_rsq_amdgcn_sqrt_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_neg_rsq_amdgcn_sqrt_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], -1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, -1.0, v[0:1], -1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], -1.0
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.amdgcn.sqrt.f64(double %x)
  %rsq = fdiv contract double -1.0, %sqrt
  ret double %rsq
}

define amdgpu_ps <2 x i32> @s_rsq_amdgcn_sqrt_f64(double inreg %x) {
; SI-SDAG-LABEL: s_rsq_amdgcn_sqrt_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s2, 0x3ff00000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[0:1], 1.0, v[0:1], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[0:1], s2, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[0:1], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; SI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; SI-SDAG-NEXT:    ; return to shader part epilog
;
; SI-GISEL-LABEL: s_rsq_amdgcn_sqrt_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x3ff00000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[0:1], 1.0, v[0:1], 1.0
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[0:1], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[0:1]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; SI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; SI-GISEL-NEXT:    ; return to shader part epilog
;
; VI-SDAG-LABEL: s_rsq_amdgcn_sqrt_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s0, v0
; VI-SDAG-NEXT:    v_readfirstlane_b32 s1, v1
; VI-SDAG-NEXT:    ; return to shader part epilog
;
; VI-GISEL-LABEL: s_rsq_amdgcn_sqrt_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], s[0:1]
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[0:1], v[0:1], v[0:1], 1.0
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, 1.0, v[0:1], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], 1.0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s0, v0
; VI-GISEL-NEXT:    v_readfirstlane_b32 s1, v1
; VI-GISEL-NEXT:    ; return to shader part epilog
  %rsq = call contract double @llvm.amdgcn.sqrt.f64(double %x)
  %result = fdiv contract double 1.0, %rsq
  %cast = bitcast double %result to <2 x i32>
  %cast.0 = extractelement <2 x i32> %cast, i32 0
  %cast.1 = extractelement <2 x i32> %cast, i32 1
  %lane.0 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.0)
  %lane.1 = call i32 @llvm.amdgcn.readfirstlane(i32 %cast.1)
  %insert.0 = insertelement <2 x i32> poison, i32 %lane.0, i32 0
  %insert.1 = insertelement <2 x i32> %insert.0, i32 %lane.1, i32 1
  ret <2 x i32> %insert.1
}

define double @v_div_contract_sqrt_f64(double %x, double %y) {
; SI-SDAG-LABEL: v_div_contract_sqrt_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v3, v5
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[0:1], v[2:3], v[0:1]
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v9
; SI-SDAG-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_div_contract_sqrt_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; SI-GISEL-NEXT:    v_div_scale_f64 v[10:11], s[4:5], v[0:1], v[2:3], v[0:1]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v3, v5
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v11
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-GISEL-NEXT:    v_mul_f64 v[8:9], v[10:11], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[8:9], v[10:11]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_div_contract_sqrt_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_scale_f64 v[8:9], vcc, v[0:1], v[2:3], v[0:1]
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; VI-SDAG-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_div_contract_sqrt_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_scale_f64 v[8:9], vcc, v[0:1], v[2:3], v[0:1]
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; VI-GISEL-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.sqrt.f64(double %y)
  %rsq = fdiv contract double %x, %sqrt
  ret double %rsq
}

define double @v_div_arcp_sqrt_f64(double %x, double %y) {
; SI-SDAG-LABEL: v_div_arcp_sqrt_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v3, v5
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[0:1], v[2:3], v[0:1]
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v9
; SI-SDAG-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_div_arcp_sqrt_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; SI-GISEL-NEXT:    v_div_scale_f64 v[10:11], s[4:5], v[0:1], v[2:3], v[0:1]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v3, v5
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v11
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-GISEL-NEXT:    v_mul_f64 v[8:9], v[10:11], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[8:9], v[10:11]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_div_arcp_sqrt_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_scale_f64 v[8:9], vcc, v[0:1], v[2:3], v[0:1]
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; VI-SDAG-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_div_arcp_sqrt_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_scale_f64 v[8:9], vcc, v[0:1], v[2:3], v[0:1]
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; VI-GISEL-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call double @llvm.sqrt.f64(double %y)
  %rsq = fdiv arcp double %x, %sqrt
  ret double %rsq
}

define double @v_div_contract_arcp_sqrt_f64(double %x, double %y) {
; SI-SDAG-LABEL: v_div_contract_arcp_sqrt_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v3, v5
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_scale_f64 v[8:9], s[4:5], v[0:1], v[2:3], v[0:1]
; SI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v9
; SI-SDAG-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_div_contract_arcp_sqrt_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; SI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; SI-GISEL-NEXT:    v_div_scale_f64 v[10:11], s[4:5], v[0:1], v[2:3], v[0:1]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v3, v5
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v11
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; SI-GISEL-NEXT:    v_mul_f64 v[8:9], v[10:11], v[6:7]
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[8:9], v[10:11]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_div_contract_arcp_sqrt_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-SDAG-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_scale_f64 v[8:9], vcc, v[0:1], v[2:3], v[0:1]
; VI-SDAG-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; VI-SDAG-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_div_contract_arcp_sqrt_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[2:3], v[2:3]
; VI-GISEL-NEXT:    v_div_scale_f64 v[4:5], s[4:5], v[2:3], v[2:3], v[0:1]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[4:5], v[6:7], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_scale_f64 v[8:9], vcc, v[0:1], v[2:3], v[0:1]
; VI-GISEL-NEXT:    v_fma_f64 v[10:11], -v[4:5], v[6:7], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], v[6:7], v[10:11], v[6:7]
; VI-GISEL-NEXT:    v_mul_f64 v[10:11], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], -v[4:5], v[10:11], v[8:9]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[4:5], v[4:5], v[6:7], v[10:11]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[4:5], v[2:3], v[0:1]
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.sqrt.f64(double %y)
  %rsq = fdiv contract arcp double %x, %sqrt
  ret double %rsq
}

define double @v_div_const_contract_sqrt_f64(double %x) {
; SI-SDAG-LABEL: v_div_const_contract_sqrt_f64:
; SI-SDAG:       ; %bb.0:
; SI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-SDAG-NEXT:    s_mov_b32 s6, 0
; SI-SDAG-NEXT:    s_mov_b32 s7, 0x40700000
; SI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], s[6:7]
; SI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e32 vcc, v1, v3
; SI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-SDAG-NEXT:    v_div_scale_f64 v[6:7], s[4:5], s[6:7], v[0:1], s[6:7]
; SI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; SI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; SI-SDAG-NEXT:    v_cmp_eq_u32_e64 s[4:5], s7, v7
; SI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; SI-SDAG-NEXT:    s_xor_b64 vcc, s[4:5], vcc
; SI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; SI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; SI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], s[6:7]
; SI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; SI-GISEL-LABEL: v_div_const_contract_sqrt_f64:
; SI-GISEL:       ; %bb.0:
; SI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; SI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; SI-GISEL-NEXT:    s_mov_b32 s6, 0
; SI-GISEL-NEXT:    s_mov_b32 s7, 0x40700000
; SI-GISEL-NEXT:    v_mov_b32_e32 v10, 0x40700000
; SI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[4:5], v[0:1], v[0:1], s[6:7]
; SI-GISEL-NEXT:    v_div_scale_f64 v[8:9], s[4:5], s[6:7], v[0:1], s[6:7]
; SI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; SI-GISEL-NEXT:    v_cmp_eq_u32_e64 s[4:5], v1, v3
; SI-GISEL-NEXT:    v_cmp_eq_u32_e32 vcc, v10, v9
; SI-GISEL-NEXT:    s_xor_b64 vcc, vcc, s[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; SI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; SI-GISEL-NEXT:    v_mul_f64 v[6:7], v[8:9], v[4:5]
; SI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[6:7], v[8:9]
; SI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[6:7]
; SI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], s[6:7]
; SI-GISEL-NEXT:    s_setpc_b64 s[30:31]
;
; VI-SDAG-LABEL: v_div_const_contract_sqrt_f64:
; VI-SDAG:       ; %bb.0:
; VI-SDAG-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-SDAG-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-SDAG-NEXT:    s_mov_b32 s4, 0
; VI-SDAG-NEXT:    s_mov_b32 s5, 0x40700000
; VI-SDAG-NEXT:    v_div_scale_f64 v[2:3], s[6:7], v[0:1], v[0:1], s[4:5]
; VI-SDAG-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-SDAG-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_div_scale_f64 v[6:7], vcc, s[4:5], v[0:1], s[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-SDAG-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-SDAG-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-SDAG-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-SDAG-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-SDAG-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], s[4:5]
; VI-SDAG-NEXT:    s_setpc_b64 s[30:31]
;
; VI-GISEL-LABEL: v_div_const_contract_sqrt_f64:
; VI-GISEL:       ; %bb.0:
; VI-GISEL-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
; VI-GISEL-NEXT:    v_sqrt_f64_e32 v[0:1], v[0:1]
; VI-GISEL-NEXT:    s_mov_b32 s4, 0
; VI-GISEL-NEXT:    s_mov_b32 s5, 0x40700000
; VI-GISEL-NEXT:    v_div_scale_f64 v[2:3], s[6:7], v[0:1], v[0:1], s[4:5]
; VI-GISEL-NEXT:    v_rcp_f64_e32 v[4:5], v[2:3]
; VI-GISEL-NEXT:    v_fma_f64 v[6:7], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_div_scale_f64 v[6:7], vcc, s[4:5], v[0:1], s[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[8:9], -v[2:3], v[4:5], 1.0
; VI-GISEL-NEXT:    v_fma_f64 v[4:5], v[4:5], v[8:9], v[4:5]
; VI-GISEL-NEXT:    v_mul_f64 v[8:9], v[6:7], v[4:5]
; VI-GISEL-NEXT:    v_fma_f64 v[2:3], -v[2:3], v[8:9], v[6:7]
; VI-GISEL-NEXT:    v_div_fmas_f64 v[2:3], v[2:3], v[4:5], v[8:9]
; VI-GISEL-NEXT:    v_div_fixup_f64 v[0:1], v[2:3], v[0:1], s[4:5]
; VI-GISEL-NEXT:    s_setpc_b64 s[30:31]
  %sqrt = call contract double @llvm.sqrt.f64(double %x)
  %rsq = fdiv contract double 256.0, %sqrt
  ret double %rsq
}

attributes #0 = { "unsafe-fp-math"="true" }
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; GCN: {{.*}}
