; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc --mtriple=loongarch32 --mattr=+32s,+lasx,-frecipe < %s | FileCheck %s --check-prefix=FAULT-LA32
; RUN: llc --mtriple=loongarch32 --mattr=+32s,+lasx,+frecipe < %s | FileCheck %s --check-prefix=LA32
; RUN: llc --mtriple=loongarch64 --mattr=+lasx,-frecipe < %s | FileCheck %s --check-prefix=FAULT-LA64
; RUN: llc --mtriple=loongarch64 --mattr=+lasx,+frecipe < %s | FileCheck %s --check-prefix=LA64

;; 1.0 / (fsqrt vec)
define void @one_div_sqrt_v8f32(ptr %res, ptr %a0) nounwind {
; FAULT-LA32-LABEL: one_div_sqrt_v8f32:
; FAULT-LA32:       # %bb.0: # %entry
; FAULT-LA32-NEXT:    addi.w $sp, $sp, -128
; FAULT-LA32-NEXT:    st.w $ra, $sp, 124 # 4-byte Folded Spill
; FAULT-LA32-NEXT:    st.w $fp, $sp, 120 # 4-byte Folded Spill
; FAULT-LA32-NEXT:    addi.w $fp, $sp, 128
; FAULT-LA32-NEXT:    bstrins.w $sp, $zero, 4, 0
; FAULT-LA32-NEXT:    vld $vr0, $a1, 16
; FAULT-LA32-NEXT:    vst $vr0, $sp, 48
; FAULT-LA32-NEXT:    ld.w $a2, $a1, 12
; FAULT-LA32-NEXT:    st.w $a2, $sp, 44
; FAULT-LA32-NEXT:    ld.w $a2, $a1, 8
; FAULT-LA32-NEXT:    st.w $a2, $sp, 40
; FAULT-LA32-NEXT:    ld.w $a2, $a1, 4
; FAULT-LA32-NEXT:    st.w $a2, $sp, 36
; FAULT-LA32-NEXT:    ld.w $a1, $a1, 0
; FAULT-LA32-NEXT:    st.w $a1, $sp, 32
; FAULT-LA32-NEXT:    xvld $xr0, $sp, 32
; FAULT-LA32-NEXT:    xvfrsqrt.s $xr0, $xr0
; FAULT-LA32-NEXT:    xvst $xr0, $sp, 64
; FAULT-LA32-NEXT:    vld $vr0, $sp, 80
; FAULT-LA32-NEXT:    vst $vr0, $a0, 16
; FAULT-LA32-NEXT:    ld.w $a1, $sp, 76
; FAULT-LA32-NEXT:    st.w $a1, $a0, 12
; FAULT-LA32-NEXT:    ld.w $a1, $sp, 72
; FAULT-LA32-NEXT:    st.w $a1, $a0, 8
; FAULT-LA32-NEXT:    ld.w $a1, $sp, 68
; FAULT-LA32-NEXT:    st.w $a1, $a0, 4
; FAULT-LA32-NEXT:    ld.w $a1, $sp, 64
; FAULT-LA32-NEXT:    st.w $a1, $a0, 0
; FAULT-LA32-NEXT:    addi.w $sp, $fp, -128
; FAULT-LA32-NEXT:    ld.w $fp, $sp, 120 # 4-byte Folded Reload
; FAULT-LA32-NEXT:    ld.w $ra, $sp, 124 # 4-byte Folded Reload
; FAULT-LA32-NEXT:    addi.w $sp, $sp, 128
; FAULT-LA32-NEXT:    ret
;
; LA32-LABEL: one_div_sqrt_v8f32:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    addi.w $sp, $sp, -128
; LA32-NEXT:    st.w $ra, $sp, 124 # 4-byte Folded Spill
; LA32-NEXT:    st.w $fp, $sp, 120 # 4-byte Folded Spill
; LA32-NEXT:    addi.w $fp, $sp, 128
; LA32-NEXT:    bstrins.w $sp, $zero, 4, 0
; LA32-NEXT:    vld $vr0, $a1, 16
; LA32-NEXT:    vst $vr0, $sp, 48
; LA32-NEXT:    ld.w $a2, $a1, 12
; LA32-NEXT:    st.w $a2, $sp, 44
; LA32-NEXT:    ld.w $a2, $a1, 8
; LA32-NEXT:    st.w $a2, $sp, 40
; LA32-NEXT:    ld.w $a2, $a1, 4
; LA32-NEXT:    st.w $a2, $sp, 36
; LA32-NEXT:    ld.w $a1, $a1, 0
; LA32-NEXT:    st.w $a1, $sp, 32
; LA32-NEXT:    xvld $xr0, $sp, 32
; LA32-NEXT:    xvfrsqrte.s $xr1, $xr0
; LA32-NEXT:    xvfmul.s $xr1, $xr0, $xr1
; LA32-NEXT:    xvfmul.s $xr0, $xr0, $xr1
; LA32-NEXT:    lu12i.w $a1, -261120
; LA32-NEXT:    xvreplgr2vr.w $xr2, $a1
; LA32-NEXT:    xvfmadd.s $xr0, $xr0, $xr1, $xr2
; LA32-NEXT:    lu12i.w $a1, -266240
; LA32-NEXT:    xvreplgr2vr.w $xr2, $a1
; LA32-NEXT:    xvfmul.s $xr1, $xr1, $xr2
; LA32-NEXT:    xvfmul.s $xr0, $xr1, $xr0
; LA32-NEXT:    xvst $xr0, $sp, 64
; LA32-NEXT:    vld $vr0, $sp, 80
; LA32-NEXT:    vst $vr0, $a0, 16
; LA32-NEXT:    ld.w $a1, $sp, 76
; LA32-NEXT:    st.w $a1, $a0, 12
; LA32-NEXT:    ld.w $a1, $sp, 72
; LA32-NEXT:    st.w $a1, $a0, 8
; LA32-NEXT:    ld.w $a1, $sp, 68
; LA32-NEXT:    st.w $a1, $a0, 4
; LA32-NEXT:    ld.w $a1, $sp, 64
; LA32-NEXT:    st.w $a1, $a0, 0
; LA32-NEXT:    addi.w $sp, $fp, -128
; LA32-NEXT:    ld.w $fp, $sp, 120 # 4-byte Folded Reload
; LA32-NEXT:    ld.w $ra, $sp, 124 # 4-byte Folded Reload
; LA32-NEXT:    addi.w $sp, $sp, 128
; LA32-NEXT:    ret
;
; FAULT-LA64-LABEL: one_div_sqrt_v8f32:
; FAULT-LA64:       # %bb.0: # %entry
; FAULT-LA64-NEXT:    xvld $xr0, $a1, 0
; FAULT-LA64-NEXT:    xvfrsqrt.s $xr0, $xr0
; FAULT-LA64-NEXT:    xvst $xr0, $a0, 0
; FAULT-LA64-NEXT:    ret
;
; LA64-LABEL: one_div_sqrt_v8f32:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    xvld $xr0, $a1, 0
; LA64-NEXT:    xvfrsqrte.s $xr1, $xr0
; LA64-NEXT:    xvfmul.s $xr1, $xr0, $xr1
; LA64-NEXT:    xvfmul.s $xr0, $xr0, $xr1
; LA64-NEXT:    lu12i.w $a1, -261120
; LA64-NEXT:    xvreplgr2vr.w $xr2, $a1
; LA64-NEXT:    xvfmadd.s $xr0, $xr0, $xr1, $xr2
; LA64-NEXT:    lu12i.w $a1, -266240
; LA64-NEXT:    xvreplgr2vr.w $xr2, $a1
; LA64-NEXT:    xvfmul.s $xr1, $xr1, $xr2
; LA64-NEXT:    xvfmul.s $xr0, $xr1, $xr0
; LA64-NEXT:    xvst $xr0, $a0, 0
; LA64-NEXT:    ret
entry:
  %v0 = load <8 x float>, ptr %a0, align 16
  %sqrt = call fast <8 x float> @llvm.sqrt.v8f32 (<8 x float> %v0)
  %div = fdiv fast <8 x float> <float 1.0, float 1.0, float 1.0, float 1.0, float 1.0, float 1.0, float 1.0, float 1.0>, %sqrt
  store <8 x float> %div, ptr %res, align 16
  ret void
}

define void @one_div_sqrt_v4f64(ptr %res, ptr %a0) nounwind {
; FAULT-LA32-LABEL: one_div_sqrt_v4f64:
; FAULT-LA32:       # %bb.0: # %entry
; FAULT-LA32-NEXT:    addi.w $sp, $sp, -128
; FAULT-LA32-NEXT:    st.w $ra, $sp, 124 # 4-byte Folded Spill
; FAULT-LA32-NEXT:    st.w $fp, $sp, 120 # 4-byte Folded Spill
; FAULT-LA32-NEXT:    addi.w $fp, $sp, 128
; FAULT-LA32-NEXT:    bstrins.w $sp, $zero, 4, 0
; FAULT-LA32-NEXT:    vld $vr0, $a1, 16
; FAULT-LA32-NEXT:    vst $vr0, $sp, 48
; FAULT-LA32-NEXT:    ld.w $a2, $a1, 12
; FAULT-LA32-NEXT:    st.w $a2, $sp, 44
; FAULT-LA32-NEXT:    ld.w $a2, $a1, 8
; FAULT-LA32-NEXT:    st.w $a2, $sp, 40
; FAULT-LA32-NEXT:    ld.w $a2, $a1, 4
; FAULT-LA32-NEXT:    st.w $a2, $sp, 36
; FAULT-LA32-NEXT:    ld.w $a1, $a1, 0
; FAULT-LA32-NEXT:    st.w $a1, $sp, 32
; FAULT-LA32-NEXT:    xvld $xr0, $sp, 32
; FAULT-LA32-NEXT:    pcalau12i $a1, %pc_hi20(.LCPI1_0)
; FAULT-LA32-NEXT:    xvld $xr1, $a1, %pc_lo12(.LCPI1_0)
; FAULT-LA32-NEXT:    xvfsqrt.d $xr0, $xr0
; FAULT-LA32-NEXT:    xvfdiv.d $xr0, $xr1, $xr0
; FAULT-LA32-NEXT:    xvst $xr0, $sp, 64
; FAULT-LA32-NEXT:    vld $vr0, $sp, 80
; FAULT-LA32-NEXT:    vst $vr0, $a0, 16
; FAULT-LA32-NEXT:    ld.w $a1, $sp, 76
; FAULT-LA32-NEXT:    st.w $a1, $a0, 12
; FAULT-LA32-NEXT:    ld.w $a1, $sp, 72
; FAULT-LA32-NEXT:    st.w $a1, $a0, 8
; FAULT-LA32-NEXT:    ld.w $a1, $sp, 68
; FAULT-LA32-NEXT:    st.w $a1, $a0, 4
; FAULT-LA32-NEXT:    ld.w $a1, $sp, 64
; FAULT-LA32-NEXT:    st.w $a1, $a0, 0
; FAULT-LA32-NEXT:    addi.w $sp, $fp, -128
; FAULT-LA32-NEXT:    ld.w $fp, $sp, 120 # 4-byte Folded Reload
; FAULT-LA32-NEXT:    ld.w $ra, $sp, 124 # 4-byte Folded Reload
; FAULT-LA32-NEXT:    addi.w $sp, $sp, 128
; FAULT-LA32-NEXT:    ret
;
; LA32-LABEL: one_div_sqrt_v4f64:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    addi.w $sp, $sp, -128
; LA32-NEXT:    st.w $ra, $sp, 124 # 4-byte Folded Spill
; LA32-NEXT:    st.w $fp, $sp, 120 # 4-byte Folded Spill
; LA32-NEXT:    addi.w $fp, $sp, 128
; LA32-NEXT:    bstrins.w $sp, $zero, 4, 0
; LA32-NEXT:    vld $vr0, $a1, 16
; LA32-NEXT:    vst $vr0, $sp, 48
; LA32-NEXT:    ld.w $a2, $a1, 12
; LA32-NEXT:    st.w $a2, $sp, 44
; LA32-NEXT:    ld.w $a2, $a1, 8
; LA32-NEXT:    st.w $a2, $sp, 40
; LA32-NEXT:    ld.w $a2, $a1, 4
; LA32-NEXT:    st.w $a2, $sp, 36
; LA32-NEXT:    ld.w $a1, $a1, 0
; LA32-NEXT:    st.w $a1, $sp, 32
; LA32-NEXT:    xvld $xr0, $sp, 32
; LA32-NEXT:    xvfrsqrte.d $xr1, $xr0
; LA32-NEXT:    pcalau12i $a1, %pc_hi20(.LCPI1_0)
; LA32-NEXT:    xvld $xr2, $a1, %pc_lo12(.LCPI1_0)
; LA32-NEXT:    pcalau12i $a1, %pc_hi20(.LCPI1_1)
; LA32-NEXT:    xvld $xr3, $a1, %pc_lo12(.LCPI1_1)
; LA32-NEXT:    xvfmul.d $xr1, $xr0, $xr1
; LA32-NEXT:    xvfmul.d $xr4, $xr0, $xr1
; LA32-NEXT:    xvfmadd.d $xr4, $xr4, $xr1, $xr2
; LA32-NEXT:    xvfmul.d $xr1, $xr1, $xr3
; LA32-NEXT:    xvfmul.d $xr1, $xr1, $xr4
; LA32-NEXT:    xvfmul.d $xr0, $xr0, $xr1
; LA32-NEXT:    xvfmadd.d $xr0, $xr0, $xr1, $xr2
; LA32-NEXT:    xvfmul.d $xr1, $xr1, $xr3
; LA32-NEXT:    xvfmul.d $xr0, $xr1, $xr0
; LA32-NEXT:    xvst $xr0, $sp, 64
; LA32-NEXT:    vld $vr0, $sp, 80
; LA32-NEXT:    vst $vr0, $a0, 16
; LA32-NEXT:    ld.w $a1, $sp, 76
; LA32-NEXT:    st.w $a1, $a0, 12
; LA32-NEXT:    ld.w $a1, $sp, 72
; LA32-NEXT:    st.w $a1, $a0, 8
; LA32-NEXT:    ld.w $a1, $sp, 68
; LA32-NEXT:    st.w $a1, $a0, 4
; LA32-NEXT:    ld.w $a1, $sp, 64
; LA32-NEXT:    st.w $a1, $a0, 0
; LA32-NEXT:    addi.w $sp, $fp, -128
; LA32-NEXT:    ld.w $fp, $sp, 120 # 4-byte Folded Reload
; LA32-NEXT:    ld.w $ra, $sp, 124 # 4-byte Folded Reload
; LA32-NEXT:    addi.w $sp, $sp, 128
; LA32-NEXT:    ret
;
; FAULT-LA64-LABEL: one_div_sqrt_v4f64:
; FAULT-LA64:       # %bb.0: # %entry
; FAULT-LA64-NEXT:    xvld $xr0, $a1, 0
; FAULT-LA64-NEXT:    xvfrsqrt.d $xr0, $xr0
; FAULT-LA64-NEXT:    xvst $xr0, $a0, 0
; FAULT-LA64-NEXT:    ret
;
; LA64-LABEL: one_div_sqrt_v4f64:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    xvld $xr0, $a1, 0
; LA64-NEXT:    xvfrsqrte.d $xr1, $xr0
; LA64-NEXT:    xvfmul.d $xr1, $xr0, $xr1
; LA64-NEXT:    xvfmul.d $xr2, $xr0, $xr1
; LA64-NEXT:    ori $a1, $zero, 0
; LA64-NEXT:    lu32i.d $a1, -524288
; LA64-NEXT:    lu52i.d $a1, $a1, -1024
; LA64-NEXT:    xvreplgr2vr.d $xr3, $a1
; LA64-NEXT:    xvfmadd.d $xr2, $xr2, $xr1, $xr3
; LA64-NEXT:    lu52i.d $a1, $zero, -1026
; LA64-NEXT:    xvreplgr2vr.d $xr4, $a1
; LA64-NEXT:    xvfmul.d $xr1, $xr1, $xr4
; LA64-NEXT:    xvfmul.d $xr1, $xr1, $xr2
; LA64-NEXT:    xvfmul.d $xr0, $xr0, $xr1
; LA64-NEXT:    xvfmadd.d $xr0, $xr0, $xr1, $xr3
; LA64-NEXT:    xvfmul.d $xr1, $xr1, $xr4
; LA64-NEXT:    xvfmul.d $xr0, $xr1, $xr0
; LA64-NEXT:    xvst $xr0, $a0, 0
; LA64-NEXT:    ret
entry:
  %v0 = load <4 x double>, ptr %a0, align 16
  %sqrt = call fast <4 x double> @llvm.sqrt.v4f64 (<4 x double> %v0)
  %div = fdiv fast <4 x double> <double 1.0, double 1.0, double 1.0, double 1.0>, %sqrt
  store <4 x double> %div, ptr %res, align 16
  ret void
}

declare <8 x float> @llvm.sqrt.v8f32(<8 x float>)
declare <4 x double> @llvm.sqrt.v4f64(<4 x double>)
