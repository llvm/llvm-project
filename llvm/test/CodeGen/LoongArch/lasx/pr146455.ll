; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc --mtriple=loongarch64 -mattr=+d -mattr=+lasx < %s | FileCheck %s

define void @foo(ptr %0, ptr %1, ptr %2, ptr %3, ptr %4, ptr %5, ptr %6, ptr %7, ptr %8, ptr %9, ptr %10, float %11, ptr %_QMmodule_ra_rrtmEabsa12, <8 x float> %12, <8 x float> %13, <8 x float> %14) {
; CHECK-LABEL: foo:
; CHECK:       # %bb.0: # %.lr.ph.preheader
; CHECK-NEXT:    addi.d $sp, $sp, -736
; CHECK-NEXT:    .cfi_def_cfa_offset 736
; CHECK-NEXT:    st.d $ra, $sp, 728 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $fp, $sp, 720 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s0, $sp, 712 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s1, $sp, 704 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s2, $sp, 696 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s3, $sp, 688 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s4, $sp, 680 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s5, $sp, 672 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s6, $sp, 664 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s7, $sp, 656 # 8-byte Folded Spill
; CHECK-NEXT:    st.d $s8, $sp, 648 # 8-byte Folded Spill
; CHECK-NEXT:    fst.d $fs0, $sp, 640 # 8-byte Folded Spill
; CHECK-NEXT:    fst.d $fs1, $sp, 632 # 8-byte Folded Spill
; CHECK-NEXT:    fst.d $fs2, $sp, 624 # 8-byte Folded Spill
; CHECK-NEXT:    fst.d $fs3, $sp, 616 # 8-byte Folded Spill
; CHECK-NEXT:    fst.d $fs4, $sp, 608 # 8-byte Folded Spill
; CHECK-NEXT:    fst.d $fs5, $sp, 600 # 8-byte Folded Spill
; CHECK-NEXT:    fst.d $fs6, $sp, 592 # 8-byte Folded Spill
; CHECK-NEXT:    fst.d $fs7, $sp, 584 # 8-byte Folded Spill
; CHECK-NEXT:    .cfi_offset 1, -8
; CHECK-NEXT:    .cfi_offset 22, -16
; CHECK-NEXT:    .cfi_offset 23, -24
; CHECK-NEXT:    .cfi_offset 24, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 26, -48
; CHECK-NEXT:    .cfi_offset 27, -56
; CHECK-NEXT:    .cfi_offset 28, -64
; CHECK-NEXT:    .cfi_offset 29, -72
; CHECK-NEXT:    .cfi_offset 30, -80
; CHECK-NEXT:    .cfi_offset 31, -88
; CHECK-NEXT:    .cfi_offset 56, -96
; CHECK-NEXT:    .cfi_offset 57, -104
; CHECK-NEXT:    .cfi_offset 58, -112
; CHECK-NEXT:    .cfi_offset 59, -120
; CHECK-NEXT:    .cfi_offset 60, -128
; CHECK-NEXT:    .cfi_offset 61, -136
; CHECK-NEXT:    .cfi_offset 62, -144
; CHECK-NEXT:    .cfi_offset 63, -152
; CHECK-NEXT:    addi.d $fp, $sp, 736
; CHECK-NEXT:    .cfi_def_cfa 22, 0
; CHECK-NEXT:    bstrins.d $sp, $zero, 4, 0
; CHECK-NEXT:    ld.d $t0, $fp, 24
; CHECK-NEXT:    ld.d $t1, $fp, 16
; CHECK-NEXT:    ld.d $t2, $fp, 8
; CHECK-NEXT:    ld.d $t3, $fp, 0
; CHECK-NEXT:    movgr2fr.w $fa4, $zero
; CHECK-NEXT:    xvst $xr4, $sp, 288 # 32-byte Folded Spill
; CHECK-NEXT:    fmul.s $fa4, $fa0, $fa4
; CHECK-NEXT:    pcalau12i $t4, %pc_hi20(.LCPI0_0)
; CHECK-NEXT:    xvld $xr0, $t4, %pc_lo12(.LCPI0_0)
; CHECK-NEXT:    xvst $xr0, $sp, 256 # 32-byte Folded Spill
; CHECK-NEXT:    pcalau12i $t4, %pc_hi20(.LCPI0_1)
; CHECK-NEXT:    fld.s $fa5, $t4, %pc_lo12(.LCPI0_1)
; CHECK-NEXT:    xvst $xr2, $sp, 352 # 32-byte Folded Spill
; CHECK-NEXT:    xvpermi.d $xr2, $xr2, 68
; CHECK-NEXT:    xvrepl128vei.w $xr2, $xr2, 1
; CHECK-NEXT:    xvpickve2gr.w $t4, $xr1, 0
; CHECK-NEXT:    movgr2fr.w $fa0, $t4
; CHECK-NEXT:    xvpermi.d $xr2, $xr2, 68
; CHECK-NEXT:    xvst $xr2, $sp, 224 # 32-byte Folded Spill
; CHECK-NEXT:    movfr2gr.s $t4, $fa0
; CHECK-NEXT:    xvrepli.b $xr6, 0
; CHECK-NEXT:    pcalau12i $t5, %pc_hi20(.LCPI0_2)
; CHECK-NEXT:    xvld $xr0, $t5, %pc_lo12(.LCPI0_2)
; CHECK-NEXT:    xvst $xr0, $sp, 192 # 32-byte Folded Spill
; CHECK-NEXT:    xvpermi.d $xr0, $xr4, 68
; CHECK-NEXT:    xvst $xr0, $sp, 160 # 32-byte Folded Spill
; CHECK-NEXT:    pcalau12i $t5, %pc_hi20(.LCPI0_3)
; CHECK-NEXT:    xvld $xr0, $t5, %pc_lo12(.LCPI0_3)
; CHECK-NEXT:    xvst $xr0, $sp, 128 # 32-byte Folded Spill
; CHECK-NEXT:    xvpickve2gr.w $t5, $xr1, 1
; CHECK-NEXT:    movgr2fr.w $fa0, $t5
; CHECK-NEXT:    vinsgr2vr.w $vr4, $t4, 0
; CHECK-NEXT:    movfr2gr.s $t5, $fa0
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr1, 2
; CHECK-NEXT:    movgr2fr.w $fa0, $t6
; CHECK-NEXT:    vinsgr2vr.w $vr4, $t5, 1
; CHECK-NEXT:    movfr2gr.s $t5, $fa0
; CHECK-NEXT:    pcalau12i $t6, %pc_hi20(.LCPI0_4)
; CHECK-NEXT:    fld.d $fa0, $t6, %pc_lo12(.LCPI0_4)
; CHECK-NEXT:    xvst $xr1, $sp, 320 # 32-byte Folded Spill
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr1, 3
; CHECK-NEXT:    movgr2fr.w $fa2, $t6
; CHECK-NEXT:    vinsgr2vr.w $vr4, $t5, 2
; CHECK-NEXT:    movfr2gr.s $t5, $fa2
; CHECK-NEXT:    vinsgr2vr.w $vr4, $t5, 3
; CHECK-NEXT:    vst $vr4, $sp, 112 # 16-byte Folded Spill
; CHECK-NEXT:    movfr2gr.d $t5, $fa0
; CHECK-NEXT:    lu12i.w $t6, 260096
; CHECK-NEXT:    xvreplgr2vr.w $xr1, $t6
; CHECK-NEXT:    pcalau12i $t7, %pc_hi20(.LCPI0_5)
; CHECK-NEXT:    xvld $xr0, $t7, %pc_lo12(.LCPI0_5)
; CHECK-NEXT:    xvst $xr0, $sp, 64 # 32-byte Folded Spill
; CHECK-NEXT:    pcalau12i $t7, %pc_hi20(.LCPI0_6)
; CHECK-NEXT:    xvld $xr13, $t7, %pc_lo12(.LCPI0_6)
; CHECK-NEXT:    pcalau12i $t7, %pc_hi20(.LCPI0_7)
; CHECK-NEXT:    xvld $xr0, $t7, %pc_lo12(.LCPI0_7)
; CHECK-NEXT:    xvst $xr0, $sp, 32 # 32-byte Folded Spill
; CHECK-NEXT:    pcalau12i $t7, %pc_hi20(.LCPI0_8)
; CHECK-NEXT:    xvld $xr15, $t7, %pc_lo12(.LCPI0_8)
; CHECK-NEXT:    pcalau12i $t7, %pc_hi20(.LCPI0_9)
; CHECK-NEXT:    xvld $xr16, $t7, %pc_lo12(.LCPI0_9)
; CHECK-NEXT:    xvori.b $xr12, $xr5, 0
; CHECK-NEXT:    movfr2gr.s $t7, $fa5
; CHECK-NEXT:    pcalau12i $t8, %pc_hi20(.LCPI0_10)
; CHECK-NEXT:    xvld $xr5, $t8, %pc_lo12(.LCPI0_10)
; CHECK-NEXT:    pcalau12i $t8, %pc_hi20(.LCPI0_11)
; CHECK-NEXT:    xvld $xr18, $t8, %pc_lo12(.LCPI0_11)
; CHECK-NEXT:    xvpickve2gr.w $t8, $xr3, 0
; CHECK-NEXT:    movgr2fr.w $fa2, $t8
; CHECK-NEXT:    xvpickve2gr.w $t8, $xr3, 1
; CHECK-NEXT:    movgr2fr.w $fa0, $t8
; CHECK-NEXT:    movfr2gr.s $t8, $fa2
; CHECK-NEXT:    vinsgr2vr.w $vr19, $t8, 0
; CHECK-NEXT:    movfr2gr.s $t8, $fa0
; CHECK-NEXT:    vinsgr2vr.w $vr19, $t8, 1
; CHECK-NEXT:    xvpickve2gr.w $t8, $xr3, 2
; CHECK-NEXT:    movgr2fr.w $fa2, $t8
; CHECK-NEXT:    xvori.b $xr11, $xr3, 0
; CHECK-NEXT:    xvpickve2gr.w $t8, $xr3, 3
; CHECK-NEXT:    movgr2fr.w $fa3, $t8
; CHECK-NEXT:    pcalau12i $t8, %pc_hi20(.LCPI0_12)
; CHECK-NEXT:    xvld $xr20, $t8, %pc_lo12(.LCPI0_12)
; CHECK-NEXT:    movfr2gr.s $t8, $fa2
; CHECK-NEXT:    xvori.b $xr14, $xr6, 0
; CHECK-NEXT:    xvpermi.d $xr21, $xr6, 68
; CHECK-NEXT:    xvpermi.d $xr22, $xr1, 68
; CHECK-NEXT:    vinsgr2vr.w $vr19, $t8, 2
; CHECK-NEXT:    movfr2gr.s $t8, $fa3
; CHECK-NEXT:    vldi $vr23, -1168
; CHECK-NEXT:    vinsgr2vr.w $vr19, $t8, 3
; CHECK-NEXT:    .p2align 4, , 16
; CHECK-NEXT:  .LBB0_1: # %.lr.ph
; CHECK-NEXT:    # =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    ld.d $s8, $t1, 0
; CHECK-NEXT:    ld.d $s1, $a6, 0
; CHECK-NEXT:    ld.d $s5, $t3, 0
; CHECK-NEXT:    ld.d $ra, $t2, 0
; CHECK-NEXT:    ld.d $s2, $a5, 0
; CHECK-NEXT:    ld.d $s7, $a2, 0
; CHECK-NEXT:    ld.d $s0, $a7, 0
; CHECK-NEXT:    ld.d $s6, $t0, 0
; CHECK-NEXT:    ld.d $s3, $a3, 0
; CHECK-NEXT:    ld.d $t8, $a4, 0
; CHECK-NEXT:    xvpermi.d $xr24, $xr12, 68
; CHECK-NEXT:    xvld $xr1, $sp, 256 # 32-byte Folded Reload
; CHECK-NEXT:    xvld $xr0, $sp, 224 # 32-byte Folded Reload
; CHECK-NEXT:    xvshuf.w $xr1, $xr0, $xr24
; CHECK-NEXT:    xvpickve2gr.w $s4, $xr1, 0
; CHECK-NEXT:    movgr2fr.w $fa2, $s4
; CHECK-NEXT:    ld.d $s4, $a0, 0
; CHECK-NEXT:    movfr2gr.s $t6, $fa2
; CHECK-NEXT:    xvinsgr2vr.w $xr25, $t6, 0
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr1, 1
; CHECK-NEXT:    movgr2fr.w $fa2, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr1, 2
; CHECK-NEXT:    movgr2fr.w $fa3, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa2
; CHECK-NEXT:    xvinsgr2vr.w $xr25, $t6, 1
; CHECK-NEXT:    movfr2gr.s $t6, $fa3
; CHECK-NEXT:    xvinsgr2vr.w $xr25, $t6, 2
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr1, 3
; CHECK-NEXT:    movgr2fr.w $fa2, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr1, 4
; CHECK-NEXT:    movgr2fr.w $fa3, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa2
; CHECK-NEXT:    xvinsgr2vr.w $xr25, $t6, 3
; CHECK-NEXT:    movfr2gr.s $t6, $fa3
; CHECK-NEXT:    xvinsgr2vr.w $xr25, $t6, 4
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr1, 5
; CHECK-NEXT:    movgr2fr.w $fa2, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr1, 6
; CHECK-NEXT:    movgr2fr.w $fa1, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa2
; CHECK-NEXT:    xvld $xr0, $sp, 352 # 32-byte Folded Reload
; CHECK-NEXT:    st.d $a1, $sp, 0 # 8-byte Folded Spill
; CHECK-NEXT:    addi.d $a1, $sp, 564
; CHECK-NEXT:    xvstelm.w $xr0, $a1, 0, 0
; CHECK-NEXT:    xvld $xr0, $sp, 320 # 32-byte Folded Reload
; CHECK-NEXT:    addi.d $a1, $sp, 560
; CHECK-NEXT:    xvstelm.w $xr0, $a1, 0, 4
; CHECK-NEXT:    ld.d $a1, $sp, 0 # 8-byte Folded Reload
; CHECK-NEXT:    vld $vr0, $sp, 112 # 16-byte Folded Reload
; CHECK-NEXT:    vst $vr0, $sp, 544
; CHECK-NEXT:    xvld $xr2, $sp, 544
; CHECK-NEXT:    xvinsgr2vr.w $xr25, $t6, 5
; CHECK-NEXT:    movfr2gr.s $t6, $fa1
; CHECK-NEXT:    xvinsgr2vr.w $xr25, $t6, 6
; CHECK-NEXT:    xvinsgr2vr.d $xr27, $s8, 0
; CHECK-NEXT:    xvpickve2gr.d $t6, $xr2, 0
; CHECK-NEXT:    movgr2fr.d $fa1, $t6
; CHECK-NEXT:    xvinsgr2vr.d $xr28, $ra, 0
; CHECK-NEXT:    movfr2gr.d $t6, $fa1
; CHECK-NEXT:    xvinsgr2vr.d $xr26, $t6, 0
; CHECK-NEXT:    xvpickve2gr.d $t6, $xr2, 1
; CHECK-NEXT:    movgr2fr.d $fa1, $t6
; CHECK-NEXT:    xvpickve2gr.d $t6, $xr2, 2
; CHECK-NEXT:    movgr2fr.d $fa2, $t6
; CHECK-NEXT:    movfr2gr.d $t6, $fa1
; CHECK-NEXT:    xvinsgr2vr.d $xr26, $t6, 1
; CHECK-NEXT:    movfr2gr.d $t6, $fa2
; CHECK-NEXT:    xvinsgr2vr.d $xr26, $t6, 2
; CHECK-NEXT:    xvinsgr2vr.d $xr1, $s5, 0
; CHECK-NEXT:    xvinsgr2vr.d $xr2, $s7, 0
; CHECK-NEXT:    xvinsgr2vr.d $xr3, $s6, 0
; CHECK-NEXT:    xvpermi.d $xr1, $xr1, 68
; CHECK-NEXT:    xvpermi.d $xr2, $xr2, 68
; CHECK-NEXT:    xvpackev.w $xr1, $xr2, $xr1
; CHECK-NEXT:    xvpermi.d $xr1, $xr1, 68
; CHECK-NEXT:    xvpermi.d $xr1, $xr1, 68
; CHECK-NEXT:    xvpermi.d $xr2, $xr3, 68
; CHECK-NEXT:    xvpermi.d $xr2, $xr2, 68
; CHECK-NEXT:    xvpackev.d $xr1, $xr2, $xr1
; CHECK-NEXT:    xvand.v $xr1, $xr1, $xr15
; CHECK-NEXT:    lu12i.w $t6, 260096
; CHECK-NEXT:    st.w $t6, $sp, 468
; CHECK-NEXT:    xvstelm.w $xr1, $sp, 464, 4
; CHECK-NEXT:    xvstelm.w $xr1, $sp, 460, 3
; CHECK-NEXT:    xvstelm.w $xr1, $sp, 456, 2
; CHECK-NEXT:    xvstelm.w $xr1, $sp, 452, 1
; CHECK-NEXT:    xvstelm.w $xr1, $sp, 448, 0
; CHECK-NEXT:    xvld $xr1, $sp, 448
; CHECK-NEXT:    xvinsgr2vr.d $xr30, $s1, 0
; CHECK-NEXT:    xvinsgr2vr.d $xr31, $s2, 0
; CHECK-NEXT:    xvinsgr2vr.d $xr17, $s3, 0
; CHECK-NEXT:    xvand.v $xr3, $xr1, $xr16
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr3, 0
; CHECK-NEXT:    movgr2fr.w $fa1, $t6
; CHECK-NEXT:    xvld $xr0, $sp, 288 # 32-byte Folded Reload
; CHECK-NEXT:    xvpermi.d $xr4, $xr0, 68
; CHECK-NEXT:    xvinsgr2vr.d $xr2, $s4, 0
; CHECK-NEXT:    movfr2gr.s $t6, $fa1
; CHECK-NEXT:    xvinsgr2vr.w $xr29, $t6, 0
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr3, 1
; CHECK-NEXT:    movgr2fr.w $fa1, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr3, 2
; CHECK-NEXT:    movgr2fr.w $fa0, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa1
; CHECK-NEXT:    xvinsgr2vr.w $xr29, $t6, 1
; CHECK-NEXT:    movfr2gr.s $t6, $fa0
; CHECK-NEXT:    xvinsgr2vr.w $xr29, $t6, 2
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr3, 3
; CHECK-NEXT:    movgr2fr.w $fa0, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr3, 4
; CHECK-NEXT:    movgr2fr.w $fa1, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa0
; CHECK-NEXT:    xvinsgr2vr.w $xr29, $t6, 3
; CHECK-NEXT:    movfr2gr.s $t6, $fa1
; CHECK-NEXT:    xvinsgr2vr.w $xr29, $t6, 4
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr3, 5
; CHECK-NEXT:    movgr2fr.w $fa1, $t6
; CHECK-NEXT:    xvpermi.d $xr0, $xr17, 68
; CHECK-NEXT:    xvrepl128vei.w $xr0, $xr0, 1
; CHECK-NEXT:    xvpermi.d $xr0, $xr0, 68
; CHECK-NEXT:    xvori.b $xr17, $xr5, 0
; CHECK-NEXT:    xvshuf.w $xr17, $xr0, $xr4
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr17, 0
; CHECK-NEXT:    movgr2fr.w $fa0, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr17, 1
; CHECK-NEXT:    movgr2fr.w $fa6, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa0
; CHECK-NEXT:    vinsgr2vr.w $vr0, $t6, 0
; CHECK-NEXT:    movfr2gr.s $t6, $fa6
; CHECK-NEXT:    vinsgr2vr.w $vr0, $t6, 1
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr17, 2
; CHECK-NEXT:    movgr2fr.w $fa6, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr17, 3
; CHECK-NEXT:    movgr2fr.w $fa7, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa6
; CHECK-NEXT:    vinsgr2vr.w $vr0, $t6, 2
; CHECK-NEXT:    movfr2gr.s $t6, $fa7
; CHECK-NEXT:    vinsgr2vr.w $vr0, $t6, 3
; CHECK-NEXT:    xvinsgr2vr.d $xr6, $s0, 0
; CHECK-NEXT:    xvpermi.d $xr6, $xr6, 68
; CHECK-NEXT:    xvpackod.w $xr6, $xr6, $xr21
; CHECK-NEXT:    xvpermi.d $xr6, $xr6, 68
; CHECK-NEXT:    xvori.b $xr7, $xr18, 0
; CHECK-NEXT:    xvshuf.w $xr7, $xr22, $xr6
; CHECK-NEXT:    xvand.v $xr6, $xr7, $xr15
; CHECK-NEXT:    xvinsgr2vr.d $xr7, $t8, 0
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr6, 0
; CHECK-NEXT:    movgr2fr.w $ft1, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr6, 1
; CHECK-NEXT:    movgr2fr.w $ft0, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $ft1
; CHECK-NEXT:    vinsgr2vr.w $vr9, $t6, 0
; CHECK-NEXT:    movfr2gr.s $t6, $ft0
; CHECK-NEXT:    vinsgr2vr.w $vr9, $t6, 1
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr6, 2
; CHECK-NEXT:    movgr2fr.w $ft0, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr6, 3
; CHECK-NEXT:    movgr2fr.w $ft2, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $ft0
; CHECK-NEXT:    vinsgr2vr.w $vr9, $t6, 2
; CHECK-NEXT:    movfr2gr.s $t6, $ft2
; CHECK-NEXT:    vinsgr2vr.w $vr9, $t6, 3
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr3, 6
; CHECK-NEXT:    xvstelm.w $xr2, $sp, 504, 1
; CHECK-NEXT:    xvstelm.w $xr17, $sp, 500, 5
; CHECK-NEXT:    xvstelm.w $xr17, $sp, 496, 4
; CHECK-NEXT:    vst $vr0, $sp, 480
; CHECK-NEXT:    xvld $xr2, $sp, 480
; CHECK-NEXT:    xvstelm.w $xr7, $sp, 436, 1
; CHECK-NEXT:    xvstelm.w $xr6, $sp, 432, 4
; CHECK-NEXT:    vst $vr9, $sp, 416
; CHECK-NEXT:    xvld $xr0, $sp, 416
; CHECK-NEXT:    movgr2fr.w $fa3, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa1
; CHECK-NEXT:    xvinsgr2vr.w $xr29, $t6, 5
; CHECK-NEXT:    movfr2gr.s $t6, $fa3
; CHECK-NEXT:    xvinsgr2vr.w $xr29, $t6, 6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr0, 0
; CHECK-NEXT:    movgr2fr.w $fa1, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr0, 1
; CHECK-NEXT:    movgr2fr.w $fa3, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa1
; CHECK-NEXT:    vinsgr2vr.w $vr1, $t6, 0
; CHECK-NEXT:    movfr2gr.s $t6, $fa3
; CHECK-NEXT:    vinsgr2vr.w $vr1, $t6, 1
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr0, 2
; CHECK-NEXT:    movgr2fr.w $fa3, $t6
; CHECK-NEXT:    xvpickve2gr.w $t6, $xr0, 3
; CHECK-NEXT:    movgr2fr.w $fa6, $t6
; CHECK-NEXT:    movfr2gr.s $t6, $fa3
; CHECK-NEXT:    vinsgr2vr.w $vr1, $t6, 2
; CHECK-NEXT:    movfr2gr.s $t6, $fa6
; CHECK-NEXT:    vinsgr2vr.w $vr1, $t6, 3
; CHECK-NEXT:    xvpermi.d $xr3, $xr27, 68
; CHECK-NEXT:    xvpermi.d $xr6, $xr28, 68
; CHECK-NEXT:    xvld $xr7, $sp, 192 # 32-byte Folded Reload
; CHECK-NEXT:    xvshuf.w $xr7, $xr6, $xr3
; CHECK-NEXT:    xvinsgr2vr.w $xr25, $t4, 7
; CHECK-NEXT:    xvfmul.s $xr3, $xr25, $xr14
; CHECK-NEXT:    xvfadd.s $xr3, $xr3, $xr7
; CHECK-NEXT:    xvori.b $xr6, $xr13, 0
; CHECK-NEXT:    xvshuf.w $xr6, $xr24, $xr4
; CHECK-NEXT:    xvld $xr7, $sp, 128 # 32-byte Folded Reload
; CHECK-NEXT:    xvld $xr8, $sp, 160 # 32-byte Folded Reload
; CHECK-NEXT:    xvshuf.w $xr7, $xr4, $xr8
; CHECK-NEXT:    xvinsgr2vr.d $xr26, $t5, 3
; CHECK-NEXT:    xvld $xr4, $sp, 64 # 32-byte Folded Reload
; CHECK-NEXT:    xvand.v $xr4, $xr26, $xr4
; CHECK-NEXT:    xvfmul.s $xr4, $xr7, $xr4
; CHECK-NEXT:    xvfadd.s $xr3, $xr3, $xr4
; CHECK-NEXT:    xvfadd.s $xr3, $xr3, $xr6
; CHECK-NEXT:    xvpermi.d $xr4, $xr30, 68
; CHECK-NEXT:    xvpermi.d $xr6, $xr31, 68
; CHECK-NEXT:    xvpackod.w $xr4, $xr6, $xr4
; CHECK-NEXT:    xvld $xr6, $sp, 32 # 32-byte Folded Reload
; CHECK-NEXT:    xvand.v $xr4, $xr4, $xr6
; CHECK-NEXT:    xvfadd.s $xr3, $xr3, $xr4
; CHECK-NEXT:    fst.s $ft15, $sp, 408
; CHECK-NEXT:    xvstelm.w $xr0, $sp, 404, 5
; CHECK-NEXT:    xvstelm.w $xr0, $sp, 400, 4
; CHECK-NEXT:    vst $vr1, $sp, 384
; CHECK-NEXT:    xvld $xr0, $sp, 384
; CHECK-NEXT:    addi.d $t6, $sp, 528
; CHECK-NEXT:    xvstelm.w $xr11, $t6, 0, 4
; CHECK-NEXT:    fst.s $ft15, $sp, 532
; CHECK-NEXT:    vst $vr19, $sp, 512
; CHECK-NEXT:    xvld $xr1, $sp, 512
; CHECK-NEXT:    xvinsgr2vr.w $xr29, $t7, 7
; CHECK-NEXT:    xvfadd.s $xr3, $xr3, $xr29
; CHECK-NEXT:    xvfadd.s $xr2, $xr3, $xr2
; CHECK-NEXT:    xvand.v $xr1, $xr1, $xr20
; CHECK-NEXT:    xvfsub.s $xr0, $xr0, $xr1
; CHECK-NEXT:    xvfadd.s $xr0, $xr2, $xr0
; CHECK-NEXT:    xvst $xr0, $a1, 0
; CHECK-NEXT:    b .LBB0_1
.lr.ph.preheader:
  br label %.lr.ph

.lr.ph:                                           ; preds = %.lr.ph, %.lr.ph.preheader
  %15 = fmul float 0.000000e+00, %11
  %16 = load <2 x float>, ptr %10, align 4
  %17 = load <2 x float>, ptr %6, align 4
  %18 = load <2 x float>, ptr %8, align 4
  %19 = load <2 x float>, ptr %9, align 4
  %20 = load <2 x float>, ptr %5, align 4
  %21 = load <2 x float>, ptr %2, align 4
  %22 = load <2 x float>, ptr %7, align 4
  %23 = load <2 x float>, ptr %_QMmodule_ra_rrtmEabsa12, align 4
  %24 = load <2 x float>, ptr %3, align 4
  %25 = load <2 x float>, ptr %4, align 4
  %26 = load <2 x float>, ptr %0, align 4
  %27 = shufflevector <8 x float> splat (float 0x7FF8000000000000), <8 x float> %13, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 9, i32 poison>
  %28 = shufflevector <8 x float> %27, <8 x float> %12, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 8>
  %29 = fmul <8 x float> zeroinitializer, %28
  %30 = shufflevector <2 x float> %16, <2 x float> %19, <8 x i32> <i32 0, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %31 = fadd <8 x float> %29, %30
  %32 = insertelement <8 x float> zeroinitializer, float %15, i64 0
  %33 = shufflevector <8 x float> %12, <8 x float> %13, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 8, i32 poison, i32 poison>
  %34 = shufflevector <8 x float> %33, <8 x float> splat (float 1.000000e+00), <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 poison>
  %35 = shufflevector <8 x float> %34, <8 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 8>
  %36 = fmul <8 x float> %32, %35
  %37 = fadd <8 x float> %31, %36
  %38 = shufflevector <8 x float> zeroinitializer, <8 x float> splat (float 0x7FF8000000000000), <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 9>
  %39 = fadd <8 x float> %37, %38
  %40 = shufflevector <2 x float> %17, <2 x float> %20, <8 x i32> <i32 1, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %41 = shufflevector <8 x float> %40, <8 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 9, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %42 = fadd <8 x float> %39, %41
  %43 = shufflevector <2 x float> %18, <2 x float> %21, <8 x i32> <i32 0, i32 2, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %44 = shufflevector <2 x float> %23, <2 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %45 = shufflevector <8 x float> %43, <8 x float> %44, <8 x i32> <i32 0, i32 1, i32 8, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %46 = shufflevector <8 x float> %45, <8 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 2, i32 8, i32 poison, i32 poison, i32 poison, i32 poison>
  %47 = shufflevector <8 x float> %46, <8 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 poison, i32 poison, i32 poison>
  %48 = shufflevector <2 x float> %24, <2 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %49 = shufflevector <8 x float> %47, <8 x float> splat (float 1.000000e+00), <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 8, i32 poison, i32 poison>
  %50 = shufflevector <2 x float> %26, <2 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %51 = shufflevector <8 x float> %49, <8 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 poison>
  %52 = shufflevector <8 x float> %51, <8 x float> splat (float 0x7FF8000000000000), <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 8>
  %53 = fadd <8 x float> %42, %52
  %54 = shufflevector <8 x float> zeroinitializer, <8 x float> %48, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 9, i32 poison, i32 poison>
  %55 = shufflevector <8 x float> %54, <8 x float> %50, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 9, i32 poison>
  %56 = fadd <8 x float> %53, %55
  %57 = shufflevector <2 x float> zeroinitializer, <2 x float> %22, <8 x i32> <i32 1, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %58 = shufflevector <8 x float> %57, <8 x float> splat (float 1.000000e+00), <8 x i32> <i32 0, i32 1, i32 9, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %59 = shufflevector <8 x float> %58, <8 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 2, i32 9, i32 poison, i32 poison, i32 poison, i32 poison>
  %60 = shufflevector <8 x float> %59, <8 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 9, i32 poison, i32 poison, i32 poison>
  %61 = shufflevector <2 x float> %25, <2 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
  %62 = shufflevector <8 x float> %60, <8 x float> %61, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 9, i32 poison, i32 poison>
  %63 = shufflevector <8 x float> %62, <8 x float> splat (float 1.000000e+00), <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 9, i32 poison>
  %64 = shufflevector <8 x float> %14, <8 x float> splat (float 1.000000e+00), <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 8, i32 poison, i32 poison>
  %65 = shufflevector <8 x float> %64, <8 x float> zeroinitializer, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 8>
  %66 = fsub <8 x float> %63, %65
  %67 = fadd <8 x float> %56, %66
  store <8 x float> %67, ptr %1, align 4
  br label %.lr.ph
}
