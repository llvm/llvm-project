; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc --mtriple=loongarch32 --mattr=+32s,+lasx < %s | FileCheck %s --check-prefixes=CHECK,LA32
; RUN: llc --mtriple=loongarch64 --mattr=+lasx < %s | FileCheck %s --check-prefixes=CHECK,LA64

define void @rotl_v32i8(ptr %dst, ptr %src, i8 signext %a0) nounwind {
; CHECK-LABEL: rotl_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvreplgr2vr.b $xr1, $a2
; CHECK-NEXT:    xvrepli.b $xr2, 8
; CHECK-NEXT:    xvsub.b $xr2, $xr2, $xr1
; CHECK-NEXT:    xvsll.b $xr1, $xr0, $xr1
; CHECK-NEXT:    xvsrl.b $xr0, $xr0, $xr2
; CHECK-NEXT:    xvor.v $xr0, $xr1, $xr0
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <32 x i8>, ptr %src
  %v1.ele = insertelement <32 x i8> poison, i8 %a0, i8 0
  %v1 = shufflevector <32 x i8> %v1.ele, <32 x i8> poison, <32 x i32> zeroinitializer
  %v1.sub = sub <32 x i8> splat (i8 8), %v1
  %b = shl <32 x i8> %v0, %v1
  %c = lshr <32 x i8> %v0, %v1.sub
  %d = or <32 x i8> %b, %c
  store <32 x i8> %d, ptr %dst
  ret void
}

define void @rotr_v32i8(ptr %dst, ptr %src, i8 signext %a0) nounwind {
; CHECK-LABEL: rotr_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvreplgr2vr.b $xr1, $a2
; CHECK-NEXT:    xvrepli.b $xr2, 8
; CHECK-NEXT:    xvsub.b $xr2, $xr2, $xr1
; CHECK-NEXT:    xvsrl.b $xr1, $xr0, $xr1
; CHECK-NEXT:    xvsll.b $xr0, $xr0, $xr2
; CHECK-NEXT:    xvor.v $xr0, $xr1, $xr0
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <32 x i8>, ptr %src
  %v1.ele = insertelement <32 x i8> poison, i8 %a0, i8 0
  %v1 = shufflevector <32 x i8> %v1.ele, <32 x i8> poison, <32 x i32> zeroinitializer
  %v1.sub = sub <32 x i8> splat (i8 8), %v1
  %b = lshr <32 x i8> %v0, %v1
  %c = shl <32 x i8> %v0, %v1.sub
  %d = or <32 x i8> %b, %c
  store <32 x i8> %d, ptr %dst
  ret void
}

define void @rotr_v32i8_imm(ptr %dst, ptr %src) nounwind {
; CHECK-LABEL: rotr_v32i8_imm:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvsrli.b $xr1, $xr0, 2
; CHECK-NEXT:    xvslli.b $xr0, $xr0, 6
; CHECK-NEXT:    xvor.v $xr0, $xr0, $xr1
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <32 x i8>, ptr %src
  %b = lshr <32 x i8> %v0, splat (i8 2)
  %c = shl <32 x i8> %v0, splat (i8 6)
  %d = or <32 x i8> %b, %c
  store <32 x i8> %d, ptr %dst
  ret void
}

define void @rotl_v16i16(ptr %dst, ptr %src, i16 signext %a0) nounwind {
; CHECK-LABEL: rotl_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvreplgr2vr.h $xr1, $a2
; CHECK-NEXT:    xvrepli.h $xr2, 16
; CHECK-NEXT:    xvsub.h $xr2, $xr2, $xr1
; CHECK-NEXT:    xvsll.h $xr1, $xr0, $xr1
; CHECK-NEXT:    xvsrl.h $xr0, $xr0, $xr2
; CHECK-NEXT:    xvor.v $xr0, $xr1, $xr0
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <16 x i16>, ptr %src
  %v1.ele = insertelement <16 x i16> poison, i16 %a0, i16 0
  %v1 = shufflevector <16 x i16> %v1.ele, <16 x i16> poison, <16 x i32> zeroinitializer
  %v1.sub = sub <16 x i16> splat (i16 16), %v1
  %b = shl <16 x i16> %v0, %v1
  %c = lshr <16 x i16> %v0, %v1.sub
  %d = or <16 x i16> %b, %c
  store <16 x i16> %d, ptr %dst
  ret void
}

define void @rotr_v16i16(ptr %dst, ptr %src, i16 signext %a0) nounwind {
; CHECK-LABEL: rotr_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvreplgr2vr.h $xr1, $a2
; CHECK-NEXT:    xvrepli.h $xr2, 16
; CHECK-NEXT:    xvsub.h $xr2, $xr2, $xr1
; CHECK-NEXT:    xvsrl.h $xr1, $xr0, $xr1
; CHECK-NEXT:    xvsll.h $xr0, $xr0, $xr2
; CHECK-NEXT:    xvor.v $xr0, $xr1, $xr0
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <16 x i16>, ptr %src
  %v1.ele = insertelement <16 x i16> poison, i16 %a0, i16 0
  %v1 = shufflevector <16 x i16> %v1.ele, <16 x i16> poison, <16 x i32> zeroinitializer
  %v1.sub = sub <16 x i16> splat (i16 16), %v1
  %b = lshr <16 x i16> %v0, %v1
  %c = shl <16 x i16> %v0, %v1.sub
  %d = or <16 x i16> %b, %c
  store <16 x i16> %d, ptr %dst
  ret void
}

define void @rotr_v16i16_imm(ptr %dst, ptr %src) nounwind {
; CHECK-LABEL: rotr_v16i16_imm:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvsrli.h $xr1, $xr0, 2
; CHECK-NEXT:    xvslli.h $xr0, $xr0, 14
; CHECK-NEXT:    xvor.v $xr0, $xr0, $xr1
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <16 x i16>, ptr %src
  %b = lshr <16 x i16> %v0, splat (i16 2)
  %c = shl <16 x i16> %v0, splat (i16 14)
  %d = or <16 x i16> %b, %c
  store <16 x i16> %d, ptr %dst
  ret void
}

define void @rotl_v8i32(ptr %dst, ptr %src, i32 signext %a0) nounwind {
; CHECK-LABEL: rotl_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvreplgr2vr.w $xr1, $a2
; CHECK-NEXT:    xvrepli.w $xr2, 32
; CHECK-NEXT:    xvsub.w $xr2, $xr2, $xr1
; CHECK-NEXT:    xvsll.w $xr1, $xr0, $xr1
; CHECK-NEXT:    xvsrl.w $xr0, $xr0, $xr2
; CHECK-NEXT:    xvor.v $xr0, $xr1, $xr0
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <8 x i32>, ptr %src
  %v1.ele = insertelement <8 x i32> poison, i32 %a0, i32 0
  %v1 = shufflevector <8 x i32> %v1.ele, <8 x i32> poison, <8 x i32> zeroinitializer
  %v1.sub = sub <8 x i32> splat (i32 32), %v1
  %b = shl <8 x i32> %v0, %v1
  %c = lshr <8 x i32> %v0, %v1.sub
  %d = or <8 x i32> %b, %c
  store <8 x i32> %d, ptr %dst
  ret void
}

define void @rotr_v8i32(ptr %dst, ptr %src, i32 signext %a0) nounwind {
; CHECK-LABEL: rotr_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvreplgr2vr.w $xr1, $a2
; CHECK-NEXT:    xvrepli.w $xr2, 32
; CHECK-NEXT:    xvsub.w $xr2, $xr2, $xr1
; CHECK-NEXT:    xvsrl.w $xr1, $xr0, $xr1
; CHECK-NEXT:    xvsll.w $xr0, $xr0, $xr2
; CHECK-NEXT:    xvor.v $xr0, $xr1, $xr0
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <8 x i32>, ptr %src
  %v1.ele = insertelement <8 x i32> poison, i32 %a0, i32 0
  %v1 = shufflevector <8 x i32> %v1.ele, <8 x i32> poison, <8 x i32> zeroinitializer
  %v1.sub = sub <8 x i32> splat (i32 32), %v1
  %b = lshr <8 x i32> %v0, %v1
  %c = shl <8 x i32> %v0, %v1.sub
  %d = or <8 x i32> %b, %c
  store <8 x i32> %d, ptr %dst
  ret void
}

define void @rotr_v8i32_imm(ptr %dst, ptr %src) nounwind {
; CHECK-LABEL: rotr_v8i32_imm:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvsrli.w $xr1, $xr0, 2
; CHECK-NEXT:    xvslli.w $xr0, $xr0, 30
; CHECK-NEXT:    xvor.v $xr0, $xr0, $xr1
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <8 x i32>, ptr %src
  %b = lshr <8 x i32> %v0, splat (i32 2)
  %c = shl <8 x i32> %v0, splat (i32 30)
  %d = or <8 x i32> %b, %c
  store <8 x i32> %d, ptr %dst
  ret void
}

define void @rotl_v4i64(ptr %dst, ptr %src, i64 %a0) nounwind {
; LA32-LABEL: rotl_v4i64:
; LA32:       # %bb.0:
; LA32-NEXT:    xvld $xr0, $a1, 0
; LA32-NEXT:    vinsgr2vr.w $vr1, $a2, 0
; LA32-NEXT:    vinsgr2vr.w $vr1, $a3, 1
; LA32-NEXT:    xvreplve0.d $xr1, $xr1
; LA32-NEXT:    xvrepli.d $xr2, 64
; LA32-NEXT:    xvsub.d $xr2, $xr2, $xr1
; LA32-NEXT:    xvsll.d $xr1, $xr0, $xr1
; LA32-NEXT:    xvsrl.d $xr0, $xr0, $xr2
; LA32-NEXT:    xvor.v $xr0, $xr1, $xr0
; LA32-NEXT:    xvst $xr0, $a0, 0
; LA32-NEXT:    ret
;
; LA64-LABEL: rotl_v4i64:
; LA64:       # %bb.0:
; LA64-NEXT:    xvld $xr0, $a1, 0
; LA64-NEXT:    xvreplgr2vr.d $xr1, $a2
; LA64-NEXT:    xvrepli.d $xr2, 64
; LA64-NEXT:    xvsub.d $xr2, $xr2, $xr1
; LA64-NEXT:    xvsll.d $xr1, $xr0, $xr1
; LA64-NEXT:    xvsrl.d $xr0, $xr0, $xr2
; LA64-NEXT:    xvor.v $xr0, $xr1, $xr0
; LA64-NEXT:    xvst $xr0, $a0, 0
; LA64-NEXT:    ret
  %v0 = load <4 x i64>, ptr %src
  %v1.ele = insertelement <4 x i64> poison, i64 %a0, i64 0
  %v1 = shufflevector <4 x i64> %v1.ele, <4 x i64> poison, <4 x i32> zeroinitializer
  %v1.sub = sub <4 x i64> splat (i64 64), %v1
  %b = shl <4 x i64> %v0, %v1
  %c = lshr <4 x i64> %v0, %v1.sub
  %d = or <4 x i64> %b, %c
  store <4 x i64> %d, ptr %dst
  ret void
}

define void @rotr_v4i64(ptr %dst, ptr %src, i64 %a0) nounwind {
; LA32-LABEL: rotr_v4i64:
; LA32:       # %bb.0:
; LA32-NEXT:    xvld $xr0, $a1, 0
; LA32-NEXT:    vinsgr2vr.w $vr1, $a2, 0
; LA32-NEXT:    vinsgr2vr.w $vr1, $a3, 1
; LA32-NEXT:    xvreplve0.d $xr1, $xr1
; LA32-NEXT:    xvrepli.d $xr2, 64
; LA32-NEXT:    xvsub.d $xr2, $xr2, $xr1
; LA32-NEXT:    xvsrl.d $xr1, $xr0, $xr1
; LA32-NEXT:    xvsll.d $xr0, $xr0, $xr2
; LA32-NEXT:    xvor.v $xr0, $xr1, $xr0
; LA32-NEXT:    xvst $xr0, $a0, 0
; LA32-NEXT:    ret
;
; LA64-LABEL: rotr_v4i64:
; LA64:       # %bb.0:
; LA64-NEXT:    xvld $xr0, $a1, 0
; LA64-NEXT:    xvreplgr2vr.d $xr1, $a2
; LA64-NEXT:    xvrepli.d $xr2, 64
; LA64-NEXT:    xvsub.d $xr2, $xr2, $xr1
; LA64-NEXT:    xvsrl.d $xr1, $xr0, $xr1
; LA64-NEXT:    xvsll.d $xr0, $xr0, $xr2
; LA64-NEXT:    xvor.v $xr0, $xr1, $xr0
; LA64-NEXT:    xvst $xr0, $a0, 0
; LA64-NEXT:    ret
  %v0 = load <4 x i64>, ptr %src
  %v1.ele = insertelement <4 x i64> poison, i64 %a0, i64 0
  %v1 = shufflevector <4 x i64> %v1.ele, <4 x i64> poison, <4 x i32> zeroinitializer
  %v1.sub = sub <4 x i64> splat (i64 64), %v1
  %b = lshr <4 x i64> %v0, %v1
  %c = shl <4 x i64> %v0, %v1.sub
  %d = or <4 x i64> %b, %c
  store <4 x i64> %d, ptr %dst
  ret void
}

define void @rotr_v4i64_imm(ptr %dst, ptr %src) nounwind {
; CHECK-LABEL: rotr_v4i64_imm:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xvld $xr0, $a1, 0
; CHECK-NEXT:    xvsrli.d $xr1, $xr0, 2
; CHECK-NEXT:    xvslli.d $xr0, $xr0, 62
; CHECK-NEXT:    xvor.v $xr0, $xr0, $xr1
; CHECK-NEXT:    xvst $xr0, $a0, 0
; CHECK-NEXT:    ret
  %v0 = load <4 x i64>, ptr %src
  %b = lshr <4 x i64> %v0, splat (i64 2)
  %c = shl <4 x i64> %v0, splat (i64 62)
  %d = or <4 x i64> %b, %c
  store <4 x i64> %d, ptr %dst
  ret void
}
