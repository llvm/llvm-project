; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc --mtriple=loongarch32 --mattr=+lasx < %s | FileCheck %s --check-prefix=LA32
; RUN: llc --mtriple=loongarch64 --mattr=+lasx < %s | FileCheck %s --check-prefix=LA64

declare <8 x float> @llvm.powi.v8f32.i32(<8 x float>, i32)

define <8 x float> @powi_v8f32(<8 x float> %va, i32 %b) nounwind {
; LA32-LABEL: powi_v8f32:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    addi.w $sp, $sp, -128
; LA32-NEXT:    st.w $ra, $sp, 124 # 4-byte Folded Spill
; LA32-NEXT:    st.w $fp, $sp, 120 # 4-byte Folded Spill
; LA32-NEXT:    move $fp, $a0
; LA32-NEXT:    xvst $xr0, $sp, 80 # 32-byte Folded Spill
; LA32-NEXT:    xvpickve.w $xr0, $xr0, 5
; LA32-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA32-NEXT:    bl __powisf2
; LA32-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA32-NEXT:    vst $vr0, $sp, 48 # 16-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.w $xr0, $xr0, 4
; LA32-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powisf2
; LA32-NEXT:    # kill: def $f0 killed $f0 def $xr0
; LA32-NEXT:    vld $vr1, $sp, 48 # 16-byte Folded Reload
; LA32-NEXT:    vextrins.w $vr0, $vr1, 16
; LA32-NEXT:    xvst $xr0, $sp, 48 # 32-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.w $xr0, $xr0, 6
; LA32-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powisf2
; LA32-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA32-NEXT:    xvld $xr1, $sp, 48 # 32-byte Folded Reload
; LA32-NEXT:    vextrins.w $vr1, $vr0, 32
; LA32-NEXT:    xvst $xr1, $sp, 48 # 32-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.w $xr0, $xr0, 7
; LA32-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powisf2
; LA32-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA32-NEXT:    xvld $xr1, $sp, 48 # 32-byte Folded Reload
; LA32-NEXT:    vextrins.w $vr1, $vr0, 48
; LA32-NEXT:    xvst $xr1, $sp, 48 # 32-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.w $xr0, $xr0, 1
; LA32-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powisf2
; LA32-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA32-NEXT:    vst $vr0, $sp, 16 # 16-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.w $xr0, $xr0, 0
; LA32-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powisf2
; LA32-NEXT:    # kill: def $f0 killed $f0 def $xr0
; LA32-NEXT:    vld $vr1, $sp, 16 # 16-byte Folded Reload
; LA32-NEXT:    vextrins.w $vr0, $vr1, 16
; LA32-NEXT:    xvst $xr0, $sp, 16 # 32-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.w $xr0, $xr0, 2
; LA32-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powisf2
; LA32-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA32-NEXT:    xvld $xr1, $sp, 16 # 32-byte Folded Reload
; LA32-NEXT:    vextrins.w $vr1, $vr0, 32
; LA32-NEXT:    xvst $xr1, $sp, 16 # 32-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.w $xr0, $xr0, 3
; LA32-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powisf2
; LA32-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA32-NEXT:    xvld $xr1, $sp, 16 # 32-byte Folded Reload
; LA32-NEXT:    vextrins.w $vr1, $vr0, 48
; LA32-NEXT:    xvld $xr0, $sp, 48 # 32-byte Folded Reload
; LA32-NEXT:    xvpermi.q $xr1, $xr0, 2
; LA32-NEXT:    xvori.b $xr0, $xr1, 0
; LA32-NEXT:    ld.w $fp, $sp, 120 # 4-byte Folded Reload
; LA32-NEXT:    ld.w $ra, $sp, 124 # 4-byte Folded Reload
; LA32-NEXT:    addi.w $sp, $sp, 128
; LA32-NEXT:    ret
;
; LA64-LABEL: powi_v8f32:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    addi.d $sp, $sp, -128
; LA64-NEXT:    st.d $ra, $sp, 120 # 8-byte Folded Spill
; LA64-NEXT:    st.d $fp, $sp, 112 # 8-byte Folded Spill
; LA64-NEXT:    xvst $xr0, $sp, 80 # 32-byte Folded Spill
; LA64-NEXT:    addi.w $fp, $a0, 0
; LA64-NEXT:    xvpickve.w $xr0, $xr0, 5
; LA64-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powisf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA64-NEXT:    vst $vr0, $sp, 48 # 16-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.w $xr0, $xr0, 4
; LA64-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powisf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 def $xr0
; LA64-NEXT:    vld $vr1, $sp, 48 # 16-byte Folded Reload
; LA64-NEXT:    vextrins.w $vr0, $vr1, 16
; LA64-NEXT:    xvst $xr0, $sp, 48 # 32-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.w $xr0, $xr0, 6
; LA64-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powisf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA64-NEXT:    xvld $xr1, $sp, 48 # 32-byte Folded Reload
; LA64-NEXT:    vextrins.w $vr1, $vr0, 32
; LA64-NEXT:    xvst $xr1, $sp, 48 # 32-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.w $xr0, $xr0, 7
; LA64-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powisf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA64-NEXT:    xvld $xr1, $sp, 48 # 32-byte Folded Reload
; LA64-NEXT:    vextrins.w $vr1, $vr0, 48
; LA64-NEXT:    xvst $xr1, $sp, 48 # 32-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.w $xr0, $xr0, 1
; LA64-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powisf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA64-NEXT:    vst $vr0, $sp, 16 # 16-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.w $xr0, $xr0, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powisf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 def $xr0
; LA64-NEXT:    vld $vr1, $sp, 16 # 16-byte Folded Reload
; LA64-NEXT:    vextrins.w $vr0, $vr1, 16
; LA64-NEXT:    xvst $xr0, $sp, 16 # 32-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.w $xr0, $xr0, 2
; LA64-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powisf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA64-NEXT:    xvld $xr1, $sp, 16 # 32-byte Folded Reload
; LA64-NEXT:    vextrins.w $vr1, $vr0, 32
; LA64-NEXT:    xvst $xr1, $sp, 16 # 32-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 80 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.w $xr0, $xr0, 3
; LA64-NEXT:    # kill: def $f0 killed $f0 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powisf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0 killed $f0 def $vr0
; LA64-NEXT:    xvld $xr1, $sp, 16 # 32-byte Folded Reload
; LA64-NEXT:    vextrins.w $vr1, $vr0, 48
; LA64-NEXT:    xvld $xr0, $sp, 48 # 32-byte Folded Reload
; LA64-NEXT:    xvpermi.q $xr1, $xr0, 2
; LA64-NEXT:    xvori.b $xr0, $xr1, 0
; LA64-NEXT:    ld.d $fp, $sp, 112 # 8-byte Folded Reload
; LA64-NEXT:    ld.d $ra, $sp, 120 # 8-byte Folded Reload
; LA64-NEXT:    addi.d $sp, $sp, 128
; LA64-NEXT:    ret
entry:
  %res = call <8 x float> @llvm.powi.v8f32.i32(<8 x float> %va, i32 %b)
  ret <8 x float> %res
}

declare <4 x double> @llvm.powi.v4f64.i32(<4 x double>, i32)

define <4 x double> @powi_v4f64(<4 x double> %va, i32 %b) nounwind {
; LA32-LABEL: powi_v4f64:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    addi.w $sp, $sp, -112
; LA32-NEXT:    st.w $ra, $sp, 108 # 4-byte Folded Spill
; LA32-NEXT:    st.w $fp, $sp, 104 # 4-byte Folded Spill
; LA32-NEXT:    move $fp, $a0
; LA32-NEXT:    xvst $xr0, $sp, 64 # 32-byte Folded Spill
; LA32-NEXT:    xvpickve.d $xr0, $xr0, 3
; LA32-NEXT:    # kill: def $f0_64 killed $f0_64 killed $xr0
; LA32-NEXT:    bl __powidf2
; LA32-NEXT:    # kill: def $f0_64 killed $f0_64 def $vr0
; LA32-NEXT:    vst $vr0, $sp, 32 # 16-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 64 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.d $xr0, $xr0, 2
; LA32-NEXT:    # kill: def $f0_64 killed $f0_64 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powidf2
; LA32-NEXT:    # kill: def $f0_64 killed $f0_64 def $xr0
; LA32-NEXT:    vld $vr1, $sp, 32 # 16-byte Folded Reload
; LA32-NEXT:    vextrins.d $vr0, $vr1, 16
; LA32-NEXT:    xvst $xr0, $sp, 32 # 32-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 64 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.d $xr0, $xr0, 1
; LA32-NEXT:    # kill: def $f0_64 killed $f0_64 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powidf2
; LA32-NEXT:    # kill: def $f0_64 killed $f0_64 def $vr0
; LA32-NEXT:    vst $vr0, $sp, 16 # 16-byte Folded Spill
; LA32-NEXT:    xvld $xr0, $sp, 64 # 32-byte Folded Reload
; LA32-NEXT:    xvpickve.d $xr0, $xr0, 0
; LA32-NEXT:    # kill: def $f0_64 killed $f0_64 killed $xr0
; LA32-NEXT:    move $a0, $fp
; LA32-NEXT:    bl __powidf2
; LA32-NEXT:    # kill: def $f0_64 killed $f0_64 def $xr0
; LA32-NEXT:    vld $vr1, $sp, 16 # 16-byte Folded Reload
; LA32-NEXT:    vextrins.d $vr0, $vr1, 16
; LA32-NEXT:    xvld $xr1, $sp, 32 # 32-byte Folded Reload
; LA32-NEXT:    xvpermi.q $xr0, $xr1, 2
; LA32-NEXT:    ld.w $fp, $sp, 104 # 4-byte Folded Reload
; LA32-NEXT:    ld.w $ra, $sp, 108 # 4-byte Folded Reload
; LA32-NEXT:    addi.w $sp, $sp, 112
; LA32-NEXT:    ret
;
; LA64-LABEL: powi_v4f64:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    addi.d $sp, $sp, -112
; LA64-NEXT:    st.d $ra, $sp, 104 # 8-byte Folded Spill
; LA64-NEXT:    st.d $fp, $sp, 96 # 8-byte Folded Spill
; LA64-NEXT:    xvst $xr0, $sp, 64 # 32-byte Folded Spill
; LA64-NEXT:    addi.w $fp, $a0, 0
; LA64-NEXT:    xvpickve.d $xr0, $xr0, 3
; LA64-NEXT:    # kill: def $f0_64 killed $f0_64 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powidf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0_64 killed $f0_64 def $vr0
; LA64-NEXT:    vst $vr0, $sp, 32 # 16-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 64 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.d $xr0, $xr0, 2
; LA64-NEXT:    # kill: def $f0_64 killed $f0_64 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powidf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0_64 killed $f0_64 def $xr0
; LA64-NEXT:    vld $vr1, $sp, 32 # 16-byte Folded Reload
; LA64-NEXT:    vextrins.d $vr0, $vr1, 16
; LA64-NEXT:    xvst $xr0, $sp, 32 # 32-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 64 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.d $xr0, $xr0, 1
; LA64-NEXT:    # kill: def $f0_64 killed $f0_64 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powidf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0_64 killed $f0_64 def $vr0
; LA64-NEXT:    vst $vr0, $sp, 16 # 16-byte Folded Spill
; LA64-NEXT:    xvld $xr0, $sp, 64 # 32-byte Folded Reload
; LA64-NEXT:    xvpickve.d $xr0, $xr0, 0
; LA64-NEXT:    # kill: def $f0_64 killed $f0_64 killed $xr0
; LA64-NEXT:    move $a0, $fp
; LA64-NEXT:    pcaddu18i $ra, %call36(__powidf2)
; LA64-NEXT:    jirl $ra, $ra, 0
; LA64-NEXT:    # kill: def $f0_64 killed $f0_64 def $xr0
; LA64-NEXT:    vld $vr1, $sp, 16 # 16-byte Folded Reload
; LA64-NEXT:    vextrins.d $vr0, $vr1, 16
; LA64-NEXT:    xvld $xr1, $sp, 32 # 32-byte Folded Reload
; LA64-NEXT:    xvpermi.q $xr0, $xr1, 2
; LA64-NEXT:    ld.d $fp, $sp, 96 # 8-byte Folded Reload
; LA64-NEXT:    ld.d $ra, $sp, 104 # 8-byte Folded Reload
; LA64-NEXT:    addi.d $sp, $sp, 112
; LA64-NEXT:    ret
entry:
  %res = call <4 x double> @llvm.powi.v4f64.i32(<4 x double> %va, i32 %b)
  ret <4 x double> %res
}
