; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc --mtriple=loongarch32 --mattr=+32s,+lsx,-frecipe < %s | FileCheck %s --check-prefixes=FAULT,FAULT-LA32
; RUN: llc --mtriple=loongarch32 --mattr=+32s,+lsx,+frecipe < %s | FileCheck %s --check-prefixes=CHECK,LA32
; RUN: llc --mtriple=loongarch64 --mattr=+lsx,-frecipe < %s | FileCheck %s --check-prefixes=FAULT,FAULT-LA64
; RUN: llc --mtriple=loongarch64 --mattr=+lsx,+frecipe < %s | FileCheck %s --check-prefixes=CHECK,LA64

;; 1.0 / (fsqrt vec)
define void @one_div_sqrt_v4f32(ptr %res, ptr %a0) nounwind {
; FAULT-LABEL: one_div_sqrt_v4f32:
; FAULT:       # %bb.0: # %entry
; FAULT-NEXT:    vld $vr0, $a1, 0
; FAULT-NEXT:    vfrsqrt.s $vr0, $vr0
; FAULT-NEXT:    vst $vr0, $a0, 0
; FAULT-NEXT:    ret
;
; CHECK-LABEL: one_div_sqrt_v4f32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vfrsqrte.s $vr1, $vr0
; CHECK-NEXT:    vfmul.s $vr1, $vr0, $vr1
; CHECK-NEXT:    vfmul.s $vr0, $vr0, $vr1
; CHECK-NEXT:    lu12i.w $a1, -261120
; CHECK-NEXT:    vreplgr2vr.w $vr2, $a1
; CHECK-NEXT:    vfmadd.s $vr0, $vr0, $vr1, $vr2
; CHECK-NEXT:    lu12i.w $a1, -266240
; CHECK-NEXT:    vreplgr2vr.w $vr2, $a1
; CHECK-NEXT:    vfmul.s $vr1, $vr1, $vr2
; CHECK-NEXT:    vfmul.s $vr0, $vr1, $vr0
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <4 x float>, ptr %a0, align 16
  %sqrt = call fast <4 x float> @llvm.sqrt.v4f32 (<4 x float> %v0)
  %div = fdiv fast <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>, %sqrt
  store <4 x float> %div, ptr %res, align 16
  ret void
}

define void @one_div_sqrt_v2f64(ptr %res, ptr %a0) nounwind {
; FAULT-LA32-LABEL: one_div_sqrt_v2f64:
; FAULT-LA32:       # %bb.0: # %entry
; FAULT-LA32-NEXT:    vld $vr0, $a1, 0
; FAULT-LA32-NEXT:    pcalau12i $a1, %pc_hi20(.LCPI1_0)
; FAULT-LA32-NEXT:    vld $vr1, $a1, %pc_lo12(.LCPI1_0)
; FAULT-LA32-NEXT:    vfsqrt.d $vr0, $vr0
; FAULT-LA32-NEXT:    vfdiv.d $vr0, $vr1, $vr0
; FAULT-LA32-NEXT:    vst $vr0, $a0, 0
; FAULT-LA32-NEXT:    ret
;
; LA32-LABEL: one_div_sqrt_v2f64:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    vld $vr0, $a1, 0
; LA32-NEXT:    vfrsqrte.d $vr1, $vr0
; LA32-NEXT:    pcalau12i $a1, %pc_hi20(.LCPI1_0)
; LA32-NEXT:    vld $vr2, $a1, %pc_lo12(.LCPI1_0)
; LA32-NEXT:    pcalau12i $a1, %pc_hi20(.LCPI1_1)
; LA32-NEXT:    vld $vr3, $a1, %pc_lo12(.LCPI1_1)
; LA32-NEXT:    vfmul.d $vr1, $vr0, $vr1
; LA32-NEXT:    vfmul.d $vr4, $vr0, $vr1
; LA32-NEXT:    vfmadd.d $vr4, $vr4, $vr1, $vr2
; LA32-NEXT:    vfmul.d $vr1, $vr1, $vr3
; LA32-NEXT:    vfmul.d $vr1, $vr1, $vr4
; LA32-NEXT:    vfmul.d $vr0, $vr0, $vr1
; LA32-NEXT:    vfmadd.d $vr0, $vr0, $vr1, $vr2
; LA32-NEXT:    vfmul.d $vr1, $vr1, $vr3
; LA32-NEXT:    vfmul.d $vr0, $vr1, $vr0
; LA32-NEXT:    vst $vr0, $a0, 0
; LA32-NEXT:    ret
;
; FAULT-LA64-LABEL: one_div_sqrt_v2f64:
; FAULT-LA64:       # %bb.0: # %entry
; FAULT-LA64-NEXT:    vld $vr0, $a1, 0
; FAULT-LA64-NEXT:    vfrsqrt.d $vr0, $vr0
; FAULT-LA64-NEXT:    vst $vr0, $a0, 0
; FAULT-LA64-NEXT:    ret
;
; LA64-LABEL: one_div_sqrt_v2f64:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    vld $vr0, $a1, 0
; LA64-NEXT:    vfrsqrte.d $vr1, $vr0
; LA64-NEXT:    vfmul.d $vr1, $vr0, $vr1
; LA64-NEXT:    vfmul.d $vr2, $vr0, $vr1
; LA64-NEXT:    ori $a1, $zero, 0
; LA64-NEXT:    lu32i.d $a1, -524288
; LA64-NEXT:    lu52i.d $a1, $a1, -1024
; LA64-NEXT:    vreplgr2vr.d $vr3, $a1
; LA64-NEXT:    vfmadd.d $vr2, $vr2, $vr1, $vr3
; LA64-NEXT:    lu52i.d $a1, $zero, -1026
; LA64-NEXT:    vreplgr2vr.d $vr4, $a1
; LA64-NEXT:    vfmul.d $vr1, $vr1, $vr4
; LA64-NEXT:    vfmul.d $vr1, $vr1, $vr2
; LA64-NEXT:    vfmul.d $vr0, $vr0, $vr1
; LA64-NEXT:    vfmadd.d $vr0, $vr0, $vr1, $vr3
; LA64-NEXT:    vfmul.d $vr1, $vr1, $vr4
; LA64-NEXT:    vfmul.d $vr0, $vr1, $vr0
; LA64-NEXT:    vst $vr0, $a0, 0
; LA64-NEXT:    ret
entry:
  %v0 = load <2 x double>, ptr %a0, align 16
  %sqrt = call fast <2 x double> @llvm.sqrt.v2f64 (<2 x double> %v0)
  %div = fdiv fast <2 x double> <double 1.0, double 1.0>, %sqrt
  store <2 x double> %div, ptr %res, align 16
  ret void
}

declare <4 x float> @llvm.sqrt.v4f32(<4 x float>)
declare <2 x double> @llvm.sqrt.v2f64(<2 x double>)
