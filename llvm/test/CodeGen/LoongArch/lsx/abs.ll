; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc --mtriple=loongarch32 --mattr=+32s,+lsx < %s | FileCheck %s
; RUN: llc --mtriple=loongarch64 --mattr=+lsx < %s | FileCheck %s

define void @vabs_b(ptr %dst, ptr %src) {
; CHECK-LABEL: vabs_b:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vneg.b $vr1, $vr0
; CHECK-NEXT:    vmax.b $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %a = load <16 x i8>, ptr %src
  %b = tail call <16 x i8> @llvm.abs.v16i8(<16 x i8> %a, i1 true)
  store <16 x i8> %b, ptr %dst
  ret void
}

define void @vabs_b_1(ptr %dst, ptr %src) {
; CHECK-LABEL: vabs_b_1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vneg.b $vr1, $vr0
; CHECK-NEXT:    vmax.b $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %a = load <16 x i8>, ptr %src
  %b = tail call <16 x i8> @llvm.abs.v16i8(<16 x i8> %a, i1 false)
  store <16 x i8> %b, ptr %dst
  ret void
}

define void @vabs_h(ptr %dst, ptr %src) {
; CHECK-LABEL: vabs_h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vneg.h $vr1, $vr0
; CHECK-NEXT:    vmax.h $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %a = load <8 x i16>, ptr %src
  %b = tail call <8 x i16> @llvm.abs.v8i16(<8 x i16> %a, i1 true)
  store <8 x i16> %b, ptr %dst
  ret void
}

define void @vabs_h_1(ptr %dst, ptr %src) {
; CHECK-LABEL: vabs_h_1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vneg.h $vr1, $vr0
; CHECK-NEXT:    vmax.h $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %a = load <8 x i16>, ptr %src
  %b = tail call <8 x i16> @llvm.abs.v8i16(<8 x i16> %a, i1 false)
  store <8 x i16> %b, ptr %dst
  ret void
}

define void @vabs_w(ptr %dst, ptr %src) {
; CHECK-LABEL: vabs_w:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vneg.w $vr1, $vr0
; CHECK-NEXT:    vmax.w $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %a = load <4 x i32>, ptr %src
  %b = tail call <4 x i32> @llvm.abs.v4i32(<4 x i32> %a, i1 true)
  store <4 x i32> %b, ptr %dst
  ret void
}

define void @vabs_w_1(ptr %dst, ptr %src) {
; CHECK-LABEL: vabs_w_1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vneg.w $vr1, $vr0
; CHECK-NEXT:    vmax.w $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %a = load <4 x i32>, ptr %src
  %b = tail call <4 x i32> @llvm.abs.v4i32(<4 x i32> %a, i1 false)
  store <4 x i32> %b, ptr %dst
  ret void
}

define void @vabs_d(ptr %dst, ptr %src) {
; CHECK-LABEL: vabs_d:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vneg.d $vr1, $vr0
; CHECK-NEXT:    vmax.d $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %a = load <2 x i64>, ptr %src
  %b = tail call <2 x i64> @llvm.abs.v2i64(<2 x i64> %a, i1 true)
  store <2 x i64> %b, ptr %dst
  ret void
}

define void @vabs_d_1(ptr %dst, ptr %src) {
; CHECK-LABEL: vabs_d_1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vneg.d $vr1, $vr0
; CHECK-NEXT:    vmax.d $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %a = load <2 x i64>, ptr %src
  %b = tail call <2 x i64> @llvm.abs.v2i64(<2 x i64> %a, i1 false)
  store <2 x i64> %b, ptr %dst
  ret void
}

declare <16 x i8> @llvm.abs.v16i8(<16 x i8>, i1)
declare <8 x i16> @llvm.abs.v8i16(<8 x i16>, i1)
declare <4 x i32> @llvm.abs.v4i32(<4 x i32>, i1)
declare <2 x i64> @llvm.abs.v2i64(<2 x i64>, i1)
