; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc --mtriple=loongarch32 --mattr=+32s,+lsx < %s | FileCheck %s
; RUN: llc --mtriple=loongarch64 --mattr=+lsx < %s | FileCheck %s

;; ceilf
define void @ceil_v4f32(ptr %res, ptr %a0) nounwind {
; CHECK-LABEL: ceil_v4f32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vreplvei.w $vr1, $vr0, 1
; CHECK-NEXT:    vreplvei.w $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrp.s $vr1, $vr1
; CHECK-NEXT:    vreplvei.w $vr2, $vr0, 0
; CHECK-NEXT:    vreplvei.w $vr2, $vr2, 0
; CHECK-NEXT:    vfrintrp.s $vr2, $vr2
; CHECK-NEXT:    vextrins.w $vr2, $vr1, 16
; CHECK-NEXT:    vreplvei.w $vr1, $vr0, 2
; CHECK-NEXT:    vreplvei.w $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrp.s $vr1, $vr1
; CHECK-NEXT:    vextrins.w $vr2, $vr1, 32
; CHECK-NEXT:    vreplvei.w $vr0, $vr0, 3
; CHECK-NEXT:    vreplvei.w $vr0, $vr0, 0
; CHECK-NEXT:    vfrintrp.s $vr0, $vr0
; CHECK-NEXT:    vextrins.w $vr2, $vr0, 48
; CHECK-NEXT:    vst $vr2, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <4 x float>, ptr %a0
  %r = call <4 x float> @llvm.ceil.v4f32(<4 x float> %v0)
  store <4 x float> %r, ptr %res
  ret void
}

;; ceil
define void @ceil_v2f64(ptr %res, ptr %a0) nounwind {
; CHECK-LABEL: ceil_v2f64:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vreplvei.d $vr1, $vr0, 1
; CHECK-NEXT:    vreplvei.d $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrp.d $vr1, $vr1
; CHECK-NEXT:    vreplvei.d $vr0, $vr0, 0
; CHECK-NEXT:    vreplvei.d $vr0, $vr0, 0
; CHECK-NEXT:    vfrintrp.d $vr0, $vr0
; CHECK-NEXT:    vextrins.d $vr0, $vr1, 16
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <2 x double>, ptr %a0
  %r = call <2 x double> @llvm.ceil.v2f64(<2 x double> %v0)
  store <2 x double> %r, ptr %res
  ret void
}

;; floorf
define void @floor_v4f32(ptr %res, ptr %a0) nounwind {
; CHECK-LABEL: floor_v4f32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vreplvei.w $vr1, $vr0, 1
; CHECK-NEXT:    vreplvei.w $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrm.s $vr1, $vr1
; CHECK-NEXT:    vreplvei.w $vr2, $vr0, 0
; CHECK-NEXT:    vreplvei.w $vr2, $vr2, 0
; CHECK-NEXT:    vfrintrm.s $vr2, $vr2
; CHECK-NEXT:    vextrins.w $vr2, $vr1, 16
; CHECK-NEXT:    vreplvei.w $vr1, $vr0, 2
; CHECK-NEXT:    vreplvei.w $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrm.s $vr1, $vr1
; CHECK-NEXT:    vextrins.w $vr2, $vr1, 32
; CHECK-NEXT:    vreplvei.w $vr0, $vr0, 3
; CHECK-NEXT:    vreplvei.w $vr0, $vr0, 0
; CHECK-NEXT:    vfrintrm.s $vr0, $vr0
; CHECK-NEXT:    vextrins.w $vr2, $vr0, 48
; CHECK-NEXT:    vst $vr2, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <4 x float>, ptr %a0
  %r = call <4 x float> @llvm.floor.v4f32(<4 x float> %v0)
  store <4 x float> %r, ptr %res
  ret void
}

;; floor
define void @floor_v2f64(ptr %res, ptr %a0) nounwind {
; CHECK-LABEL: floor_v2f64:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vreplvei.d $vr1, $vr0, 1
; CHECK-NEXT:    vreplvei.d $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrm.d $vr1, $vr1
; CHECK-NEXT:    vreplvei.d $vr0, $vr0, 0
; CHECK-NEXT:    vreplvei.d $vr0, $vr0, 0
; CHECK-NEXT:    vfrintrm.d $vr0, $vr0
; CHECK-NEXT:    vextrins.d $vr0, $vr1, 16
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <2 x double>, ptr %a0
  %r = call <2 x double> @llvm.floor.v2f64(<2 x double> %v0)
  store <2 x double> %r, ptr %res
  ret void
}

;; truncf
define void @trunc_v4f32(ptr %res, ptr %a0) nounwind {
; CHECK-LABEL: trunc_v4f32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vreplvei.w $vr1, $vr0, 1
; CHECK-NEXT:    vreplvei.w $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrz.s $vr1, $vr1
; CHECK-NEXT:    vreplvei.w $vr2, $vr0, 0
; CHECK-NEXT:    vreplvei.w $vr2, $vr2, 0
; CHECK-NEXT:    vfrintrz.s $vr2, $vr2
; CHECK-NEXT:    vextrins.w $vr2, $vr1, 16
; CHECK-NEXT:    vreplvei.w $vr1, $vr0, 2
; CHECK-NEXT:    vreplvei.w $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrz.s $vr1, $vr1
; CHECK-NEXT:    vextrins.w $vr2, $vr1, 32
; CHECK-NEXT:    vreplvei.w $vr0, $vr0, 3
; CHECK-NEXT:    vreplvei.w $vr0, $vr0, 0
; CHECK-NEXT:    vfrintrz.s $vr0, $vr0
; CHECK-NEXT:    vextrins.w $vr2, $vr0, 48
; CHECK-NEXT:    vst $vr2, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <4 x float>, ptr %a0
  %r = call <4 x float> @llvm.trunc.v4f32(<4 x float> %v0)
  store <4 x float> %r, ptr %res
  ret void
}

;; trunc
define void @trunc_v2f64(ptr %res, ptr %a0) nounwind {
; CHECK-LABEL: trunc_v2f64:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vreplvei.d $vr1, $vr0, 1
; CHECK-NEXT:    vreplvei.d $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrz.d $vr1, $vr1
; CHECK-NEXT:    vreplvei.d $vr0, $vr0, 0
; CHECK-NEXT:    vreplvei.d $vr0, $vr0, 0
; CHECK-NEXT:    vfrintrz.d $vr0, $vr0
; CHECK-NEXT:    vextrins.d $vr0, $vr1, 16
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <2 x double>, ptr %a0
  %r = call <2 x double> @llvm.trunc.v2f64(<2 x double> %v0)
  store <2 x double> %r, ptr %res
  ret void
}

;; roundevenf
define void @roundeven_v4f32(ptr %res, ptr %a0) nounwind {
; CHECK-LABEL: roundeven_v4f32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vreplvei.w $vr1, $vr0, 1
; CHECK-NEXT:    vreplvei.w $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrne.s $vr1, $vr1
; CHECK-NEXT:    vreplvei.w $vr2, $vr0, 0
; CHECK-NEXT:    vreplvei.w $vr2, $vr2, 0
; CHECK-NEXT:    vfrintrne.s $vr2, $vr2
; CHECK-NEXT:    vextrins.w $vr2, $vr1, 16
; CHECK-NEXT:    vreplvei.w $vr1, $vr0, 2
; CHECK-NEXT:    vreplvei.w $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrne.s $vr1, $vr1
; CHECK-NEXT:    vextrins.w $vr2, $vr1, 32
; CHECK-NEXT:    vreplvei.w $vr0, $vr0, 3
; CHECK-NEXT:    vreplvei.w $vr0, $vr0, 0
; CHECK-NEXT:    vfrintrne.s $vr0, $vr0
; CHECK-NEXT:    vextrins.w $vr2, $vr0, 48
; CHECK-NEXT:    vst $vr2, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <4 x float>, ptr %a0
  %r = call <4 x float> @llvm.roundeven.v4f32(<4 x float> %v0)
  store <4 x float> %r, ptr %res
  ret void
}

;; roundeven
define void @roundeven_v2f64(ptr %res, ptr %a0) nounwind {
; CHECK-LABEL: roundeven_v2f64:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vreplvei.d $vr1, $vr0, 1
; CHECK-NEXT:    vreplvei.d $vr1, $vr1, 0
; CHECK-NEXT:    vfrintrne.d $vr1, $vr1
; CHECK-NEXT:    vreplvei.d $vr0, $vr0, 0
; CHECK-NEXT:    vreplvei.d $vr0, $vr0, 0
; CHECK-NEXT:    vfrintrne.d $vr0, $vr0
; CHECK-NEXT:    vextrins.d $vr0, $vr1, 16
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %v0 = load <2 x double>, ptr %a0
  %r = call <2 x double> @llvm.roundeven.v2f64(<2 x double> %v0)
  store <2 x double> %r, ptr %res
  ret void
}

declare <4 x float> @llvm.ceil.v4f32(<4 x float>)
declare <2 x double> @llvm.ceil.v2f64(<2 x double>)
declare <4 x float> @llvm.floor.v4f32(<4 x float>)
declare <2 x double> @llvm.floor.v2f64(<2 x double>)
declare <4 x float> @llvm.trunc.v4f32(<4 x float>)
declare <2 x double> @llvm.trunc.v2f64(<2 x double>)
declare <4 x float> @llvm.roundeven.v4f32(<4 x float>)
declare <2 x double> @llvm.roundeven.v2f64(<2 x double>)
