; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc --mtriple=loongarch64 --mattr=+lsx < %s | FileCheck %s

declare <8 x i16> @llvm.loongarch.lsx.vmaddwev.h.b(<8 x i16>, <16 x i8>, <16 x i8>)

define <8 x i16> @lsx_vmaddwev_h_b(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_h_b:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.h.b $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <8 x i16> @llvm.loongarch.lsx.vmaddwev.h.b(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc)
  ret <8 x i16> %res
}

declare <4 x i32> @llvm.loongarch.lsx.vmaddwev.w.h(<4 x i32>, <8 x i16>, <8 x i16>)

define <4 x i32> @lsx_vmaddwev_w_h(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_w_h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.w.h $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <4 x i32> @llvm.loongarch.lsx.vmaddwev.w.h(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc)
  ret <4 x i32> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwev.d.w(<2 x i64>, <4 x i32>, <4 x i32>)

define <2 x i64> @lsx_vmaddwev_d_w(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_d_w:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.d.w $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwev.d.w(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc)
  ret <2 x i64> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwev.q.d(<2 x i64>, <2 x i64>, <2 x i64>)

define <2 x i64> @lsx_vmaddwev_q_d(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_q_d:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.q.d $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwev.q.d(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc)
  ret <2 x i64> %res
}

declare <8 x i16> @llvm.loongarch.lsx.vmaddwev.h.bu(<8 x i16>, <16 x i8>, <16 x i8>)

define <8 x i16> @lsx_vmaddwev_h_bu(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_h_bu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.h.bu $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <8 x i16> @llvm.loongarch.lsx.vmaddwev.h.bu(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc)
  ret <8 x i16> %res
}

declare <4 x i32> @llvm.loongarch.lsx.vmaddwev.w.hu(<4 x i32>, <8 x i16>, <8 x i16>)

define <4 x i32> @lsx_vmaddwev_w_hu(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_w_hu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.w.hu $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <4 x i32> @llvm.loongarch.lsx.vmaddwev.w.hu(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc)
  ret <4 x i32> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwev.d.wu(<2 x i64>, <4 x i32>, <4 x i32>)

define <2 x i64> @lsx_vmaddwev_d_wu(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_d_wu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.d.wu $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwev.d.wu(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc)
  ret <2 x i64> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwev.q.du(<2 x i64>, <2 x i64>, <2 x i64>)

define <2 x i64> @lsx_vmaddwev_q_du(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_q_du:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.q.du $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwev.q.du(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc)
  ret <2 x i64> %res
}

declare <8 x i16> @llvm.loongarch.lsx.vmaddwev.h.bu.b(<8 x i16>, <16 x i8>, <16 x i8>)

define <8 x i16> @lsx_vmaddwev_h_bu_b(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_h_bu_b:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.h.bu.b $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <8 x i16> @llvm.loongarch.lsx.vmaddwev.h.bu.b(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc)
  ret <8 x i16> %res
}

declare <4 x i32> @llvm.loongarch.lsx.vmaddwev.w.hu.h(<4 x i32>, <8 x i16>, <8 x i16>)

define <4 x i32> @lsx_vmaddwev_w_hu_h(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_w_hu_h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.w.hu.h $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <4 x i32> @llvm.loongarch.lsx.vmaddwev.w.hu.h(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc)
  ret <4 x i32> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwev.d.wu.w(<2 x i64>, <4 x i32>, <4 x i32>)

define <2 x i64> @lsx_vmaddwev_d_wu_w(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_d_wu_w:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.d.wu.w $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwev.d.wu.w(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc)
  ret <2 x i64> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwev.q.du.d(<2 x i64>, <2 x i64>, <2 x i64>)

define <2 x i64> @lsx_vmaddwev_q_du_d(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwev_q_du_d:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwev.q.du.d $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwev.q.du.d(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc)
  ret <2 x i64> %res
}

declare <8 x i16> @llvm.loongarch.lsx.vmaddwod.h.b(<8 x i16>, <16 x i8>, <16 x i8>)

define <8 x i16> @lsx_vmaddwod_h_b(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_h_b:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.h.b $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <8 x i16> @llvm.loongarch.lsx.vmaddwod.h.b(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc)
  ret <8 x i16> %res
}

declare <4 x i32> @llvm.loongarch.lsx.vmaddwod.w.h(<4 x i32>, <8 x i16>, <8 x i16>)

define <4 x i32> @lsx_vmaddwod_w_h(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_w_h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.w.h $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <4 x i32> @llvm.loongarch.lsx.vmaddwod.w.h(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc)
  ret <4 x i32> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwod.d.w(<2 x i64>, <4 x i32>, <4 x i32>)

define <2 x i64> @lsx_vmaddwod_d_w(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_d_w:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.d.w $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwod.d.w(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc)
  ret <2 x i64> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwod.q.d(<2 x i64>, <2 x i64>, <2 x i64>)

define <2 x i64> @lsx_vmaddwod_q_d(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_q_d:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.q.d $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwod.q.d(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc)
  ret <2 x i64> %res
}

declare <8 x i16> @llvm.loongarch.lsx.vmaddwod.h.bu(<8 x i16>, <16 x i8>, <16 x i8>)

define <8 x i16> @lsx_vmaddwod_h_bu(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_h_bu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.h.bu $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <8 x i16> @llvm.loongarch.lsx.vmaddwod.h.bu(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc)
  ret <8 x i16> %res
}

declare <4 x i32> @llvm.loongarch.lsx.vmaddwod.w.hu(<4 x i32>, <8 x i16>, <8 x i16>)

define <4 x i32> @lsx_vmaddwod_w_hu(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_w_hu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.w.hu $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <4 x i32> @llvm.loongarch.lsx.vmaddwod.w.hu(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc)
  ret <4 x i32> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwod.d.wu(<2 x i64>, <4 x i32>, <4 x i32>)

define <2 x i64> @lsx_vmaddwod_d_wu(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_d_wu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.d.wu $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwod.d.wu(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc)
  ret <2 x i64> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwod.q.du(<2 x i64>, <2 x i64>, <2 x i64>)

define <2 x i64> @lsx_vmaddwod_q_du(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_q_du:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.q.du $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwod.q.du(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc)
  ret <2 x i64> %res
}

declare <8 x i16> @llvm.loongarch.lsx.vmaddwod.h.bu.b(<8 x i16>, <16 x i8>, <16 x i8>)

define <8 x i16> @lsx_vmaddwod_h_bu_b(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_h_bu_b:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.h.bu.b $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <8 x i16> @llvm.loongarch.lsx.vmaddwod.h.bu.b(<8 x i16> %va, <16 x i8> %vb, <16 x i8> %vc)
  ret <8 x i16> %res
}

declare <4 x i32> @llvm.loongarch.lsx.vmaddwod.w.hu.h(<4 x i32>, <8 x i16>, <8 x i16>)

define <4 x i32> @lsx_vmaddwod_w_hu_h(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_w_hu_h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.w.hu.h $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <4 x i32> @llvm.loongarch.lsx.vmaddwod.w.hu.h(<4 x i32> %va, <8 x i16> %vb, <8 x i16> %vc)
  ret <4 x i32> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwod.d.wu.w(<2 x i64>, <4 x i32>, <4 x i32>)

define <2 x i64> @lsx_vmaddwod_d_wu_w(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_d_wu_w:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.d.wu.w $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwod.d.wu.w(<2 x i64> %va, <4 x i32> %vb, <4 x i32> %vc)
  ret <2 x i64> %res
}

declare <2 x i64> @llvm.loongarch.lsx.vmaddwod.q.du.d(<2 x i64>, <2 x i64>, <2 x i64>)

define <2 x i64> @lsx_vmaddwod_q_du_d(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc) nounwind {
; CHECK-LABEL: lsx_vmaddwod_q_du_d:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmaddwod.q.du.d $vr0, $vr1, $vr2
; CHECK-NEXT:    ret
entry:
  %res = call <2 x i64> @llvm.loongarch.lsx.vmaddwod.q.du.d(<2 x i64> %va, <2 x i64> %vb, <2 x i64> %vc)
  ret <2 x i64> %res
}
