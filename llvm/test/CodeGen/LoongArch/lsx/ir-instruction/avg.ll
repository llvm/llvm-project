; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc --mtriple=loongarch32 --mattr=+32s,+lsx < %s | FileCheck %s --check-prefixes=CHECK,LA32
; RUN: llc --mtriple=loongarch64 --mattr=+lsx < %s | FileCheck %s --check-prefixes=CHECK,LA64

define void @vavg_b(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavg_b:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavg.b $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <16 x i8>, ptr %a
  %vb = load <16 x i8>, ptr %b
  %add = add <16 x i8> %va, %vb
  %shr = ashr <16 x i8> %add, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  store <16 x i8> %shr, ptr %res
  ret void
}

define void @vavg_h(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavg_h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavg.h $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <8 x i16>, ptr %a
  %vb = load <8 x i16>, ptr %b
  %add = add <8 x i16> %va, %vb
  %shr = ashr <8 x i16> %add, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  store <8 x i16> %shr, ptr %res
  ret void
}

define void @vavg_w(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavg_w:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavg.w $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <4 x i32>, ptr %a
  %vb = load <4 x i32>, ptr %b
  %add = add <4 x i32> %va, %vb
  %shr = ashr <4 x i32> %add, <i32 1, i32 1, i32 1, i32 1>
  store <4 x i32> %shr, ptr %res
  ret void
}

define void @vavg_d(ptr %res, ptr %a, ptr %b) nounwind {
; LA32-LABEL: vavg_d:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    vld $vr0, $a1, 0
; LA32-NEXT:    vld $vr1, $a2, 0
; LA32-NEXT:    vadd.d $vr0, $vr0, $vr1
; LA32-NEXT:    vsrai.d $vr0, $vr0, 1
; LA32-NEXT:    vst $vr0, $a0, 0
; LA32-NEXT:    ret
;
; LA64-LABEL: vavg_d:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    vld $vr0, $a1, 0
; LA64-NEXT:    vld $vr1, $a2, 0
; LA64-NEXT:    vavg.d $vr0, $vr0, $vr1
; LA64-NEXT:    vst $vr0, $a0, 0
; LA64-NEXT:    ret
entry:
  %va = load <2 x i64>, ptr %a
  %vb = load <2 x i64>, ptr %b
  %add = add <2 x i64> %va, %vb
  %shr = ashr <2 x i64> %add, <i64 1, i64 1>
  store <2 x i64> %shr, ptr %res
  ret void
}

define void @vavg_bu(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavg_bu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavg.bu $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <16 x i8>, ptr %a
  %vb = load <16 x i8>, ptr %b
  %add = add <16 x i8> %va, %vb
  %shr = lshr <16 x i8> %add, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  store <16 x i8> %shr, ptr %res
  ret void
}

define void @vavg_hu(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavg_hu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavg.hu $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <8 x i16>, ptr %a
  %vb = load <8 x i16>, ptr %b
  %add = add <8 x i16> %va, %vb
  %shr = lshr <8 x i16> %add, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  store <8 x i16> %shr, ptr %res
  ret void
}

define void @vavg_wu(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavg_wu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavg.wu $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <4 x i32>, ptr %a
  %vb = load <4 x i32>, ptr %b
  %add = add <4 x i32> %va, %vb
  %shr = lshr <4 x i32> %add, <i32 1, i32 1, i32 1, i32 1>
  store <4 x i32> %shr, ptr %res
  ret void
}

define void @vavg_du(ptr %res, ptr %a, ptr %b) nounwind {
; LA32-LABEL: vavg_du:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    vld $vr0, $a1, 0
; LA32-NEXT:    vld $vr1, $a2, 0
; LA32-NEXT:    vadd.d $vr0, $vr0, $vr1
; LA32-NEXT:    vsrli.d $vr0, $vr0, 1
; LA32-NEXT:    vst $vr0, $a0, 0
; LA32-NEXT:    ret
;
; LA64-LABEL: vavg_du:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    vld $vr0, $a1, 0
; LA64-NEXT:    vld $vr1, $a2, 0
; LA64-NEXT:    vavg.du $vr0, $vr0, $vr1
; LA64-NEXT:    vst $vr0, $a0, 0
; LA64-NEXT:    ret
entry:
  %va = load <2 x i64>, ptr %a
  %vb = load <2 x i64>, ptr %b
  %add = add <2 x i64> %va, %vb
  %shr = lshr <2 x i64> %add, <i64 1, i64 1>
  store <2 x i64> %shr, ptr %res
  ret void
}

define void @vavgr_b(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavgr_b:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavgr.b $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <16 x i8>, ptr %a
  %vb = load <16 x i8>, ptr %b
  %add = add <16 x i8> %va, %vb
  %add1 = add <16 x i8> %add, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %shr = ashr <16 x i8> %add1, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  store <16 x i8> %shr, ptr %res
  ret void
}

define void @vavgr_h(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavgr_h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavgr.h $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <8 x i16>, ptr %a
  %vb = load <8 x i16>, ptr %b
  %add = add <8 x i16> %va, %vb
  %add1 = add <8 x i16> %add, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %shr = ashr <8 x i16> %add1, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  store <8 x i16> %shr, ptr %res
  ret void
}

define void @vavgr_w(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavgr_w:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavgr.w $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <4 x i32>, ptr %a
  %vb = load <4 x i32>, ptr %b
  %add = add <4 x i32> %va, %vb
  %add1 = add <4 x i32> %add, <i32 1, i32 1, i32 1, i32 1>
  %shr = ashr <4 x i32> %add1, <i32 1, i32 1, i32 1, i32 1>
  store <4 x i32> %shr, ptr %res
  ret void
}

define void @vavgr_d(ptr %res, ptr %a, ptr %b) nounwind {
; LA32-LABEL: vavgr_d:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    vld $vr0, $a1, 0
; LA32-NEXT:    vld $vr1, $a2, 0
; LA32-NEXT:    vadd.d $vr0, $vr0, $vr1
; LA32-NEXT:    vaddi.du $vr0, $vr0, 1
; LA32-NEXT:    vsrai.d $vr0, $vr0, 1
; LA32-NEXT:    vst $vr0, $a0, 0
; LA32-NEXT:    ret
;
; LA64-LABEL: vavgr_d:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    vld $vr0, $a1, 0
; LA64-NEXT:    vld $vr1, $a2, 0
; LA64-NEXT:    vavgr.d $vr0, $vr0, $vr1
; LA64-NEXT:    vst $vr0, $a0, 0
; LA64-NEXT:    ret
entry:
  %va = load <2 x i64>, ptr %a
  %vb = load <2 x i64>, ptr %b
  %add = add <2 x i64> %va, %vb
  %add1 = add <2 x i64> %add, <i64 1, i64 1>
  %shr = ashr <2 x i64> %add1, <i64 1, i64 1>
  store <2 x i64> %shr, ptr %res
  ret void
}

define void @vavgr_bu(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavgr_bu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavgr.bu $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <16 x i8>, ptr %a
  %vb = load <16 x i8>, ptr %b
  %add = add <16 x i8> %va, %vb
  %add1 = add <16 x i8> %add, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %shr = lshr <16 x i8> %add1, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  store <16 x i8> %shr, ptr %res
  ret void
}

define void @vavgr_hu(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavgr_hu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavgr.hu $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <8 x i16>, ptr %a
  %vb = load <8 x i16>, ptr %b
  %add = add <8 x i16> %va, %vb
  %add1 = add <8 x i16> %add, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %shr = lshr <8 x i16> %add1, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  store <8 x i16> %shr, ptr %res
  ret void
}

define void @vavgr_wu(ptr %res, ptr %a, ptr %b) nounwind {
; CHECK-LABEL: vavgr_wu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vld $vr0, $a1, 0
; CHECK-NEXT:    vld $vr1, $a2, 0
; CHECK-NEXT:    vavgr.wu $vr0, $vr0, $vr1
; CHECK-NEXT:    vst $vr0, $a0, 0
; CHECK-NEXT:    ret
entry:
  %va = load <4 x i32>, ptr %a
  %vb = load <4 x i32>, ptr %b
  %add = add <4 x i32> %va, %vb
  %add1 = add <4 x i32> %add, <i32 1, i32 1, i32 1, i32 1>
  %shr = lshr <4 x i32> %add1, <i32 1, i32 1, i32 1, i32 1>
  store <4 x i32> %shr, ptr %res
  ret void
}

define void @vavgr_du(ptr %res, ptr %a, ptr %b) nounwind {
; LA32-LABEL: vavgr_du:
; LA32:       # %bb.0: # %entry
; LA32-NEXT:    vld $vr0, $a1, 0
; LA32-NEXT:    vld $vr1, $a2, 0
; LA32-NEXT:    vadd.d $vr0, $vr0, $vr1
; LA32-NEXT:    vaddi.du $vr0, $vr0, 1
; LA32-NEXT:    vsrli.d $vr0, $vr0, 1
; LA32-NEXT:    vst $vr0, $a0, 0
; LA32-NEXT:    ret
;
; LA64-LABEL: vavgr_du:
; LA64:       # %bb.0: # %entry
; LA64-NEXT:    vld $vr0, $a1, 0
; LA64-NEXT:    vld $vr1, $a2, 0
; LA64-NEXT:    vavgr.du $vr0, $vr0, $vr1
; LA64-NEXT:    vst $vr0, $a0, 0
; LA64-NEXT:    ret
entry:
  %va = load <2 x i64>, ptr %a
  %vb = load <2 x i64>, ptr %b
  %add = add <2 x i64> %va, %vb
  %add1 = add <2 x i64> %add, <i64 1, i64 1>
  %shr = lshr <2 x i64> %add1, <i64 1, i64 1>
  store <2 x i64> %shr, ptr %res
  ret void
}
