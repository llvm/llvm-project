; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc --mtriple=loongarch32 < %s | FileCheck %s --check-prefix=LA32
; RUN: llc --mtriple=loongarch64 < %s | FileCheck %s --check-prefix=LA64

define zeroext i1 @smuloi64(i64 %v1, i64 %v2, ptr %res) {
; LA32-LABEL: smuloi64:
; LA32:       # %bb.0:
; LA32-NEXT:    addi.w $sp, $sp, -16
; LA32-NEXT:    .cfi_def_cfa_offset 16
; LA32-NEXT:    st.w $ra, $sp, 12 # 4-byte Folded Spill
; LA32-NEXT:    st.w $fp, $sp, 8 # 4-byte Folded Spill
; LA32-NEXT:    .cfi_offset 1, -4
; LA32-NEXT:    .cfi_offset 22, -8
; LA32-NEXT:    move $fp, $a4
; LA32-NEXT:    st.w $zero, $sp, 4
; LA32-NEXT:    addi.w $a4, $sp, 4
; LA32-NEXT:    bl %plt(__mulodi4)
; LA32-NEXT:    st.w $a1, $fp, 4
; LA32-NEXT:    st.w $a0, $fp, 0
; LA32-NEXT:    ld.w $a0, $sp, 4
; LA32-NEXT:    sltu $a0, $zero, $a0
; LA32-NEXT:    ld.w $fp, $sp, 8 # 4-byte Folded Reload
; LA32-NEXT:    ld.w $ra, $sp, 12 # 4-byte Folded Reload
; LA32-NEXT:    addi.w $sp, $sp, 16
; LA32-NEXT:    ret
;
; LA64-LABEL: smuloi64:
; LA64:       # %bb.0:
; LA64-NEXT:    mul.d $a3, $a0, $a1
; LA64-NEXT:    st.d $a3, $a2, 0
; LA64-NEXT:    mulh.d $a0, $a0, $a1
; LA64-NEXT:    srai.d $a1, $a3, 63
; LA64-NEXT:    xor $a0, $a0, $a1
; LA64-NEXT:    sltu $a0, $zero, $a0
; LA64-NEXT:    ret
  %t = call {i64, i1} @llvm.smul.with.overflow.i64(i64 %v1, i64 %v2)
  %val = extractvalue {i64, i1} %t, 0
  %obit = extractvalue {i64, i1} %t, 1
  store i64 %val, ptr %res
  ret i1 %obit
}

define zeroext i1 @smuloi128(i128 %v1, i128 %v2, ptr %res) {
; LA32-LABEL: smuloi128:
; LA32:       # %bb.0:
; LA32-NEXT:    addi.w $sp, $sp, -64
; LA32-NEXT:    .cfi_def_cfa_offset 64
; LA32-NEXT:    st.w $ra, $sp, 60 # 4-byte Folded Spill
; LA32-NEXT:    st.w $fp, $sp, 56 # 4-byte Folded Spill
; LA32-NEXT:    .cfi_offset 1, -4
; LA32-NEXT:    .cfi_offset 22, -8
; LA32-NEXT:    move $fp, $a2
; LA32-NEXT:    st.w $zero, $sp, 52
; LA32-NEXT:    ld.w $a2, $a1, 12
; LA32-NEXT:    st.w $a2, $sp, 12
; LA32-NEXT:    ld.w $a2, $a1, 8
; LA32-NEXT:    st.w $a2, $sp, 8
; LA32-NEXT:    ld.w $a2, $a1, 4
; LA32-NEXT:    st.w $a2, $sp, 4
; LA32-NEXT:    ld.w $a1, $a1, 0
; LA32-NEXT:    st.w $a1, $sp, 0
; LA32-NEXT:    ld.w $a1, $a0, 12
; LA32-NEXT:    st.w $a1, $sp, 28
; LA32-NEXT:    ld.w $a1, $a0, 8
; LA32-NEXT:    st.w $a1, $sp, 24
; LA32-NEXT:    ld.w $a1, $a0, 4
; LA32-NEXT:    st.w $a1, $sp, 20
; LA32-NEXT:    ld.w $a0, $a0, 0
; LA32-NEXT:    st.w $a0, $sp, 16
; LA32-NEXT:    addi.w $a0, $sp, 32
; LA32-NEXT:    addi.w $a1, $sp, 16
; LA32-NEXT:    addi.w $a2, $sp, 0
; LA32-NEXT:    addi.w $a3, $sp, 52
; LA32-NEXT:    bl %plt(__muloti4)
; LA32-NEXT:    ld.w $a0, $sp, 44
; LA32-NEXT:    st.w $a0, $fp, 12
; LA32-NEXT:    ld.w $a0, $sp, 40
; LA32-NEXT:    st.w $a0, $fp, 8
; LA32-NEXT:    ld.w $a0, $sp, 36
; LA32-NEXT:    st.w $a0, $fp, 4
; LA32-NEXT:    ld.w $a0, $sp, 32
; LA32-NEXT:    st.w $a0, $fp, 0
; LA32-NEXT:    ld.w $a0, $sp, 52
; LA32-NEXT:    sltu $a0, $zero, $a0
; LA32-NEXT:    ld.w $fp, $sp, 56 # 4-byte Folded Reload
; LA32-NEXT:    ld.w $ra, $sp, 60 # 4-byte Folded Reload
; LA32-NEXT:    addi.w $sp, $sp, 64
; LA32-NEXT:    ret
;
; LA64-LABEL: smuloi128:
; LA64:       # %bb.0:
; LA64-NEXT:    addi.d $sp, $sp, -32
; LA64-NEXT:    .cfi_def_cfa_offset 32
; LA64-NEXT:    st.d $ra, $sp, 24 # 8-byte Folded Spill
; LA64-NEXT:    st.d $fp, $sp, 16 # 8-byte Folded Spill
; LA64-NEXT:    .cfi_offset 1, -8
; LA64-NEXT:    .cfi_offset 22, -16
; LA64-NEXT:    move $fp, $a4
; LA64-NEXT:    st.d $zero, $sp, 8
; LA64-NEXT:    addi.d $a4, $sp, 8
; LA64-NEXT:    bl %plt(__muloti4)
; LA64-NEXT:    st.d $a1, $fp, 8
; LA64-NEXT:    st.d $a0, $fp, 0
; LA64-NEXT:    ld.d $a0, $sp, 8
; LA64-NEXT:    sltu $a0, $zero, $a0
; LA64-NEXT:    ld.d $fp, $sp, 16 # 8-byte Folded Reload
; LA64-NEXT:    ld.d $ra, $sp, 24 # 8-byte Folded Reload
; LA64-NEXT:    addi.d $sp, $sp, 32
; LA64-NEXT:    ret
  %t = call {i128, i1} @llvm.smul.with.overflow.i128(i128 %v1, i128 %v2)
  %val = extractvalue {i128, i1} %t, 0
  %obit = extractvalue {i128, i1} %t, 1
  store i128 %val, ptr %res
  ret i1 %obit
}

declare {i64, i1} @llvm.smul.with.overflow.i64(i64, i64) nounwind readnone
declare {i128, i1} @llvm.smul.with.overflow.i128(i128, i128) nounwind readnone
