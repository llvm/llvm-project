; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 -verify-machineinstrs -mcpu=pwr4 -mattr=-altivec -mtriple powerpc-ibm-aix-xcoff < %s | FileCheck %s

define i32 @int_va_arg(i32 %a, ...) local_unnamed_addr  {
; CHECK-LABEL: int_va_arg:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi 11, 1, 28
; CHECK-NEXT:    stw 4, 28(1)
; CHECK-NEXT:    addi 4, 1, 32
; CHECK-NEXT:    stw 6, 36(1)
; CHECK-NEXT:    stw 11, -4(1)
; CHECK-NEXT:    stw 11, -8(1)
; CHECK-NEXT:    stw 4, -4(1)
; CHECK-NEXT:    lwz 6, 28(1)
; CHECK-NEXT:    stw 4, -8(1)
; CHECK-NEXT:    add 3, 6, 3
; CHECK-NEXT:    lwz 4, 28(1)
; CHECK-NEXT:    slwi 4, 4, 1
; CHECK-NEXT:    stw 7, 40(1)
; CHECK-NEXT:    add 3, 3, 4
; CHECK-NEXT:    stw 8, 44(1)
; CHECK-NEXT:    stw 9, 48(1)
; CHECK-NEXT:    stw 10, 52(1)
; CHECK-NEXT:    stw 5, 32(1)
; CHECK-NEXT:    blr
entry:
  %arg1 = alloca ptr, align 4
  %arg2 = alloca ptr, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %arg1)
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %arg2)
  call void @llvm.va_start(ptr nonnull %arg1)
  call void @llvm.va_copy(ptr nonnull %arg2, ptr nonnull %arg1)
  %argp.cur = load ptr, ptr %arg1, align 4
  %argp.next = getelementptr inbounds i8, ptr %argp.cur, i32 4
  store ptr %argp.next, ptr %arg1, align 4
  %0 = load i32, ptr %argp.cur, align 4
  %add = add nsw i32 %0, %a
  %argp.cur2 = load ptr, ptr %arg2, align 4
  %argp.next3 = getelementptr inbounds i8, ptr %argp.cur2, i32 4
  store ptr %argp.next3, ptr %arg2, align 4
  %1 = load i32, ptr %argp.cur2, align 4
  %mul = shl i32 %1, 1
  %add4 = add nsw i32 %add, %mul
  call void @llvm.va_end(ptr nonnull %arg1)
  call void @llvm.va_end(ptr nonnull %arg2)
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %arg2)
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %arg1)
  ret i32 %add4
}

declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture)
declare void @llvm.va_start(ptr)
declare void @llvm.va_copy(ptr, ptr)
declare void @llvm.va_end(ptr)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture)

define i32 @int_stack_va_arg(i32 %one, i32 %two, i32 %three, i32 %four, i32 %five, i32 %six, i32 %seven, i32 %eight, ...) local_unnamed_addr {
; CHECK-LABEL: int_stack_va_arg:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    add 3, 4, 3
; CHECK-NEXT:    lwz 4, 56(1)
; CHECK-NEXT:    li 11, 4
; CHECK-NEXT:    add 3, 3, 5
; CHECK-NEXT:    addi 12, 1, 56
; CHECK-NEXT:    add 3, 3, 6
; CHECK-NEXT:    rlwimi 12, 11, 0, 29, 29
; CHECK-NEXT:    stw 12, -4(1)
; CHECK-NEXT:    add 3, 3, 7
; CHECK-NEXT:    add 3, 3, 8
; CHECK-NEXT:    add 3, 3, 9
; CHECK-NEXT:    add 3, 3, 10
; CHECK-NEXT:    add 3, 3, 4
; CHECK-NEXT:    slwi 4, 4, 1
; CHECK-NEXT:    add 3, 3, 4
; CHECK-NEXT:    blr
entry:
  %arg1 = alloca ptr, align 4
  %arg2 = alloca ptr, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %arg1)
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %arg2)
  call void @llvm.va_start(ptr nonnull %arg1)
  call void @llvm.va_copy(ptr nonnull %arg2, ptr nonnull %arg1)
  %add = add nsw i32 %two, %one
  %add2 = add nsw i32 %add, %three
  %add3 = add nsw i32 %add2, %four
  %add4 = add nsw i32 %add3, %five
  %add5 = add nsw i32 %add4, %six
  %add6 = add nsw i32 %add5, %seven
  %add7 = add nsw i32 %add6, %eight
  %argp.cur = load ptr, ptr %arg1, align 4
  %argp.next = getelementptr inbounds i8, ptr %argp.cur, i32 4
  store ptr %argp.next, ptr %arg1, align 4
  %0 = load i32, ptr %argp.cur, align 4
  %add8 = add nsw i32 %add7, %0
  %argp.cur9 = load ptr, ptr %arg2, align 4
  %argp.next10 = getelementptr inbounds i8, ptr %argp.cur9, i32 4
  store ptr %argp.next10, ptr %arg2, align 4
  %1 = load i32, ptr %argp.cur9, align 4
  %mul = shl i32 %1, 1
  %add11 = add nsw i32 %add8, %mul
  call void @llvm.va_end(ptr nonnull %arg1)
  call void @llvm.va_end(ptr nonnull %arg2)
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %arg2)
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %arg1)
  ret i32 %add11
}

define double @double_va_arg(double %a, ...) local_unnamed_addr  {
; CHECK-LABEL: double_va_arg:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    stw 5, -16(1)
; CHECK-NEXT:    addi 3, 1, 32
; CHECK-NEXT:    stw 6, -12(1)
; CHECK-NEXT:    lfd 0, -16(1)
; CHECK-NEXT:    stw 5, -24(1)
; CHECK-NEXT:    fadd 0, 0, 1
; CHECK-NEXT:    stw 6, -20(1)
; CHECK-NEXT:    lfd 1, -24(1)
; CHECK-NEXT:    fadd 1, 1, 1
; CHECK-NEXT:    stw 7, 40(1)
; CHECK-NEXT:    fadd 1, 0, 1
; CHECK-NEXT:    stw 5, 32(1)
; CHECK-NEXT:    stw 6, 36(1)
; CHECK-NEXT:    stw 8, 44(1)
; CHECK-NEXT:    stw 9, 48(1)
; CHECK-NEXT:    stw 10, 52(1)
; CHECK-NEXT:    stw 3, -4(1)
; CHECK-NEXT:    stw 3, -8(1)
; CHECK-NEXT:    blr
entry:
  %arg1 = alloca ptr, align 4
  %arg2 = alloca ptr, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %arg1)
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %arg2)
  call void @llvm.va_start(ptr nonnull %arg1)
  call void @llvm.va_copy(ptr nonnull %arg2, ptr nonnull %arg1)
  %argp.cur = load ptr, ptr %arg1, align 4
  %argp.next = getelementptr inbounds i8, ptr %argp.cur, i32 8
  store ptr %argp.next, ptr %arg1, align 4
  %0 = load double, ptr %argp.cur, align 4
  %add = fadd double %0, %a
  %argp.cur2 = load ptr, ptr %arg2, align 4
  %argp.next3 = getelementptr inbounds i8, ptr %argp.cur2, i32 8
  store ptr %argp.next3, ptr %arg2, align 4
  %1 = load double, ptr %argp.cur2, align 4
  %mul = fmul double %1, 2.000000e+00
  %add4 = fadd double %add, %mul
  call void @llvm.va_end(ptr nonnull %arg1)
  call void @llvm.va_end(ptr nonnull %arg2)
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %arg2)
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %arg1)
  ret double %add4
}

define double @double_stack_va_arg(double %one, double %two, double %three, double %four, double %five, double %six, double %seven, double %eight, double %nine, double %ten, double %eleven, double %twelve, double %thirteen, ...) local_unnamed_addr  {
; CHECK-LABEL: double_stack_va_arg:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fadd 0, 1, 2
; CHECK-NEXT:    addi 3, 1, 128
; CHECK-NEXT:    lwz 4, 132(1)
; CHECK-NEXT:    fadd 0, 0, 3
; CHECK-NEXT:    stw 3, -4(1)
; CHECK-NEXT:    fadd 0, 0, 4
; CHECK-NEXT:    lwz 3, 128(1)
; CHECK-NEXT:    fadd 0, 0, 5
; CHECK-NEXT:    stw 3, -16(1)
; CHECK-NEXT:    fadd 0, 0, 6
; CHECK-NEXT:    stw 4, -12(1)
; CHECK-NEXT:    fadd 0, 0, 7
; CHECK-NEXT:    lfd 1, -16(1)
; CHECK-NEXT:    fadd 0, 0, 8
; CHECK-NEXT:    stw 3, -24(1)
; CHECK-NEXT:    fadd 0, 0, 9
; CHECK-NEXT:    stw 4, -20(1)
; CHECK-NEXT:    fadd 0, 0, 10
; CHECK-NEXT:    fadd 0, 0, 11
; CHECK-NEXT:    fadd 0, 0, 12
; CHECK-NEXT:    fadd 0, 0, 13
; CHECK-NEXT:    fadd 0, 0, 1
; CHECK-NEXT:    lfd 1, -24(1)
; CHECK-NEXT:    fadd 1, 1, 1
; CHECK-NEXT:    fadd 1, 0, 1
; CHECK-NEXT:    blr
entry:
  %arg1 = alloca ptr, align 4
  %arg2 = alloca ptr, align 4
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %arg1)
  call void @llvm.lifetime.start.p0(i64 4, ptr nonnull %arg2)
  call void @llvm.va_start(ptr nonnull %arg1)
  call void @llvm.va_copy(ptr nonnull %arg2, ptr nonnull %arg1)
  %add = fadd double %one, %two
  %add2 = fadd double %add, %three
  %add3 = fadd double %add2, %four
  %add4 = fadd double %add3, %five
  %add5 = fadd double %add4, %six
  %add6 = fadd double %add5, %seven
  %add7 = fadd double %add6, %eight
  %add8 = fadd double %add7, %nine
  %add9 = fadd double %add8, %ten
  %add10 = fadd double %add9, %eleven
  %add11 = fadd double %add10, %twelve
  %add12 = fadd double %add11, %thirteen
  %argp.cur1 = load ptr, ptr %arg1, align 4
  %0 = load double, ptr %argp.cur1, align 4
  %add13 = fadd double %add12, %0
  %argp.cur142 = load ptr, ptr %arg2, align 4
  %1 = load double, ptr %argp.cur142, align 4
  %mul = fmul double %1, 2.000000e+00
  %add16 = fadd double %add13, %mul
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %arg2)
  call void @llvm.lifetime.end.p0(i64 4, ptr nonnull %arg1)
  ret double %add16
}
