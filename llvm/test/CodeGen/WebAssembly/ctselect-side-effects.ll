; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s -mtriple=wasm32-unknown-unknown -O3 -filetype=asm | FileCheck %s --check-prefix=W32
; RUN: llc < %s -mtriple=wasm64-unknown-unknown -O3 -filetype=asm | FileCheck %s --check-prefix=W64

; Test 1: Basic optimizations should still work
define i32 @test_basic_opts(i32 %x) {
; W32-LABEL: test_basic_opts:
; W32:         .functype test_basic_opts (i32) -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    local.get 0
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_basic_opts:
; W64:         .functype test_basic_opts (i32) -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    local.get 0
; W64-NEXT:    # fallthrough-return
  %a = or i32 %x, 0      ; Should eliminate
  %b = and i32 %a, -1    ; Should eliminate
  %c = xor i32 %b, 0     ; Should eliminate
  ret i32 %c
}

; Test 2: Constant folding should work
define i32 @test_constant_fold() {
; W32-LABEL: test_constant_fold:
; W32:         .functype test_constant_fold () -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    i32.const 0
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_constant_fold:
; W64:         .functype test_constant_fold () -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    i32.const 0
; W64-NEXT:    # fallthrough-return
  %a = xor i32 -1, -1    ; Should fold to 0
  ret i32 %a
}

; Test 3: Protected pattern should NOT have branches
define i32 @test_protected_no_branch(i1 %cond, i32 %a, i32 %b) {
; W32-LABEL: test_protected_no_branch:
; W32:         .functype test_protected_no_branch (i32, i32, i32) -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    i32.const 0
; W32-NEXT:    local.get 0
; W32-NEXT:    i32.const 1
; W32-NEXT:    i32.and
; W32-NEXT:    i32.const 1
; W32-NEXT:    i32.and
; W32-NEXT:    i32.sub
; W32-NEXT:    local.tee 0
; W32-NEXT:    local.get 1
; W32-NEXT:    i32.and
; W32-NEXT:    local.get 0
; W32-NEXT:    i32.const -1
; W32-NEXT:    i32.xor
; W32-NEXT:    local.get 2
; W32-NEXT:    i32.and
; W32-NEXT:    i32.or
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_protected_no_branch:
; W64:         .functype test_protected_no_branch (i32, i32, i32) -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    i32.const 0
; W64-NEXT:    local.get 0
; W64-NEXT:    i32.const 1
; W64-NEXT:    i32.and
; W64-NEXT:    i32.const 1
; W64-NEXT:    i32.and
; W64-NEXT:    i32.sub
; W64-NEXT:    local.tee 0
; W64-NEXT:    local.get 1
; W64-NEXT:    i32.and
; W64-NEXT:    local.get 0
; W64-NEXT:    i32.const -1
; W64-NEXT:    i32.xor
; W64-NEXT:    local.get 2
; W64-NEXT:    i32.and
; W64-NEXT:    i32.or
; W64-NEXT:    # fallthrough-return
  %result = call i32 @llvm.ct.select.i32(i1 %cond, i32 %a, i32 %b)
  ret i32 %result
}

; Test 4: Explicit branch should still generate branches
define i32 @test_explicit_branch(i1 %cond, i32 %a, i32 %b) {
; W32-LABEL: test_explicit_branch:
; W32:         .functype test_explicit_branch (i32, i32, i32) -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    block
; W32-NEXT:    local.get 0
; W32-NEXT:    i32.const 1
; W32-NEXT:    i32.and
; W32-NEXT:    i32.eqz
; W32-NEXT:    br_if 0 # 0: down to label0
; W32-NEXT:  # %bb.1: # %true
; W32-NEXT:    local.get 1
; W32-NEXT:    return
; W32-NEXT:  .LBB3_2: # %false
; W32-NEXT:    end_block # label0:
; W32-NEXT:    local.get 2
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_explicit_branch:
; W64:         .functype test_explicit_branch (i32, i32, i32) -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    block
; W64-NEXT:    local.get 0
; W64-NEXT:    i32.const 1
; W64-NEXT:    i32.and
; W64-NEXT:    i32.eqz
; W64-NEXT:    br_if 0 # 0: down to label0
; W64-NEXT:  # %bb.1: # %true
; W64-NEXT:    local.get 1
; W64-NEXT:    return
; W64-NEXT:  .LBB3_2: # %false
; W64-NEXT:    end_block # label0:
; W64-NEXT:    local.get 2
; W64-NEXT:    # fallthrough-return
  br i1 %cond, label %true, label %false
true:
  ret i32 %a
false:
  ret i32 %b
}

; Test 5: Regular select (not ct.select) - whatever wasm wants to do
define i32 @test_regular_select(i1 %cond, i32 %a, i32 %b) {
; W32-LABEL: test_regular_select:
; W32:         .functype test_regular_select (i32, i32, i32) -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    local.get 1
; W32-NEXT:    local.get 2
; W32-NEXT:    local.get 0
; W32-NEXT:    i32.const 1
; W32-NEXT:    i32.and
; W32-NEXT:    i32.select
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_regular_select:
; W64:         .functype test_regular_select (i32, i32, i32) -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    local.get 1
; W64-NEXT:    local.get 2
; W64-NEXT:    local.get 0
; W64-NEXT:    i32.const 1
; W64-NEXT:    i32.and
; W64-NEXT:    i32.select
; W64-NEXT:    # fallthrough-return
  %result = select i1 %cond, i32 %a, i32 %b
  ret i32 %result
}

; Test if XOR with all-ones still gets optimized
define i32 @test_xor_all_ones() {
; W32-LABEL: test_xor_all_ones:
; W32:         .functype test_xor_all_ones () -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    i32.const 0
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_xor_all_ones:
; W64:         .functype test_xor_all_ones () -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    i32.const 0
; W64-NEXT:    # fallthrough-return
  %xor1 = xor i32 -1, -1  ; Should optimize to 0
  ret i32 %xor1
}

define i32 @test_xor_same_value(i32 %x) {
; W32-LABEL: test_xor_same_value:
; W32:         .functype test_xor_same_value (i32) -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    i32.const 0
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_xor_same_value:
; W64:         .functype test_xor_same_value (i32) -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    i32.const 0
; W64-NEXT:    # fallthrough-return
  %xor2 = xor i32 %x, %x  ; Should optimize to 0
  ret i32 %xor2
}

define i32 @test_normal_ops(i32 %x) {
; W32-LABEL: test_normal_ops:
; W32:         .functype test_normal_ops (i32) -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    local.get 0
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_normal_ops:
; W64:         .functype test_normal_ops (i32) -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    local.get 0
; W64-NEXT:    # fallthrough-return
  %or1 = or i32 %x, 0
  %and1 = and i32 %or1, -1
  %xor1 = xor i32 %and1, 0
  ret i32 %xor1
}

; This simulates what the reviewer is worried about
define i32 @test_xor_with_const_operands() {
; W32-LABEL: test_xor_with_const_operands:
; W32:         .functype test_xor_with_const_operands () -> (i32)
; W32-NEXT:  # %bb.0:
; W32-NEXT:    i32.const 0
; W32-NEXT:    # fallthrough-return
;
; W64-LABEL: test_xor_with_const_operands:
; W64:         .functype test_xor_with_const_operands () -> (i32)
; W64-NEXT:  # %bb.0:
; W64-NEXT:    i32.const 0
; W64-NEXT:    # fallthrough-return
  %a = xor i32 -1, -1
  %b = xor i32 0, 0
  %c = xor i32 42, 42
  %result = or i32 %a, %b
  %final = or i32 %result, %c
  ret i32 %final  ; Should optimize to 0
}

declare i32 @llvm.ct.select.i32(i1, i32, i32)

