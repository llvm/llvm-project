; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s -mtriple=arm64-apple-ios7.0.0 |  FileCheck %s --check-prefixes=CHECK,CHECK-SD
; RUN: llc < %s -mtriple=arm64-apple-ios7.0.0 -global-isel |  FileCheck %s --check-prefixes=CHECK,CHECK-GI

target datalayout = "e-m:o-i64:64-i128:128-n32:64-S128"

declare i32 @llvm.ctlz.i32(i32, i1) #0
declare i64 @llvm.ctlz.i64(i64, i1) #1

define i32 @clrsb32(i32 %x) #2 {
; CHECK-LABEL: clrsb32:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls w0, w0
; CHECK-NEXT:    ret
entry:
  %shr = ashr i32 %x, 31
  %xor = xor i32 %shr, %x
  %mul = shl i32 %xor, 1
  %add = or i32 %mul, 1
  %0 = tail call i32 @llvm.ctlz.i32(i32 %add, i1 false)
  ret i32 %0
}

define i32 @clrsb32_2(i32 %x) #2 {
; CHECK-LABEL: clrsb32_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls w8, w0
; CHECK-NEXT:    add w0, w8, #2
; CHECK-NEXT:    ret
entry:
  %shr = ashr i32 %x, 31
  %xor = xor i32 %shr, %x
  %ctlz = tail call i32 @llvm.ctlz.i32(i32 %xor, i1 false)
  %sub = add i32 %ctlz, 1
  ret i32 %sub
}

define i64 @clrsb64(i64 %x) #3 {
; CHECK-LABEL: clrsb64:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls x0, x0
; CHECK-NEXT:    ret
entry:
  %shr = ashr i64 %x, 63
  %xor = xor i64 %shr, %x
  %mul = shl nsw i64 %xor, 1
  %add = or i64 %mul, 1
  %0 = tail call i64 @llvm.ctlz.i64(i64 %add, i1 false)
  ret i64 %0
}

define i64 @clrsb64_2(i64 %x) #3 {
; CHECK-LABEL: clrsb64_2:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls x8, x0
; CHECK-NEXT:    add x0, x8, #2
; CHECK-NEXT:    ret
entry:
  %shr = ashr i64 %x, 63
  %xor = xor i64 %shr, %x
  %ctlz = tail call i64 @llvm.ctlz.i64(i64 %xor, i1 false)
  %sub = add i64 %ctlz, 1
  ret i64 %sub
}

define i32 @clrsb32_zeroundef(i32 %x) #2 {
; CHECK-LABEL: clrsb32_zeroundef:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls w0, w0
; CHECK-NEXT:    ret
entry:
  %shr = ashr i32 %x, 31
  %xor = xor i32 %shr, %x
  %mul = shl i32 %xor, 1
  %add = or i32 %mul, 1
  %0 = tail call i32 @llvm.ctlz.i32(i32 %add, i1 true)
  ret i32 %0
}

define i64 @clrsb64_zeroundef(i64 %x) #3 {
; CHECK-LABEL: clrsb64_zeroundef:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls x0, x0
; CHECK-NEXT:    ret
entry:
  %shr = ashr i64 %x, 63
  %xor = xor i64 %shr, %x
  %mul = shl nsw i64 %xor, 1
  %add = or i64 %mul, 1
  %0 = tail call i64 @llvm.ctlz.i64(i64 %add, i1 true)
  ret i64 %0
}

define i8 @cls_i8(i8 %x) {
; CHECK-LABEL: cls_i8:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    sxtb w8, w0
; CHECK-NEXT:    cls w8, w8
; CHECK-NEXT:    sub w0, w8, #24
; CHECK-NEXT:    ret

  %a = ashr i8 %x, 7
  %b = xor i8 %x, %a
  %c = call i8 @llvm.ctlz.i8(i8 %b, i1 false)
  %d = sub i8 %c, 1
  ret i8 %d
}

; The result is in the range [1-31], so we don't need an andi after the cls.
define i32 @cls_i32_knownbits(i32 %x) {
; CHECK-LABEL: cls_i32_knownbits:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    cls w0, w0
; CHECK-NEXT:    ret
  %a = ashr i32 %x, 31
  %b = xor i32 %x, %a
  %c = call i32 @llvm.ctlz.i32(i32 %b, i1 false)
  %d = sub i32 %c, 1
  %e = and i32 %d, 31
  ret i32 %e
}

; There are at least 16 redundant sign bits so we don't need an ori after the cls.
define i32 @cls_i32_knownbits_2(i16 signext %x) {
; CHECK-SD-LABEL: cls_i32_knownbits_2:
; CHECK-SD:       ; %bb.0:
; CHECK-SD-NEXT:    cls w0, w0
; CHECK-SD-NEXT:    ret
;
; CHECK-GI-LABEL: cls_i32_knownbits_2:
; CHECK-GI:       ; %bb.0:
; CHECK-GI-NEXT:    cls w8, w0
; CHECK-GI-NEXT:    orr w0, w8, #0x10
; CHECK-GI-NEXT:    ret
  %sext = sext i16 %x to i32
  %a = ashr i32 %sext, 31
  %b = xor i32 %sext, %a
  %c = call i32 @llvm.ctlz.i32(i32 %b, i1 false)
  %d = sub i32 %c, 1
  %e = or i32 %d, 16
  ret i32 %e
}

; Check that the range max in ctls cls knownbits
; is not set to 32
define i64 @cls_i64_not_32(i64 %x) {
; CHECK-SD-LABEL: cls_i64_not_32:
; CHECK-SD:       ; %bb.0:
; CHECK-SD-NEXT:    asr x8, x0, #16
; CHECK-SD-NEXT:    cls x8, x8
; CHECK-SD-NEXT:    orr x0, x8, #0x10
; CHECK-SD-NEXT:    ret
;
; CHECK-GI-LABEL: cls_i64_not_32:
; CHECK-GI:       ; %bb.0:
; CHECK-GI-NEXT:    asr x8, x0, #63
; CHECK-GI-NEXT:    eor x8, x8, x0, asr #16
; CHECK-GI-NEXT:    lsl x8, x8, #1
; CHECK-GI-NEXT:    orr x8, x8, #0x1
; CHECK-GI-NEXT:    clz x8, x8
; CHECK-GI-NEXT:    orr x0, x8, #0x10
; CHECK-GI-NEXT:    ret
  %val = ashr i64 %x, 16
  %a = ashr i64 %val, 63
  %b = xor i64 %val, %a
  %c = shl i64 %b, 1
  %d = or i64 %c, 1
  %e = call i64 @llvm.ctlz.i64(i64 %d, i1 true)
  %f = or i64 %e, 16
  ret i64 %f
}

; There are at least 24 redundant sign bits so we don't need an ori after the clsw.
define i32 @cls_i32_knownbits_3(i8 signext %x) {
; CHECK-SD-LABEL: cls_i32_knownbits_3:
; CHECK-SD:       ; %bb.0:
; CHECK-SD-NEXT:    cls w0, w0
; CHECK-SD-NEXT:    ret
;
; CHECK-GI-LABEL: cls_i32_knownbits_3:
; CHECK-GI:       ; %bb.0:
; CHECK-GI-NEXT:    cls w8, w0
; CHECK-GI-NEXT:    orr w0, w8, #0x18
; CHECK-GI-NEXT:    ret
  %sext = sext i8 %x to i32
  %a = ashr i32 %sext, 31
  %b = xor i32 %sext, %a
  %c = call i32 @llvm.ctlz.i32(i32 %b, i1 false)
  %d = sub i32 %c, 1
  %e = or i32 %d, 24
  ret i32 %e
}

; Negative test. We only know there is at least 1 redundant sign bit. We can't
; remove the ori.
define i32 @cls_i32_knownbits_4(i32 signext %x) {
; CHECK-LABEL: cls_i32_knownbits_4:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    sbfx w8, w0, #0, #31
; CHECK-NEXT:    cls w8, w8
; CHECK-NEXT:    orr w0, w8, #0x1
; CHECK-NEXT:    ret
  %shl = shl i32 %x, 1
  %ashr = ashr i32 %shl, 1
  %a = ashr i32 %ashr, 31
  %b = xor i32 %ashr, %a
  %c = call i32 @llvm.ctlz.i32(i32 %b, i1 false)
  %d = sub i32 %c, 1
  %e = or i32 %d, 1
  ret i32 %e
 }

; Negative test. Check that the number of sign bits is not
; overestimated. If it is, the orr disappears.
define i32 @cls_i32_knownbits_no_overestimate(i32 signext %x) {
; CHECK-SD-LABEL: cls_i32_knownbits_no_overestimate:
; CHECK-SD:       ; %bb.0:
; CHECK-SD-NEXT:    asr w8, w0, #15
; CHECK-SD-NEXT:    cls w8, w8
; CHECK-SD-NEXT:    orr w0, w8, #0x10
; CHECK-SD-NEXT:    ret
;
; CHECK-GI-LABEL: cls_i32_knownbits_no_overestimate:
; CHECK-GI:       ; %bb.0:
; CHECK-GI-NEXT:    asr w8, w0, #31
; CHECK-GI-NEXT:    eor w8, w8, w0, asr #15
; CHECK-GI-NEXT:    clz w8, w8
; CHECK-GI-NEXT:    sub w8, w8, #1
; CHECK-GI-NEXT:    orr w0, w8, #0x10
; CHECK-GI-NEXT:    ret
  %ashr = ashr i32 %x, 15
  %a = ashr i32 %ashr, 31
  %b = xor i32 %ashr, %a
  %c = call i32 @llvm.ctlz.i32(i32 %b, i1 false)
  %d = sub i32 %c, 1
  %e = or i32 %d, 16
  ret i32 %e
 }

