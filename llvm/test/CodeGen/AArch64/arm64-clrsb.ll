; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s -mtriple=arm64-apple-ios7.0.0 |  FileCheck %s --check-prefixes=CHECK,CHECK-SD
; RUN: llc < %s -mtriple=arm64-apple-ios7.0.0 -global-isel |  FileCheck %s --check-prefixes=CHECK,CHECK-GI

target datalayout = "e-m:o-i64:64-i128:128-n32:64-S128"

declare i32 @llvm.ctlz.i32(i32, i1) #0
declare i64 @llvm.ctlz.i64(i64, i1) #1

define i32 @clrsb32(i32 %x) #2 {
; CHECK-LABEL: clrsb32:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls w0, w0
; CHECK-NEXT:    ret
entry:
  %shr = ashr i32 %x, 31
  %xor = xor i32 %shr, %x
  %mul = shl i32 %xor, 1
  %add = or i32 %mul, 1
  %0 = tail call i32 @llvm.ctlz.i32(i32 %add, i1 false)
  ret i32 %0
}

define i32 @clrsb32_2(i32 %x) #2 {
; CHECK-SD-LABEL: clrsb32_2:
; CHECK-SD:       ; %bb.0: ; %entry
; CHECK-SD-NEXT:    cls w8, w0
; CHECK-SD-NEXT:    add w0, w8, #2
; CHECK-SD-NEXT:    ret
;
; CHECK-GI-LABEL: clrsb32_2:
; CHECK-GI:       ; %bb.0: ; %entry
; CHECK-GI-NEXT:    eor w8, w0, w0, asr #31
; CHECK-GI-NEXT:    clz w8, w8
; CHECK-GI-NEXT:    add w0, w8, #1
; CHECK-GI-NEXT:    ret
entry:
  %shr = ashr i32 %x, 31
  %xor = xor i32 %shr, %x
  %ctlz = tail call i32 @llvm.ctlz.i32(i32 %xor, i1 false)
  %sub = add i32 %ctlz, 1
  ret i32 %sub
}

define i64 @clrsb64(i64 %x) #3 {
; CHECK-LABEL: clrsb64:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls x0, x0
; CHECK-NEXT:    ret
entry:
  %shr = ashr i64 %x, 63
  %xor = xor i64 %shr, %x
  %mul = shl nsw i64 %xor, 1
  %add = or i64 %mul, 1
  %0 = tail call i64 @llvm.ctlz.i64(i64 %add, i1 false)
  ret i64 %0
}

define i64 @clrsb64_2(i64 %x) #3 {
; CHECK-SD-LABEL: clrsb64_2:
; CHECK-SD:       ; %bb.0: ; %entry
; CHECK-SD-NEXT:    cls x8, x0
; CHECK-SD-NEXT:    add x0, x8, #2
; CHECK-SD-NEXT:    ret
;
; CHECK-GI-LABEL: clrsb64_2:
; CHECK-GI:       ; %bb.0: ; %entry
; CHECK-GI-NEXT:    eor x8, x0, x0, asr #63
; CHECK-GI-NEXT:    clz x8, x8
; CHECK-GI-NEXT:    add x0, x8, #1
; CHECK-GI-NEXT:    ret
entry:
  %shr = ashr i64 %x, 63
  %xor = xor i64 %shr, %x
  %ctlz = tail call i64 @llvm.ctlz.i64(i64 %xor, i1 false)
  %sub = add i64 %ctlz, 1
  ret i64 %sub
}

define i32 @clrsb32_zeroundef(i32 %x) #2 {
; CHECK-LABEL: clrsb32_zeroundef:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls w0, w0
; CHECK-NEXT:    ret
entry:
  %shr = ashr i32 %x, 31
  %xor = xor i32 %shr, %x
  %mul = shl i32 %xor, 1
  %add = or i32 %mul, 1
  %0 = tail call i32 @llvm.ctlz.i32(i32 %add, i1 true)
  ret i32 %0
}

define i64 @clrsb64_zeroundef(i64 %x) #3 {
; CHECK-LABEL: clrsb64_zeroundef:
; CHECK:       ; %bb.0: ; %entry
; CHECK-NEXT:    cls x0, x0
; CHECK-NEXT:    ret
entry:
  %shr = ashr i64 %x, 63
  %xor = xor i64 %shr, %x
  %mul = shl nsw i64 %xor, 1
  %add = or i64 %mul, 1
  %0 = tail call i64 @llvm.ctlz.i64(i64 %add, i1 true)
  ret i64 %0
}

