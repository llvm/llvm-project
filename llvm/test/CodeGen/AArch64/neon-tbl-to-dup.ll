; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s -verify-machineinstrs -mtriple=aarch64-none-linux-gnu -mattr=neon | FileCheck %s

define <4 x i32> @tbl_v16i8_broadcast_i32_lane0(<4 x i32> %v) {
; CHECK-LABEL: tbl_v16i8_broadcast_i32_lane0:
; CHECK:       // %bb.0:
; CHECK-NEXT:    dup v0.4s, v0.s[0]
; CHECK-NEXT:    ret
  %bc = bitcast <4 x i32> %v to <16 x i8>
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> <i8 0, i8 1, i8 2, i8 3, i8 0, i8 1, i8 2, i8 3, i8 0, i8 1, i8 2, i8 3, i8 0, i8 1, i8 2, i8 3>)
  %res = bitcast <16 x i8> %tbl to <4 x i32>
  ret <4 x i32> %res
}

define <4 x i32> @tbl_v16i8_broadcast_i32_lane2(<4 x i32> %v) {
; CHECK-LABEL: tbl_v16i8_broadcast_i32_lane2:
; CHECK:       // %bb.0:
; CHECK-NEXT:    dup v0.4s, v0.s[2]
; CHECK-NEXT:    ret
  %bc = bitcast <4 x i32> %v to <16 x i8>
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> <i8 8, i8 9, i8 10, i8 11, i8 8, i8 9, i8 10, i8 11, i8 8, i8 9, i8 10, i8 11, i8 8, i8 9, i8 10, i8 11>)
  %res = bitcast <16 x i8> %tbl to <4 x i32>
  ret <4 x i32> %res
}

define <8 x i16> @tbl_v16i8_broadcast_i16_lane0(<8 x i16> %v) {
; CHECK-LABEL: tbl_v16i8_broadcast_i16_lane0:
; CHECK:       // %bb.0:
; CHECK-NEXT:    dup v0.8h, v0.h[0]
; CHECK-NEXT:    ret
  %bc = bitcast <8 x i16> %v to <16 x i8>
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> <i8 0, i8 1, i8 0, i8 1, i8 0, i8 1, i8 0, i8 1, i8 0, i8 1, i8 0, i8 1, i8 0, i8 1, i8 0, i8 1>)
  %res = bitcast <16 x i8> %tbl to <8 x i16>
  ret <8 x i16> %res
}

define <8 x i16> @tbl_v16i8_broadcast_i16_lane5(<8 x i16> %v) {
; CHECK-LABEL: tbl_v16i8_broadcast_i16_lane5:
; CHECK:       // %bb.0:
; CHECK-NEXT:    dup v0.8h, v0.h[5]
; CHECK-NEXT:    ret
  %bc = bitcast <8 x i16> %v to <16 x i8>
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> <i8 10, i8 11, i8 10, i8 11, i8 10, i8 11, i8 10, i8 11, i8 10, i8 11, i8 10, i8 11, i8 10, i8 11, i8 10, i8 11>)
  %res = bitcast <16 x i8> %tbl to <8 x i16>
  ret <8 x i16> %res
}

define <2 x i64> @tbl_v16i8_broadcast_i64_lane1(<2 x i64> %v) {
; CHECK-LABEL: tbl_v16i8_broadcast_i64_lane1:
; CHECK:       // %bb.0:
; CHECK-NEXT:    dup v0.2d, v0.d[1]
; CHECK-NEXT:    ret
  %bc = bitcast <2 x i64> %v to <16 x i8>
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> <i8 8, i8 9, i8 10, i8 11, i8 12, i8 13, i8 14, i8 15, i8 8, i8 9, i8 10, i8 11, i8 12, i8 13, i8 14, i8 15>)
  %res = bitcast <16 x i8> %tbl to <2 x i64>
  ret <2 x i64> %res
}

; Negative tests - should NOT be converted to DUP

define <4 x i32> @tbl_not_broadcast_mixed(<4 x i32> %v) {
; CHECK-LABEL: tbl_not_broadcast_mixed:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adrp x8, .LCPI5_0
; CHECK-NEXT:    ldr q1, [x8, :lo12:.LCPI5_0]
; CHECK-NEXT:    tbl v0.16b, { v0.16b }, v1.16b
; CHECK-NEXT:    ret
  %bc = bitcast <4 x i32> %v to <16 x i8>
  ; Mixed pattern - alternates between lanes 2 and 0
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> <i8 8, i8 9, i8 10, i8 11, i8 0, i8 1, i8 2, i8 3, i8 8, i8 9, i8 10, i8 11, i8 0, i8 1, i8 2, i8 3>)
  %res = bitcast <16 x i8> %tbl to <4 x i32>
  ret <4 x i32> %res
}

define <4 x i32> @tbl_not_broadcast_all_negative(<4 x i32> %v) {
; CHECK-LABEL: tbl_not_broadcast_all_negative:
; CHECK:       // %bb.0:
; CHECK-NEXT:    movi v1.2d, #0xffffffffffffffff
; CHECK-NEXT:    tbl v0.16b, { v0.16b }, v1.16b
; CHECK-NEXT:    ret
  %bc = bitcast <4 x i32> %v to <16 x i8>
  ; All indices are out-of-bounds (0xFF = -1)
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> splat (i8 -1))
  %res = bitcast <16 x i8> %tbl to <4 x i32>
  ret <4 x i32> %res
}

define <4 x i32> @tbl_not_broadcast_some_negative(<4 x i32> %v) {
; CHECK-LABEL: tbl_not_broadcast_some_negative:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adrp x8, .LCPI7_0
; CHECK-NEXT:    ldr q1, [x8, :lo12:.LCPI7_0]
; CHECK-NEXT:    tbl v0.16b, { v0.16b }, v1.16b
; CHECK-NEXT:    ret
  %bc = bitcast <4 x i32> %v to <16 x i8>
  ; Mix of valid broadcast pattern with negatives - should not optimize
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> <i8 0, i8 1, i8 2, i8 3, i8 -1, i8 -1, i8 -1, i8 -1, i8 0, i8 1, i8 2, i8 3, i8 -1, i8 -1, i8 -1, i8 -1>)
  %res = bitcast <16 x i8> %tbl to <4 x i32>
  ret <4 x i32> %res
}

define <4 x i32> @tbl_not_broadcast_reverse(<4 x i32> %v) {
; CHECK-LABEL: tbl_not_broadcast_reverse:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adrp x8, .LCPI8_0
; CHECK-NEXT:    ldr q1, [x8, :lo12:.LCPI8_0]
; CHECK-NEXT:    tbl v0.16b, { v0.16b }, v1.16b
; CHECK-NEXT:    ret
  %bc = bitcast <4 x i32> %v to <16 x i8>
  ; Byte-reversed within element - not a simple broadcast
  %tbl = call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> %bc, <16 x i8> <i8 11, i8 10, i8 9, i8 8, i8 11, i8 10, i8 9, i8 8, i8 11, i8 10, i8 9, i8 8, i8 11, i8 10, i8 9, i8 8>)
  %res = bitcast <16 x i8> %tbl to <4 x i32>
  ret <4 x i32> %res
}

; Shufflevector-based tests

define <4 x i32> @shuffle_bitcast_broadcast_i32_lane2(<4 x i32> %v) {
; CHECK-LABEL: shuffle_bitcast_broadcast_i32_lane2:
; CHECK:       // %bb.0:
; CHECK-NEXT:    dup v0.4s, v0.s[2]
; CHECK-NEXT:    ret
  %bc1 = bitcast <4 x i32> %v to <16 x i8>
  ; Broadcast bytes 8-11 (lane 2 of i32) across all positions
  %shuf = shufflevector <16 x i8> %bc1, <16 x i8> poison,
    <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 8, i32 9, i32 10, i32 11,
                i32 8, i32 9, i32 10, i32 11, i32 8, i32 9, i32 10, i32 11>
  %bc2 = bitcast <16 x i8> %shuf to <4 x i32>
  ret <4 x i32> %bc2
}

define <8 x i16> @shuffle_bitcast_broadcast_i16_lane3(<8 x i16> %v) {
; CHECK-LABEL: shuffle_bitcast_broadcast_i16_lane3:
; CHECK:       // %bb.0:
; CHECK-NEXT:    dup v0.8h, v0.h[3]
; CHECK-NEXT:    ret
  %bc1 = bitcast <8 x i16> %v to <16 x i8>
  ; Broadcast bytes 6-7 (lane 3 of i16) across all positions
  %shuf = shufflevector <16 x i8> %bc1, <16 x i8> poison,
    <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7,
                i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %bc2 = bitcast <16 x i8> %shuf to <8 x i16>
  ret <8 x i16> %bc2
}

define <2 x i64> @shuffle_bitcast_broadcast_i64_lane0(<2 x i64> %v) {
; CHECK-LABEL: shuffle_bitcast_broadcast_i64_lane0:
; CHECK:       // %bb.0:
; CHECK-NEXT:    dup v0.2d, v0.d[0]
; CHECK-NEXT:    ret
  %bc1 = bitcast <2 x i64> %v to <16 x i8>
  ; Broadcast bytes 0-7 (lane 0 of i64) across both halves
  %shuf = shufflevector <16 x i8> %bc1, <16 x i8> poison,
    <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7,
                i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %bc2 = bitcast <16 x i8> %shuf to <2 x i64>
  ret <2 x i64> %bc2
}

declare <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8>, <16 x i8>)
