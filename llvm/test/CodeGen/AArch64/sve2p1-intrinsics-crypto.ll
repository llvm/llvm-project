; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=aarch64-linux-gnu -mattr=+sve,+sve-aes2 < %s | FileCheck %s
; RUN: llc -mtriple=aarch64-linux-gnu -mattr=+sve-aes2,+ssve-aes -force-streaming < %s | FileCheck %s

;
; AESE
;

define { <vscale x 16 x i8>, <vscale x 16 x i8> } @aese_x2(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c) {
; CHECK-LABEL: aese_x2:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    aese { z0.b, z1.b }, { z0.b, z1.b }, z2.q[0]
; CHECK-NEXT:    ret
  %out = call { <vscale x 16 x i8>, <vscale x 16 x i8> } @llvm.aarch64.sve.aese.lane.x2(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c, i32 0)
  ret { <vscale x 16 x i8>, <vscale x 16 x i8> } %out
}

define { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> } @aese_x4(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c, <vscale x 16 x i8> %d) {
; CHECK-LABEL: aese_x4:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z3 killed $z3 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z2 killed $z2 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    aese { z0.b - z3.b }, { z0.b - z3.b }, z2.q[0]
; CHECK-NEXT:    ret
  %out= call { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> }  @llvm.aarch64.sve.aese.lane.x4(<vscale x 16 x i8> %a,
                                                                                                    <vscale x 16 x i8> %b, <vscale x 16 x i8> %c,
                                                                                                    <vscale x 16 x i8> %d, <vscale x 16 x i8> %c , i32 0)
  ret { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> } %out
}

;
; AESD
;

define { <vscale x 16 x i8>, <vscale x 16 x i8> } @aesd_x2(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c) {
; CHECK-LABEL: aesd_x2:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    aesd { z0.b, z1.b }, { z0.b, z1.b }, z2.q[0]
; CHECK-NEXT:    ret
  %out= call { <vscale x 16 x i8>, <vscale x 16 x i8> } @llvm.aarch64.sve.aesd.lane.x2(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c, i32 0)
  ret { <vscale x 16 x i8>, <vscale x 16 x i8> } %out
}

define { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> } @aesd_x4(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c, <vscale x 16 x i8> %d) {
; CHECK-LABEL: aesd_x4:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z3 killed $z3 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z2 killed $z2 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    aesd { z0.b - z3.b }, { z0.b - z3.b }, z2.q[0]
; CHECK-NEXT:    ret
  %out= call { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> }  @llvm.aarch64.sve.aesd.lane.x4(<vscale x 16 x i8> %a,
                                                                                                    <vscale x 16 x i8> %b, <vscale x 16 x i8> %c,
                                                                                                    <vscale x 16 x i8> %d, <vscale x 16 x i8> %c , i32 0)
  ret { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> } %out
}


;
; AESEMC
;

define { <vscale x 16 x i8>, <vscale x 16 x i8> } @aesemc_x2(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c) {
; CHECK-LABEL: aesemc_x2:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    aesemc { z0.b, z1.b }, { z0.b, z1.b }, z2.q[0]
; CHECK-NEXT:    ret
  %out= call { <vscale x 16 x i8>, <vscale x 16 x i8> } @llvm.aarch64.sve.aesemc.lane.x2(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c, i32 0)
  ret { <vscale x 16 x i8>, <vscale x 16 x i8> } %out
}

define { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> } @aesemc_x4(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c, <vscale x 16 x i8> %d) {
; CHECK-LABEL: aesemc_x4:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z3 killed $z3 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z2 killed $z2 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    aesemc { z0.b - z3.b }, { z0.b - z3.b }, z2.q[0]
; CHECK-NEXT:    ret
  %out= call { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> }  @llvm.aarch64.sve.aesemc.lane.x4(<vscale x 16 x i8> %a,
                                                                                                    <vscale x 16 x i8> %b, <vscale x 16 x i8> %c,
                                                                                                    <vscale x 16 x i8> %d, <vscale x 16 x i8> %c , i32 0)
  ret { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> } %out
}

;
; AESDIMC
;

define { <vscale x 16 x i8>, <vscale x 16 x i8> } @aesdimc_x2(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c) {
; CHECK-LABEL: aesdimc_x2:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    aesdimc { z0.b, z1.b }, { z0.b, z1.b }, z2.q[0]
; CHECK-NEXT:    ret
  %out= call { <vscale x 16 x i8>, <vscale x 16 x i8> } @llvm.aarch64.sve.aesdimc.lane.x2(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c, i32 0)
  ret { <vscale x 16 x i8>, <vscale x 16 x i8> } %out
}

define { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> } @aesdimc_x4(<vscale x 16 x i8> %a, <vscale x 16 x i8> %b, <vscale x 16 x i8> %c, <vscale x 16 x i8> %d) {
; CHECK-LABEL: aesdimc_x4:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z3 killed $z3 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z2 killed $z2 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1_z2_z3 def $z0_z1_z2_z3
; CHECK-NEXT:    aesdimc { z0.b - z3.b }, { z0.b - z3.b }, z2.q[0]
; CHECK-NEXT:    ret
  %out= call { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> }  @llvm.aarch64.sve.aesdimc.lane.x4(<vscale x 16 x i8> %a,
                                                                                                    <vscale x 16 x i8> %b, <vscale x 16 x i8> %c,
                                                                                                    <vscale x 16 x i8> %d, <vscale x 16 x i8> %c , i32 0)
  ret { <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8>, <vscale x 16 x i8> } %out
}

;
; PMULL
;

define { <vscale x 2 x i64>, <vscale x 2 x i64> } @pmull_i64(<vscale x 2 x i64> %a, <vscale x 2 x i64> %b) {
; CHECK-LABEL: pmull_i64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    pmull { z0.q, z1.q }, z0.d, z1.d
; CHECK-NEXT:    ret
  %out = call { <vscale x 2 x i64>, <vscale x 2 x i64> } @llvm.aarch64.sve.pmull.pair.x2(<vscale x 2 x i64> %a,
                                                                       <vscale x 2 x i64> %b)
  ret { <vscale x 2 x i64>, <vscale x 2 x i64> } %out
}


;
; PMLAL
;

define { <vscale x 2 x i64>, <vscale x 2 x i64> } @pmlal_i64(<vscale x 2 x i64> %a, <vscale x 2 x i64> %b, <vscale x 2 x i64> %c, <vscale x 2 x i64> %d) {
; CHECK-LABEL: pmlal_i64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    // kill: def $z1 killed $z1 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    // kill: def $z0 killed $z0 killed $z0_z1 def $z0_z1
; CHECK-NEXT:    pmlal { z0.q, z1.q }, z2.d, z3.d
; CHECK-NEXT:    ret
  %out = call { <vscale x 2 x i64>, <vscale x 2 x i64> } @llvm.aarch64.sve.pmlal.pair.x2(<vscale x 2 x i64> %a, <vscale x 2 x i64> %b, <vscale x 2 x i64> %c,
                                                                       <vscale x 2 x i64> %d)
  ret { <vscale x 2 x i64>, <vscale x 2 x i64> } %out
}
