; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=aarch64-linux-gnu -mattr=+sve < %s | FileCheck %s

define i8 @uaddv_zexti8_nxv16i1(<vscale x 16 x i1> %v) {
; CHECK-LABEL: uaddv_zexti8_nxv16i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.b
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 16 x i1> %v to <vscale x 16 x i8>
  %4 = tail call i8 @llvm.vector.reduce.add.nxv16i8(<vscale x 16 x i8> %3)
  ret i8 %4
}

define i32 @uaddv_zexti8_nxv16i32(<vscale x 16 x i1> %v) {
; CHECK-LABEL: uaddv_zexti8_nxv16i32:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    punpklo p1.h, p0.b
; CHECK-NEXT:    mov z0.s, #1 // =0x1
; CHECK-NEXT:    punpkhi p0.h, p0.b
; CHECK-NEXT:    punpklo p2.h, p1.b
; CHECK-NEXT:    punpkhi p1.h, p1.b
; CHECK-NEXT:    mov z1.s, p2/z, #1 // =0x1
; CHECK-NEXT:    punpklo p3.h, p0.b
; CHECK-NEXT:    mov z2.s, p1/z, #1 // =0x1
; CHECK-NEXT:    punpkhi p0.h, p0.b
; CHECK-NEXT:    add z1.s, p3/m, z1.s, z0.s
; CHECK-NEXT:    add z2.s, p0/m, z2.s, z0.s
; CHECK-NEXT:    ptrue p0.s
; CHECK-NEXT:    add z0.s, z1.s, z2.s
; CHECK-NEXT:    uaddv d0, p0, z0.s
; CHECK-NEXT:    fmov w0, s0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 16 x i1> %v to <vscale x 16 x i32>
  %4 = tail call i32 @llvm.vector.reduce.add.nxv16i32(<vscale x 16 x i32> %3)
  ret i32 %4
}

define i8 @uaddv_zexti8_nxv8i1(<vscale x 8 x i1> %v) {
; CHECK-LABEL: uaddv_zexti8_nxv8i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.h
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 8 x i1> %v to <vscale x 8 x i8>
  %4 = tail call i8 @llvm.vector.reduce.add.nxv8i8(<vscale x 8 x i8> %3)
  ret i8 %4
}

define i16 @uaddv_zexti16_nxv8i1(<vscale x 8 x i1> %v) {
; CHECK-LABEL: uaddv_zexti16_nxv8i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.h
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 8 x i1> %v to <vscale x 8 x i16>
  %4 = tail call i16 @llvm.vector.reduce.add.nxv8i16(<vscale x 8 x i16> %3)
  ret i16 %4
}

define i32 @uaddv_zexti32_nxv8i1(<vscale x 8 x i1> %v) {
; CHECK-LABEL: uaddv_zexti32_nxv8i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    punpklo p1.h, p0.b
; CHECK-NEXT:    mov z0.s, #1 // =0x1
; CHECK-NEXT:    punpkhi p0.h, p0.b
; CHECK-NEXT:    mov z1.s, p1/z, #1 // =0x1
; CHECK-NEXT:    add z1.s, p0/m, z1.s, z0.s
; CHECK-NEXT:    ptrue p0.s
; CHECK-NEXT:    uaddv d0, p0, z1.s
; CHECK-NEXT:    fmov w0, s0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 8 x i1> %v to <vscale x 8 x i32>
  %4 = tail call i32 @llvm.vector.reduce.add.nxv8i32(<vscale x 8 x i32> %3)
  ret i32 %4
}

define i8 @uaddv_zexti8_nxv4i1(<vscale x 4 x i1> %v) {
; CHECK-LABEL: uaddv_zexti8_nxv4i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.s
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 4 x i1> %v to <vscale x 4 x i8>
  %4 = tail call i8 @llvm.vector.reduce.add.nxv4i8(<vscale x 4 x i8> %3)
  ret i8 %4
}

define i16 @uaddv_zexti16_nxv4i1(<vscale x 4 x i1> %v) {
; CHECK-LABEL: uaddv_zexti16_nxv4i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.s
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 4 x i1> %v to <vscale x 4 x i16>
  %4 = tail call i16 @llvm.vector.reduce.add.nxv4i16(<vscale x 4 x i16> %3)
  ret i16 %4
}

define i32 @uaddv_zexti32_nxv4i1(<vscale x 4 x i1> %v) {
; CHECK-LABEL: uaddv_zexti32_nxv4i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.s
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 4 x i1> %v to <vscale x 4 x i32>
  %4 = tail call i32 @llvm.vector.reduce.add.nxv4i32(<vscale x 4 x i32> %3)
  ret i32 %4
}

define i8 @uaddv_zexti8_nxv2i1(<vscale x 2 x i1> %v) {
; CHECK-LABEL: uaddv_zexti8_nxv2i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.d
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 2 x i1> %v to <vscale x 2 x i8>
  %4 = tail call i8 @llvm.vector.reduce.add.nxv2i8(<vscale x 2 x i8> %3)
  ret i8 %4
}

define i16 @uaddv_zexti16_nxv2i1(<vscale x 2 x i1> %v) {
; CHECK-LABEL: uaddv_zexti16_nxv2i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.d
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 2 x i1> %v to <vscale x 2 x i16>
  %4 = tail call i16 @llvm.vector.reduce.add.nxv2i16(<vscale x 2 x i16> %3)
  ret i16 %4
}

define i32 @uaddv_zexti32_nxv2i1(<vscale x 2 x i1> %v) {
; CHECK-LABEL: uaddv_zexti32_nxv2i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.d
; CHECK-NEXT:    // kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 2 x i1> %v to <vscale x 2 x i32>
  %4 = tail call i32 @llvm.vector.reduce.add.nxv2i32(<vscale x 2 x i32> %3)
  ret i32 %4
}

define i64 @uaddv_zexti64_nxv2i1(<vscale x 2 x i1> %v) {
; CHECK-LABEL: uaddv_zexti64_nxv2i1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    cntp x0, p0, p0.d
; CHECK-NEXT:    ret
entry:
  %3 = zext <vscale x 2 x i1> %v to <vscale x 2 x i64>
  %4 = tail call i64 @llvm.vector.reduce.add.nxv2i64(<vscale x 2 x i64> %3)
  ret i64 %4
}

declare i8 @llvm.vector.reduce.add.nxv16i8(<vscale x 16 x i8>)
declare i8 @llvm.vector.reduce.add.nxv8i8(<vscale x 8 x i8>)
declare i16 @llvm.vector.reduce.add.nxv8i16(<vscale x 8 x i16>)
declare i8 @llvm.vector.reduce.add.nxv4i8(<vscale x 4 x i8>)
declare i16 @llvm.vector.reduce.add.nxv4i16(<vscale x 4 x i16>)
declare i32 @llvm.vector.reduce.add.nxv4i32(<vscale x 4 x i32>)
declare i8 @llvm.vector.reduce.add.nxv2i8(<vscale x 2 x i8>)
declare i16 @llvm.vector.reduce.add.nxv2i16(<vscale x 2 x i16>)
declare i32 @llvm.vector.reduce.add.nxv2i32(<vscale x 2 x i32>)
declare i64 @llvm.vector.reduce.add.nxv2i64(<vscale x 2 x i64>)
