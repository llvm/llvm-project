; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=aarch64-unknown-unknown | FileCheck %s

; Test for DAGCombiner optimization: fold (xor (smin(x, C), C)) -> select (x < C), xor (x, C), 0

define i64 @test_smin_neg_one(i64 %a) {
; CHECK-LABEL: test_smin_neg_one:
; CHECK:       // %bb.0:
; CHECK-NEXT:    cmn x0, #1
; CHECK-NEXT:    csinv x0, xzr, x0, ge
; CHECK-NEXT:    ret
  %1 = tail call i64 @llvm.smin.i64(i64 %a, i64 -1)
  %retval.0 = xor i64 %1, -1
  ret i64 %retval.0
}

define i64 @test_smin_zero(i64 %a) {
; CHECK-LABEL: test_smin_zero:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x0, x0, x0, asr #63
; CHECK-NEXT:    ret
  %1 = tail call i64 @llvm.smin.i64(i64 %a, i64 0)
  %retval.0 = xor i64 %1, 0
  ret i64 %retval.0
}

define i64 @test_smin_constant(i64 %a) {
; CHECK-LABEL: test_smin_constant:
; CHECK:       // %bb.0:
; CHECK-NEXT:    eor x8, x0, #0x8
; CHECK-NEXT:    cmp x0, #8
; CHECK-NEXT:    csel x0, x8, xzr, lt
; CHECK-NEXT:    ret
  %1 = tail call i64 @llvm.smin.i64(i64 %a, i64 8)
  %retval.0 = xor i64 %1, 8
  ret i64 %retval.0
}

; Test for DAGCombiner optimization: fold (xor (smax(x, C), C)) -> select (x > C), xor (x, C), 0

define i64 @test_smax_neg_one(i64 %a) {
; CHECK-LABEL: test_smax_neg_one:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mvn x8, x0
; CHECK-NEXT:    bic x0, x8, x0, asr #63
; CHECK-NEXT:    ret
  %1 = tail call i64 @llvm.smax.i64(i64 %a, i64 -1)
  %retval.0 = xor i64 %1, -1
  ret i64 %retval.0
}

define i64 @test_smax_zero(i64 %a) {
; CHECK-LABEL: test_smax_zero:
; CHECK:       // %bb.0:
; CHECK-NEXT:    bic x0, x0, x0, asr #63
; CHECK-NEXT:    ret
  %1 = tail call i64 @llvm.smax.i64(i64 %a, i64 0)
  %retval.0 = xor i64 %1, 0
  ret i64 %retval.0
}

define i64 @test_smax_constant(i64 %a) {
; CHECK-LABEL: test_smax_constant:
; CHECK:       // %bb.0:
; CHECK-NEXT:    eor x8, x0, #0x8
; CHECK-NEXT:    cmp x0, #8
; CHECK-NEXT:    csel x0, x8, xzr, gt
; CHECK-NEXT:    ret
  %1 = tail call i64 @llvm.smax.i64(i64 %a, i64 8)
  %retval.0 = xor i64 %1, 8
  ret i64 %retval.0
}

declare i64 @llvm.smin.i64(i64, i64)
declare i64 @llvm.smax.i64(i64, i64)