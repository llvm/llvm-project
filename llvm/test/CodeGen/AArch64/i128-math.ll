; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=aarch64-- | FileCheck %s

declare { i128, i1 } @llvm.uadd.with.overflow.i128(i128, i128)
declare   i128       @llvm.uadd.sat.i128(i128, i128)

declare { i128, i1 } @llvm.usub.with.overflow.i128(i128, i128)
declare   i128       @llvm.usub.sat.i128(i128, i128)

declare { i128, i1 } @llvm.umul.with.overflow.i128(i128, i128)
declare   i128       @llvm.umul.sat.i128(i128, i128)

declare { i128, i1 } @llvm.sadd.with.overflow.i128(i128, i128)
declare   i128       @llvm.sadd.sat.i128(i128, i128)

declare { i128, i1 } @llvm.ssub.with.overflow.i128(i128, i128)
declare   i128       @llvm.ssub.sat.i128(i128, i128)

declare { i128, i1 } @llvm.smul.with.overflow.i128(i128, i128)
declare   i128       @llvm.smul.sat.i128(i128, i128)

define i128 @u128_add(i128 %x, i128 %y) {
; CHECK-LABEL: u128_add:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adds x0, x0, x2
; CHECK-NEXT:    adc x1, x1, x3
; CHECK-NEXT:    ret
  %1 = add i128 %x, %y
  ret i128 %1
}

define { i128, i8 } @u128_checked_add(i128 %x, i128 %y) {
; CHECK-LABEL: u128_checked_add:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adds x0, x0, x2
; CHECK-NEXT:    adcs x1, x1, x3
; CHECK-NEXT:    cset w8, hs
; CHECK-NEXT:    eor w2, w8, #0x1
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.uadd.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = xor i1 %3, true
  %5 = zext i1 %4 to i8
  %6 = insertvalue { i128, i8 } undef, i128 %2, 0
  %7 = insertvalue { i128, i8 } %6, i8 %5, 1
  ret { i128, i8 } %7
}

define { i128, i8 } @u128_overflowing_add(i128 %x, i128 %y) {
; CHECK-LABEL: u128_overflowing_add:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adds x0, x0, x2
; CHECK-NEXT:    adcs x1, x1, x3
; CHECK-NEXT:    cset w2, hs
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.uadd.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = zext i1 %3 to i8
  %5 = insertvalue { i128, i8 } undef, i128 %2, 0
  %6 = insertvalue { i128, i8 } %5, i8 %4, 1
  ret { i128, i8 } %6
}

define i128 @u128_saturating_add(i128 %x, i128 %y) {
; CHECK-LABEL: u128_saturating_add:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adds x8, x0, x2
; CHECK-NEXT:    adcs x9, x1, x3
; CHECK-NEXT:    csinv x0, x8, xzr, lo
; CHECK-NEXT:    csinv x1, x9, xzr, lo
; CHECK-NEXT:    ret
  %1 = tail call i128 @llvm.uadd.sat.i128(i128 %x, i128 %y)
  ret i128 %1
}

define i128 @u128_sub(i128 %x, i128 %y) {
; CHECK-LABEL: u128_sub:
; CHECK:       // %bb.0:
; CHECK-NEXT:    subs x0, x0, x2
; CHECK-NEXT:    sbc x1, x1, x3
; CHECK-NEXT:    ret
  %1 = sub i128 %x, %y
  ret i128 %1
}

define { i128, i8 } @u128_checked_sub(i128 %x, i128 %y) {
; CHECK-LABEL: u128_checked_sub:
; CHECK:       // %bb.0:
; CHECK-NEXT:    subs x0, x0, x2
; CHECK-NEXT:    sbcs x1, x1, x3
; CHECK-NEXT:    cset w8, lo
; CHECK-NEXT:    eor w2, w8, #0x1
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.usub.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = xor i1 %3, true
  %5 = zext i1 %4 to i8
  %6 = insertvalue { i128, i8 } undef, i128 %2, 0
  %7 = insertvalue { i128, i8 } %6, i8 %5, 1
  ret { i128, i8 } %7
}

define { i128, i8 } @u128_overflowing_sub(i128 %x, i128 %y) {
; CHECK-LABEL: u128_overflowing_sub:
; CHECK:       // %bb.0:
; CHECK-NEXT:    subs x0, x0, x2
; CHECK-NEXT:    sbcs x1, x1, x3
; CHECK-NEXT:    cset w2, lo
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.usub.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = zext i1 %3 to i8
  %5 = insertvalue { i128, i8 } undef, i128 %2, 0
  %6 = insertvalue { i128, i8 } %5, i8 %4, 1
  ret { i128, i8 } %6
}

define i128 @u128_saturating_sub(i128 %x, i128 %y) {
; CHECK-LABEL: u128_saturating_sub:
; CHECK:       // %bb.0:
; CHECK-NEXT:    subs x8, x0, x2
; CHECK-NEXT:    sbcs x9, x1, x3
; CHECK-NEXT:    csel x0, xzr, x8, lo
; CHECK-NEXT:    csel x1, xzr, x9, lo
; CHECK-NEXT:    ret
  %1 = tail call i128 @llvm.usub.sat.i128(i128 %x, i128 %y)
  ret i128 %1
}

define i128 @i128_add(i128 %x, i128 %y) {
; CHECK-LABEL: i128_add:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adds x0, x0, x2
; CHECK-NEXT:    adc x1, x1, x3
; CHECK-NEXT:    ret
  %1 = add i128 %x, %y
  ret i128 %1
}

define { i128, i8 } @i128_checked_add(i128 %x, i128 %y) {
; CHECK-LABEL: i128_checked_add:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adds x0, x0, x2
; CHECK-NEXT:    adcs x1, x1, x3
; CHECK-NEXT:    cset w8, vs
; CHECK-NEXT:    eor w2, w8, #0x1
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.sadd.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = xor i1 %3, true
  %5 = zext i1 %4 to i8
  %6 = insertvalue { i128, i8 } undef, i128 %2, 0
  %7 = insertvalue { i128, i8 } %6, i8 %5, 1
  ret { i128, i8 } %7
}

define { i128, i8 } @i128_overflowing_add(i128 %x, i128 %y) {
; CHECK-LABEL: i128_overflowing_add:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adds x0, x0, x2
; CHECK-NEXT:    adcs x1, x1, x3
; CHECK-NEXT:    cset w2, vs
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.sadd.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = zext i1 %3 to i8
  %5 = insertvalue { i128, i8 } undef, i128 %2, 0
  %6 = insertvalue { i128, i8 } %5, i8 %4, 1
  ret { i128, i8 } %6
}

define i128 @i128_saturating_add(i128 %x, i128 %y) {
; CHECK-LABEL: i128_saturating_add:
; CHECK:       // %bb.0:
; CHECK-NEXT:    adds x8, x0, x2
; CHECK-NEXT:    adcs x9, x1, x3
; CHECK-NEXT:    asr x10, x9, #63
; CHECK-NEXT:    eor x11, x10, #0x8000000000000000
; CHECK-NEXT:    csel x0, x10, x8, vs
; CHECK-NEXT:    csel x1, x11, x9, vs
; CHECK-NEXT:    ret
  %1 = tail call i128 @llvm.sadd.sat.i128(i128 %x, i128 %y)
  ret i128 %1
}

define i128 @i128_sub(i128 %x, i128 %y) {
; CHECK-LABEL: i128_sub:
; CHECK:       // %bb.0:
; CHECK-NEXT:    subs x0, x0, x2
; CHECK-NEXT:    sbc x1, x1, x3
; CHECK-NEXT:    ret
  %1 = sub i128 %x, %y
  ret i128 %1
}

define { i128, i8 } @i128_checked_sub(i128 %x, i128 %y) {
; CHECK-LABEL: i128_checked_sub:
; CHECK:       // %bb.0:
; CHECK-NEXT:    subs x0, x0, x2
; CHECK-NEXT:    sbcs x1, x1, x3
; CHECK-NEXT:    cset w8, vs
; CHECK-NEXT:    eor w2, w8, #0x1
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.ssub.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = xor i1 %3, true
  %5 = zext i1 %4 to i8
  %6 = insertvalue { i128, i8 } undef, i128 %2, 0
  %7 = insertvalue { i128, i8 } %6, i8 %5, 1
  ret { i128, i8 } %7
}

define { i128, i8 } @i128_overflowing_sub(i128 %x, i128 %y) {
; CHECK-LABEL: i128_overflowing_sub:
; CHECK:       // %bb.0:
; CHECK-NEXT:    subs x0, x0, x2
; CHECK-NEXT:    sbcs x1, x1, x3
; CHECK-NEXT:    cset w2, vs
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.ssub.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = zext i1 %3 to i8
  %5 = insertvalue { i128, i8 } undef, i128 %2, 0
  %6 = insertvalue { i128, i8 } %5, i8 %4, 1
  ret { i128, i8 } %6
}

define i128 @i128_saturating_sub(i128 %x, i128 %y) {
; CHECK-LABEL: i128_saturating_sub:
; CHECK:       // %bb.0:
; CHECK-NEXT:    subs x8, x0, x2
; CHECK-NEXT:    sbcs x9, x1, x3
; CHECK-NEXT:    asr x10, x9, #63
; CHECK-NEXT:    eor x11, x10, #0x8000000000000000
; CHECK-NEXT:    csel x0, x10, x8, vs
; CHECK-NEXT:    csel x1, x11, x9, vs
; CHECK-NEXT:    ret
  %1 = tail call i128 @llvm.ssub.sat.i128(i128 %x, i128 %y)
  ret i128 %1
}

define i128 @u128_mul(i128 %x, i128 %y) {
; CHECK-LABEL: u128_mul:
; CHECK:       // %bb.0:
; CHECK-NEXT:    umulh x8, x0, x2
; CHECK-NEXT:    madd x8, x0, x3, x8
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    madd x1, x1, x2, x8
; CHECK-NEXT:    ret
  %1 = mul i128 %x, %y
  ret i128 %1
}

define { i128, i8 } @u128_checked_mul(i128 %x, i128 %y) {
; CHECK-LABEL: u128_checked_mul:
; CHECK:       // %bb.0: // %overflow.entry
; CHECK-NEXT:    cbz x1, .LBB17_3
; CHECK-NEXT:  // %bb.1: // %overflow.lhs
; CHECK-NEXT:    cbz x3, .LBB17_5
; CHECK-NEXT:  // %bb.2: // %overflow
; CHECK-NEXT:    mul x9, x3, x0
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    ccmp x3, #0, #4, ne
; CHECK-NEXT:    umulh x10, x1, x2
; CHECK-NEXT:    umulh x8, x3, x0
; CHECK-NEXT:    madd x9, x1, x2, x9
; CHECK-NEXT:    ccmp xzr, x10, #0, eq
; CHECK-NEXT:    umulh x11, x0, x2
; CHECK-NEXT:    ccmp xzr, x8, #0, eq
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    cset w8, ne
; CHECK-NEXT:    adds x1, x11, x9
; CHECK-NEXT:    csinc w8, w8, wzr, lo
; CHECK-NEXT:    b .LBB17_8
; CHECK-NEXT:  .LBB17_3: // %overflow.no.lhs
; CHECK-NEXT:    umulh x8, x0, x2
; CHECK-NEXT:    cbz x3, .LBB17_7
; CHECK-NEXT:  // %bb.4: // %overflow.no.lhs.only
; CHECK-NEXT:    madd x8, x1, x2, x8
; CHECK-NEXT:    umulh x9, x0, x3
; CHECK-NEXT:    mul x10, x0, x3
; CHECK-NEXT:    mul x11, x1, x3
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    b .LBB17_6
; CHECK-NEXT:  .LBB17_5: // %overflow.no.rhs.only
; CHECK-NEXT:    umulh x8, x2, x0
; CHECK-NEXT:    umulh x9, x2, x1
; CHECK-NEXT:    madd x8, x3, x0, x8
; CHECK-NEXT:    mul x10, x2, x1
; CHECK-NEXT:    mul x11, x3, x1
; CHECK-NEXT:    mul x0, x2, x0
; CHECK-NEXT:  .LBB17_6: // %overflow.res
; CHECK-NEXT:    adds x1, x8, x10
; CHECK-NEXT:    adcs xzr, x9, x11
; CHECK-NEXT:    cset w8, ne
; CHECK-NEXT:    b .LBB17_8
; CHECK-NEXT:  .LBB17_7: // %overflow.no
; CHECK-NEXT:    madd x8, x0, x3, x8
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    madd x1, x1, x2, x8
; CHECK-NEXT:    mov w8, wzr
; CHECK-NEXT:  .LBB17_8: // %overflow.res
; CHECK-NEXT:    mov w9, #1 // =0x1
; CHECK-NEXT:    bic w2, w9, w8
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.umul.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = xor i1 %3, true
  %5 = zext i1 %4 to i8
  %6 = insertvalue { i128, i8 } undef, i128 %2, 0
  %7 = insertvalue { i128, i8 } %6, i8 %5, 1
  ret { i128, i8 } %7
}

define { i128, i8 } @u128_overflowing_mul(i128 %x, i128 %y) {
; CHECK-LABEL: u128_overflowing_mul:
; CHECK:       // %bb.0: // %overflow.entry
; CHECK-NEXT:    cbz x1, .LBB18_3
; CHECK-NEXT:  // %bb.1: // %overflow.lhs
; CHECK-NEXT:    cbz x3, .LBB18_5
; CHECK-NEXT:  // %bb.2: // %overflow
; CHECK-NEXT:    mul x9, x3, x0
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    ccmp x3, #0, #4, ne
; CHECK-NEXT:    umulh x10, x1, x2
; CHECK-NEXT:    umulh x8, x3, x0
; CHECK-NEXT:    madd x9, x1, x2, x9
; CHECK-NEXT:    ccmp xzr, x10, #0, eq
; CHECK-NEXT:    umulh x11, x0, x2
; CHECK-NEXT:    ccmp xzr, x8, #0, eq
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    cset w8, ne
; CHECK-NEXT:    adds x1, x11, x9
; CHECK-NEXT:    csinc w8, w8, wzr, lo
; CHECK-NEXT:    and w2, w8, #0x1
; CHECK-NEXT:    ret
; CHECK-NEXT:  .LBB18_3: // %overflow.no.lhs
; CHECK-NEXT:    umulh x8, x0, x2
; CHECK-NEXT:    cbz x3, .LBB18_7
; CHECK-NEXT:  // %bb.4: // %overflow.no.lhs.only
; CHECK-NEXT:    madd x8, x1, x2, x8
; CHECK-NEXT:    umulh x9, x0, x3
; CHECK-NEXT:    mul x10, x0, x3
; CHECK-NEXT:    mul x11, x1, x3
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    b .LBB18_6
; CHECK-NEXT:  .LBB18_5: // %overflow.no.rhs.only
; CHECK-NEXT:    umulh x8, x2, x0
; CHECK-NEXT:    umulh x9, x2, x1
; CHECK-NEXT:    madd x8, x3, x0, x8
; CHECK-NEXT:    mul x10, x2, x1
; CHECK-NEXT:    mul x11, x3, x1
; CHECK-NEXT:    mul x0, x2, x0
; CHECK-NEXT:  .LBB18_6: // %overflow.res
; CHECK-NEXT:    adds x1, x8, x10
; CHECK-NEXT:    adcs xzr, x9, x11
; CHECK-NEXT:    cset w8, ne
; CHECK-NEXT:    and w2, w8, #0x1
; CHECK-NEXT:    ret
; CHECK-NEXT:  .LBB18_7: // %overflow.no
; CHECK-NEXT:    madd x8, x0, x3, x8
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    madd x1, x1, x2, x8
; CHECK-NEXT:    and w2, wzr, #0x1
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.umul.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = zext i1 %3 to i8
  %5 = insertvalue { i128, i8 } undef, i128 %2, 0
  %6 = insertvalue { i128, i8 } %5, i8 %4, 1
  ret { i128, i8 } %6
}

define i128 @u128_saturating_mul(i128 %x, i128 %y) {
; CHECK-LABEL: u128_saturating_mul:
; CHECK:       // %bb.0: // %overflow.entry
; CHECK-NEXT:    cbz x1, .LBB19_3
; CHECK-NEXT:  // %bb.1: // %overflow.lhs
; CHECK-NEXT:    cbz x3, .LBB19_5
; CHECK-NEXT:  // %bb.2: // %overflow
; CHECK-NEXT:    mul x8, x3, x0
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    ccmp x3, #0, #4, ne
; CHECK-NEXT:    umulh x10, x1, x2
; CHECK-NEXT:    umulh x9, x3, x0
; CHECK-NEXT:    madd x11, x1, x2, x8
; CHECK-NEXT:    ccmp xzr, x10, #0, eq
; CHECK-NEXT:    umulh x12, x0, x2
; CHECK-NEXT:    ccmp xzr, x9, #0, eq
; CHECK-NEXT:    mul x8, x0, x2
; CHECK-NEXT:    cset w10, ne
; CHECK-NEXT:    adds x9, x12, x11
; CHECK-NEXT:    csinc w10, w10, wzr, lo
; CHECK-NEXT:    b .LBB19_8
; CHECK-NEXT:  .LBB19_3: // %overflow.no.lhs
; CHECK-NEXT:    umulh x8, x0, x2
; CHECK-NEXT:    cbz x3, .LBB19_7
; CHECK-NEXT:  // %bb.4: // %overflow.no.lhs.only
; CHECK-NEXT:    madd x9, x1, x2, x8
; CHECK-NEXT:    umulh x10, x0, x3
; CHECK-NEXT:    mul x11, x0, x3
; CHECK-NEXT:    mul x12, x1, x3
; CHECK-NEXT:    mul x8, x0, x2
; CHECK-NEXT:    b .LBB19_6
; CHECK-NEXT:  .LBB19_5: // %overflow.no.rhs.only
; CHECK-NEXT:    umulh x8, x2, x0
; CHECK-NEXT:    umulh x10, x2, x1
; CHECK-NEXT:    madd x9, x3, x0, x8
; CHECK-NEXT:    mul x11, x2, x1
; CHECK-NEXT:    mul x12, x3, x1
; CHECK-NEXT:    mul x8, x2, x0
; CHECK-NEXT:  .LBB19_6: // %overflow.res
; CHECK-NEXT:    adds x9, x9, x11
; CHECK-NEXT:    adcs xzr, x10, x12
; CHECK-NEXT:    cset w10, ne
; CHECK-NEXT:    b .LBB19_8
; CHECK-NEXT:  .LBB19_7: // %overflow.no
; CHECK-NEXT:    madd x8, x0, x3, x8
; CHECK-NEXT:    mov w10, wzr
; CHECK-NEXT:    madd x9, x1, x2, x8
; CHECK-NEXT:    mul x8, x0, x2
; CHECK-NEXT:  .LBB19_8: // %overflow.res
; CHECK-NEXT:    tst w10, #0x1
; CHECK-NEXT:    csinv x0, x8, xzr, eq
; CHECK-NEXT:    csinv x1, x9, xzr, eq
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.umul.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = select i1 %3, i128 -1, i128 %2
  ret i128 %4
}

define i128 @i128_mul(i128 %x, i128 %y) {
; CHECK-LABEL: i128_mul:
; CHECK:       // %bb.0:
; CHECK-NEXT:    umulh x8, x0, x2
; CHECK-NEXT:    madd x8, x0, x3, x8
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    madd x1, x1, x2, x8
; CHECK-NEXT:    ret
  %1 = mul i128 %x, %y
  ret i128 %1
}

define { i128, i8 } @i128_checked_mul(i128 %x, i128 %y) {
; CHECK-LABEL: i128_checked_mul:
; CHECK:       // %bb.0: // %overflow.entry
; CHECK-NEXT:    asr x8, x2, #63
; CHECK-NEXT:    cmp x1, x0, asr #63
; CHECK-NEXT:    b.eq .LBB21_3
; CHECK-NEXT:  // %bb.1: // %overflow.lhs
; CHECK-NEXT:    cmp x3, x8
; CHECK-NEXT:    b.eq .LBB21_5
; CHECK-NEXT:  // %bb.2: // %overflow
; CHECK-NEXT:    asr x9, x1, #63
; CHECK-NEXT:    umulh x10, x0, x2
; CHECK-NEXT:    asr x13, x3, #63
; CHECK-NEXT:    mul x11, x1, x2
; CHECK-NEXT:    umulh x8, x1, x2
; CHECK-NEXT:    mul x9, x9, x2
; CHECK-NEXT:    adds x10, x11, x10
; CHECK-NEXT:    mul x14, x0, x3
; CHECK-NEXT:    umulh x12, x0, x3
; CHECK-NEXT:    adc x8, x8, x9
; CHECK-NEXT:    mul x13, x0, x13
; CHECK-NEXT:    asr x11, x8, #63
; CHECK-NEXT:    adds x9, x14, x10
; CHECK-NEXT:    mul x15, x1, x3
; CHECK-NEXT:    smulh x10, x1, x3
; CHECK-NEXT:    mov x1, x9
; CHECK-NEXT:    adc x9, x12, x13
; CHECK-NEXT:    asr x12, x9, #63
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    adds x8, x8, x9
; CHECK-NEXT:    asr x9, x1, #63
; CHECK-NEXT:    adc x11, x11, x12
; CHECK-NEXT:    adds x8, x15, x8
; CHECK-NEXT:    adc x10, x10, x11
; CHECK-NEXT:    cmp x8, x9
; CHECK-NEXT:    ccmp x10, x9, #0, eq
; CHECK-NEXT:    b .LBB21_7
; CHECK-NEXT:  .LBB21_3: // %overflow.no.lhs
; CHECK-NEXT:    cmp x3, x8
; CHECK-NEXT:    b.eq .LBB21_8
; CHECK-NEXT:  // %bb.4: // %overflow.no.lhs.only
; CHECK-NEXT:    asr x8, x1, #63
; CHECK-NEXT:    asr x10, x3, #63
; CHECK-NEXT:    eor x9, x0, x8
; CHECK-NEXT:    eor x11, x1, x8
; CHECK-NEXT:    eor x12, x2, x10
; CHECK-NEXT:    subs x9, x9, x8
; CHECK-NEXT:    sbc x8, x11, x8
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    eor x11, x3, x10
; CHECK-NEXT:    csel x8, x8, x1, lt
; CHECK-NEXT:    csel x9, x9, x0, lt
; CHECK-NEXT:    cset w13, lt
; CHECK-NEXT:    subs x12, x12, x10
; CHECK-NEXT:    sbc x10, x11, x10
; CHECK-NEXT:    cmp x3, #0
; CHECK-NEXT:    csel x11, x12, x2, lt
; CHECK-NEXT:    csel x10, x10, x3, lt
; CHECK-NEXT:    umulh x12, x9, x11
; CHECK-NEXT:    mul x15, x8, x10
; CHECK-NEXT:    madd x8, x8, x11, x12
; CHECK-NEXT:    cset w12, lt
; CHECK-NEXT:    mul x14, x9, x11
; CHECK-NEXT:    mul x11, x9, x10
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    eor w10, w12, w13
; CHECK-NEXT:    b .LBB21_6
; CHECK-NEXT:  .LBB21_5: // %overflow.no.rhs.only
; CHECK-NEXT:    asr x8, x3, #63
; CHECK-NEXT:    asr x10, x1, #63
; CHECK-NEXT:    eor x9, x2, x8
; CHECK-NEXT:    eor x11, x3, x8
; CHECK-NEXT:    eor x12, x0, x10
; CHECK-NEXT:    subs x9, x9, x8
; CHECK-NEXT:    sbc x8, x11, x8
; CHECK-NEXT:    cmp x3, #0
; CHECK-NEXT:    eor x11, x1, x10
; CHECK-NEXT:    csel x8, x8, x3, lt
; CHECK-NEXT:    csel x9, x9, x2, lt
; CHECK-NEXT:    cset w13, lt
; CHECK-NEXT:    subs x12, x12, x10
; CHECK-NEXT:    sbc x10, x11, x10
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    csel x11, x12, x0, lt
; CHECK-NEXT:    csel x10, x10, x1, lt
; CHECK-NEXT:    umulh x12, x9, x11
; CHECK-NEXT:    mul x14, x9, x11
; CHECK-NEXT:    mul x15, x8, x10
; CHECK-NEXT:    madd x8, x8, x11, x12
; CHECK-NEXT:    cset w12, lt
; CHECK-NEXT:    mul x11, x9, x10
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    eor w10, w13, w12
; CHECK-NEXT:  .LBB21_6: // %overflow.res
; CHECK-NEXT:    sbfx x12, x10, #0, #1
; CHECK-NEXT:    adds x8, x8, x11
; CHECK-NEXT:    adc x9, x9, x15
; CHECK-NEXT:    eor x13, x14, x12
; CHECK-NEXT:    eor x8, x8, x12
; CHECK-NEXT:    add x0, x13, x10
; CHECK-NEXT:    cmp x0, x10
; CHECK-NEXT:    cset w10, lo
; CHECK-NEXT:    cinc x1, x8, lo
; CHECK-NEXT:    eor x8, x9, x12
; CHECK-NEXT:    cmp x1, x10
; CHECK-NEXT:    cinc x8, x8, lo
; CHECK-NEXT:    cmp x8, #0
; CHECK-NEXT:  .LBB21_7: // %overflow.res
; CHECK-NEXT:    cset w8, ne
; CHECK-NEXT:    b .LBB21_9
; CHECK-NEXT:  .LBB21_8: // %overflow.no
; CHECK-NEXT:    umulh x8, x0, x2
; CHECK-NEXT:    madd x8, x0, x3, x8
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    madd x1, x1, x2, x8
; CHECK-NEXT:    mov w8, wzr
; CHECK-NEXT:  .LBB21_9: // %overflow.res
; CHECK-NEXT:    mov w9, #1 // =0x1
; CHECK-NEXT:    bic w2, w9, w8
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.smul.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = xor i1 %3, true
  %5 = zext i1 %4 to i8
  %6 = insertvalue { i128, i8 } undef, i128 %2, 0
  %7 = insertvalue { i128, i8 } %6, i8 %5, 1
  ret { i128, i8 } %7
}

define { i128, i8 } @i128_overflowing_mul(i128 %x, i128 %y) {
; CHECK-LABEL: i128_overflowing_mul:
; CHECK:       // %bb.0: // %overflow.entry
; CHECK-NEXT:    asr x8, x2, #63
; CHECK-NEXT:    cmp x1, x0, asr #63
; CHECK-NEXT:    b.eq .LBB22_3
; CHECK-NEXT:  // %bb.1: // %overflow.lhs
; CHECK-NEXT:    cmp x3, x8
; CHECK-NEXT:    b.eq .LBB22_5
; CHECK-NEXT:  // %bb.2: // %overflow
; CHECK-NEXT:    asr x9, x1, #63
; CHECK-NEXT:    umulh x10, x0, x2
; CHECK-NEXT:    asr x13, x3, #63
; CHECK-NEXT:    mul x11, x1, x2
; CHECK-NEXT:    umulh x8, x1, x2
; CHECK-NEXT:    mul x9, x9, x2
; CHECK-NEXT:    adds x10, x11, x10
; CHECK-NEXT:    mul x14, x0, x3
; CHECK-NEXT:    umulh x12, x0, x3
; CHECK-NEXT:    adc x8, x8, x9
; CHECK-NEXT:    mul x13, x0, x13
; CHECK-NEXT:    asr x11, x8, #63
; CHECK-NEXT:    adds x9, x14, x10
; CHECK-NEXT:    mul x15, x1, x3
; CHECK-NEXT:    smulh x10, x1, x3
; CHECK-NEXT:    mov x1, x9
; CHECK-NEXT:    adc x9, x12, x13
; CHECK-NEXT:    asr x12, x9, #63
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    adds x8, x8, x9
; CHECK-NEXT:    asr x9, x1, #63
; CHECK-NEXT:    adc x11, x11, x12
; CHECK-NEXT:    adds x8, x15, x8
; CHECK-NEXT:    adc x10, x10, x11
; CHECK-NEXT:    cmp x8, x9
; CHECK-NEXT:    ccmp x10, x9, #0, eq
; CHECK-NEXT:    b .LBB22_7
; CHECK-NEXT:  .LBB22_3: // %overflow.no.lhs
; CHECK-NEXT:    cmp x3, x8
; CHECK-NEXT:    b.eq .LBB22_8
; CHECK-NEXT:  // %bb.4: // %overflow.no.lhs.only
; CHECK-NEXT:    asr x8, x1, #63
; CHECK-NEXT:    asr x10, x3, #63
; CHECK-NEXT:    eor x9, x0, x8
; CHECK-NEXT:    eor x11, x1, x8
; CHECK-NEXT:    eor x12, x2, x10
; CHECK-NEXT:    subs x9, x9, x8
; CHECK-NEXT:    sbc x8, x11, x8
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    eor x11, x3, x10
; CHECK-NEXT:    csel x8, x8, x1, lt
; CHECK-NEXT:    csel x9, x9, x0, lt
; CHECK-NEXT:    cset w13, lt
; CHECK-NEXT:    subs x12, x12, x10
; CHECK-NEXT:    sbc x10, x11, x10
; CHECK-NEXT:    cmp x3, #0
; CHECK-NEXT:    csel x11, x12, x2, lt
; CHECK-NEXT:    csel x10, x10, x3, lt
; CHECK-NEXT:    umulh x12, x9, x11
; CHECK-NEXT:    mul x15, x8, x10
; CHECK-NEXT:    madd x8, x8, x11, x12
; CHECK-NEXT:    cset w12, lt
; CHECK-NEXT:    mul x14, x9, x11
; CHECK-NEXT:    mul x11, x9, x10
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    eor w10, w12, w13
; CHECK-NEXT:    b .LBB22_6
; CHECK-NEXT:  .LBB22_5: // %overflow.no.rhs.only
; CHECK-NEXT:    asr x8, x3, #63
; CHECK-NEXT:    asr x10, x1, #63
; CHECK-NEXT:    eor x9, x2, x8
; CHECK-NEXT:    eor x11, x3, x8
; CHECK-NEXT:    eor x12, x0, x10
; CHECK-NEXT:    subs x9, x9, x8
; CHECK-NEXT:    sbc x8, x11, x8
; CHECK-NEXT:    cmp x3, #0
; CHECK-NEXT:    eor x11, x1, x10
; CHECK-NEXT:    csel x8, x8, x3, lt
; CHECK-NEXT:    csel x9, x9, x2, lt
; CHECK-NEXT:    cset w13, lt
; CHECK-NEXT:    subs x12, x12, x10
; CHECK-NEXT:    sbc x10, x11, x10
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    csel x11, x12, x0, lt
; CHECK-NEXT:    csel x10, x10, x1, lt
; CHECK-NEXT:    umulh x12, x9, x11
; CHECK-NEXT:    mul x14, x9, x11
; CHECK-NEXT:    mul x15, x8, x10
; CHECK-NEXT:    madd x8, x8, x11, x12
; CHECK-NEXT:    cset w12, lt
; CHECK-NEXT:    mul x11, x9, x10
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    eor w10, w13, w12
; CHECK-NEXT:  .LBB22_6: // %overflow.res
; CHECK-NEXT:    sbfx x12, x10, #0, #1
; CHECK-NEXT:    adds x8, x8, x11
; CHECK-NEXT:    adc x9, x9, x15
; CHECK-NEXT:    eor x13, x14, x12
; CHECK-NEXT:    eor x8, x8, x12
; CHECK-NEXT:    add x0, x13, x10
; CHECK-NEXT:    cmp x0, x10
; CHECK-NEXT:    cset w10, lo
; CHECK-NEXT:    cinc x1, x8, lo
; CHECK-NEXT:    eor x8, x9, x12
; CHECK-NEXT:    cmp x1, x10
; CHECK-NEXT:    cinc x8, x8, lo
; CHECK-NEXT:    cmp x8, #0
; CHECK-NEXT:  .LBB22_7: // %overflow.res
; CHECK-NEXT:    cset w8, ne
; CHECK-NEXT:    and w2, w8, #0x1
; CHECK-NEXT:    ret
; CHECK-NEXT:  .LBB22_8: // %overflow.no
; CHECK-NEXT:    umulh x8, x0, x2
; CHECK-NEXT:    madd x8, x0, x3, x8
; CHECK-NEXT:    mul x0, x0, x2
; CHECK-NEXT:    madd x1, x1, x2, x8
; CHECK-NEXT:    and w2, wzr, #0x1
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.smul.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = zext i1 %3 to i8
  %5 = insertvalue { i128, i8 } undef, i128 %2, 0
  %6 = insertvalue { i128, i8 } %5, i8 %4, 1
  ret { i128, i8 } %6
}

define i128 @i128_saturating_mul(i128 %x, i128 %y) {
; CHECK-LABEL: i128_saturating_mul:
; CHECK:       // %bb.0: // %overflow.entry
; CHECK-NEXT:    asr x8, x2, #63
; CHECK-NEXT:    cmp x1, x0, asr #63
; CHECK-NEXT:    b.eq .LBB23_3
; CHECK-NEXT:  // %bb.1: // %overflow.lhs
; CHECK-NEXT:    cmp x3, x8
; CHECK-NEXT:    b.eq .LBB23_5
; CHECK-NEXT:  // %bb.2: // %overflow
; CHECK-NEXT:    asr x9, x1, #63
; CHECK-NEXT:    umulh x10, x0, x2
; CHECK-NEXT:    asr x13, x3, #63
; CHECK-NEXT:    mul x11, x1, x2
; CHECK-NEXT:    umulh x8, x1, x2
; CHECK-NEXT:    mul x9, x9, x2
; CHECK-NEXT:    adds x10, x11, x10
; CHECK-NEXT:    mul x14, x0, x3
; CHECK-NEXT:    umulh x12, x0, x3
; CHECK-NEXT:    adc x8, x8, x9
; CHECK-NEXT:    mul x13, x0, x13
; CHECK-NEXT:    adds x9, x14, x10
; CHECK-NEXT:    mul x15, x1, x3
; CHECK-NEXT:    asr x14, x9, #63
; CHECK-NEXT:    smulh x10, x1, x3
; CHECK-NEXT:    adc x11, x12, x13
; CHECK-NEXT:    asr x12, x8, #63
; CHECK-NEXT:    asr x13, x11, #63
; CHECK-NEXT:    adds x11, x8, x11
; CHECK-NEXT:    mul x8, x0, x2
; CHECK-NEXT:    adc x12, x12, x13
; CHECK-NEXT:    adds x11, x15, x11
; CHECK-NEXT:    adc x10, x10, x12
; CHECK-NEXT:    cmp x11, x14
; CHECK-NEXT:    ccmp x10, x14, #0, eq
; CHECK-NEXT:    b .LBB23_7
; CHECK-NEXT:  .LBB23_3: // %overflow.no.lhs
; CHECK-NEXT:    cmp x3, x8
; CHECK-NEXT:    b.eq .LBB23_8
; CHECK-NEXT:  // %bb.4: // %overflow.no.lhs.only
; CHECK-NEXT:    asr x8, x1, #63
; CHECK-NEXT:    asr x10, x3, #63
; CHECK-NEXT:    eor x9, x0, x8
; CHECK-NEXT:    eor x11, x1, x8
; CHECK-NEXT:    eor x12, x2, x10
; CHECK-NEXT:    subs x9, x9, x8
; CHECK-NEXT:    sbc x8, x11, x8
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    eor x11, x3, x10
; CHECK-NEXT:    cset w13, lt
; CHECK-NEXT:    csel x8, x8, x1, lt
; CHECK-NEXT:    csel x9, x9, x0, lt
; CHECK-NEXT:    subs x12, x12, x10
; CHECK-NEXT:    sbc x10, x11, x10
; CHECK-NEXT:    cmp x3, #0
; CHECK-NEXT:    csel x11, x12, x2, lt
; CHECK-NEXT:    csel x10, x10, x3, lt
; CHECK-NEXT:    umulh x12, x9, x11
; CHECK-NEXT:    mul x15, x8, x10
; CHECK-NEXT:    madd x8, x8, x11, x12
; CHECK-NEXT:    cset w12, lt
; CHECK-NEXT:    mul x14, x9, x11
; CHECK-NEXT:    mul x11, x9, x10
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    eor w10, w12, w13
; CHECK-NEXT:    b .LBB23_6
; CHECK-NEXT:  .LBB23_5: // %overflow.no.rhs.only
; CHECK-NEXT:    asr x8, x3, #63
; CHECK-NEXT:    asr x10, x1, #63
; CHECK-NEXT:    eor x9, x2, x8
; CHECK-NEXT:    eor x11, x3, x8
; CHECK-NEXT:    eor x12, x0, x10
; CHECK-NEXT:    subs x9, x9, x8
; CHECK-NEXT:    sbc x8, x11, x8
; CHECK-NEXT:    cmp x3, #0
; CHECK-NEXT:    eor x11, x1, x10
; CHECK-NEXT:    cset w13, lt
; CHECK-NEXT:    csel x8, x8, x3, lt
; CHECK-NEXT:    csel x9, x9, x2, lt
; CHECK-NEXT:    subs x12, x12, x10
; CHECK-NEXT:    sbc x10, x11, x10
; CHECK-NEXT:    cmp x1, #0
; CHECK-NEXT:    csel x11, x12, x0, lt
; CHECK-NEXT:    csel x10, x10, x1, lt
; CHECK-NEXT:    umulh x12, x9, x11
; CHECK-NEXT:    mul x14, x9, x11
; CHECK-NEXT:    mul x15, x8, x10
; CHECK-NEXT:    madd x8, x8, x11, x12
; CHECK-NEXT:    cset w12, lt
; CHECK-NEXT:    mul x11, x9, x10
; CHECK-NEXT:    umulh x9, x9, x10
; CHECK-NEXT:    eor w10, w13, w12
; CHECK-NEXT:  .LBB23_6: // %overflow.res
; CHECK-NEXT:    sbfx x12, x10, #0, #1
; CHECK-NEXT:    adds x11, x8, x11
; CHECK-NEXT:    eor x13, x14, x12
; CHECK-NEXT:    add x8, x13, x10
; CHECK-NEXT:    adc x13, x9, x15
; CHECK-NEXT:    eor x9, x11, x12
; CHECK-NEXT:    cmp x8, x10
; CHECK-NEXT:    cset w10, lo
; CHECK-NEXT:    cinc x9, x9, lo
; CHECK-NEXT:    cmp x9, x10
; CHECK-NEXT:    eor x10, x13, x12
; CHECK-NEXT:    cinc x10, x10, lo
; CHECK-NEXT:    cmp x10, #0
; CHECK-NEXT:  .LBB23_7: // %overflow.res
; CHECK-NEXT:    cset w10, ne
; CHECK-NEXT:    b .LBB23_9
; CHECK-NEXT:  .LBB23_8: // %overflow.no
; CHECK-NEXT:    umulh x8, x0, x2
; CHECK-NEXT:    mov w10, wzr
; CHECK-NEXT:    madd x8, x0, x3, x8
; CHECK-NEXT:    madd x9, x1, x2, x8
; CHECK-NEXT:    mul x8, x0, x2
; CHECK-NEXT:  .LBB23_9: // %overflow.res
; CHECK-NEXT:    eor x11, x3, x1
; CHECK-NEXT:    tst w10, #0x1
; CHECK-NEXT:    asr x11, x11, #63
; CHECK-NEXT:    eor x12, x11, #0x7fffffffffffffff
; CHECK-NEXT:    csinv x0, x8, x11, eq
; CHECK-NEXT:    csel x1, x12, x9, ne
; CHECK-NEXT:    ret
  %1 = tail call { i128, i1 } @llvm.smul.with.overflow.i128(i128 %x, i128 %y)
  %2 = extractvalue { i128, i1 } %1, 0
  %3 = extractvalue { i128, i1 } %1, 1
  %4 = xor i128 %y, %x
  %5 = icmp sgt i128 %4, -1
  %6 = select i1 %5, i128 170141183460469231731687303715884105727, i128 -170141183460469231731687303715884105728
  %7 = select i1 %3, i128 %6, i128 %2
  ret i128 %7
}

define { i128, i1 } @saddo_not_1(i128 %x) nounwind {
; CHECK-LABEL: saddo_not_1:
; CHECK:       // %bb.0:
; CHECK-NEXT:    negs x0, x0
; CHECK-NEXT:    ngcs x1, x1
; CHECK-NEXT:    cset w2, vs
; CHECK-NEXT:    ret
  %not = xor i128 %x, -1
  %r = call { i128, i1 } @llvm.sadd.with.overflow.i128(i128 %not, i128 1)
  ret { i128, i1 } %r
}

define { i128, i1 } @saddo_carry_not_1(i128 %x) nounwind {
; CHECK-LABEL: saddo_carry_not_1:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov w8, #1 // =0x1
; CHECK-NEXT:    negs x0, x0
; CHECK-NEXT:    sbcs x1, x8, x1
; CHECK-NEXT:    cset w2, vs
; CHECK-NEXT:    ret
  %not = xor i128 %x, -1
  %r = call { i128, i1 } @llvm.sadd.with.overflow.i128(i128 %not, i128 u0x10000000000000001)
  ret { i128, i1 } %r
}
