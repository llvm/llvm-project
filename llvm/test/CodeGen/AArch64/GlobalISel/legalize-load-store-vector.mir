# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
# RUN: llc -O0 -mtriple=aarch64 -verify-machineinstrs -run-pass=legalizer -global-isel-abort=0 -pass-remarks-missed='gisel.*' -o - %s 2> %t.err | FileCheck %s
# RUN: FileCheck -check-prefix=ERR %s < %t.err

# ERR: remark: <unknown>:0:0: unable to legalize instruction: G_STORE %{{[0-9]+}}:_(<8 x s9>), %{{[0-9]+}}:_(p0) :: (store (<8 x s9>), align 16) (in function: store-narrow-non-byte-sized)
# ERR-NEXT: remark: <unknown>:0:0: unable to legalize instruction: %{{[0-9]+}}:_(<8 x s9>) = G_LOAD %{{[0-9]+}}:_(p0) :: (load (<8 x s9>), align 16) (in function: load-narrow-non-byte-sized)
# ERR-NEXT: remark: <unknown>:0:0: unable to legalize instruction: %{{[0-9]+}}:_(s128) = G_LOAD %{{[0-9]+}}:_(p0) :: (load (<2 x s63>)) (in function: load-narrow-scalar-high-bits)

# FIXME: Non-byte-sized vector elements cause fallback in LegalizerHelper::reduceLoadStoreWidth
---
name:            store-narrow-non-byte-sized
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x8
    ; CHECK-LABEL: name: store-narrow-non-byte-sized
    ; CHECK: liveins: $x8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x8
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s9) = G_CONSTANT i9 -256
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s9) = G_CONSTANT i9 -255
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<8 x s9>) = G_BUILD_VECTOR [[C]](s9), [[C1]](s9), [[C]](s9), [[C1]](s9), [[C]](s9), [[C1]](s9), [[C]](s9), [[C1]](s9)
    ; CHECK-NEXT: G_STORE [[BUILD_VECTOR]](<8 x s9>), [[COPY]](p0) :: (store (<8 x s9>), align 16)
    ; CHECK-NEXT: RET_ReallyLR
    %0:_(p0) = COPY $x8
    %1:_(s9) = G_CONSTANT i9 256
    %2:_(s9) = G_CONSTANT i9 257
    %3:_(<8 x s9>) = G_BUILD_VECTOR %1(s9), %2(s9), %1(s9), %2(s9), %1(s9), %2(s9), %1(s9), %2(s9)
    G_STORE %3(<8 x s9>), %0(p0) :: (store (<8 x s9>), align 16)
    RET_ReallyLR
...

# FIXME: Vector stores only sometimes act as per-lane truncating stores (see e.g. PR#121169).
---
name:            store-narrow-per-lane-trunc
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x8
    ; CHECK-LABEL: name: store-narrow-per-lane-trunc
    ; CHECK: liveins: $x8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x8
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 42
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x s64>) = G_BUILD_VECTOR [[C]](s64), [[C]](s64)
    ; CHECK-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x s64>) = G_BUILD_VECTOR [[C]](s64), [[C]](s64)
    ; CHECK-NEXT: G_STORE [[BUILD_VECTOR]](<2 x s64>), [[COPY]](p0) :: (store (<2 x s64>))
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 16
    ; CHECK-NEXT: [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C1]](s64)
    ; CHECK-NEXT: G_STORE [[BUILD_VECTOR1]](<2 x s64>), [[PTR_ADD]](p0) :: (store (<2 x s64>) into unknown-address + 16)
    ; CHECK-NEXT: RET_ReallyLR
    %0:_(p0) = COPY $x8
    %1:_(s64) = G_CONSTANT i64 42
    %2:_(<4 x s64>) = G_BUILD_VECTOR %1(s64), %1(s64), %1(s64), %1(s64)
    G_STORE %2(<4 x s64>), %0(p0) :: (store (<4 x s63>), align 16)
    RET_ReallyLR
...

# FIXME: Clarify behavior of stores between scalar and vector types in documentation. Should we consider this malformed?
---
name:            store-narrow-vector-high-bits
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x8
    ; CHECK-LABEL: name: store-narrow-vector-high-bits
    ; CHECK: liveins: $x8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x8
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 42
    ; CHECK-NEXT: [[BUILD_VECTOR:%[0-9]+]]:_(<2 x s64>) = G_BUILD_VECTOR [[C]](s64), [[C]](s64)
    ; CHECK-NEXT: [[BUILD_VECTOR1:%[0-9]+]]:_(<2 x s64>) = G_BUILD_VECTOR [[C]](s64), [[C]](s64)
    ; CHECK-NEXT: G_STORE [[BUILD_VECTOR]](<2 x s64>), [[COPY]](p0) :: (store (<2 x s64>))
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 16
    ; CHECK-NEXT: [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C1]](s64)
    ; CHECK-NEXT: G_STORE [[BUILD_VECTOR1]](<2 x s64>), [[PTR_ADD]](p0) :: (store (<2 x s64>) into unknown-address + 16)
    ; CHECK-NEXT: RET_ReallyLR
    %0:_(p0) = COPY $x8
    %1:_(s64) = G_CONSTANT i64 42
    %2:_(<4 x s64>) = G_BUILD_VECTOR %1(s64), %1(s64), %1(s64), %1(s64)
    G_STORE %2(<4 x s64>), %0(p0) :: (store (s252), align 16)
    RET_ReallyLR
...
---
name:            store-narrow-scalar-high-bits
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x8
    ; CHECK-LABEL: name: store-narrow-scalar-high-bits
    ; CHECK: liveins: $x8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x8
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 42
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; CHECK-NEXT: G_STORE [[C]](s64), [[COPY]](p0) :: (store (s64), align 16)
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s64) = G_CONSTANT i64 8
    ; CHECK-NEXT: [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C2]](s64)
    ; CHECK-NEXT: G_STORE [[C1]](s64), [[PTR_ADD]](p0) :: (store (s64) into unknown-address + 8)
    ; CHECK-NEXT: RET_ReallyLR
    %0:_(p0) = COPY $x8
    %1:_(s128) = G_CONSTANT i128 42
    G_STORE %1(s128), %0(p0) :: (store (<2 x s63>), align 16)
    RET_ReallyLR
...


# FIXME: Non-byte-sized vector elements cause fallback in LegalizerHelper::reduceLoadStoreWidth
---
name:            load-narrow-non-byte-sized
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x8
    ; CHECK-LABEL: name: load-narrow-non-byte-sized
    ; CHECK: liveins: $x8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x8
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:_(<8 x s9>) = G_LOAD [[COPY]](p0) :: (load (<8 x s9>), align 16)
    ; CHECK-NEXT: [[ZEXT:%[0-9]+]]:_(<8 x s16>) = G_ZEXT [[LOAD]](<8 x s9>)
    ; CHECK-NEXT: $q0 = COPY [[ZEXT]](<8 x s16>)
    ; CHECK-NEXT: RET_ReallyLR implicit $q0
    %0:_(p0) = COPY $x8
    %2:_(<8 x s9>) = G_LOAD %0(p0) :: (load (<8 x s9>), align 16)
    %3:_(<8 x s16>) = G_ZEXT %2(<8 x s9>)
    $q0 = COPY %3(<8 x s16>)
    RET_ReallyLR implicit $q0
...

# FIXME: Vector stores sometimes act as per-lane truncating stores (see PR#121169). If we want to keep these semantics we should change the semantics of G_LOAD to behave as a per-lane extending load.
---
name:            load-narrow-per-lane-ext
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x8
    ; CHECK-LABEL: name: load-narrow-per-lane-ext
    ; CHECK: liveins: $x8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x8
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:_(<2 x s64>) = G_LOAD [[COPY]](p0) :: (load (<2 x s64>))
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 16
    ; CHECK-NEXT: [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C]](s64)
    ; CHECK-NEXT: [[LOAD1:%[0-9]+]]:_(<2 x s64>) = G_LOAD [[PTR_ADD]](p0) :: (load (<2 x s64>) from unknown-address + 16)
    ; CHECK-NEXT: $q0 = COPY [[LOAD]](<2 x s64>)
    ; CHECK-NEXT: $q1 = COPY [[LOAD1]](<2 x s64>)
    ; CHECK-NEXT: RET_ReallyLR implicit $q0, implicit $q1
    %0:_(p0) = COPY $x8
    %2:_(<4 x s64>) = G_LOAD %0(p0) :: (load (<4 x s63>), align 16)
    %3:_(<2 x s64>), %4:_(<2 x s64>) = G_UNMERGE_VALUES %2(<4 x s64>)
    $q0 = COPY %3(<2 x s64>)
    $q1 = COPY %4(<2 x s64>)
    RET_ReallyLR implicit $q0, implicit $q1
...

# FIXME: Clarify behavior of loads between scalar and vector types in documentation. Should we consider this malformed?
---
name:            load-narrow-vector-high-bits
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x8
    ; CHECK-LABEL: name: load-narrow-vector-high-bits
    ; CHECK: liveins: $x8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x8
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:_(<2 x s64>) = G_LOAD [[COPY]](p0) :: (load (<2 x s64>))
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 16
    ; CHECK-NEXT: [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C]](s64)
    ; CHECK-NEXT: [[LOAD1:%[0-9]+]]:_(<2 x s64>) = G_LOAD [[PTR_ADD]](p0) :: (load (<2 x s64>) from unknown-address + 16)
    ; CHECK-NEXT: $q0 = COPY [[LOAD]](<2 x s64>)
    ; CHECK-NEXT: $q1 = COPY [[LOAD1]](<2 x s64>)
    ; CHECK-NEXT: RET_ReallyLR implicit $q0, implicit $q1
    %0:_(p0) = COPY $x8
    %2:_(<4 x s64>) = G_LOAD %0(p0) :: (load (s252), align 16)
    %3:_(<2 x s64>), %4:_(<2 x s64>) = G_UNMERGE_VALUES %2(<4 x s64>)
    $q0 = COPY %3(<2 x s64>)
    $q1 = COPY %4(<2 x s64>)
    RET_ReallyLR implicit $q0, implicit $q1
...
---
name:            load-narrow-scalar-high-bits
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x8
    ; CHECK-LABEL: name: load-narrow-scalar-high-bits
    ; CHECK: liveins: $x8
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(p0) = COPY $x8
    ; CHECK-NEXT: [[LOAD:%[0-9]+]]:_(s128) = G_LOAD [[COPY]](p0) :: (load (<2 x s63>))
    ; CHECK-NEXT: [[UV:%[0-9]+]]:_(s64), [[UV1:%[0-9]+]]:_(s64) = G_UNMERGE_VALUES [[LOAD]](s128)
    ; CHECK-NEXT: $x0 = COPY [[UV]](s64)
    ; CHECK-NEXT: $x1 = COPY [[UV1]](s64)
    ; CHECK-NEXT: RET_ReallyLR implicit $x0, implicit $x1
    %0:_(p0) = COPY $x8
    %2:_(s128) = G_LOAD %0(p0) :: (load (<2 x s63>), align 16)
    %3:_(s64), %4:_(s64) = G_UNMERGE_VALUES %2(s128)
    $x0 = COPY %3(s64)
    $x1 = COPY %4(s64)
    RET_ReallyLR implicit $x0, implicit $x1
...
