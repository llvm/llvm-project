# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -O0 -mtriple=arm64-unknown-unknown -global-isel -run-pass=legalizer -global-isel-abort=1 %s -o - | FileCheck %s
---
name:            test_v8s8
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $d0

    ; CHECK-LABEL: name: test_v8s8
    ; CHECK: liveins: $d0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<8 x s8>) = COPY $d0
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(<8 x s8>) = G_CTLZ [[COPY]](<8 x s8>)
    ; CHECK-NEXT: $d0 = COPY [[CTLZ]](<8 x s8>)
    ; CHECK-NEXT: RET_ReallyLR implicit $d0
    %0:_(<8 x s8>) = COPY $d0
    %1:_(<8 x s8>) = G_CTLZ %0(<8 x s8>)
    $d0 = COPY %1(<8 x s8>)
    RET_ReallyLR implicit $d0

...
---
name:            test_v4s16
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $d0

    ; CHECK-LABEL: name: test_v4s16
    ; CHECK: liveins: $d0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x s16>) = COPY $d0
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(<4 x s16>) = G_CTLZ [[COPY]](<4 x s16>)
    ; CHECK-NEXT: $d0 = COPY [[CTLZ]](<4 x s16>)
    ; CHECK-NEXT: RET_ReallyLR implicit $d0
    %0:_(<4 x s16>) = COPY $d0
    %1:_(<4 x s16>) = G_CTLZ %0(<4 x s16>)
    $d0 = COPY %1(<4 x s16>)
    RET_ReallyLR implicit $d0

...
---
name:            test_v2s32
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $d0

    ; CHECK-LABEL: name: test_v2s32
    ; CHECK: liveins: $d0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<2 x s32>) = COPY $d0
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(<2 x s32>) = G_CTLZ [[COPY]](<2 x s32>)
    ; CHECK-NEXT: $d0 = COPY [[CTLZ]](<2 x s32>)
    ; CHECK-NEXT: RET_ReallyLR implicit $d0
    %0:_(<2 x s32>) = COPY $d0
    %1:_(<2 x s32>) = G_CTLZ %0(<2 x s32>)
    $d0 = COPY %1(<2 x s32>)
    RET_ReallyLR implicit $d0

...
---
name:            test_s64
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $d0

    ; CHECK-LABEL: name: test_s64
    ; CHECK: liveins: $d0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s64) = COPY $d0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY [[COPY]](s64)
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(s64) = G_CTLZ [[COPY1]](s64)
    ; CHECK-NEXT: $d0 = COPY [[CTLZ]](s64)
    ; CHECK-NEXT: RET_ReallyLR implicit $d0
    %0:_(s64) = COPY $d0
    %2:_(s64) = COPY %0(s64)
    %1:_(s64) = G_CTLZ %2(s64)
    $d0 = COPY %1(s64)
    RET_ReallyLR implicit $d0

...
---
name:            test_s32
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $s0
    ; CHECK-LABEL: name: test_s32
    ; CHECK: liveins: $s0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY $s0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s32) = COPY [[COPY]](s32)
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(s32) = G_CTLZ [[COPY1]](s32)
    ; CHECK-NEXT: $s0 = COPY [[CTLZ]](s32)
    ; CHECK-NEXT: RET_ReallyLR implicit $s0
    %0:_(s32) = COPY $s0
    %2:_(s32) = COPY %0(s32)
    %1:_(s32) = G_CTLZ %2(s32)
    $s0 = COPY %1(s32)
    RET_ReallyLR implicit $s0

...
---
name:            test_v16s8
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $q0

    ; CHECK-LABEL: name: test_v16s8
    ; CHECK: liveins: $q0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<16 x s8>) = COPY $q0
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(<16 x s8>) = G_CTLZ [[COPY]](<16 x s8>)
    ; CHECK-NEXT: $q0 = COPY [[CTLZ]](<16 x s8>)
    ; CHECK-NEXT: RET_ReallyLR implicit $q0
    %0:_(<16 x s8>) = COPY $q0
    %1:_(<16 x s8>) = G_CTLZ %0(<16 x s8>)
    $q0 = COPY %1(<16 x s8>)
    RET_ReallyLR implicit $q0

...
---
name:            test_v8s16
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $q0

    ; CHECK-LABEL: name: test_v8s16
    ; CHECK: liveins: $q0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<8 x s16>) = COPY $q0
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(<8 x s16>) = G_CTLZ [[COPY]](<8 x s16>)
    ; CHECK-NEXT: $q0 = COPY [[CTLZ]](<8 x s16>)
    ; CHECK-NEXT: RET_ReallyLR implicit $q0
    %0:_(<8 x s16>) = COPY $q0
    %1:_(<8 x s16>) = G_CTLZ %0(<8 x s16>)
    $q0 = COPY %1(<8 x s16>)
    RET_ReallyLR implicit $q0

...
---
name:            test_v4s32
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $q0

    ; CHECK-LABEL: name: test_v4s32
    ; CHECK: liveins: $q0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(<4 x s32>) = COPY $q0
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(<4 x s32>) = G_CTLZ [[COPY]](<4 x s32>)
    ; CHECK-NEXT: $q0 = COPY [[CTLZ]](<4 x s32>)
    ; CHECK-NEXT: RET_ReallyLR implicit $q0
    %0:_(<4 x s32>) = COPY $q0
    %1:_(<4 x s32>) = G_CTLZ %0(<4 x s32>)
    $q0 = COPY %1(<4 x s32>)
    RET_ReallyLR implicit $q0

...

# The ZERO_UNDEF variants just lower into the vanilla ones.
---
name:            test_s32_zeroundef
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $s0
    ; CHECK-LABEL: name: test_s32_zeroundef
    ; CHECK: liveins: $s0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY $s0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s32) = COPY [[COPY]](s32)
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(s32) = G_CTLZ [[COPY1]](s32)
    ; CHECK-NEXT: $s0 = COPY [[CTLZ]](s32)
    ; CHECK-NEXT: RET_ReallyLR implicit $s0
    %0:_(s32) = COPY $s0
    %2:_(s32) = COPY %0(s32)
    %1:_(s32) = G_CTLZ_ZERO_UNDEF %2(s32)
    $s0 = COPY %1(s32)
    RET_ReallyLR implicit $s0

...
---
name:            test_s64_zeroundef
alignment:       4
tracksRegLiveness: true
body:             |
  bb.0:
    liveins: $d0

    ; CHECK-LABEL: name: test_s64_zeroundef
    ; CHECK: liveins: $d0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s64) = COPY $d0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY [[COPY]](s64)
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(s64) = G_CTLZ [[COPY1]](s64)
    ; CHECK-NEXT: $d0 = COPY [[CTLZ]](s64)
    ; CHECK-NEXT: RET_ReallyLR implicit $d0
    %0:_(s64) = COPY $d0
    %2:_(s64) = COPY %0(s64)
    %1:_(s64) = G_CTLZ_ZERO_UNDEF %2(s64)
    $d0 = COPY %1(s64)
    RET_ReallyLR implicit $d0

...
---
name:            test_s35
alignment:       4
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x0

    ; CHECK-LABEL: name: test_s35
    ; CHECK: liveins: $x0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s64) = COPY $x0
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 34359738367
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(s64) = G_AND [[COPY]], [[C]]
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(s64) = G_CTLZ [[AND]](s64)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 29
    ; CHECK-NEXT: [[SUB:%[0-9]+]]:_(s64) = G_SUB [[CTLZ]], [[C1]]
    ; CHECK-NEXT: $x0 = COPY [[SUB]](s64)
    ; CHECK-NEXT: RET_ReallyLR implicit $x0
    %1:_(s64) = COPY $x0
    %0:_(s35) = G_TRUNC %1(s64)
    %2:_(s35) = G_CTLZ %0(s35)
    %3:_(s64) = G_ANYEXT %2(s35)
    $x0 = COPY %3(s64)
    RET_ReallyLR implicit $x0
...
---
name:            test_s8
alignment:       4
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $w0

    ; CHECK-LABEL: name: test_s8
    ; CHECK: liveins: $w0
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s32) = COPY $w0
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 255
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(s32) = G_AND [[COPY]], [[C]]
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(s32) = G_CTLZ [[AND]](s32)
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 24
    ; CHECK-NEXT: [[SUB:%[0-9]+]]:_(s32) = G_SUB [[CTLZ]], [[C1]]
    ; CHECK-NEXT: $w0 = COPY [[SUB]](s32)
    ; CHECK-NEXT: RET_ReallyLR implicit $w0
    %1:_(s32) = COPY $w0
    %0:_(s8) = G_TRUNC %1(s32)
    %2:_(s8) = G_CTLZ %0(s8)
    %3:_(s32) = G_ANYEXT %2(s8)
    $w0 = COPY %3(s32)
    RET_ReallyLR implicit $w0
...
---
name:            test_s65
alignment:       4
tracksRegLiveness: true
body:             |
  bb.1:
    liveins: $x0, $x1

    ; CHECK-LABEL: name: test_s65
    ; CHECK: liveins: $x0, $x1
    ; CHECK-NEXT: {{  $}}
    ; CHECK-NEXT: [[COPY:%[0-9]+]]:_(s64) = COPY $x0
    ; CHECK-NEXT: [[COPY1:%[0-9]+]]:_(s64) = COPY $x1
    ; CHECK-NEXT: [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 -1
    ; CHECK-NEXT: [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
    ; CHECK-NEXT: [[AND:%[0-9]+]]:_(s64) = G_AND [[COPY]], [[C]]
    ; CHECK-NEXT: [[AND1:%[0-9]+]]:_(s64) = G_AND [[COPY1]], [[C1]]
    ; CHECK-NEXT: [[C2:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
    ; CHECK-NEXT: [[ICMP:%[0-9]+]]:_(s32) = G_ICMP intpred(eq), [[AND1]](s64), [[C2]]
    ; CHECK-NEXT: [[CTLZ:%[0-9]+]]:_(s64) = G_CTLZ [[AND]](s64)
    ; CHECK-NEXT: [[C3:%[0-9]+]]:_(s64) = G_CONSTANT i64 64
    ; CHECK-NEXT: [[UADDO:%[0-9]+]]:_(s64), [[UADDO1:%[0-9]+]]:_(s32) = G_UADDO [[CTLZ]], [[C3]]
    ; CHECK-NEXT: [[C4:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
    ; CHECK-NEXT: [[AND2:%[0-9]+]]:_(s32) = G_AND [[UADDO1]], [[C4]]
    ; CHECK-NEXT: [[UADDE:%[0-9]+]]:_(s64), [[UADDE1:%[0-9]+]]:_(s32) = G_UADDE [[C2]], [[C2]], [[AND2]]
    ; CHECK-NEXT: [[CTLZ1:%[0-9]+]]:_(s64) = G_CTLZ [[AND1]](s64)
    ; CHECK-NEXT: [[AND3:%[0-9]+]]:_(s32) = G_AND [[ICMP]], [[C4]]
    ; CHECK-NEXT: [[SELECT:%[0-9]+]]:_(s64) = G_SELECT [[AND3]](s32), [[UADDO]], [[CTLZ1]]
    ; CHECK-NEXT: [[AND4:%[0-9]+]]:_(s32) = G_AND [[ICMP]], [[C4]]
    ; CHECK-NEXT: [[SELECT1:%[0-9]+]]:_(s64) = G_SELECT [[AND4]](s32), [[UADDE]], [[C2]]
    ; CHECK-NEXT: [[C5:%[0-9]+]]:_(s64) = G_CONSTANT i64 63
    ; CHECK-NEXT: [[USUBO:%[0-9]+]]:_(s64), [[USUBO1:%[0-9]+]]:_(s32) = G_USUBO [[SELECT]], [[C5]]
    ; CHECK-NEXT: [[AND5:%[0-9]+]]:_(s32) = G_AND [[USUBO1]], [[C4]]
    ; CHECK-NEXT: [[USUBE:%[0-9]+]]:_(s64), [[USUBE1:%[0-9]+]]:_(s32) = G_USUBE [[SELECT1]], [[C2]], [[AND5]]
    ; CHECK-NEXT: $x0 = COPY [[USUBO]](s64)
    ; CHECK-NEXT: $x1 = COPY [[USUBE]](s64)
    ; CHECK-NEXT: RET_ReallyLR implicit $x0, implicit $x1
    %1:_(s64) = COPY $x0
    %2:_(s64) = COPY $x1
    %3:_(s128) = G_MERGE_VALUES %1(s64), %2(s64)
    %0:_(s65) = G_TRUNC %3(s128)
    %4:_(s65) = G_CTLZ %0(s65)
    %7:_(s128) = G_ANYEXT %4(s65)
    %5:_(s64), %6:_(s64) = G_UNMERGE_VALUES %7(s128)
    $x0 = COPY %5(s64)
    $x1 = COPY %6(s64)
    RET_ReallyLR implicit $x0, implicit $x1
...
