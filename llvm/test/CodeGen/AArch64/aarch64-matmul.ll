; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc -mtriple aarch64-none-linux-gnu -mattr=+neon,+i8mm    < %s | FileCheck %s --check-prefixes=CHECK,CHECK-SD
; RUN: llc -mtriple aarch64-none-linux-gnu -mattr=+neon,+i8mm -global-isel < %s | FileCheck %s --check-prefixes=CHECK,CHECK-GI

define <4 x i32> @smmla.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) {
; CHECK-LABEL: smmla.v4i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    smmla v0.4s, v1.16b, v2.16b
; CHECK-NEXT:    ret
entry:
  %vmmla1.i = tail call <4 x i32> @llvm.aarch64.neon.smmla.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b)
  ret <4 x i32> %vmmla1.i
}

define <4 x i32> @ummla.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) {
; CHECK-LABEL: ummla.v4i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    ummla v0.4s, v1.16b, v2.16b
; CHECK-NEXT:    ret
entry:
  %vmmla1.i = tail call <4 x i32> @llvm.aarch64.neon.ummla.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b)
  ret <4 x i32> %vmmla1.i
}

define <4 x i32> @usmmla.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) {
; CHECK-LABEL: usmmla.v4i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    usmmla v0.4s, v1.16b, v2.16b
; CHECK-NEXT:    ret
entry:
  %vusmmla1.i = tail call <4 x i32> @llvm.aarch64.neon.usmmla.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) #3
  ret <4 x i32> %vusmmla1.i
}

define <2 x i32> @usdot.v2i32.v8i8(<2 x i32> %r, <8 x i8> %a, <8 x i8> %b) {
; CHECK-LABEL: usdot.v2i32.v8i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    usdot v0.2s, v1.8b, v2.8b
; CHECK-NEXT:    ret
entry:
  %vusdot1.i = tail call <2 x i32> @llvm.aarch64.neon.usdot.v2i32.v8i8(<2 x i32> %r, <8 x i8> %a, <8 x i8> %b)
  ret <2 x i32> %vusdot1.i
}

define <2 x i32> @usdot_lane.v2i32.v8i8(<2 x i32> %r, <8 x i8> %a, <8 x i8> %b) {
; CHECK-LABEL: usdot_lane.v2i32.v8i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    // kill: def $d2 killed $d2 def $q2
; CHECK-NEXT:    usdot v0.2s, v1.8b, v2.4b[0]
; CHECK-NEXT:    ret
entry:
  %0 = bitcast <8 x i8> %b to <2 x i32>
  %shuffle = shufflevector <2 x i32> %0, <2 x i32> undef, <2 x i32> zeroinitializer
  %1 = bitcast <2 x i32> %shuffle to <8 x i8>
  %vusdot1.i = tail call <2 x i32> @llvm.aarch64.neon.usdot.v2i32.v8i8(<2 x i32> %r, <8 x i8> %a, <8 x i8> %1)
  ret <2 x i32> %vusdot1.i
}

define <2 x i32> @sudot_lane.v2i32.v8i8(<2 x i32> %r, <8 x i8> %a, <8 x i8> %b) {
; CHECK-LABEL: sudot_lane.v2i32.v8i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    // kill: def $d2 killed $d2 def $q2
; CHECK-NEXT:    sudot v0.2s, v1.8b, v2.4b[0]
; CHECK-NEXT:    ret
entry:
  %0 = bitcast <8 x i8> %b to <2 x i32>
  %shuffle = shufflevector <2 x i32> %0, <2 x i32> undef, <2 x i32> zeroinitializer
  %1 = bitcast <2 x i32> %shuffle to <8 x i8>
  %vusdot1.i = tail call <2 x i32> @llvm.aarch64.neon.usdot.v2i32.v8i8(<2 x i32> %r, <8 x i8> %1, <8 x i8> %a)
  ret <2 x i32> %vusdot1.i
}

define <2 x i32> @usdot_lane.v2i32.v16i8(<2 x i32> %r, <8 x i8> %a, <16 x i8> %b) {
; CHECK-LABEL: usdot_lane.v2i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    usdot v0.2s, v1.8b, v2.4b[0]
; CHECK-NEXT:    ret
entry:
  %0 = bitcast <16 x i8> %b to <4 x i32>
  %shuffle = shufflevector <4 x i32> %0, <4 x i32> undef, <2 x i32> zeroinitializer
  %1 = bitcast <2 x i32> %shuffle to <8 x i8>
  %vusdot1.i = tail call <2 x i32> @llvm.aarch64.neon.usdot.v2i32.v8i8(<2 x i32> %r, <8 x i8> %a, <8 x i8> %1)
  ret <2 x i32> %vusdot1.i
}

define <2 x i32> @sudot_lane.v2i32.v16i8(<2 x i32> %r, <8 x i8> %a, <16 x i8> %b) {
; CHECK-LABEL: sudot_lane.v2i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    sudot v0.2s, v1.8b, v2.4b[0]
; CHECK-NEXT:    ret
entry:
  %0 = bitcast <16 x i8> %b to <4 x i32>
  %shuffle = shufflevector <4 x i32> %0, <4 x i32> undef, <2 x i32> zeroinitializer
  %1 = bitcast <2 x i32> %shuffle to <8 x i8>
  %vusdot1.i = tail call <2 x i32> @llvm.aarch64.neon.usdot.v2i32.v8i8(<2 x i32> %r, <8 x i8> %1, <8 x i8> %a) #3
  ret <2 x i32> %vusdot1.i
}

define <4 x i32> @usdot.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) {
; CHECK-LABEL: usdot.v4i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    usdot v0.4s, v1.16b, v2.16b
; CHECK-NEXT:    ret
entry:
  %vusdot1.i = tail call <4 x i32> @llvm.aarch64.neon.usdot.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) #3
  ret <4 x i32> %vusdot1.i
}

define <4 x i32> @usdot_lane.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <8 x i8> %b) {
; CHECK-LABEL: usdot_lane.v4i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    // kill: def $d2 killed $d2 def $q2
; CHECK-NEXT:    usdot v0.4s, v1.16b, v2.4b[0]
; CHECK-NEXT:    ret
entry:
  %0 = bitcast <8 x i8> %b to <2 x i32>
  %shuffle = shufflevector <2 x i32> %0, <2 x i32> undef, <4 x i32> zeroinitializer
  %1 = bitcast <4 x i32> %shuffle to <16 x i8>
  %vusdot1.i = tail call <4 x i32> @llvm.aarch64.neon.usdot.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %1) #3
  ret <4 x i32> %vusdot1.i
}

define <4 x i32> @sudot_lane.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <8 x i8> %b) {
; CHECK-LABEL: sudot_lane.v4i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    // kill: def $d2 killed $d2 def $q2
; CHECK-NEXT:    sudot v0.4s, v1.16b, v2.4b[0]
; CHECK-NEXT:    ret
entry:
  %0 = bitcast <8 x i8> %b to <2 x i32>
  %shuffle = shufflevector <2 x i32> %0, <2 x i32> undef, <4 x i32> zeroinitializer
  %1 = bitcast <4 x i32> %shuffle to <16 x i8>
  %vusdot1.i = tail call <4 x i32> @llvm.aarch64.neon.usdot.v4i32.v16i8(<4 x i32> %r, <16 x i8> %1, <16 x i8> %a) #3
  ret <4 x i32> %vusdot1.i
}

define <4 x i32> @usdot_laneq.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) {
; CHECK-LABEL: usdot_laneq.v4i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    usdot v0.4s, v1.16b, v2.4b[0]
; CHECK-NEXT:    ret
entry:
  %0 = bitcast <16 x i8> %b to <4 x i32>
  %shuffle = shufflevector <4 x i32> %0, <4 x i32> undef, <4 x i32> zeroinitializer
  %1 = bitcast <4 x i32> %shuffle to <16 x i8>
  %vusdot1.i = tail call <4 x i32> @llvm.aarch64.neon.usdot.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %1) #3
  ret <4 x i32> %vusdot1.i
}

define <4 x i32> @sudot_laneq.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) {
; CHECK-LABEL: sudot_laneq.v4i32.v16i8:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    sudot v0.4s, v1.16b, v2.4b[0]
; CHECK-NEXT:    ret
entry:
  %0 = bitcast <16 x i8> %b to <4 x i32>
  %shuffle = shufflevector <4 x i32> %0, <4 x i32> undef, <4 x i32> zeroinitializer
  %1 = bitcast <4 x i32> %shuffle to <16 x i8>
  %vusdot1.i = tail call <4 x i32> @llvm.aarch64.neon.usdot.v4i32.v16i8(<4 x i32> %r, <16 x i8> %1, <16 x i8> %a) #3
  ret <4 x i32> %vusdot1.i
}

define <2 x i32> @usdot_add_zero.v2i32.v8i8(<2 x i32> %r, <8 x i8> %a, <8 x i8> %b) {
; CHECK-SD-LABEL: usdot_add_zero.v2i32.v8i8:
; CHECK-SD:       // %bb.0: // %entry
; CHECK-SD-NEXT:    usdot v0.2s, v1.8b, v2.8b
; CHECK-SD-NEXT:    ret
;
; CHECK-GI-LABEL: usdot_add_zero.v2i32.v8i8:
; CHECK-GI:       // %bb.0: // %entry
; CHECK-GI-NEXT:    movi v3.2d, #0000000000000000
; CHECK-GI-NEXT:    usdot v3.2s, v1.8b, v2.8b
; CHECK-GI-NEXT:    add v0.2s, v3.2s, v0.2s
; CHECK-GI-NEXT:    ret
entry:
  %x = tail call <2 x i32> @llvm.aarch64.neon.usdot.v2i32.v8i8(<2 x i32> zeroinitializer, <8 x i8> %a, <8 x i8> %b)
  %y = add <2 x i32> %x, %r
  ret <2 x i32> %y
}

define <4 x i32> @usdot_add_zero.v4i32.v16i8(<4 x i32> %r, <16 x i8> %a, <16 x i8> %b) {
; CHECK-SD-LABEL: usdot_add_zero.v4i32.v16i8:
; CHECK-SD:       // %bb.0: // %entry
; CHECK-SD-NEXT:    usdot v0.4s, v1.16b, v2.16b
; CHECK-SD-NEXT:    ret
;
; CHECK-GI-LABEL: usdot_add_zero.v4i32.v16i8:
; CHECK-GI:       // %bb.0: // %entry
; CHECK-GI-NEXT:    movi v3.2d, #0000000000000000
; CHECK-GI-NEXT:    usdot v3.4s, v1.16b, v2.16b
; CHECK-GI-NEXT:    add v0.4s, v3.4s, v0.4s
; CHECK-GI-NEXT:    ret
entry:
  %x = tail call <4 x i32> @llvm.aarch64.neon.usdot.v4i32.v16i8(<4 x i32> zeroinitializer, <16 x i8> %a, <16 x i8> %b)
  %y = add <4 x i32> %x, %r
  ret <4 x i32> %y
}

declare <4 x i32> @llvm.aarch64.neon.smmla.v4i32.v16i8(<4 x i32>, <16 x i8>, <16 x i8>) #2
declare <4 x i32> @llvm.aarch64.neon.ummla.v4i32.v16i8(<4 x i32>, <16 x i8>, <16 x i8>) #2
declare <4 x i32> @llvm.aarch64.neon.usmmla.v4i32.v16i8(<4 x i32>, <16 x i8>, <16 x i8>) #2
declare <2 x i32> @llvm.aarch64.neon.usdot.v2i32.v8i8(<2 x i32>, <8 x i8>, <8 x i8>) #2
declare <4 x i32> @llvm.aarch64.neon.usdot.v4i32.v16i8(<4 x i32>, <16 x i8>, <16 x i8>) #2
