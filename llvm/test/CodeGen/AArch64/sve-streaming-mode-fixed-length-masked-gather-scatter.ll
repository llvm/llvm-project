; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mattr=+sve < %s | FileCheck %s --check-prefix=SVE
; FIXME: We shouldn't ever be emitting any SVE instructions when +sme is set but the function is not in streaming mode.
; RUN: llc -mattr=+sme < %s | FileCheck %s --check-prefix=SME
; RUN: llc -mattr=+sve -force-streaming-compatible < %s | FileCheck %s --check-prefix=NONEON-SVE-NOGATHER
; RUN: llc -mattr=+sme -force-streaming-compatible < %s | FileCheck %s --check-prefix=NONEON-NOSVE


target triple = "aarch64-unknown-linux-gnu"

define <2 x i64> @masked_gather_v2i64(ptr %a, ptr %b) vscale_range(2, 2) {
; SVE-LABEL: masked_gather_v2i64:
; SVE:       // %bb.0:
; SVE-NEXT:    ldr q0, [x0]
; SVE-NEXT:    ptrue p0.d, vl2
; SVE-NEXT:    cmeq v0.2d, v0.2d, #0
; SVE-NEXT:    cmpne p0.d, p0/z, z0.d, #0
; SVE-NEXT:    ldr q0, [x1]
; SVE-NEXT:    ld1d { z0.d }, p0/z, [z0.d]
; SVE-NEXT:    // kill: def $q0 killed $q0 killed $z0
; SVE-NEXT:    ret
;
; SME-LABEL: masked_gather_v2i64:
; SME:       // %bb.0:
; SME-NEXT:    ldr q0, [x0]
; SME-NEXT:    adrp x8, .LCPI0_0
; SME-NEXT:    ldr q1, [x8, :lo12:.LCPI0_0]
; SME-NEXT:    cmeq v0.2d, v0.2d, #0
; SME-NEXT:    and v0.16b, v0.16b, v1.16b
; SME-NEXT:    ldr q1, [x1]
; SME-NEXT:    addp d0, v0.2d
; SME-NEXT:    fmov x8, d0
; SME-NEXT:    // implicit-def: $q0
; SME-NEXT:    tbnz w8, #0, .LBB0_3
; SME-NEXT:  // %bb.1: // %else
; SME-NEXT:    tbnz w8, #1, .LBB0_4
; SME-NEXT:  .LBB0_2: // %else2
; SME-NEXT:    ret
; SME-NEXT:  .LBB0_3: // %cond.load
; SME-NEXT:    fmov x9, d1
; SME-NEXT:    ldr d0, [x9]
; SME-NEXT:    tbz w8, #1, .LBB0_2
; SME-NEXT:  .LBB0_4: // %cond.load1
; SME-NEXT:    mov x8, v1.d[1]
; SME-NEXT:    ld1 { v0.d }[1], [x8]
; SME-NEXT:    ret
;
; NONEON-SVE-NOGATHER-LABEL: masked_gather_v2i64:
; NONEON-SVE-NOGATHER:       // %bb.0:
; NONEON-SVE-NOGATHER-NEXT:    sub sp, sp, #16
; NONEON-SVE-NOGATHER-NEXT:    .cfi_def_cfa_offset 16
; NONEON-SVE-NOGATHER-NEXT:    ptrue p0.d, vl2
; NONEON-SVE-NOGATHER-NEXT:    ldr q0, [x0]
; NONEON-SVE-NOGATHER-NEXT:    cmpeq p1.d, p0/z, z0.d, #0
; NONEON-SVE-NOGATHER-NEXT:    index z0.d, #1, #1
; NONEON-SVE-NOGATHER-NEXT:    mov z1.d, p1/z, #-1 // =0xffffffffffffffff
; NONEON-SVE-NOGATHER-NEXT:    and z0.d, z1.d, z0.d
; NONEON-SVE-NOGATHER-NEXT:    ldr q1, [x1]
; NONEON-SVE-NOGATHER-NEXT:    uaddv d0, p0, z0.d
; NONEON-SVE-NOGATHER-NEXT:    ptrue p0.d
; NONEON-SVE-NOGATHER-NEXT:    fmov x8, d0
; NONEON-SVE-NOGATHER-NEXT:    strb w8, [sp, #12]
; NONEON-SVE-NOGATHER-NEXT:    and w8, w8, #0xff
; NONEON-SVE-NOGATHER-NEXT:    tbz w8, #0, .LBB0_2
; NONEON-SVE-NOGATHER-NEXT:  // %bb.1: // %cond.load
; NONEON-SVE-NOGATHER-NEXT:    fmov x9, d1
; NONEON-SVE-NOGATHER-NEXT:    ld1rd { z0.d }, p0/z, [x9]
; NONEON-SVE-NOGATHER-NEXT:    tbnz w8, #1, .LBB0_3
; NONEON-SVE-NOGATHER-NEXT:    b .LBB0_4
; NONEON-SVE-NOGATHER-NEXT:  .LBB0_2:
; NONEON-SVE-NOGATHER-NEXT:    adrp x9, .LCPI0_0
; NONEON-SVE-NOGATHER-NEXT:    ldr q0, [x9, :lo12:.LCPI0_0]
; NONEON-SVE-NOGATHER-NEXT:    tbz w8, #1, .LBB0_4
; NONEON-SVE-NOGATHER-NEXT:  .LBB0_3: // %cond.load1
; NONEON-SVE-NOGATHER-NEXT:    mov w8, #1 // =0x1
; NONEON-SVE-NOGATHER-NEXT:    index z2.d, #0, #1
; NONEON-SVE-NOGATHER-NEXT:    mov z1.d, z1.d[1]
; NONEON-SVE-NOGATHER-NEXT:    mov z3.d, x8
; NONEON-SVE-NOGATHER-NEXT:    fmov x8, d1
; NONEON-SVE-NOGATHER-NEXT:    cmpeq p0.d, p0/z, z2.d, z3.d
; NONEON-SVE-NOGATHER-NEXT:    ldr x8, [x8]
; NONEON-SVE-NOGATHER-NEXT:    mov z0.d, p0/m, x8
; NONEON-SVE-NOGATHER-NEXT:  .LBB0_4: // %else2
; NONEON-SVE-NOGATHER-NEXT:    // kill: def $q0 killed $q0 killed $z0
; NONEON-SVE-NOGATHER-NEXT:    add sp, sp, #16
; NONEON-SVE-NOGATHER-NEXT:    ret
;
; NONEON-NOSVE-LABEL: masked_gather_v2i64:
; NONEON-NOSVE:       // %bb.0:
; NONEON-NOSVE-NEXT:    sub sp, sp, #16
; NONEON-NOSVE-NEXT:    .cfi_def_cfa_offset 16
; NONEON-NOSVE-NEXT:    ptrue p0.d, vl2
; NONEON-NOSVE-NEXT:    ldr q0, [x0]
; NONEON-NOSVE-NEXT:    cmpeq p1.d, p0/z, z0.d, #0
; NONEON-NOSVE-NEXT:    index z0.d, #1, #1
; NONEON-NOSVE-NEXT:    mov z1.d, p1/z, #-1 // =0xffffffffffffffff
; NONEON-NOSVE-NEXT:    and z0.d, z1.d, z0.d
; NONEON-NOSVE-NEXT:    ldr q1, [x1]
; NONEON-NOSVE-NEXT:    uaddv d0, p0, z0.d
; NONEON-NOSVE-NEXT:    ptrue p0.d
; NONEON-NOSVE-NEXT:    fmov x8, d0
; NONEON-NOSVE-NEXT:    strb w8, [sp, #12]
; NONEON-NOSVE-NEXT:    and w8, w8, #0xff
; NONEON-NOSVE-NEXT:    tbz w8, #0, .LBB0_2
; NONEON-NOSVE-NEXT:  // %bb.1: // %cond.load
; NONEON-NOSVE-NEXT:    fmov x9, d1
; NONEON-NOSVE-NEXT:    ld1rd { z0.d }, p0/z, [x9]
; NONEON-NOSVE-NEXT:    tbnz w8, #1, .LBB0_3
; NONEON-NOSVE-NEXT:    b .LBB0_4
; NONEON-NOSVE-NEXT:  .LBB0_2:
; NONEON-NOSVE-NEXT:    adrp x9, .LCPI0_0
; NONEON-NOSVE-NEXT:    ldr q0, [x9, :lo12:.LCPI0_0]
; NONEON-NOSVE-NEXT:    tbz w8, #1, .LBB0_4
; NONEON-NOSVE-NEXT:  .LBB0_3: // %cond.load1
; NONEON-NOSVE-NEXT:    mov w8, #1 // =0x1
; NONEON-NOSVE-NEXT:    index z2.d, #0, #1
; NONEON-NOSVE-NEXT:    mov z1.d, z1.d[1]
; NONEON-NOSVE-NEXT:    mov z3.d, x8
; NONEON-NOSVE-NEXT:    fmov x8, d1
; NONEON-NOSVE-NEXT:    cmpeq p0.d, p0/z, z2.d, z3.d
; NONEON-NOSVE-NEXT:    ldr x8, [x8]
; NONEON-NOSVE-NEXT:    mov z0.d, p0/m, x8
; NONEON-NOSVE-NEXT:  .LBB0_4: // %else2
; NONEON-NOSVE-NEXT:    // kill: def $q0 killed $q0 killed $z0
; NONEON-NOSVE-NEXT:    add sp, sp, #16
; NONEON-NOSVE-NEXT:    ret
  %vals = load <2 x i64>, ptr %a
  %ptrs = load <2 x ptr>, ptr %b
  %mask = icmp eq <2 x i64> %vals, zeroinitializer
  %res = call <2 x i64> @llvm.masked.gather.v2i64(<2 x ptr> %ptrs, i32 8, <2 x i1> %mask, <2 x i64> poison)
  ret <2 x i64> %res
}

define void @masked_scatter_v2i64(ptr %a, ptr %b) vscale_range(2, 2) {
; SVE-LABEL: masked_scatter_v2i64:
; SVE:       // %bb.0:
; SVE-NEXT:    ldr q0, [x0]
; SVE-NEXT:    ptrue p0.d, vl2
; SVE-NEXT:    cmeq v1.2d, v0.2d, #0
; SVE-NEXT:    cmpne p0.d, p0/z, z1.d, #0
; SVE-NEXT:    ldr q1, [x1]
; SVE-NEXT:    st1d { z0.d }, p0, [z1.d]
; SVE-NEXT:    ret
;
; SME-LABEL: masked_scatter_v2i64:
; SME:       // %bb.0:
; SME-NEXT:    ldr q0, [x0]
; SME-NEXT:    adrp x8, .LCPI1_0
; SME-NEXT:    ldr q2, [x8, :lo12:.LCPI1_0]
; SME-NEXT:    cmeq v1.2d, v0.2d, #0
; SME-NEXT:    and v1.16b, v1.16b, v2.16b
; SME-NEXT:    addp d2, v1.2d
; SME-NEXT:    ldr q1, [x1]
; SME-NEXT:    fmov x8, d2
; SME-NEXT:    tbnz w8, #0, .LBB1_3
; SME-NEXT:  // %bb.1: // %else
; SME-NEXT:    tbnz w8, #1, .LBB1_4
; SME-NEXT:  .LBB1_2: // %else2
; SME-NEXT:    ret
; SME-NEXT:  .LBB1_3: // %cond.store
; SME-NEXT:    fmov x9, d1
; SME-NEXT:    str d0, [x9]
; SME-NEXT:    tbz w8, #1, .LBB1_2
; SME-NEXT:  .LBB1_4: // %cond.store1
; SME-NEXT:    mov x8, v1.d[1]
; SME-NEXT:    st1 { v0.d }[1], [x8]
; SME-NEXT:    ret
;
; NONEON-SVE-NOGATHER-LABEL: masked_scatter_v2i64:
; NONEON-SVE-NOGATHER:       // %bb.0:
; NONEON-SVE-NOGATHER-NEXT:    sub sp, sp, #16
; NONEON-SVE-NOGATHER-NEXT:    .cfi_def_cfa_offset 16
; NONEON-SVE-NOGATHER-NEXT:    ptrue p0.d, vl2
; NONEON-SVE-NOGATHER-NEXT:    ldr q0, [x0]
; NONEON-SVE-NOGATHER-NEXT:    index z1.d, #1, #1
; NONEON-SVE-NOGATHER-NEXT:    cmpeq p1.d, p0/z, z0.d, #0
; NONEON-SVE-NOGATHER-NEXT:    mov z2.d, p1/z, #-1 // =0xffffffffffffffff
; NONEON-SVE-NOGATHER-NEXT:    and z1.d, z2.d, z1.d
; NONEON-SVE-NOGATHER-NEXT:    uaddv d1, p0, z1.d
; NONEON-SVE-NOGATHER-NEXT:    fmov x8, d1
; NONEON-SVE-NOGATHER-NEXT:    ldr q1, [x1]
; NONEON-SVE-NOGATHER-NEXT:    strb w8, [sp, #12]
; NONEON-SVE-NOGATHER-NEXT:    and w8, w8, #0xff
; NONEON-SVE-NOGATHER-NEXT:    tbnz w8, #0, .LBB1_3
; NONEON-SVE-NOGATHER-NEXT:  // %bb.1: // %else
; NONEON-SVE-NOGATHER-NEXT:    tbnz w8, #1, .LBB1_4
; NONEON-SVE-NOGATHER-NEXT:  .LBB1_2: // %else2
; NONEON-SVE-NOGATHER-NEXT:    add sp, sp, #16
; NONEON-SVE-NOGATHER-NEXT:    ret
; NONEON-SVE-NOGATHER-NEXT:  .LBB1_3: // %cond.store
; NONEON-SVE-NOGATHER-NEXT:    fmov x9, d0
; NONEON-SVE-NOGATHER-NEXT:    fmov x10, d1
; NONEON-SVE-NOGATHER-NEXT:    str x9, [x10]
; NONEON-SVE-NOGATHER-NEXT:    tbz w8, #1, .LBB1_2
; NONEON-SVE-NOGATHER-NEXT:  .LBB1_4: // %cond.store1
; NONEON-SVE-NOGATHER-NEXT:    mov z0.d, z0.d[1]
; NONEON-SVE-NOGATHER-NEXT:    mov z1.d, z1.d[1]
; NONEON-SVE-NOGATHER-NEXT:    fmov x8, d0
; NONEON-SVE-NOGATHER-NEXT:    fmov x9, d1
; NONEON-SVE-NOGATHER-NEXT:    str x8, [x9]
; NONEON-SVE-NOGATHER-NEXT:    add sp, sp, #16
; NONEON-SVE-NOGATHER-NEXT:    ret
;
; NONEON-NOSVE-LABEL: masked_scatter_v2i64:
; NONEON-NOSVE:       // %bb.0:
; NONEON-NOSVE-NEXT:    sub sp, sp, #16
; NONEON-NOSVE-NEXT:    .cfi_def_cfa_offset 16
; NONEON-NOSVE-NEXT:    ptrue p0.d, vl2
; NONEON-NOSVE-NEXT:    ldr q0, [x0]
; NONEON-NOSVE-NEXT:    index z1.d, #1, #1
; NONEON-NOSVE-NEXT:    cmpeq p1.d, p0/z, z0.d, #0
; NONEON-NOSVE-NEXT:    mov z2.d, p1/z, #-1 // =0xffffffffffffffff
; NONEON-NOSVE-NEXT:    and z1.d, z2.d, z1.d
; NONEON-NOSVE-NEXT:    uaddv d1, p0, z1.d
; NONEON-NOSVE-NEXT:    fmov x8, d1
; NONEON-NOSVE-NEXT:    ldr q1, [x1]
; NONEON-NOSVE-NEXT:    strb w8, [sp, #12]
; NONEON-NOSVE-NEXT:    and w8, w8, #0xff
; NONEON-NOSVE-NEXT:    tbnz w8, #0, .LBB1_3
; NONEON-NOSVE-NEXT:  // %bb.1: // %else
; NONEON-NOSVE-NEXT:    tbnz w8, #1, .LBB1_4
; NONEON-NOSVE-NEXT:  .LBB1_2: // %else2
; NONEON-NOSVE-NEXT:    add sp, sp, #16
; NONEON-NOSVE-NEXT:    ret
; NONEON-NOSVE-NEXT:  .LBB1_3: // %cond.store
; NONEON-NOSVE-NEXT:    fmov x9, d0
; NONEON-NOSVE-NEXT:    fmov x10, d1
; NONEON-NOSVE-NEXT:    str x9, [x10]
; NONEON-NOSVE-NEXT:    tbz w8, #1, .LBB1_2
; NONEON-NOSVE-NEXT:  .LBB1_4: // %cond.store1
; NONEON-NOSVE-NEXT:    mov z0.d, z0.d[1]
; NONEON-NOSVE-NEXT:    mov z1.d, z1.d[1]
; NONEON-NOSVE-NEXT:    fmov x8, d0
; NONEON-NOSVE-NEXT:    fmov x9, d1
; NONEON-NOSVE-NEXT:    str x8, [x9]
; NONEON-NOSVE-NEXT:    add sp, sp, #16
; NONEON-NOSVE-NEXT:    ret
  %vals = load <2 x i64>, ptr %a
  %ptrs = load <2 x ptr>, ptr %b
  %mask = icmp eq <2 x i64> %vals, zeroinitializer
  call void @llvm.masked.scatter.v2i64(<2 x i64> %vals, <2 x ptr> %ptrs, i32 8, <2 x i1> %mask)
  ret void
}

declare void @llvm.masked.scatter.v2i64(<2 x i64>, <2 x ptr>, i32, <2 x i1>)
declare <2 x i64> @llvm.masked.gather.v2i64(<2 x ptr>, i32, <2 x i1>, <2 x i64>)
