; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=aarch64 -mattr=+sve -verify-machineinstrs < %s | FileCheck %s

declare i64 @llvm.vscale.i64()

define i64 @vscale_exact_value() vscale_range(2, 2) {
; CHECK-LABEL: vscale_exact_value:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov w0, #2 // =0x2
; CHECK-NEXT:    ret
  %vscale = call i64 @llvm.vscale.i64()
  ret i64 %vscale
}

define i64 @vscale_mul_bounded(i64 %x) vscale_range(1, 4) {
; CHECK-LABEL: vscale_mul_bounded:
; CHECK:       // %bb.0:
; CHECK-NEXT:    cntw x0
; CHECK-NEXT:    ret
  %vscale = call i64 @llvm.vscale.i64()
  %mul = mul i64 %vscale, 4
  ret i64 %mul
}

define i64 @vscale_and_mask(i64 %x) vscale_range(1, 4) {
; CHECK-LABEL: vscale_and_mask:
; CHECK:       // %bb.0:
; CHECK-NEXT:    rdvl x8, #1
; CHECK-NEXT:    lsr x0, x8, #4
; CHECK-NEXT:    ret
  %vscale = call i64 @llvm.vscale.i64()
  %masked = and i64 %vscale, 15
  ret i64 %masked
}

define i1 @vscale_shl_known_bits(i64 %x) vscale_range(1, 4) {
; CHECK-LABEL: vscale_shl_known_bits:
; CHECK:       // %bb.0:
; CHECK-NEXT:    mov w0, #1 // =0x1
; CHECK-NEXT:    ret
  %vscale = call i64 @llvm.vscale.i64()
  %shl = shl i64 %vscale, 2
  %and = and i64 %shl, 3
  %cmp = icmp eq i64 %and, 0
  ret i1 %cmp
}
