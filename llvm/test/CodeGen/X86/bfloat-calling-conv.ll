; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -fast-isel=false -mtriple=x86_64-linux-unknown -mattr=+sse2 < %s | FileCheck -check-prefixes=SSE2 %s
; RUN: llc -fast-isel -mtriple=x86_64-linux-unknown -mattr=+sse2 < %s | FileCheck -check-prefixes=FAST_ISEL_SSE2 %s
; RUN: llc -fast-isel=false -mtriple=x86_64-linux-unknown -mattr=+avx512bf16,avx512vl < %s | FileCheck -check-prefixes=AVX512BF16 %s
; RUN: llc -fast-isel -mtriple=x86_64-linux-unknown -mattr=+avx512bf16,avx512vl < %s | FileCheck -check-prefixes=FAST_ISEL_AVX512BF16 %s
; RUN: llc -fast-isel=false -mtriple=x86_64-linux-unknown -mattr=+avxneconvert < %s | FileCheck -check-prefixes=AVXNECONVERT %s
; RUN: llc -fast-isel -mtriple=x86_64-linux-unknown -mattr=+avxneconvert < %s | FileCheck -check-prefixes=FAST_ISEL_AVXNECONVERT %s

define bfloat @return_arg_bf16(bfloat %x) #0 {
; SSE2-LABEL: return_arg_bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: return_arg_bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %rax
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movd %eax, %xmm0
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    popq %rax
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: return_arg_bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: return_arg_bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    vpextrw $0, %xmm0, %eax
; FAST_ISEL_AVX512BF16-NEXT:    shll $16, %eax
; FAST_ISEL_AVX512BF16-NEXT:    vmovd %eax, %xmm0
; FAST_ISEL_AVX512BF16-NEXT:    vcvtneps2bf16 %xmm0, %xmm0
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: return_arg_bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: return_arg_bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm0, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    shll $16, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovd %eax, %xmm0
; FAST_ISEL_AVXNECONVERT-NEXT:    {vex} vcvtneps2bf16 %xmm0, %xmm0
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  ret bfloat %x
}

define <2 x bfloat> @return_arg_v2bf16(<2 x bfloat> %x) #0 {
; SSE2-LABEL: return_arg_v2bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: return_arg_v2bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    subq $40, %rsp
; FAST_ISEL_SSE2-NEXT:    pextrw $1, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movd %eax, %xmm0
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    punpcklwd {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1],xmm1[2],xmm0[2],xmm1[3],xmm0[3]
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm1, %xmm0
; FAST_ISEL_SSE2-NEXT:    addq $40, %rsp
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: return_arg_v2bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: return_arg_v2bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: return_arg_v2bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: return_arg_v2bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  ret <2 x bfloat> %x
}

define <3 x bfloat> @return_arg_v3bf16(<3 x bfloat> %x) #0 {
; SSE2-LABEL: return_arg_v3bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: return_arg_v3bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    subq $40, %rsp
; FAST_ISEL_SSE2-NEXT:    pextrw $2, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $1, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movd %eax, %xmm0
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    punpcklwd {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1],xmm1[2],xmm0[2],xmm1[3],xmm0[3]
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    unpcklps {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; FAST_ISEL_SSE2-NEXT:    movaps %xmm1, %xmm0
; FAST_ISEL_SSE2-NEXT:    addq $40, %rsp
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: return_arg_v3bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: return_arg_v3bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    vpextrw $2, %xmm0, %eax
; FAST_ISEL_AVX512BF16-NEXT:    shll $16, %eax
; FAST_ISEL_AVX512BF16-NEXT:    vmovd %eax, %xmm1
; FAST_ISEL_AVX512BF16-NEXT:    vpextrw $1, %xmm0, %eax
; FAST_ISEL_AVX512BF16-NEXT:    shll $16, %eax
; FAST_ISEL_AVX512BF16-NEXT:    vmovd %eax, %xmm2
; FAST_ISEL_AVX512BF16-NEXT:    vmovd %xmm0, %eax
; FAST_ISEL_AVX512BF16-NEXT:    shll $16, %eax
; FAST_ISEL_AVX512BF16-NEXT:    vmovd %eax, %xmm0
; FAST_ISEL_AVX512BF16-NEXT:    vcvtneps2bf16 %xmm1, %xmm1
; FAST_ISEL_AVX512BF16-NEXT:    vmovd %xmm1, %eax
; FAST_ISEL_AVX512BF16-NEXT:    vcvtneps2bf16 %xmm0, %xmm0
; FAST_ISEL_AVX512BF16-NEXT:    vcvtneps2bf16 %xmm2, %xmm1
; FAST_ISEL_AVX512BF16-NEXT:    vpunpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; FAST_ISEL_AVX512BF16-NEXT:    vpinsrw $2, %eax, %xmm0, %xmm0
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: return_arg_v3bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: return_arg_v3bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $2, %xmm0, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    shll $16, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovd %eax, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $1, %xmm0, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    shll $16, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovd %eax, %xmm2
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovd %xmm0, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    shll $16, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovd %eax, %xmm0
; FAST_ISEL_AVXNECONVERT-NEXT:    {vex} vcvtneps2bf16 %xmm1, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovd %xmm1, %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    {vex} vcvtneps2bf16 %xmm0, %xmm0
; FAST_ISEL_AVXNECONVERT-NEXT:    {vex} vcvtneps2bf16 %xmm2, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vpunpcklwd {{.*#+}} xmm1 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; FAST_ISEL_AVXNECONVERT-NEXT:    vpinsrw $2, %eax, %xmm1, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovq %xmm1, %rax
; FAST_ISEL_AVXNECONVERT-NEXT:    movl %eax, %ecx
; FAST_ISEL_AVXNECONVERT-NEXT:    shrl $16, %ecx
; FAST_ISEL_AVXNECONVERT-NEXT:    vpinsrw $0, %ecx, %xmm0, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vpunpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; FAST_ISEL_AVXNECONVERT-NEXT:    shrq $32, %rax
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovd %eax, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vpbroadcastw %xmm1, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1],xmm1[2],xmm0[3,4,5,6,7]
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  ret <3 x bfloat> %x
}

define <4 x bfloat> @return_arg_v4bf16(<4 x bfloat> %x) #0 {
; SSE2-LABEL: return_arg_v4bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: return_arg_v4bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    subq $56, %rsp
; FAST_ISEL_SSE2-NEXT:    pextrw $3, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $2, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $1, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movd %eax, %xmm0
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    punpcklwd {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1],xmm1[2],xmm0[2],xmm1[3],xmm0[3]
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    punpcklwd {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1],xmm1[2],xmm0[2],xmm1[3],xmm0[3]
; FAST_ISEL_SSE2-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    punpckldq {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1]
; FAST_ISEL_SSE2-NEXT:    addq $56, %rsp
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: return_arg_v4bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: return_arg_v4bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: return_arg_v4bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: return_arg_v4bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  ret <4 x bfloat> %x
}

define <8 x bfloat> @return_arg_v8bf16(<8 x bfloat> %x) #0 {
; SSE2-LABEL: return_arg_v8bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: return_arg_v8bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %r14
; FAST_ISEL_SSE2-NEXT:    pushq %rbx
; FAST_ISEL_SSE2-NEXT:    subq $56, %rsp
; FAST_ISEL_SSE2-NEXT:    pextrw $7, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $6, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $5, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $4, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $3, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $2, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $1, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movd %eax, %xmm1
; FAST_ISEL_SSE2-NEXT:    movd %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm1, %xmm0
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %r14d
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %r14d
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %eax
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %eax
; FAST_ISEL_SSE2-NEXT:    shlq $32, %rax
; FAST_ISEL_SSE2-NEXT:    orq %r14, %rax
; FAST_ISEL_SSE2-NEXT:    movq %rax, %xmm0
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %r14d
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %r14d
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %eax
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %eax
; FAST_ISEL_SSE2-NEXT:    shlq $32, %rax
; FAST_ISEL_SSE2-NEXT:    orq %r14, %rax
; FAST_ISEL_SSE2-NEXT:    movq %rax, %xmm1
; FAST_ISEL_SSE2-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    punpcklqdq {{.*#+}} xmm0 = xmm0[0],xmm1[0]
; FAST_ISEL_SSE2-NEXT:    addq $56, %rsp
; FAST_ISEL_SSE2-NEXT:    popq %rbx
; FAST_ISEL_SSE2-NEXT:    popq %r14
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: return_arg_v8bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: return_arg_v8bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: return_arg_v8bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: return_arg_v8bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  ret <8 x bfloat> %x
}

define <16 x bfloat> @return_arg_v16bf16(<16 x bfloat> %x) #0 {
;
; SSE2-LABEL: return_arg_v16bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: return_arg_v16bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %r14
; FAST_ISEL_SSE2-NEXT:    pushq %rbx
; FAST_ISEL_SSE2-NEXT:    subq $104, %rsp
; FAST_ISEL_SSE2-NEXT:    pextrw $7, %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $6, %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $5, %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $4, %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $3, %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $2, %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $1, %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $7, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $6, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $5, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $4, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $3, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $2, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    pextrw $1, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movd %eax, %xmm1
; FAST_ISEL_SSE2-NEXT:    movd %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    shll $16, %eax
; FAST_ISEL_SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm1, %xmm0
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %r14d
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %r14d
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %eax
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %eax
; FAST_ISEL_SSE2-NEXT:    shlq $32, %rax
; FAST_ISEL_SSE2-NEXT:    orq %r14, %rax
; FAST_ISEL_SSE2-NEXT:    movq %rax, %xmm0
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %r14d
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %r14d
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %eax
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %eax
; FAST_ISEL_SSE2-NEXT:    shlq $32, %rax
; FAST_ISEL_SSE2-NEXT:    orq %r14, %rax
; FAST_ISEL_SSE2-NEXT:    movq %rax, %xmm0
; FAST_ISEL_SSE2-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm0[0]
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %r14d
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %r14d
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %eax
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %eax
; FAST_ISEL_SSE2-NEXT:    shlq $32, %rax
; FAST_ISEL_SSE2-NEXT:    orq %r14, %rax
; FAST_ISEL_SSE2-NEXT:    movq %rax, %xmm0
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %r14d
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %r14d
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %ebx
; FAST_ISEL_SSE2-NEXT:    shll $16, %ebx
; FAST_ISEL_SSE2-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
; FAST_ISEL_SSE2-NEXT:    # xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq __truncsfbf2@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movzwl %ax, %eax
; FAST_ISEL_SSE2-NEXT:    orl %ebx, %eax
; FAST_ISEL_SSE2-NEXT:    shlq $32, %rax
; FAST_ISEL_SSE2-NEXT:    orq %r14, %rax
; FAST_ISEL_SSE2-NEXT:    movq %rax, %xmm0
; FAST_ISEL_SSE2-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm0[0]
; FAST_ISEL_SSE2-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; FAST_ISEL_SSE2-NEXT:    addq $104, %rsp
; FAST_ISEL_SSE2-NEXT:    popq %rbx
; FAST_ISEL_SSE2-NEXT:    popq %r14
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: return_arg_v16bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: return_arg_v16bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: return_arg_v16bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: return_arg_v16bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  ret <16 x bfloat> %x
}

declare bfloat @returns_bf16(bfloat)
declare <2 x bfloat> @returns_v2bf16(<2 x bfloat>)
declare <3 x bfloat> @returns_v3bf16(<3 x bfloat>)
declare <4 x bfloat> @returns_v4bf16(<4 x bfloat>)
declare <8 x bfloat> @returns_v8bf16(<8 x bfloat>)
declare <16 x bfloat> @returns_v16bf16(<16 x bfloat>)

define void @call_ret_bf16(ptr %ptr) #0 {
;
; SSE2-LABEL: call_ret_bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    pushq %rbx
; SSE2-NEXT:    movq %rdi, %rbx
; SSE2-NEXT:    pinsrw $0, (%rdi), %xmm0
; SSE2-NEXT:    callq returns_bf16@PLT
; SSE2-NEXT:    pextrw $0, %xmm0, %eax
; SSE2-NEXT:    movw %ax, (%rbx)
; SSE2-NEXT:    popq %rbx
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: call_ret_bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %rbx
; FAST_ISEL_SSE2-NEXT:    movq %rdi, %rbx
; FAST_ISEL_SSE2-NEXT:    pinsrw $0, (%rdi), %xmm0
; FAST_ISEL_SSE2-NEXT:    callq returns_bf16@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movw %ax, (%rbx)
; FAST_ISEL_SSE2-NEXT:    popq %rbx
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: call_ret_bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    pushq %rbx
; AVX512BF16-NEXT:    movq %rdi, %rbx
; AVX512BF16-NEXT:    vpinsrw $0, (%rdi), %xmm0, %xmm0
; AVX512BF16-NEXT:    callq returns_bf16@PLT
; AVX512BF16-NEXT:    vpextrw $0, %xmm0, (%rbx)
; AVX512BF16-NEXT:    popq %rbx
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: call_ret_bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    pushq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVX512BF16-NEXT:    vpinsrw $0, (%rdi), %xmm0, %xmm0
; FAST_ISEL_AVX512BF16-NEXT:    callq returns_bf16@PLT
; FAST_ISEL_AVX512BF16-NEXT:    vpextrw $0, %xmm0, (%rbx)
; FAST_ISEL_AVX512BF16-NEXT:    popq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: call_ret_bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    pushq %rbx
; AVXNECONVERT-NEXT:    movq %rdi, %rbx
; AVXNECONVERT-NEXT:    vpinsrw $0, (%rdi), %xmm0, %xmm0
; AVXNECONVERT-NEXT:    callq returns_bf16@PLT
; AVXNECONVERT-NEXT:    vpextrw $0, %xmm0, (%rbx)
; AVXNECONVERT-NEXT:    popq %rbx
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: call_ret_bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    pushq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    vpinsrw $0, (%rdi), %xmm0, %xmm0
; FAST_ISEL_AVXNECONVERT-NEXT:    callq returns_bf16@PLT
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm0, (%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    popq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  %val = load bfloat, ptr %ptr
  %bf16 = call bfloat @returns_bf16(bfloat %val)
  store bfloat %bf16, ptr %ptr
  ret void
}

define void @call_ret_v2bf16(ptr %ptr) #0 {
;
; SSE2-LABEL: call_ret_v2bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    pushq %rbx
; SSE2-NEXT:    movq %rdi, %rbx
; SSE2-NEXT:    movd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; SSE2-NEXT:    callq returns_v2bf16@PLT
; SSE2-NEXT:    pextrw $0, %xmm0, %eax
; SSE2-NEXT:    psrld $16, %xmm0
; SSE2-NEXT:    movw %ax, (%rbx)
; SSE2-NEXT:    pextrw $0, %xmm0, %eax
; SSE2-NEXT:    movw %ax, 2(%rbx)
; SSE2-NEXT:    popq %rbx
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: call_ret_v2bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %rbx
; FAST_ISEL_SSE2-NEXT:    movq %rdi, %rbx
; FAST_ISEL_SSE2-NEXT:    movd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    callq returns_v2bf16@PLT
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    psrld $16, %xmm0
; FAST_ISEL_SSE2-NEXT:    movw %ax, (%rbx)
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movw %ax, 2(%rbx)
; FAST_ISEL_SSE2-NEXT:    popq %rbx
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: call_ret_v2bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    pushq %rbx
; AVX512BF16-NEXT:    movq %rdi, %rbx
; AVX512BF16-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; AVX512BF16-NEXT:    callq returns_v2bf16@PLT
; AVX512BF16-NEXT:    vmovss %xmm0, (%rbx)
; AVX512BF16-NEXT:    popq %rbx
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: call_ret_v2bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    pushq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVX512BF16-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_AVX512BF16-NEXT:    callq returns_v2bf16@PLT
; FAST_ISEL_AVX512BF16-NEXT:    vmovss %xmm0, (%rbx)
; FAST_ISEL_AVX512BF16-NEXT:    popq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: call_ret_v2bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    pushq %rbx
; AVXNECONVERT-NEXT:    movq %rdi, %rbx
; AVXNECONVERT-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; AVXNECONVERT-NEXT:    callq returns_v2bf16@PLT
; AVXNECONVERT-NEXT:    vpsrld $16, %xmm0, %xmm1
; AVXNECONVERT-NEXT:    vpextrw $0, %xmm0, (%rbx)
; AVXNECONVERT-NEXT:    vpextrw $0, %xmm1, 2(%rbx)
; AVXNECONVERT-NEXT:    popq %rbx
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: call_ret_v2bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    pushq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_AVXNECONVERT-NEXT:    callq returns_v2bf16@PLT
; FAST_ISEL_AVXNECONVERT-NEXT:    vpsrld $16, %xmm0, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm0, (%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm1, 2(%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    popq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  %val = load <2 x bfloat>, ptr %ptr
  %bf16 = call <2 x bfloat> @returns_v2bf16(<2 x bfloat> %val)
  store <2 x bfloat> %bf16, ptr %ptr
  ret void
}

define void @call_ret_v3bf16(ptr %ptr) #0 {
;
; SSE2-LABEL: call_ret_v3bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    pushq %rbx
; SSE2-NEXT:    movq %rdi, %rbx
; SSE2-NEXT:    movl 4(%rdi), %eax
; SSE2-NEXT:    pinsrw $0, %eax, %xmm1
; SSE2-NEXT:    movd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; SSE2-NEXT:    punpckldq {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1]
; SSE2-NEXT:    callq returns_v3bf16@PLT
; SSE2-NEXT:    movd %xmm0, (%rbx)
; SSE2-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; SSE2-NEXT:    pextrw $0, %xmm0, %eax
; SSE2-NEXT:    movw %ax, 4(%rbx)
; SSE2-NEXT:    popq %rbx
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: call_ret_v3bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %rbx
; FAST_ISEL_SSE2-NEXT:    movq %rdi, %rbx
; FAST_ISEL_SSE2-NEXT:    movl 4(%rdi), %eax
; FAST_ISEL_SSE2-NEXT:    pinsrw $0, %eax, %xmm1
; FAST_ISEL_SSE2-NEXT:    movd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; FAST_ISEL_SSE2-NEXT:    punpckldq {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1]
; FAST_ISEL_SSE2-NEXT:    callq returns_v3bf16@PLT
; FAST_ISEL_SSE2-NEXT:    movd %xmm0, (%rbx)
; FAST_ISEL_SSE2-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movw %ax, 4(%rbx)
; FAST_ISEL_SSE2-NEXT:    popq %rbx
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: call_ret_v3bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    pushq %rbx
; AVX512BF16-NEXT:    movq %rdi, %rbx
; AVX512BF16-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; AVX512BF16-NEXT:    callq returns_v3bf16@PLT
; AVX512BF16-NEXT:    vmovss %xmm0, (%rbx)
; AVX512BF16-NEXT:    vmovshdup {{.*#+}} xmm0 = xmm0[1,1,3,3]
; AVX512BF16-NEXT:    vpextrw $0, %xmm0, 4(%rbx)
; AVX512BF16-NEXT:    popq %rbx
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: call_ret_v3bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    pushq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVX512BF16-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; FAST_ISEL_AVX512BF16-NEXT:    callq returns_v3bf16@PLT
; FAST_ISEL_AVX512BF16-NEXT:    vmovss %xmm0, (%rbx)
; FAST_ISEL_AVX512BF16-NEXT:    vmovshdup {{.*#+}} xmm0 = xmm0[1,1,3,3]
; FAST_ISEL_AVX512BF16-NEXT:    vpextrw $0, %xmm0, 4(%rbx)
; FAST_ISEL_AVX512BF16-NEXT:    popq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: call_ret_v3bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    pushq %rbx
; AVXNECONVERT-NEXT:    movq %rdi, %rbx
; AVXNECONVERT-NEXT:    movl 4(%rdi), %eax
; AVXNECONVERT-NEXT:    vpinsrw $0, %eax, %xmm0, %xmm0
; AVXNECONVERT-NEXT:    vmovss {{.*#+}} xmm1 = mem[0],zero,zero,zero
; AVXNECONVERT-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0],xmm0[0],zero,zero
; AVXNECONVERT-NEXT:    callq returns_v3bf16@PLT
; AVXNECONVERT-NEXT:    vmovshdup {{.*#+}} xmm1 = xmm0[1,1,3,3]
; AVXNECONVERT-NEXT:    vmovss %xmm0, (%rbx)
; AVXNECONVERT-NEXT:    vpextrw $0, %xmm1, 4(%rbx)
; AVXNECONVERT-NEXT:    popq %rbx
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: call_ret_v3bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    pushq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    movl 4(%rdi), %eax
; FAST_ISEL_AVXNECONVERT-NEXT:    vpinsrw $0, %eax, %xmm0, %xmm0
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovss {{.*#+}} xmm1 = mem[0],zero,zero,zero
; FAST_ISEL_AVXNECONVERT-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0],xmm0[0],zero,zero
; FAST_ISEL_AVXNECONVERT-NEXT:    callq returns_v3bf16@PLT
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovshdup {{.*#+}} xmm1 = xmm0[1,1,3,3]
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovss %xmm0, (%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm1, 4(%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    popq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  %val = load <3 x bfloat>, ptr %ptr
  %bf16 = call <3 x bfloat> @returns_v3bf16(<3 x bfloat> %val)
  store <3 x bfloat> %bf16, ptr %ptr
  ret void
}

define void @call_ret_v4bf16(ptr %ptr) #0 {
;
; SSE2-LABEL: call_ret_v4bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    pushq %rbx
; SSE2-NEXT:    movq %rdi, %rbx
; SSE2-NEXT:    movq {{.*#+}} xmm0 = mem[0],zero
; SSE2-NEXT:    callq returns_v4bf16@PLT
; SSE2-NEXT:    movdqa %xmm0, %xmm1
; SSE2-NEXT:    movdqa %xmm0, %xmm2
; SSE2-NEXT:    pextrw $0, %xmm0, %eax
; SSE2-NEXT:    psrld $16, %xmm0
; SSE2-NEXT:    shufps {{.*#+}} xmm1 = xmm1[1,1,1,1]
; SSE2-NEXT:    psrlq $48, %xmm2
; SSE2-NEXT:    movw %ax, (%rbx)
; SSE2-NEXT:    pextrw $0, %xmm2, %eax
; SSE2-NEXT:    movw %ax, 6(%rbx)
; SSE2-NEXT:    pextrw $0, %xmm1, %eax
; SSE2-NEXT:    movw %ax, 4(%rbx)
; SSE2-NEXT:    pextrw $0, %xmm0, %eax
; SSE2-NEXT:    movw %ax, 2(%rbx)
; SSE2-NEXT:    popq %rbx
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: call_ret_v4bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %rbx
; FAST_ISEL_SSE2-NEXT:    movq %rdi, %rbx
; FAST_ISEL_SSE2-NEXT:    movq {{.*#+}} xmm0 = mem[0],zero
; FAST_ISEL_SSE2-NEXT:    callq returns_v4bf16@PLT
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm0, %xmm1
; FAST_ISEL_SSE2-NEXT:    movdqa %xmm0, %xmm2
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    psrld $16, %xmm0
; FAST_ISEL_SSE2-NEXT:    shufps {{.*#+}} xmm1 = xmm1[1,1,1,1]
; FAST_ISEL_SSE2-NEXT:    psrlq $48, %xmm2
; FAST_ISEL_SSE2-NEXT:    movw %ax, (%rbx)
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm2, %eax
; FAST_ISEL_SSE2-NEXT:    movw %ax, 6(%rbx)
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm1, %eax
; FAST_ISEL_SSE2-NEXT:    movw %ax, 4(%rbx)
; FAST_ISEL_SSE2-NEXT:    pextrw $0, %xmm0, %eax
; FAST_ISEL_SSE2-NEXT:    movw %ax, 2(%rbx)
; FAST_ISEL_SSE2-NEXT:    popq %rbx
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: call_ret_v4bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    pushq %rbx
; AVX512BF16-NEXT:    movq %rdi, %rbx
; AVX512BF16-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; AVX512BF16-NEXT:    callq returns_v4bf16@PLT
; AVX512BF16-NEXT:    vmovlps %xmm0, (%rbx)
; AVX512BF16-NEXT:    popq %rbx
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: call_ret_v4bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    pushq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVX512BF16-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; FAST_ISEL_AVX512BF16-NEXT:    callq returns_v4bf16@PLT
; FAST_ISEL_AVX512BF16-NEXT:    vmovlps %xmm0, (%rbx)
; FAST_ISEL_AVX512BF16-NEXT:    popq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: call_ret_v4bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    pushq %rbx
; AVXNECONVERT-NEXT:    movq %rdi, %rbx
; AVXNECONVERT-NEXT:    vmovq {{.*#+}} xmm0 = mem[0],zero
; AVXNECONVERT-NEXT:    callq returns_v4bf16@PLT
; AVXNECONVERT-NEXT:    vpsrld $16, %xmm0, %xmm1
; AVXNECONVERT-NEXT:    vmovshdup {{.*#+}} xmm2 = xmm0[1,1,3,3]
; AVXNECONVERT-NEXT:    vpsrlq $48, %xmm0, %xmm3
; AVXNECONVERT-NEXT:    vpextrw $0, %xmm0, (%rbx)
; AVXNECONVERT-NEXT:    vpextrw $0, %xmm3, 6(%rbx)
; AVXNECONVERT-NEXT:    vpextrw $0, %xmm2, 4(%rbx)
; AVXNECONVERT-NEXT:    vpextrw $0, %xmm1, 2(%rbx)
; AVXNECONVERT-NEXT:    popq %rbx
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: call_ret_v4bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    pushq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovq {{.*#+}} xmm0 = mem[0],zero
; FAST_ISEL_AVXNECONVERT-NEXT:    callq returns_v4bf16@PLT
; FAST_ISEL_AVXNECONVERT-NEXT:    vpsrld $16, %xmm0, %xmm1
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovshdup {{.*#+}} xmm2 = xmm0[1,1,3,3]
; FAST_ISEL_AVXNECONVERT-NEXT:    vpsrlq $48, %xmm0, %xmm3
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm0, (%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm3, 6(%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm2, 4(%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    vpextrw $0, %xmm1, 2(%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    popq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  %val = load <4 x bfloat>, ptr %ptr
  %bf16 = call <4 x bfloat> @returns_v4bf16(<4 x bfloat> %val)
  store <4 x bfloat> %bf16, ptr %ptr
  ret void
}

define void @call_ret_v8bf16(ptr %ptr) #0 {
;
; SSE2-LABEL: call_ret_v8bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    pushq %rbx
; SSE2-NEXT:    movq %rdi, %rbx
; SSE2-NEXT:    movaps (%rdi), %xmm0
; SSE2-NEXT:    callq returns_v8bf16@PLT
; SSE2-NEXT:    movaps %xmm0, (%rbx)
; SSE2-NEXT:    popq %rbx
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: call_ret_v8bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %rbx
; FAST_ISEL_SSE2-NEXT:    movq %rdi, %rbx
; FAST_ISEL_SSE2-NEXT:    movaps (%rdi), %xmm0
; FAST_ISEL_SSE2-NEXT:    callq returns_v8bf16@PLT
; FAST_ISEL_SSE2-NEXT:    movaps %xmm0, (%rbx)
; FAST_ISEL_SSE2-NEXT:    popq %rbx
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: call_ret_v8bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    pushq %rbx
; AVX512BF16-NEXT:    movq %rdi, %rbx
; AVX512BF16-NEXT:    vmovaps (%rdi), %xmm0
; AVX512BF16-NEXT:    callq returns_v8bf16@PLT
; AVX512BF16-NEXT:    vmovaps %xmm0, (%rbx)
; AVX512BF16-NEXT:    popq %rbx
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: call_ret_v8bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    pushq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVX512BF16-NEXT:    vmovaps (%rdi), %xmm0
; FAST_ISEL_AVX512BF16-NEXT:    callq returns_v8bf16@PLT
; FAST_ISEL_AVX512BF16-NEXT:    vmovaps %xmm0, (%rbx)
; FAST_ISEL_AVX512BF16-NEXT:    popq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: call_ret_v8bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    pushq %rbx
; AVXNECONVERT-NEXT:    movq %rdi, %rbx
; AVXNECONVERT-NEXT:    vmovaps (%rdi), %xmm0
; AVXNECONVERT-NEXT:    callq returns_v8bf16@PLT
; AVXNECONVERT-NEXT:    vmovaps %xmm0, (%rbx)
; AVXNECONVERT-NEXT:    popq %rbx
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: call_ret_v8bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    pushq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovaps (%rdi), %xmm0
; FAST_ISEL_AVXNECONVERT-NEXT:    callq returns_v8bf16@PLT
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovaps %xmm0, (%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    popq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  %val = load <8 x bfloat>, ptr %ptr
  %bf16 = call <8 x bfloat> @returns_v8bf16(<8 x bfloat> %val)
  store <8 x bfloat> %bf16, ptr %ptr
  ret void
}

define void @call_ret_v16bf16(ptr %ptr) #0 {
;
; SSE2-LABEL: call_ret_v16bf16:
; SSE2:       # %bb.0:
; SSE2-NEXT:    pushq %rbx
; SSE2-NEXT:    movq %rdi, %rbx
; SSE2-NEXT:    movaps (%rdi), %xmm0
; SSE2-NEXT:    movaps 16(%rdi), %xmm1
; SSE2-NEXT:    callq returns_v16bf16@PLT
; SSE2-NEXT:    movaps %xmm1, 16(%rbx)
; SSE2-NEXT:    movaps %xmm0, (%rbx)
; SSE2-NEXT:    popq %rbx
; SSE2-NEXT:    retq
;
; FAST_ISEL_SSE2-LABEL: call_ret_v16bf16:
; FAST_ISEL_SSE2:       # %bb.0:
; FAST_ISEL_SSE2-NEXT:    pushq %rbx
; FAST_ISEL_SSE2-NEXT:    movq %rdi, %rbx
; FAST_ISEL_SSE2-NEXT:    movaps (%rdi), %xmm0
; FAST_ISEL_SSE2-NEXT:    movaps 16(%rdi), %xmm1
; FAST_ISEL_SSE2-NEXT:    callq returns_v16bf16@PLT
; FAST_ISEL_SSE2-NEXT:    movaps %xmm1, 16(%rbx)
; FAST_ISEL_SSE2-NEXT:    movaps %xmm0, (%rbx)
; FAST_ISEL_SSE2-NEXT:    popq %rbx
; FAST_ISEL_SSE2-NEXT:    retq
;
; AVX512BF16-LABEL: call_ret_v16bf16:
; AVX512BF16:       # %bb.0:
; AVX512BF16-NEXT:    pushq %rbx
; AVX512BF16-NEXT:    movq %rdi, %rbx
; AVX512BF16-NEXT:    vmovaps (%rdi), %ymm0
; AVX512BF16-NEXT:    callq returns_v16bf16@PLT
; AVX512BF16-NEXT:    vmovaps %ymm0, (%rbx)
; AVX512BF16-NEXT:    popq %rbx
; AVX512BF16-NEXT:    vzeroupper
; AVX512BF16-NEXT:    retq
;
; FAST_ISEL_AVX512BF16-LABEL: call_ret_v16bf16:
; FAST_ISEL_AVX512BF16:       # %bb.0:
; FAST_ISEL_AVX512BF16-NEXT:    pushq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVX512BF16-NEXT:    vmovaps (%rdi), %ymm0
; FAST_ISEL_AVX512BF16-NEXT:    callq returns_v16bf16@PLT
; FAST_ISEL_AVX512BF16-NEXT:    vmovaps %ymm0, (%rbx)
; FAST_ISEL_AVX512BF16-NEXT:    popq %rbx
; FAST_ISEL_AVX512BF16-NEXT:    vzeroupper
; FAST_ISEL_AVX512BF16-NEXT:    retq
;
; AVXNECONVERT-LABEL: call_ret_v16bf16:
; AVXNECONVERT:       # %bb.0:
; AVXNECONVERT-NEXT:    pushq %rbx
; AVXNECONVERT-NEXT:    movq %rdi, %rbx
; AVXNECONVERT-NEXT:    vmovaps (%rdi), %ymm0
; AVXNECONVERT-NEXT:    callq returns_v16bf16@PLT
; AVXNECONVERT-NEXT:    vmovaps %ymm0, (%rbx)
; AVXNECONVERT-NEXT:    popq %rbx
; AVXNECONVERT-NEXT:    vzeroupper
; AVXNECONVERT-NEXT:    retq
;
; FAST_ISEL_AVXNECONVERT-LABEL: call_ret_v16bf16:
; FAST_ISEL_AVXNECONVERT:       # %bb.0:
; FAST_ISEL_AVXNECONVERT-NEXT:    pushq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    movq %rdi, %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovaps (%rdi), %ymm0
; FAST_ISEL_AVXNECONVERT-NEXT:    callq returns_v16bf16@PLT
; FAST_ISEL_AVXNECONVERT-NEXT:    vmovaps %ymm0, (%rbx)
; FAST_ISEL_AVXNECONVERT-NEXT:    popq %rbx
; FAST_ISEL_AVXNECONVERT-NEXT:    vzeroupper
; FAST_ISEL_AVXNECONVERT-NEXT:    retq
  %val = load <16 x bfloat>, ptr %ptr
  %bf16 = call <16 x bfloat> @returns_v16bf16(<16 x bfloat> %val)
  store <16 x bfloat> %bf16, ptr %ptr
  ret void
}

attributes #0 = { nounwind }
