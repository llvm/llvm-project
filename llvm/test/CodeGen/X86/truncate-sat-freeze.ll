; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx2 | FileCheck %s

; Test that freeze is eliminated for saturation truncate patterns.
; The freeze elimination happens at the IR level due to the IntrNoCreateUndefOrPoison
; attribute on the llvm.smax/smin/umin intrinsics. At the SelectionDAG level,
; TRUNCATE_SSAT_S/U and TRUNCATE_USAT_U operations are also marked in
; canCreateUndefOrPoison() to ensure consistency and enable potential future
; optimizations. This test validates the end-to-end behavior that no freeze
; instruction appears in the output.

define <2 x i32> @trunc_ssat_s_freeze(<2 x i64> %a0) {
; CHECK-LABEL: trunc_ssat_s_freeze:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpbroadcastq {{.*#+}} xmm1 = [18446744071562067968,18446744071562067968]
; CHECK-NEXT:    vpcmpgtq %xmm1, %xmm0, %xmm2
; CHECK-NEXT:    vblendvpd %xmm2, %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vpbroadcastq {{.*#+}} xmm1 = [2147483647,2147483647]
; CHECK-NEXT:    vpcmpgtq %xmm0, %xmm1, %xmm2
; CHECK-NEXT:    vblendvpd %xmm2, %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vshufps {{.*#+}} xmm0 = xmm0[0,2,2,3]
; CHECK-NEXT:    retq
  %1 = call <2 x i64> @llvm.smax.v2i64(<2 x i64> %a0, <2 x i64> <i64 -2147483648, i64 -2147483648>)
  %2 = call <2 x i64> @llvm.smin.v2i64(<2 x i64> %1, <2 x i64> <i64 2147483647, i64 2147483647>)
  %3 = trunc <2 x i64> %2 to <2 x i32>
  %4 = freeze <2 x i32> %3
  ret <2 x i32> %4
}

define <2 x i32> @trunc_ssat_u_freeze(<2 x i64> %a0) {
; CHECK-LABEL: trunc_ssat_u_freeze:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpxor %xmm1, %xmm1, %xmm1
; CHECK-NEXT:    vpcmpgtq %xmm1, %xmm0, %xmm1
; CHECK-NEXT:    vpand %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vpmovsxbd {{.*#+}} xmm1 = [4294967295,0,4294967295,0]
; CHECK-NEXT:    vpcmpgtq %xmm0, %xmm1, %xmm2
; CHECK-NEXT:    vblendvpd %xmm2, %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vshufps {{.*#+}} xmm0 = xmm0[0,2,2,3]
; CHECK-NEXT:    retq
  %1 = call <2 x i64> @llvm.smax.v2i64(<2 x i64> %a0, <2 x i64> zeroinitializer)
  %2 = call <2 x i64> @llvm.smin.v2i64(<2 x i64> %1, <2 x i64> <i64 4294967295, i64 4294967295>)
  %3 = trunc <2 x i64> %2 to <2 x i32>
  %4 = freeze <2 x i32> %3
  ret <2 x i32> %4
}

define <2 x i32> @trunc_usat_u_freeze(<2 x i64> %a0) {
; CHECK-LABEL: trunc_usat_u_freeze:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0, %xmm1
; CHECK-NEXT:    vpcmpgtq {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1, %xmm1
; CHECK-NEXT:    vblendvpd %xmm1, {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0, %xmm0
; CHECK-NEXT:    vshufps {{.*#+}} xmm0 = xmm0[0,2,2,3]
; CHECK-NEXT:    retq
  %1 = call <2 x i64> @llvm.umin.v2i64(<2 x i64> %a0, <2 x i64> <i64 4294967295, i64 4294967295>)
  %2 = trunc <2 x i64> %1 to <2 x i32>
  %3 = freeze <2 x i32> %2
  ret <2 x i32> %3
}

declare <2 x i64> @llvm.smax.v2i64(<2 x i64>, <2 x i64>)
declare <2 x i64> @llvm.smin.v2i64(<2 x i64>, <2 x i64>)
declare <2 x i64> @llvm.umin.v2i64(<2 x i64>, <2 x i64>)
