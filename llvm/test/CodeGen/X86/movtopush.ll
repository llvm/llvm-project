; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s -mtriple=i686-windows | FileCheck %s -check-prefix=NORMAL
; RUN: llc < %s -mtriple=i686-windows -no-x86-call-frame-opt | FileCheck %s -check-prefix=NOPUSH
; RUN: llc < %s -mtriple=x86_64-windows | FileCheck %s -check-prefix=X64
; RUN: llc < %s -mtriple=x86_64-uefi | FileCheck %s -check-prefix=X64
; RUN: llc < %s -mtriple=i686-pc-linux | FileCheck %s -check-prefix=LINUX

%class.Class = type { i32 }
%struct.s = type { i64 }

declare void @good(i32 %a, i32 %b, i32 %c, i32 %d)
declare void @inreg(i32 %a, i32 inreg %b, i32 %c, i32 %d)
declare x86_thiscallcc void @thiscall(ptr %class, i32 %a, i32 %b, i32 %c, i32 %d)
declare void @oneparam(i32 %a)
declare void @eightparams(i32 %a, i32 %b, i32 %c, i32 %d, i32 %e, i32 %f, i32 %g, i32 %h)
declare void @eightparams16(i16 %a, i16 %b, i16 %c, i16 %d, i16 %e, i16 %f, i16 %g, i16 %h)
declare void @eightparams64(i64 %a, i64 %b, i64 %c, i64 %d, i64 %e, i64 %f, i64 %g, i64 %h)
declare void @struct(ptr byval(%struct.s) %a, i32 %b, i32 %c, i32 %d)
declare void @inalloca(ptr inalloca(<{ %struct.s }>))

declare ptr @llvm.stacksave()
declare void @llvm.stackrestore(ptr)

; We should get pushes for x86, even though there is a reserved call frame.
; Make sure we don't touch x86-64, and that turning it off works.
define void @test1() {
; NORMAL-LABEL: test1:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test1:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    addl $16, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test1:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $40, %rsp
; X64-NEXT:    .seh_stackalloc 40
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl $1, %ecx
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $40, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test1:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
entry:
  call void @good(i32 1, i32 2, i32 3, i32 4)
  ret void
}

; If we have a reserved frame, we should have pushes
define void @test2(i32 %k) {
; NORMAL-LABEL: test2:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    pushl %ebp
; NORMAL-NEXT:    movl %esp, %ebp
; NORMAL-NEXT:    movl 8(%ebp), %eax
; NORMAL-NEXT:    shll $2, %eax
; NORMAL-NEXT:    calll __chkstk
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    movl %ebp, %esp
; NORMAL-NEXT:    popl %ebp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test2:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    pushl %ebp
; NOPUSH-NEXT:    movl %esp, %ebp
; NOPUSH-NEXT:    movl 8(%ebp), %eax
; NOPUSH-NEXT:    shll $2, %eax
; NOPUSH-NEXT:    calll __chkstk
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    movl %ebp, %esp
; NOPUSH-NEXT:    popl %ebp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test2:
; X64:       # %bb.0: # %entry
; X64-NEXT:    pushq %rbp
; X64-NEXT:    .seh_pushreg %rbp
; X64-NEXT:    movq %rsp, %rbp
; X64-NEXT:    .seh_setframe %rbp, 0
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl %ecx, %eax
; X64-NEXT:    leaq 15(,%rax,4), %rax
; X64-NEXT:    andq $-16, %rax
; X64-NEXT:    callq __chkstk
; X64-NEXT:    subq %rax, %rsp
; X64-NEXT:    subq $32, %rsp
; X64-NEXT:    movl $1, %ecx
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    movq %rbp, %rsp
; X64-NEXT:    popq %rbp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test2:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    pushl %ebp
; LINUX-NEXT:    .cfi_def_cfa_offset 8
; LINUX-NEXT:    .cfi_offset %ebp, -8
; LINUX-NEXT:    movl %esp, %ebp
; LINUX-NEXT:    .cfi_def_cfa_register %ebp
; LINUX-NEXT:    subl $8, %esp
; LINUX-NEXT:    movl 8(%ebp), %eax
; LINUX-NEXT:    movl %esp, %ecx
; LINUX-NEXT:    leal 15(,%eax,4), %eax
; LINUX-NEXT:    andl $-16, %eax
; LINUX-NEXT:    subl %eax, %ecx
; LINUX-NEXT:    movl %ecx, %esp
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    movl %ebp, %esp
; LINUX-NEXT:    popl %ebp
; LINUX-NEXT:    .cfi_def_cfa %esp, 4
; LINUX-NEXT:    retl
entry:
  %a = alloca i32, i32 %k
  call void @good(i32 1, i32 2, i32 3, i32 4)
  ret void
}

; Again, we expect a sequence of 4 immediate pushes
; Checks that we generate the right pushes for >8bit immediates
define void @test2b() optsize {
; NORMAL-LABEL: test2b:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    pushl $4096 # imm = 0x1000
; NORMAL-NEXT:    pushl $3072 # imm = 0xC00
; NORMAL-NEXT:    pushl $2048 # imm = 0x800
; NORMAL-NEXT:    pushl $1024 # imm = 0x400
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test2b:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl $4096, {{[0-9]+}}(%esp) # imm = 0x1000
; NOPUSH-NEXT:    movl $3072, {{[0-9]+}}(%esp) # imm = 0xC00
; NOPUSH-NEXT:    movl $2048, {{[0-9]+}}(%esp) # imm = 0x800
; NOPUSH-NEXT:    movl $1024, (%esp) # imm = 0x400
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    addl $16, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test2b:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $40, %rsp
; X64-NEXT:    .seh_stackalloc 40
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl $1024, %ecx # imm = 0x400
; X64-NEXT:    movl $2048, %edx # imm = 0x800
; X64-NEXT:    movl $3072, %r8d # imm = 0xC00
; X64-NEXT:    movl $4096, %r9d # imm = 0x1000
; X64-NEXT:    callq good
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $40, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test2b:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    pushl $4096 # imm = 0x1000
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3072 # imm = 0xC00
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2048 # imm = 0x800
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1024 # imm = 0x400
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
entry:
  call void @good(i32 1024, i32 2048, i32 3072, i32 4096)
  ret void
}

; The first push should push a register
define void @test3(i32 %k) optsize {
; NORMAL-LABEL: test3:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NORMAL-NEXT:    incl %eax
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test3:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    incl %eax
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    addl $16, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test3:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $40, %rsp
; X64-NEXT:    .seh_stackalloc 40
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    incl %ecx
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $40, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test3:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    incl %eax
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
entry:
  %f = add i32 %k, 1
  call void @good(i32 %f, i32 2, i32 3, i32 4)
  ret void
}

; We support weird calling conventions
define void @test4() optsize {
; NORMAL-LABEL: test4:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    movl $2, %eax
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _inreg
; NORMAL-NEXT:    addl $12, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test4:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $12, %esp
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    movl $2, %eax
; NOPUSH-NEXT:    calll _inreg
; NOPUSH-NEXT:    addl $12, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test4:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $40, %rsp
; X64-NEXT:    .seh_stackalloc 40
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl $1, %ecx
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq inreg
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $40, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test4:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $16, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset 16
; LINUX-NEXT:    movl $2, %eax
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll inreg@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
entry:
  call void @inreg(i32 1, i32 inreg 2, i32 3, i32 4)
  ret void
}

define void @test4b(ptr %f) optsize {
; NORMAL-LABEL: test4b:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _thiscall
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test4b:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll _thiscall
; NOPUSH-NEXT:    retl
;
; LINUX-LABEL: test4b:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll thiscall@PLT
; LINUX-NEXT:    .cfi_adjust_cfa_offset -16
; LINUX-NEXT:    addl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 4
; LINUX-NEXT:    retl
entry:
  call x86_thiscallcc void @thiscall(ptr %f, i32 1, i32 2, i32 3, i32 4)
  ret void
}

; Check that pushing the addresses of globals (Or generally, things that
; aren't exactly immediates) isn't broken.
; Fixes PR21878.
declare void @f(ptr)
@ext = external dso_local constant i8

define void @test6() {
; NORMAL-LABEL: test6:
; NORMAL:       # %bb.0:
; NORMAL-NEXT:    pushl %ebp
; NORMAL-NEXT:    movl %esp, %ebp
; NORMAL-NEXT:    pushl $_ext
; NORMAL-NEXT:    calll _f
; NORMAL-NEXT:    addl $4, %esp
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    movl %ebp, %esp
; NORMAL-NEXT:    popl %ebp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test6:
; NOPUSH:       # %bb.0:
; NOPUSH-NEXT:    pushl %ebp
; NOPUSH-NEXT:    movl %esp, %ebp
; NOPUSH-NEXT:    subl $4, %esp
; NOPUSH-NEXT:    movl $_ext, (%esp)
; NOPUSH-NEXT:    calll _f
; NOPUSH-NEXT:    addl $4, %esp
; NOPUSH-NEXT:    pushl %eax
; NOPUSH-NEXT:    movl %ebp, %esp
; NOPUSH-NEXT:    popl %ebp
; NOPUSH-NEXT:    retl
;
; LINUX-LABEL: test6:
; LINUX:       # %bb.0:
; LINUX-NEXT:    pushl %ebp
; LINUX-NEXT:    .cfi_def_cfa_offset 8
; LINUX-NEXT:    .cfi_offset %ebp, -8
; LINUX-NEXT:    movl %esp, %ebp
; LINUX-NEXT:    .cfi_def_cfa_register %ebp
; LINUX-NEXT:    subl $8, %esp
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    pushl $ext
; LINUX-NEXT:    calll f@PLT
; LINUX-NEXT:    addl $16, %esp
; LINUX-NEXT:    movl %esp, %eax
; LINUX-NEXT:    addl $-16, %eax
; LINUX-NEXT:    movl %eax, %esp
; LINUX-NEXT:    movl %ebp, %esp
; LINUX-NEXT:    popl %ebp
; LINUX-NEXT:    .cfi_def_cfa %esp, 4
; LINUX-NEXT:    retl
  call void @f(ptr @ext)
  br label %bb
bb:
  alloca i32
  ret void
}

; Check that we fold simple cases into the push
define void @test7(ptr %ptr) optsize {
; NORMAL-LABEL: test7:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl (%eax)
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test7:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl (%eax), %eax
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    addl $16, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test7:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $40, %rsp
; X64-NEXT:    .seh_stackalloc 40
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl (%rcx), %r8d
; X64-NEXT:    movl $1, %ecx
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $40, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test7:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl (%eax)
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
entry:
  %val = load i32, ptr %ptr
  call void @good(i32 1, i32 2, i32 %val, i32 4)
  ret void
}

; Fold stack-relative loads into the push, with correct offset
; In particular, at the second push, %b was at 12(%esp) and
; %a wast at 8(%esp), but the second push bumped %esp, so %a
; is now it at 12(%esp)
define void @test8(i32 %a, i32 %b) optsize {
; NORMAL-LABEL: test8:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl {{[0-9]+}}(%esp)
; NORMAL-NEXT:    pushl {{[0-9]+}}(%esp)
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test8:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    addl $16, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test8:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $40, %rsp
; X64-NEXT:    .seh_stackalloc 40
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl %edx, %r8d
; X64-NEXT:    movl %ecx, %edx
; X64-NEXT:    movl $1, %ecx
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $40, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test8:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl {{[0-9]+}}(%esp)
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl {{[0-9]+}}(%esp)
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
entry:
  call void @good(i32 1, i32 %a, i32 %b, i32 4)
  ret void
}

; If one function is using push instructions, and the other isn't
; (because it has frame-index references), then we must resolve
; these references correctly.
define void @test9() optsize {
; NORMAL-LABEL: test9:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    pushl %ebp
; NORMAL-NEXT:    movl %esp, %ebp
; NORMAL-NEXT:    pushl %esi
; NORMAL-NEXT:    andl $-8, %esp
; NORMAL-NEXT:    subl $24, %esp
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    movl (%esp), %eax
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NORMAL-NEXT:    leal {{[0-9]+}}(%esp), %edx
; NORMAL-NEXT:    leal {{[0-9]+}}(%esp), %esi
; NORMAL-NEXT:    pushl %edx
; NORMAL-NEXT:    pushl %esi
; NORMAL-NEXT:    pushl $6
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _struct
; NORMAL-NEXT:    addl $20, %esp
; NORMAL-NEXT:    leal -4(%ebp), %esp
; NORMAL-NEXT:    popl %esi
; NORMAL-NEXT:    popl %ebp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test9:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    pushl %ebp
; NOPUSH-NEXT:    movl %esp, %ebp
; NOPUSH-NEXT:    andl $-8, %esp
; NOPUSH-NEXT:    subl $40, %esp
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    leal {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    leal {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $6, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _struct
; NOPUSH-NEXT:    movl %ebp, %esp
; NOPUSH-NEXT:    popl %ebp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test9:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $72, %rsp
; X64-NEXT:    .seh_stackalloc 72
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl $1, %ecx
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %r9
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %r8
; X64-NEXT:    movq {{[0-9]+}}(%rsp), %rax
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %rcx
; X64-NEXT:    movq %rax, (%rcx)
; X64-NEXT:    movl $6, %edx
; X64-NEXT:    # kill: def $r8d killed $r8d killed $r8
; X64-NEXT:    # kill: def $r9d killed $r9d killed $r9
; X64-NEXT:    callq struct
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $72, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test9:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    pushl %esi
; LINUX-NEXT:    .cfi_def_cfa_offset 8
; LINUX-NEXT:    subl $24, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 32
; LINUX-NEXT:    .cfi_offset %esi, -8
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $4, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -4
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; LINUX-NEXT:    leal {{[0-9]+}}(%esp), %edx
; LINUX-NEXT:    leal {{[0-9]+}}(%esp), %esi
; LINUX-NEXT:    pushl %edx
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %esi
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $6
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll struct@PLT
; LINUX-NEXT:    addl $56, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -56
; LINUX-NEXT:    popl %esi
; LINUX-NEXT:    .cfi_def_cfa_offset 4
; LINUX-NEXT:    retl
entry:
  %p = alloca i32, align 4
  %q = alloca i32, align 4
  %s = alloca %struct.s, align 8
  call void @good(i32 1, i32 2, i32 3, i32 4)
  %pv = ptrtoint ptr %p to i32
  %qv = ptrtoint ptr %q to i32
  call void @struct(ptr byval(%struct.s) %s, i32 6, i32 %qv, i32 %pv)
  ret void
}

; We can end up with an indirect call which gets reloaded on the spot.
; Make sure we reference the correct stack slot - we spill into (%esp)
; and reload from 16(%esp) due to the pushes.
define void @test10() optsize {
; NORMAL-LABEL: test10:
; NORMAL:       # %bb.0:
; NORMAL-NEXT:    pushl %ebp
; NORMAL-NEXT:    pushl %ebx
; NORMAL-NEXT:    pushl %edi
; NORMAL-NEXT:    pushl %esi
; NORMAL-NEXT:    subl $8, %esp
; NORMAL-NEXT:    movl $_good, {{[0-9]+}}(%esp)
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NORMAL-NEXT:    movl %eax, (%esp) # 4-byte Spill
; NORMAL-NEXT:    #APP
; NORMAL-NEXT:    nop
; NORMAL-NEXT:    #NO_APP
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll *{{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Folded Reload
; NORMAL-NEXT:    addl $24, %esp
; NORMAL-NEXT:    popl %esi
; NORMAL-NEXT:    popl %edi
; NORMAL-NEXT:    popl %ebx
; NORMAL-NEXT:    popl %ebp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test10:
; NOPUSH:       # %bb.0:
; NOPUSH-NEXT:    pushl %ebp
; NOPUSH-NEXT:    pushl %ebx
; NOPUSH-NEXT:    pushl %edi
; NOPUSH-NEXT:    pushl %esi
; NOPUSH-NEXT:    subl $24, %esp
; NOPUSH-NEXT:    movl $_good, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; NOPUSH-NEXT:    #APP
; NOPUSH-NEXT:    nop
; NOPUSH-NEXT:    #NO_APP
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll *{{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Folded Reload
; NOPUSH-NEXT:    addl $24, %esp
; NOPUSH-NEXT:    popl %esi
; NOPUSH-NEXT:    popl %edi
; NOPUSH-NEXT:    popl %ebx
; NOPUSH-NEXT:    popl %ebp
; NOPUSH-NEXT:    retl
;
; LINUX-LABEL: test10:
; LINUX:       # %bb.0:
; LINUX-NEXT:    pushl %ebp
; LINUX-NEXT:    .cfi_def_cfa_offset 8
; LINUX-NEXT:    pushl %ebx
; LINUX-NEXT:    .cfi_def_cfa_offset 12
; LINUX-NEXT:    pushl %edi
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    pushl %esi
; LINUX-NEXT:    .cfi_def_cfa_offset 20
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 32
; LINUX-NEXT:    .cfi_offset %esi, -20
; LINUX-NEXT:    .cfi_offset %edi, -16
; LINUX-NEXT:    .cfi_offset %ebx, -12
; LINUX-NEXT:    .cfi_offset %ebp, -8
; LINUX-NEXT:    movl $good, {{[0-9]+}}(%esp)
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; LINUX-NEXT:    #APP
; LINUX-NEXT:    nop
; LINUX-NEXT:    #NO_APP
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll *{{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Folded Reload
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    popl %esi
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    popl %edi
; LINUX-NEXT:    .cfi_def_cfa_offset 12
; LINUX-NEXT:    popl %ebx
; LINUX-NEXT:    .cfi_def_cfa_offset 8
; LINUX-NEXT:    popl %ebp
; LINUX-NEXT:    .cfi_def_cfa_offset 4
; LINUX-NEXT:    retl
  %stack_fptr = alloca ptr
  store ptr @good, ptr %stack_fptr
  %good_ptr = load volatile ptr, ptr %stack_fptr
  call void asm sideeffect "nop", "~{ax},~{bx},~{cx},~{dx},~{bp},~{si},~{di}"()
  call void (i32, i32, i32, i32) %good_ptr(i32 1, i32 2, i32 3, i32 4)
  ret void
}

; We can't fold the load from the global into the push because of
; interference from the store
@the_global = external dso_local global i32
define void @test11() optsize {
; NORMAL-LABEL: test11:
; NORMAL:       # %bb.0:
; NORMAL-NEXT:    movl _the_global, %eax
; NORMAL-NEXT:    movl $42, _the_global
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test11:
; NOPUSH:       # %bb.0:
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl _the_global, %eax
; NOPUSH-NEXT:    movl $42, _the_global
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    addl $16, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test11:
; X64:       # %bb.0:
; X64-NEXT:    subq $40, %rsp
; X64-NEXT:    .seh_stackalloc 40
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl the_global(%rip), %ecx
; X64-NEXT:    movl $42, the_global(%rip)
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $40, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test11:
; LINUX:       # %bb.0:
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    movl the_global, %eax
; LINUX-NEXT:    movl $42, the_global
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
  %myload = load i32, ptr @the_global
  store i32 42, ptr @the_global
  call void @good(i32 %myload, i32 2, i32 3, i32 4)
  ret void
}

; Converting one mov into a push isn't worth it when
; doing so forces too much overhead for other calls.
define void @test12() optsize {
; NORMAL-LABEL: test12:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    subl $8, %esp
; NORMAL-NEXT:    movl (%esp), %eax
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _struct
; NORMAL-NEXT:    addl $20, %esp
; NORMAL-NEXT:    pushl $8
; NORMAL-NEXT:    pushl $7
; NORMAL-NEXT:    pushl $6
; NORMAL-NEXT:    pushl $5
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    movl (%esp), %eax
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NORMAL-NEXT:    pushl $12
; NORMAL-NEXT:    pushl $11
; NORMAL-NEXT:    pushl $10
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _struct
; NORMAL-NEXT:    addl $28, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test12:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $28, %esp
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _struct
; NOPUSH-NEXT:    movl $8, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $7, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $6, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $5, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    movl $12, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $11, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $10, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _struct
; NOPUSH-NEXT:    addl $28, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test12:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $72, %rsp
; X64-NEXT:    .seh_stackalloc 72
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movq {{[0-9]+}}(%rsp), %rax
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %rcx
; X64-NEXT:    movq %rax, (%rcx)
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq struct
; X64-NEXT:    movl $5, %ecx
; X64-NEXT:    movl $6, %edx
; X64-NEXT:    movl $7, %r8d
; X64-NEXT:    movl $8, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    movq {{[0-9]+}}(%rsp), %rax
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %rcx
; X64-NEXT:    movq %rax, (%rcx)
; X64-NEXT:    movl $10, %edx
; X64-NEXT:    movl $11, %r8d
; X64-NEXT:    movl $12, %r9d
; X64-NEXT:    callq struct
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $72, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test12:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $24, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset 24
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll struct@PLT
; LINUX-NEXT:    addl $32, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -32
; LINUX-NEXT:    pushl $8
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $7
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $6
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $5
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $4, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -4
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; LINUX-NEXT:    pushl $12
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $11
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $10
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll struct@PLT
; LINUX-NEXT:    addl $44, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -44
; LINUX-NEXT:    retl
entry:
  %s = alloca %struct.s, align 4
  call void @struct(ptr byval(%struct.s) %s, i32 2, i32 3, i32 4)
  call void @good(i32 5, i32 6, i32 7, i32 8)
  call void @struct(ptr byval(%struct.s) %s, i32 10, i32 11, i32 12)
  ret void
}

; But if the gains outweigh the overhead, we should do it
define void @test12b() optsize {
; NORMAL-LABEL: test12b:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    subl $8, %esp
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    movl (%esp), %eax
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NORMAL-NEXT:    pushl $8
; NORMAL-NEXT:    pushl $7
; NORMAL-NEXT:    pushl $6
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _struct
; NORMAL-NEXT:    addl $20, %esp
; NORMAL-NEXT:    pushl $12
; NORMAL-NEXT:    pushl $11
; NORMAL-NEXT:    pushl $10
; NORMAL-NEXT:    pushl $9
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $24, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test12b:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $28, %esp
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    movl $8, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $7, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $6, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _struct
; NOPUSH-NEXT:    movl $12, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $11, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $10, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $9, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    addl $28, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test12b:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $56, %rsp
; X64-NEXT:    .seh_stackalloc 56
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movl $1, %ecx
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    movq {{[0-9]+}}(%rsp), %rax
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %rcx
; X64-NEXT:    movq %rax, (%rcx)
; X64-NEXT:    movl $6, %edx
; X64-NEXT:    movl $7, %r8d
; X64-NEXT:    movl $8, %r9d
; X64-NEXT:    callq struct
; X64-NEXT:    movl $9, %ecx
; X64-NEXT:    movl $10, %edx
; X64-NEXT:    movl $11, %r8d
; X64-NEXT:    movl $12, %r9d
; X64-NEXT:    callq good
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $56, %rsp
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test12b:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $4, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -4
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; LINUX-NEXT:    pushl $8
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $7
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $6
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll struct@PLT
; LINUX-NEXT:    addl $32, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -32
; LINUX-NEXT:    pushl $12
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $11
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $10
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $9
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
entry:
  %s = alloca %struct.s, align 4
  call void @good(i32 1, i32 2, i32 3, i32 4)
  call void @struct(ptr byval(%struct.s) %s, i32 6, i32 7, i32 8)
  call void @good(i32 9, i32 10, i32 11, i32 12)
  ret void
}

; Make sure the add does not prevent folding loads into pushes.
; val1 and val2 will not be folded into pushes since they have
; an additional use, but val3 should be.
define ptr @test13(ptr inreg %ptr1, ptr inreg %ptr2, ptr inreg %ptr3) optsize {
; NORMAL-LABEL: test13:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    pushl %esi
; NORMAL-NEXT:    movl %ecx, %esi
; NORMAL-NEXT:    movl (%eax), %eax
; NORMAL-NEXT:    movl (%edx), %ecx
; NORMAL-NEXT:    leal (%eax,%ecx), %edx
; NORMAL-NEXT:    pushl %edx
; NORMAL-NEXT:    pushl (%esi)
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    movl %esi, %eax
; NORMAL-NEXT:    popl %esi
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test13:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    pushl %edi
; NOPUSH-NEXT:    pushl %esi
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl %ecx, %esi
; NOPUSH-NEXT:    movl (%eax), %eax
; NOPUSH-NEXT:    movl (%edx), %ecx
; NOPUSH-NEXT:    movl (%esi), %edx
; NOPUSH-NEXT:    leal (%eax,%ecx), %edi
; NOPUSH-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    movl %esi, %eax
; NOPUSH-NEXT:    addl $16, %esp
; NOPUSH-NEXT:    popl %esi
; NOPUSH-NEXT:    popl %edi
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test13:
; X64:       # %bb.0: # %entry
; X64-NEXT:    pushq %rsi
; X64-NEXT:    .seh_pushreg %rsi
; X64-NEXT:    subq $32, %rsp
; X64-NEXT:    .seh_stackalloc 32
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movq %r8, %rsi
; X64-NEXT:    movl (%rcx), %ecx
; X64-NEXT:    movl (%rdx), %edx
; X64-NEXT:    movl (%r8), %r8d
; X64-NEXT:    leal (%rcx,%rdx), %r9d
; X64-NEXT:    # kill: def $ecx killed $ecx killed $rcx
; X64-NEXT:    # kill: def $edx killed $edx killed $rdx
; X64-NEXT:    callq good
; X64-NEXT:    movq %rsi, %rax
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $32, %rsp
; X64-NEXT:    popq %rsi
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test13:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    pushl %esi
; LINUX-NEXT:    .cfi_def_cfa_offset 8
; LINUX-NEXT:    subl $8, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    .cfi_offset %esi, -8
; LINUX-NEXT:    movl %ecx, %esi
; LINUX-NEXT:    movl (%eax), %eax
; LINUX-NEXT:    movl (%edx), %ecx
; LINUX-NEXT:    leal (%eax,%ecx), %edx
; LINUX-NEXT:    pushl %edx
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl (%esi)
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $16, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -16
; LINUX-NEXT:    movl %esi, %eax
; LINUX-NEXT:    addl $8, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 8
; LINUX-NEXT:    popl %esi
; LINUX-NEXT:    .cfi_def_cfa_offset 4
; LINUX-NEXT:    retl
entry:
  %val1 = load i32, ptr %ptr1
  %val2 = load i32, ptr %ptr2
  %val3 = load i32, ptr %ptr3
  %add = add i32 %val1, %val2
  call void @good(i32 %val1, i32 %val2, i32 %val3, i32 %add)
  ret ptr %ptr3
}

; Make sure to fold adjacent stack adjustments.
define void @pr27140() optsize {
; NORMAL-LABEL: pr27140:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    pushl $4
; NORMAL-NEXT:    pushl $3
; NORMAL-NEXT:    pushl $2
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    calll _good
; NORMAL-NEXT:    addl $16, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: pr27140:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $16, %esp
; NOPUSH-NEXT:    movl $4, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $3, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $2, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl $1, (%esp)
; NOPUSH-NEXT:    calll _good
; NOPUSH-NEXT:    addl $16, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: pr27140:
; X64:       # %bb.0: # %entry
; X64-NEXT:    movl $1, %ecx
; X64-NEXT:    movl $2, %edx
; X64-NEXT:    movl $3, %r8d
; X64-NEXT:    movl $4, %r9d
; X64-NEXT:    jmp good # TAILCALL
;
; LINUX-LABEL: pr27140:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 16
; LINUX-NEXT:    pushl $4
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $3
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $2
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll good@PLT
; LINUX-NEXT:    addl $28, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -28
; LINUX-NEXT:    retl
entry:
  tail call void @good(i32 1, i32 2, i32 3, i32 4)
  ret void
}

; Check that a stack restore (leal -4(%ebp), %esp) doesn't get merged with a
; stack adjustment (addl $12, %esp). Just because it's a lea doesn't mean it's
; simply decreasing the stack pointer.
%struct.A = type { i32, i32 }
%struct.B = type { i8 }
declare x86_thiscallcc ptr @B_ctor(ptr returned, ptr byval(%struct.A))
declare void @B_func(ptr sret(%struct.B), ptr, i32)
define void @test14(ptr %a) {
; NORMAL-LABEL: test14:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    pushl %ebp
; NORMAL-NEXT:    movl %esp, %ebp
; NORMAL-NEXT:    pushl %esi
; NORMAL-NEXT:    andl $-8, %esp
; NORMAL-NEXT:    subl $24, %esp
; NORMAL-NEXT:    movl 8(%ebp), %eax
; NORMAL-NEXT:    movl (%eax), %edx
; NORMAL-NEXT:    movl 4(%eax), %eax
; NORMAL-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NORMAL-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NORMAL-NEXT:    leal {{[0-9]+}}(%esp), %esi
; NORMAL-NEXT:    movl %esi, %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %edx
; NORMAL-NEXT:    calll _B_ctor
; NORMAL-NEXT:    leal {{[0-9]+}}(%esp), %eax
; NORMAL-NEXT:    pushl $1
; NORMAL-NEXT:    pushl %esi
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _B_func
; NORMAL-NEXT:    addl $12, %esp
; NORMAL-NEXT:    leal -4(%ebp), %esp
; NORMAL-NEXT:    popl %esi
; NORMAL-NEXT:    popl %ebp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: test14:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    pushl %ebp
; NOPUSH-NEXT:    movl %esp, %ebp
; NOPUSH-NEXT:    pushl %esi
; NOPUSH-NEXT:    andl $-8, %esp
; NOPUSH-NEXT:    subl $32, %esp
; NOPUSH-NEXT:    movl 8(%ebp), %eax
; NOPUSH-NEXT:    movl (%eax), %ecx
; NOPUSH-NEXT:    movl 4(%eax), %eax
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %ecx, (%esp)
; NOPUSH-NEXT:    leal {{[0-9]+}}(%esp), %esi
; NOPUSH-NEXT:    movl %esi, %ecx
; NOPUSH-NEXT:    calll _B_ctor
; NOPUSH-NEXT:    subl $8, %esp
; NOPUSH-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    leal {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    movl $1, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _B_func
; NOPUSH-NEXT:    leal -4(%ebp), %esp
; NOPUSH-NEXT:    popl %esi
; NOPUSH-NEXT:    popl %ebp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: test14:
; X64:       # %bb.0: # %entry
; X64-NEXT:    pushq %rsi
; X64-NEXT:    .seh_pushreg %rsi
; X64-NEXT:    subq $64, %rsp
; X64-NEXT:    .seh_stackalloc 64
; X64-NEXT:    .seh_endprologue
; X64-NEXT:    movq (%rcx), %rax
; X64-NEXT:    movq %rax, {{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rax, {{[0-9]+}}(%rsp)
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %rsi
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %rdx
; X64-NEXT:    movq %rsi, %rcx
; X64-NEXT:    callq B_ctor
; X64-NEXT:    leaq {{[0-9]+}}(%rsp), %rcx
; X64-NEXT:    movq %rsi, %rdx
; X64-NEXT:    movl $1, %r8d
; X64-NEXT:    callq B_func
; X64-NEXT:    nop
; X64-NEXT:    .seh_startepilogue
; X64-NEXT:    addq $64, %rsp
; X64-NEXT:    popq %rsi
; X64-NEXT:    .seh_endepilogue
; X64-NEXT:    retq
; X64-NEXT:    .seh_endproc
;
; LINUX-LABEL: test14:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    pushl %esi
; LINUX-NEXT:    .cfi_def_cfa_offset 8
; LINUX-NEXT:    subl $24, %esp
; LINUX-NEXT:    .cfi_def_cfa_offset 32
; LINUX-NEXT:    .cfi_offset %esi, -8
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    movl (%eax), %edx
; LINUX-NEXT:    movl 4(%eax), %eax
; LINUX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; LINUX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; LINUX-NEXT:    subl $8, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset 8
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    leal {{[0-9]+}}(%esp), %esi
; LINUX-NEXT:    movl %esi, %ecx
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %edx
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll B_ctor@PLT
; LINUX-NEXT:    .cfi_adjust_cfa_offset -8
; LINUX-NEXT:    addl $4, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -4
; LINUX-NEXT:    leal {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    pushl $1
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %esi
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    .cfi_adjust_cfa_offset 4
; LINUX-NEXT:    calll B_func@PLT
; LINUX-NEXT:    .cfi_adjust_cfa_offset -4
; LINUX-NEXT:    addl $36, %esp
; LINUX-NEXT:    .cfi_adjust_cfa_offset -36
; LINUX-NEXT:    popl %esi
; LINUX-NEXT:    .cfi_def_cfa_offset 4
; LINUX-NEXT:    retl
entry:
  %ref.tmp = alloca %struct.B, align 1
  %agg.tmp = alloca i64, align 8
  %tmp = alloca %struct.B, align 1
  %0 = load i64, ptr %a, align 4
  store i64 %0, ptr %agg.tmp, align 4
  %call = call x86_thiscallcc ptr @B_ctor(ptr returned %ref.tmp, ptr byval(%struct.A) %agg.tmp)
  call void @B_func(ptr sret(%struct.B) %tmp, ptr %ref.tmp, i32 1)
  ret void
}

define void @pr34863_16(i16 %x) minsize nounwind {
; NORMAL-LABEL: pr34863_16:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NORMAL-NEXT:    pushl $65535 # imm = 0xFFFF
; NORMAL-NEXT:    pushl $0
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _eightparams16
; NORMAL-NEXT:    addl $32, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: pr34863_16:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $32, %esp
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    movl $65535, {{[0-9]+}}(%esp) # imm = 0xFFFF
; NOPUSH-NEXT:    andl $0, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _eightparams16
; NOPUSH-NEXT:    addl $32, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: pr34863_16:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $72, %rsp
; X64-NEXT:    movw %cx, {{[0-9]+}}(%rsp)
; X64-NEXT:    orw $-1, {{[0-9]+}}(%rsp)
; X64-NEXT:    movw %cx, {{[0-9]+}}(%rsp)
; X64-NEXT:    andw $0, {{[0-9]+}}(%rsp)
; X64-NEXT:    movl %ecx, %edx
; X64-NEXT:    movl %ecx, %r8d
; X64-NEXT:    movl %ecx, %r9d
; X64-NEXT:    callq eightparams16
; X64-NEXT:    addq $72, %rsp
; X64-NEXT:    retq
;
; LINUX-LABEL: pr34863_16:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    pushl $65535 # imm = 0xFFFF
; LINUX-NEXT:    pushl $0
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    calll eightparams16@PLT
; LINUX-NEXT:    addl $44, %esp
; LINUX-NEXT:    retl
entry:
  tail call void @eightparams16(i16 %x, i16 %x, i16 %x, i16 %x, i16 %x, i16 %x, i16 0, i16 -1)
  ret void
}

define void @pr34863_32(i32 %x) minsize nounwind {
; NORMAL-LABEL: pr34863_32:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NORMAL-NEXT:    pushl $-1
; NORMAL-NEXT:    pushl $0
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _eightparams
; NORMAL-NEXT:    addl $32, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: pr34863_32:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $32, %esp
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    orl $-1, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    andl $0, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _eightparams
; NOPUSH-NEXT:    addl $32, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: pr34863_32:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $72, %rsp
; X64-NEXT:    movl %ecx, {{[0-9]+}}(%rsp)
; X64-NEXT:    orl $-1, {{[0-9]+}}(%rsp)
; X64-NEXT:    movl %ecx, {{[0-9]+}}(%rsp)
; X64-NEXT:    andl $0, {{[0-9]+}}(%rsp)
; X64-NEXT:    movl %ecx, %edx
; X64-NEXT:    movl %ecx, %r8d
; X64-NEXT:    movl %ecx, %r9d
; X64-NEXT:    callq eightparams
; X64-NEXT:    addq $72, %rsp
; X64-NEXT:    retq
;
; LINUX-LABEL: pr34863_32:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    pushl $-1
; LINUX-NEXT:    pushl $0
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    calll eightparams@PLT
; LINUX-NEXT:    addl $44, %esp
; LINUX-NEXT:    retl
entry:
  tail call void @eightparams(i32 %x, i32 %x, i32 %x, i32 %x, i32 %x, i32 %x, i32 0, i32 -1)
  ret void
}

define void @pr34863_64(i64 %x) minsize nounwind {
; NORMAL-LABEL: pr34863_64:
; NORMAL:       # %bb.0: # %entry
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NORMAL-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NORMAL-NEXT:    pushl $-1
; NORMAL-NEXT:    pushl $-1
; NORMAL-NEXT:    pushl $0
; NORMAL-NEXT:    pushl $0
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    pushl %ecx
; NORMAL-NEXT:    pushl %eax
; NORMAL-NEXT:    calll _eightparams64
; NORMAL-NEXT:    addl $64, %esp
; NORMAL-NEXT:    retl
;
; NOPUSH-LABEL: pr34863_64:
; NOPUSH:       # %bb.0: # %entry
; NOPUSH-NEXT:    subl $64, %esp
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %eax
; NOPUSH-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    orl $-1, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    orl $-1, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    andl $0, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    movl %eax, (%esp)
; NOPUSH-NEXT:    andl $0, {{[0-9]+}}(%esp)
; NOPUSH-NEXT:    calll _eightparams64
; NOPUSH-NEXT:    addl $64, %esp
; NOPUSH-NEXT:    retl
;
; X64-LABEL: pr34863_64:
; X64:       # %bb.0: # %entry
; X64-NEXT:    subq $72, %rsp
; X64-NEXT:    movq %rcx, {{[0-9]+}}(%rsp)
; X64-NEXT:    orq $-1, {{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rcx, {{[0-9]+}}(%rsp)
; X64-NEXT:    andq $0, {{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rcx, %rdx
; X64-NEXT:    movq %rcx, %r8
; X64-NEXT:    movq %rcx, %r9
; X64-NEXT:    callq eightparams64
; X64-NEXT:    addq $72, %rsp
; X64-NEXT:    retq
;
; LINUX-LABEL: pr34863_64:
; LINUX:       # %bb.0: # %entry
; LINUX-NEXT:    subl $12, %esp
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; LINUX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; LINUX-NEXT:    pushl $-1
; LINUX-NEXT:    pushl $-1
; LINUX-NEXT:    pushl $0
; LINUX-NEXT:    pushl $0
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    pushl %ecx
; LINUX-NEXT:    pushl %eax
; LINUX-NEXT:    calll eightparams64@PLT
; LINUX-NEXT:    addl $76, %esp
; LINUX-NEXT:    retl
entry:
  tail call void @eightparams64(i64 %x, i64 %x, i64 %x, i64 %x, i64 %x, i64 %x, i64 0, i64 -1)
  ret void
}
