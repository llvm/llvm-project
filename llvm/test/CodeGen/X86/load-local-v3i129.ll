; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --no_x86_scrub_sp
; RUN: llc < %s -mtriple=x86_64-unknown-unknown | FileCheck %s --check-prefix=FAST-SHLD
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+slow-shld | FileCheck %s --check-prefix=SLOW-SHLD

define void @_start() nounwind {
; FAST-SHLD-LABEL: _start:
; FAST-SHLD:       # %bb.0: # %Entry
; FAST-SHLD-NEXT:    movq -40(%rsp), %rax
; FAST-SHLD-NEXT:    movq -32(%rsp), %rcx
; FAST-SHLD-NEXT:    shrdq $2, %rcx, %rax
; FAST-SHLD-NEXT:    shrq $2, %rcx
; FAST-SHLD-NEXT:    leaq 1(,%rax,4), %rdx
; FAST-SHLD-NEXT:    movq %rdx, -40(%rsp)
; FAST-SHLD-NEXT:    shrdq $62, %rcx, %rax
; FAST-SHLD-NEXT:    movq %rax, -32(%rsp)
; FAST-SHLD-NEXT:    orq $-2, -56(%rsp)
; FAST-SHLD-NEXT:    movq $-1, -48(%rsp)
; FAST-SHLD-NEXT:    retq
;
; SLOW-SHLD-LABEL: _start:
; SLOW-SHLD:       # %bb.0: # %Entry
; SLOW-SHLD-NEXT:    movq -40(%rsp), %rax
; SLOW-SHLD-NEXT:    movq -32(%rsp), %rcx
; SLOW-SHLD-NEXT:    shrq $2, %rax
; SLOW-SHLD-NEXT:    movq %rcx, %rdx
; SLOW-SHLD-NEXT:    shlq $62, %rdx
; SLOW-SHLD-NEXT:    orq %rax, %rdx
; SLOW-SHLD-NEXT:    andq $-4, %rcx
; SLOW-SHLD-NEXT:    leaq 1(,%rdx,4), %rax
; SLOW-SHLD-NEXT:    movq %rax, -40(%rsp)
; SLOW-SHLD-NEXT:    shrq $62, %rdx
; SLOW-SHLD-NEXT:    orq %rcx, %rdx
; SLOW-SHLD-NEXT:    movq %rdx, -32(%rsp)
; SLOW-SHLD-NEXT:    orq $-2, -56(%rsp)
; SLOW-SHLD-NEXT:    movq $-1, -48(%rsp)
; SLOW-SHLD-NEXT:    retq
Entry:
  %y = alloca <3 x i129>, align 4
  %L = load <3 x i129>, <3 x i129>* %y
  %I1 = insertelement <3 x i129> %L, i129 340282366920938463463374607431768211455, i32 1
  store <3 x i129> %I1, <3 x i129>* %y
  ret void
}
