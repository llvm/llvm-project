; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx512fp16 | FileCheck %s
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx512fp16,+avx512vl | FileCheck %s

declare <2 x half> @llvm.experimental.complex.fmul.v2f16(<2 x half>, <2 x half>)
declare <4 x half> @llvm.experimental.complex.fmul.v4f16(<4 x half>, <4 x half>)
declare <8 x half> @llvm.experimental.complex.fmul.v8f16(<8 x half>, <8 x half>)
declare <16 x half> @llvm.experimental.complex.fmul.v16f16(<16 x half>, <16 x half>)
declare <32 x half> @llvm.experimental.complex.fmul.v32f16(<32 x half>, <32 x half>)
declare <20 x half> @llvm.experimental.complex.fmul.v20f16(<20 x half>, <20 x half>)
declare <64 x half> @llvm.experimental.complex.fmul.v64f16(<64 x half>, <64 x half>)

; FIXME: llvm.experimental.complex.fmul.v2f16 should be lowered to vfmulcsh
define <2 x half> @intrinsic_fast_v2f16(<2 x half> %z, <2 x half> %w) {
; CHECK-LABEL: intrinsic_fast_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %xmm1, %xmm0, %xmm2
; CHECK-NEXT:    vmovaps %xmm2, %xmm0
; CHECK-NEXT:    retq
  %mul = call fast <2 x half> @llvm.experimental.complex.fmul.v2f16(<2 x half> %z, <2 x half> %w)
  ret <2 x half> %mul
}

define <4 x half> @intrinsic_fast_v4f16(<4 x half> %z, <4 x half> %w) {
; CHECK-LABEL: intrinsic_fast_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %xmm1, %xmm0, %xmm2
; CHECK-NEXT:    vmovaps %xmm2, %xmm0
; CHECK-NEXT:    retq
  %mul = call fast <4 x half> @llvm.experimental.complex.fmul.v4f16(<4 x half> %z, <4 x half> %w)
  ret <4 x half> %mul
}

define <8 x half> @intrinsic_fast_v8f16(<8 x half> %z, <8 x half> %w) {
; CHECK-LABEL: intrinsic_fast_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %xmm1, %xmm0, %xmm2
; CHECK-NEXT:    vmovaps %xmm2, %xmm0
; CHECK-NEXT:    retq
  %mul = call fast <8 x half> @llvm.experimental.complex.fmul.v8f16(<8 x half> %z, <8 x half> %w)
  ret <8 x half> %mul
}

define <16 x half> @intrinsic_fast_v16f16(<16 x half> %z, <16 x half> %w) {
; CHECK-LABEL: intrinsic_fast_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %ymm1, %ymm0, %ymm2
; CHECK-NEXT:    vmovaps %ymm2, %ymm0
; CHECK-NEXT:    retq
  %mul = call fast <16 x half> @llvm.experimental.complex.fmul.v16f16(<16 x half> %z, <16 x half> %w)
  ret <16 x half> %mul
}

define <32 x half> @intrinsic_fast_v32f16(<32 x half> %z, <32 x half> %w) {
; CHECK-LABEL: intrinsic_fast_v32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %zmm1, %zmm0, %zmm2
; CHECK-NEXT:    vmovaps %zmm2, %zmm0
; CHECK-NEXT:    retq
  %mul = call fast <32 x half> @llvm.experimental.complex.fmul.v32f16(<32 x half> %z, <32 x half> %w)
  ret <32 x half> %mul
}

define <20 x half> @intrinsic_fast_v20f16(<20 x half> %z, <20 x half> %w) {
; CHECK-LABEL: intrinsic_fast_v20f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %zmm1, %zmm0, %zmm2
; CHECK-NEXT:    vmovaps %zmm2, %zmm0
; CHECK-NEXT:    retq
  %mul = call fast <20 x half> @llvm.experimental.complex.fmul.v20f16(<20 x half> %z, <20 x half> %w)
  ret <20 x half> %mul
}

define <2 x half> @intrinsic_limited_v2f16(<2 x half> %z, <2 x half> %w) {
; CHECK-LABEL: intrinsic_limited_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %xmm1, %xmm0, %xmm2
; CHECK-NEXT:    vmovaps %xmm2, %xmm0
; CHECK-NEXT:    retq
  %mul = call <2 x half> @llvm.experimental.complex.fmul.v2f16(<2 x half> %z, <2 x half> %w) #0
  ret <2 x half> %mul
}

define <4 x half> @intrinsic_limited_v4f16(<4 x half> %z, <4 x half> %w) {
; CHECK-LABEL: intrinsic_limited_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %xmm1, %xmm0, %xmm2
; CHECK-NEXT:    vmovaps %xmm2, %xmm0
; CHECK-NEXT:    retq
  %mul = call <4 x half> @llvm.experimental.complex.fmul.v4f16(<4 x half> %z, <4 x half> %w) #0
  ret <4 x half> %mul
}

define <8 x half> @intrinsic_limited_v8f16(<8 x half> %z, <8 x half> %w) {
; CHECK-LABEL: intrinsic_limited_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %xmm1, %xmm0, %xmm2
; CHECK-NEXT:    vmovaps %xmm2, %xmm0
; CHECK-NEXT:    retq
  %mul = call <8 x half> @llvm.experimental.complex.fmul.v8f16(<8 x half> %z, <8 x half> %w) #0
  ret <8 x half> %mul
}

define <16 x half> @intrinsic_limited_v16f16(<16 x half> %z, <16 x half> %w) {
; CHECK-LABEL: intrinsic_limited_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %ymm1, %ymm0, %ymm2
; CHECK-NEXT:    vmovaps %ymm2, %ymm0
; CHECK-NEXT:    retq
  %mul = call <16 x half> @llvm.experimental.complex.fmul.v16f16(<16 x half> %z, <16 x half> %w) #0
  ret <16 x half> %mul
}

define <32 x half> @intrinsic_limited_v32f16(<32 x half> %z, <32 x half> %w) {
; CHECK-LABEL: intrinsic_limited_v32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %zmm1, %zmm0, %zmm2
; CHECK-NEXT:    vmovaps %zmm2, %zmm0
; CHECK-NEXT:    retq
  %mul = call <32 x half> @llvm.experimental.complex.fmul.v32f16(<32 x half> %z, <32 x half> %w) #0
  ret <32 x half> %mul
}

define <20 x half> @intrinsic_limited_v20f16(<20 x half> %z, <20 x half> %w) {
; CHECK-LABEL: intrinsic_limited_v20f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %zmm1, %zmm0, %zmm2
; CHECK-NEXT:    vmovaps %zmm2, %zmm0
; CHECK-NEXT:    retq
  %mul = call <20 x half> @llvm.experimental.complex.fmul.v20f16(<20 x half> %z, <20 x half> %w) #0
  ret <20 x half> %mul
}

; Test the vector size bigger than 512 bits
define <64 x half> @intrinsic_limited_v64f16(<64 x half> %z, <64 x half> %w) {
; CHECK-LABEL: intrinsic_limited_v64f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmulcph %zmm2, %zmm0, %zmm4
; CHECK-NEXT:    vfmulcph %zmm3, %zmm1, %zmm2
; CHECK-NEXT:    vmovaps %zmm4, %zmm0
; CHECK-NEXT:    vmovaps %zmm2, %zmm1
; CHECK-NEXT:    retq
  %mul = call <64 x half> @llvm.experimental.complex.fmul.v64f16(<64 x half> %z, <64 x half> %w) #0
  ret <64 x half> %mul
}

define <2 x half> @intrinsic_slow_v2f16(<2 x half> %z, <2 x half> %w) {
; CHECK-LABEL: intrinsic_slow_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    vmovdqa %xmm1, %xmm2
; CHECK-NEXT:    vpsrld $16, %xmm0, %xmm1
; CHECK-NEXT:    vpsrld $16, %xmm2, %xmm3
; CHECK-NEXT:    callq __mulhc3@PLT
; CHECK-NEXT:    popq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    retq
  %mul = call <2 x half> @llvm.experimental.complex.fmul.v2f16(<2 x half> %z, <2 x half> %w)
  ret <2 x half> %mul
}

define <4 x half> @intrinsic_slow_v4f16(<4 x half> %z, <4 x half> %w) {
; CHECK-LABEL: intrinsic_slow_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    vmovdqa %xmm1, %xmm2
; CHECK-NEXT:    vpsrld $16, %xmm0, %xmm1
; CHECK-NEXT:    vpsrld $16, %xmm2, %xmm3
; CHECK-NEXT:    callq __mulhc3@PLT
; CHECK-NEXT:    popq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    retq
  %mul = call <4 x half> @llvm.experimental.complex.fmul.v4f16(<4 x half> %z, <4 x half> %w)
  ret <4 x half> %mul
}

define <8 x half> @intrinsic_slow_v8f16(<8 x half> %z, <8 x half> %w) {
; CHECK-LABEL: intrinsic_slow_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    vmovdqa %xmm1, %xmm2
; CHECK-NEXT:    vpsrld $16, %xmm0, %xmm1
; CHECK-NEXT:    vpsrld $16, %xmm2, %xmm3
; CHECK-NEXT:    callq __mulhc3@PLT
; CHECK-NEXT:    popq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    retq
  %mul = call <8 x half> @llvm.experimental.complex.fmul.v8f16(<8 x half> %z, <8 x half> %w)
  ret <8 x half> %mul
}

define <16 x half> @intrinsic_slow_v16f16(<16 x half> %z, <16 x half> %w) {
; CHECK-LABEL: intrinsic_slow_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    vmovdqa %ymm1, %ymm2
; CHECK-NEXT:    vpsrld $16, %xmm0, %xmm1
; CHECK-NEXT:    vpsrld $16, %xmm2, %xmm3
; CHECK-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; CHECK-NEXT:    # kill: def $xmm2 killed $xmm2 killed $ymm2
; CHECK-NEXT:    callq __mulhc3@PLT
; CHECK-NEXT:    popq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    retq
  %mul = call <16 x half> @llvm.experimental.complex.fmul.v16f16(<16 x half> %z, <16 x half> %w)
  ret <16 x half> %mul
}

define <32 x half> @intrinsic_slow_v32f16(<32 x half> %z, <32 x half> %w) {
; CHECK-LABEL: intrinsic_slow_v32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    vmovdqa64 %zmm1, %zmm2
; CHECK-NEXT:    vpsrld $16, %xmm0, %xmm1
; CHECK-NEXT:    vpsrld $16, %xmm2, %xmm3
; CHECK-NEXT:    # kill: def $xmm0 killed $xmm0 killed $zmm0
; CHECK-NEXT:    # kill: def $xmm2 killed $xmm2 killed $zmm2
; CHECK-NEXT:    callq __mulhc3@PLT
; CHECK-NEXT:    popq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    retq
  %mul = call <32 x half> @llvm.experimental.complex.fmul.v32f16(<32 x half> %z, <32 x half> %w)
  ret <32 x half> %mul
}

attributes #0 = { "complex-range"="limited" }
