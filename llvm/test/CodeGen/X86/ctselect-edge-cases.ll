; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+cmov | FileCheck %s --check-prefix=X64
; RUN: llc < %s -mtriple=i386-unknown-linux-gnu -mattr=+cmov | FileCheck %s --check-prefix=X32

; Test ct.select edge cases and corner cases

; Test with very large integers
define i128 @test_ctselect_i128(i1 %cond, i128 %a, i128 %b) {
; X64-LABEL: test_ctselect_i128:
; X64:       # %bb.0:
; X64-NEXT:    movq %rcx, %rax
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovneq %rsi, %rax
; X64-NEXT:    cmovneq %rdx, %r8
; X64-NEXT:    movq %r8, %rdx
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_i128:
; X32:       # %bb.0:
; X32-NEXT:    pushl %edi
; X32-NEXT:    .cfi_def_cfa_offset 8
; X32-NEXT:    pushl %esi
; X32-NEXT:    .cfi_def_cfa_offset 12
; X32-NEXT:    pushl %eax
; X32-NEXT:    .cfi_def_cfa_offset 16
; X32-NEXT:    .cfi_offset %esi, -12
; X32-NEXT:    .cfi_offset %edi, -8
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X32-NEXT:    movl {{[0-9]+}}(%esp), %edi
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %esi
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %edi
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %edx
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl %ecx, 12(%eax)
; X32-NEXT:    movl %edx, 8(%eax)
; X32-NEXT:    movl %edi, 4(%eax)
; X32-NEXT:    movl %esi, (%eax)
; X32-NEXT:    addl $4, %esp
; X32-NEXT:    .cfi_def_cfa_offset 12
; X32-NEXT:    popl %esi
; X32-NEXT:    .cfi_def_cfa_offset 8
; X32-NEXT:    popl %edi
; X32-NEXT:    .cfi_def_cfa_offset 4
; X32-NEXT:    retl $4
  %result = call i128 @llvm.ct.select.i128(i1 %cond, i128 %a, i128 %b)
  ret i128 %result
}

; Test with small integer types
define i1 @test_ctselect_i1(i1 %cond, i1 %a, i1 %b) {
; X64-LABEL: test_ctselect_i1:
; X64:       # %bb.0:
; X64-NEXT:    movl %edx, %eax
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovnel %esi, %eax
; X64-NEXT:    # kill: def $al killed $al killed $eax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_i1:
; X32:       # %bb.0:
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %eax
; X32-NEXT:    # kill: def $al killed $al killed $eax
; X32-NEXT:    retl
  %result = call i1 @llvm.ct.select.i1(i1 %cond, i1 %a, i1 %b)
  ret i1 %result
}

; Test with extremal values
define i32 @test_ctselect_extremal_values(i1 %cond) {
; X64-LABEL: test_ctselect_extremal_values:
; X64:       # %bb.0:
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    movl $2147483647, %ecx # imm = 0x7FFFFFFF
; X64-NEXT:    movl $-2147483648, %eax # imm = 0x80000000
; X64-NEXT:    cmovnel %ecx, %eax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_extremal_values:
; X32:       # %bb.0:
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $2147483647, %ecx # imm = 0x7FFFFFFF
; X32-NEXT:    movl $-2147483648, %eax # imm = 0x80000000
; X32-NEXT:    cmovnel %ecx, %eax
; X32-NEXT:    retl
  %result = call i32 @llvm.ct.select.i32(i1 %cond, i32 2147483647, i32 -2147483648)
  ret i32 %result
}

; Test with floating point special values
define float @test_ctselect_f32_special_values(i1 %cond) {
; X64-LABEL: test_ctselect_f32_special_values:
; X64:       # %bb.0:
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    movl $2143289344, %eax # imm = 0x7FC00000
; X64-NEXT:    movl $2139095040, %ecx # imm = 0x7F800000
; X64-NEXT:    cmovnel %eax, %ecx
; X64-NEXT:    movd %ecx, %xmm0
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_f32_special_values:
; X32:       # %bb.0:
; X32-NEXT:    pushl %edi
; X32-NEXT:    .cfi_def_cfa_offset 8
; X32-NEXT:    pushl %esi
; X32-NEXT:    .cfi_def_cfa_offset 12
; X32-NEXT:    pushl %eax
; X32-NEXT:    .cfi_def_cfa_offset 16
; X32-NEXT:    .cfi_offset %esi, -12
; X32-NEXT:    .cfi_offset %edi, -8
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    sete %al
; X32-NEXT:    movl {{\.?LCPI[0-9]+_[0-9]+}}, %ecx
; X32-NEXT:    movl {{\.?LCPI[0-9]+_[0-9]+}}, %edx
; X32-NEXT:    movb %al, %ah
; X32-NEXT:    movzbl %ah, %edi
; X32-NEXT:    negl %edi
; X32-NEXT:    movl %edx, %esi
; X32-NEXT:    andl %edi, %esi
; X32-NEXT:    notl %edi
; X32-NEXT:    andl %ecx, %edi
; X32-NEXT:    orl %edi, %esi
; X32-NEXT:    movl %esi, (%esp)
; X32-NEXT:    flds (%esp)
; X32-NEXT:    addl $4, %esp
; X32-NEXT:    .cfi_def_cfa_offset 12
; X32-NEXT:    popl %esi
; X32-NEXT:    .cfi_def_cfa_offset 8
; X32-NEXT:    popl %edi
; X32-NEXT:    .cfi_def_cfa_offset 4
; X32-NEXT:    retl
  %result = call float @llvm.ct.select.f32(i1 %cond, float 0x7FF8000000000000, float 0x7FF0000000000000)
  ret float %result
}

define double @test_ctselect_f64_special_values(i1 %cond) {
; X64-LABEL: test_ctselect_f64_special_values:
; X64:       # %bb.0:
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    movabsq $9221120237041090560, %rax # imm = 0x7FF8000000000000
; X64-NEXT:    movabsq $9218868437227405312, %rcx # imm = 0x7FF0000000000000
; X64-NEXT:    cmovneq %rax, %rcx
; X64-NEXT:    movq %rcx, %xmm0
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_f64_special_values:
; X32:       # %bb.0:
; X32-NEXT:    pushl %edi
; X32-NEXT:    .cfi_def_cfa_offset 8
; X32-NEXT:    pushl %esi
; X32-NEXT:    .cfi_def_cfa_offset 12
; X32-NEXT:    subl $24, %esp
; X32-NEXT:    .cfi_def_cfa_offset 36
; X32-NEXT:    .cfi_offset %esi, -12
; X32-NEXT:    .cfi_offset %edi, -8
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    flds {{\.?LCPI[0-9]+_[0-9]+}}
; X32-NEXT:    flds {{\.?LCPI[0-9]+_[0-9]+}}
; X32-NEXT:    sete %al
; X32-NEXT:    fxch %st(1)
; X32-NEXT:    fstpl {{[0-9]+}}(%esp)
; X32-NEXT:    fstpl (%esp)
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl (%esp), %edx
; X32-NEXT:    movb %al, %ah
; X32-NEXT:    movzbl %ah, %edi
; X32-NEXT:    negl %edi
; X32-NEXT:    movl %edx, %esi
; X32-NEXT:    andl %edi, %esi
; X32-NEXT:    notl %edi
; X32-NEXT:    andl %ecx, %edi
; X32-NEXT:    orl %edi, %esi
; X32-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NEXT:    movb %al, %ah
; X32-NEXT:    movzbl %ah, %edi
; X32-NEXT:    negl %edi
; X32-NEXT:    movl %edx, %esi
; X32-NEXT:    andl %edi, %esi
; X32-NEXT:    notl %edi
; X32-NEXT:    andl %ecx, %edi
; X32-NEXT:    orl %edi, %esi
; X32-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X32-NEXT:    fldl {{[0-9]+}}(%esp)
; X32-NEXT:    addl $24, %esp
; X32-NEXT:    .cfi_def_cfa_offset 12
; X32-NEXT:    popl %esi
; X32-NEXT:    .cfi_def_cfa_offset 8
; X32-NEXT:    popl %edi
; X32-NEXT:    .cfi_def_cfa_offset 4
; X32-NEXT:    retl
  %result = call double @llvm.ct.select.f64(i1 %cond, double 0x7FF8000000000000, double 0x7FF0000000000000)
  ret double %result
}

; Test with null pointers
define ptr @test_ctselect_null_ptr(i1 %cond, ptr %ptr) {
; X64-LABEL: test_ctselect_null_ptr:
; X64:       # %bb.0:
; X64-NEXT:    xorl %eax, %eax
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovneq %rsi, %rax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_null_ptr:
; X32:       # %bb.0:
; X32-NEXT:    xorl %eax, %eax
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %eax
; X32-NEXT:    retl
  %result = call ptr @llvm.ct.select.p0(i1 %cond, ptr %ptr, ptr null)
  ret ptr %result
}

; Test with function pointers
define ptr @test_ctselect_function_ptr(i1 %cond, ptr %func1, ptr %func2) {
; X64-LABEL: test_ctselect_function_ptr:
; X64:       # %bb.0:
; X64-NEXT:    movq %rdx, %rax
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovneq %rsi, %rax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_function_ptr:
; X32:       # %bb.0:
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %eax
; X32-NEXT:    retl
  %result = call ptr @llvm.ct.select.p0(i1 %cond, ptr %func1, ptr %func2)
  ret ptr %result
}

; Test with volatile loads
define i32 @test_ctselect_volatile_load(i1 %cond, ptr %p1, ptr %p2) {
; X64-LABEL: test_ctselect_volatile_load:
; X64:       # %bb.0:
; X64-NEXT:    movl (%rsi), %ecx
; X64-NEXT:    movl (%rdx), %eax
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovnel %ecx, %eax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_volatile_load:
; X32:       # %bb.0:
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl (%ecx), %ecx
; X32-NEXT:    movl (%eax), %eax
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel %ecx, %eax
; X32-NEXT:    retl
  %a = load volatile i32, ptr %p1
  %b = load volatile i32, ptr %p2
  %result = call i32 @llvm.ct.select.i32(i1 %cond, i32 %a, i32 %b)
  ret i32 %result
}

; Test with atomic loads
define i32 @test_ctselect_atomic_load(i1 %cond, ptr %p1, ptr %p2) {
; X64-LABEL: test_ctselect_atomic_load:
; X64:       # %bb.0:
; X64-NEXT:    movl (%rsi), %ecx
; X64-NEXT:    movl (%rdx), %eax
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovnel %ecx, %eax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_atomic_load:
; X32:       # %bb.0:
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl (%ecx), %ecx
; X32-NEXT:    movl (%eax), %eax
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel %ecx, %eax
; X32-NEXT:    retl
  %a = load atomic i32, ptr %p1 acquire, align 4
  %b = load atomic i32, ptr %p2 acquire, align 4
  %result = call i32 @llvm.ct.select.i32(i1 %cond, i32 %a, i32 %b)
  ret i32 %result
}

; Test with condition from icmp on pointers
define ptr @test_ctselect_ptr_cmp(ptr %p1, ptr %p2, ptr %a, ptr %b) {
; X64-LABEL: test_ctselect_ptr_cmp:
; X64:       # %bb.0:
; X64-NEXT:    movq %rcx, %rax
; X64-NEXT:    cmpq %rsi, %rdi
; X64-NEXT:    sete %cl
; X64-NEXT:    testb %cl, %cl
; X64-NEXT:    cmovneq %rdx, %rax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_ptr_cmp:
; X32:       # %bb.0:
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    cmpl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    sete %cl
; X32-NEXT:    testb %cl, %cl
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %eax
; X32-NEXT:    retl
  %cmp = icmp eq ptr %p1, %p2
  %result = call ptr @llvm.ct.select.p0(i1 %cmp, ptr %a, ptr %b)
  ret ptr %result
}

; Test with struct pointer types (struct types themselves may not be directly supported)
%struct.pair = type { i32, i32 }

define ptr @test_ctselect_struct_ptr(i1 %cond, ptr %a, ptr %b) {
; X64-LABEL: test_ctselect_struct_ptr:
; X64:       # %bb.0:
; X64-NEXT:    movq %rdx, %rax
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovneq %rsi, %rax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_struct_ptr:
; X32:       # %bb.0:
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %eax
; X32-NEXT:    retl
  %result = call ptr @llvm.ct.select.p0(i1 %cond, ptr %a, ptr %b)
  ret ptr %result
}

; Test with deeply nested conditions (stress test for instruction selection)
define i32 @test_ctselect_deeply_nested(i1 %c1, i1 %c2, i1 %c3, i1 %c4, i32 %a, i32 %b, i32 %c, i32 %d, i32 %e) {
; X64-LABEL: test_ctselect_deeply_nested:
; X64:       # %bb.0:
; X64-NEXT:    movl {{[0-9]+}}(%rsp), %eax
; X64-NEXT:    movl {{[0-9]+}}(%rsp), %r10d
; X64-NEXT:    movl {{[0-9]+}}(%rsp), %r11d
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovnel %r8d, %r9d
; X64-NEXT:    testb $1, %sil
; X64-NEXT:    cmovnel %r9d, %r11d
; X64-NEXT:    testb $1, %dl
; X64-NEXT:    cmovnel %r11d, %r10d
; X64-NEXT:    testb $1, %cl
; X64-NEXT:    cmovnel %r10d, %eax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_deeply_nested:
; X32:       # %bb.0:
; X32-NEXT:    pushl %esi
; X32-NEXT:    .cfi_def_cfa_offset 8
; X32-NEXT:    .cfi_offset %esi, -8
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel {{[0-9]+}}(%esp), %esi
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel %esi, %edx
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel %edx, %ecx
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel %ecx, %eax
; X32-NEXT:    popl %esi
; X32-NEXT:    .cfi_def_cfa_offset 4
; X32-NEXT:    retl
  %sel1 = call i32 @llvm.ct.select.i32(i1 %c1, i32 %a, i32 %b)
  %sel2 = call i32 @llvm.ct.select.i32(i1 %c2, i32 %sel1, i32 %c)
  %sel3 = call i32 @llvm.ct.select.i32(i1 %c3, i32 %sel2, i32 %d)
  %sel4 = call i32 @llvm.ct.select.i32(i1 %c4, i32 %sel3, i32 %e)
  ret i32 %sel4
}

; Test with misaligned loads
define i32 @test_ctselect_misaligned_load(i1 %cond, ptr %p1, ptr %p2) {
; X64-LABEL: test_ctselect_misaligned_load:
; X64:       # %bb.0:
; X64-NEXT:    movl (%rdx), %eax
; X64-NEXT:    testb $1, %dil
; X64-NEXT:    cmovnel (%rsi), %eax
; X64-NEXT:    retq
;
; X32-LABEL: test_ctselect_misaligned_load:
; X32:       # %bb.0:
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl (%eax), %eax
; X32-NEXT:    testb $1, {{[0-9]+}}(%esp)
; X32-NEXT:    cmovnel (%ecx), %eax
; X32-NEXT:    retl
  %a = load i32, ptr %p1, align 1
  %b = load i32, ptr %p2, align 1
  %result = call i32 @llvm.ct.select.i32(i1 %cond, i32 %a, i32 %b)
  ret i32 %result
}

; Declare the intrinsics
declare i1 @llvm.ct.select.i1(i1, i1, i1)
declare i128 @llvm.ct.select.i128(i1, i128, i128)
declare i32 @llvm.ct.select.i32(i1, i32, i32)
declare float @llvm.ct.select.f32(i1, float, float)
declare double @llvm.ct.select.f64(i1, double, double)
declare ptr @llvm.ct.select.p0(i1, ptr, ptr)
