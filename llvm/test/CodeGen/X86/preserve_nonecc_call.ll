; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=x86_64-unknown-unknown -mcpu=corei7 < %s | FileCheck %s --check-prefixes=X64
; RUN: llc -mtriple=i686-unknown-unknown < %s | FileCheck %s --check-prefixes=X86

; This test checks various function call behaviors between preserve_none and
; normal calling conventions.

declare preserve_nonecc void @callee(ptr)

; Normal caller calls preserve_none callee. Will not generated tail call because
; of incompatible calling convention. Callee saved registers are saved/restored
; around the call.
define void @caller1(ptr %a) {
; X64-LABEL: caller1:
; X64:       # %bb.0:
; X64-NEXT:    pushq %r15
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    pushq %r14
; X64-NEXT:    .cfi_def_cfa_offset 24
; X64-NEXT:    pushq %r13
; X64-NEXT:    .cfi_def_cfa_offset 32
; X64-NEXT:    pushq %r12
; X64-NEXT:    .cfi_def_cfa_offset 40
; X64-NEXT:    pushq %rax
; X64-NEXT:    .cfi_def_cfa_offset 48
; X64-NEXT:    .cfi_offset %r12, -40
; X64-NEXT:    .cfi_offset %r13, -32
; X64-NEXT:    .cfi_offset %r14, -24
; X64-NEXT:    .cfi_offset %r15, -16
; X64-NEXT:    movq %rdi, %r12
; X64-NEXT:    callq callee@PLT
; X64-NEXT:    addq $8, %rsp
; X64-NEXT:    .cfi_def_cfa_offset 40
; X64-NEXT:    popq %r12
; X64-NEXT:    .cfi_def_cfa_offset 32
; X64-NEXT:    popq %r13
; X64-NEXT:    .cfi_def_cfa_offset 24
; X64-NEXT:    popq %r14
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    popq %r15
; X64-NEXT:    .cfi_def_cfa_offset 8
; X64-NEXT:    retq
;
; X86-LABEL: caller1:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebx
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    pushl %edi
; X86-NEXT:    .cfi_def_cfa_offset 12
; X86-NEXT:    .cfi_offset %edi, -12
; X86-NEXT:    .cfi_offset %ebx, -8
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edi
; X86-NEXT:    calll callee@PLT
; X86-NEXT:    popl %edi
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    popl %ebx
; X86-NEXT:    .cfi_def_cfa_offset 4
; X86-NEXT:    retl
  tail call preserve_nonecc void @callee(ptr %a)
  ret void
}

; Preserve_none caller calls preserve_none callee. Same function body.
; The tail call is preserved. No registers are saved/restored around the call.
; Actually a simple jmp instruction is generated.
define preserve_nonecc void @caller2(ptr %a) {
; X64-LABEL: caller2:
; X64:       # %bb.0:
; X64-NEXT:    jmp callee@PLT # TAILCALL
;
; X86-LABEL: caller2:
; X86:       # %bb.0:
; X86-NEXT:    jmp callee@PLT # TAILCALL
  tail call preserve_nonecc void @callee(ptr %a)
  ret void
}

; Preserve_none function can use more registers to pass parameters.
declare preserve_nonecc i64 @callee_with_11_params(i64 %a1, i64 %a2, i64 %a3, i64 %a4, i64 %a5, i64 %a6, i64 %a7, i64 %a8, i64 %a9, i64 %a10, i64 %a11)
define preserve_nonecc i64 @callee_with_12_params(i64 %a1, i64 %a2, i64 %a3, i64 %a4, i64 %a5, i64 %a6, i64 %a7, i64 %a8, i64 %a9, i64 %a10, i64 %a11, i64 %a12) {
; X64-LABEL: callee_with_12_params:
; X64:       # %bb.0:
; X64-NEXT:    pushq %rax
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    movq %r13, %r12
; X64-NEXT:    movq %r14, %r13
; X64-NEXT:    movq %r15, %r14
; X64-NEXT:    movq %rdi, %r15
; X64-NEXT:    movq %rsi, %rdi
; X64-NEXT:    movq %rdx, %rsi
; X64-NEXT:    movq %rcx, %rdx
; X64-NEXT:    movq %r8, %rcx
; X64-NEXT:    movq %r9, %r8
; X64-NEXT:    movq %r11, %r9
; X64-NEXT:    movq %rax, %r11
; X64-NEXT:    callq callee_with_11_params@PLT
; X64-NEXT:    popq %rcx
; X64-NEXT:    .cfi_def_cfa_offset 8
; X64-NEXT:    retq
;
; X86-LABEL: callee_with_12_params:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %eax, %edi
; X86-NEXT:    movl %ecx, %eax
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    calll callee_with_11_params@PLT
; X86-NEXT:    addl $76, %esp
; X86-NEXT:    .cfi_adjust_cfa_offset -76
; X86-NEXT:    retl
  %ret = call preserve_nonecc i64 @callee_with_11_params(i64 %a2, i64 %a3, i64 %a4, i64 %a5, i64 %a6, i64 %a7, i64 %a8, i64 %a9, i64 %a10, i64 %a11, i64 %a12)
  ret i64 %ret
}

define i64 @caller3() {
; X64-LABEL: caller3:
; X64:       # %bb.0:
; X64-NEXT:    pushq %r15
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    pushq %r14
; X64-NEXT:    .cfi_def_cfa_offset 24
; X64-NEXT:    pushq %r13
; X64-NEXT:    .cfi_def_cfa_offset 32
; X64-NEXT:    pushq %r12
; X64-NEXT:    .cfi_def_cfa_offset 40
; X64-NEXT:    pushq %rax
; X64-NEXT:    .cfi_def_cfa_offset 48
; X64-NEXT:    .cfi_offset %r12, -40
; X64-NEXT:    .cfi_offset %r13, -32
; X64-NEXT:    .cfi_offset %r14, -24
; X64-NEXT:    .cfi_offset %r15, -16
; X64-NEXT:    movl $1, %r12d
; X64-NEXT:    movl $2, %r13d
; X64-NEXT:    movl $3, %r14d
; X64-NEXT:    movl $4, %r15d
; X64-NEXT:    movl $5, %edi
; X64-NEXT:    movl $6, %esi
; X64-NEXT:    movl $7, %edx
; X64-NEXT:    movl $8, %ecx
; X64-NEXT:    movl $9, %r8d
; X64-NEXT:    movl $10, %r9d
; X64-NEXT:    movl $11, %r11d
; X64-NEXT:    movl $12, %eax
; X64-NEXT:    callq callee_with_12_params@PLT
; X64-NEXT:    addq $8, %rsp
; X64-NEXT:    .cfi_def_cfa_offset 40
; X64-NEXT:    popq %r12
; X64-NEXT:    .cfi_def_cfa_offset 32
; X64-NEXT:    popq %r13
; X64-NEXT:    .cfi_def_cfa_offset 24
; X64-NEXT:    popq %r14
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    popq %r15
; X64-NEXT:    .cfi_def_cfa_offset 8
; X64-NEXT:    retq
;
; X86-LABEL: caller3:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebx
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    pushl %edi
; X86-NEXT:    .cfi_def_cfa_offset 12
; X86-NEXT:    .cfi_offset %edi, -12
; X86-NEXT:    .cfi_offset %ebx, -8
; X86-NEXT:    movl $1, %edi
; X86-NEXT:    xorl %edx, %edx
; X86-NEXT:    movl $2, %eax
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $12
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $11
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $10
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $9
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $8
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $7
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $6
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $5
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $4
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $3
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $0
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    calll callee_with_12_params@PLT
; X86-NEXT:    addl $84, %esp
; X86-NEXT:    .cfi_adjust_cfa_offset -84
; X86-NEXT:    popl %edi
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    popl %ebx
; X86-NEXT:    .cfi_def_cfa_offset 4
; X86-NEXT:    retl
  %ret = call preserve_nonecc i64 @callee_with_12_params(i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7, i64 8, i64 9, i64 10, i64 11, i64 12)
  ret i64 %ret
}

declare preserve_nonecc i32 @callee_with_4_params(i32 %a1, i32 %a2, i32 %a3, i32 %a4)
define preserve_nonecc i32 @callee_with_5_params(i32 %a1, i32 %a2, i32 %a3, i32 %a4, i32 %a5) {
; X64-LABEL: callee_with_5_params:
; X64:       # %bb.0:
; X64-NEXT:    pushq %rax
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    movl %r13d, %r12d
; X64-NEXT:    movl %r14d, %r13d
; X64-NEXT:    movl %r15d, %r14d
; X64-NEXT:    movl %edi, %r15d
; X64-NEXT:    callq callee_with_4_params@PLT
; X64-NEXT:    popq %rcx
; X64-NEXT:    .cfi_def_cfa_offset 8
; X64-NEXT:    retq
;
; X86-LABEL: callee_with_5_params:
; X86:       # %bb.0:
; X86-NEXT:    movl %edx, %edi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %eax, %edx
; X86-NEXT:    movl %ecx, %eax
; X86-NEXT:    pushl {{[0-9]+}}(%esp)
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    calll callee_with_4_params@PLT
; X86-NEXT:    addl $4, %esp
; X86-NEXT:    .cfi_adjust_cfa_offset -4
; X86-NEXT:    retl
  %ret = call preserve_nonecc i32 @callee_with_4_params(i32 %a2, i32 %a3, i32 %a4, i32 %a5)
  ret i32 %ret
}

define i32 @caller4() {
; X64-LABEL: caller4:
; X64:       # %bb.0:
; X64-NEXT:    pushq %r15
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    pushq %r14
; X64-NEXT:    .cfi_def_cfa_offset 24
; X64-NEXT:    pushq %r13
; X64-NEXT:    .cfi_def_cfa_offset 32
; X64-NEXT:    pushq %r12
; X64-NEXT:    .cfi_def_cfa_offset 40
; X64-NEXT:    pushq %rax
; X64-NEXT:    .cfi_def_cfa_offset 48
; X64-NEXT:    .cfi_offset %r12, -40
; X64-NEXT:    .cfi_offset %r13, -32
; X64-NEXT:    .cfi_offset %r14, -24
; X64-NEXT:    .cfi_offset %r15, -16
; X64-NEXT:    movl $1, %r12d
; X64-NEXT:    movl $2, %r13d
; X64-NEXT:    movl $3, %r14d
; X64-NEXT:    movl $4, %r15d
; X64-NEXT:    movl $5, %edi
; X64-NEXT:    callq callee_with_5_params@PLT
; X64-NEXT:    addq $8, %rsp
; X64-NEXT:    .cfi_def_cfa_offset 40
; X64-NEXT:    popq %r12
; X64-NEXT:    .cfi_def_cfa_offset 32
; X64-NEXT:    popq %r13
; X64-NEXT:    .cfi_def_cfa_offset 24
; X64-NEXT:    popq %r14
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    popq %r15
; X64-NEXT:    .cfi_def_cfa_offset 8
; X64-NEXT:    retq
;
; X86-LABEL: caller4:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebx
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    pushl %edi
; X86-NEXT:    .cfi_def_cfa_offset 12
; X86-NEXT:    .cfi_offset %edi, -12
; X86-NEXT:    .cfi_offset %ebx, -8
; X86-NEXT:    movl $1, %edi
; X86-NEXT:    movl $2, %edx
; X86-NEXT:    movl $3, %eax
; X86-NEXT:    pushl $5
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    pushl $4
; X86-NEXT:    .cfi_adjust_cfa_offset 4
; X86-NEXT:    calll callee_with_5_params@PLT
; X86-NEXT:    addl $8, %esp
; X86-NEXT:    .cfi_adjust_cfa_offset -8
; X86-NEXT:    popl %edi
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    popl %ebx
; X86-NEXT:    .cfi_def_cfa_offset 4
; X86-NEXT:    retl
  %ret = call preserve_nonecc i32 @callee_with_5_params(i32 1, i32 2, i32 3, i32 4, i32 5)
  ret i32 %ret
}

; Non-volatile registers are used to pass the first few parameters.
declare void @boring()
declare preserve_nonecc void @continuation4(ptr, ptr, ptr, ptr)
define preserve_nonecc void @entry4(ptr %a, ptr %b, ptr %c, ptr %d) {
; X64-LABEL: entry4:
; X64:       # %bb.0:
; X64-NEXT:    pushq %rax
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    callq boring@PLT
; X64-NEXT:    popq %rax
; X64-NEXT:    .cfi_def_cfa_offset 8
; X64-NEXT:    jmp continuation4@PLT # TAILCALL
;
; X86-LABEL: entry4:
; X86:       # %bb.0:
; X86-NEXT:    pushl %esi
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    pushl %ebp
; X86-NEXT:    .cfi_def_cfa_offset 12
; X86-NEXT:    .cfi_offset %ebp, -12
; X86-NEXT:    .cfi_offset %esi, -8
; X86-NEXT:    movl %eax, %ebx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-NEXT:    calll boring@PLT
; X86-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NEXT:    movl %esi, %edx
; X86-NEXT:    movl %ebx, %eax
; X86-NEXT:    popl %ebp
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    popl %esi
; X86-NEXT:    .cfi_def_cfa_offset 4
; X86-NEXT:    jmp continuation4@PLT # TAILCALL
  call void @boring()
  musttail call preserve_nonecc void @continuation4(ptr %a, ptr %b, ptr %c, ptr %d)
  ret void
}

declare preserve_nonecc void @continuation1(ptr, ptr)
define preserve_nonecc void @entry1(ptr %a) {
; X64-LABEL: entry1:
; X64:       # %bb.0:
; X64-NEXT:    pushq %rax
; X64-NEXT:    .cfi_def_cfa_offset 16
; X64-NEXT:    callq boring@PLT
; X64-NEXT:    popq %rax
; X64-NEXT:    .cfi_def_cfa_offset 8
; X64-NEXT:    jmp continuation1@PLT # TAILCALL
;
; X86-LABEL: entry1:
; X86:       # %bb.0:
; X86-NEXT:    calll boring@PLT
; X86-NEXT:    jmp continuation1@PLT # TAILCALL
  call void @boring()
  musttail call preserve_nonecc void @continuation1(ptr %a)
  ret void
}
