; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-- -mattr=+sse4.1,+fast-hops | FileCheck %s --check-prefixes=SSE41
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx2,+fast-hops | FileCheck %s --check-prefixes=AVX2

define { i16, i16 } @test_reduce_v16i16_with_umin(<16 x i16> %x, <16 x i16> %y) {
; SSE41-LABEL: test_reduce_v16i16_with_umin:
; SSE41:       # %bb.0:
; SSE41-NEXT:    movdqa %xmm0, %xmm4
; SSE41-NEXT:    pminuw %xmm1, %xmm4
; SSE41-NEXT:    phminposuw %xmm4, %xmm4
; SSE41-NEXT:    movd %xmm4, %eax
; SSE41-NEXT:    pshuflw {{.*#+}} xmm4 = xmm4[0,0,0,0,4,5,6,7]
; SSE41-NEXT:    pshufd {{.*#+}} xmm4 = xmm4[0,1,0,1]
; SSE41-NEXT:    pcmpeqw %xmm4, %xmm1
; SSE41-NEXT:    pcmpeqd %xmm5, %xmm5
; SSE41-NEXT:    pxor %xmm5, %xmm1
; SSE41-NEXT:    por %xmm3, %xmm1
; SSE41-NEXT:    pcmpeqw %xmm4, %xmm0
; SSE41-NEXT:    pxor %xmm5, %xmm0
; SSE41-NEXT:    por %xmm2, %xmm0
; SSE41-NEXT:    pminuw %xmm1, %xmm0
; SSE41-NEXT:    phminposuw %xmm0, %xmm0
; SSE41-NEXT:    movd %xmm0, %edx
; SSE41-NEXT:    # kill: def $ax killed $ax killed $eax
; SSE41-NEXT:    # kill: def $dx killed $dx killed $edx
; SSE41-NEXT:    retq
;
; AVX2-LABEL: test_reduce_v16i16_with_umin:
; AVX2:       # %bb.0:
; AVX2-NEXT:    vextracti128 $1, %ymm0, %xmm2
; AVX2-NEXT:    vpminuw %xmm2, %xmm0, %xmm2
; AVX2-NEXT:    vphminposuw %xmm2, %xmm2
; AVX2-NEXT:    vmovd %xmm2, %eax
; AVX2-NEXT:    vpbroadcastw %xmm2, %ymm2
; AVX2-NEXT:    vpcmpeqw %ymm2, %ymm0, %ymm0
; AVX2-NEXT:    vpcmpeqd %ymm2, %ymm2, %ymm2
; AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
; AVX2-NEXT:    vpor %ymm1, %ymm0, %ymm0
; AVX2-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX2-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX2-NEXT:    vphminposuw %xmm0, %xmm0
; AVX2-NEXT:    vmovd %xmm0, %edx
; AVX2-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX2-NEXT:    # kill: def $dx killed $dx killed $edx
; AVX2-NEXT:    vzeroupper
; AVX2-NEXT:    retq
  %min_x = tail call i16 @llvm.vector.reduce.umin.v16i16(<16 x i16> %x)
  %min_x_vec = insertelement <1 x i16> poison, i16 %min_x, i64 0
  %min_x_splat = shufflevector <1 x i16> %min_x_vec, <1 x i16> poison, <16 x i32> zeroinitializer
  %cmp = icmp eq <16 x i16> %x, %min_x_splat
  %select = select <16 x i1> %cmp, <16 x i16> %y, <16 x i16> splat (i16 -1)
  %select_min = tail call i16 @llvm.vector.reduce.umin.v16i16(<16 x i16> %select)
  %ret_0 = insertvalue { i16, i16 } poison, i16 %min_x, 0
  %ret = insertvalue { i16, i16 } %ret_0, i16 %select_min, 1
  ret { i16, i16 } %ret
}

define { i16, i16 } @test_reduce_v16i16_with_add(<16 x i16> %x, <16 x i16> %y) {
; SSE41-LABEL: test_reduce_v16i16_with_add:
; SSE41:       # %bb.0: # %start
; SSE41-NEXT:    movdqa %xmm1, %xmm4
; SSE41-NEXT:    phaddw %xmm0, %xmm4
; SSE41-NEXT:    phaddw %xmm4, %xmm4
; SSE41-NEXT:    phaddw %xmm4, %xmm4
; SSE41-NEXT:    phaddw %xmm4, %xmm4
; SSE41-NEXT:    movd %xmm4, %eax
; SSE41-NEXT:    pshuflw {{.*#+}} xmm4 = xmm4[0,0,0,0,4,5,6,7]
; SSE41-NEXT:    pshufd {{.*#+}} xmm4 = xmm4[0,1,0,1]
; SSE41-NEXT:    pcmpeqw %xmm4, %xmm1
; SSE41-NEXT:    pcmpeqd %xmm5, %xmm5
; SSE41-NEXT:    pxor %xmm5, %xmm1
; SSE41-NEXT:    por %xmm3, %xmm1
; SSE41-NEXT:    pcmpeqw %xmm4, %xmm0
; SSE41-NEXT:    pxor %xmm5, %xmm0
; SSE41-NEXT:    por %xmm2, %xmm0
; SSE41-NEXT:    pminuw %xmm1, %xmm0
; SSE41-NEXT:    phminposuw %xmm0, %xmm0
; SSE41-NEXT:    movd %xmm0, %edx
; SSE41-NEXT:    # kill: def $ax killed $ax killed $eax
; SSE41-NEXT:    # kill: def $dx killed $dx killed $edx
; SSE41-NEXT:    retq
;
; AVX2-LABEL: test_reduce_v16i16_with_add:
; AVX2:       # %bb.0: # %start
; AVX2-NEXT:    vextracti128 $1, %ymm0, %xmm2
; AVX2-NEXT:    vphaddw %xmm0, %xmm2, %xmm2
; AVX2-NEXT:    vphaddw %xmm2, %xmm2, %xmm2
; AVX2-NEXT:    vphaddw %xmm2, %xmm2, %xmm2
; AVX2-NEXT:    vphaddw %xmm2, %xmm2, %xmm2
; AVX2-NEXT:    vmovd %xmm2, %eax
; AVX2-NEXT:    vpbroadcastw %xmm2, %ymm2
; AVX2-NEXT:    vpcmpeqw %ymm2, %ymm0, %ymm0
; AVX2-NEXT:    vpcmpeqd %ymm2, %ymm2, %ymm2
; AVX2-NEXT:    vpxor %ymm2, %ymm0, %ymm0
; AVX2-NEXT:    vpor %ymm1, %ymm0, %ymm0
; AVX2-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX2-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX2-NEXT:    vphminposuw %xmm0, %xmm0
; AVX2-NEXT:    vmovd %xmm0, %edx
; AVX2-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX2-NEXT:    # kill: def $dx killed $dx killed $edx
; AVX2-NEXT:    vzeroupper
; AVX2-NEXT:    retq
start:
  %sum_x = tail call i16 @llvm.vector.reduce.add.v16i16(<16 x i16> %x)
  %sum_x_vec = insertelement <1 x i16> poison, i16 %sum_x, i64 0
  %sum_x_splat = shufflevector <1 x i16> %sum_x_vec, <1 x i16> poison, <16 x i32> zeroinitializer
  %cmp = icmp eq <16 x i16> %x, %sum_x_splat
  %select = select <16 x i1> %cmp, <16 x i16> %y, <16 x i16> splat (i16 -1)
  %select_min = tail call i16 @llvm.vector.reduce.umin.v16i16(<16 x i16> %select)
  %ret_0 = insertvalue { i16, i16 } poison, i16 %sum_x, 0
  %ret = insertvalue { i16, i16 } %ret_0, i16 %select_min, 1
  ret { i16, i16 } %ret
}
