; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc < %s -mtriple=x86_64-- -mcpu=x86-64-v3 | FileCheck %s
; RUN: llc < %s -mtriple=x86_64-- -mcpu=x86-64-v4 | FileCheck %s

define i256 @PR173924(<8 x i256> %a0) {
; CHECK-LABEL: PR173924:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movq %rdi, %rax
; CHECK-NEXT:    movq {{[0-9]+}}(%rsp), %rcx
; CHECK-NEXT:    movq {{[0-9]+}}(%rsp), %rdi
; CHECK-NEXT:    movq {{[0-9]+}}(%rsp), %r8
; CHECK-NEXT:    movq {{[0-9]+}}(%rsp), %rdx
; CHECK-NEXT:    movq {{[0-9]+}}(%rsp), %r10
; CHECK-NEXT:    andl $1, %r10d
; CHECK-NEXT:    andl $1, %r9d
; CHECK-NEXT:    addq %r10, %r9
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = [1,0,0,0]
; CHECK-NEXT:    vpand {{[0-9]+}}(%rsp), %xmm0, %xmm1
; CHECK-NEXT:    vmovq %xmm1, %r10
; CHECK-NEXT:    andl $1, %edx
; CHECK-NEXT:    addq %r10, %rdx
; CHECK-NEXT:    addq %r9, %rdx
; CHECK-NEXT:    andl $1, %r8d
; CHECK-NEXT:    andl $1, %esi
; CHECK-NEXT:    addq %r8, %rsi
; CHECK-NEXT:    andl $1, %edi
; CHECK-NEXT:    andl $1, %ecx
; CHECK-NEXT:    addq %rdi, %rcx
; CHECK-NEXT:    addq %rsi, %rcx
; CHECK-NEXT:    addq %rdx, %rcx
; CHECK-NEXT:    vmovq %rcx, %xmm1
; CHECK-NEXT:    vpblendd {{.*#+}} ymm0 = ymm1[0,1],ymm0[2,3,4,5,6,7]
; CHECK-NEXT:    vmovdqu %ymm0, (%rax)
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
  %m = and <8 x i256> %a0, splat (i256 1)
  %r = call i256 @llvm.vector.reduce.add.v8i256(<8 x i256> %m)
  ret i256 %r
}
