; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=i686-unknown-linux-gnu < %s | FileCheck %s --check-prefixes=X86
; RUN: llc -mtriple=x86_64-unknown-linux-gnu < %s | FileCheck %s --check-prefixes=X64
; RUN: llc -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2 < %s | FileCheck %s --check-prefixes=X64,SSE2
; RUN: llc -mtriple=x86_64-unknown-linux-gnu -mattr=+sse4.1 < %s | FileCheck %s --check-prefixes=X64,SSE41
; RUN: llc -mtriple=x86_64-unknown-linux-gnu -mattr=+avx < %s | FileCheck %s --check-prefixes=X64,AVX1
; RUN: llc -mtriple=x86_64-unknown-linux-gnu -mattr=+avx2 < %s | FileCheck %s --check-prefixes=X64,AVX2
; RUN: llc -mtriple=x86_64-unknown-linux-gnu -mattr=+avx512f,+avx512vl < %s | FileCheck %s --check-prefixes=X64,AVX512VL

define i1 @test_urem_odd(i13 %X) nounwind {
; X86-LABEL: test_urem_odd:
; X86:       # %bb.0:
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    andl $8191, %eax # imm = 0x1FFF
; X86-NEXT:    imull $-13107, %eax, %eax # imm = 0xCCCD
; X86-NEXT:    movzwl %ax, %eax
; X86-NEXT:    cmpl $13108, %eax # imm = 0x3334
; X86-NEXT:    setb %al
; X86-NEXT:    retl
;
; X64-LABEL: test_urem_odd:
; X64:       # %bb.0:
; X64-NEXT:    andl $8191, %edi # imm = 0x1FFF
; X64-NEXT:    imull $-13107, %edi, %eax # imm = 0xCCCD
; X64-NEXT:    movzwl %ax, %eax
; X64-NEXT:    cmpl $13108, %eax # imm = 0x3334
; X64-NEXT:    setb %al
; X64-NEXT:    retq
  %urem = urem i13 %X, 5
  %cmp = icmp eq i13 %urem, 0
  ret i1 %cmp
}

define i1 @test_urem_even(i27 %X) nounwind {
; X86-LABEL: test_urem_even:
; X86:       # %bb.0:
; X86-NEXT:    movl $134217727, %eax # imm = 0x7FFFFFF
; X86-NEXT:    andl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    imull $-1227133513, %eax, %eax # imm = 0xB6DB6DB7
; X86-NEXT:    rorl %eax
; X86-NEXT:    cmpl $306783379, %eax # imm = 0x12492493
; X86-NEXT:    setb %al
; X86-NEXT:    retl
;
; X64-LABEL: test_urem_even:
; X64:       # %bb.0:
; X64-NEXT:    andl $134217727, %edi # imm = 0x7FFFFFF
; X64-NEXT:    imull $-1227133513, %edi, %eax # imm = 0xB6DB6DB7
; X64-NEXT:    rorl %eax
; X64-NEXT:    cmpl $306783379, %eax # imm = 0x12492493
; X64-NEXT:    setb %al
; X64-NEXT:    retq
  %urem = urem i27 %X, 14
  %cmp = icmp eq i27 %urem, 0
  ret i1 %cmp
}

define i1 @test_urem_odd_setne(i4 %X) nounwind {
; X86-LABEL: test_urem_odd_setne:
; X86:       # %bb.0:
; X86-NEXT:    movb {{[0-9]+}}(%esp), %al
; X86-NEXT:    andb $15, %al
; X86-NEXT:    movzbl %al, %eax
; X86-NEXT:    imull $-51, %eax, %eax
; X86-NEXT:    cmpb $51, %al
; X86-NEXT:    seta %al
; X86-NEXT:    retl
;
; X64-LABEL: test_urem_odd_setne:
; X64:       # %bb.0:
; X64-NEXT:    andb $15, %dil
; X64-NEXT:    movzbl %dil, %eax
; X64-NEXT:    imull $-51, %eax, %eax
; X64-NEXT:    cmpb $51, %al
; X64-NEXT:    seta %al
; X64-NEXT:    retq
  %urem = urem i4 %X, 5
  %cmp = icmp ne i4 %urem, 0
  ret i1 %cmp
}

define i1 @test_urem_negative_odd(i9 %X) nounwind {
; X86-LABEL: test_urem_negative_odd:
; X86:       # %bb.0:
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    andl $511, %eax # imm = 0x1FF
; X86-NEXT:    imull $-7885, %eax, %eax # imm = 0xE133
; X86-NEXT:    movzwl %ax, %eax
; X86-NEXT:    cmpl $129, %eax
; X86-NEXT:    seta %al
; X86-NEXT:    retl
;
; X64-LABEL: test_urem_negative_odd:
; X64:       # %bb.0:
; X64-NEXT:    andl $511, %edi # imm = 0x1FF
; X64-NEXT:    imull $-7885, %edi, %eax # imm = 0xE133
; X64-NEXT:    movzwl %ax, %eax
; X64-NEXT:    cmpl $129, %eax
; X64-NEXT:    seta %al
; X64-NEXT:    retq
  %urem = urem i9 %X, -5
  %cmp = icmp ne i9 %urem, 0
  ret i1 %cmp
}

define <3 x i1> @test_urem_vec(<3 x i11> %X) nounwind {
; X86-LABEL: test_urem_vec:
; X86:       # %bb.0:
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    andl $2047, %edx # imm = 0x7FF
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    andl $2047, %eax # imm = 0x7FF
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    andl $2047, %ecx # imm = 0x7FF
; X86-NEXT:    imull $-5325, %ecx, %ecx # imm = 0xEB33
; X86-NEXT:    addl $10650, %ecx # imm = 0x299A
; X86-NEXT:    cmpw $32, %cx
; X86-NEXT:    seta %cl
; X86-NEXT:    imull $-21845, %eax, %eax # imm = 0xAAAB
; X86-NEXT:    rorw %ax
; X86-NEXT:    movzwl %ax, %eax
; X86-NEXT:    cmpl $10922, %eax # imm = 0x2AAA
; X86-NEXT:    seta %al
; X86-NEXT:    imull $28087, %edx, %edx # imm = 0x6DB7
; X86-NEXT:    addl $-28087, %edx # imm = 0x9249
; X86-NEXT:    movzwl %dx, %edx
; X86-NEXT:    cmpl $9362, %edx # imm = 0x2492
; X86-NEXT:    seta %dl
; X86-NEXT:    retl
;
; SSE2-LABEL: test_urem_vec:
; SSE2:       # %bb.0:
; SSE2-NEXT:    movl %esi, %eax
; SSE2-NEXT:    andl $2047, %eax # imm = 0x7FF
; SSE2-NEXT:    imull $9363, %eax, %ecx # imm = 0x2493
; SSE2-NEXT:    shrl $16, %ecx
; SSE2-NEXT:    subl %ecx, %eax
; SSE2-NEXT:    movzwl %ax, %eax
; SSE2-NEXT:    shrl %eax
; SSE2-NEXT:    addl %ecx, %eax
; SSE2-NEXT:    shrl $2, %eax
; SSE2-NEXT:    leal (,%rax,8), %ecx
; SSE2-NEXT:    subl %ecx, %eax
; SSE2-NEXT:    addl %esi, %eax
; SSE2-NEXT:    andl $2047, %edi # imm = 0x7FF
; SSE2-NEXT:    imull $43691, %edi, %ecx # imm = 0xAAAB
; SSE2-NEXT:    shrl $17, %ecx
; SSE2-NEXT:    andl $-2, %ecx
; SSE2-NEXT:    leal (%rcx,%rcx,2), %ecx
; SSE2-NEXT:    subl %ecx, %edi
; SSE2-NEXT:    movd %edi, %xmm0
; SSE2-NEXT:    pinsrw $2, %eax, %xmm0
; SSE2-NEXT:    movl %edx, %eax
; SSE2-NEXT:    andl $2047, %eax # imm = 0x7FF
; SSE2-NEXT:    imull $161, %eax, %ecx
; SSE2-NEXT:    shrl $16, %ecx
; SSE2-NEXT:    subl %ecx, %eax
; SSE2-NEXT:    movzwl %ax, %eax
; SSE2-NEXT:    shrl %eax
; SSE2-NEXT:    addl %ecx, %eax
; SSE2-NEXT:    shrl $10, %eax
; SSE2-NEXT:    imull $2043, %eax, %eax # imm = 0x7FB
; SSE2-NEXT:    subl %eax, %edx
; SSE2-NEXT:    pinsrw $4, %edx, %xmm0
; SSE2-NEXT:    pand {{.*}}(%rip), %xmm0
; SSE2-NEXT:    pcmpeqd {{.*}}(%rip), %xmm0
; SSE2-NEXT:    pcmpeqd %xmm1, %xmm1
; SSE2-NEXT:    pxor %xmm0, %xmm1
; SSE2-NEXT:    movdqa %xmm1, -{{[0-9]+}}(%rsp)
; SSE2-NEXT:    movb -{{[0-9]+}}(%rsp), %al
; SSE2-NEXT:    movb -{{[0-9]+}}(%rsp), %dl
; SSE2-NEXT:    movb -{{[0-9]+}}(%rsp), %cl
; SSE2-NEXT:    retq
;
; SSE41-LABEL: test_urem_vec:
; SSE41:       # %bb.0:
; SSE41-NEXT:    movl %esi, %eax
; SSE41-NEXT:    andl $2047, %eax # imm = 0x7FF
; SSE41-NEXT:    imull $9363, %eax, %ecx # imm = 0x2493
; SSE41-NEXT:    shrl $16, %ecx
; SSE41-NEXT:    subl %ecx, %eax
; SSE41-NEXT:    movzwl %ax, %eax
; SSE41-NEXT:    shrl %eax
; SSE41-NEXT:    addl %ecx, %eax
; SSE41-NEXT:    shrl $2, %eax
; SSE41-NEXT:    leal (,%rax,8), %ecx
; SSE41-NEXT:    subl %ecx, %eax
; SSE41-NEXT:    addl %esi, %eax
; SSE41-NEXT:    andl $2047, %edi # imm = 0x7FF
; SSE41-NEXT:    imull $43691, %edi, %ecx # imm = 0xAAAB
; SSE41-NEXT:    shrl $17, %ecx
; SSE41-NEXT:    andl $-2, %ecx
; SSE41-NEXT:    leal (%rcx,%rcx,2), %ecx
; SSE41-NEXT:    subl %ecx, %edi
; SSE41-NEXT:    movd %edi, %xmm0
; SSE41-NEXT:    pinsrw $2, %eax, %xmm0
; SSE41-NEXT:    movl %edx, %eax
; SSE41-NEXT:    andl $2047, %eax # imm = 0x7FF
; SSE41-NEXT:    imull $161, %eax, %ecx
; SSE41-NEXT:    shrl $16, %ecx
; SSE41-NEXT:    subl %ecx, %eax
; SSE41-NEXT:    movzwl %ax, %eax
; SSE41-NEXT:    shrl %eax
; SSE41-NEXT:    addl %ecx, %eax
; SSE41-NEXT:    shrl $10, %eax
; SSE41-NEXT:    imull $2043, %eax, %eax # imm = 0x7FB
; SSE41-NEXT:    subl %eax, %edx
; SSE41-NEXT:    pinsrw $4, %edx, %xmm0
; SSE41-NEXT:    pand {{.*}}(%rip), %xmm0
; SSE41-NEXT:    pcmpeqd {{.*}}(%rip), %xmm0
; SSE41-NEXT:    pcmpeqd %xmm1, %xmm1
; SSE41-NEXT:    pxor %xmm0, %xmm1
; SSE41-NEXT:    movd %xmm1, %eax
; SSE41-NEXT:    pextrb $4, %xmm1, %edx
; SSE41-NEXT:    pextrb $8, %xmm1, %ecx
; SSE41-NEXT:    # kill: def $al killed $al killed $eax
; SSE41-NEXT:    # kill: def $dl killed $dl killed $edx
; SSE41-NEXT:    # kill: def $cl killed $cl killed $ecx
; SSE41-NEXT:    retq
;
; AVX1-LABEL: test_urem_vec:
; AVX1:       # %bb.0:
; AVX1-NEXT:    movl %esi, %eax
; AVX1-NEXT:    andl $2047, %eax # imm = 0x7FF
; AVX1-NEXT:    imull $9363, %eax, %ecx # imm = 0x2493
; AVX1-NEXT:    shrl $16, %ecx
; AVX1-NEXT:    subl %ecx, %eax
; AVX1-NEXT:    movzwl %ax, %eax
; AVX1-NEXT:    shrl %eax
; AVX1-NEXT:    addl %ecx, %eax
; AVX1-NEXT:    shrl $2, %eax
; AVX1-NEXT:    leal (,%rax,8), %ecx
; AVX1-NEXT:    subl %ecx, %eax
; AVX1-NEXT:    addl %esi, %eax
; AVX1-NEXT:    andl $2047, %edi # imm = 0x7FF
; AVX1-NEXT:    imull $43691, %edi, %ecx # imm = 0xAAAB
; AVX1-NEXT:    shrl $17, %ecx
; AVX1-NEXT:    andl $-2, %ecx
; AVX1-NEXT:    leal (%rcx,%rcx,2), %ecx
; AVX1-NEXT:    subl %ecx, %edi
; AVX1-NEXT:    vmovd %edi, %xmm0
; AVX1-NEXT:    vpinsrw $2, %eax, %xmm0, %xmm0
; AVX1-NEXT:    movl %edx, %eax
; AVX1-NEXT:    andl $2047, %eax # imm = 0x7FF
; AVX1-NEXT:    imull $161, %eax, %ecx
; AVX1-NEXT:    shrl $16, %ecx
; AVX1-NEXT:    subl %ecx, %eax
; AVX1-NEXT:    movzwl %ax, %eax
; AVX1-NEXT:    shrl %eax
; AVX1-NEXT:    addl %ecx, %eax
; AVX1-NEXT:    shrl $10, %eax
; AVX1-NEXT:    imull $2043, %eax, %eax # imm = 0x7FB
; AVX1-NEXT:    subl %eax, %edx
; AVX1-NEXT:    vpinsrw $4, %edx, %xmm0, %xmm0
; AVX1-NEXT:    vpand {{.*}}(%rip), %xmm0, %xmm0
; AVX1-NEXT:    vpcmpeqd {{.*}}(%rip), %xmm0, %xmm0
; AVX1-NEXT:    vpcmpeqd %xmm1, %xmm1, %xmm1
; AVX1-NEXT:    vpxor %xmm1, %xmm0, %xmm0
; AVX1-NEXT:    vmovd %xmm0, %eax
; AVX1-NEXT:    vpextrb $4, %xmm0, %edx
; AVX1-NEXT:    vpextrb $8, %xmm0, %ecx
; AVX1-NEXT:    # kill: def $al killed $al killed $eax
; AVX1-NEXT:    # kill: def $dl killed $dl killed $edx
; AVX1-NEXT:    # kill: def $cl killed $cl killed $ecx
; AVX1-NEXT:    retq
;
; AVX2-LABEL: test_urem_vec:
; AVX2:       # %bb.0:
; AVX2-NEXT:    andl $2047, %esi # imm = 0x7FF
; AVX2-NEXT:    imull $9363, %esi, %eax # imm = 0x2493
; AVX2-NEXT:    shrl $16, %eax
; AVX2-NEXT:    movl %esi, %ecx
; AVX2-NEXT:    subl %eax, %ecx
; AVX2-NEXT:    movzwl %cx, %ecx
; AVX2-NEXT:    shrl %ecx
; AVX2-NEXT:    addl %eax, %ecx
; AVX2-NEXT:    shrl $2, %ecx
; AVX2-NEXT:    leal (,%rcx,8), %eax
; AVX2-NEXT:    subl %eax, %ecx
; AVX2-NEXT:    addl %esi, %ecx
; AVX2-NEXT:    andl $2047, %edi # imm = 0x7FF
; AVX2-NEXT:    imull $43691, %edi, %eax # imm = 0xAAAB
; AVX2-NEXT:    shrl $17, %eax
; AVX2-NEXT:    andl $-2, %eax
; AVX2-NEXT:    leal (%rax,%rax,2), %eax
; AVX2-NEXT:    subl %eax, %edi
; AVX2-NEXT:    vmovd %edi, %xmm0
; AVX2-NEXT:    vpinsrw $2, %ecx, %xmm0, %xmm0
; AVX2-NEXT:    andl $2047, %edx # imm = 0x7FF
; AVX2-NEXT:    imull $161, %edx, %eax
; AVX2-NEXT:    shrl $16, %eax
; AVX2-NEXT:    movl %edx, %ecx
; AVX2-NEXT:    subl %eax, %ecx
; AVX2-NEXT:    movzwl %cx, %ecx
; AVX2-NEXT:    shrl %ecx
; AVX2-NEXT:    addl %eax, %ecx
; AVX2-NEXT:    shrl $10, %ecx
; AVX2-NEXT:    imull $2043, %ecx, %eax # imm = 0x7FB
; AVX2-NEXT:    subl %eax, %edx
; AVX2-NEXT:    vpinsrw $4, %edx, %xmm0, %xmm0
; AVX2-NEXT:    vpbroadcastd {{.*#+}} xmm1 = [2047,2047,2047,2047]
; AVX2-NEXT:    vpand %xmm1, %xmm0, %xmm0
; AVX2-NEXT:    vpcmpeqd {{.*}}(%rip), %xmm0, %xmm0
; AVX2-NEXT:    vpcmpeqd %xmm1, %xmm1, %xmm1
; AVX2-NEXT:    vpxor %xmm1, %xmm0, %xmm0
; AVX2-NEXT:    vmovd %xmm0, %eax
; AVX2-NEXT:    vpextrb $4, %xmm0, %edx
; AVX2-NEXT:    vpextrb $8, %xmm0, %ecx
; AVX2-NEXT:    # kill: def $al killed $al killed $eax
; AVX2-NEXT:    # kill: def $dl killed $dl killed $edx
; AVX2-NEXT:    # kill: def $cl killed $cl killed $ecx
; AVX2-NEXT:    retq
;
; AVX512VL-LABEL: test_urem_vec:
; AVX512VL:       # %bb.0:
; AVX512VL-NEXT:    andl $2047, %esi # imm = 0x7FF
; AVX512VL-NEXT:    imull $9363, %esi, %eax # imm = 0x2493
; AVX512VL-NEXT:    shrl $16, %eax
; AVX512VL-NEXT:    movl %esi, %ecx
; AVX512VL-NEXT:    subl %eax, %ecx
; AVX512VL-NEXT:    movzwl %cx, %ecx
; AVX512VL-NEXT:    shrl %ecx
; AVX512VL-NEXT:    addl %eax, %ecx
; AVX512VL-NEXT:    shrl $2, %ecx
; AVX512VL-NEXT:    leal (,%rcx,8), %eax
; AVX512VL-NEXT:    subl %eax, %ecx
; AVX512VL-NEXT:    addl %esi, %ecx
; AVX512VL-NEXT:    andl $2047, %edi # imm = 0x7FF
; AVX512VL-NEXT:    imull $43691, %edi, %eax # imm = 0xAAAB
; AVX512VL-NEXT:    shrl $17, %eax
; AVX512VL-NEXT:    andl $-2, %eax
; AVX512VL-NEXT:    leal (%rax,%rax,2), %eax
; AVX512VL-NEXT:    subl %eax, %edi
; AVX512VL-NEXT:    vmovd %edi, %xmm0
; AVX512VL-NEXT:    vpinsrw $2, %ecx, %xmm0, %xmm0
; AVX512VL-NEXT:    andl $2047, %edx # imm = 0x7FF
; AVX512VL-NEXT:    imull $161, %edx, %eax
; AVX512VL-NEXT:    shrl $16, %eax
; AVX512VL-NEXT:    movl %edx, %ecx
; AVX512VL-NEXT:    subl %eax, %ecx
; AVX512VL-NEXT:    movzwl %cx, %ecx
; AVX512VL-NEXT:    shrl %ecx
; AVX512VL-NEXT:    addl %eax, %ecx
; AVX512VL-NEXT:    shrl $10, %ecx
; AVX512VL-NEXT:    imull $2043, %ecx, %eax # imm = 0x7FB
; AVX512VL-NEXT:    subl %eax, %edx
; AVX512VL-NEXT:    vpinsrw $4, %edx, %xmm0, %xmm0
; AVX512VL-NEXT:    vpandd {{.*}}(%rip){1to4}, %xmm0, %xmm0
; AVX512VL-NEXT:    vpcmpneqd {{.*}}(%rip), %xmm0, %k0
; AVX512VL-NEXT:    kshiftrw $1, %k0, %k1
; AVX512VL-NEXT:    kmovw %k1, %edx
; AVX512VL-NEXT:    kshiftrw $2, %k0, %k1
; AVX512VL-NEXT:    kmovw %k1, %ecx
; AVX512VL-NEXT:    kmovw %k0, %eax
; AVX512VL-NEXT:    # kill: def $al killed $al killed $eax
; AVX512VL-NEXT:    # kill: def $dl killed $dl killed $edx
; AVX512VL-NEXT:    # kill: def $cl killed $cl killed $ecx
; AVX512VL-NEXT:    retq
  %urem = urem <3 x i11> %X, <i11 6, i11 7, i11 -5>
  %cmp = icmp ne <3 x i11> %urem, <i11 0, i11 1, i11 2>
  ret <3 x i1> %cmp
}
