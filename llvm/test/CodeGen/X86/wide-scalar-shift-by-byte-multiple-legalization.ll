; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-SSE2,X64-NO-BMI2,X64-NO-SHLD-NO-BMI2,X64-NO-SHLD-NO-BMI2-SSE2
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-SSE2,X64-NO-BMI2,X64-HAVE-SHLD-NO-BMI2,X64-HAVE-SHLD-NO-BMI2-SSE2
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-SSE2,X64-HAVE-BMI2,X64-NO-SHLD-HAVE-BMI2,X64-NO-SHLD-HAVE-BMI2-SSE2
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-SSE2,X64-HAVE-BMI2,X64-HAVE-SHLD-HAVE-BMI2,X64-HAVE-SHLD-HAVE-BMI2-SSE2
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse4.2,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-SSE42,X64-NO-BMI2,X64-NO-SHLD-NO-BMI2,X64-NO-SHLD-NO-BMI2-SSE4
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse4.2,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-SSE42,X64-NO-BMI2,X64-HAVE-SHLD-NO-BMI2,X64-HAVE-SHLD-NO-BMI2-SSE4
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse4.2,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-SSE42,X64-HAVE-BMI2,X64-NO-SHLD-HAVE-BMI2,X64-NO-SHLD-HAVE-BMI2-SSE4
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse4.2,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-SSE42,X64-HAVE-BMI2,X64-HAVE-SHLD-HAVE-BMI2,X64-HAVE-SHLD-HAVE-BMI2-SSE4
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-AVX,X64-AVX1,X64-NO-BMI2,X64-NO-SHLD-NO-BMI2,X64-NO-SHLD-NO-BMI2-AVX,X64-NO-SHLD-NO-BMI2-AVX1
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-AVX,X64-AVX1,X64-NO-BMI2,X64-HAVE-SHLD-NO-BMI2,X64-HAVE-SHLD-NO-BMI2-AVX,X64-HAVE-SHLD-NO-BMI2-AVX1
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-AVX,X64-AVX1,X64-HAVE-BMI2,X64-NO-SHLD-HAVE-BMI2,X64-NO-SHLD-HAVE-BMI2-AVX,X64-NO-SHLD-HAVE-BMI2-AVX1
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-AVX,X64-AVX1,X64-HAVE-BMI2,X64-HAVE-SHLD-HAVE-BMI2,X64-HAVE-SHLD-HAVE-BMI2-AVX,X64-HAVE-SHLD-HAVE-BMI2-AVX1
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx512vl,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-AVX,X64-AVX512,X64-NO-BMI2,X64-NO-SHLD-NO-BMI2,X64-NO-SHLD-NO-BMI2-AVX,X64-NO-SHLD-NO-BMI2-AVX512
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx512vl,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-AVX,X64-AVX512,X64-NO-BMI2,X64-HAVE-SHLD-NO-BMI2,X64-HAVE-SHLD-NO-BMI2-AVX,X64-HAVE-SHLD-NO-BMI2-AVX512
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx512vl,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-AVX,X64-AVX512,X64-HAVE-BMI2,X64-NO-SHLD-HAVE-BMI2,X64-NO-SHLD-HAVE-BMI2-AVX,X64-NO-SHLD-HAVE-BMI2-AVX512
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx512vl,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-AVX,X64-AVX512,X64-HAVE-BMI2,X64-HAVE-SHLD-HAVE-BMI2,X64-HAVE-SHLD-HAVE-BMI2-AVX,X64-HAVE-SHLD-HAVE-BMI2-AVX512
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse2,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-SSE2,X86-NO-BMI2,X86-NO-SHLD-NO-BMI2,X86-NO-SHLD-NO-BMI2-SSE2
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse2,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-SSE2,X86-NO-BMI2,X86-HAVE-SHLD-NO-BMI2,X86-HAVE-SHLD-NO-BMI2-SSE2
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse2,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-SSE2,X86-HAVE-BMI2,X86-NO-SHLD-HAVE-BMI2,X86-NO-SHLD-HAVE-BMI2-SSE2
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse2,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-SSE2,X86-HAVE-BMI2,X86-HAVE-SHLD-HAVE-BMI2,X86-HAVE-SHLD-HAVE-BMI2-SSE2
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse4.2,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-SSE42,X86-NO-BMI2,X86-NO-SHLD-NO-BMI2,X86-NO-SHLD-NO-BMI2-SSE4
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse4.2,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-SSE42,X86-NO-BMI2,X86-HAVE-SHLD-NO-BMI2,X86-HAVE-SHLD-NO-BMI2-SSE4
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse4.2,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-SSE42,X86-HAVE-BMI2,X86-NO-SHLD-HAVE-BMI2,X86-NO-SHLD-HAVE-BMI2-SSE4
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse4.2,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-SSE42,X86-HAVE-BMI2,X86-HAVE-SHLD-HAVE-BMI2,X86-HAVE-SHLD-HAVE-BMI2-SSE4
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+avx,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-AVX,X86-AVX1,X86-NO-BMI2,X86-NO-SHLD-NO-BMI2,X86-NO-SHLD-NO-BMI2-AVX,X86-NO-SHLD-NO-BMI2-AVX1
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+avx,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-AVX,X86-AVX1,X86-NO-BMI2,X86-HAVE-SHLD-NO-BMI2,X86-HAVE-SHLD-NO-BMI2-AVX,X86-HAVE-SHLD-NO-BMI2-AVX1
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+avx,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-AVX,X86-AVX1,X86-HAVE-BMI2,X86-NO-SHLD-HAVE-BMI2,X86-NO-SHLD-HAVE-BMI2-AVX,X86-NO-SHLD-HAVE-BMI2-AVX1
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+avx,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-AVX,X86-AVX1,X86-HAVE-BMI2,X86-HAVE-SHLD-HAVE-BMI2,X86-HAVE-SHLD-HAVE-BMI2-AVX,X86-HAVE-SHLD-HAVE-BMI2-AVX1
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+avx512vl,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-AVX,X86-AVX512,X86-NO-BMI2,X86-NO-SHLD-NO-BMI2,X86-NO-SHLD-NO-BMI2-AVX,X86-NO-SHLD-NO-BMI2-AVX512
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+avx512vl,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-AVX,X86-AVX512,X86-NO-BMI2,X86-HAVE-SHLD-NO-BMI2,X86-HAVE-SHLD-NO-BMI2-AVX,X86-HAVE-SHLD-NO-BMI2-AVX512
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+avx512vl,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-AVX,X86-AVX512,X86-HAVE-BMI2,X86-NO-SHLD-HAVE-BMI2,X86-NO-SHLD-HAVE-BMI2-AVX,X86-NO-SHLD-HAVE-BMI2-AVX512
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+avx512vl,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X86,X86-AVX,X86-AVX512,X86-HAVE-BMI2,X86-HAVE-SHLD-HAVE-BMI2,X86-HAVE-SHLD-HAVE-BMI2-AVX,X86-HAVE-SHLD-HAVE-BMI2-AVX512

define void @lshr_4bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: lshr_4bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movl (%rdi), %eax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    shrl %cl, %eax
; X64-NO-BMI2-NEXT:    movl %eax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-HAVE-BMI2-LABEL: lshr_4bytes:
; X64-HAVE-BMI2:       # %bb.0:
; X64-HAVE-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-BMI2-NEXT:    shlb $3, %al
; X64-HAVE-BMI2-NEXT:    shrxl %eax, (%rdi), %eax
; X64-HAVE-BMI2-NEXT:    movl %eax, (%rdx)
; X64-HAVE-BMI2-NEXT:    retq
;
; X86-NO-BMI2-LABEL: lshr_4bytes:
; X86-NO-BMI2:       # %bb.0:
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-BMI2-NEXT:    movl (%edx), %edx
; X86-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-NO-BMI2-NEXT:    shlb $3, %cl
; X86-NO-BMI2-NEXT:    shrl %cl, %edx
; X86-NO-BMI2-NEXT:    movl %edx, (%eax)
; X86-NO-BMI2-NEXT:    retl
;
; X86-HAVE-BMI2-LABEL: lshr_4bytes:
; X86-HAVE-BMI2:       # %bb.0:
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-BMI2-NEXT:    movzbl (%edx), %edx
; X86-HAVE-BMI2-NEXT:    shlb $3, %dl
; X86-HAVE-BMI2-NEXT:    shrxl %edx, (%ecx), %ecx
; X86-HAVE-BMI2-NEXT:    movl %ecx, (%eax)
; X86-HAVE-BMI2-NEXT:    retl
  %src = load i32, ptr %src.ptr, align 1
  %byteOff = load i32, ptr %byteOff.ptr, align 1
  %bitOff = shl i32 %byteOff, 3
  %res = lshr i32 %src, %bitOff
  store i32 %res, ptr %dst, align 1
  ret void
}
define void @shl_4bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: shl_4bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movl (%rdi), %eax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    shll %cl, %eax
; X64-NO-BMI2-NEXT:    movl %eax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-HAVE-BMI2-LABEL: shl_4bytes:
; X64-HAVE-BMI2:       # %bb.0:
; X64-HAVE-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-BMI2-NEXT:    shlb $3, %al
; X64-HAVE-BMI2-NEXT:    shlxl %eax, (%rdi), %eax
; X64-HAVE-BMI2-NEXT:    movl %eax, (%rdx)
; X64-HAVE-BMI2-NEXT:    retq
;
; X86-NO-BMI2-LABEL: shl_4bytes:
; X86-NO-BMI2:       # %bb.0:
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-BMI2-NEXT:    movl (%edx), %edx
; X86-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-NO-BMI2-NEXT:    shlb $3, %cl
; X86-NO-BMI2-NEXT:    shll %cl, %edx
; X86-NO-BMI2-NEXT:    movl %edx, (%eax)
; X86-NO-BMI2-NEXT:    retl
;
; X86-HAVE-BMI2-LABEL: shl_4bytes:
; X86-HAVE-BMI2:       # %bb.0:
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-BMI2-NEXT:    movzbl (%edx), %edx
; X86-HAVE-BMI2-NEXT:    shlb $3, %dl
; X86-HAVE-BMI2-NEXT:    shlxl %edx, (%ecx), %ecx
; X86-HAVE-BMI2-NEXT:    movl %ecx, (%eax)
; X86-HAVE-BMI2-NEXT:    retl
  %src = load i32, ptr %src.ptr, align 1
  %byteOff = load i32, ptr %byteOff.ptr, align 1
  %bitOff = shl i32 %byteOff, 3
  %res = shl i32 %src, %bitOff
  store i32 %res, ptr %dst, align 1
  ret void
}
define void @ashr_4bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: ashr_4bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movl (%rdi), %eax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    sarl %cl, %eax
; X64-NO-BMI2-NEXT:    movl %eax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-HAVE-BMI2-LABEL: ashr_4bytes:
; X64-HAVE-BMI2:       # %bb.0:
; X64-HAVE-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-BMI2-NEXT:    shlb $3, %al
; X64-HAVE-BMI2-NEXT:    sarxl %eax, (%rdi), %eax
; X64-HAVE-BMI2-NEXT:    movl %eax, (%rdx)
; X64-HAVE-BMI2-NEXT:    retq
;
; X86-NO-BMI2-LABEL: ashr_4bytes:
; X86-NO-BMI2:       # %bb.0:
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-BMI2-NEXT:    movl (%edx), %edx
; X86-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-NO-BMI2-NEXT:    shlb $3, %cl
; X86-NO-BMI2-NEXT:    sarl %cl, %edx
; X86-NO-BMI2-NEXT:    movl %edx, (%eax)
; X86-NO-BMI2-NEXT:    retl
;
; X86-HAVE-BMI2-LABEL: ashr_4bytes:
; X86-HAVE-BMI2:       # %bb.0:
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-BMI2-NEXT:    movzbl (%edx), %edx
; X86-HAVE-BMI2-NEXT:    shlb $3, %dl
; X86-HAVE-BMI2-NEXT:    sarxl %edx, (%ecx), %ecx
; X86-HAVE-BMI2-NEXT:    movl %ecx, (%eax)
; X86-HAVE-BMI2-NEXT:    retl
  %src = load i32, ptr %src.ptr, align 1
  %byteOff = load i32, ptr %byteOff.ptr, align 1
  %bitOff = shl i32 %byteOff, 3
  %res = ashr i32 %src, %bitOff
  store i32 %res, ptr %dst, align 1
  ret void
}

define void @lshr_8bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: lshr_8bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    shrq %cl, %rax
; X64-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-HAVE-BMI2-LABEL: lshr_8bytes:
; X64-HAVE-BMI2:       # %bb.0:
; X64-HAVE-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-BMI2-NEXT:    shlb $3, %al
; X64-HAVE-BMI2-NEXT:    shrxq %rax, (%rdi), %rax
; X64-HAVE-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-BMI2-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-LABEL: lshr_8bytes:
; X86-NO-SHLD-NO-BMI2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl (%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 4(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movzbl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X86-NO-SHLD-NO-BMI2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    xorl %ecx, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    testb $32, %al
; X86-NO-SHLD-NO-BMI2-NEXT:    cmovnel %esi, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    cmovel %esi, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ecx, 4(%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edi, (%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-LABEL: lshr_8bytes:
; X86-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl (%esi), %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 4(%esi), %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shrl %cl, %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    xorl %esi, %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    testb $32, %cl
; X86-HAVE-SHLD-NO-BMI2-NEXT:    cmovnel %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    cmovel %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %esi, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-LABEL: lshr_8bytes:
; X86-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl 4(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shrxl %ecx, (%edx), %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlxl %ebx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    orl %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shrxl %ecx, %esi, %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    xorl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    testb $32, %cl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    cmovnel %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    cmovel %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %esi, 4(%eax)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %edi, (%eax)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-LABEL: lshr_8bytes:
; X86-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl (%esi), %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 4(%esi), %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shrxl %ecx, %esi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    xorl %edi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $32, %cl
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovnel %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovel %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    retl
  %src = load i64, ptr %src.ptr, align 1
  %byteOff = load i64, ptr %byteOff.ptr, align 1
  %bitOff = shl i64 %byteOff, 3
  %res = lshr i64 %src, %bitOff
  store i64 %res, ptr %dst, align 1
  ret void
}
define void @shl_8bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: shl_8bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    shlq %cl, %rax
; X64-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-HAVE-BMI2-LABEL: shl_8bytes:
; X64-HAVE-BMI2:       # %bb.0:
; X64-HAVE-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-BMI2-NEXT:    shlb $3, %al
; X64-HAVE-BMI2-NEXT:    shlxq %rax, (%rdi), %rax
; X64-HAVE-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-BMI2-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-LABEL: shl_8bytes:
; X86-NO-SHLD-NO-BMI2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl (%ecx), %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 4(%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movzbl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X86-NO-SHLD-NO-BMI2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    xorl %ecx, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    testb $32, %al
; X86-NO-SHLD-NO-BMI2-NEXT:    cmovnel %esi, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    cmovel %esi, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ecx, (%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edi, 4(%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-LABEL: shl_8bytes:
; X86-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl (%edx), %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 4(%edx), %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shll %cl, %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    xorl %esi, %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    testb $32, %cl
; X86-HAVE-SHLD-NO-BMI2-NEXT:    cmovnel %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    cmovel %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %esi, (%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-LABEL: shl_8bytes:
; X86-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl (%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlxl %ecx, 4(%edx), %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlxl %ecx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    orl %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    xorl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    testb $32, %cl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    cmovnel %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    cmovel %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %esi, 4(%eax)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-LABEL: shl_8bytes:
; X86-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl (%edx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 4(%edx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shlxl %ecx, %esi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    xorl %edi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $32, %cl
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovnel %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovel %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edi, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    retl
  %src = load i64, ptr %src.ptr, align 1
  %byteOff = load i64, ptr %byteOff.ptr, align 1
  %bitOff = shl i64 %byteOff, 3
  %res = shl i64 %src, %bitOff
  store i64 %res, ptr %dst, align 1
  ret void
}
define void @ashr_8bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: ashr_8bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    sarq %cl, %rax
; X64-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-HAVE-BMI2-LABEL: ashr_8bytes:
; X64-HAVE-BMI2:       # %bb.0:
; X64-HAVE-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-BMI2-NEXT:    shlb $3, %al
; X64-HAVE-BMI2-NEXT:    sarxq %rax, (%rdi), %rax
; X64-HAVE-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-BMI2-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-LABEL: ashr_8bytes:
; X86-NO-SHLD-NO-BMI2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl (%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 4(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movzbl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X86-NO-SHLD-NO-BMI2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    sarl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    sarl $31, %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    testb $32, %al
; X86-NO-SHLD-NO-BMI2-NEXT:    cmovnel %ebx, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    cmovel %ebx, %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %esi, 4(%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edi, (%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-LABEL: ashr_8bytes:
; X86-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl (%esi), %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 4(%esi), %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    sarl %cl, %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    sarl $31, %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    testb $32, %cl
; X86-HAVE-SHLD-NO-BMI2-NEXT:    cmovnel %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    cmovel %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %esi, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-LABEL: ashr_8bytes:
; X86-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl 4(%esi), %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%edx), %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlb $3, %dl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shrxl %edx, (%esi), %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    leal (%ecx,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlxl %ebx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    sarxl %edx, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    testb $32, %dl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    cmovnel %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    cmovel %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %edi, (%eax)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-LABEL: ashr_8bytes:
; X86-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl (%esi), %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 4(%esi), %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    sarxl %ecx, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    sarl $31, %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $32, %cl
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovnel %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovel %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %esi, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    retl
  %src = load i64, ptr %src.ptr, align 1
  %byteOff = load i64, ptr %byteOff.ptr, align 1
  %bitOff = shl i64 %byteOff, 3
  %res = ashr i64 %src, %bitOff
  store i64 %res, ptr %dst, align 1
  ret void
}

define void @lshr_16bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-LABEL: lshr_16bytes:
; X64-NO-SHLD-NO-BMI2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-NEXT:    movq (%rdi), %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-NO-SHLD-NO-BMI2-NEXT:    shlb $3, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    leaq (%rdi,%rdi), %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X64-NO-SHLD-NO-BMI2-NEXT:    shlq %cl, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    orq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    xorl %ecx, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    testb $64, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    cmovneq %rdi, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    cmoveq %rdi, %rcx
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rcx, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rsi, (%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-LABEL: lshr_16bytes:
; X64-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shlb $3, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shrq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    xorl %edi, %edi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-LABEL: lshr_16bytes:
; X64-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrxq %rcx, (%rdi), %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, %edi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    notb %dil
; X64-NO-SHLD-HAVE-BMI2-NEXT:    leaq (%rax,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlxq %rdi, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    orq %rsi, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrxq %rcx, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    xorl %esi, %esi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmovneq %rax, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmoveq %rax, %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rsi, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-LABEL: lshr_16bytes:
; X64-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shrxq %rcx, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    xorl %edi, %edi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-SSE2-LABEL: lshr_16bytes:
; X86-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl $60, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ecx), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb (%eax), %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ah, %al
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $12, %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %ah, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%esp,%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%esp,%ebp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ecx,%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%esp,%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Folded Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%esp,%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ebx,%ebx), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 12(%edx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 8(%edx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, (%edx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 4(%edx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl $60, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE2-LABEL: lshr_16bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%edx), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%edx), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%edx), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%edx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movb (%ecx), %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, (%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $12, %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %ch, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%esp,%ebx), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp,%ebx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%esp,%ebx), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%esp,%ebx), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %ebx, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %ebp, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 12(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_16bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %al
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, (%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $12, %bl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %bl, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%esp,%edi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%esp,%edi), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %ebx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%esi,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %eax, %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, (%esp,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %eax, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%esp,%edi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %eax, %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 12(%esi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%esi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, (%esi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 4(%esi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_16bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%edx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%edx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%edx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%edx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, (%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $12, %al
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %al, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%esp,%eax), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp,%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%esp,%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %ebx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%esp,%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %eax, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-SSE4-LABEL: lshr_16bytes:
; X86-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl $60, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm1, %xmm1
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $12, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 16(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 20(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 24(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 28(%esp,%edi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 12(%edx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 4(%edx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 8(%edx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, (%edx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl $60, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE4-LABEL: lshr_16bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%edx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm1, %xmm1
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, (%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $12, %dl
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %dl, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 12(%esp,%ebx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 8(%esp,%ebx), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%esp,%ebx), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 4(%esp,%ebx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %ebp, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_16bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $60, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %al
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm1, %xmm1
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $12, %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %dl, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, 16(%esp,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 20(%esp,%edi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 24(%esp,%edi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %eax, %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 28(%esp,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%ebp,%ebp), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %ebx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %eax, %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 12(%esi)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 4(%esi)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 8(%esi)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, (%esi)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $60, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_16bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%edx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm1, %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, (%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $12, %dl
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %dl, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 12(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 8(%esp,%ebx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%esp,%ebx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 4(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %ebp, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %edx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX-LABEL: lshr_16bytes:
; X86-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    subl $60, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $12, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 16(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 20(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 24(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 28(%esp,%edi), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 12(%edx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, 4(%edx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, 8(%edx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, (%edx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl $60, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX-LABEL: lshr_16bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%edx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, (%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $12, %dl
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl %dl, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 12(%esp,%ebx), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 8(%esp,%ebx), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl (%esp,%ebx), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 4(%esp,%ebx), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %ebp, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX-LABEL: lshr_16bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    subl $60, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %al
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $12, %dl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %dl, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ecx, 16(%esp,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %al
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 20(%esp,%edi), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 24(%esp,%edi), %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %eax, %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 28(%esp,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%ebp,%ebp), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ecx, %ebx, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %eax, %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ecx, %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 12(%esi)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 4(%esi)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 8(%esi)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, (%esi)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl $60, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: lshr_16bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%edx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, (%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $12, %dl
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %dl, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 12(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 8(%esp,%ebx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl (%esp,%ebx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 4(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %ebp, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ecx, %edx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %byteOff = load i128, ptr %byteOff.ptr, align 1
  %bitOff = shl i128 %byteOff, 3
  %res = lshr i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}

define void @lshr_16bytes_dwordOff(ptr %src.ptr, ptr %dwordOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-LABEL: lshr_16bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-NEXT:    movq (%rdi), %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-NO-SHLD-NO-BMI2-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    leaq (%rdi,%rdi), %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X64-NO-SHLD-NO-BMI2-NEXT:    shlq %cl, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    orq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    xorl %ecx, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    testb $64, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    cmovneq %rdi, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    cmoveq %rdi, %rcx
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rcx, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rsi, (%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-LABEL: lshr_16bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shrq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    xorl %edi, %edi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-LABEL: lshr_16bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlb $5, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrxq %rcx, (%rdi), %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, %edi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    notb %dil
; X64-NO-SHLD-HAVE-BMI2-NEXT:    leaq (%rax,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlxq %rdi, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    orq %rsi, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrxq %rcx, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    xorl %esi, %esi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmovneq %rax, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmoveq %rax, %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rsi, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-LABEL: lshr_16bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shrxq %rcx, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    xorl %edi, %edi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    retq
;
; X86-SSE2-LABEL: lshr_16bytes_dwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $32, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE2-NEXT:    movl (%edx), %esi
; X86-SSE2-NEXT:    movl 4(%edx), %edi
; X86-SSE2-NEXT:    movl 8(%edx), %ebx
; X86-SSE2-NEXT:    movl 12(%edx), %edx
; X86-SSE2-NEXT:    movzbl (%ecx), %ecx
; X86-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, (%esp)
; X86-SSE2-NEXT:    andl $3, %ecx
; X86-SSE2-NEXT:    movl (%esp,%ecx,4), %edx
; X86-SSE2-NEXT:    movl 4(%esp,%ecx,4), %esi
; X86-SSE2-NEXT:    movl 12(%esp,%ecx,4), %edi
; X86-SSE2-NEXT:    movl 8(%esp,%ecx,4), %ecx
; X86-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-SSE2-NEXT:    movl %edi, 12(%eax)
; X86-SSE2-NEXT:    movl %edx, (%eax)
; X86-SSE2-NEXT:    movl %esi, 4(%eax)
; X86-SSE2-NEXT:    addl $32, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: lshr_16bytes_dwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    subl $44, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    xorps %xmm1, %xmm1
; X86-SSE42-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, (%esp)
; X86-SSE42-NEXT:    andl $3, %ecx
; X86-SSE42-NEXT:    movups (%esp,%ecx,4), %xmm0
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $44, %esp
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: lshr_16bytes_dwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    subl $44, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %xmm0
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    vmovaps %xmm0, (%esp)
; X86-AVX-NEXT:    andl $3, %ecx
; X86-AVX-NEXT:    vmovups (%esp,%ecx,4), %xmm0
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $44, %esp
; X86-AVX-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %dwordOff = load i128, ptr %dwordOff.ptr, align 1
  %bitOff = shl i128 %dwordOff, 5
  %res = lshr i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}

define void @shl_16bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-LABEL: shl_16bytes:
; X64-NO-SHLD-NO-BMI2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-NEXT:    movq (%rdi), %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-NO-SHLD-NO-BMI2-NEXT:    shlb $3, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %cl, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    orq %rdi, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    xorl %ecx, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    testb $64, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    cmovneq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    cmoveq %r8, %rcx
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rcx, (%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rsi, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-LABEL: shl_16bytes:
; X64-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shlb $3, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shlq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shldq %cl, %rax, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    xorl %eax, %eax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmovneq %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmoveq %rsi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-LABEL: shl_16bytes:
; X64-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq (%rdi), %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlxq %rcx, 8(%rdi), %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, %edi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    notb %dil
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlxq %rcx, %rax, %r8
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrq %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrxq %rdi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    orq %rsi, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    xorl %esi, %esi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmovneq %r8, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmoveq %r8, %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rsi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-LABEL: shl_16bytes:
; X64-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shldq %cl, %rax, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shlxq %rcx, %rax, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    xorl %esi, %esi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovneq %rax, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmoveq %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rsi, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-SSE2-LABEL: shl_16bytes:
; X86-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl $60, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ecx), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb (%eax), %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ah, %dh
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %dh
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $12, %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    negb %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movsbl %ah, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%esp,%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%esp,%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %dl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%esp,%ebp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%esp,%ebp), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl $60, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE2-LABEL: shl_16bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl $32, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%edx), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%edx), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%edx), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%edx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movb (%ecx), %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, (%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $12, %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    negb %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movsbl %ch, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%esp,%edi), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%esp,%edi), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%esp,%edi), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%esp,%edi), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %ebx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 12(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, (%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addl $32, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE2-LABEL: shl_16bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %al
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, (%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $12, %bl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    negb %bl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movsbl %bl, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%esp,%esi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%esp,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %ebx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, 28(%esp,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%esp,%esi), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, (%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 12(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 4(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: shl_16bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%edx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%edx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%edx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%edx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, (%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $12, %al
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    negb %al
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movsbl %al, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%esp,%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%esp,%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%esp,%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%esp,%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edi, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-SSE4-LABEL: shl_16bytes:
; X86-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl $60, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm1, %xmm1
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $12, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    negb %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movsbl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 44(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 40(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 32(%esp,%edi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 36(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, (%edx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 4(%edx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 8(%edx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 12(%edx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl $60, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE4-LABEL: shl_16bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%edx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm1, %xmm1
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, (%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $12, %dl
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    negb %dl
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movsbl %dl, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 24(%esp,%edi), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 28(%esp,%edi), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 16(%esp,%edi), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 20(%esp,%edi), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %ebx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, 12(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, (%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE4-LABEL: shl_16bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %al
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm1, %xmm1
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, (%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $12, %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    negb %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movsbl %dl, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, 28(%esp,%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 24(%esp,%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %esi, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %eax, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 20(%esp,%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %eax, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 16(%esp,%edx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %edx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %eax, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, (%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: shl_16bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%edx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm1, %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, (%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $12, %dl
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    negb %dl
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movsbl %dl, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 24(%esp,%edi), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 28(%esp,%edi), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 16(%esp,%edi), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 20(%esp,%edi), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %ebx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %ebx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX-LABEL: shl_16bytes:
; X86-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    subl $60, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $12, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    negb %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movsbl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 44(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 40(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 32(%esp,%edi), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 36(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebp, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, (%edx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, 4(%edx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 8(%edx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 12(%edx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl $60, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX-LABEL: shl_16bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%edx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm1, (%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $12, %dl
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    negb %dl
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movsbl %dl, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 24(%esp,%edi), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 28(%esp,%edi), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 16(%esp,%edi), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 20(%esp,%edi), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %ebx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, 12(%eax)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, (%eax)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX-LABEL: shl_16bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    subl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %al
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm1, (%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $12, %dl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    negb %dl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movsbl %dl, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, 28(%esp,%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %al
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 24(%esp,%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %esi, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 20(%esp,%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 16(%esp,%edx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %edx, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, (%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: shl_16bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%edx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm1, (%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $12, %dl
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    negb %dl
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movsbl %dl, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 24(%esp,%edi), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 28(%esp,%edi), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 16(%esp,%edi), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 20(%esp,%edi), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %ebx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %ebx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %byteOff = load i128, ptr %byteOff.ptr, align 1
  %bitOff = shl i128 %byteOff, 3
  %res = shl i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}

define void @shl_16bytes_dwordOff(ptr %src.ptr, ptr %dwordOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-LABEL: shl_16bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-NEXT:    movq (%rdi), %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-NO-SHLD-NO-BMI2-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %cl, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    orq %rdi, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    xorl %ecx, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    testb $64, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    cmovneq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    cmoveq %r8, %rcx
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rcx, (%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rsi, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-LABEL: shl_16bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shlq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shldq %cl, %rax, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    xorl %eax, %eax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmovneq %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmoveq %rsi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-LABEL: shl_16bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq (%rdi), %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlb $5, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlxq %rcx, 8(%rdi), %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, %edi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    notb %dil
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlxq %rcx, %rax, %r8
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrq %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrxq %rdi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    orq %rsi, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    xorl %esi, %esi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmovneq %r8, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmoveq %r8, %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rsi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-LABEL: shl_16bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shldq %cl, %rax, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shlxq %rcx, %rax, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    xorl %esi, %esi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovneq %rax, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmoveq %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rsi, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    retq
;
; X86-SSE2-LABEL: shl_16bytes_dwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $32, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE2-NEXT:    movl (%edx), %esi
; X86-SSE2-NEXT:    movl 4(%edx), %edi
; X86-SSE2-NEXT:    movl 8(%edx), %ebx
; X86-SSE2-NEXT:    movl 12(%edx), %edx
; X86-SSE2-NEXT:    movzbl (%ecx), %ecx
; X86-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-SSE2-NEXT:    movaps %xmm0, (%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    shlb $2, %cl
; X86-SSE2-NEXT:    andb $12, %cl
; X86-SSE2-NEXT:    negb %cl
; X86-SSE2-NEXT:    movsbl %cl, %ecx
; X86-SSE2-NEXT:    movl 16(%esp,%ecx), %edx
; X86-SSE2-NEXT:    movl 20(%esp,%ecx), %esi
; X86-SSE2-NEXT:    movl 28(%esp,%ecx), %edi
; X86-SSE2-NEXT:    movl 24(%esp,%ecx), %ecx
; X86-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-SSE2-NEXT:    movl %edi, 12(%eax)
; X86-SSE2-NEXT:    movl %edx, (%eax)
; X86-SSE2-NEXT:    movl %esi, 4(%eax)
; X86-SSE2-NEXT:    addl $32, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: shl_16bytes_dwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    subl $44, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    xorps %xmm1, %xmm1
; X86-SSE42-NEXT:    movaps %xmm1, (%esp)
; X86-SSE42-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    shlb $2, %cl
; X86-SSE42-NEXT:    andb $12, %cl
; X86-SSE42-NEXT:    negb %cl
; X86-SSE42-NEXT:    movsbl %cl, %ecx
; X86-SSE42-NEXT:    movups 16(%esp,%ecx), %xmm0
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $44, %esp
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: shl_16bytes_dwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    subl $44, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %xmm0
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-AVX-NEXT:    vmovaps %xmm1, (%esp)
; X86-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    shlb $2, %cl
; X86-AVX-NEXT:    andb $12, %cl
; X86-AVX-NEXT:    negb %cl
; X86-AVX-NEXT:    movsbl %cl, %ecx
; X86-AVX-NEXT:    vmovups 16(%esp,%ecx), %xmm0
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $44, %esp
; X86-AVX-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %dwordOff = load i128, ptr %dwordOff.ptr, align 1
  %bitOff = shl i128 %dwordOff, 5
  %res = shl i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}

define void @ashr_16bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-LABEL: ashr_16bytes:
; X64-NO-SHLD-NO-BMI2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-NEXT:    movq (%rdi), %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-NO-SHLD-NO-BMI2-NEXT:    shlb $3, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    leaq (%rdi,%rdi), %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X64-NO-SHLD-NO-BMI2-NEXT:    shlq %cl, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    orq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rdi, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    sarq %cl, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    testb $64, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    cmovneq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    cmoveq %r8, %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rsi, (%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-LABEL: ashr_16bytes:
; X64-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shlb $3, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    sarq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-LABEL: ashr_16bytes:
; X64-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrxq %rcx, (%rdi), %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, %edi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    notb %dil
; X64-NO-SHLD-HAVE-BMI2-NEXT:    leaq (%rax,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlxq %rdi, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    orq %rsi, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    sarxq %rcx, %rax, %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    sarq $63, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmovneq %rsi, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmoveq %rsi, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-LABEL: ashr_16bytes:
; X64-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    sarxq %rcx, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-LABEL: ashr_16bytes:
; X86-NO-SHLD-NO-BMI2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    subl $60, %esp
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl (%ecx), %edx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 4(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 8(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 12(%ecx), %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movb (%eax), %ah
; X86-NO-SHLD-NO-BMI2-NEXT:    movb %ah, %al
; X86-NO-SHLD-NO-BMI2-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-NEXT:    andb $12, %ah
; X86-NO-SHLD-NO-BMI2-NEXT:    movzbl %ah, %ebp
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 20(%esp,%ebp), %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 24(%esp,%ebp), %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-NEXT:    leal (%ecx,%ecx), %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 16(%esp,%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shrl %cl, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Folded Spill
; X86-NO-SHLD-NO-BMI2-NEXT:    movl 28(%esp,%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    leal (%ebx,%ebx), %ebp
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-NEXT:    sarl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ebx, 12(%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %ebp, 8(%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %esi, (%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    movl %edi, 4(%edx)
; X86-NO-SHLD-NO-BMI2-NEXT:    addl $60, %esp
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-LABEL: ashr_16bytes:
; X86-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl (%edx), %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 4(%edx), %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 8(%edx), %ebx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 12(%edx), %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movb (%ecx), %ch
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movb %ch, %cl
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %esi, (%esp)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    sarl $31, %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    andb $12, %ch
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movzbl %ch, %ebx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 8(%esp,%ebx), %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl (%esp,%ebx), %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 4(%esp,%ebx), %ebp
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %ebp, %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl 12(%esp,%ebx), %ebx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shrdl %cl, %ebx, %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    shrdl %cl, %ebp, %edx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    sarl %cl, %ebx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %ebx, 12(%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-LABEL: ashr_16bytes:
; X86-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    subl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl (%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl 4(%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl 8(%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl 12(%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlb $3, %al
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %edx, (%esp)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    andb $12, %bl
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movzbl %bl, %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl 4(%esp,%edi), %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl 8(%esp,%edi), %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shrxl %ecx, %ebx, %ebp
; X86-NO-SHLD-HAVE-BMI2-NEXT:    notb %al
; X86-NO-SHLD-HAVE-BMI2-NEXT:    leal (%esi,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlxl %eax, %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    orl %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shrxl %ecx, (%esp,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlxl %eax, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl 12(%esp,%edi), %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shlxl %eax, %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-NEXT:    shrxl %ecx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-NEXT:    sarxl %ecx, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, 12(%esi)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %eax, 8(%esi)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %ebx, (%esi)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    movl %edx, 4(%esi)
; X86-NO-SHLD-HAVE-BMI2-NEXT:    addl $44, %esp
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-LABEL: ashr_16bytes:
; X86-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    subl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl (%edx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 4(%edx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 8(%edx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 12(%edx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %esi, (%esp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    sarl $31, %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    andb $12, %al
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl %al, %eax
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 8(%esp,%eax), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl (%esp,%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 4(%esp,%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdl %cl, %ebx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl 12(%esp,%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %ebx, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    sarxl %ecx, %eax, %eax
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edx, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    movl %edi, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    addl $44, %esp
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %byteOff = load i128, ptr %byteOff.ptr, align 1
  %bitOff = shl i128 %byteOff, 3
  %res = ashr i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}

define void @ashr_16bytes_dwordOff(ptr %src.ptr, ptr %dwordOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-LABEL: ashr_16bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-NEXT:    movq (%rdi), %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-NO-SHLD-NO-BMI2-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    leaq (%rdi,%rdi), %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    notb %cl
; X64-NO-SHLD-NO-BMI2-NEXT:    shlq %cl, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    orq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rdi, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-NEXT:    sarq %cl, %r8
; X64-NO-SHLD-NO-BMI2-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    testb $64, %al
; X64-NO-SHLD-NO-BMI2-NEXT:    cmovneq %r8, %rsi
; X64-NO-SHLD-NO-BMI2-NEXT:    cmoveq %r8, %rdi
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    movq %rsi, (%rdx)
; X64-NO-SHLD-NO-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-LABEL: ashr_16bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    sarq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-SHLD-NO-BMI2-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-LABEL: ashr_16bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlb $5, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shrxq %rcx, (%rdi), %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movl %ecx, %edi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    notb %dil
; X64-NO-SHLD-HAVE-BMI2-NEXT:    leaq (%rax,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-NEXT:    shlxq %rdi, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    orq %rsi, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    sarxq %rcx, %rax, %rsi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    sarq $63, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmovneq %rsi, %rdi
; X64-NO-SHLD-HAVE-BMI2-NEXT:    cmoveq %rsi, %rax
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-LABEL: ashr_16bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    sarxq %rcx, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    testb $64, %cl
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    movq %rax, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-NEXT:    retq
;
; X86-SSE2-LABEL: ashr_16bytes_dwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $32, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE2-NEXT:    movl (%edx), %esi
; X86-SSE2-NEXT:    movl 4(%edx), %edi
; X86-SSE2-NEXT:    movl 8(%edx), %ebx
; X86-SSE2-NEXT:    movl 12(%edx), %edx
; X86-SSE2-NEXT:    movzbl (%ecx), %ecx
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, (%esp)
; X86-SSE2-NEXT:    sarl $31, %edx
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    andl $3, %ecx
; X86-SSE2-NEXT:    movl (%esp,%ecx,4), %edx
; X86-SSE2-NEXT:    movl 4(%esp,%ecx,4), %esi
; X86-SSE2-NEXT:    movl 12(%esp,%ecx,4), %edi
; X86-SSE2-NEXT:    movl 8(%esp,%ecx,4), %ecx
; X86-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-SSE2-NEXT:    movl %edi, 12(%eax)
; X86-SSE2-NEXT:    movl %edx, (%eax)
; X86-SSE2-NEXT:    movl %esi, 4(%eax)
; X86-SSE2-NEXT:    addl $32, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: ashr_16bytes_dwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    pushl %ebx
; X86-SSE42-NEXT:    pushl %edi
; X86-SSE42-NEXT:    pushl %esi
; X86-SSE42-NEXT:    subl $32, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movl (%edx), %esi
; X86-SSE42-NEXT:    movl 4(%edx), %edi
; X86-SSE42-NEXT:    movl 8(%edx), %ebx
; X86-SSE42-NEXT:    movl 12(%edx), %edx
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %esi, (%esp)
; X86-SSE42-NEXT:    sarl $31, %edx
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    andl $3, %ecx
; X86-SSE42-NEXT:    movups (%esp,%ecx,4), %xmm0
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $32, %esp
; X86-SSE42-NEXT:    popl %esi
; X86-SSE42-NEXT:    popl %edi
; X86-SSE42-NEXT:    popl %ebx
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: ashr_16bytes_dwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    pushl %ebx
; X86-AVX-NEXT:    pushl %edi
; X86-AVX-NEXT:    pushl %esi
; X86-AVX-NEXT:    subl $32, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    movl (%edx), %esi
; X86-AVX-NEXT:    movl 4(%edx), %edi
; X86-AVX-NEXT:    movl 8(%edx), %ebx
; X86-AVX-NEXT:    movl 12(%edx), %edx
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %esi, (%esp)
; X86-AVX-NEXT:    sarl $31, %edx
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    andl $3, %ecx
; X86-AVX-NEXT:    vmovups (%esp,%ecx,4), %xmm0
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $32, %esp
; X86-AVX-NEXT:    popl %esi
; X86-AVX-NEXT:    popl %edi
; X86-AVX-NEXT:    popl %ebx
; X86-AVX-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %dwordOff = load i128, ptr %dwordOff.ptr, align 1
  %bitOff = shl i128 %dwordOff, 5
  %res = ashr i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}

define void @lshr_32bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: lshr_32bytes:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %sil, %r9d
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%r9), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%rbx,%rbx), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %rdi, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -40(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%r9,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: lshr_32bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%rax), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rsi, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r8, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_32bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %sil, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rdi, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, -72(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%rsi,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r8, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rax), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rsi, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r8, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rax, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: lshr_32bytes:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rcx,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $24, %cl
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %cl, %r9d
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%r9), %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r9,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: lshr_32bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $24, %al
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %al, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_32bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rcx,8), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $24, %cl
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %cl, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, -72(%rsp,%rcx), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rcx), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rcx), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rcx), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%rcx,%rcx), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %rcx, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $24, %al
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %al, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX-LABEL: lshr_32bytes:
; X64-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (,%rcx,8), %eax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $24, %cl
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl %cl, %r9d
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -64(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -56(%rsp,%r9), %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -48(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -40(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r9,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX-LABEL: lshr_32bytes:
; X64-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $24, %al
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl %al, %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -48(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -56(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -72(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -64(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX-LABEL: lshr_32bytes:
; X64-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%rax,8), %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $24, %al
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %al, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, -72(%rsp,%rax), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %cl
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -64(%rsp,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -56(%rsp,%rax), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -48(%rsp,%rax), %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%rax,%rax), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r9, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: lshr_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $24, %al
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %al, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -48(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -56(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -72(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -64(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rcx, %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-SSE2-LABEL: lshr_32bytes:
; X86-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ebp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ebp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ebp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ebp), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb (%eax), %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%ebp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%ebp), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ah, %dh
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %dh
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $28, %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %ah, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%esp,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %dl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%esp,%edi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%esp,%eax), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%esp,%eax), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%eax,%eax), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%esp,%eax), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%esp,%eax), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%esi,%esi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%esp,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ebx,%ebx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE2-LABEL: lshr_32bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movb (%ecx), %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%ebp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $28, %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %ch, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %ebx, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_32bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%ebx), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $28, %bl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %bl, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%esp,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%esp,%esi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %cl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%ebp,%ebp), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, 32(%esp,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%esp,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%esp,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%esp,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%edi,%edi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%esp,%esi), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, %eax, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%esp,%esi), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%esi,%esi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %ebx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 28(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 24(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 16(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 20(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, (%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 4(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%ecx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%ecx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%ecx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $28, %bl
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %bl, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %edi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-SSE4-LABEL: lshr_32bytes:
; X86-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $28, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 32(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 36(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 44(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%esp,%edi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 40(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%esp,%edi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ecx,%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, (%esp) # 4-byte Folded Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%esp,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ebx,%ebx), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl (%esp), %edi # 4-byte Folded Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Folded Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Folded Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE4-LABEL: lshr_32bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $28, %al
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %al, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 44(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 40(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 32(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 36(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %ebp, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_32bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $28, %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %dl, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %eax, 32(%esp,%ebx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %cl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 36(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 44(%esp,%ebx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edi, %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 40(%esp,%ebx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edi, %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%esi,%esi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edi, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edx, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%esi,%esi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edx, {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, (%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $28, %al
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %al, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%esp,%ebx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 44(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 40(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%esp,%ebx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %ebp, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 32(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 36(%esp,%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX-LABEL: lshr_32bytes:
; X86-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %al
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $28, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 32(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 36(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 44(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 48(%esp,%edi), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 40(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 52(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 56(%esp,%edi), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%ecx,%ecx), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, (%esp) # 4-byte Folded Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 60(%esp,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%ebx,%ebx), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl (%esp), %edi # 4-byte Folded Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Folded Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Folded Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 4(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 24(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, 16(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX-LABEL: lshr_32bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    subl $108, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $28, %al
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl %al, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 48(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 44(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 40(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 56(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 32(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 36(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %ebp, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    addl $108, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX-LABEL: lshr_32bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $28, %dl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %dl, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, 32(%esp,%ebx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %cl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 36(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 48(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%eax,%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 44(%esp,%ebx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edi, %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 40(%esp,%ebx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edi, %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 56(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%esi,%esi), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 52(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edi, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edx, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 60(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%esi,%esi), %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edx, {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, (%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: lshr_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    subl $108, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $28, %al
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %al, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 48(%esp,%ebx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 44(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 40(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 56(%esp,%ebx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 52(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %ebp, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 60(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 32(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 36(%esp,%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    addl $108, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %byteOff = load i256, ptr %byteOff.ptr, align 1
  %bitOff = shl i256 %byteOff, 3
  %res = lshr i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @lshr_32bytes_dwordOff(ptr %src.ptr, ptr %dwordOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: lshr_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $6, %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %sil, %r9d
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%r9,4), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%r9,4), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%rbx,%rbx), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %rdi, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -40(%rsp,%r9,4), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%r9,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: lshr_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $6, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%rax,4), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rsi, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r8, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $5, %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $6, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %sil, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rsi,4), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rsi,4), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rdi, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, -72(%rsp,%rsi,4), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rsi,4), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%rsi,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r8, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $6, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rax,4), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rsi, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r8, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rax, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: lshr_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $6, %cl
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %cl, %r9d
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%r9,4), %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%r9,4), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r9,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: lshr_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $6, %al
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %al, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax,4), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $5, %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $6, %cl
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %cl, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, -72(%rsp,%rcx,4), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rcx,4), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rcx,4), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rcx,4), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%rcx,%rcx), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %rcx, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $6, %al
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %al, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax,4), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX-LABEL: lshr_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, %eax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $6, %cl
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl %cl, %r9d
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -64(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -56(%rsp,%r9,4), %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -48(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -40(%rsp,%r9,4), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r9,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX-LABEL: lshr_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $6, %al
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl %al, %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -48(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -56(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -72(%rsp,%rax,4), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -64(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX-LABEL: lshr_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $5, %cl
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $6, %al
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %al, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, -72(%rsp,%rax,4), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %cl
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -64(%rsp,%rax,4), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -56(%rsp,%rax,4), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -48(%rsp,%rax,4), %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%rax,%rax), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r9, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: lshr_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $6, %al
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %al, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -48(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -56(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -72(%rsp,%rax,4), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -64(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rcx, %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X86-SSE2-LABEL: lshr_32bytes_dwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $92, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl (%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%eax), %esi
; X86-SSE2-NEXT:    movl 12(%eax), %edi
; X86-SSE2-NEXT:    movl 16(%eax), %ebx
; X86-SSE2-NEXT:    movl 20(%eax), %ebp
; X86-SSE2-NEXT:    movl 24(%eax), %edx
; X86-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movzbl (%eax), %eax
; X86-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    andl $7, %eax
; X86-SSE2-NEXT:    movl 16(%esp,%eax,4), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 20(%esp,%eax,4), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 28(%esp,%eax,4), %esi
; X86-SSE2-NEXT:    movl 24(%esp,%eax,4), %edi
; X86-SSE2-NEXT:    movl 36(%esp,%eax,4), %ebx
; X86-SSE2-NEXT:    movl 32(%esp,%eax,4), %ebp
; X86-SSE2-NEXT:    movl 44(%esp,%eax,4), %edx
; X86-SSE2-NEXT:    movl 40(%esp,%eax,4), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-SSE2-NEXT:    movl %edx, 28(%eax)
; X86-SSE2-NEXT:    movl %ebp, 16(%eax)
; X86-SSE2-NEXT:    movl %ebx, 20(%eax)
; X86-SSE2-NEXT:    movl %edi, 8(%eax)
; X86-SSE2-NEXT:    movl %esi, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $92, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: lshr_32bytes_dwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    subl $76, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movups 16(%edx), %xmm1
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    xorps %xmm2, %xmm2
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, (%esp)
; X86-SSE42-NEXT:    andl $7, %ecx
; X86-SSE42-NEXT:    movups (%esp,%ecx,4), %xmm0
; X86-SSE42-NEXT:    movups 16(%esp,%ecx,4), %xmm1
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $76, %esp
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: lshr_32bytes_dwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    subl $76, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %ymm0
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    vmovups %ymm0, (%esp)
; X86-AVX-NEXT:    andl $7, %ecx
; X86-AVX-NEXT:    vmovups (%esp,%ecx,4), %xmm0
; X86-AVX-NEXT:    vmovups 16(%esp,%ecx,4), %xmm1
; X86-AVX-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $76, %esp
; X86-AVX-NEXT:    vzeroupper
; X86-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %dwordOff = load i256, ptr %dwordOff.ptr, align 1
  %bitOff = shl i256 %dwordOff, 5
  %res = lshr i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @lshr_32bytes_qwordOff(ptr %src.ptr, ptr %qwordOff.ptr, ptr %dst) nounwind {
; X64-SSE2-LABEL: lshr_32bytes_qwordOff:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    movq (%rdi), %rax
; X64-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    andl $3, %esi
; X64-SSE2-NEXT:    movq -72(%rsp,%rsi,8), %rax
; X64-SSE2-NEXT:    movq -64(%rsp,%rsi,8), %rcx
; X64-SSE2-NEXT:    movq -48(%rsp,%rsi,8), %rdi
; X64-SSE2-NEXT:    movq -56(%rsp,%rsi,8), %rsi
; X64-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-SSE2-NEXT:    movq %rax, (%rdx)
; X64-SSE2-NEXT:    movq %rcx, 8(%rdx)
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: lshr_32bytes_qwordOff:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    movups (%rdi), %xmm0
; X64-SSE42-NEXT:    movups 16(%rdi), %xmm1
; X64-SSE42-NEXT:    movzbl (%rsi), %eax
; X64-SSE42-NEXT:    xorps %xmm2, %xmm2
; X64-SSE42-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    andl $3, %eax
; X64-SSE42-NEXT:    movups -72(%rsp,%rax,8), %xmm0
; X64-SSE42-NEXT:    movups -56(%rsp,%rax,8), %xmm1
; X64-SSE42-NEXT:    movups %xmm1, 16(%rdx)
; X64-SSE42-NEXT:    movups %xmm0, (%rdx)
; X64-SSE42-NEXT:    retq
;
; X64-AVX-LABEL: lshr_32bytes_qwordOff:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-AVX-NEXT:    movzbl (%rsi), %eax
; X64-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    andl $3, %eax
; X64-AVX-NEXT:    vmovups -72(%rsp,%rax,8), %xmm0
; X64-AVX-NEXT:    vmovups -56(%rsp,%rax,8), %xmm1
; X64-AVX-NEXT:    vmovups %xmm1, 16(%rdx)
; X64-AVX-NEXT:    vmovups %xmm0, (%rdx)
; X64-AVX-NEXT:    vzeroupper
; X64-AVX-NEXT:    retq
;
; X86-SSE2-LABEL: lshr_32bytes_qwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $92, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl (%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%eax), %esi
; X86-SSE2-NEXT:    movl 12(%eax), %edi
; X86-SSE2-NEXT:    movl 16(%eax), %ebx
; X86-SSE2-NEXT:    movl 20(%eax), %ebp
; X86-SSE2-NEXT:    movl 24(%eax), %edx
; X86-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movzbl (%eax), %eax
; X86-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    andl $3, %eax
; X86-SSE2-NEXT:    movl 16(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 20(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 28(%esp,%eax,8), %esi
; X86-SSE2-NEXT:    movl 24(%esp,%eax,8), %edi
; X86-SSE2-NEXT:    movl 36(%esp,%eax,8), %ebx
; X86-SSE2-NEXT:    movl 32(%esp,%eax,8), %ebp
; X86-SSE2-NEXT:    movl 44(%esp,%eax,8), %edx
; X86-SSE2-NEXT:    movl 40(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-SSE2-NEXT:    movl %edx, 28(%eax)
; X86-SSE2-NEXT:    movl %ebp, 16(%eax)
; X86-SSE2-NEXT:    movl %ebx, 20(%eax)
; X86-SSE2-NEXT:    movl %edi, 8(%eax)
; X86-SSE2-NEXT:    movl %esi, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $92, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: lshr_32bytes_qwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    subl $76, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movups 16(%edx), %xmm1
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    xorps %xmm2, %xmm2
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, (%esp)
; X86-SSE42-NEXT:    andl $3, %ecx
; X86-SSE42-NEXT:    movups (%esp,%ecx,8), %xmm0
; X86-SSE42-NEXT:    movups 16(%esp,%ecx,8), %xmm1
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $76, %esp
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: lshr_32bytes_qwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    subl $76, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %ymm0
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    vmovups %ymm0, (%esp)
; X86-AVX-NEXT:    andl $3, %ecx
; X86-AVX-NEXT:    vmovups (%esp,%ecx,8), %xmm0
; X86-AVX-NEXT:    vmovups 16(%esp,%ecx,8), %xmm1
; X86-AVX-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $76, %esp
; X86-AVX-NEXT:    vzeroupper
; X86-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %qwordOff = load i256, ptr %qwordOff.ptr, align 1
  %bitOff = shl i256 %qwordOff, 6
  %res = lshr i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @shl_32bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: shl_32bytes:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    negb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movsbq %sil, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -32(%rsp,%r10), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -24(%rsp,%r10), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -8(%rsp,%r10), %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -16(%rsp,%r10), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: shl_32bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    negb %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movsbq %sil, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: shl_32bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    negb %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movsbq %sil, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -40(%rsp,%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -32(%rsp,%rdi), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rsi, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r8, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, -16(%rsp,%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -24(%rsp,%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rdi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %rsi, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rcx, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: shl_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    negb %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movsbq %sil, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r8, %rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: shl_32bytes:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rcx,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $24, %cl
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    negb %cl
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movsbq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -16(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -24(%rsp,%r8), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -32(%rsp,%r8), %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: shl_32bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $24, %al
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    negb %al
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movsbq %al, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: shl_32bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    negb %sil
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movsbq %sil, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, -16(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -24(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r8, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -40(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -32(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rsi, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %rsi, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r9, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rdi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r10, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rsi, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: shl_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $24, %al
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    negb %al
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movsbq %al, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r8, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX-LABEL: shl_32bytes:
; X64-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (,%rcx,8), %eax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $24, %cl
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    negb %cl
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movsbq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -16(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -24(%rsp,%r8), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -40(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -32(%rsp,%r8), %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r10, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX-LABEL: shl_32bytes:
; X64-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $24, %al
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    negb %al
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movsbq %al, %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX-LABEL: shl_32bytes:
; X64-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    negb %sil
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movsbq %sil, %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, -16(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -24(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r8, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -40(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -32(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %rsi, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrq %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rax, %rsi, %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r9, %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %rdi, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rax, %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r10, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rsi, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: shl_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $24, %al
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    negb %al
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movsbq %al, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r8, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-SSE2-LABEL: shl_32bytes:
; X86-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb (%eax), %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%ecx), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%ecx), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ah, %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $28, %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    negb %ah
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movsbl %ah, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 64(%esp,%ebx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 68(%esp,%ebx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %dl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 76(%esp,%ebx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 72(%esp,%ebx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 84(%esp,%ebx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 80(%esp,%ebx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 92(%esp,%ebx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 88(%esp,%ebx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE2-LABEL: shl_32bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%eax), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movb (%ecx), %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%eax), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $28, %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    negb %ch
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movsbl %ch, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%esp,%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%esp,%eax), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edx, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%esp,%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 64(%esp,%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 68(%esp,%eax), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %ebx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%esp,%eax), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 72(%esp,%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 76(%esp,%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edx, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 24(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 28(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 16(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 20(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 8(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 12(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, (%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 4(%eax)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE2-LABEL: shl_32bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%ebx), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %dl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $28, %bl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    negb %bl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movsbl %bl, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 64(%esp,%esi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 68(%esp,%esi), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %eax, %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %dl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %edx, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 72(%esp,%esi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 76(%esp,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ebp, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %esi, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %edx, %ecx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 80(%esp,%ebp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %edx, %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 84(%esp,%ebp), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %esi, %ebx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %esi, %ecx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %esi, {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %esi, 92(%esp,%ecx), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 88(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %eax, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %edx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %edx, %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, (%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: shl_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%ecx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%ecx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%ecx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $28, %bl
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    negb %bl
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movsbl %bl, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%esp,%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%esp,%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edx, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%esp,%eax), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 64(%esp,%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 68(%esp,%eax), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%esp,%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 72(%esp,%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 76(%esp,%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edx, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %esi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-SSE4-LABEL: shl_32bytes:
; X86-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %cl, %dh
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %dh
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $28, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    negb %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movsbl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 84(%esp,%ebx), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %dl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 80(%esp,%ebx), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 76(%esp,%ebx), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 72(%esp,%ebx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 68(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 64(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 88(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 92(%esp,%eax), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE4-LABEL: shl_32bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $28, %al
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    negb %al
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movsbl %al, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 64(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 68(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %ebx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 72(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %esi, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 76(%esp,%ebp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edx, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 28(%edx)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 24(%edx)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 4(%edx)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 8(%edx)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 12(%edx)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 16(%edx)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 20(%edx)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, (%edx)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE4-LABEL: shl_32bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $28, %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    negb %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movsbl %dl, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 84(%esp,%edx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %cl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 80(%esp,%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 76(%esp,%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 72(%esp,%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 68(%esp,%edx), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 64(%esp,%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 88(%esp,%edx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, 92(%esp,%edx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, (%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 28(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 24(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 4(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 8(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 12(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 16(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 20(%ecx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: shl_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $28, %al
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    negb %al
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movsbl %al, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 64(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 68(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%esp,%ebx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%esp,%ebx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %ebp, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 72(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %esi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%esp,%ebx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 76(%esp,%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 28(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 24(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %esi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %esi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, 4(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 8(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 12(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 16(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 20(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, (%edx)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX-LABEL: shl_32bytes:
; X86-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %cl, %dh
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %dh
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $28, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    negb %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movsbl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 84(%esp,%ebx), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %dl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 80(%esp,%ebx), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edi, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 76(%esp,%ebx), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %esi, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 72(%esp,%ebx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 68(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 64(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 88(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edi, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 92(%esp,%eax), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, 28(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 8(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX-LABEL: shl_32bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $28, %al
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    negb %al
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movsbl %al, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 64(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 68(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 60(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 56(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 52(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %ebx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 72(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %esi, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 48(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 76(%esp,%ebp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %edx, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, 28(%edx)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 24(%edx)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldl %cl, %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, 4(%edx)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 8(%edx)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 12(%edx)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 16(%edx)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 20(%edx)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, (%edx)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX-LABEL: shl_32bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %al
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $28, %dl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    negb %dl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movsbl %dl, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 84(%esp,%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %al
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 80(%esp,%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 76(%esp,%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 72(%esp,%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 68(%esp,%edx), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 64(%esp,%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 88(%esp,%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, 92(%esp,%edx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, (%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 28(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 24(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 4(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 8(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 12(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 16(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 20(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: shl_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $28, %al
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    negb %al
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movsbl %al, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 64(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 68(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 60(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 56(%esp,%ebx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 52(%esp,%ebx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %ebp, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 72(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %esi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 48(%esp,%ebx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 76(%esp,%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, 28(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 24(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ecx, %esi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldl %cl, %esi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, 4(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 8(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 12(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 16(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 20(%edx)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, (%edx)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %byteOff = load i256, ptr %byteOff.ptr, align 1
  %bitOff = shl i256 %byteOff, 3
  %res = shl i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @shl_32bytes_dwordOff(ptr %src.ptr, ptr %dwordOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: shl_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $2, %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    negb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movsbq %sil, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -32(%rsp,%r10), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -24(%rsp,%r10), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -8(%rsp,%r10), %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -16(%rsp,%r10), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: shl_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $2, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    negb %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movsbq %sil, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: shl_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $5, %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $2, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    negb %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movsbq %sil, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -40(%rsp,%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -32(%rsp,%rdi), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rsi, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r8, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, -16(%rsp,%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -24(%rsp,%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rdi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %rsi, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rcx, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: shl_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $2, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    negb %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movsbq %sil, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r8, %rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: shl_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $2, %cl
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $24, %cl
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    negb %cl
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movsbq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -16(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -24(%rsp,%r8), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -32(%rsp,%r8), %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: shl_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $2, %al
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $24, %al
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    negb %al
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movsbq %al, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: shl_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $5, %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $2, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    negb %sil
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movsbq %sil, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, -16(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -24(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r8, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -40(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -32(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rsi, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %rsi, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r9, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rdi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r10, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rsi, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: shl_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm2, %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $2, %al
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $24, %al
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    negb %al
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movsbq %al, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r8, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX-LABEL: shl_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, %eax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $2, %cl
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $24, %cl
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    negb %cl
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movsbq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -16(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -24(%rsp,%r8), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -40(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -32(%rsp,%r8), %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r10, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX-LABEL: shl_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $2, %al
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $24, %al
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    negb %al
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movsbq %al, %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX-LABEL: shl_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $5, %al
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $2, %sil
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    negb %sil
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movsbq %sil, %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, -16(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -24(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r8, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -40(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -32(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %rsi, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrq %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rax, %rsi, %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r9, %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %rdi, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rax, %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r10, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rsi, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: shl_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $2, %al
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $24, %al
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    negb %al
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movsbq %al, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldq %cl, %rsi, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -40(%rsp,%rax), %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -32(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r8, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shldq %cl, %r8, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X86-SSE2-LABEL: shl_32bytes_dwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $92, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-SSE2-NEXT:    movl (%ebp), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%ebp), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%ebp), %esi
; X86-SSE2-NEXT:    movl 12(%ebp), %edi
; X86-SSE2-NEXT:    movl 16(%ebp), %ebx
; X86-SSE2-NEXT:    movzbl (%ecx), %ecx
; X86-SSE2-NEXT:    movl 20(%ebp), %edx
; X86-SSE2-NEXT:    movl 24(%ebp), %eax
; X86-SSE2-NEXT:    movl 28(%ebp), %ebp
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    shlb $2, %cl
; X86-SSE2-NEXT:    andb $28, %cl
; X86-SSE2-NEXT:    negb %cl
; X86-SSE2-NEXT:    movsbl %cl, %edx
; X86-SSE2-NEXT:    movl 48(%esp,%edx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 52(%esp,%edx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 60(%esp,%edx), %esi
; X86-SSE2-NEXT:    movl 56(%esp,%edx), %edi
; X86-SSE2-NEXT:    movl 68(%esp,%edx), %ebx
; X86-SSE2-NEXT:    movl 64(%esp,%edx), %ebp
; X86-SSE2-NEXT:    movl 76(%esp,%edx), %ecx
; X86-SSE2-NEXT:    movl 72(%esp,%edx), %edx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %edx, 24(%eax)
; X86-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-SSE2-NEXT:    movl %ebp, 16(%eax)
; X86-SSE2-NEXT:    movl %ebx, 20(%eax)
; X86-SSE2-NEXT:    movl %edi, 8(%eax)
; X86-SSE2-NEXT:    movl %esi, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $92, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: shl_32bytes_dwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    subl $76, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movups 16(%edx), %xmm1
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    xorps %xmm2, %xmm2
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm2, (%esp)
; X86-SSE42-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    shlb $2, %cl
; X86-SSE42-NEXT:    andb $28, %cl
; X86-SSE42-NEXT:    negb %cl
; X86-SSE42-NEXT:    movsbl %cl, %ecx
; X86-SSE42-NEXT:    movups 32(%esp,%ecx), %xmm0
; X86-SSE42-NEXT:    movups 48(%esp,%ecx), %xmm1
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $76, %esp
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: shl_32bytes_dwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    subl $76, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %ymm0
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-AVX-NEXT:    vmovups %ymm1, (%esp)
; X86-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    shlb $2, %cl
; X86-AVX-NEXT:    andb $28, %cl
; X86-AVX-NEXT:    negb %cl
; X86-AVX-NEXT:    movsbl %cl, %ecx
; X86-AVX-NEXT:    vmovups 32(%esp,%ecx), %xmm0
; X86-AVX-NEXT:    vmovups 48(%esp,%ecx), %xmm1
; X86-AVX-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $76, %esp
; X86-AVX-NEXT:    vzeroupper
; X86-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %dwordOff = load i256, ptr %dwordOff.ptr, align 1
  %bitOff = shl i256 %dwordOff, 5
  %res = shl i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @shl_32bytes_qwordOff(ptr %src.ptr, ptr %qwordOff.ptr, ptr %dst) nounwind {
; X64-SSE2-LABEL: shl_32bytes_qwordOff:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    movq (%rdi), %rax
; X64-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    shlb $3, %sil
; X64-SSE2-NEXT:    andb $24, %sil
; X64-SSE2-NEXT:    negb %sil
; X64-SSE2-NEXT:    movsbq %sil, %rax
; X64-SSE2-NEXT:    movq -40(%rsp,%rax), %rcx
; X64-SSE2-NEXT:    movq -32(%rsp,%rax), %rsi
; X64-SSE2-NEXT:    movq -16(%rsp,%rax), %rdi
; X64-SSE2-NEXT:    movq -24(%rsp,%rax), %rax
; X64-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-SSE2-NEXT:    movq %rcx, (%rdx)
; X64-SSE2-NEXT:    movq %rsi, 8(%rdx)
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: shl_32bytes_qwordOff:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    movups (%rdi), %xmm0
; X64-SSE42-NEXT:    movups 16(%rdi), %xmm1
; X64-SSE42-NEXT:    movzbl (%rsi), %eax
; X64-SSE42-NEXT:    xorps %xmm2, %xmm2
; X64-SSE42-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    shlb $3, %al
; X64-SSE42-NEXT:    andb $24, %al
; X64-SSE42-NEXT:    negb %al
; X64-SSE42-NEXT:    movsbq %al, %rax
; X64-SSE42-NEXT:    movups -40(%rsp,%rax), %xmm0
; X64-SSE42-NEXT:    movups -24(%rsp,%rax), %xmm1
; X64-SSE42-NEXT:    movups %xmm1, 16(%rdx)
; X64-SSE42-NEXT:    movups %xmm0, (%rdx)
; X64-SSE42-NEXT:    retq
;
; X64-AVX-LABEL: shl_32bytes_qwordOff:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-AVX-NEXT:    movzbl (%rsi), %eax
; X64-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-AVX-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    shlb $3, %al
; X64-AVX-NEXT:    andb $24, %al
; X64-AVX-NEXT:    negb %al
; X64-AVX-NEXT:    movsbq %al, %rax
; X64-AVX-NEXT:    vmovups -40(%rsp,%rax), %xmm0
; X64-AVX-NEXT:    vmovups -24(%rsp,%rax), %xmm1
; X64-AVX-NEXT:    vmovups %xmm1, 16(%rdx)
; X64-AVX-NEXT:    vmovups %xmm0, (%rdx)
; X64-AVX-NEXT:    vzeroupper
; X64-AVX-NEXT:    retq
;
; X86-SSE2-LABEL: shl_32bytes_qwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $92, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-SSE2-NEXT:    movl (%ebp), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%ebp), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%ebp), %esi
; X86-SSE2-NEXT:    movl 12(%ebp), %edi
; X86-SSE2-NEXT:    movl 16(%ebp), %ebx
; X86-SSE2-NEXT:    movzbl (%ecx), %ecx
; X86-SSE2-NEXT:    movl 20(%ebp), %edx
; X86-SSE2-NEXT:    movl 24(%ebp), %eax
; X86-SSE2-NEXT:    movl 28(%ebp), %ebp
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    shlb $3, %cl
; X86-SSE2-NEXT:    andb $24, %cl
; X86-SSE2-NEXT:    negb %cl
; X86-SSE2-NEXT:    movsbl %cl, %edx
; X86-SSE2-NEXT:    movl 48(%esp,%edx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 52(%esp,%edx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 60(%esp,%edx), %esi
; X86-SSE2-NEXT:    movl 56(%esp,%edx), %edi
; X86-SSE2-NEXT:    movl 68(%esp,%edx), %ebx
; X86-SSE2-NEXT:    movl 64(%esp,%edx), %ebp
; X86-SSE2-NEXT:    movl 76(%esp,%edx), %ecx
; X86-SSE2-NEXT:    movl 72(%esp,%edx), %edx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %edx, 24(%eax)
; X86-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-SSE2-NEXT:    movl %ebp, 16(%eax)
; X86-SSE2-NEXT:    movl %ebx, 20(%eax)
; X86-SSE2-NEXT:    movl %edi, 8(%eax)
; X86-SSE2-NEXT:    movl %esi, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $92, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: shl_32bytes_qwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    subl $76, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movups 16(%edx), %xmm1
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    xorps %xmm2, %xmm2
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm2, (%esp)
; X86-SSE42-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    shlb $3, %cl
; X86-SSE42-NEXT:    andb $24, %cl
; X86-SSE42-NEXT:    negb %cl
; X86-SSE42-NEXT:    movsbl %cl, %ecx
; X86-SSE42-NEXT:    movups 32(%esp,%ecx), %xmm0
; X86-SSE42-NEXT:    movups 48(%esp,%ecx), %xmm1
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $76, %esp
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: shl_32bytes_qwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    subl $76, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %ymm0
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-AVX-NEXT:    vmovups %ymm1, (%esp)
; X86-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    shlb $3, %cl
; X86-AVX-NEXT:    andb $24, %cl
; X86-AVX-NEXT:    negb %cl
; X86-AVX-NEXT:    movsbl %cl, %ecx
; X86-AVX-NEXT:    vmovups 32(%esp,%ecx), %xmm0
; X86-AVX-NEXT:    vmovups 48(%esp,%ecx), %xmm1
; X86-AVX-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $76, %esp
; X86-AVX-NEXT:    vzeroupper
; X86-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %qwordOff = load i256, ptr %qwordOff.ptr, align 1
  %bitOff = shl i256 %qwordOff, 6
  %res = shl i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @ashr_32bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: ashr_32bytes:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %sil, %r9d
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%r9), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%rbx,%rbx), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %rdi, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -40(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%r9,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: ashr_32bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%rax), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rsi, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r8, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarq %cl, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_32bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %sil, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rdi, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, -72(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%rsi,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r8, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rax), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rsi, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r8, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxq %rcx, %rax, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: ashr_32bytes:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq 16(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $24, %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %sil, %r9d
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%r9), %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r9,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: ashr_32bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq 16(%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_32bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 16(%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %sil, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, -72(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%rsi,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 16(%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxq %rcx, %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX-LABEL: ashr_32bytes:
; X64-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq 16(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $24, %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl %sil, %r9d
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -64(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -56(%rsp,%r9), %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -48(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -40(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r9,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    sarq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX-LABEL: ashr_32bytes:
; X64-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq 16(%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -48(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -56(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -72(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -64(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX-LABEL: ashr_32bytes:
; X64-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq 16(%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $24, %sil
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %sil, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rcx, -72(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -64(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -56(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rcx, %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -48(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%rsi,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rcx, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: ashr_32bytes:
; X64-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq 16(%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $24, %sil
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -48(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -56(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -72(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -64(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarxq %rcx, %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-SSE2-LABEL: ashr_32bytes:
; X86-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%esi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%esi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%esi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%esi), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %dl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarl $31, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $28, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%esp,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%esp,%edi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %eax, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%esp,%eax), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%esp,%eax), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edx,%edx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ebx,%ebx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%esp,%eax), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%eax,%eax), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 1-byte Folded Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 28(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 24(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 16(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 20(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 8(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 12(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, (%ecx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 4(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE2-LABEL: ashr_32bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ecx), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%ecx), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%ecx), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%ecx), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarl $31, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $28, %al
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %al, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %ebx, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_32bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esi), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%esi), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%esi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%esi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%edx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%esi), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%esi), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%esi), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarl $31, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $28, %dl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %dl, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%esp,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%esp,%esi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %cl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%ebp,%ebp), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %ebx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, 32(%esp,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%esp,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%esp,%esi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %eax, %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%esp,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%edi,%edi), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%esp,%esi), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, %eax, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%esp,%esi), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%esi,%esi), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %ebx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxl %ebp, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 28(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 24(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 16(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 20(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, (%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 4(%edi)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%ecx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%ecx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%ecx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%ecx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarl $31, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $28, %al
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %al, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxl %ecx, %edi, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $92, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-SSE4-LABEL: ashr_32bytes:
; X86-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 16(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 20(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 24(%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 28(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarl $31, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $28, %al
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %al, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 32(%esp,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 36(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %cl, %dh
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 44(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 40(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%esp,%edi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%esp,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 28(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 4(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 24(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 16(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 20(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 8(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 12(%ecx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, (%ecx)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE4-LABEL: ashr_32bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 16(%ecx), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 20(%ecx), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 24(%ecx), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 28(%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarl $31, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $28, %al
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %al, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 44(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 40(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 32(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 36(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %ebp, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_32bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 16(%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 20(%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 24(%ecx), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 28(%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %bl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $28, %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %dl, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %eax, 32(%esp,%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 36(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 44(%esp,%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebp, %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 40(%esp,%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebp, %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%esi,%esi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edx, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%esp,%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%ecx,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %edx, {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxl %ebx, %ecx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, (%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $108, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 16(%ecx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 20(%ecx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 24(%ecx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 28(%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarl $31, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $28, %al
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %al, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%esp,%ebx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 44(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 40(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%esp,%ebx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %ebp, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 32(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 36(%esp,%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $108, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX-LABEL: ashr_32bytes:
; X86-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    subl $108, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 16(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 20(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 24(%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 28(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    sarl $31, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $28, %al
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl %al, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 32(%esp,%edi), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 36(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %cl, %dh
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %dl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %eax, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 44(%esp,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 48(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %eax, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 40(%esp,%edi), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 52(%esp,%edi), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 56(%esp,%edi), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 60(%esp,%edi), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dh, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    sarl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 28(%ecx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 4(%ecx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 24(%ecx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, 16(%ecx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 20(%ecx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 8(%ecx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 12(%ecx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, (%ecx)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl $108, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX-LABEL: ashr_32bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    subl $108, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 16(%ecx), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 20(%ecx), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 24(%ecx), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 28(%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarl $31, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $28, %al
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl %al, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 48(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 44(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 40(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 56(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 32(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 36(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %ebp, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    addl $108, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX-LABEL: ashr_32bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    subl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 16(%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 20(%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 24(%ecx), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 28(%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %bl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $28, %dl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %dl, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %eax, 32(%esp,%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 36(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 48(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%eax,%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 44(%esp,%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebp, %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %edx, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %edx, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 40(%esp,%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebp, %edx, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 56(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%esi,%esi), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 52(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edx, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 60(%esp,%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%ecx,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %ebx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %edx, {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarxl %ebx, %ecx, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, (%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl $108, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: ashr_32bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    subl $108, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 16(%ecx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 20(%ecx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 24(%ecx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 28(%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $3, %cl
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarl $31, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $28, %al
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %al, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 48(%esp,%ebx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 44(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 40(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 56(%esp,%ebx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 52(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %ebp, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 60(%esp,%ebx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 32(%esp,%ebx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 36(%esp,%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %esi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    addl $108, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %byteOff = load i256, ptr %byteOff.ptr, align 1
  %bitOff = shl i256 %byteOff, 3
  %res = ashr i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @ashr_32bytes_dwordOff(ptr %src.ptr, ptr %dwordOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: ashr_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andb $6, %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %sil, %r9d
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%r9,4), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%r9,4), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%rbx,%rbx), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %rdi, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -40(%rsp,%r9,4), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%r9,%r9), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: ashr_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andb $6, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%rax,4), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rsi, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r8, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarq %cl, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $5, %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $6, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %sil, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rsi,4), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rsi,4), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rdi, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, -72(%rsp,%rsi,4), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rsi,4), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%rsi,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r8, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andb $6, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rax,4), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rsi, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r8, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxq %rcx, %rax, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: ashr_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq 16(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andb $6, %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %sil, %r9d
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%r9,4), %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%r9,4), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r9,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: ashr_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq 16(%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andb $6, %sil
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax,4), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 16(%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $5, %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $6, %sil
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %sil, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, -72(%rsp,%rsi,4), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rsi,4), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rsi,4), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rsi,4), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%rsi,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 16(%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andb $6, %sil
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax,4), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxq %rcx, %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX-LABEL: ashr_32bytes_dwordOff:
; X64-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq 16(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %eax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlb $5, %al
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    andb $6, %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movzbl %sil, %r9d
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -64(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -56(%rsp,%r9,4), %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -48(%rsp,%r9,4), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -40(%rsp,%r9,4), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r9,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r11, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r8, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    sarq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX-LABEL: ashr_32bytes_dwordOff:
; X64-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq 16(%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andb $6, %sil
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -48(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -56(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -72(%rsp,%rax,4), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -64(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarq %cl, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX-LABEL: ashr_32bytes_dwordOff:
; X64-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq 16(%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq 24(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $5, %al
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andb $6, %sil
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %sil, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rcx, -72(%rsp,%rsi,4), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -64(%rsp,%rsi,4), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -56(%rsp,%rsi,4), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%r8,%r8), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rcx, %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -48(%rsp,%rsi,4), %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%rsi,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rcx, %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rdi, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: ashr_32bytes_dwordOff:
; X64-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq 16(%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq 24(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shlb $5, %cl
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andb $6, %sil
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movzbl %sil, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -48(%rsp,%rax,4), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -56(%rsp,%rax,4), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rsi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -72(%rsp,%rax,4), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -64(%rsp,%rax,4), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarxq %rcx, %rsi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X86-SSE2-LABEL: ashr_32bytes_dwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $92, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl (%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%eax), %edi
; X86-SSE2-NEXT:    movl 12(%eax), %ebx
; X86-SSE2-NEXT:    movl 16(%eax), %ebp
; X86-SSE2-NEXT:    movl 20(%eax), %esi
; X86-SSE2-NEXT:    movl 24(%eax), %edx
; X86-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movzbl (%eax), %eax
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    sarl $31, %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    andl $7, %eax
; X86-SSE2-NEXT:    movl 16(%esp,%eax,4), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 20(%esp,%eax,4), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 28(%esp,%eax,4), %esi
; X86-SSE2-NEXT:    movl 24(%esp,%eax,4), %edi
; X86-SSE2-NEXT:    movl 36(%esp,%eax,4), %ebx
; X86-SSE2-NEXT:    movl 32(%esp,%eax,4), %ebp
; X86-SSE2-NEXT:    movl 44(%esp,%eax,4), %edx
; X86-SSE2-NEXT:    movl 40(%esp,%eax,4), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-SSE2-NEXT:    movl %edx, 28(%eax)
; X86-SSE2-NEXT:    movl %ebp, 16(%eax)
; X86-SSE2-NEXT:    movl %ebx, 20(%eax)
; X86-SSE2-NEXT:    movl %edi, 8(%eax)
; X86-SSE2-NEXT:    movl %esi, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $92, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: ashr_32bytes_dwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    pushl %ebx
; X86-SSE42-NEXT:    pushl %edi
; X86-SSE42-NEXT:    pushl %esi
; X86-SSE42-NEXT:    subl $64, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movl 16(%edx), %esi
; X86-SSE42-NEXT:    movl 20(%edx), %edi
; X86-SSE42-NEXT:    movl 24(%edx), %ebx
; X86-SSE42-NEXT:    movl 28(%edx), %edx
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, (%esp)
; X86-SSE42-NEXT:    sarl $31, %edx
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    andl $7, %ecx
; X86-SSE42-NEXT:    movups (%esp,%ecx,4), %xmm0
; X86-SSE42-NEXT:    movups 16(%esp,%ecx,4), %xmm1
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $64, %esp
; X86-SSE42-NEXT:    popl %esi
; X86-SSE42-NEXT:    popl %edi
; X86-SSE42-NEXT:    popl %ebx
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: ashr_32bytes_dwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    pushl %ebx
; X86-AVX-NEXT:    pushl %edi
; X86-AVX-NEXT:    pushl %esi
; X86-AVX-NEXT:    subl $64, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %xmm0
; X86-AVX-NEXT:    movl 16(%edx), %esi
; X86-AVX-NEXT:    movl 20(%edx), %edi
; X86-AVX-NEXT:    movl 24(%edx), %ebx
; X86-AVX-NEXT:    movl 28(%edx), %edx
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    vmovaps %xmm0, (%esp)
; X86-AVX-NEXT:    sarl $31, %edx
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    andl $7, %ecx
; X86-AVX-NEXT:    vmovups (%esp,%ecx,4), %xmm0
; X86-AVX-NEXT:    vmovups 16(%esp,%ecx,4), %xmm1
; X86-AVX-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $64, %esp
; X86-AVX-NEXT:    popl %esi
; X86-AVX-NEXT:    popl %edi
; X86-AVX-NEXT:    popl %ebx
; X86-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %dwordOff = load i256, ptr %dwordOff.ptr, align 1
  %bitOff = shl i256 %dwordOff, 5
  %res = ashr i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @ashr_32bytes_qwordOff(ptr %src.ptr, ptr %qwordOff.ptr, ptr %dst) nounwind {
; X64-SSE2-LABEL: ashr_32bytes_qwordOff:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    movq (%rdi), %rax
; X64-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-SSE2-NEXT:    movq 24(%rdi), %rdi
; X64-SSE2-NEXT:    movzbl (%rsi), %esi
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    sarq $63, %rdi
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    andl $3, %esi
; X64-SSE2-NEXT:    movq -72(%rsp,%rsi,8), %rax
; X64-SSE2-NEXT:    movq -64(%rsp,%rsi,8), %rcx
; X64-SSE2-NEXT:    movq -48(%rsp,%rsi,8), %rdi
; X64-SSE2-NEXT:    movq -56(%rsp,%rsi,8), %rsi
; X64-SSE2-NEXT:    movq %rsi, 16(%rdx)
; X64-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-SSE2-NEXT:    movq %rax, (%rdx)
; X64-SSE2-NEXT:    movq %rcx, 8(%rdx)
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: ashr_32bytes_qwordOff:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    movups (%rdi), %xmm0
; X64-SSE42-NEXT:    movq 16(%rdi), %rax
; X64-SSE42-NEXT:    movq 24(%rdi), %rcx
; X64-SSE42-NEXT:    movzbl (%rsi), %esi
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    sarq $63, %rcx
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    andl $3, %esi
; X64-SSE42-NEXT:    movups -72(%rsp,%rsi,8), %xmm0
; X64-SSE42-NEXT:    movups -56(%rsp,%rsi,8), %xmm1
; X64-SSE42-NEXT:    movups %xmm1, 16(%rdx)
; X64-SSE42-NEXT:    movups %xmm0, (%rdx)
; X64-SSE42-NEXT:    retq
;
; X64-AVX-LABEL: ashr_32bytes_qwordOff:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovups (%rdi), %xmm0
; X64-AVX-NEXT:    movq 16(%rdi), %rax
; X64-AVX-NEXT:    movq 24(%rdi), %rcx
; X64-AVX-NEXT:    movzbl (%rsi), %esi
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    sarq $63, %rcx
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    andl $3, %esi
; X64-AVX-NEXT:    vmovups -72(%rsp,%rsi,8), %xmm0
; X64-AVX-NEXT:    vmovups -56(%rsp,%rsi,8), %xmm1
; X64-AVX-NEXT:    vmovups %xmm1, 16(%rdx)
; X64-AVX-NEXT:    vmovups %xmm0, (%rdx)
; X64-AVX-NEXT:    retq
;
; X86-SSE2-LABEL: ashr_32bytes_qwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $92, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl (%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%eax), %edi
; X86-SSE2-NEXT:    movl 12(%eax), %ebx
; X86-SSE2-NEXT:    movl 16(%eax), %ebp
; X86-SSE2-NEXT:    movl 20(%eax), %esi
; X86-SSE2-NEXT:    movl 24(%eax), %edx
; X86-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movzbl (%eax), %eax
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    sarl $31, %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    andl $3, %eax
; X86-SSE2-NEXT:    movl 16(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 20(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 28(%esp,%eax,8), %esi
; X86-SSE2-NEXT:    movl 24(%esp,%eax,8), %edi
; X86-SSE2-NEXT:    movl 36(%esp,%eax,8), %ebx
; X86-SSE2-NEXT:    movl 32(%esp,%eax,8), %ebp
; X86-SSE2-NEXT:    movl 44(%esp,%eax,8), %edx
; X86-SSE2-NEXT:    movl 40(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-SSE2-NEXT:    movl %edx, 28(%eax)
; X86-SSE2-NEXT:    movl %ebp, 16(%eax)
; X86-SSE2-NEXT:    movl %ebx, 20(%eax)
; X86-SSE2-NEXT:    movl %edi, 8(%eax)
; X86-SSE2-NEXT:    movl %esi, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $92, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: ashr_32bytes_qwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    pushl %ebx
; X86-SSE42-NEXT:    pushl %edi
; X86-SSE42-NEXT:    pushl %esi
; X86-SSE42-NEXT:    subl $64, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movl 16(%edx), %esi
; X86-SSE42-NEXT:    movl 20(%edx), %edi
; X86-SSE42-NEXT:    movl 24(%edx), %ebx
; X86-SSE42-NEXT:    movl 28(%edx), %edx
; X86-SSE42-NEXT:    movzbl (%ecx), %ecx
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, (%esp)
; X86-SSE42-NEXT:    sarl $31, %edx
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    andl $3, %ecx
; X86-SSE42-NEXT:    movups (%esp,%ecx,8), %xmm0
; X86-SSE42-NEXT:    movups 16(%esp,%ecx,8), %xmm1
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $64, %esp
; X86-SSE42-NEXT:    popl %esi
; X86-SSE42-NEXT:    popl %edi
; X86-SSE42-NEXT:    popl %ebx
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: ashr_32bytes_qwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    pushl %ebx
; X86-AVX-NEXT:    pushl %edi
; X86-AVX-NEXT:    pushl %esi
; X86-AVX-NEXT:    subl $64, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %xmm0
; X86-AVX-NEXT:    movl 16(%edx), %esi
; X86-AVX-NEXT:    movl 20(%edx), %edi
; X86-AVX-NEXT:    movl 24(%edx), %ebx
; X86-AVX-NEXT:    movl 28(%edx), %edx
; X86-AVX-NEXT:    movzbl (%ecx), %ecx
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    vmovaps %xmm0, (%esp)
; X86-AVX-NEXT:    sarl $31, %edx
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    andl $3, %ecx
; X86-AVX-NEXT:    vmovups (%esp,%ecx,8), %xmm0
; X86-AVX-NEXT:    vmovups 16(%esp,%ecx,8), %xmm1
; X86-AVX-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $64, %esp
; X86-AVX-NEXT:    popl %esi
; X86-AVX-NEXT:    popl %edi
; X86-AVX-NEXT:    popl %ebx
; X86-AVX-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %qwordOff = load i256, ptr %qwordOff.ptr, align 1
  %bitOff = shl i256 %qwordOff, 6
  %res = ashr i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}

define void @lshr_64bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: lshr_64bytes:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 56(%rdi), %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%rsi), %edi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rdi,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %edi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -128(%rsp,%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -120(%rsp,%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -112(%rsp,%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%rbx,%rbx), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %r8, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -104(%rsp,%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -96(%rsp,%rdi), %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%r14,%r14), %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r15, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -88(%rsp,%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -80(%rsp,%rdi), %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%r13,%r13), %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r12, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r14, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -72(%rsp,%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%rdi,%rdi), %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r13, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: lshr_64bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 32(%rdi), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 40(%rdi), %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 48(%rdi), %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -112(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -128(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -120(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -96(%rsp,%rax), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -104(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r10, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -80(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -88(%rsp,%rax), %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r11, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r14, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r15, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_64bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 32(%rdi), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 40(%rdi), %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 48(%rdi), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%rsi), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rax,8), %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -120(%rsp,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -112(%rsp,%rax), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r8, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %cl
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r10,%r10), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, -128(%rsp,%rax), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -104(%rsp,%rax), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r11, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -96(%rsp,%rax), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r14,%r14), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r10, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -88(%rsp,%rax), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r10, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -80(%rsp,%rax), %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r15,%r15), %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r12, %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r14, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r15, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%rax,%rax), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r14, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r12, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq $8, %rsp
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 32(%rdi), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 40(%rdi), %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 48(%rdi), %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -112(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -128(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -120(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -96(%rsp,%rax), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -104(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r10, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -80(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -88(%rsp,%rax), %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r11, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r14, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rcx, %rax, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r15, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: lshr_64bytes:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 48(%rdi), %xmm3
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl (%rsi), %r8d
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%r8,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %r8d
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -128(%rsp,%r8), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -120(%rsp,%r8), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r9,%r9), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -104(%rsp,%r8), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -96(%rsp,%r8), %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r12,%r12), %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -112(%rsp,%r8), %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r14, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -88(%rsp,%r8), %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -80(%rsp,%r8), %rbp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%rbp,%rbp), %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r13, %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %r14, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r12, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rbp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -72(%rsp,%r8), %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r8,%r8), %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %rbp, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r9, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r12, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq $8, %rsp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: lshr_64bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 48(%rdi), %xmm3
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r11
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_64bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 48(%rdi), %xmm3
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%rsi), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, -128(%rsp,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %cl
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -120(%rsp,%rax), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -112(%rsp,%rax), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r10,%r10), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -104(%rsp,%rax), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r11, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -96(%rsp,%rax), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r14,%r14), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rbx, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r9, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -88(%rsp,%rax), %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %rbx, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -80(%rsp,%rax), %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r12,%r12), %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r13, %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r15, %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r14, %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r14, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r12, %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%rax,%rax), %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r15, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r14, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r9, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r10, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r15, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rbx, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r13, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 48(%rdi), %xmm3
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rcx, %r11, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX1-LABEL: lshr_64bytes:
; X64-NO-SHLD-NO-BMI2-AVX1:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %rbp
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %rax
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl (%rsi), %r9d
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (,%r9,8), %eax
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    andl $56, %r9d
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -128(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -120(%rsp,%r9), %r8
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -104(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r10, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -96(%rsp,%r9), %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    leaq (%r12,%r12), %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -112(%rsp,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %rbx, %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r14, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -88(%rsp,%r9), %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r14, %r13
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r13
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -80(%rsp,%r9), %rbp
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    leaq (%rbp,%rbp), %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r13, %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    addq %r14, %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r12, %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %rbp
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -72(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    leaq (%r9,%r9), %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %rbp, %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r8, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r9, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %rbx, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r12, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r14, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    addq $8, %rsp
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %rbp
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX1-LABEL: lshr_64bytes:
; X64-HAVE-SHLD-NO-BMI2-AVX1:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r11
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r11, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX1-LABEL: lshr_64bytes:
; X64-NO-SHLD-HAVE-BMI2-AVX1:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r13
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $56, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, -128(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -120(%rsp,%rsi), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -112(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leaq (%r10,%r10), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -104(%rsp,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, %r11, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -96(%rsp,%rsi), %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leaq (%r14,%r14), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %rbx, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, %r9, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addq %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -88(%rsp,%rsi), %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, %rbx, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -80(%rsp,%rsi), %r12
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leaq (%r12,%r12), %r13
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rax, %r13, %r13
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r15, %r13
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, %r14, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rax, %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r14, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, %r12, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -72(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leaq (%rsi,%rsi), %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rax, %r15, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r14, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r10, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rcx, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r15, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rbx, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r13, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r13
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-LABEL: lshr_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-AVX1:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rcx, %r11, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r10, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX512-LABEL: lshr_64bytes:
; X64-NO-SHLD-NO-BMI2-AVX512:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %rbp
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %rax
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl (%rsi), %r9d
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (,%r9,8), %eax
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    andl $56, %r9d
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -128(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -120(%rsp,%r9), %r8
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    leaq (%r8,%r8), %rdi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r10, %rdi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -104(%rsp,%r9), %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r10, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -96(%rsp,%r9), %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    leaq (%r12,%r12), %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -112(%rsp,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %rbx, %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r14, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -88(%rsp,%r9), %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r14, %r13
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r13
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -80(%rsp,%r9), %rbp
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    leaq (%rbp,%rbp), %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r13, %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    addq %r14, %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r12, %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %rbp
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -72(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    leaq (%r9,%r9), %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %rbp, %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r8, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r9, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %rbx, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r12, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r14, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    addq $8, %rsp
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %rbp
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX512-LABEL: lshr_64bytes:
; X64-HAVE-SHLD-NO-BMI2-AVX512:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl (%rsi), %edi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    leal (,%rdi,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    andl $56, %edi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -96(%rsp,%rdi), %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -104(%rsp,%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r9, %rax
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdq %cl, %rsi, %rax
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -112(%rsp,%rdi), %r10
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -80(%rsp,%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -88(%rsp,%rdi), %r11
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdq %cl, %r11, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -72(%rsp,%rdi), %r11
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -128(%rsp,%rdi), %r14
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -120(%rsp,%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %rdi, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdq %cl, %rdi, %r14
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r11
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r11, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %rsi, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %rax, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX512-LABEL: lshr_64bytes:
; X64-NO-SHLD-HAVE-BMI2-AVX512:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r13
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $56, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, -128(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -120(%rsp,%rsi), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -112(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leaq (%r10,%r10), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -104(%rsp,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, %r11, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -96(%rsp,%rsi), %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leaq (%r14,%r14), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %rbx, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, %r9, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addq %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -88(%rsp,%rsi), %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, %rbx, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -80(%rsp,%rsi), %r12
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leaq (%r12,%r12), %r13
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rax, %r13, %r13
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r15, %r13
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, %r14, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rax, %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r14, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, %r12, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -72(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leaq (%rsi,%rsi), %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rax, %r15, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r14, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rax, %r9, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r10, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rcx, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rax, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r15, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rbx, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r13, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r13
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-LABEL: lshr_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-AVX512:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rcx, %r11, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r10, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-SSE2-LABEL: lshr_64bytes:
; X86-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%eax), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%eax), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%eax), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%eax), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%eax), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $60, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 68(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll $3, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $24, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 72(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 64(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 76(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 80(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edi,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 84(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 88(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %eax, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 92(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 96(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edi,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 100(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 104(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edx,%edx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 108(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 112(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 116(%esp,%esi), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 120(%esp,%edx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 124(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ebx,%ebx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 60(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 48(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 40(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE2-LABEL: lshr_64bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%ecx), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%ecx), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%ecx), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%ecx), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 88(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 104(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 100(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 108(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_64bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%ebx,8), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $24, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $60, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 68(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 72(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %dl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, 64(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 80(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 76(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 88(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 84(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 96(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 92(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 104(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 100(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 112(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 108(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 120(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%edi,%edi), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 116(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 124(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %ebx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebp, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 52(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: lshr_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%ecx), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%ecx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%ecx), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%ecx), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%ecx), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%ecx), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 88(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 104(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 100(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 108(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 56(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 52(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 40(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-SSE4-LABEL: lshr_64bytes:
; X86-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 48(%ecx), %xmm3
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $60, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 68(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll $3, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $24, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 72(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %ch
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 64(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 76(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 80(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%edi,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 84(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 88(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %eax, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 92(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 96(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%edi,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 100(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 104(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%edx,%edx), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 108(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 112(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 116(%esp,%esi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 120(%esp,%edx), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 124(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ebx,%ebx), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 60(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 48(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 40(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE4-LABEL: lshr_64bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 48(%ecx), %xmm3
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 88(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 104(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 100(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 108(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_64bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 48(%ecx), %xmm3
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%ebx,8), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $24, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $60, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 68(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 72(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, 64(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 80(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 76(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 88(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 84(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 96(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 92(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 104(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 100(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 112(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 108(%esp,%ebx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 120(%esp,%ebx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%edi,%edi), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 116(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebp, %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 124(%esp,%ebx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %ebx, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebp, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebp, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 52(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: lshr_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 48(%ecx), %xmm3
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 88(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 104(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 100(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 108(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 56(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, 52(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 40(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ecx, (%esp), %eax # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX1-LABEL: lshr_64bytes:
; X86-NO-SHLD-NO-BMI2-AVX1:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups 32(%ecx), %ymm1
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    andl $60, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 68(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll $3, %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    andl $24, %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 72(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (%eax,%eax), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %cl, %ch
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 64(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %edi, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 76(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 80(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (%edi,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 84(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 88(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl %eax, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 92(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 96(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (%edi,%edi), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 100(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 104(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (%edx,%edx), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 108(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 112(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 116(%esp,%esi), %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 120(%esp,%edx), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 124(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (%ebx,%ebx), %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, 60(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, 48(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, 40(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vzeroupper
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX1-LABEL: lshr_64bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX1:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups (%ecx), %ymm0
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups 32(%ecx), %ymm1
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 88(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 104(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 100(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 48(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 108(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vzeroupper
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX1-LABEL: lshr_64bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX1:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups 32(%ecx), %ymm1
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (,%ecx,8), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $24, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $60, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 68(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 72(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    notb %dl
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, 64(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 80(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 76(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 88(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 84(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 96(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 92(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 104(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 100(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 112(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 108(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 120(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 116(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 124(%esp,%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (%ecx,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edx, %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, 60(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, 56(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 48(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, 52(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, 40(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 44(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 32(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 36(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 24(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 28(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 16(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 20(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 8(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 12(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, (%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 4(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vzeroupper
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-LABEL: lshr_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX1:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups (%ecx), %ymm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups 32(%ecx), %ymm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 88(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 104(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 100(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 48(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 108(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 56(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, 52(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebx, 40(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ecx, (%esp), %eax # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vzeroupper
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX512-LABEL: lshr_64bytes:
; X86-NO-SHLD-NO-BMI2-AVX512:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups (%ecx), %zmm0
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    andl $60, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 68(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll $3, %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    andl $24, %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 72(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (%eax,%eax), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %cl, %ch
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 64(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %edi, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 76(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 80(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (%edi,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 84(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 88(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl %eax, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 92(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 96(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (%edi,%edi), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 100(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 104(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (%edx,%edx), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 108(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 112(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 116(%esp,%esi), %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 120(%esp,%edx), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 124(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (%ebx,%ebx), %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, 60(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, 48(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, 40(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vzeroupper
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX512-LABEL: lshr_64bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX512:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups (%ecx), %zmm0
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 88(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 104(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 100(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 48(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 108(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vzeroupper
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX512-LABEL: lshr_64bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX512:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups (%ecx), %zmm0
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (,%ecx,8), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $24, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $60, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 68(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 72(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    notb %dl
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %ebp, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, 64(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 80(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 76(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 88(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 84(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 96(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 92(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 104(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 100(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 112(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 108(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 120(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 116(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 124(%esp,%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (%ecx,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edx, %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, 60(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, 56(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 48(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, 52(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, 40(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 44(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 32(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 36(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 24(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 28(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 16(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 20(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 8(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 12(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, (%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 4(%ecx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vzeroupper
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-LABEL: lshr_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX512:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups (%ecx), %zmm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 88(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 104(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 100(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 48(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 108(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 56(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, 52(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebx, 40(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ecx, (%esp), %eax # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vzeroupper
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    retl
  %src = load i512, ptr %src.ptr, align 1
  %byteOff = load i512, ptr %byteOff.ptr, align 1
  %bitOff = shl i512 %byteOff, 3
  %res = lshr i512 %src, %bitOff
  store i512 %res, ptr %dst, align 1
  ret void
}

define void @lshr_64bytes_qwordOff(ptr %src.ptr, ptr %qwordOff.ptr, ptr %dst) nounwind {
; X64-SSE2-LABEL: lshr_64bytes_qwordOff:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    pushq %rbx
; X64-SSE2-NEXT:    movq (%rdi), %rax
; X64-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-SSE2-NEXT:    movl (%rsi), %esi
; X64-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    andl $7, %esi
; X64-SSE2-NEXT:    movq -128(%rsp,%rsi,8), %rax
; X64-SSE2-NEXT:    movq -120(%rsp,%rsi,8), %rcx
; X64-SSE2-NEXT:    movq -104(%rsp,%rsi,8), %rdi
; X64-SSE2-NEXT:    movq -112(%rsp,%rsi,8), %r8
; X64-SSE2-NEXT:    movq -88(%rsp,%rsi,8), %r9
; X64-SSE2-NEXT:    movq -96(%rsp,%rsi,8), %r10
; X64-SSE2-NEXT:    movq -72(%rsp,%rsi,8), %r11
; X64-SSE2-NEXT:    movq -80(%rsp,%rsi,8), %rsi
; X64-SSE2-NEXT:    movq %rsi, 48(%rdx)
; X64-SSE2-NEXT:    movq %r11, 56(%rdx)
; X64-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-SSE2-NEXT:    movq %r9, 40(%rdx)
; X64-SSE2-NEXT:    movq %r8, 16(%rdx)
; X64-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-SSE2-NEXT:    movq %rax, (%rdx)
; X64-SSE2-NEXT:    movq %rcx, 8(%rdx)
; X64-SSE2-NEXT:    popq %rbx
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: lshr_64bytes_qwordOff:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    pushq %rax
; X64-SSE42-NEXT:    movups (%rdi), %xmm0
; X64-SSE42-NEXT:    movups 16(%rdi), %xmm1
; X64-SSE42-NEXT:    movups 32(%rdi), %xmm2
; X64-SSE42-NEXT:    movups 48(%rdi), %xmm3
; X64-SSE42-NEXT:    movl (%rsi), %eax
; X64-SSE42-NEXT:    xorps %xmm4, %xmm4
; X64-SSE42-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    andl $7, %eax
; X64-SSE42-NEXT:    movups -128(%rsp,%rax,8), %xmm0
; X64-SSE42-NEXT:    movups -112(%rsp,%rax,8), %xmm1
; X64-SSE42-NEXT:    movups -96(%rsp,%rax,8), %xmm2
; X64-SSE42-NEXT:    movups -80(%rsp,%rax,8), %xmm3
; X64-SSE42-NEXT:    movups %xmm3, 48(%rdx)
; X64-SSE42-NEXT:    movups %xmm1, 16(%rdx)
; X64-SSE42-NEXT:    movups %xmm2, 32(%rdx)
; X64-SSE42-NEXT:    movups %xmm0, (%rdx)
; X64-SSE42-NEXT:    popq %rax
; X64-SSE42-NEXT:    retq
;
; X64-AVX1-LABEL: lshr_64bytes_qwordOff:
; X64-AVX1:       # %bb.0:
; X64-AVX1-NEXT:    pushq %rax
; X64-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-AVX1-NEXT:    movl (%rsi), %eax
; X64-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-AVX1-NEXT:    andl $7, %eax
; X64-AVX1-NEXT:    vmovups -128(%rsp,%rax,8), %xmm0
; X64-AVX1-NEXT:    vmovups -112(%rsp,%rax,8), %xmm1
; X64-AVX1-NEXT:    vmovups -96(%rsp,%rax,8), %xmm2
; X64-AVX1-NEXT:    vmovups -80(%rsp,%rax,8), %xmm3
; X64-AVX1-NEXT:    vmovups %xmm3, 48(%rdx)
; X64-AVX1-NEXT:    vmovups %xmm1, 16(%rdx)
; X64-AVX1-NEXT:    vmovups %xmm2, 32(%rdx)
; X64-AVX1-NEXT:    vmovups %xmm0, (%rdx)
; X64-AVX1-NEXT:    popq %rax
; X64-AVX1-NEXT:    vzeroupper
; X64-AVX1-NEXT:    retq
;
; X64-AVX512-LABEL: lshr_64bytes_qwordOff:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    pushq %rax
; X64-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-AVX512-NEXT:    movl (%rsi), %eax
; X64-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-AVX512-NEXT:    andl $7, %eax
; X64-AVX512-NEXT:    vmovups -128(%rsp,%rax,8), %xmm0
; X64-AVX512-NEXT:    vmovups -112(%rsp,%rax,8), %xmm1
; X64-AVX512-NEXT:    vmovups -96(%rsp,%rax,8), %xmm2
; X64-AVX512-NEXT:    vmovups -80(%rsp,%rax,8), %xmm3
; X64-AVX512-NEXT:    vmovups %xmm3, 48(%rdx)
; X64-AVX512-NEXT:    vmovups %xmm1, 16(%rdx)
; X64-AVX512-NEXT:    vmovups %xmm2, 32(%rdx)
; X64-AVX512-NEXT:    vmovups %xmm0, (%rdx)
; X64-AVX512-NEXT:    popq %rax
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
;
; X86-SSE2-LABEL: lshr_64bytes_qwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $188, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl (%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 40(%eax), %ebp
; X86-SSE2-NEXT:    movl 44(%eax), %ebx
; X86-SSE2-NEXT:    movl 48(%eax), %edi
; X86-SSE2-NEXT:    movl 52(%eax), %esi
; X86-SSE2-NEXT:    movl 56(%eax), %edx
; X86-SSE2-NEXT:    movl 60(%eax), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl (%eax), %eax
; X86-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    andl $7, %eax
; X86-SSE2-NEXT:    movl 48(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 52(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 60(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 56(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 68(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 64(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 76(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 72(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 84(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 80(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 92(%esp,%eax,8), %ebp
; X86-SSE2-NEXT:    movl 88(%esp,%eax,8), %ebx
; X86-SSE2-NEXT:    movl 100(%esp,%eax,8), %edi
; X86-SSE2-NEXT:    movl 96(%esp,%eax,8), %esi
; X86-SSE2-NEXT:    movl 108(%esp,%eax,8), %edx
; X86-SSE2-NEXT:    movl 104(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %ecx, 56(%eax)
; X86-SSE2-NEXT:    movl %edx, 60(%eax)
; X86-SSE2-NEXT:    movl %esi, 48(%eax)
; X86-SSE2-NEXT:    movl %edi, 52(%eax)
; X86-SSE2-NEXT:    movl %ebx, 40(%eax)
; X86-SSE2-NEXT:    movl %ebp, 44(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $188, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: lshr_64bytes_qwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    subl $140, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movups 16(%edx), %xmm1
; X86-SSE42-NEXT:    movups 32(%edx), %xmm2
; X86-SSE42-NEXT:    movups 48(%edx), %xmm3
; X86-SSE42-NEXT:    movl (%ecx), %ecx
; X86-SSE42-NEXT:    xorps %xmm4, %xmm4
; X86-SSE42-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, (%esp)
; X86-SSE42-NEXT:    andl $7, %ecx
; X86-SSE42-NEXT:    movups (%esp,%ecx,8), %xmm0
; X86-SSE42-NEXT:    movups 16(%esp,%ecx,8), %xmm1
; X86-SSE42-NEXT:    movups 32(%esp,%ecx,8), %xmm2
; X86-SSE42-NEXT:    movups 48(%esp,%ecx,8), %xmm3
; X86-SSE42-NEXT:    movups %xmm3, 48(%eax)
; X86-SSE42-NEXT:    movups %xmm2, 32(%eax)
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $140, %esp
; X86-SSE42-NEXT:    retl
;
; X86-AVX1-LABEL: lshr_64bytes_qwordOff:
; X86-AVX1:       # %bb.0:
; X86-AVX1-NEXT:    subl $140, %esp
; X86-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX1-NEXT:    vmovups (%edx), %ymm0
; X86-AVX1-NEXT:    vmovups 32(%edx), %ymm1
; X86-AVX1-NEXT:    movl (%ecx), %ecx
; X86-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-AVX1-NEXT:    vmovups %ymm0, (%esp)
; X86-AVX1-NEXT:    andl $7, %ecx
; X86-AVX1-NEXT:    vmovups (%esp,%ecx,8), %xmm0
; X86-AVX1-NEXT:    vmovups 16(%esp,%ecx,8), %xmm1
; X86-AVX1-NEXT:    vmovups 32(%esp,%ecx,8), %xmm2
; X86-AVX1-NEXT:    vmovups 48(%esp,%ecx,8), %xmm3
; X86-AVX1-NEXT:    vmovups %xmm3, 48(%eax)
; X86-AVX1-NEXT:    vmovups %xmm2, 32(%eax)
; X86-AVX1-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX1-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX1-NEXT:    addl $140, %esp
; X86-AVX1-NEXT:    vzeroupper
; X86-AVX1-NEXT:    retl
;
; X86-AVX512-LABEL: lshr_64bytes_qwordOff:
; X86-AVX512:       # %bb.0:
; X86-AVX512-NEXT:    subl $140, %esp
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX512-NEXT:    vmovups (%edx), %zmm0
; X86-AVX512-NEXT:    movl (%ecx), %ecx
; X86-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-AVX512-NEXT:    vmovups %zmm0, (%esp)
; X86-AVX512-NEXT:    andl $7, %ecx
; X86-AVX512-NEXT:    vmovups (%esp,%ecx,8), %xmm0
; X86-AVX512-NEXT:    vmovups 16(%esp,%ecx,8), %xmm1
; X86-AVX512-NEXT:    vmovups 32(%esp,%ecx,8), %xmm2
; X86-AVX512-NEXT:    vmovups 48(%esp,%ecx,8), %xmm3
; X86-AVX512-NEXT:    vmovups %xmm3, 48(%eax)
; X86-AVX512-NEXT:    vmovups %xmm2, 32(%eax)
; X86-AVX512-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX512-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX512-NEXT:    addl $140, %esp
; X86-AVX512-NEXT:    vzeroupper
; X86-AVX512-NEXT:    retl
  %src = load i512, ptr %src.ptr, align 1
  %qwordOff = load i512, ptr %qwordOff.ptr, align 1
  %bitOff = shl i512 %qwordOff, 6
  %res = lshr i512 %src, %bitOff
  store i512 %res, ptr %dst, align 1
  ret void
}

define void @shl_64bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: shl_64bytes:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%rsi), %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    negl %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movslq %esi, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%rbx), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%rbx), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -40(%rsp,%rbx), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%rbx), %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r15, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r14, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r15, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -24(%rsp,%rbx), %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -32(%rsp,%rbx), %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r13, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r12, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r13, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -8(%rsp,%rbx), %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -16(%rsp,%rbx), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r12, %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %rbx, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r13, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: shl_64bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%rsi), %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    negl %esi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movslq %esi, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -48(%rsp,%r9), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -40(%rsp,%r9), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -64(%rsp,%r9), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -56(%rsp,%r9), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %rdi, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -32(%rsp,%r9), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -24(%rsp,%r9), %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %r11, %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %r10, %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -16(%rsp,%r9), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -8(%rsp,%r9), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %r10, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %rbx, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldq %cl, %r8, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addq $8, %rsp
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: shl_64bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    negl %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movslq %esi, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rdi, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r9, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r8, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -40(%rsp,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r11, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r8, %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r14, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -24(%rsp,%rsi), %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rbx, %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -32(%rsp,%rsi), %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r15, %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %r15, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r14, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r12, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, -8(%rsp,%rsi), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -16(%rsp,%rsi), %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rsi, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %rsi, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r14, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rax, %rbx, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rcx, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq $8, %rsp
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: shl_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%rsi), %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rsi,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    negl %esi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movslq %esi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -48(%rsp,%r8), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -40(%rsp,%r8), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -64(%rsp,%r8), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -56(%rsp,%r8), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %rdi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -32(%rsp,%r8), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -24(%rsp,%r8), %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %r11, %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %r9, %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -16(%rsp,%r8), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -8(%rsp,%r8), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %r9, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %rbx, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldq %cl, %r10, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r10, %rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r14, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addq $8, %rsp
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: shl_64bytes:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 48(%rdi), %xmm3
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rcx,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    negl %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movslq %ecx, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -24(%rsp,%r9), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -32(%rsp,%r9), %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r11, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%r9), %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r15, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%r9), %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%r9), %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r12, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r15, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r12, %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -16(%rsp,%r9), %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r12, %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r13, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -8(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r9, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r12, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r15, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: shl_64bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 48(%rdi), %xmm3
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    negl %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movslq %eax, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -32(%rsp,%r8), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -24(%rsp,%r8), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -40(%rsp,%r8), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %rdi, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -48(%rsp,%r8), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %r10, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -64(%rsp,%r8), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -56(%rsp,%r8), %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %rbx, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -16(%rsp,%r8), %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %r9, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -8(%rsp,%r8), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %r14, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldq %cl, %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r15, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: shl_64bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 48(%rdi), %xmm3
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    negl %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movslq %esi, %rsi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -24(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rdi, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -32(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r8, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r9, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -40(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r9, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r10, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%rsi), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r10, %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r11, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%rsi), %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r11, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r14, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rbx, %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r15, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -16(%rsp,%rsi), %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r15, %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r12, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, -8(%rsp,%rsi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rax, %r15, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rcx, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r14, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rbx, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq $8, %rsp
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: shl_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 48(%rdi), %xmm3
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    negl %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movslq %eax, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -32(%rsp,%r8), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -24(%rsp,%r8), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -40(%rsp,%r8), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %rdi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -48(%rsp,%r8), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %r10, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -64(%rsp,%r8), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -56(%rsp,%r8), %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %rbx, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -16(%rsp,%r8), %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %r9, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -8(%rsp,%r8), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %r14, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r11, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldq %cl, %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r15, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rbx, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rsi, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX1-LABEL: shl_64bytes:
; X64-NO-SHLD-NO-BMI2-AVX1:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal (,%rcx,8), %eax
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    andl $56, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    negl %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movslq %ecx, %r9
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -24(%rsp,%r9), %rdi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %rdi, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -32(%rsp,%r9), %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r11, %r8
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %r8
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r10, %r8
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -40(%rsp,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r11, %r10
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -48(%rsp,%r9), %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r15, %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -64(%rsp,%r9), %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -56(%rsp,%r9), %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r12, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r15, %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r14, %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r12, %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -16(%rsp,%r9), %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r12, %r13
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r13
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r13, %rdi
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq -8(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    orq %r9, %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r14, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r12, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %rdi, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r15, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r10, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    movq %r8, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX1-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX1-LABEL: shl_64bytes:
; X64-HAVE-SHLD-NO-BMI2-AVX1:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    negl %eax
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movslq %eax, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -32(%rsp,%r8), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -24(%rsp,%r8), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -40(%rsp,%r8), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldq %cl, %rdi, %rax
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -48(%rsp,%r8), %r10
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldq %cl, %r10, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -64(%rsp,%r8), %r11
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -56(%rsp,%r8), %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldq %cl, %rbx, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -16(%rsp,%r8), %r14
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldq %cl, %r9, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq -8(%rsp,%r8), %r8
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldq %cl, %r14, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r11, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shlq %cl, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldq %cl, %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r8, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r15, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %rbx, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r10, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %rax, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %rsi, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX1-LABEL: shl_64bytes:
; X64-NO-SHLD-HAVE-BMI2-AVX1:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %rax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $56, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    negl %esi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movslq %esi, %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -24(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, %rdi, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -32(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, %r8, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r9, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -40(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, %r9, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrq %r9
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rax, %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r10, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -48(%rsp,%rsi), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, %r10, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrq %r10
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r11, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -64(%rsp,%rsi), %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -56(%rsp,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, %r11, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrq %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r14, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, %rbx, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rax, %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r15, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -16(%rsp,%rsi), %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, %r15, %r12
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %r12, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, -8(%rsp,%rsi), %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxq %rax, %r15, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orq %rcx, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r14, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rax, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rdi, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rbx, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r10, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r9, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r8, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addq $8, %rsp
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-LABEL: shl_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-AVX1:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    negl %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movslq %eax, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -32(%rsp,%r8), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -24(%rsp,%r8), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -40(%rsp,%r8), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldq %cl, %rdi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -48(%rsp,%r8), %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldq %cl, %r10, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -64(%rsp,%r8), %r11
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -56(%rsp,%r8), %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldq %cl, %rbx, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -16(%rsp,%r8), %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldq %cl, %r9, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq -8(%rsp,%r8), %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldq %cl, %r14, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxq %rcx, %r11, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldq %cl, %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r8, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r15, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rbx, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r10, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rax, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %rsi, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX512-LABEL: shl_64bytes:
; X64-NO-SHLD-NO-BMI2-AVX512:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl (%rsi), %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal (,%rcx,8), %eax
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    andl $56, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    negl %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movslq %ecx, %r9
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -24(%rsp,%r9), %rdi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %rdi, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -32(%rsp,%r9), %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r11, %r8
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %r8
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r10, %r8
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -40(%rsp,%r9), %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r11, %r10
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -48(%rsp,%r9), %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r15, %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -64(%rsp,%r9), %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -56(%rsp,%r9), %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r12, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r15, %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r14, %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r12, %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -16(%rsp,%r9), %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r12, %r13
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r13
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %rdi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r13, %rdi
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq -8(%rsp,%r9), %r9
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    orq %r9, %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r14, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r12, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %rdi, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r15, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %rbx, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r10, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    movq %r8, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX512-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX512-LABEL: shl_64bytes:
; X64-HAVE-SHLD-NO-BMI2-AVX512:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    negl %eax
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movslq %eax, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -32(%rsp,%r8), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -24(%rsp,%r8), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -40(%rsp,%r8), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldq %cl, %rdi, %rax
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -48(%rsp,%r8), %r10
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldq %cl, %r10, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -64(%rsp,%r8), %r11
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -56(%rsp,%r8), %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldq %cl, %rbx, %r10
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -16(%rsp,%r8), %r14
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldq %cl, %r9, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq -8(%rsp,%r8), %r8
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldq %cl, %r14, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r11, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shlq %cl, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldq %cl, %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r8, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r15, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %rbx, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r10, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %rax, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %rsi, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX512-LABEL: shl_64bytes:
; X64-NO-SHLD-HAVE-BMI2-AVX512:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %rax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%rsi), %esi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (,%rsi,8), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $56, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    negl %esi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movslq %esi, %rsi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -24(%rsp,%rsi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, %rdi, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    notb %al
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -32(%rsp,%rsi), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, %r8, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrq %r8
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rax, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r9, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -40(%rsp,%rsi), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, %r9, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrq %r9
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rax, %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r10, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -48(%rsp,%rsi), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, %r10, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrq %r10
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rax, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r11, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -64(%rsp,%rsi), %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -56(%rsp,%rsi), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, %r11, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrq %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rax, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r14, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, %rbx, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rax, %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r15, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -16(%rsp,%rsi), %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, %r15, %r12
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrq %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rax, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %r12, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, -8(%rsp,%rsi), %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxq %rax, %r15, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orq %rcx, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r14, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rax, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rdi, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rbx, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r10, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r9, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r8, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addq $8, %rsp
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-LABEL: shl_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-AVX512:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    negl %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movslq %eax, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -32(%rsp,%r8), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -24(%rsp,%r8), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldq %cl, %rax, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -40(%rsp,%r8), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldq %cl, %rdi, %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -48(%rsp,%r8), %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldq %cl, %r10, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -64(%rsp,%r8), %r11
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -56(%rsp,%r8), %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldq %cl, %rbx, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -16(%rsp,%r8), %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldq %cl, %r9, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq -8(%rsp,%r8), %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldq %cl, %r14, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxq %rcx, %r11, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldq %cl, %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r8, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r15, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rbx, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r10, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rdi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rax, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %rsi, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movq %r9, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-SSE2-LABEL: shl_64bytes:
; X86-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%eax), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%eax), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%eax), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%eax), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%eax), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%eax), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $60, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll $3, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $24, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%edx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%edx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    negl %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 176(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%edi), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 56(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE2-LABEL: shl_64bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%ecx), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%ecx), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%ecx), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%ecx), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%ecx), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%ecx), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl %ebp, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%eax), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    negl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 160(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shldl %cl, %edi, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE2-LABEL: shl_64bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ebp), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%ebp,8), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $24, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $60, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %eax, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ebp, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %ecx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edi, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edi, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edi, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %eax, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%edx), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %esi, %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %esi, %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ebp, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ebp, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    negl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ebp, 188(%esp,%ebx), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ecx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, (%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 56(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 60(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 48(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 52(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 40(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 44(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 32(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 36(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: shl_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $204, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%ebp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%ebp,8), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%eax), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %esi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    negl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 176(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 56(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, 60(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %ecx, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %ebp, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shldl %cl, %edx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, 48(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 52(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 40(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 44(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $204, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-SSE4-LABEL: shl_64bytes:
; X86-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 48(%ecx), %xmm3
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $60, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl (%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 4(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll $3, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $24, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %ch
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 12(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 8(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 20(%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 16(%edi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 28(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 24(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 36(%edx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 32(%edx), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 44(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 40(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    negl %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 176(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%edi), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 56(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE4-LABEL: shl_64bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 48(%ecx), %xmm3
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl %ebp, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 8(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 12(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 4(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 16(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 20(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 24(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 28(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 32(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 36(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 40(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 44(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%eax), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    negl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 160(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shldl %cl, %edi, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE4-LABEL: shl_64bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 48(%ecx), %xmm3
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%eax,8), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $24, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $60, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl %eax, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 4(%edx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 8(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 12(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %ecx, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 16(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 20(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edi, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 24(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 28(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edi, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 32(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 36(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edi, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 40(%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 44(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %eax, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%edx), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %esi, %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %esi, %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebp, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebp, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    negl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ebp, 188(%esp,%ebx), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ecx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, (%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 56(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 60(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 48(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 52(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 40(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 44(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 32(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 36(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: shl_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $204, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 48(%ecx), %xmm3
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%eax), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    xorps %xmm4, %xmm4
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%ebp,8), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 4(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 8(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 12(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 16(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 20(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 24(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 28(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 32(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 36(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 40(%eax), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 44(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %esi, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    negl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 176(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, 56(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 60(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %ecx, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %ebp, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shldl %cl, %edx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, 48(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 52(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 40(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 44(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 32(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 36(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $204, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX1-LABEL: shl_64bytes:
; X86-NO-SHLD-NO-BMI2-AVX1:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups 32(%ecx), %ymm1
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    andl $60, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    leal {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    subl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl (%ecx), %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 4(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll $3, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    andl $24, %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %ch
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 12(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 8(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 20(%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 16(%edi), %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 28(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 24(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 36(%edx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 32(%edx), %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 44(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 40(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 52(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    negl %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 176(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 60(%edi), %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl 56(%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, 56(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    vzeroupper
; X86-NO-SHLD-NO-BMI2-AVX1-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX1-LABEL: shl_64bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX1:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups (%ecx), %ymm0
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups 32(%ecx), %ymm1
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    subl %ebp, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 8(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 12(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 4(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 16(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 20(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 24(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 28(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 32(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 36(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 40(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 44(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 60(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl (%eax), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    negl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl 160(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edi, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shll %cl, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    shldl %cl, %edi, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %esi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    movl %edx, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    vzeroupper
; X86-HAVE-SHLD-NO-BMI2-AVX1-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX1-LABEL: shl_64bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX1:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups 32(%ecx), %ymm1
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (,%eax,8), %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $24, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebx, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $60, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    leal {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    subl %eax, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 4(%edx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %ecx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 8(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 12(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %ecx, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %ecx, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 16(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 20(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edi, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 24(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 28(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edi, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 32(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 36(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edi, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 40(%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 44(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %eax, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 48(%edx), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 52(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %esi, %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %esi, %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 56(%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %ebp, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shrxl %ebx, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %ebp, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    negl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %ebp, 188(%esp,%ebx), %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    orl %ecx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, (%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 56(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebx, 60(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, 48(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 52(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 40(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 44(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 32(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 36(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    vzeroupper
; X86-NO-SHLD-HAVE-BMI2-AVX1-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-LABEL: shl_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX1:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    subl $204, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups (%ecx), %ymm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups 32(%ecx), %ymm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%eax), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    leal (,%ebx,8), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    andl $60, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    subl %ebx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 4(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 8(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 12(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 16(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 20(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 24(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 28(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 32(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 36(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 40(%eax), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 44(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %ebp, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %esi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 60(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl (%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    negl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl 176(%esp,%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edx, 56(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, 60(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shlxl %ecx, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %ebx, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    shldl %cl, %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebx, 48(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %esi, 52(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ebp, 40(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 44(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 32(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 36(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    movl %ecx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    addl $204, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    vzeroupper
; X86-HAVE-SHLD-HAVE-BMI2-AVX1-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX512-LABEL: shl_64bytes:
; X86-NO-SHLD-NO-BMI2-AVX512:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups (%ecx), %zmm0
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    andl $60, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    leal {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    subl %edx, %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl (%ecx), %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 4(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll $3, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    andl $24, %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %ch
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 12(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 8(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 20(%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 16(%edi), %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 28(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 24(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 36(%edx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 32(%edx), %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 44(%ebp), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 40(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 52(%ebp), %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    negl %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 176(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 60(%edi), %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl 56(%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, (%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, 56(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    vzeroupper
; X86-NO-SHLD-NO-BMI2-AVX512-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX512-LABEL: shl_64bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX512:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups (%ecx), %zmm0
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    subl %ebp, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 8(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 12(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 4(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 16(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 20(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 24(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 28(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 32(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 36(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edi, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 40(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 44(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 60(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl (%eax), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    negl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl 160(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edi, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %ebx, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shll %cl, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    shldl %cl, %edi, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %esi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    movl %edx, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    vzeroupper
; X86-HAVE-SHLD-NO-BMI2-AVX512-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX512-LABEL: shl_64bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX512:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups (%ecx), %zmm0
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (,%eax,8), %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $24, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebx, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $60, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    leal {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    subl %eax, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 4(%edx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    notb %bl
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %ecx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 8(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 12(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %ecx, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %ecx, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 16(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 20(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edi, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 24(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 28(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edi, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 32(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 36(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edi, %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %edi, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 40(%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %esi, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 44(%edx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %eax, %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %eax, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 48(%edx), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 52(%edx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %esi, %ecx, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %esi, %ebp, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %eax, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %edi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 56(%edx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %ebp, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shrxl %ebx, %edi, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %ebp, {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    negl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %ebp, 188(%esp,%ebx), %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    orl %ecx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, (%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 56(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebx, 60(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, 48(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 52(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 40(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 44(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 32(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 36(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 24(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 28(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 16(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 20(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 8(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 12(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %eax, 4(%edx)
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    vzeroupper
; X86-NO-SHLD-HAVE-BMI2-AVX512-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-LABEL: shl_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX512:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    subl $204, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups (%ecx), %zmm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%eax), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    leal (,%ebx,8), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    andl $60, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    subl %ebx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 4(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 8(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 12(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 16(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 20(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 24(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 28(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %esi, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 32(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 36(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 40(%eax), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 44(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %ebp, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %esi, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 60(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl (%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    negl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl 176(%esp,%ebx), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edx, 56(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, 60(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shlxl %ecx, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edi # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %ebx, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    shldl %cl, %edx, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebx, 48(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %esi, 52(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ebp, 40(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 44(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 32(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 36(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 24(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 28(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 16(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 20(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 8(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, 12(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %edi, 4(%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    movl %ecx, (%eax)
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    addl $204, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    vzeroupper
; X86-HAVE-SHLD-HAVE-BMI2-AVX512-NEXT:    retl
  %src = load i512, ptr %src.ptr, align 1
  %byteOff = load i512, ptr %byteOff.ptr, align 1
  %bitOff = shl i512 %byteOff, 3
  %res = shl i512 %src, %bitOff
  store i512 %res, ptr %dst, align 1
  ret void
}

define void @shl_64bytes_qwordOff(ptr %src.ptr, ptr %qwordOff.ptr, ptr %dst) nounwind {
; X64-SSE2-LABEL: shl_64bytes_qwordOff:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    pushq %rbx
; X64-SSE2-NEXT:    movq (%rdi), %rax
; X64-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-SSE2-NEXT:    movl (%rsi), %esi
; X64-SSE2-NEXT:    xorps %xmm0, %xmm0
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    shll $3, %esi
; X64-SSE2-NEXT:    andl $56, %esi
; X64-SSE2-NEXT:    negl %esi
; X64-SSE2-NEXT:    movslq %esi, %rax
; X64-SSE2-NEXT:    movq -64(%rsp,%rax), %rcx
; X64-SSE2-NEXT:    movq -56(%rsp,%rax), %rsi
; X64-SSE2-NEXT:    movq -40(%rsp,%rax), %rdi
; X64-SSE2-NEXT:    movq -48(%rsp,%rax), %r8
; X64-SSE2-NEXT:    movq -24(%rsp,%rax), %r9
; X64-SSE2-NEXT:    movq -32(%rsp,%rax), %r10
; X64-SSE2-NEXT:    movq -8(%rsp,%rax), %r11
; X64-SSE2-NEXT:    movq -16(%rsp,%rax), %rax
; X64-SSE2-NEXT:    movq %rax, 48(%rdx)
; X64-SSE2-NEXT:    movq %r11, 56(%rdx)
; X64-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-SSE2-NEXT:    movq %r9, 40(%rdx)
; X64-SSE2-NEXT:    movq %r8, 16(%rdx)
; X64-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-SSE2-NEXT:    movq %rcx, (%rdx)
; X64-SSE2-NEXT:    movq %rsi, 8(%rdx)
; X64-SSE2-NEXT:    popq %rbx
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: shl_64bytes_qwordOff:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    pushq %rax
; X64-SSE42-NEXT:    movups (%rdi), %xmm0
; X64-SSE42-NEXT:    movups 16(%rdi), %xmm1
; X64-SSE42-NEXT:    movups 32(%rdi), %xmm2
; X64-SSE42-NEXT:    movups 48(%rdi), %xmm3
; X64-SSE42-NEXT:    movl (%rsi), %eax
; X64-SSE42-NEXT:    xorps %xmm4, %xmm4
; X64-SSE42-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm4, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm3, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    shll $3, %eax
; X64-SSE42-NEXT:    andl $56, %eax
; X64-SSE42-NEXT:    negl %eax
; X64-SSE42-NEXT:    cltq
; X64-SSE42-NEXT:    movups -64(%rsp,%rax), %xmm0
; X64-SSE42-NEXT:    movups -48(%rsp,%rax), %xmm1
; X64-SSE42-NEXT:    movups -32(%rsp,%rax), %xmm2
; X64-SSE42-NEXT:    movups -16(%rsp,%rax), %xmm3
; X64-SSE42-NEXT:    movups %xmm3, 48(%rdx)
; X64-SSE42-NEXT:    movups %xmm1, 16(%rdx)
; X64-SSE42-NEXT:    movups %xmm2, 32(%rdx)
; X64-SSE42-NEXT:    movups %xmm0, (%rdx)
; X64-SSE42-NEXT:    popq %rax
; X64-SSE42-NEXT:    retq
;
; X64-AVX1-LABEL: shl_64bytes_qwordOff:
; X64-AVX1:       # %bb.0:
; X64-AVX1-NEXT:    pushq %rax
; X64-AVX1-NEXT:    vmovups (%rdi), %ymm0
; X64-AVX1-NEXT:    vmovups 32(%rdi), %ymm1
; X64-AVX1-NEXT:    movl (%rsi), %eax
; X64-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X64-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-AVX1-NEXT:    vmovups %ymm2, -{{[0-9]+}}(%rsp)
; X64-AVX1-NEXT:    vmovups %ymm1, -{{[0-9]+}}(%rsp)
; X64-AVX1-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-AVX1-NEXT:    shll $3, %eax
; X64-AVX1-NEXT:    andl $56, %eax
; X64-AVX1-NEXT:    negl %eax
; X64-AVX1-NEXT:    cltq
; X64-AVX1-NEXT:    vmovups -64(%rsp,%rax), %xmm0
; X64-AVX1-NEXT:    vmovups -48(%rsp,%rax), %xmm1
; X64-AVX1-NEXT:    vmovups -32(%rsp,%rax), %xmm2
; X64-AVX1-NEXT:    vmovups -16(%rsp,%rax), %xmm3
; X64-AVX1-NEXT:    vmovups %xmm3, 48(%rdx)
; X64-AVX1-NEXT:    vmovups %xmm1, 16(%rdx)
; X64-AVX1-NEXT:    vmovups %xmm2, 32(%rdx)
; X64-AVX1-NEXT:    vmovups %xmm0, (%rdx)
; X64-AVX1-NEXT:    popq %rax
; X64-AVX1-NEXT:    vzeroupper
; X64-AVX1-NEXT:    retq
;
; X64-AVX512-LABEL: shl_64bytes_qwordOff:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    pushq %rax
; X64-AVX512-NEXT:    vmovups (%rdi), %zmm0
; X64-AVX512-NEXT:    movl (%rsi), %eax
; X64-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X64-AVX512-NEXT:    vmovups %zmm1, -{{[0-9]+}}(%rsp)
; X64-AVX512-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; X64-AVX512-NEXT:    shll $3, %eax
; X64-AVX512-NEXT:    andl $56, %eax
; X64-AVX512-NEXT:    negl %eax
; X64-AVX512-NEXT:    cltq
; X64-AVX512-NEXT:    vmovups -64(%rsp,%rax), %xmm0
; X64-AVX512-NEXT:    vmovups -48(%rsp,%rax), %xmm1
; X64-AVX512-NEXT:    vmovups -32(%rsp,%rax), %xmm2
; X64-AVX512-NEXT:    vmovups -16(%rsp,%rax), %xmm3
; X64-AVX512-NEXT:    vmovups %xmm3, 48(%rdx)
; X64-AVX512-NEXT:    vmovups %xmm1, 16(%rdx)
; X64-AVX512-NEXT:    vmovups %xmm2, 32(%rdx)
; X64-AVX512-NEXT:    vmovups %xmm0, (%rdx)
; X64-AVX512-NEXT:    popq %rax
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
;
; X86-SSE2-LABEL: shl_64bytes_qwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $188, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE2-NEXT:    movl (%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 12(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 16(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 20(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 24(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 28(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 32(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 36(%ecx), %eax
; X86-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 40(%ecx), %ebp
; X86-SSE2-NEXT:    movl 44(%ecx), %ebx
; X86-SSE2-NEXT:    movl 48(%ecx), %edi
; X86-SSE2-NEXT:    movl 52(%ecx), %esi
; X86-SSE2-NEXT:    movl 56(%ecx), %edx
; X86-SSE2-NEXT:    movl 60(%ecx), %eax
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE2-NEXT:    movl (%ecx), %ecx
; X86-SSE2-NEXT:    xorps %xmm0, %xmm0
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    shll $3, %ecx
; X86-SSE2-NEXT:    andl $56, %ecx
; X86-SSE2-NEXT:    leal {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    subl %ecx, %eax
; X86-SSE2-NEXT:    movl (%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 12(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 20(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 16(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 28(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 24(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 36(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 32(%eax), %edx
; X86-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 44(%eax), %ebp
; X86-SSE2-NEXT:    movl 40(%eax), %ebx
; X86-SSE2-NEXT:    movl 52(%eax), %edi
; X86-SSE2-NEXT:    movl 60(%eax), %esi
; X86-SSE2-NEXT:    movl 56(%eax), %edx
; X86-SSE2-NEXT:    negl %ecx
; X86-SSE2-NEXT:    movl 160(%esp,%ecx), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %edx, 56(%eax)
; X86-SSE2-NEXT:    movl %esi, 60(%eax)
; X86-SSE2-NEXT:    movl %ecx, 48(%eax)
; X86-SSE2-NEXT:    movl %edi, 52(%eax)
; X86-SSE2-NEXT:    movl %ebx, 40(%eax)
; X86-SSE2-NEXT:    movl %ebp, 44(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $188, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: shl_64bytes_qwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    subl $140, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movups 16(%edx), %xmm1
; X86-SSE42-NEXT:    movups 32(%edx), %xmm2
; X86-SSE42-NEXT:    movups 48(%edx), %xmm3
; X86-SSE42-NEXT:    movl (%ecx), %ecx
; X86-SSE42-NEXT:    xorps %xmm4, %xmm4
; X86-SSE42-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm4, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm4, (%esp)
; X86-SSE42-NEXT:    movaps %xmm3, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    shll $3, %ecx
; X86-SSE42-NEXT:    andl $56, %ecx
; X86-SSE42-NEXT:    leal {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    subl %ecx, %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movups 16(%edx), %xmm1
; X86-SSE42-NEXT:    movups 32(%edx), %xmm2
; X86-SSE42-NEXT:    negl %ecx
; X86-SSE42-NEXT:    movups 112(%esp,%ecx), %xmm3
; X86-SSE42-NEXT:    movups %xmm3, 48(%eax)
; X86-SSE42-NEXT:    movups %xmm2, 32(%eax)
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $140, %esp
; X86-SSE42-NEXT:    retl
;
; X86-AVX1-LABEL: shl_64bytes_qwordOff:
; X86-AVX1:       # %bb.0:
; X86-AVX1-NEXT:    subl $140, %esp
; X86-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX1-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX1-NEXT:    vmovups (%edx), %ymm0
; X86-AVX1-NEXT:    vmovups 32(%edx), %ymm1
; X86-AVX1-NEXT:    movl (%ecx), %ecx
; X86-AVX1-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-AVX1-NEXT:    vmovups %ymm2, {{[0-9]+}}(%esp)
; X86-AVX1-NEXT:    vmovups %ymm2, (%esp)
; X86-AVX1-NEXT:    vmovups %ymm1, {{[0-9]+}}(%esp)
; X86-AVX1-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-AVX1-NEXT:    shll $3, %ecx
; X86-AVX1-NEXT:    andl $56, %ecx
; X86-AVX1-NEXT:    leal {{[0-9]+}}(%esp), %edx
; X86-AVX1-NEXT:    subl %ecx, %edx
; X86-AVX1-NEXT:    vmovups (%edx), %xmm0
; X86-AVX1-NEXT:    vmovups 16(%edx), %xmm1
; X86-AVX1-NEXT:    vmovups 32(%edx), %xmm2
; X86-AVX1-NEXT:    negl %ecx
; X86-AVX1-NEXT:    vmovups 112(%esp,%ecx), %xmm3
; X86-AVX1-NEXT:    vmovups %xmm3, 48(%eax)
; X86-AVX1-NEXT:    vmovups %xmm2, 32(%eax)
; X86-AVX1-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX1-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX1-NEXT:    addl $140, %esp
; X86-AVX1-NEXT:    vzeroupper
; X86-AVX1-NEXT:    retl
;
; X86-AVX512-LABEL: shl_64bytes_qwordOff:
; X86-AVX512:       # %bb.0:
; X86-AVX512-NEXT:    subl $140, %esp
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX512-NEXT:    vmovups (%edx), %zmm0
; X86-AVX512-NEXT:    movl (%ecx), %ecx
; X86-AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; X86-AVX512-NEXT:    vmovups %zmm1, (%esp)
; X86-AVX512-NEXT:    vmovups %zmm0, {{[0-9]+}}(%esp)
; X86-AVX512-NEXT:    shll $3, %ecx
; X86-AVX512-NEXT:    andl $56, %ecx
; X86-AVX512-NEXT:    leal {{[0-9]+}}(%esp), %edx
; X86-AVX512-NEXT:    subl %ecx, %edx
; X86-AVX512-NEXT:    vmovups (%edx), %xmm0
; X86-AVX512-NEXT:    vmovups 16(%edx), %xmm1
; X86-AVX512-NEXT:    vmovups 32(%edx), %xmm2
; X86-AVX512-NEXT:    negl %ecx
; X86-AVX512-NEXT:    vmovups 112(%esp,%ecx), %xmm3
; X86-AVX512-NEXT:    vmovups %xmm3, 48(%eax)
; X86-AVX512-NEXT:    vmovups %xmm2, 32(%eax)
; X86-AVX512-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX512-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX512-NEXT:    addl $140, %esp
; X86-AVX512-NEXT:    vzeroupper
; X86-AVX512-NEXT:    retl
  %src = load i512, ptr %src.ptr, align 1
  %qwordOff = load i512, ptr %qwordOff.ptr, align 1
  %bitOff = shl i512 %qwordOff, 6
  %res = shl i512 %src, %bitOff
  store i512 %res, ptr %dst, align 1
  ret void
}

define void @ashr_64bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-SHLD-NO-BMI2-SSE2-LABEL: ashr_64bytes:
; X64-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq 56(%rdi), %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%rsi), %edi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarq $63, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rdi,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %edi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -128(%rsp,%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -120(%rsp,%rdi), %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -112(%rsp,%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%rbx,%rbx), %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r11, %r9
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %r8, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r10, %r8
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -104(%rsp,%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -96(%rsp,%rdi), %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%r14,%r14), %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r15, %r11
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %rbx, %r10
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -88(%rsp,%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -80(%rsp,%rdi), %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%r13,%r13), %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r12, %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r14, %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrq %cl, %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq -72(%rsp,%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    leaq (%rdi,%rdi), %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    orq %r13, %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE2-LABEL: ashr_64bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 24(%rdi), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 32(%rdi), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 40(%rdi), %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 48(%rdi), %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -112(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -128(%rsp,%rax), %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -120(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r9, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rdi, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -96(%rsp,%rax), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -104(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r10, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -80(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -88(%rsp,%rax), %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r11, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r14, %r10
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %r11
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdq %cl, %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarq %cl, %rax
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r11, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rax, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r15, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rdi, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rbx, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %rsi, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_64bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 32(%rdi), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 40(%rdi), %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 48(%rdi), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%rsi), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rax,8), %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -120(%rsp,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -112(%rsp,%rax), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r8, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %cl
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r10,%r10), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, -128(%rsp,%rax), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r9, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -104(%rsp,%rax), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r11, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -96(%rsp,%rax), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r14,%r14), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %r10, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -88(%rsp,%rax), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r10, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -80(%rsp,%rax), %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%r15,%r15), %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r12, %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r14, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxq %rsi, %r15, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leaq (%rax,%rax), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxq %rcx, %r14, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orq %rbx, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxq %rsi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r12, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addq $8, %rsp
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq (%rdi), %rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 8(%rdi), %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 16(%rdi), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 24(%rdi), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 32(%rdi), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 40(%rdi), %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 48(%rdi), %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r14, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -112(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -128(%rsp,%rax), %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -120(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r9, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rdi, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -96(%rsp,%rax), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -104(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r10, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -80(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -88(%rsp,%rax), %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r14, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r11, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r14, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq -72(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %rax, %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxq %rcx, %rax, %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdq %cl, %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r11, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r15, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rdi, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rbx, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rsi, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %r8, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movq %rax, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-SSE4-LABEL: ashr_64bytes:
; X64-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq 48(%rdi), %rax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq 56(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl (%rsi), %edi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarq $63, %rcx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rdi,8), %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %edi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -128(%rsp,%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -120(%rsp,%rdi), %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r9,%r9), %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r10, %r8
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -104(%rsp,%rdi), %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -96(%rsp,%rdi), %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%r12,%r12), %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -112(%rsp,%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r14, %r10
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -88(%rsp,%rdi), %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -80(%rsp,%rdi), %rbp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%rbp,%rbp), %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r13, %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %r14, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r12, %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %rbp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq -72(%rsp,%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    leaq (%rdi,%rdi), %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %rbp, %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    orq %r9, %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r12, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    addq $8, %rsp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbp
; X64-NO-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-SSE4-LABEL: ashr_64bytes:
; X64-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq 48(%rdi), %rcx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarq %cl, %r11
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r11, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_64bytes:
; X64-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 48(%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 56(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%rsi), %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %esi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, -128(%rsp,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %cl
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -120(%rsp,%rax), %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -112(%rsp,%rax), %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r10,%r10), %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -104(%rsp,%rax), %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r11, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -96(%rsp,%rax), %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r14,%r14), %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rbx, %r8
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r9, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -88(%rsp,%rax), %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %rbx, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -80(%rsp,%rax), %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%r12,%r12), %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r13, %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r15, %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r14, %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r14, %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r12, %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leaq (%rax,%rax), %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r15, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r14, %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxq %rsi, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxq %rcx, %r9, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orq %r10, %rcx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxq %rsi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r15, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rbx, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r13, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r13
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%rdi), %xmm0
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%rdi), %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%rdi), %xmm2
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 48(%rdi), %rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxq %rcx, %r11, %r10
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movq %r10, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retq
;
; X64-NO-SHLD-NO-BMI2-AVX-LABEL: ashr_64bytes:
; X64-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %rbp
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %r15
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %r14
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %r13
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %r12
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    pushq %rax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups 32(%rdi), %xmm1
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq 48(%rdi), %rax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq 56(%rdi), %rcx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl (%rsi), %edi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    sarq $63, %rcx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (,%rdi,8), %eax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    andl $56, %eax
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    andl $56, %edi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -128(%rsp,%rdi), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -120(%rsp,%rdi), %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %sil
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r9,%r9), %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r10, %r8
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -104(%rsp,%rdi), %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -96(%rsp,%rdi), %r12
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%r12,%r12), %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -112(%rsp,%rdi), %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rbx, %r14
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r14
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    addq %r10, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r14, %r10
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -88(%rsp,%rdi), %r14
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r14, %r13
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r13
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -80(%rsp,%rdi), %rbp
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%rbp,%rbp), %r15
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r15
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r13, %r15
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    addq %r14, %r14
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r14
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r12, %r14
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %rbp
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq -72(%rsp,%rdi), %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    leaq (%rdi,%rdi), %r12
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %r12
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %rbp, %r12
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shrq %cl, %r9
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    shlq %cl, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    orq %r9, %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    sarq %cl, %rdi
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, 56(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %rbx, 8(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r12, 48(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r14, 32(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r15, 40(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, 16(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r11, 24(%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, (%rdx)
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    addq $8, %rsp
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %rbx
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %r12
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %r13
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %r14
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %r15
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    popq %rbp
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-NO-BMI2-AVX-LABEL: ashr_64bytes:
; X64-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups 32(%rdi), %xmm1
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq 48(%rdi), %rcx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarq %cl, %r11
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r11, 56(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popq %rbx
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popq %r14
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popq %r15
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retq
;
; X64-NO-SHLD-HAVE-BMI2-AVX-LABEL: ashr_64bytes:
; X64-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushq %r13
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups 32(%rdi), %xmm1
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq 48(%rdi), %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq 56(%rdi), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl (%rsi), %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%rax,8), %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andl $56, %ecx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, %esi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andl $56, %eax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, -128(%rsp,%rax), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %cl
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -120(%rsp,%rax), %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -112(%rsp,%rax), %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%r10,%r10), %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %rdi, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r8, %rdi
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -104(%rsp,%rax), %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r11, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -96(%rsp,%rax), %r14
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%r14,%r14), %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r8, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rbx, %r8
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r9, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addq %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r11, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %rbx, %r11
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -88(%rsp,%rax), %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %rbx, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -80(%rsp,%rax), %r12
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%r12,%r12), %r13
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r13, %r13
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r15, %r13
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r14, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addq %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %rbx, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r14, %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r12, %r14
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq -72(%rsp,%rax), %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leaq (%rax,%rax), %r15
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r15, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r14, %r15
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxq %rsi, %r10, %r10
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addq %r9, %r9
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxq %rcx, %r9, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orq %r10, %rcx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarxq %rsi, %rax, %rax
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, 56(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, 8(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r15, 48(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rbx, 32(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r13, 40(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r11, 16(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r8, 24(%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, (%rdx)
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popq %rbx
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popq %r12
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popq %r13
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popq %r14
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popq %r15
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X64-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: ashr_64bytes:
; X64-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups 32(%rdi), %xmm1
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq 48(%rdi), %rcx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq 56(%rdi), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl (%rsi), %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarq $63, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%rax,8), %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andl $56, %ecx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andl $56, %eax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -96(%rsp,%rax), %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -104(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r9, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rdi, %rsi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -112(%rsp,%rax), %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %r9, %r8
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -80(%rsp,%rax), %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -88(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r11, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %r9, %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %r11, %rdi
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -72(%rsp,%rax), %r11
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %r11, %r9
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -128(%rsp,%rax), %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq -120(%rsp,%rax), %rax
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rax, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %r10, %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarxq %rcx, %r11, %r10
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $rcx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdq %cl, %rax, %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r15, 8(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r9, 48(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rdi, 32(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rbx, 40(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r8, 16(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %rsi, 24(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r14, (%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movq %r10, 56(%rdx)
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popq %rbx
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popq %r14
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popq %r15
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X64-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retq
;
; X86-NO-SHLD-NO-BMI2-SSE2-LABEL: ashr_64bytes:
; X86-NO-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%ecx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%ecx), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ebp), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $60, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 68(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll $3, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    andl $24, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 72(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %cl, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 64(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 76(%esp,%esi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 80(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edi,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edx, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 84(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 88(%esp,%esi), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%esi,%esi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 92(%esp,%edx), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 96(%esp,%eax), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edi,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edx, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebp, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 100(%esp,%edx), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 104(%esp,%edx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%esi,%esi), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 108(%esp,%ebp), %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 112(%esp,%ebp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ecx,%ecx), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %esi, %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 116(%esp,%edx), %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, %ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 120(%esp,%edx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%edx,%edx), %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %bl, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl 124(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    leal (%ebx,%ebx), %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    orl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    sarl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, 60(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 48(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 40(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE2-LABEL: ashr_64bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 40(%eax), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 44(%eax), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarl $31, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 88(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 104(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 100(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 48(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl 108(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    sarl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %edi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_64bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%eax), %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%eax), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%eax), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (,%eax,8), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $24, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $60, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 68(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 72(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    notb %dl
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, 64(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 80(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 76(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 88(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 84(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 96(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 92(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 104(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 100(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 112(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 108(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 120(%esp,%ebp), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%edi,%edi), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 116(%esp,%ebp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 124(%esp,%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shlxl %edx, %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    shrxl %ebx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxl %ebx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 52(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-LABEL: ashr_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 40(%eax), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 44(%eax), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarl $31, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 88(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 104(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 100(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 48(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl 108(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebp, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 56(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edx, 52(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ebx, 40(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    sarxl %ecx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %edi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %ecx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE2-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-SSE4-LABEL: ashr_64bytes:
; X86-NO-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%ecx), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $60, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 68(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll $3, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    andl $24, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 72(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %ch
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 64(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 76(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 80(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%edi,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 84(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 88(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %eax, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 92(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 96(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%edi,%edi), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 100(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 104(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%edx,%edx), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 108(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 112(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 116(%esp,%esi), %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 120(%esp,%edx), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl 124(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    leal (%ebx,%ebx), %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    orl %eax, %edx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    sarl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, 60(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 48(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 40(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-SSE4-LABEL: ashr_64bytes:
; X86-HAVE-SHLD-NO-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups (%eax), %xmm0
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 16(%eax), %xmm1
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movups 32(%eax), %xmm2
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarl $31, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 88(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 104(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 100(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 48(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl 108(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    sarl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %edi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_64bytes:
; X86-NO-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%ecx), %xmm0
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%ecx), %xmm1
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%ecx), %xmm2
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (,%eax,8), %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $24, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $60, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 68(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 72(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    notb %dl
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, 64(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 80(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 76(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 88(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 84(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 96(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 92(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 104(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 100(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 112(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 108(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 120(%esp,%ebp), %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%edi,%edi), %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 116(%esp,%ebp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 124(%esp,%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shlxl %edx, %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    shrxl %ebx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxl %ebx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 52(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-LABEL: ashr_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups (%eax), %xmm0
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 16(%eax), %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movups 32(%eax), %xmm2
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movaps %xmm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarl $31, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 88(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 104(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 100(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 48(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl 108(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebp, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 56(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edx, 52(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ebx, 40(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    sarxl %ecx, (%esp), %eax # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %edi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %ecx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-SSE4-NEXT:    retl
;
; X86-NO-SHLD-NO-BMI2-AVX-LABEL: ashr_64bytes:
; X86-NO-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    subl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups 32(%ecx), %xmm1
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 48(%ecx), %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 52(%ecx), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 56(%ecx), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 60(%ecx), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    andl $60, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 68(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll $3, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    andl $24, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 72(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %al, %ch
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    notb %ch
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 64(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edi, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 76(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 80(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%edi,%edi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %edx, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 84(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 88(%esp,%esi), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %eax, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 92(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 96(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%edi,%edi), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %eax, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 100(%esp,%esi), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 104(%esp,%esi), %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%edx,%edx), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %ebx, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 108(%esp,%esi), %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 112(%esp,%esi), %ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%ecx,%ecx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb {{[-0-9]+}}(%e{{[sb]}}p), %ch # 1-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebp, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %edi, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %edx, %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 116(%esp,%esi), %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %al, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 120(%esp,%edx), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ebx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl %esi, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %ebx, %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %dl, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shrl %cl, %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl 124(%esp,%edx), %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    leal (%ebx,%ebx), %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movb %ch, %cl
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    shll %cl, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    orl %eax, %edx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    sarl %cl, %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, 60(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 48(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ebp, 52(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 40(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    addl $204, %esp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X86-NO-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-NO-BMI2-AVX-LABEL: ashr_64bytes:
; X86-HAVE-SHLD-NO-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups (%eax), %ymm0
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups 32(%eax), %xmm1
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 48(%eax), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 56(%eax), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 60(%eax), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarl $31, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 88(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 104(%esp,%ebp), %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 100(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 48(%esp,%ebp), %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl 108(%esp,%ebp), %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edx, 56(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    shrdl %cl, %edx, %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    sarl %cl, %eax
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %edi, 52(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl (%esp), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 40(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %ebx, (%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    movl %eax, 4(%ebp)
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    vzeroupper
; X86-HAVE-SHLD-NO-BMI2-AVX-NEXT:    retl
;
; X86-NO-SHLD-HAVE-BMI2-AVX-LABEL: ashr_64bytes:
; X86-NO-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    subl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups 32(%ecx), %xmm1
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 48(%ecx), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 52(%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 56(%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 60(%ecx), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl (%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarl $31, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (,%eax,8), %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andl $24, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    andl $60, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 68(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 72(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    notb %dl
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%edi,%edi), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, 64(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 80(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 76(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 88(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 84(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 96(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%esi,%esi), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 92(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 104(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%eax,%eax), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 100(%esp,%ecx), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %edi, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 112(%esp,%ecx), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%eax,%eax), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 108(%esp,%ecx), %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %esi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %esi, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %esi, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ecx, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 120(%esp,%ebp), %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%edi,%edi), %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %ecx, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 116(%esp,%ebp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %eax, %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, {{[-0-9]+}}(%e{{[sb]}}p), %ebp # 4-byte Folded Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl %eax, %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %eax, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %ebp, %ecx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl 124(%esp,%eax), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    leal (%eax,%eax), %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shlxl %edx, %ebp, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    shrxl %ebx, %edi, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    orl %edi, %edx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    sarxl %ebx, %eax, %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, 60(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, 56(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 48(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 52(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 40(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 44(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 32(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 36(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 24(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 28(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 16(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 20(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 8(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 12(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, (%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 4(%eax)
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    addl $204, %esp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X86-NO-SHLD-HAVE-BMI2-AVX-NEXT:    retl
;
; X86-HAVE-SHLD-HAVE-BMI2-AVX-LABEL: ashr_64bytes:
; X86-HAVE-SHLD-HAVE-BMI2-AVX:       # %bb.0:
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    pushl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    subl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups (%eax), %ymm0
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups 32(%eax), %xmm1
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 48(%eax), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 52(%eax), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 56(%eax), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 60(%eax), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl (%ecx), %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vmovups %ymm0, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarl $31, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[0-9]+}}(%esp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andl $60, %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 56(%esp,%ebp), %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 52(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shll $3, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    andl $24, %ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %edx, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 64(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 60(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 72(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 68(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 80(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 76(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 88(%esp,%ebp), %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 84(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %ebx, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 96(%esp,%ebp), %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 92(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %esi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 104(%esp,%ebp), %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 100(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %eax, %edx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %edi, %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 48(%esp,%ebp), %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl 108(%esp,%ebp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebp, (%esp) # 4-byte Spill
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %ebp, %eax
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 56(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %esi, 48(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edx, 52(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ebx, 40(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 44(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 32(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 36(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 24(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 28(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 16(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 20(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 8(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 12(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    sarxl %ecx, (%esp), %eax # 4-byte Folded Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    shrdl %cl, %edx, %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %edi, (%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %ecx, 4(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    movl %eax, 60(%ebp)
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    addl $188, %esp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %esi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %edi
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebx
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    popl %ebp
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    vzeroupper
; X86-HAVE-SHLD-HAVE-BMI2-AVX-NEXT:    retl
  %src = load i512, ptr %src.ptr, align 1
  %byteOff = load i512, ptr %byteOff.ptr, align 1
  %bitOff = shl i512 %byteOff, 3
  %res = ashr i512 %src, %bitOff
  store i512 %res, ptr %dst, align 1
  ret void
}

define void @ashr_64bytes_qwordOff(ptr %src.ptr, ptr %qwordOff.ptr, ptr %dst) nounwind {
; X64-SSE2-LABEL: ashr_64bytes_qwordOff:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    pushq %rbx
; X64-SSE2-NEXT:    movq (%rdi), %rax
; X64-SSE2-NEXT:    movq 8(%rdi), %rcx
; X64-SSE2-NEXT:    movq 16(%rdi), %r8
; X64-SSE2-NEXT:    movq 24(%rdi), %r9
; X64-SSE2-NEXT:    movq 32(%rdi), %r10
; X64-SSE2-NEXT:    movq 40(%rdi), %r11
; X64-SSE2-NEXT:    movq 48(%rdi), %rbx
; X64-SSE2-NEXT:    movq 56(%rdi), %rdi
; X64-SSE2-NEXT:    movl (%rsi), %esi
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rbx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r11, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r10, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r9, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    sarq $63, %rdi
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-SSE2-NEXT:    andl $7, %esi
; X64-SSE2-NEXT:    movq -128(%rsp,%rsi,8), %rax
; X64-SSE2-NEXT:    movq -120(%rsp,%rsi,8), %rcx
; X64-SSE2-NEXT:    movq -104(%rsp,%rsi,8), %rdi
; X64-SSE2-NEXT:    movq -112(%rsp,%rsi,8), %r8
; X64-SSE2-NEXT:    movq -88(%rsp,%rsi,8), %r9
; X64-SSE2-NEXT:    movq -96(%rsp,%rsi,8), %r10
; X64-SSE2-NEXT:    movq -72(%rsp,%rsi,8), %r11
; X64-SSE2-NEXT:    movq -80(%rsp,%rsi,8), %rsi
; X64-SSE2-NEXT:    movq %rsi, 48(%rdx)
; X64-SSE2-NEXT:    movq %r11, 56(%rdx)
; X64-SSE2-NEXT:    movq %r10, 32(%rdx)
; X64-SSE2-NEXT:    movq %r9, 40(%rdx)
; X64-SSE2-NEXT:    movq %r8, 16(%rdx)
; X64-SSE2-NEXT:    movq %rdi, 24(%rdx)
; X64-SSE2-NEXT:    movq %rax, (%rdx)
; X64-SSE2-NEXT:    movq %rcx, 8(%rdx)
; X64-SSE2-NEXT:    popq %rbx
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: ashr_64bytes_qwordOff:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    pushq %rax
; X64-SSE42-NEXT:    movups (%rdi), %xmm0
; X64-SSE42-NEXT:    movups 16(%rdi), %xmm1
; X64-SSE42-NEXT:    movups 32(%rdi), %xmm2
; X64-SSE42-NEXT:    movq 48(%rdi), %rax
; X64-SSE42-NEXT:    movq 56(%rdi), %rcx
; X64-SSE42-NEXT:    movl (%rsi), %esi
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm2, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movaps %xmm0, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    sarq $63, %rcx
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-SSE42-NEXT:    andl $7, %esi
; X64-SSE42-NEXT:    movups -128(%rsp,%rsi,8), %xmm0
; X64-SSE42-NEXT:    movups -112(%rsp,%rsi,8), %xmm1
; X64-SSE42-NEXT:    movups -96(%rsp,%rsi,8), %xmm2
; X64-SSE42-NEXT:    movups -80(%rsp,%rsi,8), %xmm3
; X64-SSE42-NEXT:    movups %xmm3, 48(%rdx)
; X64-SSE42-NEXT:    movups %xmm1, 16(%rdx)
; X64-SSE42-NEXT:    movups %xmm2, 32(%rdx)
; X64-SSE42-NEXT:    movups %xmm0, (%rdx)
; X64-SSE42-NEXT:    popq %rax
; X64-SSE42-NEXT:    retq
;
; X64-AVX-LABEL: ashr_64bytes_qwordOff:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    pushq %rax
; X64-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-AVX-NEXT:    vmovups 32(%rdi), %xmm1
; X64-AVX-NEXT:    movq 48(%rdi), %rax
; X64-AVX-NEXT:    movq 56(%rdi), %rcx
; X64-AVX-NEXT:    movl (%rsi), %esi
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    vmovaps %xmm1, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    vmovups %ymm0, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    sarq $63, %rcx
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-AVX-NEXT:    andl $7, %esi
; X64-AVX-NEXT:    vmovups -128(%rsp,%rsi,8), %xmm0
; X64-AVX-NEXT:    vmovups -112(%rsp,%rsi,8), %xmm1
; X64-AVX-NEXT:    vmovups -96(%rsp,%rsi,8), %xmm2
; X64-AVX-NEXT:    vmovups -80(%rsp,%rsi,8), %xmm3
; X64-AVX-NEXT:    vmovups %xmm3, 48(%rdx)
; X64-AVX-NEXT:    vmovups %xmm1, 16(%rdx)
; X64-AVX-NEXT:    vmovups %xmm2, 32(%rdx)
; X64-AVX-NEXT:    vmovups %xmm0, (%rdx)
; X64-AVX-NEXT:    popq %rax
; X64-AVX-NEXT:    vzeroupper
; X64-AVX-NEXT:    retq
;
; X86-SSE2-LABEL: ashr_64bytes_qwordOff:
; X86-SSE2:       # %bb.0:
; X86-SSE2-NEXT:    pushl %ebp
; X86-SSE2-NEXT:    pushl %ebx
; X86-SSE2-NEXT:    pushl %edi
; X86-SSE2-NEXT:    pushl %esi
; X86-SSE2-NEXT:    subl $188, %esp
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl (%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 4(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 8(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 12(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 16(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 20(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 24(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 28(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 32(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 36(%eax), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 40(%eax), %ebp
; X86-SSE2-NEXT:    movl 44(%eax), %ebx
; X86-SSE2-NEXT:    movl 48(%eax), %edi
; X86-SSE2-NEXT:    movl 52(%eax), %esi
; X86-SSE2-NEXT:    movl 56(%eax), %edx
; X86-SSE2-NEXT:    movl 60(%eax), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl (%eax), %eax
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X86-SSE2-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    sarl $31, %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X86-SSE2-NEXT:    andl $7, %eax
; X86-SSE2-NEXT:    movl 48(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 52(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 60(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 56(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 68(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 64(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 76(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 72(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 84(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 80(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-SSE2-NEXT:    movl 92(%esp,%eax,8), %ebp
; X86-SSE2-NEXT:    movl 88(%esp,%eax,8), %ebx
; X86-SSE2-NEXT:    movl 100(%esp,%eax,8), %edi
; X86-SSE2-NEXT:    movl 96(%esp,%eax,8), %esi
; X86-SSE2-NEXT:    movl 108(%esp,%eax,8), %edx
; X86-SSE2-NEXT:    movl 104(%esp,%eax,8), %ecx
; X86-SSE2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE2-NEXT:    movl %ecx, 56(%eax)
; X86-SSE2-NEXT:    movl %edx, 60(%eax)
; X86-SSE2-NEXT:    movl %esi, 48(%eax)
; X86-SSE2-NEXT:    movl %edi, 52(%eax)
; X86-SSE2-NEXT:    movl %ebx, 40(%eax)
; X86-SSE2-NEXT:    movl %ebp, 44(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 32(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 36(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 24(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 28(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 16(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 20(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 8(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 12(%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, (%eax)
; X86-SSE2-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X86-SSE2-NEXT:    movl %ecx, 4(%eax)
; X86-SSE2-NEXT:    addl $188, %esp
; X86-SSE2-NEXT:    popl %esi
; X86-SSE2-NEXT:    popl %edi
; X86-SSE2-NEXT:    popl %ebx
; X86-SSE2-NEXT:    popl %ebp
; X86-SSE2-NEXT:    retl
;
; X86-SSE42-LABEL: ashr_64bytes_qwordOff:
; X86-SSE42:       # %bb.0:
; X86-SSE42-NEXT:    pushl %ebx
; X86-SSE42-NEXT:    pushl %edi
; X86-SSE42-NEXT:    pushl %esi
; X86-SSE42-NEXT:    subl $128, %esp
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-SSE42-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-SSE42-NEXT:    movups (%edx), %xmm0
; X86-SSE42-NEXT:    movups 16(%edx), %xmm1
; X86-SSE42-NEXT:    movups 32(%edx), %xmm2
; X86-SSE42-NEXT:    movl 48(%edx), %esi
; X86-SSE42-NEXT:    movl 52(%edx), %edi
; X86-SSE42-NEXT:    movl 56(%edx), %ebx
; X86-SSE42-NEXT:    movl 60(%edx), %edx
; X86-SSE42-NEXT:    movl (%ecx), %ecx
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm2, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm1, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movaps %xmm0, (%esp)
; X86-SSE42-NEXT:    sarl $31, %edx
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-SSE42-NEXT:    andl $7, %ecx
; X86-SSE42-NEXT:    movups (%esp,%ecx,8), %xmm0
; X86-SSE42-NEXT:    movups 16(%esp,%ecx,8), %xmm1
; X86-SSE42-NEXT:    movups 32(%esp,%ecx,8), %xmm2
; X86-SSE42-NEXT:    movups 48(%esp,%ecx,8), %xmm3
; X86-SSE42-NEXT:    movups %xmm3, 48(%eax)
; X86-SSE42-NEXT:    movups %xmm2, 32(%eax)
; X86-SSE42-NEXT:    movups %xmm1, 16(%eax)
; X86-SSE42-NEXT:    movups %xmm0, (%eax)
; X86-SSE42-NEXT:    addl $128, %esp
; X86-SSE42-NEXT:    popl %esi
; X86-SSE42-NEXT:    popl %edi
; X86-SSE42-NEXT:    popl %ebx
; X86-SSE42-NEXT:    retl
;
; X86-AVX-LABEL: ashr_64bytes_qwordOff:
; X86-AVX:       # %bb.0:
; X86-AVX-NEXT:    pushl %ebx
; X86-AVX-NEXT:    pushl %edi
; X86-AVX-NEXT:    pushl %esi
; X86-AVX-NEXT:    subl $128, %esp
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX-NEXT:    vmovups (%edx), %ymm0
; X86-AVX-NEXT:    vmovups 32(%edx), %xmm1
; X86-AVX-NEXT:    movl 48(%edx), %esi
; X86-AVX-NEXT:    movl 52(%edx), %edi
; X86-AVX-NEXT:    movl 56(%edx), %ebx
; X86-AVX-NEXT:    movl 60(%edx), %edx
; X86-AVX-NEXT:    movl (%ecx), %ecx
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    vmovaps %xmm1, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    vmovups %ymm0, (%esp)
; X86-AVX-NEXT:    sarl $31, %edx
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X86-AVX-NEXT:    andl $7, %ecx
; X86-AVX-NEXT:    vmovups (%esp,%ecx,8), %xmm0
; X86-AVX-NEXT:    vmovups 16(%esp,%ecx,8), %xmm1
; X86-AVX-NEXT:    vmovups 32(%esp,%ecx,8), %xmm2
; X86-AVX-NEXT:    vmovups 48(%esp,%ecx,8), %xmm3
; X86-AVX-NEXT:    vmovups %xmm3, 48(%eax)
; X86-AVX-NEXT:    vmovups %xmm2, 32(%eax)
; X86-AVX-NEXT:    vmovups %xmm1, 16(%eax)
; X86-AVX-NEXT:    vmovups %xmm0, (%eax)
; X86-AVX-NEXT:    addl $128, %esp
; X86-AVX-NEXT:    popl %esi
; X86-AVX-NEXT:    popl %edi
; X86-AVX-NEXT:    popl %ebx
; X86-AVX-NEXT:    vzeroupper
; X86-AVX-NEXT:    retl
  %src = load i512, ptr %src.ptr, align 1
  %qwordOff = load i512, ptr %qwordOff.ptr, align 1
  %bitOff = shl i512 %qwordOff, 6
  %res = ashr i512 %src, %bitOff
  store i512 %res, ptr %dst, align 1
  ret void
}

;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; ALL: {{.*}}
; X64: {{.*}}
; X86: {{.*}}
