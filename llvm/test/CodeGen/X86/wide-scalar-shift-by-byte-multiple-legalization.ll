; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-NO-BMI2,X64-NO-SHLD,X64-NO-BMI2-NO-SHLD
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-NO-BMI2,X64-SHLD,X64-NO-BMI2-HAVE-SHLD
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-BMI2,X64-NO-SHLD,X64-HAVE-BMI2-NO-SHLD
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+sse2,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X64,X64-BMI2,X64-SHLD,X64-HAVE-BMI2-HAVE-SHLD
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse2,-bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X32,X32-NO-BMI2,X32-NO-SHLD,X32-NO-BMI2-NO-SHLD
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse2,-bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X32,X32-NO-BMI2,X32-SHLD,X32-NO-BMI2-HAVE-SHLD
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse2,+bmi2,+slow-shld | FileCheck %s --check-prefixes=ALL,X32,X32-BMI2,X32-NO-SHLD,X32-HAVE-BMI2-NO-SHLD
; RUN: llc < %s -mtriple=i686-unknown-linux-gnu -mattr=+sse2,+bmi2,-slow-shld | FileCheck %s --check-prefixes=ALL,X32,X32-BMI2,X32-SHLD,X32-HAVE-BMI2-HAVE-SHLD

define void @lshr_4bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: lshr_4bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movl (%rdi), %eax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    shrl %cl, %eax
; X64-NO-BMI2-NEXT:    movl %eax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-BMI2-LABEL: lshr_4bytes:
; X64-BMI2:       # %bb.0:
; X64-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-BMI2-NEXT:    shlb $3, %al
; X64-BMI2-NEXT:    shrxl %eax, (%rdi), %eax
; X64-BMI2-NEXT:    movl %eax, (%rdx)
; X64-BMI2-NEXT:    retq
;
; X32-NO-BMI2-LABEL: lshr_4bytes:
; X32-NO-BMI2:       # %bb.0:
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NO-BMI2-NEXT:    movl (%edx), %edx
; X32-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X32-NO-BMI2-NEXT:    shlb $3, %cl
; X32-NO-BMI2-NEXT:    shrl %cl, %edx
; X32-NO-BMI2-NEXT:    movl %edx, (%eax)
; X32-NO-BMI2-NEXT:    retl
;
; X32-BMI2-LABEL: lshr_4bytes:
; X32-BMI2:       # %bb.0:
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-BMI2-NEXT:    movzbl (%edx), %edx
; X32-BMI2-NEXT:    shlb $3, %dl
; X32-BMI2-NEXT:    shrxl %edx, (%ecx), %ecx
; X32-BMI2-NEXT:    movl %ecx, (%eax)
; X32-BMI2-NEXT:    retl
  %src = load i32, ptr %src.ptr, align 1
  %byteOff = load i32, ptr %byteOff.ptr, align 1
  %bitOff = shl i32 %byteOff, 3
  %res = lshr i32 %src, %bitOff
  store i32 %res, ptr %dst, align 1
  ret void
}
define void @shl_4bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: shl_4bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movl (%rdi), %eax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    shll %cl, %eax
; X64-NO-BMI2-NEXT:    movl %eax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-BMI2-LABEL: shl_4bytes:
; X64-BMI2:       # %bb.0:
; X64-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-BMI2-NEXT:    shlb $3, %al
; X64-BMI2-NEXT:    shlxl %eax, (%rdi), %eax
; X64-BMI2-NEXT:    movl %eax, (%rdx)
; X64-BMI2-NEXT:    retq
;
; X32-NO-BMI2-LABEL: shl_4bytes:
; X32-NO-BMI2:       # %bb.0:
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NO-BMI2-NEXT:    movl (%edx), %edx
; X32-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X32-NO-BMI2-NEXT:    shlb $3, %cl
; X32-NO-BMI2-NEXT:    shll %cl, %edx
; X32-NO-BMI2-NEXT:    movl %edx, (%eax)
; X32-NO-BMI2-NEXT:    retl
;
; X32-BMI2-LABEL: shl_4bytes:
; X32-BMI2:       # %bb.0:
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-BMI2-NEXT:    movzbl (%edx), %edx
; X32-BMI2-NEXT:    shlb $3, %dl
; X32-BMI2-NEXT:    shlxl %edx, (%ecx), %ecx
; X32-BMI2-NEXT:    movl %ecx, (%eax)
; X32-BMI2-NEXT:    retl
  %src = load i32, ptr %src.ptr, align 1
  %byteOff = load i32, ptr %byteOff.ptr, align 1
  %bitOff = shl i32 %byteOff, 3
  %res = shl i32 %src, %bitOff
  store i32 %res, ptr %dst, align 1
  ret void
}
define void @ashr_4bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: ashr_4bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movl (%rdi), %eax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    sarl %cl, %eax
; X64-NO-BMI2-NEXT:    movl %eax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-BMI2-LABEL: ashr_4bytes:
; X64-BMI2:       # %bb.0:
; X64-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-BMI2-NEXT:    shlb $3, %al
; X64-BMI2-NEXT:    sarxl %eax, (%rdi), %eax
; X64-BMI2-NEXT:    movl %eax, (%rdx)
; X64-BMI2-NEXT:    retq
;
; X32-NO-BMI2-LABEL: ashr_4bytes:
; X32-NO-BMI2:       # %bb.0:
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NO-BMI2-NEXT:    movl (%edx), %edx
; X32-NO-BMI2-NEXT:    movzbl (%ecx), %ecx
; X32-NO-BMI2-NEXT:    shlb $3, %cl
; X32-NO-BMI2-NEXT:    sarl %cl, %edx
; X32-NO-BMI2-NEXT:    movl %edx, (%eax)
; X32-NO-BMI2-NEXT:    retl
;
; X32-BMI2-LABEL: ashr_4bytes:
; X32-BMI2:       # %bb.0:
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-BMI2-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-BMI2-NEXT:    movzbl (%edx), %edx
; X32-BMI2-NEXT:    shlb $3, %dl
; X32-BMI2-NEXT:    sarxl %edx, (%ecx), %ecx
; X32-BMI2-NEXT:    movl %ecx, (%eax)
; X32-BMI2-NEXT:    retl
  %src = load i32, ptr %src.ptr, align 1
  %byteOff = load i32, ptr %byteOff.ptr, align 1
  %bitOff = shl i32 %byteOff, 3
  %res = ashr i32 %src, %bitOff
  store i32 %res, ptr %dst, align 1
  ret void
}

define void @lshr_8bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: lshr_8bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    shrq %cl, %rax
; X64-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-BMI2-LABEL: lshr_8bytes:
; X64-BMI2:       # %bb.0:
; X64-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-BMI2-NEXT:    shlb $3, %al
; X64-BMI2-NEXT:    shrxq %rax, (%rdi), %rax
; X64-BMI2-NEXT:    movq %rax, (%rdx)
; X64-BMI2-NEXT:    retq
;
; X32-NO-BMI2-NO-SHLD-LABEL: lshr_8bytes:
; X32-NO-BMI2-NO-SHLD:       # %bb.0:
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl (%ecx), %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl 4(%ecx), %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    movzbl (%eax), %eax
; X32-NO-BMI2-NO-SHLD-NEXT:    shlb $3, %al
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    shrl %cl, %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    leal (%esi,%esi), %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    notb %cl
; X32-NO-BMI2-NO-SHLD-NEXT:    shll %cl, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    orl %ebx, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    shrl %cl, %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    xorl %ecx, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    testb $32, %al
; X32-NO-BMI2-NO-SHLD-NEXT:    cmovnel %esi, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    cmovel %esi, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %ecx, 4(%edx)
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %edi, (%edx)
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    retl
;
; X32-NO-BMI2-HAVE-SHLD-LABEL: lshr_8bytes:
; X32-NO-BMI2-HAVE-SHLD:       # %bb.0:
; X32-NO-BMI2-HAVE-SHLD-NEXT:    pushl %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    pushl %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl (%esi), %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl 4(%esi), %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movzbl (%ecx), %ecx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %esi, %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    shrl %cl, %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    shrdl %cl, %esi, %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    xorl %esi, %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    testb $32, %cl
; X32-NO-BMI2-HAVE-SHLD-NEXT:    cmovnel %edi, %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    cmovel %edi, %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %esi, 4(%eax)
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %edx, (%eax)
; X32-NO-BMI2-HAVE-SHLD-NEXT:    popl %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    popl %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    retl
;
; X32-HAVE-BMI2-NO-SHLD-LABEL: lshr_8bytes:
; X32-HAVE-BMI2-NO-SHLD:       # %bb.0:
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl 4(%edx), %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movzbl (%ecx), %ecx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shlb $3, %cl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shrxl %ecx, (%edx), %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %ecx, %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    notb %bl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    leal (%esi,%esi), %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shlxl %ebx, %edi, %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    orl %edx, %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shrxl %ecx, %esi, %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    xorl %esi, %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    testb $32, %cl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    cmovnel %edx, %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    cmovel %edx, %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %esi, 4(%eax)
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %edi, (%eax)
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    retl
;
; X32-HAVE-BMI2-HAVE-SHLD-LABEL: lshr_8bytes:
; X32-HAVE-BMI2-HAVE-SHLD:       # %bb.0:
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    pushl %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    pushl %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl (%esi), %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl 4(%esi), %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movzbl (%ecx), %ecx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    shrdl %cl, %esi, %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    shrxl %ecx, %esi, %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    xorl %edi, %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    testb $32, %cl
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovnel %esi, %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovel %esi, %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl %edi, 4(%eax)
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl %edx, (%eax)
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    popl %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    popl %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    retl
  %src = load i64, ptr %src.ptr, align 1
  %byteOff = load i64, ptr %byteOff.ptr, align 1
  %bitOff = shl i64 %byteOff, 3
  %res = lshr i64 %src, %bitOff
  store i64 %res, ptr %dst, align 1
  ret void
}
define void @shl_8bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: shl_8bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    shlq %cl, %rax
; X64-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-BMI2-LABEL: shl_8bytes:
; X64-BMI2:       # %bb.0:
; X64-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-BMI2-NEXT:    shlb $3, %al
; X64-BMI2-NEXT:    shlxq %rax, (%rdi), %rax
; X64-BMI2-NEXT:    movq %rax, (%rdx)
; X64-BMI2-NEXT:    retq
;
; X32-NO-BMI2-NO-SHLD-LABEL: shl_8bytes:
; X32-NO-BMI2-NO-SHLD:       # %bb.0:
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl (%ecx), %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    movl 4(%ecx), %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    movzbl (%eax), %eax
; X32-NO-BMI2-NO-SHLD-NEXT:    shlb $3, %al
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    shll %cl, %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %esi, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    shrl %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    notb %cl
; X32-NO-BMI2-NO-SHLD-NEXT:    shrl %cl, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    orl %ebx, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    shll %cl, %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    xorl %ecx, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    testb $32, %al
; X32-NO-BMI2-NO-SHLD-NEXT:    cmovnel %esi, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    cmovel %esi, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %ecx, (%edx)
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %edi, 4(%edx)
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    retl
;
; X32-NO-BMI2-HAVE-SHLD-LABEL: shl_8bytes:
; X32-NO-BMI2-HAVE-SHLD:       # %bb.0:
; X32-NO-BMI2-HAVE-SHLD-NEXT:    pushl %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    pushl %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl (%edx), %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl 4(%edx), %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movzbl (%ecx), %ecx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %esi, %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    shll %cl, %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    shldl %cl, %esi, %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    xorl %esi, %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    testb $32, %cl
; X32-NO-BMI2-HAVE-SHLD-NEXT:    cmovnel %edi, %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    cmovel %edi, %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %edx, 4(%eax)
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %esi, (%eax)
; X32-NO-BMI2-HAVE-SHLD-NEXT:    popl %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    popl %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    retl
;
; X32-HAVE-BMI2-NO-SHLD-LABEL: shl_8bytes:
; X32-HAVE-BMI2-NO-SHLD:       # %bb.0:
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl (%edx), %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movzbl (%ecx), %ecx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shlb $3, %cl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shlxl %ecx, 4(%edx), %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %ecx, %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    notb %bl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shlxl %ecx, %esi, %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shrl %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shrxl %ebx, %esi, %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    orl %edx, %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    xorl %edx, %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    testb $32, %cl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    cmovnel %edi, %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    cmovel %edi, %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %edx, (%eax)
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %esi, 4(%eax)
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    retl
;
; X32-HAVE-BMI2-HAVE-SHLD-LABEL: shl_8bytes:
; X32-HAVE-BMI2-HAVE-SHLD:       # %bb.0:
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    pushl %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    pushl %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl (%edx), %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl 4(%edx), %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movzbl (%ecx), %ecx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    shldl %cl, %esi, %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    shlxl %ecx, %esi, %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    xorl %edi, %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    testb $32, %cl
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovnel %esi, %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovel %esi, %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl %edx, 4(%eax)
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl %edi, (%eax)
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    popl %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    popl %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    retl
  %src = load i64, ptr %src.ptr, align 1
  %byteOff = load i64, ptr %byteOff.ptr, align 1
  %bitOff = shl i64 %byteOff, 3
  %res = shl i64 %src, %bitOff
  store i64 %res, ptr %dst, align 1
  ret void
}
define void @ashr_8bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-LABEL: ashr_8bytes:
; X64-NO-BMI2:       # %bb.0:
; X64-NO-BMI2-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-NEXT:    shlb $3, %cl
; X64-NO-BMI2-NEXT:    sarq %cl, %rax
; X64-NO-BMI2-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-NEXT:    retq
;
; X64-BMI2-LABEL: ashr_8bytes:
; X64-BMI2:       # %bb.0:
; X64-BMI2-NEXT:    movzbl (%rsi), %eax
; X64-BMI2-NEXT:    shlb $3, %al
; X64-BMI2-NEXT:    sarxq %rax, (%rdi), %rax
; X64-BMI2-NEXT:    movq %rax, (%rdx)
; X64-BMI2-NEXT:    retq
;
; X32-NO-BMI2-NO-SHLD-LABEL: ashr_8bytes:
; X32-NO-BMI2-NO-SHLD:       # %bb.0:
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    pushl %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl (%ecx), %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl 4(%ecx), %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    movzbl (%eax), %eax
; X32-NO-BMI2-NO-SHLD-NEXT:    shlb $3, %al
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    shrl %cl, %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    leal (%esi,%esi), %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    notb %cl
; X32-NO-BMI2-NO-SHLD-NEXT:    shll %cl, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    orl %ebx, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %esi, %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X32-NO-BMI2-NO-SHLD-NEXT:    sarl %cl, %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    sarl $31, %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    testb $32, %al
; X32-NO-BMI2-NO-SHLD-NEXT:    cmovnel %ebx, %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    cmovel %ebx, %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %esi, 4(%edx)
; X32-NO-BMI2-NO-SHLD-NEXT:    movl %edi, (%edx)
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %esi
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %edi
; X32-NO-BMI2-NO-SHLD-NEXT:    popl %ebx
; X32-NO-BMI2-NO-SHLD-NEXT:    retl
;
; X32-NO-BMI2-HAVE-SHLD-LABEL: ashr_8bytes:
; X32-NO-BMI2-HAVE-SHLD:       # %bb.0:
; X32-NO-BMI2-HAVE-SHLD-NEXT:    pushl %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    pushl %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl (%esi), %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl 4(%esi), %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movzbl (%ecx), %ecx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %esi, %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    sarl %cl, %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    shrdl %cl, %esi, %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    sarl $31, %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    testb $32, %cl
; X32-NO-BMI2-HAVE-SHLD-NEXT:    cmovnel %edi, %edx
; X32-NO-BMI2-HAVE-SHLD-NEXT:    cmovel %edi, %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %esi, 4(%eax)
; X32-NO-BMI2-HAVE-SHLD-NEXT:    movl %edx, (%eax)
; X32-NO-BMI2-HAVE-SHLD-NEXT:    popl %esi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    popl %edi
; X32-NO-BMI2-HAVE-SHLD-NEXT:    retl
;
; X32-HAVE-BMI2-NO-SHLD-LABEL: ashr_8bytes:
; X32-HAVE-BMI2-NO-SHLD:       # %bb.0:
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    pushl %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl 4(%esi), %ecx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movzbl (%edx), %edx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shlb $3, %dl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shrxl %edx, (%esi), %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %edx, %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    notb %bl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    leal (%ecx,%ecx), %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    shlxl %ebx, %edi, %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    orl %esi, %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    sarxl %edx, %ecx, %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    sarl $31, %ecx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    testb $32, %dl
; X32-HAVE-BMI2-NO-SHLD-NEXT:    cmovnel %esi, %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    cmovel %esi, %ecx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %ecx, 4(%eax)
; X32-HAVE-BMI2-NO-SHLD-NEXT:    movl %edi, (%eax)
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %esi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %edi
; X32-HAVE-BMI2-NO-SHLD-NEXT:    popl %ebx
; X32-HAVE-BMI2-NO-SHLD-NEXT:    retl
;
; X32-HAVE-BMI2-HAVE-SHLD-LABEL: ashr_8bytes:
; X32-HAVE-BMI2-HAVE-SHLD:       # %bb.0:
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    pushl %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    pushl %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl {{[0-9]+}}(%esp), %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl (%esi), %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl 4(%esi), %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movzbl (%ecx), %ecx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    shrdl %cl, %esi, %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    sarxl %ecx, %esi, %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    sarl $31, %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    testb $32, %cl
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovnel %edi, %edx
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovel %edi, %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl %esi, 4(%eax)
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    movl %edx, (%eax)
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    popl %esi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    popl %edi
; X32-HAVE-BMI2-HAVE-SHLD-NEXT:    retl
  %src = load i64, ptr %src.ptr, align 1
  %byteOff = load i64, ptr %byteOff.ptr, align 1
  %bitOff = shl i64 %byteOff, 3
  %res = ashr i64 %src, %bitOff
  store i64 %res, ptr %dst, align 1
  ret void
}

define void @lshr_16bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-NO-SHLD-LABEL: lshr_16bytes:
; X64-NO-BMI2-NO-SHLD:       # %bb.0:
; X64-NO-BMI2-NO-SHLD-NEXT:    movq (%rdi), %r8
; X64-NO-BMI2-NO-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-NO-BMI2-NO-SHLD-NEXT:    movzbl (%rsi), %eax
; X64-NO-BMI2-NO-SHLD-NEXT:    shlb $3, %al
; X64-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X64-NO-BMI2-NO-SHLD-NEXT:    shrq %cl, %r8
; X64-NO-BMI2-NO-SHLD-NEXT:    leaq (%rdi,%rdi), %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    notb %cl
; X64-NO-BMI2-NO-SHLD-NEXT:    shlq %cl, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    orq %r8, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X64-NO-BMI2-NO-SHLD-NEXT:    shrq %cl, %rdi
; X64-NO-BMI2-NO-SHLD-NEXT:    xorl %ecx, %ecx
; X64-NO-BMI2-NO-SHLD-NEXT:    testb $64, %al
; X64-NO-BMI2-NO-SHLD-NEXT:    cmovneq %rdi, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    cmoveq %rdi, %rcx
; X64-NO-BMI2-NO-SHLD-NEXT:    movq %rcx, 8(%rdx)
; X64-NO-BMI2-NO-SHLD-NEXT:    movq %rsi, (%rdx)
; X64-NO-BMI2-NO-SHLD-NEXT:    retq
;
; X64-NO-BMI2-HAVE-SHLD-LABEL: lshr_16bytes:
; X64-NO-BMI2-HAVE-SHLD:       # %bb.0:
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rdi, %rsi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    shrq %cl, %rsi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    shrdq %cl, %rdi, %rax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    xorl %edi, %edi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    testb $64, %cl
; X64-NO-BMI2-HAVE-SHLD-NEXT:    cmovneq %rsi, %rax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    cmoveq %rsi, %rdi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rdi, 8(%rdx)
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-HAVE-SHLD-NEXT:    retq
;
; X64-HAVE-BMI2-NO-SHLD-LABEL: lshr_16bytes:
; X64-HAVE-BMI2-NO-SHLD:       # %bb.0:
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq 8(%rdi), %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shlb $3, %cl
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shrxq %rcx, (%rdi), %rsi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movl %ecx, %edi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    notb %dil
; X64-HAVE-BMI2-NO-SHLD-NEXT:    leaq (%rax,%rax), %r8
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shlxq %rdi, %r8, %rdi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    orq %rsi, %rdi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shrxq %rcx, %rax, %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    xorl %esi, %esi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    testb $64, %cl
; X64-HAVE-BMI2-NO-SHLD-NEXT:    cmovneq %rax, %rdi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    cmoveq %rax, %rsi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq %rsi, 8(%rdx)
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-BMI2-NO-SHLD-NEXT:    retq
;
; X64-HAVE-BMI2-HAVE-SHLD-LABEL: lshr_16bytes:
; X64-HAVE-BMI2-HAVE-SHLD:       # %bb.0:
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq (%rdi), %rax
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    shrxq %rcx, %rdi, %rsi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    xorl %edi, %edi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    testb $64, %cl
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq %rax, (%rdx)
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    retq
;
; X32-LABEL: lshr_16bytes:
; X32:       # %bb.0:
; X32-NEXT:    pushl %ebx
; X32-NEXT:    pushl %edi
; X32-NEXT:    pushl %esi
; X32-NEXT:    subl $32, %esp
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NEXT:    movl (%edx), %esi
; X32-NEXT:    movl 4(%edx), %edi
; X32-NEXT:    movl 8(%edx), %ebx
; X32-NEXT:    movl 12(%edx), %edx
; X32-NEXT:    movzbl (%ecx), %ecx
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %esi, (%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    andl $15, %ecx
; X32-NEXT:    movl (%esp,%ecx), %edx
; X32-NEXT:    movl 4(%esp,%ecx), %esi
; X32-NEXT:    movl 12(%esp,%ecx), %edi
; X32-NEXT:    movl 8(%esp,%ecx), %ecx
; X32-NEXT:    movl %ecx, 8(%eax)
; X32-NEXT:    movl %edi, 12(%eax)
; X32-NEXT:    movl %edx, (%eax)
; X32-NEXT:    movl %esi, 4(%eax)
; X32-NEXT:    addl $32, %esp
; X32-NEXT:    popl %esi
; X32-NEXT:    popl %edi
; X32-NEXT:    popl %ebx
; X32-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %byteOff = load i128, ptr %byteOff.ptr, align 1
  %bitOff = shl i128 %byteOff, 3
  %res = lshr i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}
define void @shl_16bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-NO-SHLD-LABEL: shl_16bytes:
; X64-NO-BMI2-NO-SHLD:       # %bb.0:
; X64-NO-BMI2-NO-SHLD-NEXT:    movq (%rdi), %r8
; X64-NO-BMI2-NO-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-NO-BMI2-NO-SHLD-NEXT:    movzbl (%rsi), %eax
; X64-NO-BMI2-NO-SHLD-NEXT:    shlb $3, %al
; X64-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X64-NO-BMI2-NO-SHLD-NEXT:    shlq %cl, %rdi
; X64-NO-BMI2-NO-SHLD-NEXT:    movq %r8, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    shrq %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    notb %cl
; X64-NO-BMI2-NO-SHLD-NEXT:    shrq %cl, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    orq %rdi, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X64-NO-BMI2-NO-SHLD-NEXT:    shlq %cl, %r8
; X64-NO-BMI2-NO-SHLD-NEXT:    xorl %ecx, %ecx
; X64-NO-BMI2-NO-SHLD-NEXT:    testb $64, %al
; X64-NO-BMI2-NO-SHLD-NEXT:    cmovneq %r8, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    cmoveq %r8, %rcx
; X64-NO-BMI2-NO-SHLD-NEXT:    movq %rcx, (%rdx)
; X64-NO-BMI2-NO-SHLD-NEXT:    movq %rsi, 8(%rdx)
; X64-NO-BMI2-NO-SHLD-NEXT:    retq
;
; X64-NO-BMI2-HAVE-SHLD-LABEL: shl_16bytes:
; X64-NO-BMI2-HAVE-SHLD:       # %bb.0:
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rax, %rsi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    shlq %cl, %rsi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    shldq %cl, %rax, %rdi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    xorl %eax, %eax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    testb $64, %cl
; X64-NO-BMI2-HAVE-SHLD-NEXT:    cmovneq %rsi, %rdi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    cmoveq %rsi, %rax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rdi, 8(%rdx)
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-HAVE-SHLD-NEXT:    retq
;
; X64-HAVE-BMI2-NO-SHLD-LABEL: shl_16bytes:
; X64-HAVE-BMI2-NO-SHLD:       # %bb.0:
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq (%rdi), %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shlb $3, %cl
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shlxq %rcx, 8(%rdi), %rsi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movl %ecx, %edi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    notb %dil
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shlxq %rcx, %rax, %r8
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shrq %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shrxq %rdi, %rax, %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    orq %rsi, %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    xorl %esi, %esi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    testb $64, %cl
; X64-HAVE-BMI2-NO-SHLD-NEXT:    cmovneq %r8, %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    cmoveq %r8, %rsi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq %rsi, (%rdx)
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-BMI2-NO-SHLD-NEXT:    retq
;
; X64-HAVE-BMI2-HAVE-SHLD-LABEL: shl_16bytes:
; X64-HAVE-BMI2-HAVE-SHLD:       # %bb.0:
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq (%rdi), %rax
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    shldq %cl, %rax, %rdi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    shlxq %rcx, %rax, %rax
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    xorl %esi, %esi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    testb $64, %cl
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovneq %rax, %rdi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    cmoveq %rax, %rsi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq %rsi, (%rdx)
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    retq
;
; X32-LABEL: shl_16bytes:
; X32:       # %bb.0:
; X32-NEXT:    pushl %ebx
; X32-NEXT:    pushl %edi
; X32-NEXT:    pushl %esi
; X32-NEXT:    subl $32, %esp
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NEXT:    movl (%edx), %esi
; X32-NEXT:    movl 4(%edx), %edi
; X32-NEXT:    movl 8(%edx), %ebx
; X32-NEXT:    movl 12(%edx), %edx
; X32-NEXT:    movzbl (%ecx), %ecx
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, (%esp)
; X32-NEXT:    andb $15, %cl
; X32-NEXT:    negb %cl
; X32-NEXT:    movsbl %cl, %ecx
; X32-NEXT:    movl 16(%esp,%ecx), %edx
; X32-NEXT:    movl 20(%esp,%ecx), %esi
; X32-NEXT:    movl 28(%esp,%ecx), %edi
; X32-NEXT:    movl 24(%esp,%ecx), %ecx
; X32-NEXT:    movl %ecx, 8(%eax)
; X32-NEXT:    movl %edi, 12(%eax)
; X32-NEXT:    movl %edx, (%eax)
; X32-NEXT:    movl %esi, 4(%eax)
; X32-NEXT:    addl $32, %esp
; X32-NEXT:    popl %esi
; X32-NEXT:    popl %edi
; X32-NEXT:    popl %ebx
; X32-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %byteOff = load i128, ptr %byteOff.ptr, align 1
  %bitOff = shl i128 %byteOff, 3
  %res = shl i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}
define void @ashr_16bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-NO-BMI2-NO-SHLD-LABEL: ashr_16bytes:
; X64-NO-BMI2-NO-SHLD:       # %bb.0:
; X64-NO-BMI2-NO-SHLD-NEXT:    movq (%rdi), %r8
; X64-NO-BMI2-NO-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-NO-BMI2-NO-SHLD-NEXT:    movzbl (%rsi), %eax
; X64-NO-BMI2-NO-SHLD-NEXT:    shlb $3, %al
; X64-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X64-NO-BMI2-NO-SHLD-NEXT:    shrq %cl, %r8
; X64-NO-BMI2-NO-SHLD-NEXT:    leaq (%rdi,%rdi), %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    notb %cl
; X64-NO-BMI2-NO-SHLD-NEXT:    shlq %cl, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    orq %r8, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    movq %rdi, %r8
; X64-NO-BMI2-NO-SHLD-NEXT:    movl %eax, %ecx
; X64-NO-BMI2-NO-SHLD-NEXT:    sarq %cl, %r8
; X64-NO-BMI2-NO-SHLD-NEXT:    sarq $63, %rdi
; X64-NO-BMI2-NO-SHLD-NEXT:    testb $64, %al
; X64-NO-BMI2-NO-SHLD-NEXT:    cmovneq %r8, %rsi
; X64-NO-BMI2-NO-SHLD-NEXT:    cmoveq %r8, %rdi
; X64-NO-BMI2-NO-SHLD-NEXT:    movq %rdi, 8(%rdx)
; X64-NO-BMI2-NO-SHLD-NEXT:    movq %rsi, (%rdx)
; X64-NO-BMI2-NO-SHLD-NEXT:    retq
;
; X64-NO-BMI2-HAVE-SHLD-LABEL: ashr_16bytes:
; X64-NO-BMI2-HAVE-SHLD:       # %bb.0:
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq (%rdi), %rax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-NO-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rdi, %rsi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    sarq %cl, %rsi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    shrdq %cl, %rdi, %rax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    sarq $63, %rdi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    testb $64, %cl
; X64-NO-BMI2-HAVE-SHLD-NEXT:    cmovneq %rsi, %rax
; X64-NO-BMI2-HAVE-SHLD-NEXT:    cmoveq %rsi, %rdi
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rdi, 8(%rdx)
; X64-NO-BMI2-HAVE-SHLD-NEXT:    movq %rax, (%rdx)
; X64-NO-BMI2-HAVE-SHLD-NEXT:    retq
;
; X64-HAVE-BMI2-NO-SHLD-LABEL: ashr_16bytes:
; X64-HAVE-BMI2-NO-SHLD:       # %bb.0:
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq 8(%rdi), %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shlb $3, %cl
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shrxq %rcx, (%rdi), %rsi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movl %ecx, %edi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    notb %dil
; X64-HAVE-BMI2-NO-SHLD-NEXT:    leaq (%rax,%rax), %r8
; X64-HAVE-BMI2-NO-SHLD-NEXT:    shlxq %rdi, %r8, %rdi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    orq %rsi, %rdi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    sarxq %rcx, %rax, %rsi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    sarq $63, %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    testb $64, %cl
; X64-HAVE-BMI2-NO-SHLD-NEXT:    cmovneq %rsi, %rdi
; X64-HAVE-BMI2-NO-SHLD-NEXT:    cmoveq %rsi, %rax
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq %rax, 8(%rdx)
; X64-HAVE-BMI2-NO-SHLD-NEXT:    movq %rdi, (%rdx)
; X64-HAVE-BMI2-NO-SHLD-NEXT:    retq
;
; X64-HAVE-BMI2-HAVE-SHLD-LABEL: ashr_16bytes:
; X64-HAVE-BMI2-HAVE-SHLD:       # %bb.0:
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq (%rdi), %rax
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq 8(%rdi), %rdi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movzbl (%rsi), %ecx
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    shlb $3, %cl
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    shrdq %cl, %rdi, %rax
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    sarxq %rcx, %rdi, %rsi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    sarq $63, %rdi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    testb $64, %cl
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    cmovneq %rsi, %rax
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    cmoveq %rsi, %rdi
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq %rdi, 8(%rdx)
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    movq %rax, (%rdx)
; X64-HAVE-BMI2-HAVE-SHLD-NEXT:    retq
;
; X32-LABEL: ashr_16bytes:
; X32:       # %bb.0:
; X32-NEXT:    pushl %ebx
; X32-NEXT:    pushl %edi
; X32-NEXT:    pushl %esi
; X32-NEXT:    subl $32, %esp
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NEXT:    movl (%edx), %esi
; X32-NEXT:    movl 4(%edx), %edi
; X32-NEXT:    movl 8(%edx), %ebx
; X32-NEXT:    movl 12(%edx), %edx
; X32-NEXT:    movzbl (%ecx), %ecx
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %esi, (%esp)
; X32-NEXT:    sarl $31, %edx
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    andl $15, %ecx
; X32-NEXT:    movl (%esp,%ecx), %edx
; X32-NEXT:    movl 4(%esp,%ecx), %esi
; X32-NEXT:    movl 12(%esp,%ecx), %edi
; X32-NEXT:    movl 8(%esp,%ecx), %ecx
; X32-NEXT:    movl %ecx, 8(%eax)
; X32-NEXT:    movl %edi, 12(%eax)
; X32-NEXT:    movl %edx, (%eax)
; X32-NEXT:    movl %esi, 4(%eax)
; X32-NEXT:    addl $32, %esp
; X32-NEXT:    popl %esi
; X32-NEXT:    popl %edi
; X32-NEXT:    popl %ebx
; X32-NEXT:    retl
  %src = load i128, ptr %src.ptr, align 1
  %byteOff = load i128, ptr %byteOff.ptr, align 1
  %bitOff = shl i128 %byteOff, 3
  %res = ashr i128 %src, %bitOff
  store i128 %res, ptr %dst, align 1
  ret void
}

define void @lshr_32bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-LABEL: lshr_32bytes:
; X64:       # %bb.0:
; X64-NEXT:    movq (%rdi), %rax
; X64-NEXT:    movq 8(%rdi), %rcx
; X64-NEXT:    movq 16(%rdi), %r8
; X64-NEXT:    movq 24(%rdi), %rdi
; X64-NEXT:    movzbl (%rsi), %esi
; X64-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq $0, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq $0, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq $0, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq $0, -{{[0-9]+}}(%rsp)
; X64-NEXT:    andl $31, %esi
; X64-NEXT:    movq -64(%rsp,%rsi), %rax
; X64-NEXT:    movq -56(%rsp,%rsi), %rcx
; X64-NEXT:    movq -40(%rsp,%rsi), %rdi
; X64-NEXT:    movq -48(%rsp,%rsi), %rsi
; X64-NEXT:    movq %rsi, 16(%rdx)
; X64-NEXT:    movq %rdi, 24(%rdx)
; X64-NEXT:    movq %rax, (%rdx)
; X64-NEXT:    movq %rcx, 8(%rdx)
; X64-NEXT:    retq
;
; X32-LABEL: lshr_32bytes:
; X32:       # %bb.0:
; X32-NEXT:    pushl %ebp
; X32-NEXT:    pushl %ebx
; X32-NEXT:    pushl %edi
; X32-NEXT:    pushl %esi
; X32-NEXT:    subl $72, %esp
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl (%eax), %ecx
; X32-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X32-NEXT:    movl 4(%eax), %ecx
; X32-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X32-NEXT:    movl 8(%eax), %esi
; X32-NEXT:    movl 12(%eax), %edi
; X32-NEXT:    movl 16(%eax), %ebx
; X32-NEXT:    movl 20(%eax), %ebp
; X32-NEXT:    movl 24(%eax), %edx
; X32-NEXT:    movl 28(%eax), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movzbl (%eax), %eax
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    andl $31, %eax
; X32-NEXT:    movl 8(%esp,%eax), %ecx
; X32-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X32-NEXT:    movl 12(%esp,%eax), %ecx
; X32-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X32-NEXT:    movl 20(%esp,%eax), %esi
; X32-NEXT:    movl 16(%esp,%eax), %edi
; X32-NEXT:    movl 28(%esp,%eax), %ebx
; X32-NEXT:    movl 24(%esp,%eax), %ebp
; X32-NEXT:    movl 36(%esp,%eax), %edx
; X32-NEXT:    movl 32(%esp,%eax), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl %ecx, 24(%eax)
; X32-NEXT:    movl %edx, 28(%eax)
; X32-NEXT:    movl %ebp, 16(%eax)
; X32-NEXT:    movl %ebx, 20(%eax)
; X32-NEXT:    movl %edi, 8(%eax)
; X32-NEXT:    movl %esi, 12(%eax)
; X32-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, (%eax)
; X32-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, 4(%eax)
; X32-NEXT:    addl $72, %esp
; X32-NEXT:    popl %esi
; X32-NEXT:    popl %edi
; X32-NEXT:    popl %ebx
; X32-NEXT:    popl %ebp
; X32-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %byteOff = load i256, ptr %byteOff.ptr, align 1
  %bitOff = shl i256 %byteOff, 3
  %res = lshr i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}
define void @shl_32bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-LABEL: shl_32bytes:
; X64:       # %bb.0:
; X64-NEXT:    movq (%rdi), %rax
; X64-NEXT:    movq 8(%rdi), %rcx
; X64-NEXT:    movq 16(%rdi), %r8
; X64-NEXT:    movq 24(%rdi), %rdi
; X64-NEXT:    movzbl (%rsi), %esi
; X64-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq $0, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq $0, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq $0, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq $0, -{{[0-9]+}}(%rsp)
; X64-NEXT:    andb $31, %sil
; X64-NEXT:    negb %sil
; X64-NEXT:    movsbq %sil, %rax
; X64-NEXT:    movq -32(%rsp,%rax), %rcx
; X64-NEXT:    movq -24(%rsp,%rax), %rsi
; X64-NEXT:    movq -8(%rsp,%rax), %rdi
; X64-NEXT:    movq -16(%rsp,%rax), %rax
; X64-NEXT:    movq %rax, 16(%rdx)
; X64-NEXT:    movq %rdi, 24(%rdx)
; X64-NEXT:    movq %rcx, (%rdx)
; X64-NEXT:    movq %rsi, 8(%rdx)
; X64-NEXT:    retq
;
; X32-LABEL: shl_32bytes:
; X32:       # %bb.0:
; X32-NEXT:    pushl %ebp
; X32-NEXT:    pushl %ebx
; X32-NEXT:    pushl %edi
; X32-NEXT:    pushl %esi
; X32-NEXT:    subl $72, %esp
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X32-NEXT:    movl (%edx), %ecx
; X32-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X32-NEXT:    movl 4(%edx), %ecx
; X32-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X32-NEXT:    movl 8(%edx), %edi
; X32-NEXT:    movl 12(%edx), %ebx
; X32-NEXT:    movl 16(%edx), %ebp
; X32-NEXT:    movzbl (%eax), %eax
; X32-NEXT:    movl 20(%edx), %esi
; X32-NEXT:    movl 24(%edx), %ecx
; X32-NEXT:    movl 28(%edx), %edx
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    movl $0, {{[0-9]+}}(%esp)
; X32-NEXT:    andb $31, %al
; X32-NEXT:    negb %al
; X32-NEXT:    movsbl %al, %eax
; X32-NEXT:    movl 40(%esp,%eax), %ecx
; X32-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X32-NEXT:    movl 44(%esp,%eax), %ecx
; X32-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X32-NEXT:    movl 52(%esp,%eax), %esi
; X32-NEXT:    movl 48(%esp,%eax), %edi
; X32-NEXT:    movl 60(%esp,%eax), %ebx
; X32-NEXT:    movl 56(%esp,%eax), %ebp
; X32-NEXT:    movl 68(%esp,%eax), %edx
; X32-NEXT:    movl 64(%esp,%eax), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl %ecx, 24(%eax)
; X32-NEXT:    movl %edx, 28(%eax)
; X32-NEXT:    movl %ebp, 16(%eax)
; X32-NEXT:    movl %ebx, 20(%eax)
; X32-NEXT:    movl %edi, 8(%eax)
; X32-NEXT:    movl %esi, 12(%eax)
; X32-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, (%eax)
; X32-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, 4(%eax)
; X32-NEXT:    addl $72, %esp
; X32-NEXT:    popl %esi
; X32-NEXT:    popl %edi
; X32-NEXT:    popl %ebx
; X32-NEXT:    popl %ebp
; X32-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %byteOff = load i256, ptr %byteOff.ptr, align 1
  %bitOff = shl i256 %byteOff, 3
  %res = shl i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}
define void @ashr_32bytes(ptr %src.ptr, ptr %byteOff.ptr, ptr %dst) nounwind {
; X64-LABEL: ashr_32bytes:
; X64:       # %bb.0:
; X64-NEXT:    movq (%rdi), %rax
; X64-NEXT:    movq 8(%rdi), %rcx
; X64-NEXT:    movq 16(%rdi), %r8
; X64-NEXT:    movq 24(%rdi), %rdi
; X64-NEXT:    movzbl (%rsi), %esi
; X64-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %r8, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rcx, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; X64-NEXT:    sarq $63, %rdi
; X64-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NEXT:    movq %rdi, -{{[0-9]+}}(%rsp)
; X64-NEXT:    andl $31, %esi
; X64-NEXT:    movq -64(%rsp,%rsi), %rax
; X64-NEXT:    movq -56(%rsp,%rsi), %rcx
; X64-NEXT:    movq -40(%rsp,%rsi), %rdi
; X64-NEXT:    movq -48(%rsp,%rsi), %rsi
; X64-NEXT:    movq %rsi, 16(%rdx)
; X64-NEXT:    movq %rdi, 24(%rdx)
; X64-NEXT:    movq %rax, (%rdx)
; X64-NEXT:    movq %rcx, 8(%rdx)
; X64-NEXT:    retq
;
; X32-LABEL: ashr_32bytes:
; X32:       # %bb.0:
; X32-NEXT:    pushl %ebp
; X32-NEXT:    pushl %ebx
; X32-NEXT:    pushl %edi
; X32-NEXT:    pushl %esi
; X32-NEXT:    subl $72, %esp
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl (%eax), %ecx
; X32-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X32-NEXT:    movl 4(%eax), %ecx
; X32-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X32-NEXT:    movl 8(%eax), %edi
; X32-NEXT:    movl 12(%eax), %ebx
; X32-NEXT:    movl 16(%eax), %ebp
; X32-NEXT:    movl 20(%eax), %esi
; X32-NEXT:    movl 24(%eax), %edx
; X32-NEXT:    movl 28(%eax), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movzbl (%eax), %eax
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %esi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebp, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ebx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %edi, {{[0-9]+}}(%esp)
; X32-NEXT:    movl (%esp), %edx # 4-byte Reload
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %edx # 4-byte Reload
; X32-NEXT:    movl %edx, {{[0-9]+}}(%esp)
; X32-NEXT:    sarl $31, %ecx
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    movl %ecx, {{[0-9]+}}(%esp)
; X32-NEXT:    andl $31, %eax
; X32-NEXT:    movl 8(%esp,%eax), %ecx
; X32-NEXT:    movl %ecx, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X32-NEXT:    movl 12(%esp,%eax), %ecx
; X32-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X32-NEXT:    movl 20(%esp,%eax), %esi
; X32-NEXT:    movl 16(%esp,%eax), %edi
; X32-NEXT:    movl 28(%esp,%eax), %ebx
; X32-NEXT:    movl 24(%esp,%eax), %ebp
; X32-NEXT:    movl 36(%esp,%eax), %edx
; X32-NEXT:    movl 32(%esp,%eax), %ecx
; X32-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X32-NEXT:    movl %ecx, 24(%eax)
; X32-NEXT:    movl %edx, 28(%eax)
; X32-NEXT:    movl %ebp, 16(%eax)
; X32-NEXT:    movl %ebx, 20(%eax)
; X32-NEXT:    movl %edi, 8(%eax)
; X32-NEXT:    movl %esi, 12(%eax)
; X32-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, (%eax)
; X32-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X32-NEXT:    movl %ecx, 4(%eax)
; X32-NEXT:    addl $72, %esp
; X32-NEXT:    popl %esi
; X32-NEXT:    popl %edi
; X32-NEXT:    popl %ebx
; X32-NEXT:    popl %ebp
; X32-NEXT:    retl
  %src = load i256, ptr %src.ptr, align 1
  %byteOff = load i256, ptr %byteOff.ptr, align 1
  %bitOff = shl i256 %byteOff, 3
  %res = ashr i256 %src, %bitOff
  store i256 %res, ptr %dst, align 1
  ret void
}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; ALL: {{.*}}
; X32-NO-SHLD: {{.*}}
; X32-SHLD: {{.*}}
; X64-NO-SHLD: {{.*}}
; X64-SHLD: {{.*}}
