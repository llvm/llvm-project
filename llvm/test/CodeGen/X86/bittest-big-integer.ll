; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=i686--                   | FileCheck %s --check-prefixes=X86
; RUN: llc < %s -mtriple=x86_64-- -mcpu=x86-64    | FileCheck %s --check-prefixes=X64,SSE
; RUN: llc < %s -mtriple=x86_64-- -mcpu=x86-64-v2 | FileCheck %s --check-prefixes=X64,SSE
; RUN: llc < %s -mtriple=x86_64-- -mcpu=x86-64-v3 | FileCheck %s --check-prefixes=X64,AVX
; RUN: llc < %s -mtriple=x86_64-- -mcpu=x86-64-v4 | FileCheck %s --check-prefixes=X64,AVX

; bt/btc/btr/bts patterns + 'init' to set single bit value in large integers

;
; i32 bt/btc/btr/bts + init (reference)
;

define i1 @test_eq_i32(ptr %word, i32 %position) nounwind {
; X86-LABEL: test_eq_i32:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movl (%eax), %eax
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    btl %ecx, %eax
; X86-NEXT:    setae %al
; X86-NEXT:    retl
;
; X64-LABEL: test_eq_i32:
; X64:       # %bb.0:
; X64-NEXT:    movl (%rdi), %eax
; X64-NEXT:    btl %esi, %eax
; X64-NEXT:    setae %al
; X64-NEXT:    retq
  %rem = and i32 %position, 31
  %bit = shl nuw i32 1, %rem
  %ld = load i32, ptr %word
  %test = and i32 %ld, %bit
  %cmp = icmp eq i32 %test, 0
  ret i1 %cmp
}

define i1 @complement_ne_i32(ptr %word, i32 %position) nounwind {
; X86-LABEL: complement_ne_i32:
; X86:       # %bb.0:
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl (%ecx), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    btcl %eax, %esi
; X86-NEXT:    btl %eax, %edx
; X86-NEXT:    setb %al
; X86-NEXT:    movl %esi, (%ecx)
; X86-NEXT:    popl %esi
; X86-NEXT:    retl
;
; X64-LABEL: complement_ne_i32:
; X64:       # %bb.0:
; X64-NEXT:    movl (%rdi), %eax
; X64-NEXT:    movl %eax, %ecx
; X64-NEXT:    btcl %esi, %ecx
; X64-NEXT:    btl %esi, %eax
; X64-NEXT:    setb %al
; X64-NEXT:    movl %ecx, (%rdi)
; X64-NEXT:    retq
  %ofs = and i32 %position, 31
  %bit = shl nuw i32 1, %ofs
  %ld = load i32, ptr %word
  %test = and i32 %ld, %bit
  %res = xor i32 %ld, %bit
  %cmp = icmp ne i32 %test, 0
  store i32 %res, ptr %word
  ret i1 %cmp
}

define i1 @reset_eq_i32(ptr %word, i32 %position) nounwind {
; X86-LABEL: reset_eq_i32:
; X86:       # %bb.0:
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl (%ecx), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    btrl %eax, %esi
; X86-NEXT:    btl %eax, %edx
; X86-NEXT:    setae %al
; X86-NEXT:    movl %esi, (%ecx)
; X86-NEXT:    popl %esi
; X86-NEXT:    retl
;
; X64-LABEL: reset_eq_i32:
; X64:       # %bb.0:
; X64-NEXT:    movl (%rdi), %eax
; X64-NEXT:    movl %eax, %ecx
; X64-NEXT:    btrl %esi, %ecx
; X64-NEXT:    btl %esi, %eax
; X64-NEXT:    setae %al
; X64-NEXT:    movl %ecx, (%rdi)
; X64-NEXT:    retq
  %ofs = and i32 %position, 31
  %bit = shl nuw i32 1, %ofs
  %mask = xor i32 %bit, -1
  %ld = load i32, ptr %word
  %test = and i32 %ld, %bit
  %res = and i32 %ld, %mask
  %cmp = icmp eq i32 %test, 0
  store i32 %res, ptr %word
  ret i1 %cmp
}

define i1 @set_ne_i32(ptr %word, i32 %position) nounwind {
; X86-LABEL: set_ne_i32:
; X86:       # %bb.0:
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl (%ecx), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    btsl %eax, %esi
; X86-NEXT:    btl %eax, %edx
; X86-NEXT:    setb %al
; X86-NEXT:    movl %esi, (%ecx)
; X86-NEXT:    popl %esi
; X86-NEXT:    retl
;
; X64-LABEL: set_ne_i32:
; X64:       # %bb.0:
; X64-NEXT:    movl (%rdi), %eax
; X64-NEXT:    movl %eax, %ecx
; X64-NEXT:    btsl %esi, %ecx
; X64-NEXT:    btl %esi, %eax
; X64-NEXT:    setb %al
; X64-NEXT:    movl %ecx, (%rdi)
; X64-NEXT:    retq
  %ofs = and i32 %position, 31
  %bit = shl nuw i32 1, %ofs
  %ld = load i32, ptr %word
  %test = and i32 %ld, %bit
  %res = or i32 %ld, %bit
  %cmp = icmp ne i32 %test, 0
  store i32 %res, ptr %word
  ret i1 %cmp
}

define i1 @init_eq_i32(ptr %word, i32 %position, i1 zeroext %value) nounwind {
; X86-LABEL: init_eq_i32:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    shll %cl, %eax
; X86-NEXT:    movl (%edx), %esi
; X86-NEXT:    movl %esi, %edi
; X86-NEXT:    btrl %ecx, %edi
; X86-NEXT:    orl %eax, %edi
; X86-NEXT:    btl %ecx, %esi
; X86-NEXT:    setae %al
; X86-NEXT:    movl %edi, (%edx)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; SSE-LABEL: init_eq_i32:
; SSE:       # %bb.0:
; SSE-NEXT:    movl %esi, %ecx
; SSE-NEXT:    shll %cl, %edx
; SSE-NEXT:    movl (%rdi), %eax
; SSE-NEXT:    movl %eax, %esi
; SSE-NEXT:    btrl %ecx, %esi
; SSE-NEXT:    orl %edx, %esi
; SSE-NEXT:    btl %ecx, %eax
; SSE-NEXT:    setae %al
; SSE-NEXT:    movl %esi, (%rdi)
; SSE-NEXT:    retq
;
; AVX-LABEL: init_eq_i32:
; AVX:       # %bb.0:
; AVX-NEXT:    shlxl %esi, %edx, %eax
; AVX-NEXT:    movl (%rdi), %ecx
; AVX-NEXT:    movl %ecx, %edx
; AVX-NEXT:    btrl %esi, %edx
; AVX-NEXT:    orl %eax, %edx
; AVX-NEXT:    btl %esi, %ecx
; AVX-NEXT:    setae %al
; AVX-NEXT:    movl %edx, (%rdi)
; AVX-NEXT:    retq
  %ofs = and i32 %position, 31
  %bit = shl nuw i32 1, %ofs
  %mask = xor i32 %bit, -1
  %val0 = zext i1 %value to i32
  %val = shl nuw i32 %val0, %ofs
  %ld = load i32, ptr %word
  %test = and i32 %ld, %bit
  %res0 = and i32 %ld, %mask
  %res = or i32 %res0, %val
  %cmp = icmp eq i32 %test, 0
  store i32 %res, ptr %word
  ret i1 %cmp
}

;
; i64 bt/btc/btr/bts + init
;

define i1 @test_ne_i64(ptr %word, i32 %position) nounwind {
; X86-LABEL: test_ne_i64:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %ecx, %edx
; X86-NEXT:    andl $32, %edx
; X86-NEXT:    shrl $3, %edx
; X86-NEXT:    movl (%eax,%edx), %eax
; X86-NEXT:    btl %ecx, %eax
; X86-NEXT:    setb %al
; X86-NEXT:    retl
;
; X64-LABEL: test_ne_i64:
; X64:       # %bb.0:
; X64-NEXT:    # kill: def $esi killed $esi def $rsi
; X64-NEXT:    movq (%rdi), %rax
; X64-NEXT:    btq %rsi, %rax
; X64-NEXT:    setb %al
; X64-NEXT:    retq
  %rem = and i32 %position, 63
  %ofs = zext nneg i32 %rem to i64
  %bit = shl nuw i64 1, %ofs
  %ld = load i64, ptr %word
  %test = and i64 %ld, %bit
  %cmp = icmp ne i64 %test, 0
  ret i1 %cmp
}

define i1 @complement_ne_i64(ptr %word, i32 %position) nounwind {
; X86-LABEL: complement_ne_i64:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    andl $32, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setb %al
; X86-NEXT:    btcl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: complement_ne_i64:
; X64:       # %bb.0:
; X64-NEXT:    # kill: def $esi killed $esi def $rsi
; X64-NEXT:    movq (%rdi), %rax
; X64-NEXT:    movq %rax, %rcx
; X64-NEXT:    btcq %rsi, %rcx
; X64-NEXT:    btq %rsi, %rax
; X64-NEXT:    setb %al
; X64-NEXT:    movq %rcx, (%rdi)
; X64-NEXT:    retq
  %rem = and i32 %position, 63
  %ofs = zext nneg i32 %rem to i64
  %bit = shl nuw i64 1, %ofs
  %ld = load i64, ptr %word
  %test = and i64 %ld, %bit
  %res = xor i64 %ld, %bit
  %cmp = icmp ne i64 %test, 0
  store i64 %res, ptr %word
  ret i1 %cmp
}

define i1 @reset_eq_i64(ptr %word, i32 %position) nounwind {
; X86-LABEL: reset_eq_i64:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    andl $32, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setae %al
; X86-NEXT:    btrl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: reset_eq_i64:
; X64:       # %bb.0:
; X64-NEXT:    # kill: def $esi killed $esi def $rsi
; X64-NEXT:    movq (%rdi), %rax
; X64-NEXT:    movq %rax, %rcx
; X64-NEXT:    btrq %rsi, %rcx
; X64-NEXT:    btq %rsi, %rax
; X64-NEXT:    setae %al
; X64-NEXT:    movq %rcx, (%rdi)
; X64-NEXT:    retq
  %rem = and i32 %position, 63
  %ofs = zext nneg i32 %rem to i64
  %bit = shl nuw i64 1, %ofs
  %mask = xor i64 %bit, -1
  %ld = load i64, ptr %word
  %test = and i64 %ld, %bit
  %res = and i64 %ld, %mask
  %cmp = icmp eq i64 %test, 0
  store i64 %res, ptr %word
  ret i1 %cmp
}

define i1 @set_ne_i64(ptr %word, i32 %position) nounwind {
; X86-LABEL: set_ne_i64:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    andl $32, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setb %al
; X86-NEXT:    btsl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: set_ne_i64:
; X64:       # %bb.0:
; X64-NEXT:    # kill: def $esi killed $esi def $rsi
; X64-NEXT:    movq (%rdi), %rax
; X64-NEXT:    movq %rax, %rcx
; X64-NEXT:    btsq %rsi, %rcx
; X64-NEXT:    btq %rsi, %rax
; X64-NEXT:    setb %al
; X64-NEXT:    movq %rcx, (%rdi)
; X64-NEXT:    retq
  %rem = and i32 %position, 63
  %ofs = zext nneg i32 %rem to i64
  %bit = shl nuw i64 1, %ofs
  %ld = load i64, ptr %word
  %test = and i64 %ld, %bit
  %res = or i64 %ld, %bit
  %cmp = icmp ne i64 %test, 0
  store i64 %res, ptr %word
  ret i1 %cmp
}

define i1 @init_eq_i64(ptr %word, i32 %position, i1 zeroext %value) nounwind {
; X86-LABEL: init_eq_i64:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebx
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %ecx, %esi
; X86-NEXT:    andl $32, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    movl (%edx,%esi), %edi
; X86-NEXT:    btl %ecx, %edi
; X86-NEXT:    setae %al
; X86-NEXT:    btrl %ecx, %edi
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %ebx
; X86-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NEXT:    shll %cl, %ebx
; X86-NEXT:    orl %edi, %ebx
; X86-NEXT:    movl %ebx, (%edx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    popl %ebx
; X86-NEXT:    retl
;
; SSE-LABEL: init_eq_i64:
; SSE:       # %bb.0:
; SSE-NEXT:    movl %esi, %ecx
; SSE-NEXT:    movl %edx, %eax
; SSE-NEXT:    shlq %cl, %rax
; SSE-NEXT:    movq (%rdi), %rdx
; SSE-NEXT:    movq %rdx, %rsi
; SSE-NEXT:    btrq %rcx, %rsi
; SSE-NEXT:    orq %rax, %rsi
; SSE-NEXT:    btq %rcx, %rdx
; SSE-NEXT:    setae %al
; SSE-NEXT:    movq %rsi, (%rdi)
; SSE-NEXT:    retq
;
; AVX-LABEL: init_eq_i64:
; AVX:       # %bb.0:
; AVX-NEXT:    # kill: def $esi killed $esi def $rsi
; AVX-NEXT:    movl %edx, %eax
; AVX-NEXT:    shlxq %rsi, %rax, %rax
; AVX-NEXT:    movq (%rdi), %rcx
; AVX-NEXT:    movq %rcx, %rdx
; AVX-NEXT:    btrq %rsi, %rdx
; AVX-NEXT:    orq %rax, %rdx
; AVX-NEXT:    btq %rsi, %rcx
; AVX-NEXT:    setae %al
; AVX-NEXT:    movq %rdx, (%rdi)
; AVX-NEXT:    retq
  %rem = and i32 %position, 63
  %ofs = zext nneg i32 %rem to i64
  %bit = shl nuw i64 1, %ofs
  %mask = xor i64 %bit, -1
  %val0 = zext i1 %value to i64
  %val = shl nuw i64 %val0, %ofs
  %ld = load i64, ptr %word
  %test = and i64 %ld, %bit
  %res0 = and i64 %ld, %mask
  %res = or i64 %res0, %val
  %cmp = icmp eq i64 %test, 0
  store i64 %res, ptr %word
  ret i1 %cmp
}

;
; i128
;

define i1 @test_ne_i128(ptr %word, i32 %position) nounwind {
; X86-LABEL: test_ne_i128:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %ecx, %edx
; X86-NEXT:    andl $96, %edx
; X86-NEXT:    shrl $3, %edx
; X86-NEXT:    movl (%eax,%edx), %eax
; X86-NEXT:    btl %ecx, %eax
; X86-NEXT:    setb %al
; X86-NEXT:    retl
;
; X64-LABEL: test_ne_i128:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %eax
; X64-NEXT:    andl $96, %eax
; X64-NEXT:    shrl $3, %eax
; X64-NEXT:    movl (%rdi,%rax), %eax
; X64-NEXT:    btl %esi, %eax
; X64-NEXT:    setb %al
; X64-NEXT:    retq
  %rem = and i32 %position, 127
  %ofs = zext nneg i32 %rem to i128
  %bit = shl nuw i128 1, %ofs
  %ld = load i128, ptr %word
  %test = and i128 %ld, %bit
  %cmp = icmp ne i128 %test, 0
  ret i1 %cmp
}

define i1 @complement_ne_i128(ptr %word, i32 %position) nounwind {
; X86-LABEL: complement_ne_i128:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    andl $96, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setb %al
; X86-NEXT:    btcl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: complement_ne_i128:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %ecx
; X64-NEXT:    andl $96, %ecx
; X64-NEXT:    shrl $3, %ecx
; X64-NEXT:    movl (%rdi,%rcx), %edx
; X64-NEXT:    btl %esi, %edx
; X64-NEXT:    setb %al
; X64-NEXT:    btcl %esi, %edx
; X64-NEXT:    movl %edx, (%rdi,%rcx)
; X64-NEXT:    retq
  %rem = and i32 %position, 127
  %ofs = zext nneg i32 %rem to i128
  %bit = shl nuw i128 1, %ofs
  %ld = load i128, ptr %word
  %test = and i128 %ld, %bit
  %res = xor i128 %ld, %bit
  %cmp = icmp ne i128 %test, 0
  store i128 %res, ptr %word
  ret i1 %cmp
}

define i1 @reset_eq_i128(ptr %word, i32 %position) nounwind {
; X86-LABEL: reset_eq_i128:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    andl $96, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setae %al
; X86-NEXT:    btrl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: reset_eq_i128:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %ecx
; X64-NEXT:    andl $96, %ecx
; X64-NEXT:    shrl $3, %ecx
; X64-NEXT:    movl (%rdi,%rcx), %edx
; X64-NEXT:    btl %esi, %edx
; X64-NEXT:    setae %al
; X64-NEXT:    btrl %esi, %edx
; X64-NEXT:    movl %edx, (%rdi,%rcx)
; X64-NEXT:    retq
  %rem = and i32 %position, 127
  %ofs = zext nneg i32 %rem to i128
  %bit = shl nuw i128 1, %ofs
  %mask = xor i128 %bit, -1
  %ld = load i128, ptr %word
  %test = and i128 %ld, %bit
  %res = and i128 %ld, %mask
  %cmp = icmp eq i128 %test, 0
  store i128 %res, ptr %word
  ret i1 %cmp
}

define i1 @set_ne_i128(ptr %word, i32 %position) nounwind {
; X86-LABEL: set_ne_i128:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    andl $96, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setb %al
; X86-NEXT:    btsl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: set_ne_i128:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %ecx
; X64-NEXT:    andl $96, %ecx
; X64-NEXT:    shrl $3, %ecx
; X64-NEXT:    movl (%rdi,%rcx), %edx
; X64-NEXT:    btl %esi, %edx
; X64-NEXT:    setb %al
; X64-NEXT:    btsl %esi, %edx
; X64-NEXT:    movl %edx, (%rdi,%rcx)
; X64-NEXT:    retq
  %rem = and i32 %position, 127
  %ofs = zext nneg i32 %rem to i128
  %bit = shl nuw i128 1, %ofs
  %ld = load i128, ptr %word
  %test = and i128 %ld, %bit
  %res = or i128 %ld, %bit
  %cmp = icmp ne i128 %test, 0
  store i128 %res, ptr %word
  ret i1 %cmp
}

define i1 @init_eq_i128(ptr %word, i32 %position, i1 zeroext %value) nounwind {
; X86-LABEL: init_eq_i128:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebx
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %ecx, %esi
; X86-NEXT:    andl $96, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    movl (%edx,%esi), %edi
; X86-NEXT:    btl %ecx, %edi
; X86-NEXT:    setae %al
; X86-NEXT:    btrl %ecx, %edi
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %ebx
; X86-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NEXT:    shll %cl, %ebx
; X86-NEXT:    orl %edi, %ebx
; X86-NEXT:    movl %ebx, (%edx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    popl %ebx
; X86-NEXT:    retl
;
; SSE-LABEL: init_eq_i128:
; SSE:       # %bb.0:
; SSE-NEXT:    movl %esi, %ecx
; SSE-NEXT:    andl $96, %esi
; SSE-NEXT:    shrl $3, %esi
; SSE-NEXT:    movl (%rdi,%rsi), %r8d
; SSE-NEXT:    btl %ecx, %r8d
; SSE-NEXT:    setae %al
; SSE-NEXT:    shll %cl, %edx
; SSE-NEXT:    btrl %ecx, %r8d
; SSE-NEXT:    orl %r8d, %edx
; SSE-NEXT:    movl %edx, (%rdi,%rsi)
; SSE-NEXT:    retq
;
; AVX-LABEL: init_eq_i128:
; AVX:       # %bb.0:
; AVX-NEXT:    movl %esi, %ecx
; AVX-NEXT:    andl $96, %ecx
; AVX-NEXT:    shrl $3, %ecx
; AVX-NEXT:    movl (%rdi,%rcx), %r8d
; AVX-NEXT:    btl %esi, %r8d
; AVX-NEXT:    setae %al
; AVX-NEXT:    btrl %esi, %r8d
; AVX-NEXT:    shlxl %esi, %edx, %edx
; AVX-NEXT:    orl %r8d, %edx
; AVX-NEXT:    movl %edx, (%rdi,%rcx)
; AVX-NEXT:    retq
  %rem = and i32 %position, 127
  %ofs = zext nneg i32 %rem to i128
  %bit = shl nuw i128 1, %ofs
  %mask = xor i128 %bit, -1
  %val0 = zext i1 %value to i128
  %val = shl nuw i128 %val0, %ofs
  %ld = load i128, ptr %word
  %test = and i128 %ld, %bit
  %res0 = and i128 %ld, %mask
  %res = or i128 %res0, %val
  %cmp = icmp eq i128 %test, 0
  store i128 %res, ptr %word
  ret i1 %cmp
}

; i512

define i1 @test_ne_i512(ptr %word, i32 %position) nounwind {
; X86-LABEL: test_ne_i512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %ecx, %edx
; X86-NEXT:    shrl $3, %edx
; X86-NEXT:    andl $60, %edx
; X86-NEXT:    movl (%eax,%edx), %eax
; X86-NEXT:    btl %ecx, %eax
; X86-NEXT:    setb %al
; X86-NEXT:    retl
;
; X64-LABEL: test_ne_i512:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %eax
; X64-NEXT:    shrl $3, %eax
; X64-NEXT:    andl $60, %eax
; X64-NEXT:    movl (%rdi,%rax), %eax
; X64-NEXT:    btl %esi, %eax
; X64-NEXT:    setb %al
; X64-NEXT:    retq
  %rem = and i32 %position, 511
  %ofs = zext nneg i32 %rem to i512
  %bit = shl nuw i512 1, %ofs
  %ld = load i512, ptr %word
  %test = and i512 %ld, %bit
  %cmp = icmp ne i512 %test, 0
  ret i1 %cmp
}

define i1 @complement_ne_i512(ptr %word, i32 %position) nounwind {
; X86-LABEL: complement_ne_i512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    andl $60, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setb %al
; X86-NEXT:    btcl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: complement_ne_i512:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %ecx
; X64-NEXT:    shrl $3, %ecx
; X64-NEXT:    andl $60, %ecx
; X64-NEXT:    movl (%rdi,%rcx), %edx
; X64-NEXT:    btl %esi, %edx
; X64-NEXT:    setb %al
; X64-NEXT:    btcl %esi, %edx
; X64-NEXT:    movl %edx, (%rdi,%rcx)
; X64-NEXT:    retq
  %rem = and i32 %position, 511
  %ofs = zext nneg i32 %rem to i512
  %bit = shl nuw i512 1, %ofs
  %ld = load i512, ptr %word
  %test = and i512 %ld, %bit
  %res = xor i512 %ld, %bit
  %cmp = icmp ne i512 %test, 0
  store i512 %res, ptr %word
  ret i1 %cmp
}

define i1 @reset_eq_i512(ptr %word, i32 %position) nounwind {
; X86-LABEL: reset_eq_i512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    andl $60, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setae %al
; X86-NEXT:    btrl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: reset_eq_i512:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %ecx
; X64-NEXT:    shrl $3, %ecx
; X64-NEXT:    andl $60, %ecx
; X64-NEXT:    movl (%rdi,%rcx), %edx
; X64-NEXT:    btl %esi, %edx
; X64-NEXT:    setae %al
; X64-NEXT:    btrl %esi, %edx
; X64-NEXT:    movl %edx, (%rdi,%rcx)
; X64-NEXT:    retq
  %rem = and i32 %position, 511
  %ofs = zext nneg i32 %rem to i512
  %bit = shl nuw i512 1, %ofs
  %mask = xor i512 %bit, -1
  %ld = load i512, ptr %word
  %test = and i512 %ld, %bit
  %res = and i512 %ld, %mask
  %cmp = icmp eq i512 %test, 0
  store i512 %res, ptr %word
  ret i1 %cmp
}

define i1 @set_ne_i512(ptr %word, i32 %position) nounwind {
; X86-LABEL: set_ne_i512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl %edx, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    andl $60, %esi
; X86-NEXT:    movl (%ecx,%esi), %edi
; X86-NEXT:    btl %edx, %edi
; X86-NEXT:    setb %al
; X86-NEXT:    btsl %edx, %edi
; X86-NEXT:    movl %edi, (%ecx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    retl
;
; X64-LABEL: set_ne_i512:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %ecx
; X64-NEXT:    shrl $3, %ecx
; X64-NEXT:    andl $60, %ecx
; X64-NEXT:    movl (%rdi,%rcx), %edx
; X64-NEXT:    btl %esi, %edx
; X64-NEXT:    setb %al
; X64-NEXT:    btsl %esi, %edx
; X64-NEXT:    movl %edx, (%rdi,%rcx)
; X64-NEXT:    retq
  %rem = and i32 %position, 511
  %ofs = zext nneg i32 %rem to i512
  %bit = shl nuw i512 1, %ofs
  %ld = load i512, ptr %word
  %test = and i512 %ld, %bit
  %res = or i512 %ld, %bit
  %cmp = icmp ne i512 %test, 0
  store i512 %res, ptr %word
  ret i1 %cmp
}

define i1 @init_eq_i512(ptr %word, i32 %position, i1 zeroext %value) nounwind {
; X86-LABEL: init_eq_i512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebx
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %ecx, %esi
; X86-NEXT:    shrl $3, %esi
; X86-NEXT:    andl $60, %esi
; X86-NEXT:    movl (%edx,%esi), %edi
; X86-NEXT:    btl %ecx, %edi
; X86-NEXT:    setae %al
; X86-NEXT:    btrl %ecx, %edi
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %ebx
; X86-NEXT:    # kill: def $cl killed $cl killed $ecx
; X86-NEXT:    shll %cl, %ebx
; X86-NEXT:    orl %edi, %ebx
; X86-NEXT:    movl %ebx, (%edx,%esi)
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    popl %ebx
; X86-NEXT:    retl
;
; SSE-LABEL: init_eq_i512:
; SSE:       # %bb.0:
; SSE-NEXT:    movl %esi, %ecx
; SSE-NEXT:    shrl $3, %esi
; SSE-NEXT:    andl $60, %esi
; SSE-NEXT:    movl (%rdi,%rsi), %r8d
; SSE-NEXT:    btl %ecx, %r8d
; SSE-NEXT:    setae %al
; SSE-NEXT:    shll %cl, %edx
; SSE-NEXT:    btrl %ecx, %r8d
; SSE-NEXT:    orl %r8d, %edx
; SSE-NEXT:    movl %edx, (%rdi,%rsi)
; SSE-NEXT:    retq
;
; AVX-LABEL: init_eq_i512:
; AVX:       # %bb.0:
; AVX-NEXT:    movl %esi, %ecx
; AVX-NEXT:    shrl $3, %ecx
; AVX-NEXT:    andl $60, %ecx
; AVX-NEXT:    movl (%rdi,%rcx), %r8d
; AVX-NEXT:    btl %esi, %r8d
; AVX-NEXT:    setae %al
; AVX-NEXT:    btrl %esi, %r8d
; AVX-NEXT:    shlxl %esi, %edx, %edx
; AVX-NEXT:    orl %r8d, %edx
; AVX-NEXT:    movl %edx, (%rdi,%rcx)
; AVX-NEXT:    retq
  %rem = and i32 %position, 511
  %ofs = zext nneg i32 %rem to i512
  %bit = shl nuw i512 1, %ofs
  %mask = xor i512 %bit, -1
  %val0 = zext i1 %value to i512
  %val = shl nuw i512 %val0, %ofs
  %ld = load i512, ptr %word
  %test = and i512 %ld, %bit
  %res0 = and i512 %ld, %mask
  %res = or i512 %res0, %val
  %cmp = icmp eq i512 %test, 0
  store i512 %res, ptr %word
  ret i1 %cmp
}

; i4096

define i1 @test_ne_i4096(ptr %word, i32 %position) nounwind {
; X86-LABEL: test_ne_i4096:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    movl %ecx, %edx
; X86-NEXT:    andl $4064, %edx # imm = 0xFE0
; X86-NEXT:    shrl $3, %edx
; X86-NEXT:    movl (%eax,%edx), %eax
; X86-NEXT:    btl %ecx, %eax
; X86-NEXT:    setb %al
; X86-NEXT:    retl
;
; X64-LABEL: test_ne_i4096:
; X64:       # %bb.0:
; X64-NEXT:    movl %esi, %eax
; X64-NEXT:    andl $4064, %eax # imm = 0xFE0
; X64-NEXT:    shrl $3, %eax
; X64-NEXT:    movl (%rdi,%rax), %eax
; X64-NEXT:    btl %esi, %eax
; X64-NEXT:    setb %al
; X64-NEXT:    retq
  %rem = and i32 %position, 4095
  %ofs = zext nneg i32 %rem to i4096
  %bit = shl nuw i4096 1, %ofs
  %ld = load i4096, ptr %word
  %test = and i4096 %ld, %bit
  %cmp = icmp ne i4096 %test, 0
  ret i1 %cmp
}
