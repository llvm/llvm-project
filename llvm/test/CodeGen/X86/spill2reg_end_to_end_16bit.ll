; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc %s -o - -mtriple=x86_64-unknown-linux -enable-spill2reg -mattr=+sse4.1 | FileCheck %s
; RUN: llc %s -o - -mtriple=x86_64-unknown-linux -enable-spill2reg -mattr=+avx | FileCheck --check-prefix=AVX %s

; End-to-end check that Spill2Reg works with 16-bit registers.

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@D0 = dso_local local_unnamed_addr global i16 0, align 4
@D1 = dso_local local_unnamed_addr global i16 0, align 4
@D2 = dso_local local_unnamed_addr global i16 0, align 4
@D3 = dso_local local_unnamed_addr global i16 0, align 4
@D4 = dso_local local_unnamed_addr global i16 0, align 4
@D5 = dso_local local_unnamed_addr global i16 0, align 4
@D6 = dso_local local_unnamed_addr global i16 0, align 4
@D7 = dso_local local_unnamed_addr global i16 0, align 4
@D8 = dso_local local_unnamed_addr global i16 0, align 4
@D9 = dso_local local_unnamed_addr global i16 0, align 4
@D10 = dso_local local_unnamed_addr global i16 0, align 4
@D11 = dso_local local_unnamed_addr global i16 0, align 4
@D12 = dso_local local_unnamed_addr global i16 0, align 4
@D13 = dso_local local_unnamed_addr global i16 0, align 4
@D14 = dso_local local_unnamed_addr global i16 0, align 4
@D15 = dso_local local_unnamed_addr global i16 0, align 4
@D16 = dso_local local_unnamed_addr global i16 0, align 4
@D17 = dso_local local_unnamed_addr global i16 0, align 4
@D18 = dso_local local_unnamed_addr global i16 0, align 4
@U0 = dso_local local_unnamed_addr global i16 0, align 4
@U1 = dso_local local_unnamed_addr global i16 0, align 4
@U2 = dso_local local_unnamed_addr global i16 0, align 4
@U3 = dso_local local_unnamed_addr global i16 0, align 4
@U4 = dso_local local_unnamed_addr global i16 0, align 4
@U5 = dso_local local_unnamed_addr global i16 0, align 4
@U6 = dso_local local_unnamed_addr global i16 0, align 4
@U7 = dso_local local_unnamed_addr global i16 0, align 4
@U8 = dso_local local_unnamed_addr global i16 0, align 4
@U9 = dso_local local_unnamed_addr global i16 0, align 4
@U10 = dso_local local_unnamed_addr global i16 0, align 4
@U11 = dso_local local_unnamed_addr global i16 0, align 4
@U12 = dso_local local_unnamed_addr global i16 0, align 4
@U13 = dso_local local_unnamed_addr global i16 0, align 4
@U14 = dso_local local_unnamed_addr global i16 0, align 4
@U15 = dso_local local_unnamed_addr global i16 0, align 4
@U16 = dso_local local_unnamed_addr global i16 0, align 4
@U17 = dso_local local_unnamed_addr global i16 0, align 4
@U18 = dso_local local_unnamed_addr global i16 0, align 4

; Function Attrs: mustprogress noinline nounwind uwtable
define dso_local void @_Z5spillv() local_unnamed_addr #0 {
; CHECK-LABEL: _Z5spillv:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    pushq %r15
; CHECK-NEXT:    .cfi_def_cfa_offset 24
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    pushq %r13
; CHECK-NEXT:    .cfi_def_cfa_offset 40
; CHECK-NEXT:    pushq %r12
; CHECK-NEXT:    .cfi_def_cfa_offset 48
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    .cfi_def_cfa_offset 56
; CHECK-NEXT:    .cfi_offset %rbx, -56
; CHECK-NEXT:    .cfi_offset %r12, -48
; CHECK-NEXT:    .cfi_offset %r13, -40
; CHECK-NEXT:    .cfi_offset %r14, -32
; CHECK-NEXT:    .cfi_offset %r15, -24
; CHECK-NEXT:    .cfi_offset %rbp, -16
; CHECK-NEXT:    movw D0(%rip), %ax
; CHECK-NEXT:    movw %ax, {{[-0-9]+}}(%r{{[sb]}}p) # 2-byte Spill
; CHECK-NEXT:    movzwl D1(%rip), %ecx
; CHECK-NEXT:    movzwl D2(%rip), %edx
; CHECK-NEXT:    movzwl D3(%rip), %esi
; CHECK-NEXT:    movzwl D4(%rip), %edi
; CHECK-NEXT:    movzwl D5(%rip), %r8d
; CHECK-NEXT:    movzwl D6(%rip), %r9d
; CHECK-NEXT:    movzwl D7(%rip), %r10d
; CHECK-NEXT:    movzwl D8(%rip), %r11d
; CHECK-NEXT:    movzwl D9(%rip), %ebx
; CHECK-NEXT:    movzwl D10(%rip), %ebp
; CHECK-NEXT:    movzwl D11(%rip), %r14d
; CHECK-NEXT:    movzwl D12(%rip), %r15d
; CHECK-NEXT:    movzwl D13(%rip), %r12d
; CHECK-NEXT:    movzwl D14(%rip), %r13d
; CHECK-NEXT:    movw D15(%rip), %ax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movw D16(%rip), %ax
; CHECK-NEXT:    movw %ax, {{[-0-9]+}}(%r{{[sb]}}p) # 2-byte Spill
; CHECK-NEXT:    movw D17(%rip), %ax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    movzwl D18(%rip), %eax
; CHECK-NEXT:    movw %ax, {{[-0-9]+}}(%r{{[sb]}}p) # 2-byte Spill
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    movzwl {{[-0-9]+}}(%r{{[sb]}}p), %eax # 2-byte Folded Reload
; CHECK-NEXT:    movw %ax, U0(%rip)
; CHECK-NEXT:    movw %cx, U1(%rip)
; CHECK-NEXT:    movw %dx, U2(%rip)
; CHECK-NEXT:    movw %si, U3(%rip)
; CHECK-NEXT:    movw %di, U4(%rip)
; CHECK-NEXT:    movw %r8w, U5(%rip)
; CHECK-NEXT:    movw %r9w, U6(%rip)
; CHECK-NEXT:    movw %r10w, U7(%rip)
; CHECK-NEXT:    movw %r11w, U8(%rip)
; CHECK-NEXT:    movw %bx, U9(%rip)
; CHECK-NEXT:    movw %bp, U10(%rip)
; CHECK-NEXT:    movw %r14w, U11(%rip)
; CHECK-NEXT:    movw %r15w, U12(%rip)
; CHECK-NEXT:    movw %r12w, U13(%rip)
; CHECK-NEXT:    movw %r13w, U14(%rip)
; CHECK-NEXT:    movd %xmm0, %eax
; CHECK-NEXT:    movw %ax, U15(%rip)
; CHECK-NEXT:    movzwl {{[-0-9]+}}(%r{{[sb]}}p), %eax # 2-byte Folded Reload
; CHECK-NEXT:    movw %ax, U16(%rip)
; CHECK-NEXT:    movd %xmm1, %eax
; CHECK-NEXT:    movw %ax, U17(%rip)
; CHECK-NEXT:    movzwl {{[-0-9]+}}(%r{{[sb]}}p), %eax # 2-byte Folded Reload
; CHECK-NEXT:    movw %ax, U18(%rip)
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    .cfi_def_cfa_offset 48
; CHECK-NEXT:    popq %r12
; CHECK-NEXT:    .cfi_def_cfa_offset 40
; CHECK-NEXT:    popq %r13
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    .cfi_def_cfa_offset 24
; CHECK-NEXT:    popq %r15
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    retq
;
; AVX-LABEL: _Z5spillv:
; AVX:       # %bb.0: # %entry
; AVX-NEXT:    pushq %rbp
; AVX-NEXT:    .cfi_def_cfa_offset 16
; AVX-NEXT:    pushq %r15
; AVX-NEXT:    .cfi_def_cfa_offset 24
; AVX-NEXT:    pushq %r14
; AVX-NEXT:    .cfi_def_cfa_offset 32
; AVX-NEXT:    pushq %r13
; AVX-NEXT:    .cfi_def_cfa_offset 40
; AVX-NEXT:    pushq %r12
; AVX-NEXT:    .cfi_def_cfa_offset 48
; AVX-NEXT:    pushq %rbx
; AVX-NEXT:    .cfi_def_cfa_offset 56
; AVX-NEXT:    .cfi_offset %rbx, -56
; AVX-NEXT:    .cfi_offset %r12, -48
; AVX-NEXT:    .cfi_offset %r13, -40
; AVX-NEXT:    .cfi_offset %r14, -32
; AVX-NEXT:    .cfi_offset %r15, -24
; AVX-NEXT:    .cfi_offset %rbp, -16
; AVX-NEXT:    movw D0(%rip), %ax
; AVX-NEXT:    movw %ax, {{[-0-9]+}}(%r{{[sb]}}p) # 2-byte Spill
; AVX-NEXT:    movzwl D1(%rip), %ecx
; AVX-NEXT:    movzwl D2(%rip), %edx
; AVX-NEXT:    movzwl D3(%rip), %esi
; AVX-NEXT:    movzwl D4(%rip), %edi
; AVX-NEXT:    movzwl D5(%rip), %r8d
; AVX-NEXT:    movzwl D6(%rip), %r9d
; AVX-NEXT:    movzwl D7(%rip), %r10d
; AVX-NEXT:    movzwl D8(%rip), %r11d
; AVX-NEXT:    movzwl D9(%rip), %ebx
; AVX-NEXT:    movzwl D10(%rip), %ebp
; AVX-NEXT:    movzwl D11(%rip), %r14d
; AVX-NEXT:    movzwl D12(%rip), %r15d
; AVX-NEXT:    movzwl D13(%rip), %r12d
; AVX-NEXT:    movzwl D14(%rip), %r13d
; AVX-NEXT:    movw D15(%rip), %ax
; AVX-NEXT:    vmovd %eax, %xmm0
; AVX-NEXT:    movw D16(%rip), %ax
; AVX-NEXT:    movw %ax, {{[-0-9]+}}(%r{{[sb]}}p) # 2-byte Spill
; AVX-NEXT:    movw D17(%rip), %ax
; AVX-NEXT:    vmovd %eax, %xmm1
; AVX-NEXT:    movzwl D18(%rip), %eax
; AVX-NEXT:    movw %ax, {{[-0-9]+}}(%r{{[sb]}}p) # 2-byte Spill
; AVX-NEXT:    #APP
; AVX-NEXT:    #NO_APP
; AVX-NEXT:    movzwl {{[-0-9]+}}(%r{{[sb]}}p), %eax # 2-byte Folded Reload
; AVX-NEXT:    movw %ax, U0(%rip)
; AVX-NEXT:    movw %cx, U1(%rip)
; AVX-NEXT:    movw %dx, U2(%rip)
; AVX-NEXT:    movw %si, U3(%rip)
; AVX-NEXT:    movw %di, U4(%rip)
; AVX-NEXT:    movw %r8w, U5(%rip)
; AVX-NEXT:    movw %r9w, U6(%rip)
; AVX-NEXT:    movw %r10w, U7(%rip)
; AVX-NEXT:    movw %r11w, U8(%rip)
; AVX-NEXT:    movw %bx, U9(%rip)
; AVX-NEXT:    movw %bp, U10(%rip)
; AVX-NEXT:    movw %r14w, U11(%rip)
; AVX-NEXT:    movw %r15w, U12(%rip)
; AVX-NEXT:    movw %r12w, U13(%rip)
; AVX-NEXT:    movw %r13w, U14(%rip)
; AVX-NEXT:    vmovd %xmm0, %eax
; AVX-NEXT:    movw %ax, U15(%rip)
; AVX-NEXT:    movzwl {{[-0-9]+}}(%r{{[sb]}}p), %eax # 2-byte Folded Reload
; AVX-NEXT:    movw %ax, U16(%rip)
; AVX-NEXT:    vmovd %xmm1, %eax
; AVX-NEXT:    movw %ax, U17(%rip)
; AVX-NEXT:    movzwl {{[-0-9]+}}(%r{{[sb]}}p), %eax # 2-byte Folded Reload
; AVX-NEXT:    movw %ax, U18(%rip)
; AVX-NEXT:    popq %rbx
; AVX-NEXT:    .cfi_def_cfa_offset 48
; AVX-NEXT:    popq %r12
; AVX-NEXT:    .cfi_def_cfa_offset 40
; AVX-NEXT:    popq %r13
; AVX-NEXT:    .cfi_def_cfa_offset 32
; AVX-NEXT:    popq %r14
; AVX-NEXT:    .cfi_def_cfa_offset 24
; AVX-NEXT:    popq %r15
; AVX-NEXT:    .cfi_def_cfa_offset 16
; AVX-NEXT:    popq %rbp
; AVX-NEXT:    .cfi_def_cfa_offset 8
; AVX-NEXT:    retq
entry:
  %0 = load i16, i16* @D0
  %1 = load i16, i16* @D1
  %2 = load i16, i16* @D2
  %3 = load i16, i16* @D3
  %4 = load i16, i16* @D4
  %5 = load i16, i16* @D5
  %6 = load i16, i16* @D6
  %7 = load i16, i16* @D7
  %8 = load i16, i16* @D8
  %9 = load i16, i16* @D9
  %10 = load i16, i16* @D10
  %11 = load i16, i16* @D11
  %12 = load i16, i16* @D12
  %13 = load i16, i16* @D13
  %14 = load i16, i16* @D14
  %15 = load i16, i16* @D15
  %16 = load i16, i16* @D16
  %17 = load i16, i16* @D17
  %18 = load i16, i16* @D18
  call void asm sideeffect "", "~{memory}"() #1
  store i16 %0, i16* @U0
  store i16 %1, i16* @U1
  store i16 %2, i16* @U2
  store i16 %3, i16* @U3
  store i16 %4, i16* @U4
  store i16 %5, i16* @U5
  store i16 %6, i16* @U6
  store i16 %7, i16* @U7
  store i16 %8, i16* @U8
  store i16 %9, i16* @U9
  store i16 %10, i16* @U10
  store i16 %11, i16* @U11
  store i16 %12, i16* @U12
  store i16 %13, i16* @U13
  store i16 %14, i16* @U14
  store i16 %15, i16* @U15
  store i16 %16, i16* @U16
  store i16 %17, i16* @U17
  store i16 %18, i16* @U18
  ret void
}

attributes #0 = { mustprogress noinline nounwind uwtable "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #1 = { nounwind }
