; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=x86_64-unknown-unknown -mattr=-bmi < %s | FileCheck %s --check-prefixes=CHECK,NOBMI
; RUN: llc -mtriple=x86_64-unknown-unknown -mattr=+bmi < %s | FileCheck %s --check-prefixes=CHECK,BMI

; Test the optimization described in issue #161630:
; (Constant XOR a) & b & ~c should compile to allow andn to be done in parallel with xor

define i64 @test_constant_xor_and_andnot(i64 %a, i64 %b, i64 %c) {
; CHECK-LABEL: test_constant_xor_and_andnot:
; CHECK:       # %bb.0:
; NOBMI-NEXT:    movq %rdx, %rax
; CHECK-NEXT:    xorq $1234, %rdi # imm = 0x4D2
; NOBMI-NEXT:    andq %rsi, %rdi
; NOBMI-NEXT:    notq %rax
; NOBMI-NEXT:    andq %rdi, %rax
; BMI-NEXT:      andnq %rsi, %rdx, %rax
; BMI-NEXT:      andq %rdi, %rax
; CHECK-NEXT:    retq
  %xor = xor i64 %a, 1234
  %and1 = and i64 %xor, %b
  %not_c = xor i64 %c, -1
  %result = and i64 %and1, %not_c
  ret i64 %result
}

define i32 @test_constant_xor_and_andnot_32(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: test_constant_xor_and_andnot_32:
; CHECK:       # %bb.0:
; NOBMI-NEXT:    movl %edx, %eax
; CHECK-NEXT:    xorl $5678, %edi # imm = 0x162E
; NOBMI-NEXT:    andl %esi, %edi
; NOBMI-NEXT:    notl %eax
; NOBMI-NEXT:    andl %edi, %eax
; BMI-NEXT:      andnl %esi, %edx, %eax
; BMI-NEXT:      andl %edi, %eax
; CHECK-NEXT:    retq
  %xor = xor i32 %a, 5678
  %and1 = and i32 %xor, %b
  %not_c = xor i32 %c, -1
  %result = and i32 %and1, %not_c
  ret i32 %result
}

; Test with different operand order
define i64 @test_constant_xor_and_andnot_swapped(i64 %a, i64 %b, i64 %c) {
; CHECK-LABEL: test_constant_xor_and_andnot_swapped:
; CHECK:       # %bb.0:
; NOBMI-NEXT:    movq %rdx, %rax
; CHECK-NEXT:    xorq $1234, %rdi # imm = 0x4D2
; NOBMI-NEXT:    andq %rsi, %rdi
; NOBMI-NEXT:    notq %rax
; NOBMI-NEXT:    andq %rdi, %rax
; BMI-NEXT:      andnq %rsi, %rdx, %rax
; BMI-NEXT:      andq %rdi, %rax
; CHECK-NEXT:    retq
  %xor = xor i64 %a, 1234
  %and1 = and i64 %b, %xor
  %not_c = xor i64 %c, -1
  %result = and i64 %and1, %not_c
  ret i64 %result
}

; Test with different operand order for the final AND
define i64 @test_constant_xor_and_andnot_final_swapped(i64 %a, i64 %b, i64 %c) {
; CHECK-LABEL: test_constant_xor_and_andnot_final_swapped:
; CHECK:       # %bb.0:
; NOBMI-NEXT:    movq %rdx, %rax
; CHECK-NEXT:    xorq $1234, %rdi # imm = 0x4D2
; NOBMI-NEXT:    andq %rsi, %rdi
; NOBMI-NEXT:    notq %rax
; NOBMI-NEXT:    andq %rdi, %rax
; BMI-NEXT:      andnq %rsi, %rdx, %rax
; BMI-NEXT:      andq %rdi, %rax
; CHECK-NEXT:    retq
  %xor = xor i64 %a, 1234
  %and1 = and i64 %xor, %b
  %not_c = xor i64 %c, -1
  %result = and i64 %not_c, %and1
  ret i64 %result
}