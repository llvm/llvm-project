; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=i686-pc-unknown -mattr=+sse2 | FileCheck %s -check-prefixes=X86
; RUN: llc < %s -mtriple=x86_64-pc-unknown -mcpu=x86-64    | FileCheck %s -check-prefixes=X64-SSE2
; RUN: llc < %s -mtriple=x86_64-pc-unknown -mcpu=x86-64-v2 | FileCheck %s -check-prefixes=X64-SSE42
; RUN: llc < %s -mtriple=x86_64-pc-unknown -mcpu=x86-64-v3 | FileCheck %s -check-prefixes=X64-AVX,X64-AVX2
; RUN: llc < %s -mtriple=x86_64-pc-unknown -mcpu=x86-64-v4 | FileCheck %s -check-prefixes=X64-AVX,X64-AVX512

; PR19059

define i32 @isint_return(double %d) nounwind {
; X86-LABEL: isint_return:
; X86:       # %bb.0:
; X86-NEXT:    movsd {{.*#+}} xmm0 = mem[0],zero
; X86-NEXT:    cvttpd2dq %xmm0, %xmm1
; X86-NEXT:    cvtdq2pd %xmm1, %xmm1
; X86-NEXT:    cmpeqsd %xmm0, %xmm1
; X86-NEXT:    movd %xmm1, %eax
; X86-NEXT:    andl $1, %eax
; X86-NEXT:    retl
;
; X64-SSE2-LABEL: isint_return:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    cvttpd2dq %xmm0, %xmm1
; X64-SSE2-NEXT:    cvtdq2pd %xmm1, %xmm1
; X64-SSE2-NEXT:    cmpeqsd %xmm0, %xmm1
; X64-SSE2-NEXT:    movq %xmm1, %rax
; X64-SSE2-NEXT:    andl $1, %eax
; X64-SSE2-NEXT:    # kill: def $eax killed $eax killed $rax
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: isint_return:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    roundsd $11, %xmm0, %xmm1
; X64-SSE42-NEXT:    cmpeqsd %xmm0, %xmm1
; X64-SSE42-NEXT:    movq %xmm1, %rax
; X64-SSE42-NEXT:    andl $1, %eax
; X64-SSE42-NEXT:    # kill: def $eax killed $eax killed $rax
; X64-SSE42-NEXT:    retq
;
; X64-AVX2-LABEL: isint_return:
; X64-AVX2:       # %bb.0:
; X64-AVX2-NEXT:    vroundsd $11, %xmm0, %xmm0, %xmm1
; X64-AVX2-NEXT:    vcmpeqsd %xmm1, %xmm0, %xmm0
; X64-AVX2-NEXT:    vmovq %xmm0, %rax
; X64-AVX2-NEXT:    andl $1, %eax
; X64-AVX2-NEXT:    # kill: def $eax killed $eax killed $rax
; X64-AVX2-NEXT:    retq
;
; X64-AVX512-LABEL: isint_return:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vroundsd $11, %xmm0, %xmm0, %xmm1
; X64-AVX512-NEXT:    vcmpeqsd %xmm1, %xmm0, %k0
; X64-AVX512-NEXT:    kmovw %k0, %eax
; X64-AVX512-NEXT:    retq
  %i = fptosi double %d to i32
  %e = sitofp i32 %i to double
  %c = fcmp oeq double %d, %e
  %z = zext i1 %c to i32
  ret i32 %z
}

define i32 @isint_float_return(float %f) nounwind {
; X86-LABEL: isint_float_return:
; X86:       # %bb.0:
; X86-NEXT:    movss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-NEXT:    cvttps2dq %xmm0, %xmm1
; X86-NEXT:    cvtdq2ps %xmm1, %xmm1
; X86-NEXT:    cmpeqss %xmm0, %xmm1
; X86-NEXT:    movd %xmm1, %eax
; X86-NEXT:    andl $1, %eax
; X86-NEXT:    retl
;
; X64-SSE2-LABEL: isint_float_return:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    cvttps2dq %xmm0, %xmm1
; X64-SSE2-NEXT:    cvtdq2ps %xmm1, %xmm1
; X64-SSE2-NEXT:    cmpeqss %xmm0, %xmm1
; X64-SSE2-NEXT:    movd %xmm1, %eax
; X64-SSE2-NEXT:    andl $1, %eax
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: isint_float_return:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    roundss $11, %xmm0, %xmm1
; X64-SSE42-NEXT:    cmpeqss %xmm0, %xmm1
; X64-SSE42-NEXT:    movd %xmm1, %eax
; X64-SSE42-NEXT:    andl $1, %eax
; X64-SSE42-NEXT:    retq
;
; X64-AVX2-LABEL: isint_float_return:
; X64-AVX2:       # %bb.0:
; X64-AVX2-NEXT:    vroundss $11, %xmm0, %xmm0, %xmm1
; X64-AVX2-NEXT:    vcmpeqss %xmm1, %xmm0, %xmm0
; X64-AVX2-NEXT:    vmovd %xmm0, %eax
; X64-AVX2-NEXT:    andl $1, %eax
; X64-AVX2-NEXT:    retq
;
; X64-AVX512-LABEL: isint_float_return:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vroundss $11, %xmm0, %xmm0, %xmm1
; X64-AVX512-NEXT:    vcmpeqss %xmm1, %xmm0, %k0
; X64-AVX512-NEXT:    kmovw %k0, %eax
; X64-AVX512-NEXT:    retq
  %i = fptosi float %f to i32
  %g = sitofp i32 %i to float
  %c = fcmp oeq float %f, %g
  %z = zext i1 %c to i32
  ret i32 %z
}

define i64 @isint64_float_return(float %f) nounwind {
; SSE2-LABEL: isint64_float_return:
; SSE2:       # %bb.0:
; SSE2-NEXT:    cvttss2si %xmm0, %rax
; SSE2-NEXT:    cvtsi2ss %rax, %xmm1
; SSE2-NEXT:    cmpeqss %xmm0, %xmm1
; SSE2-NEXT:    movd %xmm1, %eax
; SSE2-NEXT:    andl $1, %eax
; SSE2-NEXT:    retq
;
; X86-LABEL: isint64_float_return:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp
; X86-NEXT:    movl %esp, %ebp
; X86-NEXT:    andl $-8, %esp
; X86-NEXT:    subl $32, %esp
; X86-NEXT:    movss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-NEXT:    movss %xmm0, {{[0-9]+}}(%esp)
; X86-NEXT:    flds {{[0-9]+}}(%esp)
; X86-NEXT:    fnstcw {{[0-9]+}}(%esp)
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    orl $3072, %eax # imm = 0xC00
; X86-NEXT:    movw %ax, {{[0-9]+}}(%esp)
; X86-NEXT:    fldcw {{[0-9]+}}(%esp)
; X86-NEXT:    fistpll {{[0-9]+}}(%esp)
; X86-NEXT:    fldcw {{[0-9]+}}(%esp)
; X86-NEXT:    movsd {{.*#+}} xmm1 = mem[0],zero
; X86-NEXT:    movlps %xmm1, {{[0-9]+}}(%esp)
; X86-NEXT:    fildll {{[0-9]+}}(%esp)
; X86-NEXT:    fstps {{[0-9]+}}(%esp)
; X86-NEXT:    cmpeqss {{[0-9]+}}(%esp), %xmm0
; X86-NEXT:    movd %xmm0, %eax
; X86-NEXT:    andl $1, %eax
; X86-NEXT:    xorl %edx, %edx
; X86-NEXT:    movl %ebp, %esp
; X86-NEXT:    popl %ebp
; X86-NEXT:    retl
;
; AVX512VL-LABEL: isint64_float_return:
; AVX512VL:       # %bb.0:
; AVX512VL-NEXT:    vcvttps2qq %xmm0, %xmm1
; AVX512VL-NEXT:    vcvtqq2ps %xmm1, %xmm1
; AVX512VL-NEXT:    vcmpeqss %xmm1, %xmm0, %k0
; AVX512VL-NEXT:    kmovw %k0, %eax
; AVX512VL-NEXT:    retq
  %i = fptosi float %f to i64
  %g = sitofp i64 %i to float
  %c = fcmp oeq float %f, %g
  %z = zext i1 %c to i64
  ret i64 %z
}

define i64 @isint64_return(double %d) nounwind {
; SSE2-LABEL: isint64_return:
; SSE2:       # %bb.0:
; SSE2-NEXT:    cvttsd2si %xmm0, %rax
; SSE2-NEXT:    cvtsi2sd %rax, %xmm1
; SSE2-NEXT:    cmpeqsd %xmm0, %xmm1
; SSE2-NEXT:    movq %xmm1, %rax
; SSE2-NEXT:    andl $1, %eax
; SSE2-NEXT:    retq
;
; X86-LABEL: isint64_return:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp
; X86-NEXT:    movl %esp, %ebp
; X86-NEXT:    andl $-8, %esp
; X86-NEXT:    subl $32, %esp
; X86-NEXT:    movsd {{.*#+}} xmm0 = mem[0],zero
; X86-NEXT:    movsd %xmm0, {{[0-9]+}}(%esp)
; X86-NEXT:    fldl {{[0-9]+}}(%esp)
; X86-NEXT:    fnstcw {{[0-9]+}}(%esp)
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    orl $3072, %eax # imm = 0xC00
; X86-NEXT:    movw %ax, {{[0-9]+}}(%esp)
; X86-NEXT:    fldcw {{[0-9]+}}(%esp)
; X86-NEXT:    fistpll {{[0-9]+}}(%esp)
; X86-NEXT:    fldcw {{[0-9]+}}(%esp)
; X86-NEXT:    movsd {{.*#+}} xmm1 = mem[0],zero
; X86-NEXT:    movlps %xmm1, {{[0-9]+}}(%esp)
; X86-NEXT:    fildll {{[0-9]+}}(%esp)
; X86-NEXT:    fstpl {{[0-9]+}}(%esp)
; X86-NEXT:    cmpeqsd {{[0-9]+}}(%esp), %xmm0
; X86-NEXT:    movd %xmm0, %eax
; X86-NEXT:    andl $1, %eax
; X86-NEXT:    xorl %edx, %edx
; X86-NEXT:    movl %ebp, %esp
; X86-NEXT:    popl %ebp
; X86-NEXT:    retl
;
; AVX512VL-LABEL: isint64_return:
; AVX512VL:       # %bb.0:
; AVX512VL-NEXT:    vcvttpd2qq %xmm0, %xmm1
; AVX512VL-NEXT:    vcvtqq2pd %xmm1, %xmm1
; AVX512VL-NEXT:    vcmpeqsd %xmm1, %xmm0, %k0
; AVX512VL-NEXT:    kmovw %k0, %eax
; AVX512VL-NEXT:    retq
  %i = fptosi double %d to i64
  %g = sitofp i64 %i to double
  %c = fcmp oeq double %d, %g
  %z = zext i1 %c to i64
  ret i64 %z
}

define i32 @isuint_return(double %d) nounwind {
; SSE2-LABEL: isuint_return:
; SSE2:       # %bb.0:
; SSE2-NEXT:    cvttsd2si %xmm0, %rax
; SSE2-NEXT:    movl %eax, %eax
; SSE2-NEXT:    cvtsi2sd %rax, %xmm1
; SSE2-NEXT:    cmpeqsd %xmm0, %xmm1
; SSE2-NEXT:    movq %xmm1, %rax
; SSE2-NEXT:    andl $1, %eax
; SSE2-NEXT:    # kill: def $eax killed $eax killed $rax
; SSE2-NEXT:    retq
;
; X86-LABEL: isuint_return:
; X86:       # %bb.0:
; X86-NEXT:    movsd {{.*#+}} xmm0 = mem[0],zero
; X86-NEXT:    cvttsd2si %xmm0, %eax
; X86-NEXT:    movl %eax, %ecx
; X86-NEXT:    sarl $31, %ecx
; X86-NEXT:    movapd %xmm0, %xmm1
; X86-NEXT:    subsd {{\.?LCPI[0-9]+_[0-9]+}}, %xmm1
; X86-NEXT:    cvttsd2si %xmm1, %edx
; X86-NEXT:    andl %ecx, %edx
; X86-NEXT:    orl %eax, %edx
; X86-NEXT:    movd %edx, %xmm1
; X86-NEXT:    por {{\.?LCPI[0-9]+_[0-9]+}}, %xmm1
; X86-NEXT:    subsd {{\.?LCPI[0-9]+_[0-9]+}}, %xmm1
; X86-NEXT:    cmpeqsd %xmm0, %xmm1
; X86-NEXT:    movd %xmm1, %eax
; X86-NEXT:    andl $1, %eax
; X86-NEXT:    retl
;
; AVX512VL-LABEL: isuint_return:
; AVX512VL:       # %bb.0:
; AVX512VL-NEXT:    vcvttpd2udq %xmm0, %xmm1
; AVX512VL-NEXT:    vcvtudq2pd %xmm1, %xmm1
; AVX512VL-NEXT:    vcmpeqsd %xmm1, %xmm0, %k0
; AVX512VL-NEXT:    kmovw %k0, %eax
; AVX512VL-NEXT:    retq
  %i = fptoui double %d to i32
  %e = uitofp i32 %i to double
  %c = fcmp oeq double %d, %e
  %z = zext i1 %c to i32
  ret i32 %z
}

define i32 @isuint_float_return(float %f) nounwind {
; SSE2-LABEL: isuint_float_return:
; SSE2:       # %bb.0:
; SSE2-NEXT:    cvttps2dq %xmm0, %xmm1
; SSE2-NEXT:    cvtdq2ps %xmm1, %xmm1
; SSE2-NEXT:    cmpeqss %xmm0, %xmm1
; SSE2-NEXT:    movd %xmm1, %eax
; SSE2-NEXT:    andl $1, %eax
; SSE2-NEXT:    retq
;
; X86-LABEL: isuint_float_return:
; X86:       # %bb.0:
; X86-NEXT:    movss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-NEXT:    cvttps2dq %xmm0, %xmm1
; X86-NEXT:    cvtdq2ps %xmm1, %xmm1
; X86-NEXT:    cmpeqss %xmm0, %xmm1
; X86-NEXT:    movd %xmm1, %eax
; X86-NEXT:    andl $1, %eax
; X86-NEXT:    retl
;
; AVX512VL-LABEL: isuint_float_return:
; AVX512VL:       # %bb.0:
; AVX512VL-NEXT:    vcvttps2dq %xmm0, %xmm1
; AVX512VL-NEXT:    vcvtdq2ps %xmm1, %xmm1
; AVX512VL-NEXT:    vcmpeqss %xmm1, %xmm0, %k0
; AVX512VL-NEXT:    kmovw %k0, %eax
; AVX512VL-NEXT:    retq
  %i = fptosi float %f to i32
  %g = sitofp i32 %i to float
  %c = fcmp oeq float %f, %g
  %z = zext i1 %c to i32
  ret i32 %z
}

define i64 @isuint64_return(double %d) nounwind {
; SSE2-LABEL: isuint64_return:
; SSE2:       # %bb.0:
; SSE2-NEXT:    cvttsd2si %xmm0, %rax
; SSE2-NEXT:    movq %rax, %rcx
; SSE2-NEXT:    sarq $63, %rcx
; SSE2-NEXT:    movapd %xmm0, %xmm1
; SSE2-NEXT:    subsd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; SSE2-NEXT:    cvttsd2si %xmm1, %rdx
; SSE2-NEXT:    andq %rcx, %rdx
; SSE2-NEXT:    orq %rax, %rdx
; SSE2-NEXT:    movq %rdx, %xmm1
; SSE2-NEXT:    punpckldq {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[1],mem[1]
; SSE2-NEXT:    subpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; SSE2-NEXT:    movapd %xmm1, %xmm2
; SSE2-NEXT:    unpckhpd {{.*#+}} xmm2 = xmm2[1],xmm1[1]
; SSE2-NEXT:    addsd %xmm1, %xmm2
; SSE2-NEXT:    cmpeqsd %xmm0, %xmm2
; SSE2-NEXT:    movq %xmm2, %rax
; SSE2-NEXT:    andl $1, %eax
; SSE2-NEXT:    retq
;
; X86-LABEL: isuint64_return:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp
; X86-NEXT:    movl %esp, %ebp
; X86-NEXT:    andl $-8, %esp
; X86-NEXT:    subl $16, %esp
; X86-NEXT:    movsd {{.*#+}} xmm0 = mem[0],zero
; X86-NEXT:    movsd {{.*#+}} xmm1 = [9.2233720368547758E+18,0.0E+0]
; X86-NEXT:    ucomisd %xmm0, %xmm1
; X86-NEXT:    jbe .LBB6_2
; X86-NEXT:  # %bb.1:
; X86-NEXT:    xorpd %xmm1, %xmm1
; X86-NEXT:  .LBB6_2:
; X86-NEXT:    movapd %xmm0, %xmm2
; X86-NEXT:    subsd %xmm1, %xmm2
; X86-NEXT:    movsd %xmm2, {{[0-9]+}}(%esp)
; X86-NEXT:    setbe %al
; X86-NEXT:    fldl {{[0-9]+}}(%esp)
; X86-NEXT:    fnstcw {{[0-9]+}}(%esp)
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    orl $3072, %ecx # imm = 0xC00
; X86-NEXT:    movw %cx, {{[0-9]+}}(%esp)
; X86-NEXT:    fldcw {{[0-9]+}}(%esp)
; X86-NEXT:    fistpll {{[0-9]+}}(%esp)
; X86-NEXT:    fldcw {{[0-9]+}}(%esp)
; X86-NEXT:    movzbl %al, %eax
; X86-NEXT:    shll $31, %eax
; X86-NEXT:    xorl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movd %eax, %xmm1
; X86-NEXT:    movd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; X86-NEXT:    punpckldq {{.*#+}} xmm2 = xmm2[0],xmm1[0],xmm2[1],xmm1[1]
; X86-NEXT:    punpckldq {{.*#+}} xmm2 = xmm2[0],mem[0],xmm2[1],mem[1]
; X86-NEXT:    subpd {{\.?LCPI[0-9]+_[0-9]+}}, %xmm2
; X86-NEXT:    movapd %xmm2, %xmm1
; X86-NEXT:    unpckhpd {{.*#+}} xmm1 = xmm1[1],xmm2[1]
; X86-NEXT:    addsd %xmm2, %xmm1
; X86-NEXT:    cmpeqsd %xmm0, %xmm1
; X86-NEXT:    movd %xmm1, %eax
; X86-NEXT:    andl $1, %eax
; X86-NEXT:    xorl %edx, %edx
; X86-NEXT:    movl %ebp, %esp
; X86-NEXT:    popl %ebp
; X86-NEXT:    retl
;
; AVX512VL-LABEL: isuint64_return:
; AVX512VL:       # %bb.0:
; AVX512VL-NEXT:    vcvttpd2uqq %xmm0, %xmm1
; AVX512VL-NEXT:    vcvtuqq2pd %xmm1, %xmm1
; AVX512VL-NEXT:    vcmpeqsd %xmm1, %xmm0, %k0
; AVX512VL-NEXT:    kmovw %k0, %eax
; AVX512VL-NEXT:    retq
  %i = fptoui double %d to i64
  %e = uitofp i64 %i to double
  %c = fcmp oeq double %d, %e
  %z = zext i1 %c to i64
  ret i64 %z
}

define i64 @isuint64_float_return(float %f) nounwind {
; SSE2-LABEL: isuint64_float_return:
; SSE2:       # %bb.0:
; SSE2-NEXT:    cvttss2si %xmm0, %rcx
; SSE2-NEXT:    movq %rcx, %rdx
; SSE2-NEXT:    sarq $63, %rdx
; SSE2-NEXT:    movaps %xmm0, %xmm1
; SSE2-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; SSE2-NEXT:    cvttss2si %xmm1, %rax
; SSE2-NEXT:    andq %rdx, %rax
; SSE2-NEXT:    orq %rcx, %rax
; SSE2-NEXT:    js .LBB7_1
; SSE2-NEXT:  # %bb.2:
; SSE2-NEXT:    xorps %xmm1, %xmm1
; SSE2-NEXT:    cvtsi2ss %rax, %xmm1
; SSE2-NEXT:    jmp .LBB7_3
; SSE2-NEXT:  .LBB7_1:
; SSE2-NEXT:    movq %rax, %rcx
; SSE2-NEXT:    shrq %rcx
; SSE2-NEXT:    andl $1, %eax
; SSE2-NEXT:    orq %rcx, %rax
; SSE2-NEXT:    xorps %xmm1, %xmm1
; SSE2-NEXT:    cvtsi2ss %rax, %xmm1
; SSE2-NEXT:    addss %xmm1, %xmm1
; SSE2-NEXT:  .LBB7_3:
; SSE2-NEXT:    cmpeqss %xmm1, %xmm0
; SSE2-NEXT:    movd %xmm0, %eax
; SSE2-NEXT:    andl $1, %eax
; SSE2-NEXT:    retq
;
; X86-LABEL: isuint64_float_return:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp
; X86-NEXT:    movl %esp, %ebp
; X86-NEXT:    andl $-8, %esp
; X86-NEXT:    subl $32, %esp
; X86-NEXT:    movss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-NEXT:    movss {{.*#+}} xmm1 = [9.22337203E+18,0.0E+0,0.0E+0,0.0E+0]
; X86-NEXT:    ucomiss %xmm0, %xmm1
; X86-NEXT:    jbe .LBB7_2
; X86-NEXT:  # %bb.1:
; X86-NEXT:    xorps %xmm1, %xmm1
; X86-NEXT:  .LBB7_2:
; X86-NEXT:    movaps %xmm0, %xmm2
; X86-NEXT:    subss %xmm1, %xmm2
; X86-NEXT:    movss %xmm2, {{[0-9]+}}(%esp)
; X86-NEXT:    setbe %al
; X86-NEXT:    flds {{[0-9]+}}(%esp)
; X86-NEXT:    fnstcw {{[0-9]+}}(%esp)
; X86-NEXT:    movzwl {{[0-9]+}}(%esp), %ecx
; X86-NEXT:    orl $3072, %ecx # imm = 0xC00
; X86-NEXT:    movw %cx, {{[0-9]+}}(%esp)
; X86-NEXT:    fldcw {{[0-9]+}}(%esp)
; X86-NEXT:    fistpll {{[0-9]+}}(%esp)
; X86-NEXT:    fldcw {{[0-9]+}}(%esp)
; X86-NEXT:    movzbl %al, %eax
; X86-NEXT:    shll $31, %eax
; X86-NEXT:    xorl {{[0-9]+}}(%esp), %eax
; X86-NEXT:    movd %eax, %xmm1
; X86-NEXT:    movd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; X86-NEXT:    punpckldq {{.*#+}} xmm2 = xmm2[0],xmm1[0],xmm2[1],xmm1[1]
; X86-NEXT:    movq %xmm2, {{[0-9]+}}(%esp)
; X86-NEXT:    shrl $31, %eax
; X86-NEXT:    fildll {{[0-9]+}}(%esp)
; X86-NEXT:    fadds {{\.?LCPI[0-9]+_[0-9]+}}(,%eax,4)
; X86-NEXT:    fstps {{[0-9]+}}(%esp)
; X86-NEXT:    cmpeqss {{[0-9]+}}(%esp), %xmm0
; X86-NEXT:    movd %xmm0, %eax
; X86-NEXT:    andl $1, %eax
; X86-NEXT:    xorl %edx, %edx
; X86-NEXT:    movl %ebp, %esp
; X86-NEXT:    popl %ebp
; X86-NEXT:    retl
;
; AVX512VL-LABEL: isuint64_float_return:
; AVX512VL:       # %bb.0:
; AVX512VL-NEXT:    vcvttps2uqq %xmm0, %xmm1
; AVX512VL-NEXT:    vcvtuqq2ps %xmm1, %xmm1
; AVX512VL-NEXT:    vcmpeqss %xmm1, %xmm0, %k0
; AVX512VL-NEXT:    kmovw %k0, %eax
; AVX512VL-NEXT:    retq
  %i = fptoui float %f to i64
  %g = uitofp i64 %i to float
  %c = fcmp oeq float %f, %g
  %z = zext i1 %c to i64
  ret i64 %z
}

declare void @foo()

define void @isint_branch(double %d) nounwind {
; X86-LABEL: isint_branch:
; X86:       # %bb.0:
; X86-NEXT:    movsd {{.*#+}} xmm0 = mem[0],zero
; X86-NEXT:    cvttpd2dq %xmm0, %xmm1
; X86-NEXT:    cvtdq2pd %xmm1, %xmm1
; X86-NEXT:    ucomisd %xmm1, %xmm0
; X86-NEXT:    jne .LBB8_2
; X86-NEXT:    jp .LBB8_2
; X86-NEXT:  # %bb.1: # %true
; X86-NEXT:    calll foo@PLT
; X86-NEXT:  .LBB8_2: # %false
; X86-NEXT:    retl
;
; X64-SSE2-LABEL: isint_branch:
; X64-SSE2:       # %bb.0:
; X64-SSE2-NEXT:    cvttpd2dq %xmm0, %xmm1
; X64-SSE2-NEXT:    cvtdq2pd %xmm1, %xmm1
; X64-SSE2-NEXT:    ucomisd %xmm1, %xmm0
; X64-SSE2-NEXT:    jne .LBB2_2
; X64-SSE2-NEXT:    jp .LBB2_2
; X64-SSE2-NEXT:  # %bb.1: # %true
; X64-SSE2-NEXT:    pushq %rax
; X64-SSE2-NEXT:    callq foo@PLT
; X64-SSE2-NEXT:    popq %rax
; X64-SSE2-NEXT:  .LBB2_2: # %false
; X64-SSE2-NEXT:    retq
;
; X64-SSE42-LABEL: isint_branch:
; X64-SSE42:       # %bb.0:
; X64-SSE42-NEXT:    roundsd $11, %xmm0, %xmm1
; X64-SSE42-NEXT:    ucomisd %xmm1, %xmm0
; X64-SSE42-NEXT:    jne .LBB2_2
; X64-SSE42-NEXT:    jp .LBB2_2
; X64-SSE42-NEXT:  # %bb.1: # %true
; X64-SSE42-NEXT:    pushq %rax
; X64-SSE42-NEXT:    callq foo@PLT
; X64-SSE42-NEXT:    popq %rax
; X64-SSE42-NEXT:  .LBB2_2: # %false
; X64-SSE42-NEXT:    retq
;
; X64-AVX-LABEL: isint_branch:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vroundsd $11, %xmm0, %xmm0, %xmm1
; X64-AVX-NEXT:    vucomisd %xmm1, %xmm0
; X64-AVX-NEXT:    jne .LBB2_2
; X64-AVX-NEXT:    jp .LBB2_2
; X64-AVX-NEXT:  # %bb.1: # %true
; X64-AVX-NEXT:    pushq %rax
; X64-AVX-NEXT:    callq foo@PLT
; X64-AVX-NEXT:    popq %rax
; X64-AVX-NEXT:  .LBB2_2: # %false
; X64-AVX-NEXT:    retq
  %i = fptosi double %d to i32
  %e = sitofp i32 %i to double
  %c = fcmp oeq double %d, %e
  br i1 %c, label %true, label %false
true:
  call void @foo()
  ret void
false:
  ret void
}
