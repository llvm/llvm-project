; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-- -mattr=+sse2 | FileCheck %s --check-prefixes=SSE
; RUN: llc < %s -mtriple=x86_64-- -mattr=+sse2 -fast-isel -fast-isel-abort=1 | FileCheck %s --check-prefixes=SSE
; RUN: llc < %s -mtriple=x86_64-- -mattr=+sse2 -global-isel -global-isel-abort=1 | FileCheck %s --check-prefixes=SSE
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx | FileCheck %s --check-prefixes=AVX
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx -fast-isel -fast-isel-abort=1 | FileCheck %s --check-prefixes=AVX
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx -global-isel -global-isel-abort=1 | FileCheck %s --check-prefixes=AVX
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx512f | FileCheck %s --check-prefixes=AVX512
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx512f -fast-isel -fast-isel-abort=1 | FileCheck %s --check-prefixes=AVX512
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx512f -global-isel -global-isel-abort=1 | FileCheck %s --check-prefixes=AVX512

define <4 x float> @test_fsub_v4s32(<4 x float> %arg1, <4 x float> %arg2) {
; SSE-LABEL: test_fsub_v4s32:
; SSE:       # %bb.0:
; SSE-NEXT:    subps %xmm1, %xmm0
; SSE-NEXT:    retq
;
; AVX-LABEL: test_fsub_v4s32:
; AVX:       # %bb.0:
; AVX-NEXT:    vsubps %xmm1, %xmm0, %xmm0
; AVX-NEXT:    retq
;
; AVX512-LABEL: test_fsub_v4s32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vsubps %xmm1, %xmm0, %xmm0
; AVX512-NEXT:    retq
  %ret = fsub <4 x float> %arg1, %arg2
  ret <4 x float> %ret
}

define <2 x double> @test_fsub_v2s64(<2 x double> %arg1, <2 x double> %arg2) {
; SSE-LABEL: test_fsub_v2s64:
; SSE:       # %bb.0:
; SSE-NEXT:    subpd %xmm1, %xmm0
; SSE-NEXT:    retq
;
; AVX-LABEL: test_fsub_v2s64:
; AVX:       # %bb.0:
; AVX-NEXT:    vsubpd %xmm1, %xmm0, %xmm0
; AVX-NEXT:    retq
;
; AVX512-LABEL: test_fsub_v2s64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vsubpd %xmm1, %xmm0, %xmm0
; AVX512-NEXT:    retq
  %ret = fsub <2 x double> %arg1, %arg2
  ret <2 x double> %ret
}

define <8 x float> @test_fsub_v8s32(<8 x float> %arg1, <8 x float> %arg2) {
; SSE-LABEL: test_fsub_v8s32:
; SSE:       # %bb.0:
; SSE-NEXT:    subps %xmm2, %xmm0
; SSE-NEXT:    subps %xmm3, %xmm1
; SSE-NEXT:    retq
;
; AVX-LABEL: test_fsub_v8s32:
; AVX:       # %bb.0:
; AVX-NEXT:    vsubps %ymm1, %ymm0, %ymm0
; AVX-NEXT:    retq
;
; AVX512-LABEL: test_fsub_v8s32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vsubps %ymm1, %ymm0, %ymm0
; AVX512-NEXT:    retq
  %ret = fsub <8 x float> %arg1, %arg2
  ret <8 x float> %ret
}

define <4 x double> @test_fsub_v4s64(<4 x double> %arg1, <4 x double> %arg2) {
; SSE-LABEL: test_fsub_v4s64:
; SSE:       # %bb.0:
; SSE-NEXT:    subpd %xmm2, %xmm0
; SSE-NEXT:    subpd %xmm3, %xmm1
; SSE-NEXT:    retq
;
; AVX-LABEL: test_fsub_v4s64:
; AVX:       # %bb.0:
; AVX-NEXT:    vsubpd %ymm1, %ymm0, %ymm0
; AVX-NEXT:    retq
;
; AVX512-LABEL: test_fsub_v4s64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vsubpd %ymm1, %ymm0, %ymm0
; AVX512-NEXT:    retq
  %ret = fsub <4 x double> %arg1, %arg2
  ret <4 x double> %ret
}

define <16 x float> @test_fsub_v16s32(<16 x float> %arg1, <16 x float> %arg2) {
; SSE-LABEL: test_fsub_v16s32:
; SSE:       # %bb.0:
; SSE-NEXT:    subps %xmm4, %xmm0
; SSE-NEXT:    subps %xmm5, %xmm1
; SSE-NEXT:    subps %xmm6, %xmm2
; SSE-NEXT:    subps %xmm7, %xmm3
; SSE-NEXT:    retq
;
; AVX-LABEL: test_fsub_v16s32:
; AVX:       # %bb.0:
; AVX-NEXT:    vsubps %ymm2, %ymm0, %ymm0
; AVX-NEXT:    vsubps %ymm3, %ymm1, %ymm1
; AVX-NEXT:    retq
;
; AVX512-LABEL: test_fsub_v16s32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vsubps %zmm1, %zmm0, %zmm0
; AVX512-NEXT:    retq
  %ret = fsub <16 x float> %arg1, %arg2
  ret <16 x float> %ret
}

define <8 x double> @test_fsub_v8s64(<8 x double> %arg1, <8 x double> %arg2) {
; SSE-LABEL: test_fsub_v8s64:
; SSE:       # %bb.0:
; SSE-NEXT:    subpd %xmm4, %xmm0
; SSE-NEXT:    subpd %xmm5, %xmm1
; SSE-NEXT:    subpd %xmm6, %xmm2
; SSE-NEXT:    subpd %xmm7, %xmm3
; SSE-NEXT:    retq
;
; AVX-LABEL: test_fsub_v8s64:
; AVX:       # %bb.0:
; AVX-NEXT:    vsubpd %ymm2, %ymm0, %ymm0
; AVX-NEXT:    vsubpd %ymm3, %ymm1, %ymm1
; AVX-NEXT:    retq
;
; AVX512-LABEL: test_fsub_v8s64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vsubpd %zmm1, %zmm0, %zmm0
; AVX512-NEXT:    retq
  %ret = fsub <8 x double> %arg1, %arg2
  ret <8 x double> %ret
}
