; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+cmov | FileCheck %s

; Test ct.select optimization patterns

; Test smin(x, 0) pattern optimization
define i32 @test_ctselect_smin_zero(i32 %x) {
; CHECK-LABEL: test_ctselect_smin_zero:
; CHECK:       # %bb.0:
; CHECK-NEXT:    testl %edi, %edi
; CHECK-NEXT:    sets %cl
; CHECK-NEXT:    xorl %eax, %eax
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %cmp = icmp slt i32 %x, 0
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 %x, i32 0)
  ret i32 %result
}

; Test smax(x, 0) pattern optimization
define i32 @test_ctselect_smax_zero(i32 %x) {
; CHECK-LABEL: test_ctselect_smax_zero:
; CHECK:       # %bb.0:
; CHECK-NEXT:    testl %edi, %edi
; CHECK-NEXT:    setg %cl
; CHECK-NEXT:    xorl %eax, %eax
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %cmp = icmp sgt i32 %x, 0
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 %x, i32 0)
  ret i32 %result
}

; Test generic smin pattern
define i32 @test_ctselect_smin_generic(i32 %x, i32 %y) {
; CHECK-LABEL: test_ctselect_smin_generic:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %esi, %eax
; CHECK-NEXT:    cmpl %esi, %edi
; CHECK-NEXT:    setl %cl
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %cmp = icmp slt i32 %x, %y
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 %x, i32 %y)
  ret i32 %result
}

; Test generic smax pattern
define i32 @test_ctselect_smax_generic(i32 %x, i32 %y) {
; CHECK-LABEL: test_ctselect_smax_generic:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %esi, %eax
; CHECK-NEXT:    cmpl %esi, %edi
; CHECK-NEXT:    setg %cl
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %cmp = icmp sgt i32 %x, %y
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 %x, i32 %y)
  ret i32 %result
}

; Test umin pattern
define i32 @test_ctselect_umin_generic(i32 %x, i32 %y) {
; CHECK-LABEL: test_ctselect_umin_generic:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %esi, %eax
; CHECK-NEXT:    cmpl %esi, %edi
; CHECK-NEXT:    setb %cl
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %cmp = icmp ult i32 %x, %y
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 %x, i32 %y)
  ret i32 %result
}

; Test umax pattern
define i32 @test_ctselect_umax_generic(i32 %x, i32 %y) {
; CHECK-LABEL: test_ctselect_umax_generic:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %esi, %eax
; CHECK-NEXT:    cmpl %esi, %edi
; CHECK-NEXT:    seta %cl
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %cmp = icmp ugt i32 %x, %y
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 %x, i32 %y)
  ret i32 %result
}

; Test abs pattern
define i32 @test_ctselect_abs(i32 %x) {
; CHECK-LABEL: test_ctselect_abs:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %edi, %eax
; CHECK-NEXT:    movl %edi, %ecx
; CHECK-NEXT:    negl %ecx
; CHECK-NEXT:    testl %edi, %edi
; CHECK-NEXT:    sets %dl
; CHECK-NEXT:    testb %dl, %dl
; CHECK-NEXT:    cmovnel %ecx, %eax
; CHECK-NEXT:    retq
  %neg = sub i32 0, %x
  %cmp = icmp slt i32 %x, 0
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 %neg, i32 %x)
  ret i32 %result
}

; Test nabs pattern (negative abs)
define i32 @test_ctselect_nabs(i32 %x) {
; CHECK-LABEL: test_ctselect_nabs:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %edi, %eax
; CHECK-NEXT:    negl %eax
; CHECK-NEXT:    testl %edi, %edi
; CHECK-NEXT:    sets %cl
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %neg = sub i32 0, %x
  %cmp = icmp slt i32 %x, 0
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 %x, i32 %neg)
  ret i32 %result
}

; Test sign extension pattern
define i32 @test_ctselect_sign_extend(i32 %x) {
; CHECK-LABEL: test_ctselect_sign_extend:
; CHECK:       # %bb.0:
; CHECK-NEXT:    testl %edi, %edi
; CHECK-NEXT:    sets %cl
; CHECK-NEXT:    xorl %eax, %eax
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    movl $-1, %ecx
; CHECK-NEXT:    cmovnel %ecx, %eax
; CHECK-NEXT:    retq
  %cmp = icmp slt i32 %x, 0
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 -1, i32 0)
  ret i32 %result
}

; Test zero extension pattern
define i32 @test_ctselect_zero_extend(i32 %x) {
; CHECK-LABEL: test_ctselect_zero_extend:
; CHECK:       # %bb.0:
; CHECK-NEXT:    testl %edi, %edi
; CHECK-NEXT:    setne %cl
; CHECK-NEXT:    xorl %eax, %eax
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    movl $1, %ecx
; CHECK-NEXT:    cmovnel %ecx, %eax
; CHECK-NEXT:    retq
  %cmp = icmp ne i32 %x, 0
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 1, i32 0)
  ret i32 %result
}

; Test mask generation pattern
define i32 @test_ctselect_mask_generation(i32 %x) {
; CHECK-LABEL: test_ctselect_mask_generation:
; CHECK:       # %bb.0:
; CHECK-NEXT:    testl %edi, %edi
; CHECK-NEXT:    sets %cl
; CHECK-NEXT:    xorl %eax, %eax
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    movl $-1, %ecx
; CHECK-NEXT:    cmovnel %ecx, %eax
; CHECK-NEXT:    retq
  %cmp = icmp slt i32 %x, 0
  %result = call i32 @llvm.ct.select.i32(i1 %cmp, i32 -1, i32 0)
  ret i32 %result
}

; Test constant folding with known condition
define i32 @test_ctselect_constant_folding_true(i32 %a, i32 %b) {
; CHECK-LABEL: test_ctselect_constant_folding_true:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %esi, %eax
; CHECK-NEXT:    movb $1, %cl
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %result = call i32 @llvm.ct.select.i32(i1 true, i32 %a, i32 %b)
  ret i32 %result
}

define i32 @test_ctselect_constant_folding_false(i32 %a, i32 %b) {
; CHECK-LABEL: test_ctselect_constant_folding_false:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %esi, %eax
; CHECK-NEXT:    xorl %ecx, %ecx
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %edi, %eax
; CHECK-NEXT:    retq
  %result = call i32 @llvm.ct.select.i32(i1 false, i32 %a, i32 %b)
  ret i32 %result
}

; Test with identical operands
define i32 @test_ctselect_identical_operands(i1 %cond, i32 %x) {
; CHECK-LABEL: test_ctselect_identical_operands:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %esi, %eax
; CHECK-NEXT:    testb $1, %dil
; CHECK-NEXT:    cmovnel %esi, %eax
; CHECK-NEXT:    retq
  %result = call i32 @llvm.ct.select.i32(i1 %cond, i32 %x, i32 %x)
  ret i32 %result
}

; Test with inverted condition
define i32 @test_ctselect_inverted_condition(i32 %x, i32 %y, i32 %a, i32 %b) {
; CHECK-LABEL: test_ctselect_inverted_condition:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl %edx, %eax
; CHECK-NEXT:    cmpl %esi, %edi
; CHECK-NEXT:    sete %dl
; CHECK-NEXT:    testb %dl, %dl
; CHECK-NEXT:    cmovnel %ecx, %eax
; CHECK-NEXT:    retq
  %cmp = icmp eq i32 %x, %y
  %not_cmp = xor i1 %cmp, true
  %result = call i32 @llvm.ct.select.i32(i1 %not_cmp, i32 %a, i32 %b)
  ret i32 %result
}

; Test for 64-bit specific optimizations
define i64 @test_ctselect_i64_smin_zero(i64 %x) {
; CHECK-LABEL: test_ctselect_i64_smin_zero:
; CHECK:       # %bb.0:
; CHECK-NEXT:    testq %rdi, %rdi
; CHECK-NEXT:    sets %cl
; CHECK-NEXT:    xorl %eax, %eax
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovneq %rdi, %rax
; CHECK-NEXT:    retq
  %cmp = icmp slt i64 %x, 0
  %result = call i64 @llvm.ct.select.i64(i1 %cmp, i64 %x, i64 0)
  ret i64 %result
}

; Test for floating point optimizations
define float @test_ctselect_f32_zero_positive(float %x) {
; CHECK-LABEL: test_ctselect_f32_zero_positive:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movd %xmm0, %eax
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    ucomiss %xmm1, %xmm0
; CHECK-NEXT:    seta %cl
; CHECK-NEXT:    xorl %edx, %edx
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovnel %eax, %edx
; CHECK-NEXT:    movd %edx, %xmm0
; CHECK-NEXT:    retq
  %cmp = fcmp ogt float %x, 0.0
  %result = call float @llvm.ct.select.f32(i1 %cmp, float %x, float 0.0)
  ret float %result
}

define double @test_ctselect_f64_zero_positive(double %x) {
; CHECK-LABEL: test_ctselect_f64_zero_positive:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movq %xmm0, %rax
; CHECK-NEXT:    xorpd %xmm1, %xmm1
; CHECK-NEXT:    ucomisd %xmm1, %xmm0
; CHECK-NEXT:    seta %cl
; CHECK-NEXT:    xorl %edx, %edx
; CHECK-NEXT:    testb %cl, %cl
; CHECK-NEXT:    cmovneq %rax, %rdx
; CHECK-NEXT:    movq %rdx, %xmm0
; CHECK-NEXT:    retq
  %cmp = fcmp ogt double %x, 0.0
  %result = call double @llvm.ct.select.f64(i1 %cmp, double %x, double 0.0)
  ret double %result
}

; Test chain of ct.select operations
define i32 @test_ctselect_chain(i1 %c1, i1 %c2, i1 %c3, i32 %a, i32 %b, i32 %c, i32 %d) {
; CHECK-LABEL: test_ctselect_chain:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl {{[0-9]+}}(%rsp), %eax
; CHECK-NEXT:    testb $1, %dil
; CHECK-NEXT:    cmovnel %ecx, %r8d
; CHECK-NEXT:    testb $1, %sil
; CHECK-NEXT:    cmovnel %r8d, %r9d
; CHECK-NEXT:    testb $1, %dl
; CHECK-NEXT:    cmovnel %r9d, %eax
; CHECK-NEXT:    retq
  %sel1 = call i32 @llvm.ct.select.i32(i1 %c1, i32 %a, i32 %b)
  %sel2 = call i32 @llvm.ct.select.i32(i1 %c2, i32 %sel1, i32 %c)
  %sel3 = call i32 @llvm.ct.select.i32(i1 %c3, i32 %sel2, i32 %d)
  ret i32 %sel3
}

; Declare the intrinsics
declare i32 @llvm.ct.select.i32(i1, i32, i32)
declare i64 @llvm.ct.select.i64(i1, i64, i64)
declare float @llvm.ct.select.f32(i1, float, float)
declare double @llvm.ct.select.f64(i1, double, double)
