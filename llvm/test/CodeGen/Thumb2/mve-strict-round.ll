; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc -mtriple=thumbv8.1m.main -mattr=+mve.fp -o - %s | FileCheck %s

define arm_aapcs_vfpcc <8 x half> @test_rint_f16(<8 x half> %a) #0 {
; CHECK-LABEL: test_rint_f16:
; CHECK:       @ %bb.0: @ %entry
; CHECK-NEXT:    vmovx.f16 s4, s0
; CHECK-NEXT:    vrintx.f16 s0, s0
; CHECK-NEXT:    vrintx.f16 s4, s4
; CHECK-NEXT:    vins.f16 s0, s4
; CHECK-NEXT:    vmovx.f16 s4, s1
; CHECK-NEXT:    vrintx.f16 s4, s4
; CHECK-NEXT:    vrintx.f16 s1, s1
; CHECK-NEXT:    vins.f16 s1, s4
; CHECK-NEXT:    vmovx.f16 s4, s2
; CHECK-NEXT:    vrintx.f16 s4, s4
; CHECK-NEXT:    vrintx.f16 s2, s2
; CHECK-NEXT:    vins.f16 s2, s4
; CHECK-NEXT:    vmovx.f16 s4, s3
; CHECK-NEXT:    vrintx.f16 s4, s4
; CHECK-NEXT:    vrintx.f16 s3, s3
; CHECK-NEXT:    vins.f16 s3, s4
; CHECK-NEXT:    bx lr
entry:
  %0 = tail call <8 x half> @llvm.experimental.constrained.rint.v8f16(<8 x half> %a, metadata !"round.dynamic", metadata !"fpexcept.strict")
  ret <8 x half> %0
}

define arm_aapcs_vfpcc <8 x half> @test_roundeven_f16(<8 x half> %a) #0 {
; CHECK-LABEL: test_roundeven_f16:
; CHECK:       @ %bb.0: @ %entry
; CHECK-NEXT:    vmovx.f16 s4, s0
; CHECK-NEXT:    vrintn.f16 s0, s0
; CHECK-NEXT:    vrintn.f16 s4, s4
; CHECK-NEXT:    vins.f16 s0, s4
; CHECK-NEXT:    vmovx.f16 s4, s1
; CHECK-NEXT:    vrintn.f16 s4, s4
; CHECK-NEXT:    vrintn.f16 s1, s1
; CHECK-NEXT:    vins.f16 s1, s4
; CHECK-NEXT:    vmovx.f16 s4, s2
; CHECK-NEXT:    vrintn.f16 s4, s4
; CHECK-NEXT:    vrintn.f16 s2, s2
; CHECK-NEXT:    vins.f16 s2, s4
; CHECK-NEXT:    vmovx.f16 s4, s3
; CHECK-NEXT:    vrintn.f16 s4, s4
; CHECK-NEXT:    vrintn.f16 s3, s3
; CHECK-NEXT:    vins.f16 s3, s4
; CHECK-NEXT:    bx lr
entry:
  %0 = tail call <8 x half> @llvm.experimental.constrained.roundeven.v8f16(<8 x half> %a, metadata !"fpexcept.strict")
  ret <8 x half> %0
}

define arm_aapcs_vfpcc <8 x half> @test_round_f16(<8 x half> %a) #0 {
; CHECK-LABEL: test_round_f16:
; CHECK:       @ %bb.0: @ %entry
; CHECK-NEXT:    vmovx.f16 s4, s0
; CHECK-NEXT:    vrinta.f16 s0, s0
; CHECK-NEXT:    vrinta.f16 s4, s4
; CHECK-NEXT:    vins.f16 s0, s4
; CHECK-NEXT:    vmovx.f16 s4, s1
; CHECK-NEXT:    vrinta.f16 s4, s4
; CHECK-NEXT:    vrinta.f16 s1, s1
; CHECK-NEXT:    vins.f16 s1, s4
; CHECK-NEXT:    vmovx.f16 s4, s2
; CHECK-NEXT:    vrinta.f16 s4, s4
; CHECK-NEXT:    vrinta.f16 s2, s2
; CHECK-NEXT:    vins.f16 s2, s4
; CHECK-NEXT:    vmovx.f16 s4, s3
; CHECK-NEXT:    vrinta.f16 s4, s4
; CHECK-NEXT:    vrinta.f16 s3, s3
; CHECK-NEXT:    vins.f16 s3, s4
; CHECK-NEXT:    bx lr
entry:
  %0 = tail call <8 x half> @llvm.experimental.constrained.round.v8f16(<8 x half> %a, metadata !"fpexcept.strict")
  ret <8 x half> %0
}

define arm_aapcs_vfpcc <8 x half> @test_trunc_f16(<8 x half> %a) #0 {
; CHECK-LABEL: test_trunc_f16:
; CHECK:       @ %bb.0: @ %entry
; CHECK-NEXT:    vmovx.f16 s4, s0
; CHECK-NEXT:    vrintz.f16 s0, s0
; CHECK-NEXT:    vrintz.f16 s4, s4
; CHECK-NEXT:    vins.f16 s0, s4
; CHECK-NEXT:    vmovx.f16 s4, s1
; CHECK-NEXT:    vrintz.f16 s4, s4
; CHECK-NEXT:    vrintz.f16 s1, s1
; CHECK-NEXT:    vins.f16 s1, s4
; CHECK-NEXT:    vmovx.f16 s4, s2
; CHECK-NEXT:    vrintz.f16 s4, s4
; CHECK-NEXT:    vrintz.f16 s2, s2
; CHECK-NEXT:    vins.f16 s2, s4
; CHECK-NEXT:    vmovx.f16 s4, s3
; CHECK-NEXT:    vrintz.f16 s4, s4
; CHECK-NEXT:    vrintz.f16 s3, s3
; CHECK-NEXT:    vins.f16 s3, s4
; CHECK-NEXT:    bx lr
entry:
  %0 = tail call <8 x half> @llvm.experimental.constrained.trunc.v8f16(<8 x half> %a, metadata !"fpexcept.strict")
  ret <8 x half> %0
}

define arm_aapcs_vfpcc <8 x half> @test_floor_f16(<8 x half> %a) #0 {
; CHECK-LABEL: test_floor_f16:
; CHECK:       @ %bb.0: @ %entry
; CHECK-NEXT:    vmovx.f16 s4, s0
; CHECK-NEXT:    vrintm.f16 s0, s0
; CHECK-NEXT:    vrintm.f16 s4, s4
; CHECK-NEXT:    vins.f16 s0, s4
; CHECK-NEXT:    vmovx.f16 s4, s1
; CHECK-NEXT:    vrintm.f16 s4, s4
; CHECK-NEXT:    vrintm.f16 s1, s1
; CHECK-NEXT:    vins.f16 s1, s4
; CHECK-NEXT:    vmovx.f16 s4, s2
; CHECK-NEXT:    vrintm.f16 s4, s4
; CHECK-NEXT:    vrintm.f16 s2, s2
; CHECK-NEXT:    vins.f16 s2, s4
; CHECK-NEXT:    vmovx.f16 s4, s3
; CHECK-NEXT:    vrintm.f16 s4, s4
; CHECK-NEXT:    vrintm.f16 s3, s3
; CHECK-NEXT:    vins.f16 s3, s4
; CHECK-NEXT:    bx lr
entry:
  %0 = tail call <8 x half> @llvm.experimental.constrained.floor.v8f16(<8 x half> %a, metadata !"fpexcept.strict")
  ret <8 x half> %0
}

define arm_aapcs_vfpcc <8 x half> @test_ceil_f16(<8 x half> %a) #0 {
; CHECK-LABEL: test_ceil_f16:
; CHECK:       @ %bb.0: @ %entry
; CHECK-NEXT:    vmovx.f16 s4, s0
; CHECK-NEXT:    vrintp.f16 s0, s0
; CHECK-NEXT:    vrintp.f16 s4, s4
; CHECK-NEXT:    vins.f16 s0, s4
; CHECK-NEXT:    vmovx.f16 s4, s1
; CHECK-NEXT:    vrintp.f16 s4, s4
; CHECK-NEXT:    vrintp.f16 s1, s1
; CHECK-NEXT:    vins.f16 s1, s4
; CHECK-NEXT:    vmovx.f16 s4, s2
; CHECK-NEXT:    vrintp.f16 s4, s4
; CHECK-NEXT:    vrintp.f16 s2, s2
; CHECK-NEXT:    vins.f16 s2, s4
; CHECK-NEXT:    vmovx.f16 s4, s3
; CHECK-NEXT:    vrintp.f16 s4, s4
; CHECK-NEXT:    vrintp.f16 s3, s3
; CHECK-NEXT:    vins.f16 s3, s4
; CHECK-NEXT:    bx lr
entry:
  %0 = tail call <8 x half> @llvm.experimental.constrained.ceil.v8f16(<8 x half> %a, metadata !"fpexcept.strict")
  ret <8 x half> %0
}

attributes #0 = { strictfp }
