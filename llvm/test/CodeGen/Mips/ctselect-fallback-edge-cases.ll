; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s -mtriple=mipsel-unknown-linux-gnu -O3 | FileCheck %s --check-prefix=M32
; RUN: llc < %s -mtriple=mips64el-unknown-linux-gnu -O3 | FileCheck %s --check-prefix=M64

; Portable edge case tests

; Test with small integer types
define i1 @test_ctselect_i1(i1 %cond, i1 %a, i1 %b) {
; M32-LABEL: test_ctselect_i1:
; M32:       # %bb.0:
; M32-NEXT:    xori $2, $4, 1
; M32-NEXT:    and $1, $4, $5
; M32-NEXT:    and $2, $2, $6
; M32-NEXT:    jr $ra
; M32-NEXT:    or $2, $1, $2
;
; M64-LABEL: test_ctselect_i1:
; M64:       # %bb.0:
; M64-NEXT:    sll $2, $4, 0
; M64-NEXT:    sll $1, $6, 0
; M64-NEXT:    xori $2, $2, 1
; M64-NEXT:    and $1, $2, $1
; M64-NEXT:    and $2, $4, $5
; M64-NEXT:    sll $2, $2, 0
; M64-NEXT:    jr $ra
; M64-NEXT:    or $2, $2, $1
  %result = call i1 @llvm.ct.select.i1(i1 %cond, i1 %a, i1 %b)
  ret i1 %result
}

; Test with extremal values
define i32 @test_ctselect_extremal_values(i1 %cond) {
; M32-LABEL: test_ctselect_extremal_values:
; M32:       # %bb.0:
; M32-NEXT:    andi $1, $4, 1
; M32-NEXT:    lui $3, 32768
; M32-NEXT:    addiu $2, $1, -1
; M32-NEXT:    negu $1, $1
; M32-NEXT:    and $2, $2, $3
; M32-NEXT:    lui $3, 32767
; M32-NEXT:    ori $3, $3, 65535
; M32-NEXT:    and $1, $1, $3
; M32-NEXT:    jr $ra
; M32-NEXT:    or $2, $1, $2
;
; M64-LABEL: test_ctselect_extremal_values:
; M64:       # %bb.0:
; M64-NEXT:    sll $1, $4, 0
; M64-NEXT:    lui $3, 32768
; M64-NEXT:    andi $1, $1, 1
; M64-NEXT:    addiu $2, $1, -1
; M64-NEXT:    negu $1, $1
; M64-NEXT:    and $2, $2, $3
; M64-NEXT:    lui $3, 32767
; M64-NEXT:    ori $3, $3, 65535
; M64-NEXT:    and $1, $1, $3
; M64-NEXT:    jr $ra
; M64-NEXT:    or $2, $1, $2
  %result = call i32 @llvm.ct.select.i32(i1 %cond, i32 2147483647, i32 -2147483648)
  ret i32 %result
}

; Test with null pointers
define ptr @test_ctselect_null_ptr(i1 %cond, ptr %ptr) {
; M32-LABEL: test_ctselect_null_ptr:
; M32:       # %bb.0:
; M32-NEXT:    andi $1, $4, 1
; M32-NEXT:    negu $1, $1
; M32-NEXT:    jr $ra
; M32-NEXT:    and $2, $1, $5
;
; M64-LABEL: test_ctselect_null_ptr:
; M64:       # %bb.0:
; M64-NEXT:    andi $1, $4, 1
; M64-NEXT:    dnegu $1, $1
; M64-NEXT:    jr $ra
; M64-NEXT:    and $2, $1, $5
  %result = call ptr @llvm.ct.select.p0(i1 %cond, ptr %ptr, ptr null)
  ret ptr %result
}

; Test with function pointers
define ptr @test_ctselect_function_ptr(i1 %cond, ptr %func1, ptr %func2) {
; M32-LABEL: test_ctselect_function_ptr:
; M32:       # %bb.0:
; M32-NEXT:    andi $1, $4, 1
; M32-NEXT:    addiu $2, $1, -1
; M32-NEXT:    negu $1, $1
; M32-NEXT:    and $2, $2, $6
; M32-NEXT:    and $1, $1, $5
; M32-NEXT:    jr $ra
; M32-NEXT:    or $2, $1, $2
;
; M64-LABEL: test_ctselect_function_ptr:
; M64:       # %bb.0:
; M64-NEXT:    andi $1, $4, 1
; M64-NEXT:    daddiu $2, $1, -1
; M64-NEXT:    dnegu $1, $1
; M64-NEXT:    and $2, $2, $6
; M64-NEXT:    and $1, $1, $5
; M64-NEXT:    jr $ra
; M64-NEXT:    or $2, $1, $2
  %result = call ptr @llvm.ct.select.p0(i1 %cond, ptr %func1, ptr %func2)
  ret ptr %result
}

; Test with condition from icmp on pointers
define ptr @test_ctselect_ptr_cmp(ptr %p1, ptr %p2, ptr %a, ptr %b) {
; M32-LABEL: test_ctselect_ptr_cmp:
; M32:       # %bb.0:
; M32-NEXT:    xor $1, $4, $5
; M32-NEXT:    sltu $1, $zero, $1
; M32-NEXT:    negu $2, $1
; M32-NEXT:    addiu $1, $1, -1
; M32-NEXT:    and $2, $2, $7
; M32-NEXT:    and $1, $1, $6
; M32-NEXT:    jr $ra
; M32-NEXT:    or $2, $1, $2
;
; M64-LABEL: test_ctselect_ptr_cmp:
; M64:       # %bb.0:
; M64-NEXT:    xor $1, $4, $5
; M64-NEXT:    daddiu $3, $zero, -1
; M64-NEXT:    daddiu $2, $zero, -1
; M64-NEXT:    movn $3, $zero, $1
; M64-NEXT:    xor $2, $3, $2
; M64-NEXT:    and $1, $3, $6
; M64-NEXT:    and $2, $2, $7
; M64-NEXT:    jr $ra
; M64-NEXT:    or $2, $1, $2
  %cmp = icmp eq ptr %p1, %p2
  %result = call ptr @llvm.ct.select.p0(i1 %cmp, ptr %a, ptr %b)
  ret ptr %result
}

; Test with struct pointer types
%struct.pair = type { i32, i32 }

define ptr @test_ctselect_struct_ptr(i1 %cond, ptr %a, ptr %b) {
; M32-LABEL: test_ctselect_struct_ptr:
; M32:       # %bb.0:
; M32-NEXT:    andi $1, $4, 1
; M32-NEXT:    addiu $2, $1, -1
; M32-NEXT:    negu $1, $1
; M32-NEXT:    and $2, $2, $6
; M32-NEXT:    and $1, $1, $5
; M32-NEXT:    jr $ra
; M32-NEXT:    or $2, $1, $2
;
; M64-LABEL: test_ctselect_struct_ptr:
; M64:       # %bb.0:
; M64-NEXT:    andi $1, $4, 1
; M64-NEXT:    daddiu $2, $1, -1
; M64-NEXT:    dnegu $1, $1
; M64-NEXT:    and $2, $2, $6
; M64-NEXT:    and $1, $1, $5
; M64-NEXT:    jr $ra
; M64-NEXT:    or $2, $1, $2
  %result = call ptr @llvm.ct.select.p0(i1 %cond, ptr %a, ptr %b)
  ret ptr %result
}

; Test with deeply nested conditions
define i32 @test_ctselect_deeply_nested(i1 %c1, i1 %c2, i1 %c3, i1 %c4, i32 %a, i32 %b, i32 %c, i32 %d, i32 %e) {
; M32-LABEL: test_ctselect_deeply_nested:
; M32:       # %bb.0:
; M32-NEXT:    andi $1, $4, 1
; M32-NEXT:    lw $3, 20($sp)
; M32-NEXT:    addiu $2, $1, -1
; M32-NEXT:    negu $1, $1
; M32-NEXT:    and $2, $2, $3
; M32-NEXT:    lw $3, 16($sp)
; M32-NEXT:    and $1, $1, $3
; M32-NEXT:    or $1, $1, $2
; M32-NEXT:    andi $2, $5, 1
; M32-NEXT:    negu $3, $2
; M32-NEXT:    addiu $2, $2, -1
; M32-NEXT:    and $1, $3, $1
; M32-NEXT:    lw $3, 24($sp)
; M32-NEXT:    and $2, $2, $3
; M32-NEXT:    andi $3, $7, 1
; M32-NEXT:    or $1, $1, $2
; M32-NEXT:    andi $2, $6, 1
; M32-NEXT:    lw $6, 32($sp)
; M32-NEXT:    negu $4, $3
; M32-NEXT:    addiu $3, $3, -1
; M32-NEXT:    negu $5, $2
; M32-NEXT:    addiu $2, $2, -1
; M32-NEXT:    and $1, $5, $1
; M32-NEXT:    lw $5, 28($sp)
; M32-NEXT:    and $2, $2, $5
; M32-NEXT:    or $1, $1, $2
; M32-NEXT:    and $2, $3, $6
; M32-NEXT:    and $1, $4, $1
; M32-NEXT:    jr $ra
; M32-NEXT:    or $2, $1, $2
;
; M64-LABEL: test_ctselect_deeply_nested:
; M64:       # %bb.0:
; M64-NEXT:    sll $1, $4, 0
; M64-NEXT:    sll $4, $9, 0
; M64-NEXT:    sll $3, $8, 0
; M64-NEXT:    sll $8, $11, 0
; M64-NEXT:    lw $9, 0($sp)
; M64-NEXT:    andi $1, $1, 1
; M64-NEXT:    negu $2, $1
; M64-NEXT:    addiu $1, $1, -1
; M64-NEXT:    and $1, $1, $4
; M64-NEXT:    sll $4, $5, 0
; M64-NEXT:    and $2, $2, $3
; M64-NEXT:    sll $3, $6, 0
; M64-NEXT:    sll $5, $7, 0
; M64-NEXT:    andi $4, $4, 1
; M64-NEXT:    or $1, $2, $1
; M64-NEXT:    andi $3, $3, 1
; M64-NEXT:    andi $5, $5, 1
; M64-NEXT:    negu $2, $4
; M64-NEXT:    addiu $4, $4, -1
; M64-NEXT:    negu $7, $3
; M64-NEXT:    negu $6, $5
; M64-NEXT:    addiu $5, $5, -1
; M64-NEXT:    and $1, $2, $1
; M64-NEXT:    sll $2, $10, 0
; M64-NEXT:    and $2, $4, $2
; M64-NEXT:    or $1, $1, $2
; M64-NEXT:    addiu $2, $3, -1
; M64-NEXT:    and $1, $7, $1
; M64-NEXT:    and $2, $2, $8
; M64-NEXT:    or $1, $1, $2
; M64-NEXT:    and $2, $5, $9
; M64-NEXT:    and $1, $6, $1
; M64-NEXT:    jr $ra
; M64-NEXT:    or $2, $1, $2
  %sel1 = call i32 @llvm.ct.select.i32(i1 %c1, i32 %a, i32 %b)
  %sel2 = call i32 @llvm.ct.select.i32(i1 %c2, i32 %sel1, i32 %c)
  %sel3 = call i32 @llvm.ct.select.i32(i1 %c3, i32 %sel2, i32 %d)
  %sel4 = call i32 @llvm.ct.select.i32(i1 %c4, i32 %sel3, i32 %e)
  ret i32 %sel4
}

 ; This test demonstrates the FStar cmovznz4 pattern using ct.select
; Based on https://godbolt.org/z/6Kb71Ks7z
; Shows that NoMerge flag prevents DAG optimization from introducing branches
define void @cmovznz4_fstar_original(i64 %cin, ptr %x, ptr %y, ptr %r) {
; M32-LABEL: cmovznz4_fstar_original:
; M32:       # %bb.0: # %entry
; M32-NEXT:    or $1, $4, $5
; M32-NEXT:    addiu $2, $7, 16
; M32-NEXT:    addiu $3, $6, 16
; M32-NEXT:    addiu $4, $6, 8
; M32-NEXT:    movz $2, $3, $1
; M32-NEXT:    addiu $3, $7, 8
; M32-NEXT:    movz $3, $4, $1
; M32-NEXT:    addiu $4, $7, 24
; M32-NEXT:    movz $7, $6, $1
; M32-NEXT:    addiu $6, $6, 24
; M32-NEXT:    lw $9, 4($2)
; M32-NEXT:    lw $2, 0($2)
; M32-NEXT:    movz $4, $6, $1
; M32-NEXT:    lw $5, 4($7)
; M32-NEXT:    lw $8, 4($3)
; M32-NEXT:    lw $7, 0($7)
; M32-NEXT:    lw $3, 0($3)
; M32-NEXT:    lw $6, 16($sp)
; M32-NEXT:    lw $1, 4($4)
; M32-NEXT:    lw $4, 0($4)
; M32-NEXT:    sw $4, 24($6)
; M32-NEXT:    sw $1, 28($6)
; M32-NEXT:    sw $2, 16($6)
; M32-NEXT:    sw $9, 20($6)
; M32-NEXT:    sw $3, 8($6)
; M32-NEXT:    sw $8, 12($6)
; M32-NEXT:    sw $7, 0($6)
; M32-NEXT:    jr $ra
; M32-NEXT:    sw $5, 4($6)
;
; M64-LABEL: cmovznz4_fstar_original:
; M64:       # %bb.0: # %entry
; M64-NEXT:    daddiu $1, $6, 8
; M64-NEXT:    daddiu $2, $5, 8
; M64-NEXT:    daddiu $3, $6, 16
; M64-NEXT:    daddiu $8, $5, 16
; M64-NEXT:    movz $1, $2, $4
; M64-NEXT:    move $2, $6
; M64-NEXT:    daddiu $6, $6, 24
; M64-NEXT:    movz $3, $8, $4
; M64-NEXT:    movz $2, $5, $4
; M64-NEXT:    daddiu $5, $5, 24
; M64-NEXT:    ld $1, 0($1)
; M64-NEXT:    ld $3, 0($3)
; M64-NEXT:    movz $6, $5, $4
; M64-NEXT:    ld $2, 0($2)
; M64-NEXT:    ld $4, 0($6)
; M64-NEXT:    sd $4, 24($7)
; M64-NEXT:    sd $3, 16($7)
; M64-NEXT:    sd $1, 8($7)
; M64-NEXT:    jr $ra
; M64-NEXT:    sd $2, 0($7)
entry:
  %.not.i = icmp eq i64 %cin, 0
  %0 = load i64, ptr %y, align 8
  %1 = load i64, ptr %x, align 8
  %or = select i1 %.not.i, i64 %1, i64 %0
  %arrayidx4 = getelementptr inbounds nuw i8, ptr %y, i64 8
  %2 = load i64, ptr %arrayidx4, align 8
  %arrayidx6 = getelementptr inbounds nuw i8, ptr %x, i64 8
  %3 = load i64, ptr %arrayidx6, align 8
  %or9 = select i1 %.not.i, i64 %3, i64 %2
  %arrayidx10 = getelementptr inbounds nuw i8, ptr %y, i64 16
  %4 = load i64, ptr %arrayidx10, align 8
  %arrayidx12 = getelementptr inbounds nuw i8, ptr %x, i64 16
  %5 = load i64, ptr %arrayidx12, align 8
  %or15 = select i1 %.not.i, i64 %5, i64 %4
  %arrayidx16 = getelementptr inbounds nuw i8, ptr %y, i64 24
  %6 = load i64, ptr %arrayidx16, align 8
  %arrayidx18 = getelementptr inbounds nuw i8, ptr %x, i64 24
  %7 = load i64, ptr %arrayidx18, align 8
  %or21 = select i1 %.not.i, i64 %7, i64 %6
  store i64 %or, ptr %r, align 8
  %arrayidx23 = getelementptr inbounds nuw i8, ptr %r, i64 8
  store i64 %or9, ptr %arrayidx23, align 8
  %arrayidx24 = getelementptr inbounds nuw i8, ptr %r, i64 16
  store i64 %or15, ptr %arrayidx24, align 8
  %arrayidx25 = getelementptr inbounds nuw i8, ptr %r, i64 24
  store i64 %or21, ptr %arrayidx25, align 8
  ret void
}

define void @cmovznz4_builtin_ctselect(i64 %cin, ptr %x, ptr %y, ptr %r) {
; M32-LABEL: cmovznz4_builtin_ctselect:
; M32:       # %bb.0: # %entry
; M32-NEXT:    or $1, $4, $5
; M32-NEXT:    lw $3, 4($7)
; M32-NEXT:    lw $4, 4($6)
; M32-NEXT:    sltu $1, $zero, $1
; M32-NEXT:    negu $2, $1
; M32-NEXT:    addiu $1, $1, -1
; M32-NEXT:    and $3, $2, $3
; M32-NEXT:    and $4, $1, $4
; M32-NEXT:    or $3, $4, $3
; M32-NEXT:    lw $4, 16($sp)
; M32-NEXT:    sw $3, 4($4)
; M32-NEXT:    lw $3, 0($7)
; M32-NEXT:    lw $5, 0($6)
; M32-NEXT:    and $3, $2, $3
; M32-NEXT:    and $5, $1, $5
; M32-NEXT:    or $3, $5, $3
; M32-NEXT:    sw $3, 0($4)
; M32-NEXT:    lw $3, 12($7)
; M32-NEXT:    lw $5, 12($6)
; M32-NEXT:    and $3, $2, $3
; M32-NEXT:    and $5, $1, $5
; M32-NEXT:    or $3, $5, $3
; M32-NEXT:    sw $3, 12($4)
; M32-NEXT:    lw $3, 8($7)
; M32-NEXT:    lw $5, 8($6)
; M32-NEXT:    and $3, $2, $3
; M32-NEXT:    and $5, $1, $5
; M32-NEXT:    or $3, $5, $3
; M32-NEXT:    sw $3, 8($4)
; M32-NEXT:    lw $3, 20($7)
; M32-NEXT:    lw $5, 20($6)
; M32-NEXT:    and $3, $2, $3
; M32-NEXT:    and $5, $1, $5
; M32-NEXT:    or $3, $5, $3
; M32-NEXT:    sw $3, 20($4)
; M32-NEXT:    lw $3, 16($7)
; M32-NEXT:    lw $5, 16($6)
; M32-NEXT:    and $3, $2, $3
; M32-NEXT:    and $5, $1, $5
; M32-NEXT:    or $3, $5, $3
; M32-NEXT:    sw $3, 16($4)
; M32-NEXT:    lw $3, 28($7)
; M32-NEXT:    lw $5, 28($6)
; M32-NEXT:    and $3, $2, $3
; M32-NEXT:    and $5, $1, $5
; M32-NEXT:    or $3, $5, $3
; M32-NEXT:    sw $3, 28($4)
; M32-NEXT:    lw $3, 24($7)
; M32-NEXT:    and $2, $2, $3
; M32-NEXT:    lw $3, 24($6)
; M32-NEXT:    and $1, $1, $3
; M32-NEXT:    or $1, $1, $2
; M32-NEXT:    jr $ra
; M32-NEXT:    sw $1, 24($4)
;
; M64-LABEL: cmovznz4_builtin_ctselect:
; M64:       # %bb.0: # %entry
; M64-NEXT:    daddiu $2, $zero, -1
; M64-NEXT:    daddiu $1, $zero, -1
; M64-NEXT:    ld $3, 0($5)
; M64-NEXT:    movn $2, $zero, $4
; M64-NEXT:    ld $4, 0($6)
; M64-NEXT:    xor $1, $2, $1
; M64-NEXT:    and $3, $2, $3
; M64-NEXT:    and $4, $1, $4
; M64-NEXT:    or $3, $3, $4
; M64-NEXT:    sd $3, 0($7)
; M64-NEXT:    ld $3, 8($6)
; M64-NEXT:    ld $4, 8($5)
; M64-NEXT:    and $3, $1, $3
; M64-NEXT:    and $4, $2, $4
; M64-NEXT:    or $3, $4, $3
; M64-NEXT:    sd $3, 8($7)
; M64-NEXT:    ld $3, 16($6)
; M64-NEXT:    ld $4, 16($5)
; M64-NEXT:    and $3, $1, $3
; M64-NEXT:    and $4, $2, $4
; M64-NEXT:    or $3, $4, $3
; M64-NEXT:    sd $3, 16($7)
; M64-NEXT:    ld $3, 24($6)
; M64-NEXT:    and $1, $1, $3
; M64-NEXT:    ld $3, 24($5)
; M64-NEXT:    and $2, $2, $3
; M64-NEXT:    or $1, $2, $1
; M64-NEXT:    jr $ra
; M64-NEXT:    sd $1, 24($7)
entry:
  %cmp = icmp eq i64 %cin, 0
  %0 = load i64, ptr %x, align 8
  %1 = load i64, ptr %y, align 8
  %2 = tail call i64 @llvm.ct.select.i64(i1 %cmp, i64 %0, i64 %1)
  store i64 %2, ptr %r, align 8
  %arrayidx4 = getelementptr inbounds nuw i8, ptr %x, i64 8
  %3 = load i64, ptr %arrayidx4, align 8
  %arrayidx5 = getelementptr inbounds nuw i8, ptr %y, i64 8
  %4 = load i64, ptr %arrayidx5, align 8
  %5 = tail call i64 @llvm.ct.select.i64(i1 %cmp, i64 %3, i64 %4)
  %arrayidx6 = getelementptr inbounds nuw i8, ptr %r, i64 8
  store i64 %5, ptr %arrayidx6, align 8
  %arrayidx8 = getelementptr inbounds nuw i8, ptr %x, i64 16
  %6 = load i64, ptr %arrayidx8, align 8
  %arrayidx9 = getelementptr inbounds nuw i8, ptr %y, i64 16
  %7 = load i64, ptr %arrayidx9, align 8
  %8 = tail call i64 @llvm.ct.select.i64(i1 %cmp, i64 %6, i64 %7)
  %arrayidx10 = getelementptr inbounds nuw i8, ptr %r, i64 16
  store i64 %8, ptr %arrayidx10, align 8
  %arrayidx12 = getelementptr inbounds nuw i8, ptr %x, i64 24
  %9 = load i64, ptr %arrayidx12, align 8
  %arrayidx13 = getelementptr inbounds nuw i8, ptr %y, i64 24
  %10 = load i64, ptr %arrayidx13, align 8
  %11 = tail call i64 @llvm.ct.select.i64(i1 %cmp, i64 %9, i64 %10)
  %arrayidx14 = getelementptr inbounds nuw i8, ptr %r, i64 24
  store i64 %11, ptr %arrayidx14, align 8
  ret void
}

; Declare the intrinsics
declare i1 @llvm.ct.select.i1(i1, i1, i1)
declare i32 @llvm.ct.select.i32(i1, i32, i32)
declare ptr @llvm.ct.select.p0(i1, ptr, ptr)
