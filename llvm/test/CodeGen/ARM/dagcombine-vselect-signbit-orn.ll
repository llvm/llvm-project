; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=armv7-unknown-unknown | FileCheck %s

; Test for the optimization: (Cond0 s> -1) ? -1 : N2 --> ~(Cond0 s>> BW-1) | freeze(N2)
; The DAGCombiner optimization transforms the select into the expected pattern,
; but further optimizations convert it to a more efficient sequence

define <4 x i32> @vselect_signbit_orn_vector(<4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: vselect_signbit_orn_vector:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov d17, r2, r3
; CHECK-NEXT:    vmov d16, r0, r1
; CHECK-NEXT:    mov r0, sp
; CHECK-NEXT:    vld1.64 {d18, d19}, [r0]
; CHECK-NEXT:    vshr.s32 q8, q8, #31
; CHECK-NEXT:    vorn q8, q9, q8
; CHECK-NEXT:    vmov r0, r1, d16
; CHECK-NEXT:    vmov r2, r3, d17
; CHECK-NEXT:    bx lr
  %cmp = icmp sgt <4 x i32> %x, <i32 -1, i32 -1, i32 -1, i32 -1>
  %sel = select <4 x i1> %cmp, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, <4 x i32> %y
  ret <4 x i32> %sel
}

define <2 x i64> @vselect_signbit_orn_vector64(<2 x i64> %x, <2 x i64> %y) {
; CHECK-LABEL: vselect_signbit_orn_vector64:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov d17, r2, r3
; CHECK-NEXT:    vmov d16, r0, r1
; CHECK-NEXT:    mov r0, sp
; CHECK-NEXT:    vld1.64 {d18, d19}, [r0]
; CHECK-NEXT:    vshr.s64 q8, q8, #63
; CHECK-NEXT:    vorn q8, q9, q8
; CHECK-NEXT:    vmov r0, r1, d16
; CHECK-NEXT:    vmov r2, r3, d17
; CHECK-NEXT:    bx lr
  %cmp = icmp sgt <2 x i64> %x, <i64 -1, i64 -1>
  %sel = select <2 x i1> %cmp, <2 x i64> <i64 -1, i64 -1>, <2 x i64> %y
  ret <2 x i64> %sel
}

; Test with different constant values for N2
define <4 x i32> @vselect_signbit_orn_const(<4 x i32> %x) {
; CHECK-LABEL: vselect_signbit_orn_const:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov d17, r2, r3
; CHECK-NEXT:    vmov d16, r0, r1
; CHECK-NEXT:    vshr.s32 q8, q8, #31
; CHECK-NEXT:    vmvn q8, q8
; CHECK-NEXT:    vorr.i32 q8, #0x2a
; CHECK-NEXT:    vmov r0, r1, d16
; CHECK-NEXT:    vmov r2, r3, d17
; CHECK-NEXT:    bx lr
  %cmp = icmp sgt <4 x i32> %x, <i32 -1, i32 -1, i32 -1, i32 -1>
  %sel = select <4 x i1> %cmp, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, <4 x i32> <i32 42, i32 42, i32 42, i32 42>
  ret <4 x i32> %sel
}

; Test the inverse pattern to ensure it doesn't get optimized (should use different instruction)
define <4 x i32> @vselect_signbit_not_orn(<4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: vselect_signbit_not_orn:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov d17, r2, r3
; CHECK-NEXT:    vmov d16, r0, r1
; CHECK-NEXT:    mov r0, sp
; CHECK-NEXT:    vld1.64 {d18, d19}, [r0]
; CHECK-NEXT:    vshr.s32 q8, q8, #31
; CHECK-NEXT:    vand q8, q8, q9
; CHECK-NEXT:    vmov r0, r1, d16
; CHECK-NEXT:    vmov r2, r3, d17
; CHECK-NEXT:    bx lr
  %cmp = icmp sgt <4 x i32> %x, <i32 -1, i32 -1, i32 -1, i32 -1>
  %sel = select <4 x i1> %cmp, <4 x i32> <i32 0, i32 0, i32 0, i32 0>, <4 x i32> %y
  ret <4 x i32> %sel
}

; Test to demonstrate that orn instruction is available when the pattern matches directly
define <4 x i32> @test_orn_instruction_direct(<4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: test_orn_instruction_direct:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov d17, r2, r3
; CHECK-NEXT:    vmov d16, r0, r1
; CHECK-NEXT:    mov r0, sp
; CHECK-NEXT:    vld1.64 {d18, d19}, [r0]
; CHECK-NEXT:    vorn q8, q8, q9
; CHECK-NEXT:    vmov r0, r1, d16
; CHECK-NEXT:    vmov r2, r3, d17
; CHECK-NEXT:    bx lr
  %not_y = xor <4 x i32> %y, <i32 -1, i32 -1, i32 -1, i32 -1>
  %result = or <4 x i32> %x, %not_y
  ret <4 x i32> %result
}

; Scalar versions of the same tests
define i32 @vselect_signbit_orn_scalar_i32(i32 %x, i32 %y) {
; CHECK-LABEL: vselect_signbit_orn_scalar_i32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    cmn r0, #1
; CHECK-NEXT:    mvngt r1, #0
; CHECK-NEXT:    mov r0, r1
; CHECK-NEXT:    bx lr
  %cmp = icmp sgt i32 %x, -1
  %sel = select i1 %cmp, i32 -1, i32 %y
  ret i32 %sel
}

define i64 @vselect_signbit_orn_scalar_i64(i64 %x, i64 %y) {
; CHECK-LABEL: vselect_signbit_orn_scalar_i64:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    cmn r1, #1
; CHECK-NEXT:    mov r0, r2
; CHECK-NEXT:    mvngt r3, #0
; CHECK-NEXT:    mvngt r0, #0
; CHECK-NEXT:    mov r1, r3
; CHECK-NEXT:    bx lr
  %cmp = icmp sgt i64 %x, -1
  %sel = select i1 %cmp, i64 -1, i64 %y
  ret i64 %sel
}

define i32 @test_orn_instruction_scalar_i32(i32 %x, i32 %y) {
; CHECK-LABEL: test_orn_instruction_scalar_i32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    mvn r1, r1
; CHECK-NEXT:    orr r0, r0, r1
; CHECK-NEXT:    bx lr
  %not_y = xor i32 %y, -1
  %result = or i32 %x, %not_y
  ret i32 %result
}

define i64 @test_orn_instruction_scalar_i64(i64 %x, i64 %y) {
; CHECK-LABEL: test_orn_instruction_scalar_i64:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    mvn r2, r2
; CHECK-NEXT:    orr r0, r0, r2
; CHECK-NEXT:    mvn r2, r3
; CHECK-NEXT:    orr r1, r1, r2
; CHECK-NEXT:    bx lr
  %not_y = xor i64 %y, -1
  %result = or i64 %x, %not_y
  ret i64 %result
}
