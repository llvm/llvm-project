; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=thumbv6m-eabi -mattr=+strict-align %s -o - | FileCheck %s -check-prefix=CHECK-V6M
; RUN: llc -mtriple=thumbv7m-eabi -mattr=+strict-align %s -o - | FileCheck %s -check-prefix=CHECK-V7M
; RUN: llc -mtriple=thumbv7m-eabi -mattr=-strict-align %s -o - | FileCheck %s -check-prefix=CHECK-ALIGNED

define void @loadstore4_align1(i32* %a, i32* %b) nounwind optsize minsize {
; CHECK-V6M-LABEL: loadstore4_align1:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r4, lr}
; CHECK-V6M-NEXT:    push {r4, lr}
; CHECK-V6M-NEXT:    mov r4, r1
; CHECK-V6M-NEXT:    bl __aeabi_uread4
; CHECK-V6M-NEXT:    mov r1, r4
; CHECK-V6M-NEXT:    bl __aeabi_uwrite4
; CHECK-V6M-NEXT:    pop {r4, pc}
;
; CHECK-V7M-LABEL: loadstore4_align1:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r4, lr}
; CHECK-V7M-NEXT:    push {r4, lr}
; CHECK-V7M-NEXT:    mov r4, r1
; CHECK-V7M-NEXT:    bl __aeabi_uread4
; CHECK-V7M-NEXT:    mov r1, r4
; CHECK-V7M-NEXT:    bl __aeabi_uwrite4
; CHECK-V7M-NEXT:    pop {r4, pc}
;
; CHECK-ALIGNED-LABEL: loadstore4_align1:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    ldr r0, [r0]
; CHECK-ALIGNED-NEXT:    str r0, [r1]
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  %tmp = load i32, i32* %a, align 1
  store i32 %tmp, i32* %b, align 1
  ret void
}

define i32 @load4_align1(i32* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load4_align1:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    bl __aeabi_uread4
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: load4_align1:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    bl __aeabi_uread4
; CHECK-V7M-NEXT:    pop {r7, pc}
;
; CHECK-ALIGNED-LABEL: load4_align1:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    ldr r0, [r0]
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  %tmp = load i32, i32* %a, align 1
  ret i32 %tmp
}

define i64 @load4_align1_zext(i32* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load4_align1_zext:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    bl __aeabi_uread4
; CHECK-V6M-NEXT:    movs r1, #0
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: load4_align1_zext:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    bl __aeabi_uread4
; CHECK-V7M-NEXT:    movs r1, #0
; CHECK-V7M-NEXT:    pop {r7, pc}
;
; CHECK-ALIGNED-LABEL: load4_align1_zext:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    ldr r0, [r0]
; CHECK-ALIGNED-NEXT:    movs r1, #0
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  %tmp = load i32, i32* %a, align 1
  %ext = zext i32 %tmp to i64
  ret i64 %ext
}

define i64 @load4_align1_sext(i32* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load4_align1_sext:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    bl __aeabi_uread4
; CHECK-V6M-NEXT:    asrs r1, r0, #31
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: load4_align1_sext:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    bl __aeabi_uread4
; CHECK-V7M-NEXT:    asrs r1, r0, #31
; CHECK-V7M-NEXT:    pop {r7, pc}
;
; CHECK-ALIGNED-LABEL: load4_align1_sext:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    ldr r0, [r0]
; CHECK-ALIGNED-NEXT:    asrs r1, r0, #31
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  %tmp = load i32, i32* %a, align 1
  %ext = sext i32 %tmp to i64
  ret i64 %ext
}

define void @store4_align1(i32* %a, i32 %b) nounwind optsize minsize {
; CHECK-V6M-LABEL: store4_align1:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    mov r2, r0
; CHECK-V6M-NEXT:    mov r0, r1
; CHECK-V6M-NEXT:    mov r1, r2
; CHECK-V6M-NEXT:    bl __aeabi_uwrite4
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: store4_align1:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    mov r2, r0
; CHECK-V7M-NEXT:    mov r0, r1
; CHECK-V7M-NEXT:    mov r1, r2
; CHECK-V7M-NEXT:    bl __aeabi_uwrite4
; CHECK-V7M-NEXT:    pop {r7, pc}
;
; CHECK-ALIGNED-LABEL: store4_align1:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    str r1, [r0]
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  store i32 %b, i32* %a, align 1
  ret void
}

define i32 @load4_align2(i32* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load4_align2:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    bl __aeabi_uread4
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: load4_align2:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    bl __aeabi_uread4
; CHECK-V7M-NEXT:    pop {r7, pc}
;
; CHECK-ALIGNED-LABEL: load4_align2:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    ldr r0, [r0]
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  %tmp = load i32, i32* %a, align 2
  ret i32 %tmp
}

define i64 @load6_align1_zext(i48* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load6_align1_zext:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r4, lr}
; CHECK-V6M-NEXT:    push {r4, lr}
; CHECK-V6M-NEXT:    ldrb r1, [r0, #4]
; CHECK-V6M-NEXT:    ldrb r2, [r0, #5]
; CHECK-V6M-NEXT:    lsls r2, r2, #8
; CHECK-V6M-NEXT:    adds r4, r2, r1
; CHECK-V6M-NEXT:    bl __aeabi_uread4
; CHECK-V6M-NEXT:    mov r1, r4
; CHECK-V6M-NEXT:    pop {r4, pc}
;
; CHECK-V7M-LABEL: load6_align1_zext:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r4, lr}
; CHECK-V7M-NEXT:    push {r4, lr}
; CHECK-V7M-NEXT:    mov r4, r0
; CHECK-V7M-NEXT:    bl __aeabi_uread4
; CHECK-V7M-NEXT:    ldrb r2, [r4, #5]
; CHECK-V7M-NEXT:    ldrb r1, [r4, #4]
; CHECK-V7M-NEXT:    orr.w r1, r1, r2, lsl #8
; CHECK-V7M-NEXT:    pop {r4, pc}
;
; CHECK-ALIGNED-LABEL: load6_align1_zext:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    ldr r2, [r0]
; CHECK-ALIGNED-NEXT:    ldrh r1, [r0, #4]
; CHECK-ALIGNED-NEXT:    mov r0, r2
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  %tmp = load i48, i48* %a, align 1
  %ext = zext i48 %tmp to i64
  ret i64 %ext
}

define i64 @load6_align1_sext(i48* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load6_align1_sext:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r4, lr}
; CHECK-V6M-NEXT:    push {r4, lr}
; CHECK-V6M-NEXT:    movs r1, #5
; CHECK-V6M-NEXT:    ldrsb r1, [r0, r1]
; CHECK-V6M-NEXT:    lsls r1, r1, #8
; CHECK-V6M-NEXT:    ldrb r2, [r0, #4]
; CHECK-V6M-NEXT:    adds r4, r1, r2
; CHECK-V6M-NEXT:    bl __aeabi_uread4
; CHECK-V6M-NEXT:    mov r1, r4
; CHECK-V6M-NEXT:    pop {r4, pc}
;
; CHECK-V7M-LABEL: load6_align1_sext:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r4, lr}
; CHECK-V7M-NEXT:    push {r4, lr}
; CHECK-V7M-NEXT:    ldrsb.w r1, [r0, #5]
; CHECK-V7M-NEXT:    ldrb r2, [r0, #4]
; CHECK-V7M-NEXT:    orr.w r4, r2, r1, lsl #8
; CHECK-V7M-NEXT:    bl __aeabi_uread4
; CHECK-V7M-NEXT:    mov r1, r4
; CHECK-V7M-NEXT:    pop {r4, pc}
;
; CHECK-ALIGNED-LABEL: load6_align1_sext:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    ldr r2, [r0]
; CHECK-ALIGNED-NEXT:    ldrsh.w r1, [r0, #4]
; CHECK-ALIGNED-NEXT:    mov r0, r2
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  %tmp = load i48, i48* %a, align 1
  %ext = sext i48 %tmp to i64
  ret i64 %ext
}

define void @store6_align1(i48* %a, i48 %b) nounwind optsize minsize {
; CHECK-V6M-LABEL: store6_align1:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    mov r1, r0
; CHECK-V6M-NEXT:    strb r3, [r0, #4]
; CHECK-V6M-NEXT:    lsrs r0, r3, #8
; CHECK-V6M-NEXT:    strb r0, [r1, #5]
; CHECK-V6M-NEXT:    mov r0, r2
; CHECK-V6M-NEXT:    bl __aeabi_uwrite4
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: store6_align1:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    mov r1, r0
; CHECK-V7M-NEXT:    strb r3, [r0, #4]
; CHECK-V7M-NEXT:    lsrs r0, r3, #8
; CHECK-V7M-NEXT:    strb r0, [r1, #5]
; CHECK-V7M-NEXT:    mov r0, r2
; CHECK-V7M-NEXT:    bl __aeabi_uwrite4
; CHECK-V7M-NEXT:    pop {r7, pc}
;
; CHECK-ALIGNED-LABEL: store6_align1:
; CHECK-ALIGNED:       @ %bb.0: @ %entry
; CHECK-ALIGNED-NEXT:    strh r3, [r0, #4]
; CHECK-ALIGNED-NEXT:    str r2, [r0]
; CHECK-ALIGNED-NEXT:    bx lr
entry:
  store i48 %b, i48* %a, align 1
  ret void
}

define void @loadstore8_align4(double* %a, double* %b) nounwind optsize minsize {
; CHECK-V6M-LABEL: loadstore8_align4:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r4, lr}
; CHECK-V6M-NEXT:    push {r4, lr}
; CHECK-V6M-NEXT:    mov r4, r1
; CHECK-V6M-NEXT:    bl __aeabi_uread8
; CHECK-V6M-NEXT:    mov r2, r4
; CHECK-V6M-NEXT:    bl __aeabi_uwrite8
; CHECK-V6M-NEXT:    pop {r4, pc}
;
; CHECK-V7M-LABEL: loadstore8_align4:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r4, lr}
; CHECK-V7M-NEXT:    push {r4, lr}
; CHECK-V7M-NEXT:    mov r4, r1
; CHECK-V7M-NEXT:    bl __aeabi_uread8
; CHECK-V7M-NEXT:    mov r2, r4
; CHECK-V7M-NEXT:    bl __aeabi_uwrite8
; CHECK-V7M-NEXT:    pop {r4, pc}
;
entry:
  %tmp = load double, double* %a, align 1
  store double %tmp, double* %b, align 1
  ret void
}

define double @load8_align1(double* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load8_align1:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    bl __aeabi_uread8
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: load8_align1:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    bl __aeabi_uread8
; CHECK-V7M-NEXT:    pop {r7, pc}
;
entry:
  %tmp = load double, double* %a, align 1
  ret double %tmp
}

define void @store8_align1(double* %a, double %b) nounwind optsize minsize {
; CHECK-V6M-LABEL: store8_align1:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    mov r1, r3
; CHECK-V6M-NEXT:    mov r3, r0
; CHECK-V6M-NEXT:    mov r0, r2
; CHECK-V6M-NEXT:    mov r2, r3
; CHECK-V6M-NEXT:    bl __aeabi_uwrite8
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: store8_align1:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    mov r1, r3
; CHECK-V7M-NEXT:    mov r3, r0
; CHECK-V7M-NEXT:    mov r0, r2
; CHECK-V7M-NEXT:    mov r2, r3
; CHECK-V7M-NEXT:    bl __aeabi_uwrite8
; CHECK-V7M-NEXT:    pop {r7, pc}
entry:
  store double %b, double* %a, align 1
  ret void
}

define double @load8_align2(double* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load8_align2:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    bl __aeabi_uread8
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: load8_align2:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    bl __aeabi_uread8
; CHECK-V7M-NEXT:    pop {r7, pc}
entry:
  %tmp = load double, double* %a, align 2
  ret double %tmp
}

define i64 @load12_align1_trunc(i96* %a) nounwind optsize minsize {
; CHECK-V6M-LABEL: load12_align1_trunc:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r7, lr}
; CHECK-V6M-NEXT:    push {r7, lr}
; CHECK-V6M-NEXT:    bl __aeabi_uread8
; CHECK-V6M-NEXT:    pop {r7, pc}
;
; CHECK-V7M-LABEL: load12_align1_trunc:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r7, lr}
; CHECK-V7M-NEXT:    push {r7, lr}
; CHECK-V7M-NEXT:    bl __aeabi_uread8
; CHECK-V7M-NEXT:    pop {r7, pc}
entry:
  %tmp = load i96, i96* %a, align 1
  %ext = trunc i96 %tmp to i64
  ret i64 %ext
}

define void @store12_align4_trunc(i96* %a, i96 %b) nounwind optsize minsize {
; CHECK-V6M-LABEL: store12_align4_trunc:
; CHECK-V6M:       @ %bb.0: @ %entry
; CHECK-V6M-NEXT:    .save {r4, lr}
; CHECK-V6M-NEXT:    push {r4, lr}
; CHECK-V6M-NEXT:    mov r1, r3
; CHECK-V6M-NEXT:    mov r4, r0
; CHECK-V6M-NEXT:    mov r0, r2
; CHECK-V6M-NEXT:    mov r2, r4
; CHECK-V6M-NEXT:    bl __aeabi_uwrite8
; CHECK-V6M-NEXT:    adds r4, #8
; CHECK-V6M-NEXT:    ldr r0, [sp, #8]
; CHECK-V6M-NEXT:    mov r1, r4
; CHECK-V6M-NEXT:    bl __aeabi_uwrite4
; CHECK-V6M-NEXT:    pop {r4, pc}
;
; CHECK-V7M-LABEL: store12_align4_trunc:
; CHECK-V7M:       @ %bb.0: @ %entry
; CHECK-V7M-NEXT:    .save {r4, lr}
; CHECK-V7M-NEXT:    push {r4, lr}
; CHECK-V7M-NEXT:    mov r4, r0
; CHECK-V7M-NEXT:    mov r0, r2
; CHECK-V7M-NEXT:    mov r1, r3
; CHECK-V7M-NEXT:    mov r2, r4
; CHECK-V7M-NEXT:    bl __aeabi_uwrite8
; CHECK-V7M-NEXT:    ldr r0, [sp, #8]
; CHECK-V7M-NEXT:    add.w r1, r4, #8
; CHECK-V7M-NEXT:    bl __aeabi_uwrite4
; CHECK-V7M-NEXT:    pop {r4, pc}
entry:
  store i96 %b, i96* %a, align 1
  ret void
}
