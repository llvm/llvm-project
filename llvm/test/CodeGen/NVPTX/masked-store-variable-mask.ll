; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc < %s -march=nvptx64 -mcpu=sm_100 -mattr=+ptx88 | FileCheck %s -check-prefixes=CHECK
; RUN: %if ptxas-sm_100 && ptxas-isa-8.8 %{ llc < %s -march=nvptx64 -mcpu=sm_100 -mattr=+ptx88 | %ptxas-verify -arch=sm_100 %}

; Confirm that a masked store with a variable mask is scalarized before lowering

define void @global_variable_mask(ptr addrspace(1) %a, ptr addrspace(1) %b, <4 x i1> %mask) {
; CHECK-LABEL: global_variable_mask(
; CHECK:       {
; CHECK-NEXT:    .reg .pred %p<9>;
; CHECK-NEXT:    .reg .b16 %rs<9>;
; CHECK-NEXT:    .reg .b64 %rd<7>;
; CHECK-EMPTY:
; CHECK-NEXT:  // %bb.0:
; CHECK-NEXT:    ld.param.b8 %rs1, [global_variable_mask_param_2+3];
; CHECK-NEXT:    ld.param.b8 %rs3, [global_variable_mask_param_2+2];
; CHECK-NEXT:    and.b16 %rs4, %rs3, 1;
; CHECK-NEXT:    ld.param.b8 %rs5, [global_variable_mask_param_2+1];
; CHECK-NEXT:    and.b16 %rs6, %rs5, 1;
; CHECK-NEXT:    setp.ne.b16 %p2, %rs6, 0;
; CHECK-NEXT:    ld.param.b8 %rs7, [global_variable_mask_param_2];
; CHECK-NEXT:    and.b16 %rs8, %rs7, 1;
; CHECK-NEXT:    setp.ne.b16 %p1, %rs8, 0;
; CHECK-NEXT:    ld.param.b64 %rd5, [global_variable_mask_param_1];
; CHECK-NEXT:    ld.param.b64 %rd6, [global_variable_mask_param_0];
; CHECK-NEXT:    ld.global.v4.b64 {%rd1, %rd2, %rd3, %rd4}, [%rd6];
; CHECK-NEXT:    not.pred %p5, %p1;
; CHECK-NEXT:    @%p5 bra $L__BB0_2;
; CHECK-NEXT:  // %bb.1: // %cond.store
; CHECK-NEXT:    st.global.b64 [%rd5], %rd1;
; CHECK-NEXT:  $L__BB0_2: // %else
; CHECK-NEXT:    and.b16 %rs2, %rs1, 1;
; CHECK-NEXT:    setp.ne.b16 %p3, %rs4, 0;
; CHECK-NEXT:    not.pred %p6, %p2;
; CHECK-NEXT:    @%p6 bra $L__BB0_4;
; CHECK-NEXT:  // %bb.3: // %cond.store1
; CHECK-NEXT:    st.global.b64 [%rd5+8], %rd2;
; CHECK-NEXT:  $L__BB0_4: // %else2
; CHECK-NEXT:    setp.ne.b16 %p4, %rs2, 0;
; CHECK-NEXT:    not.pred %p7, %p3;
; CHECK-NEXT:    @%p7 bra $L__BB0_6;
; CHECK-NEXT:  // %bb.5: // %cond.store3
; CHECK-NEXT:    st.global.b64 [%rd5+16], %rd3;
; CHECK-NEXT:  $L__BB0_6: // %else4
; CHECK-NEXT:    not.pred %p8, %p4;
; CHECK-NEXT:    @%p8 bra $L__BB0_8;
; CHECK-NEXT:  // %bb.7: // %cond.store5
; CHECK-NEXT:    st.global.b64 [%rd5+24], %rd4;
; CHECK-NEXT:  $L__BB0_8: // %else6
; CHECK-NEXT:    ret;
  %a.load = load <4 x i64>, ptr addrspace(1) %a
  tail call void @llvm.masked.store.v4i64.p1(<4 x i64> %a.load, ptr addrspace(1) align 32 %b, <4 x i1> %mask)
  ret void
}

declare void @llvm.masked.store.v4i64.p1(<4 x i64>, ptr addrspace(1), <4 x i1>)
