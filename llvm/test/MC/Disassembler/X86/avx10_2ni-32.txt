# RUN: llvm-mc --disassemble %s -triple=i386 | FileCheck %s --check-prefixes=ATT
# RUN: llvm-mc --disassemble %s -triple=i386 -x86-asm-syntax=intel --output-asm-variant=1 | FileCheck %s --check-prefixes=INTEL

# VMPSADBW

# ATT:   vmpsadbw $123, %xmm4, %xmm3, %xmm2
# INTEL: vmpsadbw xmm2, xmm3, xmm4, 123
0xc4,0xe3,0x61,0x42,0xd4,0x7b

# ATT:   vmpsadbw $123, %xmm4, %xmm3, %xmm2 {%k7}
# INTEL: vmpsadbw xmm2 {k7}, xmm3, xmm4, 123
0x62,0xf3,0x66,0x0f,0x42,0xd4,0x7b

# ATT:   vmpsadbw $123, %xmm4, %xmm3, %xmm2 {%k7} {z}
# INTEL: vmpsadbw xmm2 {k7} {z}, xmm3, xmm4, 123
0x62,0xf3,0x66,0x8f,0x42,0xd4,0x7b

# ATT:   vmpsadbw $123, %ymm4, %ymm3, %ymm2
# INTEL: vmpsadbw ymm2, ymm3, ymm4, 123
0xc4,0xe3,0x65,0x42,0xd4,0x7b

# ATT:   vmpsadbw $123, %ymm4, %ymm3, %ymm2 {%k7}
# INTEL: vmpsadbw ymm2 {k7}, ymm3, ymm4, 123
0x62,0xf3,0x66,0x2f,0x42,0xd4,0x7b

# ATT:   vmpsadbw $123, %ymm4, %ymm3, %ymm2 {%k7} {z}
# INTEL: vmpsadbw ymm2 {k7} {z}, ymm3, ymm4, 123
0x62,0xf3,0x66,0xaf,0x42,0xd4,0x7b

# ATT:   vmpsadbw $123, %zmm4, %zmm3, %zmm2
# INTEL: vmpsadbw zmm2, zmm3, zmm4, 123
0x62,0xf3,0x66,0x48,0x42,0xd4,0x7b

# ATT:   vmpsadbw $123, %zmm4, %zmm3, %zmm2 {%k7}
# INTEL: vmpsadbw zmm2 {k7}, zmm3, zmm4, 123
0x62,0xf3,0x66,0x4f,0x42,0xd4,0x7b

# ATT:   vmpsadbw $123, %zmm4, %zmm3, %zmm2 {%k7} {z}
# INTEL: vmpsadbw zmm2 {k7} {z}, zmm3, zmm4, 123
0x62,0xf3,0x66,0xcf,0x42,0xd4,0x7b

# ATT:   vmpsadbw  $123, 268435456(%esp,%esi,8), %xmm3, %xmm2
# INTEL: vmpsadbw xmm2, xmm3, xmmword ptr [esp + 8*esi + 268435456], 123
0xc4,0xe3,0x61,0x42,0x94,0xf4,0x00,0x00,0x00,0x10,0x7b

# ATT:   vmpsadbw  $123, 291(%edi,%eax,4), %xmm3, %xmm2 {%k7}
# INTEL: vmpsadbw xmm2 {k7}, xmm3, xmmword ptr [edi + 4*eax + 291], 123
0x62,0xf3,0x66,0x0f,0x42,0x94,0x87,0x23,0x01,0x00,0x00,0x7b

# ATT:   vmpsadbw  $123, (%eax), %xmm3, %xmm2
# INTEL: vmpsadbw xmm2, xmm3, xmmword ptr [eax], 123
0xc4,0xe3,0x61,0x42,0x10,0x7b

# ATT:   vmpsadbw  $123, -512(,%ebp,2), %xmm3, %xmm2
# INTEL: vmpsadbw xmm2, xmm3, xmmword ptr [2*ebp - 512], 123
0xc4,0xe3,0x61,0x42,0x14,0x6d,0x00,0xfe,0xff,0xff,0x7b

# ATT:   vmpsadbw  $123, 2032(%ecx), %xmm3, %xmm2 {%k7} {z}
# INTEL: vmpsadbw xmm2 {k7} {z}, xmm3, xmmword ptr [ecx + 2032], 123
0x62,0xf3,0x66,0x8f,0x42,0x51,0x7f,0x7b

# ATT:   vmpsadbw  $123, -2048(%edx), %xmm3, %xmm2 {%k7} {z}
# INTEL: vmpsadbw xmm2 {k7} {z}, xmm3, xmmword ptr [edx - 2048], 123
0x62,0xf3,0x66,0x8f,0x42,0x52,0x80,0x7b

# ATT:   vmpsadbw  $123, 268435456(%esp,%esi,8), %ymm3, %ymm2
# INTEL: vmpsadbw ymm2, ymm3, ymmword ptr [esp + 8*esi + 268435456], 123
0xc4,0xe3,0x65,0x42,0x94,0xf4,0x00,0x00,0x00,0x10,0x7b

# ATT:   vmpsadbw  $123, 291(%edi,%eax,4), %ymm3, %ymm2 {%k7}
# INTEL: vmpsadbw ymm2 {k7}, ymm3, ymmword ptr [edi + 4*eax + 291], 123
0x62,0xf3,0x66,0x2f,0x42,0x94,0x87,0x23,0x01,0x00,0x00,0x7b

# ATT:   vmpsadbw  $123, (%eax), %ymm3, %ymm2
# INTEL: vmpsadbw ymm2, ymm3, ymmword ptr [eax], 123
0xc4,0xe3,0x65,0x42,0x10,0x7b

# ATT:   vmpsadbw  $123, -1024(,%ebp,2), %ymm3, %ymm2
# INTEL: vmpsadbw ymm2, ymm3, ymmword ptr [2*ebp - 1024], 123
0xc4,0xe3,0x65,0x42,0x14,0x6d,0x00,0xfc,0xff,0xff,0x7b

# ATT:   vmpsadbw  $123, 4064(%ecx), %ymm3, %ymm2 {%k7} {z}
# INTEL: vmpsadbw ymm2 {k7} {z}, ymm3, ymmword ptr [ecx + 4064], 123
0x62,0xf3,0x66,0xaf,0x42,0x51,0x7f,0x7b

# ATT:   vmpsadbw  $123, -4096(%edx), %ymm3, %ymm2 {%k7} {z}
# INTEL: vmpsadbw ymm2 {k7} {z}, ymm3, ymmword ptr [edx - 4096], 123
0x62,0xf3,0x66,0xaf,0x42,0x52,0x80,0x7b

# ATT:   vmpsadbw  $123, 268435456(%esp,%esi,8), %zmm3, %zmm2
# INTEL: vmpsadbw zmm2, zmm3, zmmword ptr [esp + 8*esi + 268435456], 123
0x62,0xf3,0x66,0x48,0x42,0x94,0xf4,0x00,0x00,0x00,0x10,0x7b

# ATT:   vmpsadbw  $123, 291(%edi,%eax,4), %zmm3, %zmm2 {%k7}
# INTEL: vmpsadbw zmm2 {k7}, zmm3, zmmword ptr [edi + 4*eax + 291], 123
0x62,0xf3,0x66,0x4f,0x42,0x94,0x87,0x23,0x01,0x00,0x00,0x7b

# ATT:   vmpsadbw  $123, (%eax), %zmm3, %zmm2
# INTEL: vmpsadbw zmm2, zmm3, zmmword ptr [eax], 123
0x62,0xf3,0x66,0x48,0x42,0x10,0x7b

# ATT:   vmpsadbw  $123, -2048(,%ebp,2), %zmm3, %zmm2
# INTEL: vmpsadbw zmm2, zmm3, zmmword ptr [2*ebp - 2048], 123
0x62,0xf3,0x66,0x48,0x42,0x14,0x6d,0x00,0xf8,0xff,0xff,0x7b

# ATT:   vmpsadbw  $123, 8128(%ecx), %zmm3, %zmm2 {%k7} {z}
# INTEL: vmpsadbw zmm2 {k7} {z}, zmm3, zmmword ptr [ecx + 8128], 123
0x62,0xf3,0x66,0xcf,0x42,0x51,0x7f,0x7b

# ATT:   vmpsadbw  $123, -8192(%edx), %zmm3, %zmm2 {%k7} {z}
# INTEL: vmpsadbw zmm2 {k7} {z}, zmm3, zmmword ptr [edx - 8192], 123
0x62,0xf3,0x66,0xcf,0x42,0x52,0x80,0x7b

# YMM Rounding

# ATT:   vaddpd {rn-sae}, %ymm4, %ymm3, %ymm2
# INTEL: vaddpd ymm2, ymm3, ymm4, {rn-sae}
0x62,0xf1,0xe1,0x18,0x58,0xd4

# ATT:   vaddpd {rd-sae}, %ymm4, %ymm3, %ymm2 {%k7}
# INTEL: vaddpd ymm2 {k7}, ymm3, ymm4, {rd-sae}
0x62,0xf1,0xe1,0x3f,0x58,0xd4

# ATT:   vaddpd {rz-sae}, %ymm4, %ymm3, %ymm2 {%k7} {z}
# INTEL: vaddpd ymm2 {k7} {z}, ymm3, ymm4, {rz-sae}
0x62,0xf1,0xe1,0xff,0x58,0xd4

# ATT:   vaddph {rn-sae}, %ymm4, %ymm3, %ymm2
# INTEL: vaddph ymm2, ymm3, ymm4, {rn-sae}
0x62,0xf5,0x60,0x18,0x58,0xd4

# ATT:   vaddph {rd-sae}, %ymm4, %ymm3, %ymm2 {%k7}
# INTEL: vaddph ymm2 {k7}, ymm3, ymm4, {rd-sae}
0x62,0xf5,0x60,0x3f,0x58,0xd4

# ATT:   vaddph {rz-sae}, %ymm4, %ymm3, %ymm2 {%k7} {z}
# INTEL: vaddph ymm2 {k7} {z}, ymm3, ymm4, {rz-sae}
0x62,0xf5,0x60,0xff,0x58,0xd4

# ATT:   vaddps {rn-sae}, %ymm4, %ymm3, %ymm2
# INTEL: vaddps ymm2, ymm3, ymm4, {rn-sae}
0x62,0xf1,0x60,0x18,0x58,0xd4

# ATT:   vaddps {rd-sae}, %ymm4, %ymm3, %ymm2 {%k7}
# INTEL: vaddps ymm2 {k7}, ymm3, ymm4, {rd-sae}
0x62,0xf1,0x60,0x3f,0x58,0xd4

# ATT:   vaddps {rz-sae}, %ymm4, %ymm3, %ymm2 {%k7} {z}
# INTEL: vaddps ymm2 {k7} {z}, ymm3, ymm4, {rz-sae}
0x62,0xf1,0x60,0xff,0x58,0xd4
