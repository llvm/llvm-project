// RUN: llvm-mc -triple=amdgcn -mcpu=gfx1300 -show-encoding %s | FileCheck --check-prefix=GFX13 %s

v_cvt_to_tensor_i4_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x90,0xdd,0x05,0x01,0x00,0xa8,0x02,0x81,0x00,0x00]

v_cvt_to_tensor_i4_fp32 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_fp32 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x90,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_i4_fp32 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_fp32 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x90,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_i4_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x91,0xdd,0x05,0x01,0x00,0xa8,0x02,0x81,0x00,0x00]

v_cvt_to_tensor_i4_fp16 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_fp16 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x91,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x00,0x00]

v_cvt_to_tensor_i4_fp16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_fp16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x91,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_i4_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x92,0xdd,0x05,0x01,0x00,0xa8,0x02,0x81,0x00,0x00]

v_cvt_to_tensor_i4_bf16 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_bf16 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x92,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x00,0x00]

v_cvt_to_tensor_i4_bf16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i4_bf16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x92,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_u4_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x93,0xdd,0x05,0x01,0x00,0xa8,0x02,0x81,0x00,0x00]

v_cvt_to_tensor_u4_fp32 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_fp32 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x93,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_u4_fp32 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_fp32 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x93,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_u4_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x94,0xdd,0x05,0x01,0x00,0xa8,0x02,0x81,0x00,0x00]

v_cvt_to_tensor_u4_fp16 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_fp16 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x94,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x00,0x00]

v_cvt_to_tensor_u4_fp16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_fp16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x94,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_u4_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x95,0xdd,0x05,0x01,0x00,0xa8,0x02,0x81,0x00,0x00]

v_cvt_to_tensor_u4_bf16 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_bf16 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x95,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x00,0x00]

v_cvt_to_tensor_u4_bf16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u4_bf16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x95,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_i8_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x96,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_i8_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x96,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_i8_fp32 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_fp32 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x96,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_i8_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x97,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_i8_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x97,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_i8_fp16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_fp16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x97,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_i8_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x98,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_i8_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x98,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_i8_bf16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_i8_bf16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x98,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_u8_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x99,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_u8_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x99,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_u8_fp32 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_fp32 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x99,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_u8_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9a,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_u8_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9a,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_u8_fp16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_fp16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x9a,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_u8_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9b,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_u8_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9b,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_u8_bf16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_u8_bf16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x9b,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_fp8_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9c,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_fp8_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9c,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_fp8_fp32 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_fp32 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9c,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_fp8_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9d,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_fp8_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9d,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_fp8_fp16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_fp16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x9d,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_fp8_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9e,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_fp8_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9e,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_fp8_bf16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp8_bf16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0x9e,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_bf8_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9f,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_bf8_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9f,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_bf8_fp32 v1, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_fp32 v1, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0x9f,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_bf8_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa0,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_bf8_fp16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_fp16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa0,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_bf8_fp16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_fp16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0xa0,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_bf8_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa1,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_bf8_bf16 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_bf16 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa1,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00]

v_cvt_to_tensor_bf8_bf16 v1, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf8_bf16 v1, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0xa1,0xdd,0x05,0x01,0x00,0xa8,0x00,0x00,0x01,0x00]

v_cvt_to_tensor_fp16_fp32 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_fp32 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa2,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_fp16_fp32 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_fp32 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa2,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_fp16_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa2,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x01,0x00]

v_cvt_to_tensor_fp16_fp16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_fp16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa3,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_fp16_fp16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_fp16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa3,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_fp16_fp16 v1, v2, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_fp16 v1, v2, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0xa3,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x01,0x00]

v_cvt_to_tensor_fp16_bf16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_bf16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa4,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_fp16_bf16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_bf16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa4,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_fp16_bf16 v1, v2, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_fp16_bf16 v1, v2, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0xa4,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x01,0x00]

v_cvt_to_tensor_bf16_fp32 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_fp32 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa5,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_bf16_fp32 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_fp32 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa5,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_bf16_fp32 v1, v2, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_fp32 v1, v2, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa5,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x01,0x00]

v_cvt_to_tensor_bf16_fp16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_fp16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa6,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_bf16_fp16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_fp16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa6,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_bf16_fp16 v1, v2, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_fp16 v1, v2, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0xa6,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x01,0x00]

v_cvt_to_tensor_bf16_bf16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_bf16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa7,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_bf16_bf16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_bf16 v1, v2, v3, v4, v[5:8] aux_data:42 clamp ; encoding: [0x01,0x10,0xa7,0xde,0x05,0x01,0x00,0xa8,0x02,0x01,0x00,0x00,0x03,0x41,0x10,0x00]

v_cvt_to_tensor_bf16_bf16 v1, v2, v[5:6] aux_data:42 clamp
// GFX13: v_cvt_to_tensor_bf16_bf16 v1, v2, v[5:6] aux_data:42 clamp ; encoding: [0x01,0x10,0xa7,0xdd,0x05,0x01,0x00,0xa8,0x02,0x01,0x01,0x00]

