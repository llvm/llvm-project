; NOTE: Assertions have been autogenerated by utils/update_analyze_test_checks.py UTC_ARGS: --version 5
; RUN: opt -S -disable-output -passes='print<access-info>' %s 2>&1 | FileCheck %s

target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"

; The inner two loops of a naive matrix multiplication.
; Not annotated as parallel, so the outer loop should not be analyzed.
define void @outer_loop_not_parallel(i64 %N, i64 %M, ptr noalias %A, ptr %B, ptr %C) {
; CHECK-LABEL: 'outer_loop_not_parallel'
; CHECK-NEXT:    inner.loop:
; CHECK-NEXT:      Memory dependences are safe
; CHECK-NEXT:      Dependences:
; CHECK-NEXT:      Run-time memory checks:
; CHECK-NEXT:      Grouped accesses:
; CHECK-EMPTY:
; CHECK-NEXT:      Non vectorizable stores to invariant address were not found in loop.
; CHECK-NEXT:      SCEV assumptions:
; CHECK-EMPTY:
; CHECK-NEXT:      Expressions re-written:
; CHECK-NEXT:    loop.header:
; CHECK-NEXT:      Report: loop is not the innermost loop
; CHECK-NEXT:      Dependences:
; CHECK-NEXT:      Run-time memory checks:
; CHECK-NEXT:      Grouped accesses:
; CHECK-EMPTY:
; CHECK-NEXT:      Non vectorizable stores to invariant address were not found in loop.
; CHECK-NEXT:      SCEV assumptions:
; CHECK-EMPTY:
; CHECK-NEXT:      Expressions re-written:
;
entry:
  br label %loop.header

loop.header:
  %i = phi i64 [ %i.next, %loop.latch ], [ 0, %entry ]
  %M.is.zero = icmp eq i64 %M, 0
  br i1 %M.is.zero, label %loop.latch, label %inner.loop

inner.loop:
  %j = phi i64 [ %j.next, %inner.loop ], [ 0, %loop.header ]
  %a = phi float [ %a.next, %inner.loop ], [ 0.0, %loop.header ]
  %b.addr = getelementptr inbounds float, ptr %B, i64 %j
  %b = load float, ptr %b.addr, align 4
  %jxM = mul i64 %j, %M
  %jxMpi = add i64 %jxM, %i
  %c.addr = getelementptr inbounds float, ptr %C, i64 %jxMpi
  %c = load float, ptr %c.addr, align 4
  %mul = fmul float %b, %c
  %a.next = fadd float %a, %mul
  %j.next = add nuw nsw i64 %j, 1
  %inner.exitcond = icmp eq i64 %j.next, %M
  br i1 %inner.exitcond, label %loop.latch, label %inner.loop

loop.latch:
  %a.lcssa = phi float [ 0x0, %loop.header ], [ %a.next, %inner.loop ]
  %a.addr = getelementptr inbounds float, ptr %A, i64 %i
  store float %a.lcssa, ptr %a.addr, align 4
  %i.next = add nuw nsw i64 %i, 1
  %loop.exitcond = icmp eq i64 %i.next, %N
  br i1 %loop.exitcond, label %exit, label %loop.header

exit:
  ret void
}


; The inner two loops of a naive matrix multiplication.
; The outer loop is annotated as parallel.
define void @outer_loop_parallel(i64 %N, i64 %M, ptr noalias %A, ptr %B, ptr %C) {
; CHECK-LABEL: 'outer_loop_parallel'
; CHECK-NEXT:    inner.loop:
; CHECK-NEXT:      Memory dependences are safe
; CHECK-NEXT:      Dependences:
; CHECK-NEXT:      Run-time memory checks:
; CHECK-NEXT:      Grouped accesses:
; CHECK-EMPTY:
; CHECK-NEXT:      Non vectorizable stores to invariant address were not found in loop.
; CHECK-NEXT:      SCEV assumptions:
; CHECK-EMPTY:
; CHECK-NEXT:      Expressions re-written:
; CHECK-NEXT:    loop.header:
; CHECK-NEXT:      Memory dependences are safe
; CHECK-NEXT:      Dependences:
; CHECK-NEXT:      Run-time memory checks:
; CHECK-NEXT:      Grouped accesses:
; CHECK-EMPTY:
; CHECK-NEXT:      Non vectorizable stores to invariant address were not found in loop.
; CHECK-NEXT:      SCEV assumptions:
; CHECK-EMPTY:
; CHECK-NEXT:      Expressions re-written:
;
entry:
  br label %loop.header

loop.header:
  %i = phi i64 [ %i.next, %loop.latch ], [ 0, %entry ]
  %M.is.zero = icmp eq i64 %M, 0
  br i1 %M.is.zero, label %loop.latch, label %inner.loop

inner.loop:
  %j = phi i64 [ %j.next, %inner.loop ], [ 0, %loop.header ]
  %a = phi float [ %a.next, %inner.loop ], [ 0.0, %loop.header ]
  %b.addr = getelementptr inbounds float, ptr %B, i64 %j
  %b = load float, ptr %b.addr, align 4, !llvm.access.group !1
  %jxM = mul i64 %j, %M
  %jxMpi = add i64 %jxM, %i
  %c.addr = getelementptr inbounds float, ptr %C, i64 %jxMpi
  %c = load float, ptr %c.addr, align 4, !llvm.access.group !1
  %mul = fmul float %b, %c
  %a.next = fadd float %a, %mul
  %j.next = add nuw nsw i64 %j, 1
  %inner.exitcond = icmp eq i64 %j.next, %M
  br i1 %inner.exitcond, label %loop.latch, label %inner.loop

loop.latch:
  %a.lcssa = phi float [ 0x0, %loop.header ], [ %a.next, %inner.loop ]
  %a.addr = getelementptr inbounds float, ptr %A, i64 %i
  store float %a.lcssa, ptr %a.addr, align 4, !llvm.access.group !1
  %i.next = add nuw nsw i64 %i, 1
  %loop.exitcond = icmp eq i64 %i.next, %N
  br i1 %loop.exitcond, label %exit, label %loop.header, !llvm.loop !0

exit:
  ret void
}

!0 = distinct !{!0, !{!"llvm.loop.parallel_accesses", !1}}
!1 = distinct !{}
